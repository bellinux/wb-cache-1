0|50|Public
5000|$|Consumer protection:Product testing; labelling; <b>conformity</b> <b>checks</b> with {{marketing}} standards (e.g. fruit and vegetables) ...|$|R
50|$|<b>Conformity</b> <b>checks</b> and {{integrity}} checks need not covered in all business needs, it’s strictly under the database architecture's discretion.|$|R
40|$|Abstract. Checking {{whether the}} agreed service quality {{attributes}} are fulfilled or maintained during the service life-cycle {{is a very}} important task for SLA (Service Level Agreement) enforcement. In this paper, we leverage conformance checking techniques developed for computational services to automate the <b>conformity</b> <b>checking</b> of transport & logistics services. Our solution extends the WS-Agreement metamodel to support the definition of frame and specific SLAs. With this extension, we define a new validation operation for the <b>conformity</b> <b>check</b> of transport & logistics SLAs based on CSPs solvers. The key contribution of our work is that, as far as we know, it is the first definition of an automated <b>conformity</b> <b>check</b> solution for long term agreements in the transport & logistics domain. Nonetheless, other domains in which similar SLAs are defined can also benefit from our solution. ...|$|R
40|$|International audienceThe {{field of}} {{construction}} engineering {{is governed by}} an important volume of legal texts. Each of these texts provide a set of requirements by means of sentences written in natural language. These texts support <b>conformity</b> <b>checking</b> process of objects in construction engineering. Automate or at-least semi-automate this <b>conformity</b> <b>checking</b> process is the target of our project. This automation imposes {{to be able to}} make legal requirements processable. Thus, we envisage to rephrase natural language sentences into a set of atomic requirements (i. e a triple:). Further, we must identify between the facts found in a given sentence, the exist relations (e. g sentence = f act 1 AND f act 2 or IF f act 1 THEN f act 2, etc.), expressible using logical operators. For facts extraction, we have used Open Information Extraction-systems. Since they face a drop of precision mainly due to multi-word expressions, provide a method to handle them before OIE itself. Moreover, we also tackle the problem of enumeration items to improve OIEperformance. Using OIE for legal sentences semantics handling, handling of multi-word expressions and contextual phrases and finally computation of relations between facts constitute the originality of this work. Such decomposition is the prerequisite to our target: automatic <b>conformity</b> <b>checking...</b>|$|R
40|$|International audienceThis paper {{presents}} an ontological method {{aimed at the}} capitalization of expert knowledge {{in the context of}} semi-automatic checking model of the conformity of construction projects against a set of construction norms. The efficiency of our ontology-based reasoning model relies on two keystones. First, {{it is based on the}} matching of construction projects represented by RDF graphs to technical conformity queries formalized as SPARQL queries. Second, our reasoning model integrates the meta-knowledge on <b>conformity</b> <b>checking</b> process. Our approach of capitalizing such knowledge is based on the development of semantic annotations of conformity queries and organizing them into a query base. This helps to formalize the expert knowledge in form of expert rules scheduling the matching operations of the checking process. Semantic annotations of conformity queries also help to generate a structured conformity report, which interprets the results of reasoning in terms of <b>conformity</b> <b>checking</b> in construction...|$|R
40|$|We {{address the}} problem of {{describing}} and analyzing not only functional but also performance properties of software architectures in a formal framework. We thus develop an architectural description language with a precise syntax and semantics and we illustrate the various kinds of analysis that can be conducted on its descriptions, such as architectural compatibility and <b>conformity</b> <b>checking,</b> functional verification, and performance evaluation. The proposed architectural description language is based on stochastically timed process algebras by virtue of their compositionality, which makes them suited to work with at the architectural level...|$|R
40|$|Conformity Study for Austria Directive 2004 / 38 /EC on {{the right}} of {{citizens}} of the Union and their family members to move and reside freely within the territory of the Member StatesThis National Conformity Study has been prepared by Milieu Ltd. in consortium with the Europa Institute, Edinburgh University under Contract No JLS/ 2007 /C 4 / 004 - 30 -CE- 0159638 / 00 - 31. The actual <b>conformity</b> <b>checking</b> was carried out in Austria by Werner Schroeder and was concluded on 1 August. The study {{does not take into account}} any subsequent changes in EU law and national legislation and/or administrative practice. The views expressed herein are those of the consultants alone and do not necessarily represen...|$|R
40|$|This {{contribution}} {{presents a}} Bayesian {{approach to the}} issue of linking of the results from key comparison measurements. A mathematical treatment based on Bayesian statistics for the analysis of the results from two comparisons with some joint participants is described. This robust statistical analysis provides expressions and standard uncertainties for the key comparison reference value (KCRV) and the degree of equivalence (DOE) as well as a <b>conformity</b> <b>check</b> without any assumption on a priority of one of the comparisons. In addition to the derivation of the mathematical formulae to be used for this type of "distributed linking", we also present one synthetic and one real linking example and discuss possible applications of this new linking procedure...|$|R
40|$|International audienceExperts in {{construction}} engineering are overwhelmed by regulatory texts. It {{is a heavy}} task to go through these texts and get an unambiguous list of requirements they contain. Moreover, {{with regard to the}} number of texts and the diversity of their writers, we cannot neglect the possibility of getting inconsistencies. Finally, these requirements are to be put close to digital representation of buildings to detect potential non-conformities. This paper examines these problems and envisions solutions to help experts. We thus envisage to automate detection and extraction of business rules in regulatory texts. Next, we propose to formalise identified requirements as SPARQL queries. These queries will serve for <b>conformity</b> <b>checking</b> on OWL-representation of buildings. Moreover, we plan to leverage these queries to detect inconsistencies in regulatory texts...|$|R
40|$|The {{installation}} of a multifunctional railway portal (or TCCS - Train <b>Conformity</b> <b>Check</b> system) can contribute to improve {{the safety of a}} railway infrastructure. The TCCS can detect the conformity of the trains traveling along the tracks, and can transfer the status information to a main traffic control center. This paper proposes a methodological approach based on Analytic Hierarchy Process (AHP) to evaluate the optimal locations to install a TCCS on a railway section. The eligibility and ranking of the potential sites have been defined with respect to constraints related to the rail line track layout and geometry, the TCCS technological features, and the required safety distance allowing the train to stop. The proposed approach has been applied to a real case study on the Italian railway...|$|R
40|$|The Water Framework Directive 2000 / 60 /EC (WFD) sets {{an overall}} {{framework}} for water management in Europe. The main instrument for its implementation is the river basin management plan (RBMP) {{and the accompanying}} programme of measures. As we are almost {{in the end of}} the WFD implementation cycle (in 2015), the paper presents the progress regarding the RBMPs developed by each EU 27 member state (MS). A review of the <b>conformity</b> <b>checks</b> regarding the obligation {{and the quality of the}} RBMPs is provided for all EU 27 MS. Special focus is given to Greece attempting a comparative analysis of its RBMPs. Although they comply with the context requirements set by the WFD, there have been problems occurring as consequences intense disputes. Special focus is given in the economic assessment. Different methodologies used and the lack of data are the main problems identified. © 2014 Balaban Desalination Publications. All rights reserved...|$|R
40|$|ABSTRACT: Ten simple {{sequence}} repeat (SSR) loci {{were used}} to study polymorphism in 54 almond genotypes. All genotypes {{used in this study}} originated from almond-growing areas in Tunisia with different climatic conditions ranging from the sub-humid to the arid and are preserved in the national collection at Sidi Bouzid. Using ten SSR, 130 alleles and 250 genotypes were revealed. In order to develop an identification key for each accession, the data were analysed separately for each microsatellite marker. The most polymorphic mic-rosatellite (CPDCT 042) was used as a first marker. Two microsatellite loci (CPDCT 042 and CPDCT 025) were sufficient to discriminate among all accessions studied. Neighbour-joining clustering and principal coordinate analysis were performed to arrange the genotypes ac-cording to their genetic relationships and origin. The results are discussed in the context of almond collection management, <b>conformity</b> <b>checks,</b> identification of homonyms, and screen-ing of the local almond germplasm. Furthermore, this microsatellite-based key is a first step toward a marker-assisted identification almond database...|$|R
40|$|Specific {{microsatellites}} (SSRs) markers {{were used}} to characterize a set of 32 Tunisian pomegranate (Punica granatum L.) cultivars. Using 13 SSR primers, a total of 40 alleles and 46 genotypes have been identified. As a result, data proved that {{a high level of}} polymorphism characterizes the Tunisian pomegranate germplasm at the DNA level. The derived Neighbour-joining (NJ) dendrogram constructed using DAS genetic distances exhibited a genetic diversity structured independently from the geographical origin of cultivars and their denomination. This result suggested that a common genetic basis may characterize Tunisian pomegranate cultivars despite their phenotypic divergences. Furthermore, based on the multilocus genotypes a cultivar’s identification key has been established and permitted to unambiguously differentiate between varieties. The obtained results are discussed in term of establishment and management of a national collection of pomegranate varieties, <b>conformity</b> <b>checks,</b> identification of homonyms and synonyms, and screening of the local resources. Furthermore, this microsatellite-based key is a first step towards a marker-assisted identification pomegranate database. Peer reviewe...|$|R
40|$|International audienceIn {{machining}} workshops, workpieces {{are produced}} according to dimensions known as manufacturing dimensions. For the same workpiece {{and the same}} manufacturing plan, several sets of manufacturing dimensions can be used but none satisfy simultaneously the two main missions workshops need to fulfil: (a) Ensuring conformity of products to their design dimension tolerances (also called blueprint tolerances) and (b) steering machines in order to compensate for tool wear. The set of manufacturing dimensions obtained from the design dimensions using the minimal chain of dimensions method is optimal for a <b>conformity</b> <b>check</b> of workpieces but is practically unusable for steering machines because {{of the complexity of}} its relationships toward the tool correctors and tools dimensions. The pilot dimensions method consists in, on the one hand, identifying and representing these tool correctors and these tool/program dimensions on the production drawings (besides the manufacturing dimensions) and, on other the other hand, determining their correction values through a mathematical set of relations after having measured the manufacturing dimensions on a workpiece. Doing so will strongly reduce adjustment time, reduce the number of workpieces used for adjustments and greatly enhance the quality of workpiece batches...|$|R
40|$|Due to an {{increasing}} number of regulatory restric- tions and a rising product complexity, compliance and safety management have become key issues for enterprises today. Besides the requirements to build safe products, documentation of safety compliance and in-use restrictions have to be archived and published by law. Some research projects have already tackled the problem of visually identifying hazards zones within virtual environments. Other approaches deal with the formal analysis of safety issues in expert systems for <b>conformity</b> <b>checks.</b> What is still missing is the bridge between visual representation and documentation. The virtual reality (VR) approaches do not support storage and processing of identified hazards, furthermore 3 D models have to be prepared and converted to VR formats, which does not allow “online” analysis. Expert systems only cover an abstract, textual definition of hazard zones, which separates the safety domain from design. This paper describes a framework for “product safety information” to identify, track and document hazards and protective measures throughout the product life cycle. The underlying data model supports integration of geometric references into the safety information, similar to the use of product manufacturing information like GD&T...|$|R
40|$|The {{foreseen}} Phase 2 pixel upgrades at the LHC {{have very}} challenging {{requirements for the}} design of hybrid pixel readout chips. A versatile pixel simulation platform is as an essential development tool for the design, verification and optimization of both the system architecture and the pixel chip building blocks (Intellectual Properties, IPs). This work is focused on the implemented simulation and verification environment named VEPIX 53, built using the SystemVerilog language and the Universal Verification Methodology (UVM) class library in the framework of the RD 53 Collaboration. The environment supports pixel chips at different levels of description: its reusable components feature the generation of different classes of parameterized input hits to the pixel matrix, monitoring of pixel chip inputs and outputs, <b>conformity</b> <b>checks</b> between predicted and actual outputs and collection of statistics on system performance. The environment has been tested performing a study of shared architectures of the trigger latency buffering section of pixel chips. A fully shared architecture and a distributed one have been described at behavioral level and simulated; the resulting memory occupancy statistics and hit loss rates have subsequently been compared. Comment: 15 pages, 10 figures (11 figure files), submitted to Journal of Instrumentatio...|$|R
40|$|Masters Coursework - Masters of Early Childhood Education (MECE) This {{research}} {{focuses on}} the design and validation of a questionnaire that intends to investigate young mothers' child rearing practices in the social psychology across cultures framework. This instrument would assist teachers primarily {{in the field of}} early childhood care and education in creating more culturally responsive institutional care services. Questions about the regularity of young mothers' actions with regards to particular child rearing practices were asked in the questionnaire. The questionnaire was designed to measure five construct: a. autonomy, b. separateness, <b>c.</b> <b>conformity,</b> d. relatedness, and e. attachment. The first four constructs relate to the individualism-collectivism framework and the fifth to John Bowlby's attachment theory. A pilot test among (n= 34) young Cape Coloured mothers in South Africa, between the ages of 18 and 35 was conducted and resulted in four of the five scales being validated. The findings show that the cultural complexities of childrearing practices within this group of people however calls for further research...|$|R
40|$|Mestrado em Engenharia Alimentar - Instituto Superior de AgronomiaIn this study, {{the data}} of {{foodstuffs}} samples collected at retail and subjected to analytical determinations, {{in the period of}} 2008 to 2010, under the National Sampling Plan (NSP) by ASAE –The Portuguese Authority for Safety Food and Economic, were analyzed. The main objective {{of the study was to}} evaluate the microbiological data in the NSP report and to identify the source of the non <b>conformities,</b> <b>checking</b> the development of the foodstuff groups with higher susceptibility to contamination by microbiological hazards. During the mentioned period 5541 samples were collected among various groups of foodstuffs and the data from 1966 samples submitted to microbiological analysis were studied. The total non conformities of NSP increased from 3. 4 % to 6. 9 % and in 2010 around a third were of microbiological origin. The microbiological non conformities were detected in 3. 8 % (2008), 3. 6 % (2009) and 5. 4 % (2010) of the samples analyzed and mainly observed in meat and meat products, milk and milk-based products. The largest number of non conformities samples in the group of meat and meat products was due to the presence of Salmonella, whereas in the group of milk and milk-based products this was due to the presence of L. monocytogene...|$|R
40|$|International audienceThis paper {{presents}} {{an approach that}} aims to suggest to Construction experts a formal representation of given requirements. When available as formal expressions, requirements are suitable for automatic compliance checking. The goal of <b>conformity</b> <b>checking</b> is {{to answer the question}} " which components of a building project are non-compliant to a set of construction rules? ". When we consider both the size and the complexity of corpora of construction requirements, a computer-aided compliance checking process would be beneficial for experts. Such checking process requires a formal representation of building projects and construction rules. Nowadays, there are various tools for the formal designing of building products obeying to the Industry Foundation Classes (IFC) standard (e. g. Revit Building of Autodesk, ArchiCAD by Graphisoft, and ACTIVe 3 d by ARCHIMEN GROUP). On the other hand, {{to the best of our}} knowledge, there isn't any tool which allows business experts to convert automatically and in a formal language, construction rules written in natural language. We propose an approach which intends to convert automatically natural language requirements into formal expressions. This approach relies on the IfcOWL ontology and represents formal rules as SPARQL queries using the RAINS language as an interim result. RAINS is a controlled natural language (CNL), whose sentences can be transformed automatically into SPARQL queries, and as a CNL it hides the complexity of formal languages...|$|R
40|$|Purpose. Experimental {{definition}} of {{values of the}} dynamic parameters characterizing traffic safety of the rail autobus in tangent and curved track sections and switches, and <b>conformity</b> <b>check</b> to their demands of normative documents. Methodology. Test methods are based on comparison of experimentally determined dynamic qualities of the autobus with their admitted values. As the parameters defining traffic safety, the numerical value of which is resulted further, are used the following ones: the derailment stability coefficient; vertical dynamics coefficients {{in the first and}} second steps of spring suspension; the frame forces; smoothness of movement. Determination of the derailment stability coefficient is performed by a known technique. Vertical dynamics coefficients in the each step of spring suspension are defined as the relation of dynamic vertical bending flexures to magnitudes of their static values corresponding to the set occupancy of the autobus. Findings. Coefficient values of the vertical dynamics of train carriages in the first and second steps of spring suspension, as well as the value of frame forces and parameters of movement smoothness did not exceed the admissible standard values, and was higher than the minimum admissible value. Originality. Values of the parameters characterizing dynamic qualities of new type of the rail autobus are obtained, and possibility of its operation on the main ways of the railways of Ukraine is shown. Practical value. Admissible speeds of the rail autobus traffic on various railway track sections are defined...|$|R
40|$|Since the EURO V {{standards}} for heavy-duty engines, the European emissions legislation requires {{to verify the}} conformity of heavy-duty engines with the applicable emissions certification standards: these provisions are identified as “In Service Conformity” (ISC). It was considered impractical and expensive to adopt an ISC scheme for heavy-duty vehicles requiring the removal of engines from vehicles to test pollutant emissions against legislative limits. Therefore, it was proposed to develop a protocol for in-service <b>conformity</b> <b>checking</b> of heavy-duty vehicles based {{on the use of}} Portable Emission Measurement Systems (PEMS). As a result, ISC testing based on PEMS was introduced in the EURO V and the EURO VI standards. The corresponding administrative and technical provisions were formulated in the European Regulations 582 / 2011 and 64 / 2012. The above route was followed for non-road engines as well: preliminary research activities studied and confirmed the possibility to apply the methods developed for heavy-duty engines with minor modifications. The basis for the introduction of ISC provisions based on the PEMS approach into the European NRMM type-approval legislation has been established in several texts. The NRMM PEMS Pilot Program was launched to facilitate the introduction into the European NRMM emissions legislation of use of PEMS as a tool for ISC. This had to be achieved by improving the technical procedures (e. g. available from the heavy-duty scheme) and increasing the awareness of the different stakeholders about PEMS as a new regulatory tool. JRC. F. 8 -Sustainable Transpor...|$|R
40|$|In {{order to}} improve quality, any {{activity}} performed in garment production enterprises, must adhere to the following principles: the technical documentation must be observed first, and also all resources necessary for the proper functioning of the production process; <b>conformity</b> <b>check</b> {{must be carried out}} to fulfill production goals in advance; the technical specifications and documentation must be implemented and for proper execution there must exist a control method, consisting in discovering defects and correct them. In the garment industry, the situation is more difficult because of the large number of features present in its complex products, and the problems that may arise must be estimated. Thus, for different activities in quality assurance, experiments have been carried out which show that even the measurement results can be affected by human error. The training of inspectors is important inspection requires a high level of judgment in specific cases, which can be acquired only by experience. In many inspection situations, judgment is essential. Therefore, garment manufacturers must boost inspections, {{in order to keep the}} technological process under control. This paper focuses on meeting certain objectives in establishing certain control structures for compliance of processes, by presenting a few criteria. After analyzing quality problems along the process flow, both in terms of the manufacturing process and product quality, we propose customized solutions by product type, to prevent and solve quality issues. This analysis of the control plan for the conformity of the technological processes will improve the production of garment manufacturers, from a technical as well as economical standpoint...|$|R
40|$|In-use testing with Portable Emissions Measurement Systems (PEMS) has {{received}} attention by {{policy makers and}} industry as an effective and cost-efficient means to verify emissions {{of a wide range}} of vehicles. We provide an overview of the state-of-the-art PEMS in-use emissions testing in the current and future European emissions legislation for light-duty and heavy-duty vehicles as well as non-road mobile machinery. For obtaining type approval in European Union (EU), light-duty vehicles have to comply with Euro 6 emission standards from January 2014 onward. In parallel, a new test procedure will complement standard emissions testing in the laboratory to control gaseous and particulate emissions over a wide range of real-world driving conditions. Two candidate procedures are developed at present, i. e., random cycle testing and on-road emissions testing with PEMS. Currently, key challenges are the definition of test conditions and design of a suitable method for data evaluation. For heavy-duty vehicles, in-use testing with PEMS is already enforced in the European Union since 2009. The revision of European requirements will be completed in 2014 and shifts the focus from engine <b>conformity</b> <b>checking</b> towards the assessment of emissions under real-world driving conditions. The feasibility of PEMS for measuring particle mass is currently investigated by an industry-run pilot program. Moreover, the application of PEMS to Stage IV and V engines of non-road mobile machinery is currently under discussion. We conclude that in-use testing with PEMS will play an important role in the future European vehicle emissions legislation. The application of PEMS can effectively control vehicle emissions, may accelerate the adoption of novel emission abatement technologies and thereby contribute to air quality improvements throughout Europe. JRC. F. 8 -Sustainable Transpor...|$|R
50|$|It is {{important}} to note the scope and intent of conformity assessment. The purpose of conformity assessment is to ensure that Ada processors achieve a high degree of conformity with the Ada standard (Ada95 as corrected by TC1). Characteristics such as performance and suitability for a particular application are not specified by the standard, and thus are outside the scope of Ada conformity assessment. Moreover, the ACATS is a set of test programs intended to check broadly for correct implementation; {{it is not possible to}} exhaustively test for conformity. Thus, <b>conformity</b> is <b>checked</b> only to the extent of these tests; processors that are certified as conforming may fail to conform to the standard in ways peculiar to each, under particular circumstances.|$|R
40|$|The European {{emissions}} legislation requires to <b>check</b> the <b>conformity</b> of heavy-duty engines {{with the}} applicable emissions certification standards during the normal life of those engines: {{these are the}} “In Service Conformity” (ISC) requirements. It was considered impractical and expensive to adopt an in-service <b>conformity</b> (ISC) <b>checking</b> scheme for heavy-duty vehicles, which require removal of engines from vehicles to test pollutant emissions against legislative limits. Therefore, it has been proposed to develop a protocol for in-service <b>conformity</b> <b>checking</b> of heavy-duty vehicles based {{on the use of}} Portable Emission Measurement Systems (PEMS). The European Commission through DG ENTR in co-operation with DG JRC launched in January 2004 a co-operative research programme to study the feasibility of PEMS in view of their application in Europe for In-Service Conformity of heavy-duty engines. The technical and experimental activities were started in August 2004 to study the feasibility of PEMS systems and to study their potential application for on-road measurements on heavy-duty vehicles. The main objectives of the above project had been defined as follows: -To assess and validate the application and performance of portable instrumentation relative to each other, and in comparison with alternative options for ISC testing; -To define a test protocol for the use of portable instrumentation within the ISC of heavy-duty vehicles; -To assess on-road data evaluation methods such as the US ‘Not To Exceed’ (NTE) approach and possibly to develop a simplified ones; -To address the need of the European industry, authorities and test houses to go through a learning process with on-vehicle emissions testing. The main objective of the present document is to report on: a. The evaluation of the test protocol, i. e. to judge whether the mandatory data and its quality were appropriate for the final evaluation (S b. The analysis conducted to evaluate the potential of the different data evaluation (Pass/Fail) methods for ISC and in particular their ability to use on-road PEMS emissions data. The candidate methods were categorized into two families: -The "control-area / data reduction methods" (Chapter 4) that use only a part of the data, depending whether the operation points considered are part of a control area and belong to a sequence of consecutive points within this control area. The US-NTE (Not To Exceed) method - already established as an official tool in the United States - falls into this category but variations of the methods could be envisaged (with another control area for instance). -The "averaging window methods" (Chapter 4. 3) that use all the operation data. The main objective of task b. was to answer the following question: “Once the data has been collected correctly, what is the most appropriate method to analyze the test data measured with PEMS and to judge whether the engine is in conformity with the applicable emissions limits?”JRC. F. 9 -Sustainable Transport (Ispra...|$|R
40|$|Three sensitive, selective, {{rapid and}} easily {{reproducible}} spectrophotometric methods (A-C) {{have been developed}} for the detn. of propranolol hydrochloride (PPH) as a hydrochloride free base propranolol (PPL) in bulk sample and in its dosage forms. These methods are based on ion-pair formation between propranolol as a hydrochloride and free base and 3 acidic (sulfonphthalein) dyes; namely bromothymol blue (BTB), bromocresol green (BCG) and bromocresol purple (BCP) which induces an instantaneous bathochromic shift of the max. in the drug spectrum. The colored products are measured at 420 nm (PPL-BTB complex and PPL-BCP complex) and 425 nm (PPL-BCG complex). The reactions were extremely rapid at room temp. and the absorbance values remained const. for 90 min (method B), and over 24 h (method A and <b>C).</b> <b>Conformity</b> to Beer's law in the range 0. 4 - 7. 0 Î¼g ml- 1 for methods A and B and 0. 5 - 8. 4 Î¼g ml- 1 for method C enabled the assay of dosage forms of the drug. The proposed methods were compared with a ref. method; the results obtained were of equal accuracy and precision. In addn., these methods were also found to be specific for the anal. of PPH in the presence of excipients, which are co-formulated in the drug. Satisfactory results were obtained when applied to spiked human urine. A more detailed investigation of the propanolol hydrochloride ion pair complexes were made with respect to its compn. indicated by stability const. values. [on SciFinder(R) ...|$|R
40|$|Abstract. Reuse of high {{confidence}} subsystems {{depends on}} their appropriate modelling and documentation. This paper discusses the different aspects {{that have to be}} considered when modelling a system and its subsystems. We propose a concrete artefact model for integrated reuse from requirements to technical architecture, which satisfies documentation demands with respect to functionality and the context assumed by the subsystem. Based on the artefact model, we describe the steps for <b>conformity</b> and compatibility <b>checking</b> at the development stage of subsystem integration and/or reuse. ...|$|R
40|$|Energy {{management}} and carbon accounting schemes {{are increasingly being}} adopted as a corporate response to climate change. These schemes often demand the setting of ambitious targets for the reduction of corporate greenhouse gas emissions. There is however only limited empirical insight in the companies’ target setting process and the auditing practice of certifying agencies that evaluate ambition levels of greenhouse gas reduction targets. We studied the target setting process of firms participating in the CO 2 Performance Ladder. The CO 2 Performance Ladder is a new certifiable scheme for energy {{management and}} carbon accounting that {{is used as a}} tool for green public procurement in the Netherlands. This study aimed at answering the question ‘to what extent does the current target setting process in the CO 2 Performance Ladder lead to ambitious CO 2 emission reduction goals?’. The research methods were interviews with relevant stakeholders (auditors, companies and consultants), document reviews of the certification scheme, and an analysis of corporate target levels for the reduction of CO 2 emissions. The research findings showed that several certification requirements for target setting for the reduction of CO 2 emissions were interpreted differently by the various actors and that the <b>conformity</b> <b>checks</b> by the auditors did not include a full assessment of all certification requirements. The research results also indicated that corporate CO 2 emission reduction targets were not very ambitious. The analysis of the target setting process revealed that there was a semi-structured bottom-up auditing practice for evaluating the corporate CO 2 emission reduction targets, but the final assessment whether target levels were sufficiently ambitious were rather loose. The main conclusion is that the current target setting process in the CO 2 Performance Ladder did not necessarily lead to establishing the most ambitious goals for CO 2 emission reduction. This process and the tools to assess the ambition level of the CO 2 emission reduction targets need further improvement {{in order to maintain the}} CO 2 Performance Ladder as a valid tool for green public procurement...|$|R
40|$|Includes bibliographical {{references}} (pages [77]- 80) The {{purpose of}} this thesis was to address two basic research questions: (a) What types of goals do parents have for their children? and (t>) How might an instrument be designed to capture parents' goals for their children in a meaningful way? The availability of such an instrument would facilitate research on parents’ goals. Increased understanding of parents’ goals could improve decision making by policy makers, educators, and program providers. Completing such an instrument also could help parents clarify their goals for themselves. An extensive review of related literature and methodology was completed. It {{was found that the}} concept of parents’ goals for their children has not been well defined and often has been used interchangeably with the concept of parents’ values. It was concluded that parents’ goals for their children include both an aspirations component (representing parental values and desires) and an effort component (representing parental effort toward accomplishment of the goal). Existing instruments to measure parents’ goals typically measured only one component. No instrument was found that measured both components in any comprehensive way. Nine focus groups were held to explore parents’ goals for their children. Parents wrote down and prioritized their goals, completed a Parenting Goals Questionnaire, and participated in a group discussion. As a result of the review of related literature and the focus group study, the types of goals parents hold for their children became clearer. Parents have goals regarding what they want their children to do, have, be, feel, and think/believe. Parents’ goals fall into several functional domains, including social, emotional, cognitive/educational, spiritual/ethical, physical/health, self-reliance/responsibility, career/money, and cultural/aesthetic. Parents’ goals also appeared to fall along four dimensions: (a) internal versus external, (b) independent versus interdependent, (<b>c)</b> <b>conformity</b> versus self-direction, and (d) giving versus acquiring. Using these typologies of parents’ goals, a new Parental Goals Survey was proposed that measures both the aspirations and effort components of parents' goals for their children. M. S. (Master of Science...|$|R
40|$|The {{thin plate}} p-elements {{considered}} {{in this paper}} are based on assumed displacement field chosen so as to a priori satisfy the governing Lagrange equation within the element. The required <b>C</b> 1 <b>conformity</b> is then enforced in a weak sense trough an auxiliary displacement frame {{defined in terms of}} nodal and side mode parameters. While thus far the standard approach consisted in using three parameters (one displacement and two rotations) at corner nodes and an optional number of side mode parameters associated with mid-side nodes, other alternative formulations are also possible wherein the number of corner mode parameters is either inferior or superior to three. As compared to the standard frame, such alternative formulations may exhibit some advantages and some shortcomings with respect to accuracy, convergence rate, error distribution, computational efficiency and/or ease of use. The paper surveys and critically assesses some of such formulations and reports the results of extensive numerical studies involving regular and singular plate bending applications. 1...|$|R
40|$|The {{problem of}} {{designing}} a component that {{combined with a}} known part of a system, conforms to a given overall specifica-tion arises in several applications ranging from logic synthesis {{to the design of}} discrete controllers. We cast the problem as solving abstract equations over languages. Language equations can be defined with respect to several language composition op-erators such as synchronous composition,, and parallel com-position,; <b>conformity</b> can be <b>checked</b> by language contain-ment. In this paper we address parallel language equations. Parallel composition arises in the context of modeling delay-insensitive processes and their environments. The parallel com-position operator models an exchange protocol by which an in-put is followed by an output after a finite exchange of internal signals. It abstracts a system with two components with a singl...|$|R
40|$|International audienceIn {{high-speed}} machining {{it is of}} key importance to avoid any collision between the machine tool and the machining setup. If the machining setup has not been assembled correctly by the operator and does not conform to the 3 D CAD model sent to the machining unit, such collisions may occur. This paper presents a new chain-processing-based computer vision system to automatically avoid collision between tool and machining setup components by checking that the actual machining setup is in conformity with the desired 3 D CAD model used to generate the tool trajectory. This computer vision system utilizes a single camera to automatically <b>check</b> <b>conformity</b> {{before the start of}} the machining operation. The proposed solution was tested in different kinds of machining setups, and each step of the proposed chain was evaluated. The results show the robustness of the solution for different kinds of machining setups...|$|R
40|$|CAA section 176 (<b>c)</b> and {{transportation}} <b>conformity</b> rule (40 CFR Part 93) require that federally supported transportation projects in nonattainment tt t and maintenance areas cannot: » Cause or contribute to new air quality violations, » Worsen existing violations, or » Delay ti timely attainment tt t of the NAAQS or interim i milestones il � Section 93. 101 defines a hot-spot analysis as an estimation of likely future localized pollutant concentrations and a {{comparison to the}} relevant transportation-related NAAQS » Required for certain highway and transit projects in PM 2. 5, PM 10, and CO nonattainment and maintenance areas Project meets conformity requirements, if at each appropriate receptor: PM concentration of build PM concentration of build < NAAQS, or < PM concentration of no-buil...|$|R
40|$|Validating {{complex systems}} is {{nowadays}} achieved by simulation of cooperating components. As complex systems {{have to support}} multidisciplinarity and multiformalism it induces these components may be different. Moreover cooperation between them means a data exchange. Exchanged data among various components may have different format and then a match is necessary. The latter is called interoperability, an essential notion. HLA OMT aim {{is to provide a}} template to document the exchanged data and their characteristics and so to promote interoperability. However verification of the document consistence becomes laborious if a huge number of data is exchanged. We propose a way to check a part of the consistence of OMT by using Coloured Petri Nets. We consider the parts consist of data compliance, completeness and structural <b>conformity</b> and we <b>check</b> only the first two ones. To do it, firstly OMT is transformed into a Coloured Petri Net and secondly verification may be achieved by its structure analysis...|$|R
40|$|MODIStsp is a "R" package {{devoted to}} automatizing the {{creation}} of time series of rasters derived from MODIS Land Products data. MODIStsp allows to perform several preprocessing steps (e. g., download, mosaicking, reprojection and resize) on MODIS data available within a given time period. Users {{have the ability to}} select which specific layers of the original MODIS HDF files they want to process. They also can select which additional Quality Indicators should be extracted from the aggregated MODIS Quality Assurance layers and, in the case of Surface Reflectance products, which Spectral Indexes should be computed from the original reflectance bands. For each output layer, outputs are saved as single-band raster files corresponding to each available acquisition date. Virtual files allowing access to the entire time series as a single file can be also created. All processing parameters can be easily selected with a user-friendly GUI, although non-interactive execution exploiting a previously created Options File is possible. Stand-alone execution outside an "R" environment is also possible, allowing to use scheduled execution of MODIStsp to automatically update time series related to a MODIS product and extent whenever a new image is available. MODIStsp v 1. 2. 1 Release Notes v 1. 2. 1 was released on 20 / 04 / 2016 Major Changes 	 	Modified format of "R" output time series from rts objects to RasterStack objects with temporal information added in the "z" attribute via setZ() 	 	 	Major changes/improvements in MODIStsp_extract function: 	 		Use of plain rasterstack with "z" attribute instead than rasterstackts 		Use of gdal_rasterize (gdalUtils) instead of rasterize (rgdal) to improve speed. Temporary shapes and rasters necessay are saved in "R" temporary folder and removed automatically 		Fixed bugs on functionality for point/lines shapefiles, according to what specified by the "small" and "small_method" parameters 		Added functionality for retrieving data for small polygons 		Added out_format selection - xts or plain data. frame 		Added possibility to use a shp filename as input directly 		Added <b>conformity</b> <b>checks</b> on inputs 		Added functionality to run without specifying start and end dates 		Added id_field parameter for choosing which column of the input SP object should be used for "naming" the columns of the output 	 	 	 	Removed possibility to use "complex" resampling methods when reprojecting (e. g., bilinear, cubic, etc.) to avoid incorrect resampling on categorical variables and "contamination" of good pixels' data. 	 Minor Changes 	Changed the input method for starting and ending dates selection in the GUI. Now a text field is used 	Added functionaluty for writing data ignore value on ENVI files 	Removed automatic deletion of XML files created by writeRaster to keep metadata information 	Changed names of products in the GUI for products with both TERRA and AQUA dataset to M*D 09 A 1, M*D 13 Q 1, etc [...] . 	Modified code syntax to satisfy R code styling guidelines 	Modified roxygen parameters so that only required functions are imported from imported packages 	Updated and corrected the list of dependencies 	Updated required "R" version to 3. 2, and minimum versions for dependent packages to current versions. 	Added Welcome message 	Updated links to LPDAAC product description pages 	Changed all "print" and "cat" calls to show messages/warnings to "message" or "warning" to allow easy disabling MODIStsp verbose messages 	Using "R" tempfile/tempdir to save vrt files Bug Fixes 	Corrected a bug that threw an error in case incorrect bounding box specifie...|$|R
40|$|Quality {{assurance}} {{policies for}} long-term care in France are founded on a law passed in 2002, but the organisation {{of the system is}} still underway. It is principally based on a legal framework that sets out requirements for quality monitoring and quality improvement. Quality assessment is related to outcomes, indicators and guidelines. It pertains to formal care and is related to administrative authorisation and financial conditions. In the public sector, the aim is to develop continuous quality assurance in a system differentiated by internal and external quality assessment. In the private sector, the aim is mainly to <b>check</b> <b>conformity</b> with quality standards, as internal and external quality assurance may be replaced by a certification procedure. A central agency is in charge of enhancing quality through the production of new guidelines but quality supervision {{is the role of the}} funding institution and qualitative results are not publicly available. To date, not many organisations or units have conducted the entire quality assurance process, as the quality of long-term care is ensured by an institutional system that is in the final stages of being structured...|$|R
