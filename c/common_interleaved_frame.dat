0|45|Public
40|$|Moving Object Detection {{is one of}} the key {{research}} {{areas of}} Image processing. In this regard many researches are underway to provide a novel approach to detect moving object with less space and time complexity. This paper, outlines the novel approach to detect high speed moving object with <b>frame</b> <b>interleaving</b> in <b>frame</b> differencing operation and clustering based compression for frame and background modeling to reduce the time complexity for frame differencing operation. 1...|$|R
40|$|In {{this paper}} we study {{the impact of}} {{interleaving}} on JPEG 2000 images and video transmission through wireless channels. Based on interleaving impact evaluation, we derive a lower bound limit for the successful images decoding rate in wireless environments. Since the successful decoding rate is of central importance to guarantee Quality of Service to wireless clients, we rely on the derived limit to evaluate the performance of near-optimal <b>interleaved</b> <b>frames</b> using a wireless JPEG 2000 based client/server application. This work is a step toward optimal interleaving for robust Wireless JPEG 2000 based images and video transmission. Peer ReviewedPostprint (published version...|$|R
5000|$|A C2 {{error is}} a read error of a compact disc. C2 errors can {{to a degree}} be {{recovered}} by the hardware error detection and correction scheme. A CD drive can have extraction errors when the data on the disc is not readable due to scratches or smudges. The drive can compensate by supplying a [...] "best guess" [...] of what the missing data was, then supplying the missing data. C2 error correction is an analysis over many <b>interleaved</b> <b>frames,</b> an improvement over C1 error correction, which analyzed just one frame, resulting in more accurate data correction. C2 error correction codes are also used by the Digital Audio Tape (DAT) format.|$|R
40|$|The work {{consists}} {{first of}} making improvements of a MELP coder running at 2. 4 kbps by {{the implementation of}} packets lost concealment techniques based on the receiver. These techniques consist of <b>interleaving</b> information <b>frames,</b> then, we conducted a comparative study of several interlacing methods. For this, we used the evaluation technique standardized by ITU-T called PESQ (Perceptual Evaluation of Speech Quality) ...|$|R
30|$|The only {{input data}} {{is the image}} {{sequences}} to be analyzed. Several test sequences, around 50 images each, have been recorded with a 25 <b>interleaved</b> <b>frames</b> per second camera at 720 × 576 pixels. Therefore, every 40 ms, a complete image frame is generated, after combining two image fields provided by the interleaved camera at 20 -ms intervals. The main problem of using an interleaving camera derives from the delay in capturing both image fields, 20 ms, causing a mismatch in the final image. For example, a car traveling at 90 km/h (25 m/s) will advance 50 cm in 20 ms. One solution to fix this problem is to use only the even or the odd image fields and to ignore {{the other half of}} the original image, or to use a more expensive full-frame camera. The results in this section analyze both 720 × 576 interleaved and 720 × 288 non-interleaved images.|$|R
40|$|Interleaved {{memories}} {{are often used}} to provide the high bandwidth needed by multi- processors and high performance uniprocessors. The manner in which memory locations are distributed across the memory modules has a significant influence on whether, and for which types of reference patterns, the full bandwidth of the memory system is achieved. The most <b>common</b> <b>interleaved</b> memory architecture is the sequentially interleaved memory in which successive memory locations are assigned to successive memory modules. Although such an architecture is the simplest to implement and provides good performance with strides that are odd integers, it can degrade badly {{in the face of}} even strides, especially strides that are a power of two. This happens because all the memory references are concentrated on a subset of the memory modules. Pseudo...|$|R
40|$|An {{algorithm}} for decoding turbo {{codes that}} combines conventional turbo decoding and list sequence (LS) maximum {{a posteriori probability}} (MAP) decoding is presented and evaluated. Compared to previous results on this theme, {{a reduction in the}} order of 0. 7 dB of the signal-to-noise ratio (SNR) is obtained for turbo codes with 514 -bit pseudo-random <b>interleaving</b> at <b>frame</b> error rate (FER) 10 - 4 on the additive white Gaussian noise (AWGN) channe...|$|R
40|$|The I/O Automaton {{paradigm}} of Lynch and Tuttle models asynchrony through an interleaving parallel composition and generalizes more <b>common</b> <b>interleaving</b> models based upon message-passing, such as Hoare's CSP. It is not generally recognized that such interleaving models in fact {{can be viewed}} as special cases of synchronous parallel composition, in which components all move in lock-step. Let A be any set of finite-state I/O Automata drawing actions from a fixed finite set containing a subset Δ. In this article we establish a translation T : A ! P to a class of !-automata P closed under a synchronous parallel composition, for which T is monotonic with respect to implementation relative to Δ, and linear with respect to composition. Thus, for A 1; : : :; A m; B 1; : : :; B n 2 A and A = A 1 jj ΔΔΔ jjA m, B = B 1 jj ΔΔΔ jjB n, if Δ is the set of actions common to both A and B, then A implements B (in the sense of I/O Aut [...] ...|$|R
40|$|In {{this work}} we {{investigated}} how high frame rate speckle tracking based on plane wave imaging {{could be used}} to improve the quantification of peak velocities in shunt flows due to septal defects. Simulated jet flow was used to optimize acquisition and tracking parameters. In vivo, a packet based acquisition scheme was used where focused B-mode scans were <b>interleaved</b> high <b>frame</b> rate flow images (100 fps). Results showed that speckle tracking provides calibrated velocities in the shunt flow throughout the cardiac cycle, and improved estimates of peak velocities used for diagnosing shunt severity were acquired...|$|R
40|$|Advances {{in design}} tools and {{material}} engineering open new possibilities for architectural structures that may respond better {{to the demands}} of the increasing density of development, better space management and lesser environmental impact. Folding structures that provide adjustable on demand configurations can be effectively conceptualized if appropriate interdisciplinary expertise is brought together. Kinematic chain geometries borrowed from traditional mechanics can be developed into a variety of topologies suitable for architectural structures. Rectilinear deformable grids can provide the functionality of expanding and collapsing as well as the ability to be infinitely arrayed. Converging grids allow for circular arrays and fan like folding. The challenge is to translate a two-dimensional chain concept into a three-dimensional array of <b>interleaved</b> <b>frames</b> that form a stable structure and can bear the necessary loads. In order to complement the folding structure with the corresponding foldable shell, the algebra of rigid folds can be adapted to develop viable geometrical concepts. The demands of the design process needed to develop kinetic structures will expand the traditional architectural workflow to include parametric modelling tools that are common in mechanical engineering. Folding architectural structures require, besides traditional architectural layout development, parametric assembly capabilities and motion analysis typical for mechanical design. Potential application development, marketing, building code changes and effective multidisciplinary collaboration must take place for kinetic structures to enter the architectural mainstream...|$|R
40|$|We {{examined}} {{the role of}} feature matching in motion perception. The stimulus sequence was constructed from a vertical, 1 cycle deg- 1 sinusoidal grating divided into horizontal strips of equal height, where alternate strips moved leftward and rightward. The initial relative phase of adjacent strips was either 0 degree (aligned) or 90 degrees (non-aligned) and the motion was sampled at 90 degrees phase steps. A blank interstimulus interval (ISI) of 0 - 117 ms was introduced between each 33 ms presentation of the stimulus frames. The observers had to identify the direction of motion of the central strip. Motion was perceived correctly at short ISIs, but at longer ISIs performance was much better for the non-aligned sequence than the aligned sequence. This difference in performance may reflect a role for feature correspondence and grouping of features in motion perception at longer ISIs. In the aligned sequence half the frames consisted of a single coherent vertical grating, while the <b>interleaved</b> <b>frames</b> contained short strips. We argue that to achieve feature matching over time, the long edge and bar features must be broken up perceptually (segmented) into shorter elements before these short segments can appear to move in opposite directions. This idea correctly predicted that overlaying narrow, stationary, black horizontal lines at the junctions of the grating strips would improve performance in the aligned condition. The results support the view that, in addition to motion energy, feature analysis and feature tracking {{play an important role}} in motion perception...|$|R
40|$|Interleaved {{memories}} {{are often used}} to provide the high bandwidth needed by multiprocessors and high performance uniprocessors such as vector and VLIW processors. The manner in which memory locations are distributed across the memory modules has a significant influence on whether, and for which types of reference patterns, the full bandwidth of the memory system is achieved. The most <b>common</b> <b>interleaved</b> memory architecture is the sequentially interleaved memory in which successive memory locations are assigned to successive memory modules. Although such an architecture is the simplest to implement and provides good performance with strides that are odd integers, it can degrade badly {{in the face of}} even strides, especially strides that are a power of two. In a pseudo-randomly interleaved memory architecture, memory locations are assigned to the memory modules in some pseudo-random fashion in the hope that those sequences of references, which are likely to occur in practice, will end up being evenly distributed across the memory modules. The notion of polynomial interleaving modulo an irreducible polynomial is introduced as a way of achieving pseudo-random interleaving with certain attractive and provable properties. The theory behind this scheme is developed and the results of simulations are presented. Kev words: supercomputer memory, parallel memory, interleaved memory, hashed memory, pseudo-random interleaving, memory buffering. 1...|$|R
30|$|The {{localized}} {{spectrum sensing}} approach {{appears to be}} more appealing, thanks to its adaptivity to a changing spectrum environment. Most wireless devices have only one radio module. Therefore, it is <b>common</b> to <b>interleave</b> the channel assessment and data transmission activity. How to find the optimal sensing frequency is crucial to improve the system performance and hence becomes a popular research topic on itself[4, 5]. However, it is not always convenient to limit transmission into predefined intervals. Sensing a broad spectrum range with limited radio front-end capability and processing resources results in limited sensing performance.|$|R
40|$|Abstract – An {{algorithm}} for decoding Turbo {{codes that}} combines conventional Turbo decoding and list sequence (LS) maximum {{a posteriori probability}} (MAP) decoding is presented and evaluated. Compared to previous results on this theme, {{a reduction in the}} order of 0. 7 dB of the signal-to-noise ratio (SNR) is obtained for Turbo codes with 514 -bit pseudo-random <b>interleaving</b> at <b>frame</b> error rate (FER) 10 − 4 on the additive white Gaussian noise (AWGN) channel. This paper reviews the use of an outer error detecting code in order to achieve improved decoding performance in error control schemes with an inner Turbo code [1]. We consider an approach that combines LS-MAP decoding [3] with conventional Turbo decoding of parallel concatenated convolutional codes. Based on distance distribution arguments, this combinatio...|$|R
500|$|Hughes, {{along with}} {{associate}} producer Cody DeMatteis, utilized Adobe After Effects for {{some aspects of}} post-production editing. The special makes extensive use of compression artifacts for artistic effect, namely [...] "datamoshing", where two videos are <b>interleaved</b> so intermediate <b>frames</b> are interpolated from two separate sources. The technique referred to as [...] "photo stacking", in which time-lapse photographs are composited {{on top of one}} another, was also utilized for the NASA John Space Center footage.|$|R
30|$|In Figures 9 (a), 9 (b), and 9 (c), {{an example}} of visual quality is reported. Figures 9 (a) and 9 (c) {{correspond}} to frame n. 23 and frame n. 25, respectively, and they are key-frames, while their <b>interleaving</b> WZ <b>frame</b> (frame n. 24) is reported in Figure 9 (b). During the transmission of the first one (corresponding to frame n. 23 in the plots of Figures 5 and 6) a slice loss has occurred, leading to a very significant quality impairment. On the contrary, the following key-frame (Figure 9 (c), frame 25 in the plots of Figures 5 and 6) has been correctly received. The WZ frame initially predicted from these key-frames is characterized after decoding by a high PSNR and good visual quality, as {{can be observed in}} Figure 9 (b).|$|R
40|$|The {{performance}} {{and design of}} a deterministic interleaver for short frame turbo codes is considered in this paper. The main characteristic of this class of deterministic interleaver is that their algebraic design selects the best permutation generator such that the points in smaller subsets of the interleaved output are uniformly spread over {{the entire range of}} the information data frame. It is observed that the interleaver designed in this manner improves the minimum distance of first few spectral lines of minimum distance spectrum. Finally we introduce a circular shift in the permutation function to reduce the correlation between the parity bits corresponding to the original and <b>interleaved</b> data <b>frames</b> to improve the decoding capability of MAP decoder. The design is focused on combining good permutations with de-correlation property. Our solution to design a deterministic interleaver outperforms the semi-random interleavers and the deterministic interleavers reported in the literature. (c) 200...|$|R
50|$|The book uses wordless {{sequential}} art to tell {{four stories}} about masculine gay men who find unexpected congeniality {{as well as}} sexual passion with each other. These stories are <b>interleaved</b> with a <b>framing</b> narrative of a gay couple whose intimacy is enhanced by the stories they read in their copy of the book. The illustration consists of line art with a limited monochromatic palette for each story. The framing sequences use full color. The hardcover collection of Sticky is 80 pages long, and was published by Bruno Gmünder Verlag (Berlin, Germany) in March 2006.|$|R
50|$|In video art, one {{technique}} is datamoshing, where two videos are <b>interleaved</b> so intermediate <b>frames</b> are interpolated from two separate sources. Another technique involves simply transcoding from one lossy video format to another, which exploits {{the difference in}} how the separate video codecs process motion and color information. The technique was pioneered by artists Bertrand Planes in collaboration with Christian Jacquemin in 2006 with DivXPrime, Sven König, Takeshi Murata, Jacques Perconte and Paul B. Davis in collaboration with Paperrad, and more recently used by David OReilly and within music videos for Chairlift and Kanye West.|$|R
40|$|This paper {{evaluates the}} {{performance}} of the federal standard 2. 4 kbps MELP vocoder when used over ATM networks that are subject to cell loss. It begins by addressing the sensitivity of MELP to random deletion of frames; it quantifies {{the extent to which the}} quality of the reconstructed speech is affected by two factors [...] the rate at which frames are lost and the burstiness of that loss process. Next, the ATM structure is introduced and techniques for ameliorating the e#ects of ATM cell loss when transporting MELP-compressed speech are evaluated. <b>Interleaving</b> MELP <b>frames</b> into ATM cells is shown to improve performance significantly. Finally, the effectiveness of erasure decoding using Reed-Solomon codes to recover lost cells is investigated. Throughout this paper, cell loss is simulated by an i. i. d. model and also a bursty (Gilbert) model. The quality of the reconstructed speech is assessed using both objective measures (i. e., frequency-weighted average spectral distortion and percentage of outliers) and subjective tests. I...|$|R
40|$|One of {{important}} transmission technologies in the broadband ISDN is the synchronous transmission technology based on SDH, a key concept of SONET/SDH is the pointer-based {{access to the}} encapsulated payloads in theSONET/SDH signal. The Synchronous Digital Hierarchy (SDH) and the Synchronous Optical NETwork (SONET) are hierarchies used in Europe/South-America and NorthAmerica/Japan, respectively. Both systems employ {{synchronous time division multiplexing}} techniques to transmit different tributaries (EI, Ethernet, ATM, etc) through the same physical channel. A primary goal {{in the development of the}} SDH/SONET formats is to define a synchronous optical hierarchy with sufficient flexibility to carry payloads of different types. SONET and SDH are based on transmission at rates that are integer multiples of 51. 840 Mbps. SONET basic frame structure is called synchronous transport signal level one (STS-l). SDH basic modular signal is called synchronous transport module level one (STM-I). The STM-I rate is an extension of the basic STS-I (for this reason also called STM-O) and operates at 155. 52 Mbps, carrying three <b>interleaved</b> STS-l <b>frames...</b>|$|R
50|$|Both 260-bit vocoder {{frames and}} 184-bit L2 control frames are coded into 456 bit L1 frames. On {{channels}} with 4-burst interleaving (BCCH, CCCH, SDCCH, SACCH), these 456 bits are interleaved into 4 radio bursts with 114 payload bits per burst. On channels with 8-burst interleaving (TCH, FACCH), these 456 bits are interleaved over 8 radio bursts {{so that each}} radio burst carries 57 bits from the current L1 frame and 57 bits from the previous L1 <b>frame.</b> <b>Interleaving</b> algorithms for the most common traffic and control channels are described in GSM 05.03 Sections 3.1.3, 3.2.3 and 4.1.4.|$|R
2500|$|The new DAB+ {{standard}} has incorporated Reed-Solomon ECC as an [...] "inner layer" [...] of coding that {{is placed}} around the byte <b>interleaved</b> audio <b>frame</b> {{but inside the}} [...] "outer layer" [...] of convolutional coding used by the older DAB system, although on DAB+ the convolutional coding uses equal error protection (EEP) rather than UEP since each bit is equally important in DAB+. This combination of Reed-Solomon coding as the inner layer of coding, followed by an outer layer of convolutional coding – so-called [...] "concatenated coding" [...] – became a popular ECC scheme in the 1990s, and NASA adopted it for its deep-space missions. One slight difference between the concatenated coding used by the DAB+ system and that used on most other systems is that it uses a rectangular byte interleaver rather than Forney interleaving {{in order to provide}} a greater interleaver depth, which increases the distance over which error bursts will be spread out in the bit-stream, which in turn will allow the Reed-Solomon error decoder to correct a higher proportion of errors.|$|R
40|$|Abstract:- One of {{important}} transmission technologies in the broadband ISDN is the synchronous transmission technology based on SDH, a key concept of SONET/SDH is the pointer-based {{access to the}} encapsulated payloads in the SONET/SDH signal. The Synchronous Digital Hierarchy (SDH) and the Synchronous Optical NETwork (SONET) are hierarchies used in Europe/South-America and North-America/Japan, respectively. Both systems employ {{synchronous time division multiplexing}} techniques to transmit different tributaries (EI, Ethernet, ATM, etc) through the same physical channel. A primary goal {{in the development of the}} SDH/SONET formats is to define a synchronous optical hierarchy with sufficient flexibility to carry payloads of different types. SONET and SDH are based on transmission at rates that are integer multiples of 51. 840 Mbps. SONET basic frame structure is called synchronous transport signal level one (STS-l). SDH basic modular signal is called synchronous transport module level one (STM-I). The STM-I rate is an extension of the basic STS-I (for this reason also called STM-O) and operates at 155. 52 Mbps, carrying three <b>interleaved</b> STS-l <b>frames...</b>|$|R
40|$|International audienceThe TRIDENT (TRansmission d'Images et de Données EN Temps réeel) {{project was}} {{launched}} {{a few years}} ago by GESMA (Groupe d’Etudes Sous Marine de l'Atlantique). The initial objectives were to develop a multiple-rate underwater acoustic link for images, text and data transmission. Later, the speech option was added, and more recently channel coding options have been introduced to the TRIDENT platform. Convolutional codes (CC) and Reed Solomon (RS) block codes were then checked, but these simple codes were not able to significantly improve the Bit Error Rate (BER) at the channel decoding output. For this reason, GESMA decided to introduce turbo codes options, more specifically the Reed Solomon Block Turbo Codes (RS-BTC), to enhance the channel decoding efficiency. The data transmitted are <b>interleaved</b> and <b>frame</b> recovery is performed in reception. After system validation in static conditions, in the Penfeld river in Brest, France, sea trials were conducted in the Bay of Brest in dynamic conditions. This paper presents various possibilities offered by the platform for images and speech transmissions and the RS-BTC channel coding options...|$|R
5000|$|The new DAB+ {{standard}} has incorporated Reed-Solomon ECC as an [...] "inner layer" [...] of coding that {{is placed}} around the byte <b>interleaved</b> audio <b>frame</b> {{but inside the}} [...] "outer layer" [...] of convolutional coding used by the older DAB system, although on DAB+ the convolutional coding uses equal error protection (EEP) rather than UEP since each bit is equally important in DAB+. This combination of Reed-Solomon coding as the inner layer of coding, followed by an outer layer of convolutional coding - so-called [...] "concatenated coding" [...] - became a popular ECC scheme in the 1990s, and NASA adopted it for its deep-space missions. One slight difference between the concatenated coding used by the DAB+ system and that used on most other systems is that it uses a rectangular byte interleaver rather than Forney interleaving {{in order to provide}} a greater interleaver depth, which increases the distance over which error bursts will be spread out in the bit-stream, which in turn will allow the Reed-Solomon error decoder to correct a higher proportion of errors.|$|R
50|$|ISPs (rarely, users {{apart from}} Australia where its default) {{have the option}} to use {{interleaving}} of packets to counter the effects of burst noise on the telephone line. An interleaved line has a depth, usually 8 to 64, which describes how many Reed-Solomon codewords are accumulated before they are sent. As they can all be sent together, their forward error correction codes can be made more resilient. Interleaving adds latency as all the packets have to first be gathered (or replaced by empty packets) and they, of course, all take time to transmit. 8 <b>frame</b> <b>interleaving</b> adds 5 ms round-trip-time, while 64 deep interleaving adds 25 ms. Other possible depths are 16 and 32.|$|R
40|$|Studying {{binocular}} vision requires precise {{control over the}} stimuli presented {{to the left and}} right eyes. A popular technique is to segregate signals either temporally (<b>frame</b> <b>interleaving),</b> spectrally (using coloured filters) or through light polarization. None of these segregation methods achieves perfect isolation, and so a degree of ‘crosstalk’ is usually apparent in which signals intended for one eye are faintly visible to the other eye. Previous studies have reported crosstalk values mostly for consumer-grade systems. Here we measure crosstalk for eight systems, many of which are intended for use in vision research. We provide benchmark crosstalk values, report a negative crosstalk effect in some LCD-based systems, and give guidelines for dealing with crosstalk in different experimental paradigms...|$|R
40|$|Abstract — The TRIDENT (TRansmission d’Images et de Données EN Temps réeel) {{project was}} {{launched}} {{a few years}} ago by GESMA (Groupe d’Etudes Sous Marine de l’Atlantique). The initial objectives were to develop a multiple-rate underwater acoustic link for images, text and data transmission. Later, the speech option was added, and more recently channel coding options have been introduced to the TRIDENT platform. Convolutional codes (CC) and Reed Solomon (RS) block codes were then checked, but these simple codes were not able to significantly improve the Bit Error Rate (BER) at the channel decoding output. For this reason, GESMA decided to introduce turbo codes options, more specifically the Reed Solomon Block Turbo Codes (RS-BTC), to enhance the channel decoding efficiency. The data transmitted are <b>interleaved</b> and <b>frame</b> recovery is performed in reception. After system validation in static conditions, in the Penfeld river in Brest, France, sea trials were conducted in the Bay of Brest in dynamic conditions. This paper presents various possibilities offered by the platform for images and speech transmissions and the RS-BTC channel coding options. Keywords- Underwater acoustic communication; BER, Convolutional codes (CC); Reed Solomon (RS) block codes; Reed Solomon Block Turbo Codes (RS-BTC) ...|$|R
30|$|Frame {{compatible}} (FC) formats allow {{utilization of}} existing infrastructure and equipment for transmission {{and services for}} 3 D videos. This format has one video sequence with frame rate f {{that is the same}} as in the underlying temporal format. FC formats have lower spatial resolution than the underlying spatial format. For example, for the most widely used FC format, the SBS format, frames are spatially sub-sampled in horizontal direction. For instance, for full HD 1, 920 [*]×[*] 1, 080 resolution, {{the left and the right}} views of the SBS format have 960 [*]×[*] 1, 080 pixel frames. These sub-sampled <b>frames</b> are <b>interleaved</b> into one <b>frame</b> in full HD resolution. As in the case of the FS format, SBS representation also uses conventional single-view video encoder for coding.|$|R
30|$|The {{main purpose}} of this {{procedure}} is the MS node monitoring target BS nodes {{in the neighborhood and}} finding out if they are suitable for handover. The time during which the MS scans for available BS will be referred to as scanning interval.Either the BS or the MS nodes may initiate this procedure. That is, a BS may allocate time intervals to MS for scanning purposes. In this case, a MOB_SCN_RSP is sent by the serving BS. This message includes information relative to: the start frame, the scanning process duration (N <b>frames)</b> the <b>interleaving</b> interval (P <b>frames),</b> normal data traffic, if any, is re-established, the iteration (T times).Scanning interval and interleaving interval will repeat with the number of scan iteration.|$|R
50|$|This {{stream of}} audio frames, as a whole, is then {{subjected}} to CIRC encoding, which segments and rearranges {{the data and}} expands it with parity bits {{in a way that}} allows occasional read errors to be detected and corrected. CIRC encoding also <b>interleaves</b> the audio <b>frames</b> throughout the disc over several consecutive frames so that the information will be more resistant to burst errors. Therefore, a physical frame on the disc will actually contain information from multiple logical audio frames. This process adds 64 bits of error correction data to each frame. After this, 8 bits of subcode or subchannel data are added to each of these encoded frames, which is used for control and addressing when playing the CD.|$|R
40|$|We {{report on}} a Digital Image Correlation-based {{technique}} {{for the detection of}} in-plane elastic waves propagating in structural lattices. The experimental characterization of wave motion in lattice structures is currently of great interest due its relevance to the design of novel mechanical metamaterials with unique/unusual properties such as strongly directional behavior, negative refractive indexes and topologically protected wave motion. Assessment of these functionalities often requires the detection of highly spatially resolved in-plane wavefields, which for reticulated or porous structural assemblies is an open challenge. A Digital Image Correlation approach is implemented that tracks small displacements of the lattice nodes by centering image subsets about the lattice intersections. A high speed camera records the motion of the points by properly <b>interleaving</b> subsequent <b>frames</b> thus artificially enhancing the available sampling rate. This, along with an imaging stitching procedure, enables the capturing of a field of view that is sufficiently large for subsequent processing. The transient response is recorded {{in the form of the}} full wavefields, which are processed to unveil features of wave motion in a hexagonal lattice. Time snapshots and frequency contours in the spatial Fourier domain are compared with numerical predictions to illustrate the accuracy of the recorded wavefields and demonstrate the suitability of this technique for the experimental characterization of wave properties...|$|R
40|$|Autostereoscopic {{displays}} in fact show many {{views of the}} object of interest simultaneously. These individual views have to be re-shuffled to fit the final display. This composition task is usually done as an off-line process. We present in this paper a flexible pixel compositor that bridges the image generator (e. g., a rendering cluster) and the final display devices (such {{as a set of}} over-lapping projectors to form an ultra-high-resolution display). Our compositor is capable of performing an arbitrary mapping of pixels from any input frame to any output frame, and executing typical composition operations (e. g., blending) at the same time. To the best of our knowledge, our design is the only compositor that allows non-block based per-pixel warping and composition. This is particularly important for lenticular {{displays in}} which the different views have to be <b>interleaved</b> in the <b>frame</b> buffer. In this paper, we present an initial hardware prototype and some preliminary results in the firmware development...|$|R
40|$|Separating {{the direct}} and global {{components}} of radiance can aid shape recovery algorithms and can provide useful information about materials in a scene. Practical methods for finding {{the direct and}} global components use multiple images captured under varying illumination patterns and require the scene, light source and camera to remain sta-tionary during the image acquisition process. In this pa-per, we develop a motion compensation method that relaxes this condition and allows direct-global separation to be per-formed on video sequences of dynamic scenes captured by moving projector-camera systems. Key to our method is be-ing able to register frames in a video sequence {{to each other in}} the presence of time varying, high frequency active illu-mination patterns. We compare our motion compensated method to alternatives such as single shot separation and <b>frame</b> <b>interleaving</b> as well as ground truth. We present re-sults on challenging video sequences that include various types of motions and deformations in scenes that contain complex materials like fabric, skin, leaves and wax. 1...|$|R
40|$|The {{objective}} of this document is to introduce the video sequence selection criteria and the metrics expected to be used at INRIA for video understanding projects. 1. DATA TERMINOLOGY This section enumerates and defines all the vocabulary describing data used in a video understanding process. Image: array of pixel generated at a time step by a video camera (e. g., composite, CCD, CMOS, PTZ, omni directional). An image {{is characterized by a}} timestamp (year, month, day, hour, minute, second, millisecond) and can correspond to a <b>frame</b> <b>interleaved</b> or not. An image can be of the following type: colour, black and white, infrared and with different compression levels. Video sequence: temporal sequence of images which are generated by a video camera. A video sequence can be represented as a live stream (e. g., composite signal, MJPEG stream), as a file (e. g., a MPEG 4 encoded file) or as a sequence of files (e. g., a sequence of JPEG files). Video clip: a part of a video sequence, which corresponds to a particular situation to b...|$|R
