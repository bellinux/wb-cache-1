777|1090|Public
5000|$|... #Subtitle level 3: Background <b>correction</b> <b>techniques</b> in HR-CS AAS ...|$|E
5000|$|... 4. Training of Probation and Parole Officers in {{rehabilitation}} and <b>correction</b> <b>techniques.</b>|$|E
50|$|For recovery, some systems simply cause senders to re-transmit {{collided}} data (perhaps with backing-off algorithms which {{reduce the}} sender's re-transmit rate when collisions keep occurring) or use Error <b>Correction</b> <b>techniques</b> such as FEC.|$|E
40|$|The DRT * is {{an order}} {{preserving}} Scalable Distributed Data Structures {{with an almost}} constant amortized upper bound costs for exact searches and insertions. The result {{is based on the}} correction techinque the DRT * uses when a given request produces an address error. This technique mainly consists in exchanging information among servers about the distribution of data by means of messages. Servers can exchange the maximum (complete <b>correction</b> <b>technique)</b> or the minimum (restricted <b>correction</b> <b>technique)</b> information they know. Here, we investigate the amortized lower bound of such distributed searching technique, proving that there is not any advantage in using complete <b>correction</b> <b>technique,</b> because the lower bound result of the complete <b>correction</b> <b>technique</b> is the same of the restricted one...|$|R
30|$|This case {{demonstrates}} a minimally invasive <b>correction</b> <b>technique</b> for ureteric ligation injury following McCall culdoplasty.|$|R
40|$|An {{analytical}} bias <b>correction</b> <b>technique</b> for inequality measures {{is applied}} to income data from China and Kenya. The coefficient of variation squared is used and it is illustrated how the bias is downward for positively skewed distributions. The analytical bias <b>correction</b> <b>technique</b> is then compared to a jackknife estimator in a simulation exercise. The bias will be important, even for moderately large sample sizes. ...|$|R
5000|$|Spread {{spectrum}} and ultrawideband techniques allow several transmitters to transmit {{in the same}} place on the same frequency with very little interference, typically combined with one or more error detection and <b>correction</b> <b>techniques</b> to fix all the errors caused by that interference.|$|E
50|$|AMTOR {{improves}} on RTTY {{by incorporating}} error detection or error <b>correction</b> <b>techniques.</b> The protocol remains relatively uncomplicated and AMTOR performs well even in poor and noisy HF conditions. AMTOR operates {{in one of}} two modes: an error detection mode and an automatic repeat request (ARQ) mode.|$|E
50|$|Distributed data stores {{typically}} use {{an error}} detection and correction technique.Some distributed data stores (such as Parchive over NNTP) use forward error <b>correction</b> <b>techniques</b> {{to recover the}} original file when parts of that file are damaged or unavailable.Others try again to download that file from a different mirror.|$|E
40|$|In this paper, we {{describe}} a novel music information retrieval system using spelling <b>correction</b> <b>technique.</b> The current music retrieval systems with humming enable a user give a query with humming. However, {{there is a}} problem that a user cannot always input a complete melody to the system with humming. It is because the user often mistakes a melody in its query. In order to solve the problem, we employ the spelling <b>correction</b> <b>technique,</b> which is used usually in a document processing system. Our system first converts user’s query by humming into melody information then in order to apply the spell correction, “term” and“characters”are extracted from the melody. Finally, our system can correct the mistake of the user’s query by the spelling <b>correction</b> <b>technique.</b> 1...|$|R
40|$|This article applies an {{analytical}} bias <b>correction</b> <b>technique</b> for inequality measures to income data from China and Kenya. We use {{the coefficient of}} variation squared and illustrate how the bias is downward for positively skewed distributions. The analytical bias <b>correction</b> <b>technique</b> is then compared to a jackknife estimator in a simulation exercise. The bias will be important, even for moderately large sample sizes. Coefficient of variation, small sample bias correction, inequality measurement...|$|R
50|$|C. Xu and R. W. Guo, Algebraic {{pressure}} <b>correction</b> <b>technique</b> {{for predicting}} incompressible fluid flow, ICE'95 International Conference of Engineering Science, USA, 1995.|$|R
50|$|Error <b>correction</b> <b>techniques</b> are {{essential}} for satellite communications, because, due to satellite's limited power a {{signal to noise ratio}} at the receiver is usually rather poor. Error correction works by adding an artificial redundancy to a data stream at the transmitting side, and using this redundancy to correct errors caused by noise and interference.|$|E
50|$|Bit {{stuffing}} {{does not}} {{ensure that the}} payload is intact (i.e. not corrupted by transmission errors); it is merely a way of attempting {{to ensure that the}} transmission starts and ends at the correct places. Error detection and <b>correction</b> <b>techniques</b> are used to check the frame for corruption after its delivery and, if necessary, the frame will be re-sent.|$|E
50|$|MISSE-7 also {{contained}} experiments mounted to its ExPA base. These experiments included SpaceCube which {{was developed by}} engineers at the NASA Goddard Space Flight Center and is a reconfigurable, high-performance system based on Xilinx's Virtex-4 commercial FPGAs designed for spaceflight applications requiring compute intensive on-board processing. The MISSE-7 SpaceCube’s purpose was {{to serve as an}} “on-orbit” test-bed for demonstrating “radiation hardened by software” program execution and error detection and <b>correction</b> <b>techniques</b> that will help enable the use of commercial processing devices in space.|$|E
50|$|C. Xu and R. W. Guo, Algebraic Pressure <b>Correction</b> <b>Technique</b> for Predicting Separated flow, Third Colloquium on Bluff Body Aerodynamics and Applications, Virginia, USA, 1996.|$|R
40|$|This {{research}} {{was intended to}} (1) describe the development of telling experience skill of the students of class VII E SMP Negeri 5 Negara through the implementation of pragmatic approach (principles of language use) accompanied by pair <b>correction</b> <b>technique</b> and <b>correction</b> by Teacher, (2) describe the steps of learning and teaching activities {{in the implementation of}} pragmatic approach (principles of language use) accompanied by pair <b>correction</b> <b>technique</b> and <b>correction</b> by Teacher to develop the skill of telling experiences by the students of VII E SMP Negeri 5 Negara, and (3) describe studentsâ€™ response about the implementation of pragmatic approach (principles of language use) accompanied by pair <b>correction</b> <b>technique</b> and <b>correction</b> by teacher. The subjects of this research were students and teacher of bahasa Indonesia in SMP Negeri 5 Negara. This research used the two-cycle classroom action research. The data about the skill of telling experiences was gathered through test method analyzed by qualitative description method. The data about studentsâ€™ response was gathered through questionnaire method analyzed by qualitative description and quantitative description. The result of the research showed that the implementation of pragmatic approach (principles of language use) accompanied by pair <b>correction</b> <b>technique</b> and <b>correction</b> by teacher can (1) develop the skill of telling experience by students, (2) be done through 19 appropriate learning steps, and (3) develop studentsâ€™ positive response in telling experience. Bahasa Indonesiaâ€™s teachers is hoped to implement the pragmatic approach (principles of language use) accompanied by pair <b>correction</b> <b>technique</b> and <b>correction</b> by teacher to develop the skill of telling studentsâ€™ experiences that make the teaching-learning activity can run conducive, creative, and innovative...|$|R
5000|$|A {{transmitter}} power level optimization and error <b>correction</b> <b>technique</b> for battery-operated RF transceivers which adjust the transmit power in transceivers to an optimal level to conserve battery life.|$|R
50|$|The no-cloning theorem {{prevents}} {{the use of}} classical error <b>correction</b> <b>techniques</b> on quantum states. For example, backup copies of a state {{in the middle of}} a quantum computation cannot be created and used for correcting subsequent errors. Error correction is vital for practical quantum computing, and for some time this was thought to be a fatal limitation. In 1995, Shor and Steane revived the prospects of quantum computing by independently devising the first quantum error correcting codes, which circumvent the no-cloning theorem.|$|E
50|$|Research has {{introduced}} {{a new approach to}} the control and knowledge aspects of geocoding, by using an agent-based paradigm. In addition to the new paradigm for geocoding, additional <b>correction</b> <b>techniques</b> and control algorithms have been developed. The approach represents the geographic elements commonly found in addresses as individual agents. This provides a commonality and duality to control and geographic representation. In addition to scientific publication, the new approach and subsequent prototype gained national media coverage in Australia. The research was conducted at Curtin University in Perth, Western Australia.|$|E
50|$|Designing {{a network}} {{protocol}} to support streaming media raises many problems. Datagram protocols, {{such as the}} User Datagram Protocol (UDP), send the media stream {{as a series of}} small packets. This is simple and efficient; however, there is no mechanism within the protocol to guarantee delivery. It is up to the receiving application to detect loss or corruption and recover data using error <b>correction</b> <b>techniques.</b> If data is lost, the stream may suffer a dropout. The Real-time Streaming Protocol (RTSP), Real-time Transport Protocol (RTP) and the Real-time Transport Control Protocol (RTCP) were specifically designed to stream media over networks. RTSP runs over a variety of transport protocols, while the latter two are built on top of UDP.|$|E
40|$|In this study, we {{postulate}} that forecasters {{desire to}} improve their performance by studying their past forecasting errors. To improve performance, forecasters may measure their past mistakes and revise their forecasts by forecast revision techniques. In an empirical test, forecasts of fifty firms' EPS were prepared by seven forecasting models. The initial forecasts were corrected by the Theil optimal linear <b>correction</b> <b>technique</b> and a Bayesian revision adjustment. Results indicate that the optimal linear <b>correction</b> <b>technique</b> is superior to not correcting for past forecast error. forecasting: applications, finance: securities...|$|R
40|$|Sample-time errors {{can greatly}} degrade the dynamic {{range of a}} time-interleaved {{sampling}} system. In this paper, a novel <b>correction</b> <b>technique</b> employing a cubic spline interpolation is proposed for inter-channel sample-time error compensation. The cubic spline interpolation compensation filter is developed {{in the form of}} a finite-impulse response (FIR) filter structure. The correction method of the interpolation compensation filter coefficients is deduced. A 4 GS/s two-channel, time-interleaved ADC prototype system has been implemented to evaluate the performance of the technique. The experimental results showed that the <b>correction</b> <b>technique</b> is effective to attenuate the spurious spurs and improve the dynamic performance of the system...|$|R
40|$|It is {{well known}} that the {{algebraic}} approximations to eigenvalues of a Sturm-Liouville problem by the central difference and Numerov's schemes provide only a few estimates restricted to the first element of the eigenvalue sequence. A <b>correction</b> <b>technique,</b> used first by Paine et al. (1981) for the central difference scheme and then by Andrew and Paine (1985) for Numerov's method, improves the results, giving acceptable estimates for a larger number of eigenvalues. In this paper some linear multistep methods, called Boundary Value Methods, are proposed for discretizing a Sturm-Liouville problem and the <b>correction</b> <b>technique</b> of Andrew-Paine and Paine et al. is extended to these new methods...|$|R
50|$|However, in {{the case}} of the Write Back policy, the changed cache block will be updated in the lower-level {{hierarchy}} only when the cache block is evicted. Writing back every cache block which is evicted is not efficient. Therefore, we use the concept of a Dirty bit attached to each cache block. The dirty bit is made high whenever the cache block is modified and during eviction, only the blocks with dirty bit high will be written to the lower-level hierarchy and then the dirty bit is cleared. In this policy, there is data losing risk as the only valid copy is stored in the cache and therefore need some <b>correction</b> <b>techniques</b> to be implemented.|$|E
50|$|The {{advent of}} {{compressed}} digital video systems finally eliminated {{the need for}} line-based drop-out compensators. Most low-level media errors, such as those caused by tape damage or imperfections, are now dealt with by forward error <b>correction</b> <b>techniques,</b> and those which overwhelm the FEC layer are typically too severe to remedy using simple line-based error concealment techniques, because damage to the compressed bitstream will often damage {{large parts of the}} video image. However, since occasional signal drop-outs can still occur, either through severe tape damage or because of packet loss in packetized video transmission, modern error concealment techniques that are aware {{of the structure of the}} compressed video format have been developed to deal with these.|$|E
5000|$|Modern {{hard drives}} use CRC codes {{to detect and}} Reed-Solomon codes to correct minor errors in sector reads, and to recover data from sectors that have [...] "gone bad" [...] and store that data in the spare sectors. [...] RAID systems {{use a variety of}} error <b>correction</b> <b>techniques</b> to correct errors when a hard drive {{completely}} fails. Filesystems such as ZFS or Btrfs, as well as some RAID implementations, support data scrubbing and resilvering, which allows bad blocks to be detected and (hopefully) recovered before they are used. The recovered data may be re-written to exactly the same physical location, to spare blocks elsewhere on the same piece of hardware, or to replacement hardware.|$|E
30|$|For {{enhancing}} {{the contrast of}} each class of the images, we develop a modified gamma <b>correction</b> <b>technique</b> where the parameters are dynamically set, resulting in quite different transformation functions for different classes of images and requiring less amount of time.|$|R
40|$|Hamming code error {{detection}} and correction methodology {{is used for}} error free communication in communication system. In communication system information data transferred from source to destination by channel. In between source and destination data may be corrupted due to any type of noise. To find original information we use Hamming code {{error detection}} and <b>correction</b> <b>technique.</b> In hamming code error detection and <b>correction</b> <b>technique</b> to get error free data at destination, we encrypt information data according to even and odd parity method before transmission of information at source end. In hamming code with even and odd parity check method by using VHDL, we transmit 25 bit information data with 5 redundancy bits from source and receive this data a...|$|R
40|$|This paper investigates several {{augmented}} mixture {{models that}} are competitive alternatives to standard Bayesian models and {{prove to be}} very suitable to word sense disambiguation and related classification tasks. We present a new classification <b>correction</b> <b>technique</b> that successfully addresses the problem of under-estimation of infrequent classes in the training data. We show that the mixture models are boosting-friendly and that both Adaboost and our original <b>correction</b> <b>technique</b> can improve {{the results of the}} raw model significantly, achieving stateof -the-art performance on several standard test sets in four languages. With substantially different output to Nave Bayes and other statistical methods, the investigated models are also shown to be effective participants in classifier combination...|$|R
50|$|The {{execution}} {{time for the}} square-and-multiply algorithm used in modular exponentiation depends linearly {{on the number of}} '1' bits in the key. While the number of '1' bits alone is not nearly enough information to make finding the key trivially easy, repeated executions with the same key and different inputs can be used to perform statistical correlation analysis of timing information to recover the key completely, even by a passive attacker. Observed timing measurements often include noise (from such sources as network latency, or disk drive access differences from access to access, and the error <b>correction</b> <b>techniques</b> used to recover from transmission errors). Nevertheless, timing attacks are practical against a number of encryption algorithms, including RSA, ElGamal, and the Digital Signature Algorithm.|$|E
50|$|As {{alternatives}} to operational solutions, Griffith (1983) examined three <b>correction</b> <b>techniques</b> (i.e., statistical solutions) in removing boundary-induced bias from inference. They are (1) based on generalized least squares theory, (2) using dummy variables and a regression structure (as {{a way of}} creating a buffer zone), and (3) regarding the boundary problem as a missing values problem. However, these techniques require rather strict assumptions {{about the process of}} interest (Yoo and Kyriakidis 2008). For example, the solution according to the generalized least squares theory utilizes time-series modeling that needs an arbitrary transformation matrix to fit the multidirectional dependencies and multiple boundary units found in geographical data (Griffith 1980). Martin (1987) also argued that some of the underlying assumptions of the statistical techniques are unrealistic or unreasonably strict. Moreover, Griffith (1985) himself also identified the inferiority of the techniques through simulation analysis.|$|E
50|$|Typically the <b>correction</b> <b>techniques</b> {{involve the}} {{physical}} and electrical characterisation of the motional inductance and terminal capacitance of a crystal blank, the knowledge of {{which is used to}} create a correction polynomial, or algorithm, which in turn is implemented in circuit blocks. These are usually simulated in a mathematical modeling software tool such as SPICE, to verify that the original measured data can be corrected adequately. Once the system performance has been verified, these circuits are then implemented in a silicon die, usually in a bulk CMOS technology. Once fabricated, this die is then embedded into an oscillator module along with the crystal blank. Due to the sub 1 ppm accuracy of this type of crystal oscillator specialist packaging must be used to ensure good ageing and temperature shock characteristics. Example applications are for use in low power or battery operated consumer electronic products such as GSM or CDMA mobile phones, or GPS satellite navigation systems.|$|E
40|$|In this paper, a {{beamforming}} correction for {{dipole source}} identification {{by means of}} phased microphone array measurements is proposed and validated by numerical simulation. Conventional beamforming algorithms are normally based on the monopole source assumption, and can result in significant misinterpretation when applied directly to array measurements of dipole sources. A previous <b>correction</b> <b>technique</b> aims to realign the phases of microphone signals, and has been proved effective to retrieve dipole locations. However, this technique {{is only applicable to}} a single source with a linear microphone array and thus its applications are limited in practice. This work extends the signal <b>correction</b> <b>technique</b> to account for both source location and source power for 2 -D microphone arrays. A dipole characteristic term is obtained based on theoretical analysis and used for the correction of both signal phase and amplitude. Numerical simulations are performed for a ideal dipole source and a reference monopole to validate the improved beamforming correction. Simulation results have shown that the proposed <b>correction</b> <b>technique</b> is capable of reconstructing dipole sources in both location and amplitude. It is therefore suggested to carefully consider the source mechanisms of aeroacoustic systems before applying array measurements...|$|R
40|$|Introduction to {{the theory}} of x-ray {{microanalysis}} through the electron microprobe including ZAF matrix <b>corrections.</b> <b>Techniques</b> to be discussed are wavelength and energy dispersive spectrometry, scanning backscattered electron, secondary electron, cathodoluminescence, and X-ray imaging. Lab sessions involve hands-on use of the electron microprobe...|$|R
30|$|The {{effect of}} {{increasing}} activity from hot regions on adjacent lesion quantification, {{as well as}} the improvement brought about by the recently proposed background <b>correction</b> <b>technique</b> has been extensively studied in this work. This study shows that lesions relatively close to hot regions (within 15 – 20 [*]mm) are greatly affected by the spill-in effect, causing reduced visibility and activity overestimation of lesions. This effect is more pronounced in SUVmax than SUVmean and reduces over iteration, but it is further aggravated by the use of filter. However, improved quantification and better lesion detectability were achieved with the recently proposed background <b>correction</b> <b>technique</b> irrespective of the lesion size, lesion distance from the hot region, the activity in the hot region or application of post-filter.|$|R
