98|273|Public
5000|$|Establishment {{of state}} of art Library with {{integrated}} e-library, e-journals, Wi-Fi access for the students and in-house <b>cache</b> <b>server</b> for SIMS/SH.|$|E
50|$|<b>Caché</b> <b>Server</b> Pages (CSP) {{technology}} allows tag-based {{creation of}} web applications that dynamically generate web pages, typically {{using data from}} a Caché database. Caché also includes InterSystems Zen, an implementation of AJAX that enables component-based development of rich internet applications.|$|E
5000|$|As an example, if slow.example.com is a [...] "real" [...] web server, and www.example.com is the Squid <b>cache</b> <b>server</b> that [...] "accelerates" [...] it, {{the first}} time any page is {{requested}} from www.example.com, the <b>cache</b> <b>server</b> would get the actual page from slow.example.com, but later requests would get the stored copy directly from the accelerator (for a configurable period, after which the stored copy would be discarded). The end result, without any action by the clients, is less traffic to the source server, meaning less CPU and memory usage, and less need for bandwidth. This does, however, mean that the source server cannot accurately report on its traffic numbers without additional configuration, as all requests {{would seem to have}} come from the reverse proxy. A way to adapt the reporting on the source server is to use the X-Forwarded-For HTTP header reported by the reverse proxy, to get the real client's IP address.|$|E
40|$|The {{benefits}} of Web caching {{can be improved}} by systems of cooperative <b>cache</b> <b>servers</b> that share their cached documents. The increasing number of Web <b>cache</b> <b>servers</b> over the Internet makes the scalability of the cooperation protocol a major issue to be addressed. In this {{paper we propose a}} Two-Tier Cooperation protocol (2 TC), which is specifically designed for systems of dozens or hundreds of <b>cache</b> <b>servers</b> with no centralized control. 2 TC embeds two classical cooperation approaches for distributed Web caching systems, namely Informed Cooperation (IC) and Query Cooperation (QC), that are applied within different subsets of <b>cache</b> <b>servers</b> in the system. IC is applied within subsets of close servers and lets them cooperate through mutual exchange of state information related to their cache content. QC lets more distant <b>cache</b> <b>servers</b> cooperate through query/reply messages to locate documents within the global cache. Thanks to the use of IC among close <b>cache</b> <b>servers,</b> QC can explore the cache content of several <b>cache</b> <b>servers</b> through a single query message. High scalability ari. ses as few queries explore the cache content of many <b>cache</b> <b>servers</b> and state information is exchanged within small groups of close <b>cache</b> <b>servers.</b> We report experimental results based on real traces that compare a prototype implementation of 2 TC with classical protocols of the informed and query classes. The results point out a strong reduction (up to 50 %) of the amount of transferred information to manage cooperation. This overhead reduction is achieved with no performance degradation in terms of latency and cache hit rate...|$|R
40|$|The {{scalable}} and bandwidth-efficient {{delivery of}} IPTV services to an increasingly diverse set of screens requires {{the deployment of}} telco content distribution networks (CDNs). These CDNs are composed of <b>cache</b> <b>servers</b> located in the telco's data centers {{close to the end}} user. The additional <b>cache</b> <b>servers</b> need to be designed for energy efficiency to limit the increase of data-center energy consumption. We analyze real HTTP adaptive-streaming traces from an operational telco CDN delivering IPTV to mobile devices to identify workload characteristics that can be exploited to conserve energy. We also present a trace-driven simulator that models the energy consumption of such a CDN down {{to the level of the}} cache-server disk to evaluate potential energy-saving techniques. The traces reveal cyclic load fluctuations that can be exploited to save energy in CDNs by varying the number of powered <b>cache</b> <b>servers</b> and disks according to the load...|$|R
40|$|Proxy <b>cache</b> <b>servers</b> {{are used}} {{to deal with the}} {{increasing}} demand for information on the Internet by caching the frequently referenced web objects. It is common to have more than one proxy <b>cache</b> <b>servers</b> being installed in one local network. The problem of load balancing then arises as organizations want to utilise the resources in the best way. This article proposes two methods to tackle the load balancing problem. The two methods are based on the notion of autonomy oriented computation where entities in the model are allowed to make local decisions and they only need to interact with local neighbors...|$|R
50|$|The Nix build {{language}} used by NixOS specifies {{how to build}} packages from source. This {{makes it easy to}} adapt the system to user needs. However, building from source being a slow process, the package manager automatically downloads pre-built binaries from a <b>cache</b> <b>server</b> when they are available. This gives the flexibility of a source-based package management model with the efficiency of a binary model.|$|E
5000|$|Standalone GPS {{provides}} first {{position in}} approximately 30-40 seconds. A standalone GPS needs orbital information of the satellites {{to calculate the}} current position. The data rate of the satellite signal is only 50 bit/s, so downloading orbital information like ephemerides and the almanac directly from satellites typically takes a long time, and if the satellite signals are lost during the acquisition of this information, it is discarded and the standalone system has to start from scratch. In A-GPS, the network operator deploys an A-GPS server, a [...] <b>cache</b> <b>server</b> for GPS data. These A-GPS servers download the orbital information from the satellite and store it in the database. An A-GPS-capable device can connect to these servers and download this information using mobile-network radio bearers such as GSM, CDMA, WCDMA, LTE or even using other radio bearers such as Wi-Fi. Usually the data rate of these bearers is high, hence downloading orbital information takes less time.|$|E
40|$|Caching and proxy {{technology}} {{designed to}} solve the internet issues in organization include security and performance by cache and filter, the request between network with another network mostly internal LAN and global network. Squid <b>cache</b> <b>server</b> {{is one of the}} most famous <b>cache</b> <b>server</b> that running on multiple platform. Squid <b>cache</b> <b>server</b> use squid. conf file to store configuration and setting for the <b>cache</b> <b>server.</b> Whenever administrators want to configure the <b>cache</b> <b>server,</b> they need to interact with the ifie itse 1 f, which require administrator to study and memories a lot of the commands. Administrators also need extra knowledge on how to set up the server to run at platform. SQ Squid <b>cache</b> <b>server</b> management front end is design to overcome this inconvenient by providing graphical user interlace design to interact with the squid. conf file on behalf of the administrators. All options available for Squid <b>cache</b> <b>server</b> is configure using GUI make it easier to understand and configure. However, SQ Squid <b>cache</b> <b>server</b> management front end is not a new cache server; it's only a graphical user interface management front end for existing cache server-Squid <b>cache</b> <b>server.</b> 'SQ Squid Management front end help administrators understand and configure the Squid <b>cache</b> <b>server</b> where extra knowledge on command use in Squid <b>cache</b> <b>server</b> is not needed but only knowledge on cache, network, and security...|$|E
40|$|Part 5 : Social NetworksInternational audienceSocial network {{applications}} are inherently interactive, creating {{a requirement for}} processing user requests fast. To enable fast responses to user requests, social network applications typically rely on large banks of <b>cache</b> <b>servers</b> to hold and serve most of their content from the cache. In this work, we present DynaSoRe: a memory cache system for social network applications that optimizes data locality while placing user views across the system. DynaSoRe storage servers monitor access traffic and bring data frequently accessed together closer in the system to reduce the processing load across <b>cache</b> <b>servers</b> and network devices. Our simulation results considering realistic data center topologies show that DynaSoRe is able to adapt to traffic changes, increase data locality, and balance the load across the system. The traffic handled by the top tier of the network connecting servers drops by 94 % compared to a static assignment of views to <b>cache</b> <b>servers</b> while requiring only 30 % additional memory capacity compared to the whole volume of cached data...|$|R
40|$|Abstract—Video {{streaming}} {{is now at}} {{the fingertips}} of mobile users with recent advances in wireless communications and mobile networking. Caching has been widely deployed by wireless service providers (WSPs) to facilitate video content dissemination. Yet, capacity provisioning of <b>cache</b> <b>servers</b> is challenging given dynamic user demands and limited wireless bandwidth resources available. With increased densities of wireless service deployment, it is common that mobile users are now covered by more than one WSP within a geographical region. This brings both challenges and opportunities towards a collaborative caching paradigm among <b>cache</b> <b>servers</b> that are deployed by different WSPs. This paper explores the benefits of collaborative caching for wireless video streaming services, addressing challenges related to both incentives and truthfulness of selfish WSPs. We propose a collaborative mechanism that aims to maximize the social welfare in the context of Vickrey-Clarke-Groves (VCG) auctions, which encourages <b>cache</b> <b>servers</b> to spontaneously cooperate for trading their resources in a self-enforcing manner. Results from simulations demonstrate significant performance improvements with respect to video streaming quality. I...|$|R
25|$|In January 2005, {{the project}} ran on 39 {{dedicated}} servers in Florida. This configuration included a single master database server running MySQL, multiple database servers, 21 web servers running the Apache HTTP Server, and seven Squid <b>cache</b> <b>servers.</b>|$|R
40|$|An open Jackson-type queuing {{network model}} is {{proposed}} {{to study the}} impact of the servers breakdown on the overall response times to Web requests. The primary aim of the present paper is to modify the performance model of the Proxy <b>Cache</b> <b>Server</b> to a more realistic case when both the Proxy <b>Cache</b> <b>Server</b> and the Web server are unreliable. The main performance and reliability measures are derived, and some numerical calculations are carried out by the help of the MOSEL tool. The nu- merical results are graphically displayed to illustrate the effect of the nonreliabilit...|$|E
40|$|Abstract. Object caching is a {{desirable}} feature {{to improve the}} both scalability and performance of distributed application systems for information infrastruc-ture, the information management system leveraging the power of network computing. However, in order to exploit such benefits, we claim that the fol-lowing problems: <b>cache</b> <b>server</b> placement, cache replacement, and cache syn-chronization, should be considered when designing any object cache system. We are under developing DOC: a Distributed Object Caching, {{as a part of}} building our information infrastructures. In this paper, we show how each prob-lem is inter-related, and focus to highlight how we handle <b>cache</b> <b>server</b> deploy-ment problem. ...|$|E
40|$|In {{this thesis}} we {{introduce}} CPHash − a scalable fixed size hash table that supports eviction using an LRU list, and CPServer − a scalable in memory key/value <b>cache</b> <b>server</b> that uses CPHash to implement its hash table. CPHash uses computation migration to avoid transferring data between cores. Experiments on a 48 core ma-chine show that CPHash has 2 to 3 times higher throughput than a hash table implemented using scalable fine-grained locks. CPServer achieves 1. 2 to 1. 7 times higher throughput than a key/value <b>cache</b> <b>server</b> {{that uses a}} hash table with scalable fine-grained locks and 1. 5 to 2. 6 times higher throughput than Memcached...|$|E
30|$|The CDN {{architecture}} typically deploys a {{load balanced}} setup with distributed <b>cache</b> <b>servers</b> spread geographically {{around the world}} in order to optimize latency, bandwidth, and cost of networking [25, 26], leading to data replication into various centers and a static tier hierarchy.|$|R
25|$|To improve efficiency, reduce DNS traffic {{across the}} Internet, and {{increase}} performance in end-user applications, the Domain Name System supports DNS <b>cache</b> <b>servers</b> which store DNS query results {{for a period}} of time determined in the configuration (time-to-live) of the domain name record in question.|$|R
50|$|WinMX {{began its}} {{life as an}} OpenNAP client capable of {{connecting}} to several servers simultaneously, although Frontcode later created a proprietary protocol, termed WinMX Peer Network Protocol (WPNP), which was used starting with WinMX 2 in May 2001. Frontcode had operated several <b>cache</b> <b>servers</b> to aid WPNP network operation.|$|R
40|$|Abstract. Mobile {{devices have}} {{difficulty}} in sustaining various services as in a wired environment, {{due to the}} storage shortage of the mobile device. The re-search[8] which provides remote storage service for mobile appliances using iSCSI has been conducted to overcome the storage shortage in mobile appli-ances. In research the proposed <b>cache</b> <b>server</b> performed well with relatively small files of sizes, however, did not perform well with large files such as data-base files, multimedia files, etc. The reason was the mobile device could not grasp the file {{as a whole and}} thus the <b>cache</b> <b>server</b> encountered frequent cache miss in spite of its huge buffer. In this paper we propose a proxy server that ac-commodates large files for mobile devices thus attains very high hit ratio. ...|$|E
40|$|This paper {{presents}} {{a method of}} improving the bandwidth management controls in the Squid <b>cache</b> <b>server,</b> thus allowing the majority of users to obtain a significantly better performance in a bandwidthconstrained environment. In many countries, the unavailability of sufficient bandwidth results in very slow access to the Internet. This situation is exacerbated by {{a small number of}} users who use a disproportionate share of the available bandwidth for file downloads, etc., starving other users of bandwidth. Therefore some means of controlling and managing the bandwidth available to users is necessary. Most ISPs provide web access through cache/proxy servers. As all web accesses are channeled through the <b>cache</b> <b>server,</b> using the same server for bandwidth management is expedient. Squid is a popular <b>cache</b> <b>server</b> which contains a bandwidth management feature called “delay pools”. However, the existing implementation of delay pools did not provide satisfactory performance as bandwidth allocations are static and do not adapt to varying usage patterns. Our solution adjusts the bandwidth allowed per each user and group of users to provide an optimum level of access to all users. During off-peak hours, each user can use essentially the full available bandwidth, while during peak hours light interactive users get better performance at the expense of heavy and noninteractiv...|$|E
40|$|This {{document}} {{defines the}} configuration of squid Proxy 13; server on L 1 NUXRedhat 8. Being a proxy and <b>cache</b> <b>server,</b> it enables 13; multiple clients to simultaneously access, fast and secure internet. This 13; document also provide information for restricting the websites according 13; to the organisation's policy...|$|E
40|$|Abstract: The {{system log}} (syslog) {{files of the}} E-mail and the DNS <b>cache</b> <b>servers</b> in Kumamoto University were {{statistically}} investigated when receiving a lot of spam mails. The DNS query traffic between the E-mail and the DNS <b>cache</b> <b>servers</b> increases when many traces of spam and/or junk mails are found in syslog file of the E-mail server. The DNS query traffic decreases when preventing access between the E-mail server and the spam/junk transferring SMTP clients. This is because the DNS query between the DNS and E-mail servers are mainly driven by the SMTP access in the E-mail server. Therefore, we can detect abnormality of the E-mail server by monitoring the DNS query traffic from the E-mail server to the DNS server and get access-controlling list by analysis of the SMTP syslog files...|$|R
40|$|This paper {{describes}} LC-RTP, {{an efficient}} and simple reliable multicast protocol that complies with RTP ([1]). Its deployment would require neither {{changes to the}} network infrastructure nor to existing end-user presentation software. It provides lossless transmission of AV content into <b>cache</b> <b>servers</b> and concurrently, lossy real-time delivery to end-users using multicast. It achieves reliability by retransmission. The traffic increase is minimal because the transmission of the AV content and any caching will take place while the end-user is served. Support for multicast in the distribution system ensures that all <b>cache</b> <b>servers</b> of a multicast group can cache an AV content while transmitting it to a consumer. Finally we present the results of long distance file transmissions {{in order to show}} that LC-RTP performs well and meets the requirements for lossless transmission of AV conten...|$|R
40|$|Abstract. This paper {{presents}} {{a new approach}} to predict web documents by tracking search patterns of users and by managing documents depending upon the number of hits. Several hot spot documents and their linked documents are stored in <b>cache</b> <b>servers</b> and transmitted them to clients for fast response. The adaptive prefetching method, using search patterns of users, analyzes documents along with the navigation patterns and marks several popular documents. If one of these marked documents is hit, all marked documents are loaded into the cache but only the requested document is transmitted to clients. <b>Cache</b> <b>servers</b> can save their cache memory space as well as provide fast response to clients. The results show that the average response time of the proposed method decreases to 20 % compared with other methods and the cache hit rate is increased to 18 % of other methods. ...|$|R
40|$|This work {{attempts}} at exploring the data standard of the Ministry of Health of the Czech Republic and {{the possibilities of}} access to the hospital information system CLINICOM. At the beginning basic information about data standards in the health care, international classification of diseases and diagnosis related groups are described. The next part is focused at the database platform Caché and possibilities of word wide web access into the system via <b>Caché</b> <b>server</b> pages. Then it describes valid legislature for nation medicine registries and for mandatory reports to the Nation Medicine Registry of Inpatients. In the end of work it describes the realized program in <b>Cache</b> <b>server</b> pages for on-line data message reports about anonym patients into the National Registry of Inpatients. Patients are sort in agreement with time period and diagnosis related groups. Program utility and Internet data transfer security are discussed...|$|E
30|$|Due {{to their}} limited sizes, caches cannot store every web page/object indefinitely. When the cache becomes full, the <b>cache</b> <b>server</b> must choose {{one or more}} objects to remove {{in order to make}} space for new objects. This {{decision}} {{is the responsibility of the}} cache replacement algorithm [9], one of the most critical components of a web cache system.|$|E
30|$|AFNetworking is more {{suitable}} to process requests to Web sites, including detailed Sessions and Cookies problems. It {{can be used}} to send HTTP requests and receive HTTP responses. However, it does not <b>cache</b> <b>server</b> responses or execute the JAvascript code in the HTML page. Meanwhile, AFNetworking has built-in JSON, plist, and XML file parsing for convenient application.|$|E
40|$|Cache pre-filling is {{emerging}} as a new concept for increasing the availability of popular web items in <b>cache</b> <b>servers.</b> According to this concept, web items are sent by a "push-server" to the proxy <b>cache</b> <b>servers,</b> usually through a broadcast-based or a multicast-based distribution mechanism. One {{of the most difficult}} challenges is to design the scheduling algorithm of the push-server. This algorithm needs to determine the "broadcast scheduling map", namely which web items to broadcast and when. In this paper we study the approach where every constant period of time each proxy cache analyzes the requests it has received in the past and determines which web item it prefers to receive by broadcast and when. We formalize a related problem, called the "Cache Pre-filing Push" (CPFP) problem, analyze its computational complexity, and describe efficient algorithms to solve it...|$|R
40|$|Architectures {{consisting}} of multiple <b>cache</b> <b>servers</b> are a popular solution {{to deal with}} performance and network resource utilization {{issues related to the}} growth of the Web request. Cache cooperation is often carried out through purely hierarchical and flat schemes that suffer from scalability problems when the number of servers increases. We propose, implement and compare the performance of three novel distributed cooperation models based on a two-tier organization of the <b>cache</b> <b>servers.</b> The experimental results show that the proposed architectures are effective in supporting cooperative document lookup and download They guarantee cache hit rates comparable to those of the most performing protocols with a significant reduction of the cooperation overhead Moreover in case of congested network, they reduce the 90 -percentile of the system response time up to nearly 30 % with respect to the best pure cooperation mechanisms...|$|R
40|$|Abstract—Cache pre-filling is {{emerging}} as a new concept for increasing the availability of popular web items in <b>cache</b> <b>servers.</b> According to this concept, web items are sent by a “push-server ” to the proxy <b>cache</b> <b>servers,</b> usually through a broadcast-based or a multicast-based distribution mechanism. One {{of the most difficult}} challenges is to design the scheduling algorithm of the push-server. This algorithm needs to determine the “broadcast scheduling map”, namely which web items to broadcast and when. In this paper we study the approach where every constant period of time each proxy cache analyzes the requests it has received in the past and determines which web item it prefers to receive by broadcast and when. We formalize a related problem, called the “Cache Pre-filing Push ” (CPFP) problem, analyze its computational complexity, and describe efficient algorithms to solve it. I...|$|R
40|$|In {{this thesis}} we {{introduce}} CPHASH - a scalable fixed size hash table that supports eviction using an LRU list, and CPSERVER - a scalable in memory key/value <b>cache</b> <b>server</b> that uses CPHASH to implement its hash table. CPHASH uses computation migration to avoid transferring data between cores. Experiments on a 48 core machine show that CPHASH has 2 to 3 times higher throughput than a hash table implemented using scalable fine-grained locks. CPSERVER achieves 1. 2 to 1. 7 times higher throughput than a key/value <b>cache</b> <b>server</b> {{that uses a}} hash table with scalable fine-grained locks and 1. 5 to 2. 6 times higher throughput than MEMCACHED. by Zviad Metreveli. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2011. In title on title page,"ASH" appears as subscript upper case letters. Cataloged from PDF version of thesis. Includes bibliographical references (p. 45 - 47) ...|$|E
40|$|Term Project {{describes}} the data standard of health information systems, {{its history and}} present condition, form, composition data files and blocks. Data standard such as is used to transfer data between medical information systems. In other chapters, {{describes the}} work and access to hospital information system CLINICOM. Followed by implementation of database access via web interface CLINICOM CSP (<b>Caché</b> <b>Server</b> Pages) ...|$|E
40|$|CPHASH is a {{concurrent}} {{hash table}} for multicore processors. CPHASH partitions its table across the caches of cores and uses message passing to transfer lookups/inserts to a partition. CPHASH’s message passing avoids {{the need for}} locks, pipelines batches of asynchronous messages, and packs multiple messages into a single cache line transfer. Experiments on a 80 -core machine with 2 hardware threads per core show that CPHASH has ∼ 1. 6 × higher throughput than a hash table implemented using fine-grained locks. An analysis shows that CPHASH wins because it experiences fewer cache misses and its cache misses are less expensive, because of less contention for the on-chip interconnect and DRAM. CPSERVER, a key/value <b>cache</b> <b>server</b> using CPHASH, achieves ∼ 5 % higher throughput than a key/value <b>cache</b> <b>server</b> that uses a hash table with fine-grained locks, but both achieve better throughput and scalability than MEMCACHED. Finally, the throughput of CPHASH and CPSERVER scales near-linearly {{with the number of}} cores. ...|$|E
40|$|The growing {{end-user}} {{demand for}} video services with superior quality on laptops, tablets, and smartphones spurs {{the deployment of}} telco content distribution networks (CDNs). Such CDNs provide scalable and bandwidth-efficient video delivery thanks to disk-packed <b>cache</b> <b>servers</b> deployed in the telco's data centers near the clients. However, a sustainable growth of these CDNs may be hindered by their lack of energy proportionality. In this paper we propose to apply dynamic power management (DPM) to the CDN's <b>cache</b> <b>servers</b> and their disks to increase the CDN's energy efficiency. We evaluate DPM using a CDN energy simulator driven by HTTP adaptive-streaming workload traces recorded by an operational CDN delivering IPTV to mobile devices. Even for a minimally-provisioned CDN, we observe a reduction of the energy dissipation by approximately 30 % thanks to large cyclic load fluctuations characteristic of IPTV delivery...|$|R
40|$|Mobile network {{operators}} are experiencing a tremendous increase in data traffic {{due to the}} growing popularity of bandwidth-intensive video services. This challenge can be faced either by boosting the capacity of the network infrastructure, or by means of offloading traffic from the backhaul and core network and serving contents from distributed <b>cache</b> <b>servers</b> close to the users. Network operators can extend the coverage of traditional CDNs by making usage of caching locations much closer to the users than traditional CDNs. Additionally, {{network operators}} can optimize the caching and delivery of contents by exploiting the complete knowledge of their network for designing a cost-effective infrastructure able to achieve both improved user satisfaction and cost savings. This article provides thoroughly justified design principles for a highly distributed operator-owned CDN while focusing on four key aspects: the optimal location of <b>cache</b> <b>servers,</b> mechanisms for request routing, content replica placement, and content outsourcing and retrieval...|$|R
40|$|The global content {{distribution}} {{infrastructure is}} expanding towards {{the edge of}} the Internet with <b>cache</b> <b>servers</b> deployed closer to the clients to enable a highly available and bandwidth-efficient delivery of high-quality video services to a broadening range of consumer terminals. The proliferation of <b>cache</b> <b>servers</b> in telco data centers contributes to the unsustainable increase of data-center power consumption. In this paper, we propose to save energy in content distribution networks (CDNs) by means of combined dynamic power management (DPM) of the CDN’s <b>cache</b> <b>servers</b> and the disks in these servers. We present an online load-directed threshold-based power control policy that reduces the CDN’s power consumption while ensuring the best possible viewing experience and a high service availability. In addition, the proposed policy avoids an increase of the bandwidth cost and an excessive wear of the servers and disks. We compare such online policy with a near-optimal offline heuristic greedy policy that determines an upper bound for the energy savings that can be realized by DPM. The evaluation of the power control policies is based on a CDN energy simulator driven by HTTP adaptive-streaming workload traces recorded by an operational telco CDN delivering IPTV services to mobile devices. Even for a minimally provisioned CDN, the online policy reduces the cache-server power consumption by 24 %. The energy savings realized by the online policy correspond to 85 % of the energy-savings upper bound determined by the offline policy. status: publishe...|$|R
