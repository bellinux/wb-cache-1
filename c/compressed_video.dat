979|597|Public
2500|$|With the {{introduction}} of widespread support of the HTML5 [...] tag in most web browsers, some websites use a looped version of the video tag generated by JavaScript functions. This gives {{the appearance of a}} GIF, but with the size and speed advantages of <b>compressed</b> <b>video.</b> Notable examples are Gfycat and Imgur and their GIFV metaformat, which is really a video tag playing a looped MP4 or WebM <b>compressed</b> <b>video.</b>|$|E
5000|$|SMPTE 2047-2:2010 Carriage of VC-2 <b>Compressed</b> <b>Video</b> over HD-SDI ...|$|E
5000|$|PAVP Lite: Reserves {{buffer memory}} for {{encryption}} of <b>compressed</b> <b>video</b> data.|$|E
5000|$|<b>Compress</b> - <b>Video</b> Compression Software that <b>compress</b> <b>videos</b> {{up to one}} {{tenth of}} the {{original}} size ...|$|R
50|$|Digital Video (DV) {{adopts a}} similar method by <b>compressing</b> <b>video</b> frames individually.|$|R
5000|$|DV uses lossy {{compression}} of video while audio is stored uncompressed. [...] An intraframe video compression scheme {{is used to}} <b>compress</b> <b>video</b> on a frame-by-frame basis with the discrete cosine transform (DCT).|$|R
5000|$|<b>Compressed</b> <b>video</b> is {{also carried}} using UDP-IP over Ethernet. Two {{approaches}} exist for this: ...|$|E
5000|$|H.264: <b>Compressed</b> <b>video</b> {{using the}} H.264 codec in an MPEG-4 file; usually stored in tapeless media ...|$|E
50|$|UVC v1.1 support {{transmission}} of <b>compressed</b> <b>video</b> streams, including MPEG-2 TS, H.264, MPEG-4 SL SMPTE VC1 and MJPEG.|$|E
40|$|This paper {{describes}} the novel application of using linear fractal interpolation functions (FIFs) to model video signals represented as single-valued discrete-time sequences to <b>compress</b> <b>video</b> images. The problem is data compression of full-motion broadband television signals. The viability of using FIFs to model video signals {{is shown by}} modelling test static image frames. Compression ratios, SNRs and compression-decompression times are reported. Extension of this work to <b>compress</b> motion <b>video</b> is described. Finally the images are analysed by calculating and plotting the fractal dimensions of each line in the frame against the line for that image. Appendix F Using Linear Fractal Interpolation Functions to <b>Compress</b> <b>Video</b> Images 1. LINEAR FRACTAL INTERPOLATION FUNCTIONS (SELF-AFFINE FRACTAL MODEL) In linear fractal interpolation, a set of points is interpolated with a continuous, single valued function that passes through the given interpolation point...|$|R
30|$|However, {{these models}} are derived {{in terms of}} mean squared error (MSE), which {{has been criticized for}} weak {{correlation}} with perceptual characteristics. As most <b>compressed</b> <b>videos</b> are presented to humans, it is meaningful to incorporate visual features into the error-resilient video coding to protect important visual information of <b>compressed</b> <b>videos</b> from packet loss. Thus, several region-of-interest (ROI)-based approaches were presented to better evaluate the visual quality [14, 15]. However, ROI-based approaches do not provide accurate distortion estimation, and ROI determination may be difficult for most videos, especially for videos with natural scenes. Therefore, it is expected that a perception-based end-to-end distortion model could provide a more general and accurate perceptual distortion estimation.|$|R
50|$|One of {{the most}} {{powerful}} techniques for <b>compressing</b> <b>video</b> is interframe compression. Interframe compression uses one or more earlier or later frames in a sequence to compress the current frame, while intraframe compression uses only the current frame, effectively being image compression.|$|R
50|$|VGZ {{files are}} <b>compressed</b> <b>video</b> files that use Chateau Technical's propriety H.264 codec. They are usually found in {{security}} camera DVRs.|$|E
50|$|A {{standalone}} {{video recorder}} is {{a device that}} receives uncompressed video and stores it in either uncompressed or compressed form. These devices typically have a video output {{which can be used}} to monitor or playback recorded video.When playing back <b>compressed</b> <b>video,</b> the <b>compressed</b> <b>video</b> is uncompressed by the device before being output. Such devices may also have a communication interface, such as Ethernet or USB, which can used to exchange video files with an external computer, and in some cases control the recorder from an external computer as well.|$|E
50|$|EVS has {{achieved}} success in <b>compressed</b> <b>video</b> and audio data processing, and is endeavouring {{to maintain its}} market position in the migration from analogue to digital in television networks.|$|E
5000|$|H.264/AVC/MPEG-4 Part 10 {{contains}} {{a number of}} new features that allow it to <b>compress</b> <b>video</b> much more efficiently than older standards and to provide more flexibility for application {{to a wide variety of}} network environments. In particular, some such key features include: ...|$|R
40|$|As most of MPEG and JPEG {{compression}} {{standards are}} DCT-based, we propose a simple, low-cost and fast algorithm to extract dominant colour features directly in DCT domain without involving full decompression {{to access the}} pixel data. As dominant colour {{is one of the}} colour features used in constructing MPEG- 7 dominant colour descriptors, the proposed algorithm would provide useful technique for those already <b>compressed</b> <b>videos</b> and images, where MPEG- 7 dominant colour descriptors are needed. While the proposed algorithm presents advantages in terms of computing efficiency, i. e. eliminating the need of IDCT for <b>compressed</b> <b>videos</b> and images, extensive experiments also support that the proposed algorithm achieves competitive performances in extracting dominant colour features when compared with the pixel domain extraction described in MPEG- 7. Crown Copyright © 2006...|$|R
5000|$|File formats: JPEG, NEF (Nikon's RAW, 14-bit <b>compressed),</b> H.264 <b>video</b> codec.|$|R
5000|$|Video mode : VGA (640 × 480 pixels) at 30 frame/s, QVGA (320 × 240 pixels) at 30 frame/s up to 80 min. {{based on}} memory {{capacity}} continuous MPEG-4 <b>compressed</b> <b>video</b> with audio (QuickTime), 3X zoom during video ...|$|E
50|$|Developed {{to address}} the needs of the growing number of <b>compressed</b> <b>video</b> {{standards}} (DV, DVCPRO, BetaSX, MPEG2) it allows lossless transfer of data to other devices which have the same codec, for example DV to DV or SX to SX.|$|E
50|$|Since its {{invention}} in the 1950s, {{the magnetic}} coating used in analog video tape has experienced radio frequency (RF) signal drop-outs. Some {{of the techniques}} that were used for resolving these issues are analogous to those used for concealing errors in modern <b>compressed</b> <b>video</b> signals.|$|E
40|$|A reduced {{reference}} picture quality measure is proposed for MPEG- 2 <b>compressed</b> <b>videos.</b> The measure {{can be calculated}} from the ratio of three N tap one-dimensional discrete cosine transform (DCT) coefficients. The proposed measures are highly correlated to subjective test scores and can provide accurate assessment of picture quality for {{a certain type of}} sequences. close 5...|$|R
40|$|International Telemetering Conference Proceedings / October 17 - 20, 1988 / Riviera Hotel, Las Vegas, NevadaThis paper {{discusses}} {{the development of}} a standard for <b>compressed</b> digital <b>video.</b> The benefits and applications of <b>compressed</b> digital <b>video</b> are reviewed, and some examples of compression techniques are presented. A hardware implementation of a differential pulse code modulation approach is examined...|$|R
50|$|VirtualDub was {{originally}} {{created for the}} purpose of <b>compressing</b> anime <b>videos</b> of Sailor Moon.|$|R
50|$|The first {{commercial}} reference software products were reformulations of existing content into CD-ROM editions, often supplemented with new multimedia content, including <b>compressed</b> <b>video</b> and sound. More recent products {{made use of}} internet technologies, to supplement CD-ROM products, then, more recently, to replace them entirely.|$|E
5000|$|Developed, in 1995, a Post baccalaureate Pharm.D. program {{utilizing}} interactive <b>Compressed</b> <b>Video.</b> The practicing pharmacists {{throughout the}} state of Florida and Puerto Rico who cannot afford to interrupt their careers or relocate to a college campus are enrolled in this innovative and flexible program.|$|E
5000|$|In the 1990s, the {{population}} of Marvell was approximately 1545. [...] In 1997 the Marvell Medical Clinic was built with citizen donations. The clinic expanded in only one year to include dental services and interactive two-way <b>compressed</b> <b>video</b> use for medical consultations and health education.|$|E
40|$|In this work, we {{used two}} types of {{impairments}} in a psychophysical experiment to measure the overall annoyance and individual strength of three impairment features (fuzzy, blocky, and blurry). The impairments were generated by <b>compressing</b> the original <b>videos</b> with MPEG- 2 at two different bitrates: 1. 0 and 7. 5 Mbps. The heavily <b>compressed</b> <b>videos</b> presented blurry and blocky impairments, while the lightly <b>compressed</b> <b>videos</b> presented `fuzzy' impairments, using a word provided by our test subjects. These impairments were then linearly combined in different proportions and strengths, generating videos in which all three impairment features are present. Our goal was to determine how these impairment features combine to produce the overall annoyance. A modified Minkowski metric was {{used to describe the}} `combination rule' which relates the strengths of the impairment features to the overall annoyance. For the data set containing all test sequences, the optimal value found for the Minkowski parameter p was 1. 55. From the data obtained, we also estimated the psychometric and annoyance functions. We found that for blocky-blurry and fuzzy artifacts there is no consistent difference between either the thresholds or mid-annoyance strengths...|$|R
40|$|In {{this paper}} we {{show how the}} use of an {{automatic}} threshold selection technique can improve some critical video parsing operations. To this end, in the framework of an information-theoretic approach, we propose a technique based on entropy maximization. We also present an algorithm for detecting dissolves in Mpeg <b>compressed</b> <b>videos,</b> which demonstrates the reliability of the proposed technique. Experimental results are provided and discussed...|$|R
40|$|This paper {{describes}} how Fractal Coding Theory may {{be applied to}} <b>compress</b> <b>video</b> images using an image resampling sequencer (IRS) in a video compression system on a modular image processing system. The {{first part of the}} paper describes the background theory of image coding using a form of fractal equation known as Iterated Function System (IFS) codes. The second part deals with the modular image processing system on which to implement these operations. The third part briefly covers how IFS codes may be calculated. Finally, how the IRS and 2 nd order geometric transformations may be used to describe inter-frame changes to <b>compress</b> motion <b>video.</b> Appendix E The Use of Fractal Theory in a Video Compression System 26...|$|R
5000|$|The value (CD / CF) {{represents}} the average {{bits per pixel}} (BPP). As an example, {{if we have a}} color depth of 12bits/pixel and an algorithm that compresses at 40x, then BPP equals 0.3 (12/40). So in the case of <b>compressed</b> <b>video</b> the formula for bit rate is: ...|$|E
50|$|Such {{approaches}} do {{not constitute}} compromises of the AACS encryption itself, relying instead on an officially licensed software player to perform the decryption. As such, the output data {{will not be in}} the form of the <b>compressed</b> <b>video</b> from the disc, but rather decompressed video. This is an example of the analog hole.|$|E
50|$|In {{the early}} 2000s, Flash was widely {{installed}} on desktop computers, and was {{commonly used to}} display interactive web pages, online games, and to playback video and audio content. In 2005, YouTube was founded by former PayPal employees, and it used Flash Player {{as a means to}} display <b>compressed</b> <b>video</b> content on the web.|$|E
50|$|By {{the early}} 1990s {{engineers}} {{were able to}} digitize and <b>compress</b> <b>video</b> signals, greatly improving storage efficiency. Because this new format could hold 83 minutes of audio and video, releasing movies on compact discs finally became a reality. Extra capacity was obtained by sacrificing the error correction (it was believed that minor errors in the datastream would go unnoticed by the viewer). This format was named Video CD or VCD.|$|R
40|$|Efficient motion {{estimation}} {{is very important}} for <b>compressing</b> <b>video</b> in standards like MPEG 1 / 2 / 4 and ITU-T H. 261 / 263. In this paper a new algorithm will be presented which can outperform most of the traditional fast {{motion estimation}} algorithms in both speed and quality. In addition, in some cases this algorithm can achieve even better visual quality, than the `optimal' but computational intensive `full search' algorithm...|$|R
40|$|This paper {{presents}} a suggested framework for video matching based on local features {{extracted from the}} DCimage of MPEG <b>compressed</b> <b>videos,</b> without decompression. The relevant arguments and supporting evidences are discussed for developing video similarity techniques that works directly on <b>compressed</b> <b>videos,</b> without decompression, and especially utilising small size images. Two experiments are carried to support the above. The first is comparing between the DC-image and I-frame, in terms of matching performance and the corresponding computation complexity. The second experiment compares between using local features and global features in video matching, especially in the compressed domain and with the small size images. The results confirmed {{that the use of}} DC-image, despite its highly reduced size, is promising as it produces at least similar (if not better) matching precision, compared to the full I-frame. Also, using SIFT, as a local feature, outperforms precision of most of the standard global features. On the other hand, its computation complexity is relatively higher, but it is still within the realtime margin. There are also various optimisations {{that can be done to}} improve this computation complexity...|$|R
