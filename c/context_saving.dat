13|77|Public
50|$|As it {{was stated}} in 'Threads Management' chapter, the {{firmware}} consists of pseudo-parallel threads. Each thread {{has its own}} context, that contains core registers of the processor, last execution address and private stack. During the switch between threads the system saves the context of stopped thread and recovers {{the context of the}} one being run. This state saving makes possible breaking the thread execution and further continuation, even if between them other thread has been executed. Note that preemption followed by context switch may happen in any moment, even if no system function is called in the thread. Although it may happen in unexpected location in the executed code, the thread work is not distorted due to the system and the <b>context</b> <b>saving.</b> From the thread point of view, the switch can be done in background.|$|E
30|$|After a {{preemption}} of {{the corresponding}} task, a context {{can be stored}} in more than one LCM in addition to the copy stored in the CCR. In such situation, care must be taken to ensure the consistency of the task execution. For that purpose, contexts are tagged by the CMU each time a <b>context</b> <b>saving</b> is performed with a version number. The operating system keeps track of this version number and also increments it each time a <b>context</b> <b>saving</b> is performed. In this way the system can then check for the validity of a context before a context restoration. The system must also try to update the context copy in the CCR as short as possible after a <b>context</b> <b>saving</b> is performed with a write-through policy.|$|E
30|$|In {{order to}} enable more choice on {{scheduling}} scheme, and to match some real time requirements, our FGDRA platform must also include preemption facilities. For {{the same reasons}} as configuration, the speed of <b>context</b> <b>saving</b> and restoring processes {{will be one of}} our primary concerns. On this particular point, previous work we have discussed in Section 2 will be adapted and reused.|$|E
25|$|In the <b>context</b> of <b>savings</b> and loans, the IRR is {{also called}} the {{effective}} interest rate.|$|R
40|$|In a way : Making new {{material}} from old stuff. In the sustainable development <b>context.</b> Resources <b>saving.</b> Energy saving (especially with in place recycling) While keeping {{at least the}} same global performances as {{new material}}s ones. Need for global analysis (technical, environmental and economical) on these materials...|$|R
40|$|Presents {{the main}} aspects of {{research}} carried {{out into the}} behaviour of conventional turbines reconverted to provide simultaneously heat and power supply. The problem is considered in the <b>context</b> of <b>saving</b> energy. The adopted approach is briefly described with the calculation methods related to each step. Two machines are fully studied and the limiting factors in the thermodynamical, aerodynamical and structural ranges are pointed out. Anglai...|$|R
3000|$|Case study {{considering}} several typical applications {{with different}} degrees of dynamicity revealed that this architecture permits to obtain a far better efficiency for task loading and execution <b>context</b> <b>saving</b> services than actual FPGA traditionally used as FGDRA in most recent studies. In the best case, task switching can be achieved in just one clock cycle. More realistic statistical analysis showed that for any basic dynamic case considered, the OLLAF platform always outperform commercially available solution by a factor around [...]...|$|E
30|$|The five first {{solution}} {{uses the}} ICAP interface as configuration transfer method. Using this method, transfers are made as configuration bitstream. A configuration bistream contains both a configuration and a context. In the same way, for the XIL solution that {{also use the}} ICAP interface for <b>context</b> <b>saving,</b> the readback bitsteam contains both a configuration and an context. In this case only context is useful. But we need to transfer both configuration and context and then to spend some extra time to extract the context.|$|E
40|$|Multitasking on an FPGA-based {{processor}} is {{one possibility}} {{to explore the}} efficacy of reconfigurable computing. Conventional computers and operating systems have demonstrated the many advantages of sharing computational hardware by several tasks over time. The ability to do run-time configuration and readback of FPGAs in a coprocessor architecture allows investigating the problems of implementing realistic multitasking. This paper explores the control software required to support task switching for an application split over the host processor [...] coprocessor boundary {{as well as the}} requirements and features of <b>context</b> <b>saving</b> and restoring in the FPGA coprocessor context. An FPGA coprocessor designed especially to support multitasking of such applications is described...|$|E
5000|$|In 2016, presidential {{candidate}} Donald Trump released {{a health care}} plan which used the term [...] "death penalty" [...] in the <b>context</b> of health <b>savings</b> accounts which would pass tax-free to the heirs of an estate.|$|R
40|$|International audienceIn {{a global}} <b>context</b> of <b>saving</b> {{energy and the}} desire to improve heat exchangers, the use of nanofluidstoday seems like a craze growing. Are nanofluids a solution?What are the {{limitations}} of the use of such fluids? This article proposes a review of thermo physicals coefficients of carbonnanotube-water nanofluids. This article reports on an experimental study completed to observe the impacts of the concentration, temperature, aspect ratio, and surfactant on the thermal conductivity and viscosity. Finally this article advocates a field for using nanofluid in heat exchangers...|$|R
40|$|In {{this paper}} we avail of new data {{in studies of}} {{financial}} capability conducted separately in the United Kingdom and Ireland to model the determinants of individuals’ attitudes to risk. These risk attitudes are explored explicitly in the <b>context</b> of <b>savings</b> and investments and are modelled {{on the basis of}} socio-economic characteristics such as age, gender, region of residence and educational attainment. Furthermore, we explore the relatively complex relationship between risk attitudes and proxies of individual’s wealth levels in the context of potential reverse causation. ...|$|R
30|$|In the figure, at {{the bottom}} of each column you cannotice two {{hardware}} blocks called CMU and HCM. The CMU is an IP able to manage automatically task's <b>context</b> <b>saving</b> and restoring. The HCM standing for Hardware Configuration Manager is pretty much the same but to handle configuration data is also called bitstream. More details about this controller can be found in [1]. On each column a local cache memory named LCM is added. This memory is a first level of cache memory to store contexts and configurations close to the column where it might most probably be required. The internal architecture of the core provides adequate materials to work with CMU and HCM. More about this will be discussed in the next section.|$|E
40|$|International audienceThis paper {{presents}} an efficient reconfigurable entropy encoder for real time adaptation of multi-standard compressed video stream. The proposed embedded architecture {{is based on}} partial and dynamic reconfiguration. Static and dynamic wrappers are defined to encapsulate different types of entropy coders with efficient swapping capabilities for <b>context</b> <b>saving</b> and restoring. The wrappers are designed to reduce the area overhead. A partitioning of reconfigurable area is also presented aiming at the optimization of reconfiguration overhead. The obtained results show a significant gain up to 40 % in silicon area compared to a solution without reconfiguration and a significant gain of 23 % in reconfiguration time. Thanks to reconfigurable entropy coder, {{it is possible to}} treat MPEG- 2 and H. 264 video streams meeting its real time constraints using dynamic reconfiguration...|$|E
40|$|Despite diverse {{trends in}} {{household}} saving in OECD countries, many governments are introducing tax incentives designed to boost saving by particular groups. Such schemes have been justified by many trends, including increasing income inequality, ageing populations, and greater cross-border competition. It is dangerous, however, to base policy {{on what is}} happening to aggregate household saving alone. First, personal saving should be viewed within a lifecycle <b>context.</b> <b>Saving</b> may look inadequate today, but households may already have made plans to redress this in future. Second, data on aggregate saving conceal significant differences between different household groups. Only disaggregation yields reliable inferences on which policy can be based. In particular, it is impossible to assess the consequences of demographic changes without analysis that distinguishes between different generations. " Copyright Centre for Economic Policy Research, Centre for Economic Studies, Maison des Sciences de l'Homme 1997. ...|$|E
40|$|A high saving rate is the {{foundation}} of a sustainable national social and economic policy. Nevertheless, boosting saving is not an end in itself. The process of making savings should be analysed taking into account several related aspects. This paper aims at conducting a detailed and comprehensive analysis of saving behaviour in Latvia and its estimation in the global <b>context.</b> Household <b>saving</b> behaviour and saving habits are in a particular focus and are examined econometrically using a unique source of Latvia's micro data, i. e. household budget surveys. savings, household saving habits, micro data, cross-section model...|$|R
40|$|The {{increased}} recent {{attention to}} the customer confusion phenomenon, {{in order to examine}} its detrimental effects on consumers as well as the organisations instigating it, has motivated researchers to investigate its incidence in a number of industries and markets. This paper explores the customer confusion concept in the <b>context</b> of <b>savings</b> and investments in the UK financial services sector. A review of conceptual theories and secondary sources in the financial services facilitated the formation of an interview approach guide in order to investigate confusion among 10 UK savers and investors. The findings, conclusions and implications have been presented...|$|R
40|$|International audienceContext-aware {{computing}} has to {{deal with}} a huge amount of context data. Taking into account the quality of these data becomes a corner stone of an efficient context management solution. Information on the quality of context helps taking appropriate decisions and allows to identify uncertain <b>context</b> information <b>saving</b> processing time for deriving a pertinent description of the observed phenomenon. This paper presents a work in progress for integrating Quality of Context in COSMOS (COntext entitieS coMpositiOn and Sharing) [4, 13], a component-based framework for managing context data in ubiquitous environments, and illustrates it throughout the example of the composition of context information to implement a network connectivity vs energy adaptation situatio...|$|R
40|$|Partial {{reconfiguration}} (PR) is an FPGA {{feature that}} allows the modification of certain parts of an FPGA {{while the rest of}} the system continues to operate without disruption. This distinctive characteristic of FPGAs has many potential benefits but also challenges. The lack of good CAD tools and the deep hardware knowledge requirement result in a hard-to-use feature. In this paper, the new partition-based Xilinx PR flow is used to incorporate PR within our MPI-based message-passing framework to allow hardware designers to create template bitstreams, which are predesigned, prerouted, generic bitstreams that can be reused for multiple applications. As an example of the generality of this approach, four different applications that use the same template bitstream are run consecutively, with a PR operation performed at the beginning of each application to instantiate the desired application engine. We demonstrate a simplified, reusable, high-level, and portable PR interface for X 86 -FPGA hybrid machines. PR issues such as local resets of reconfigurable modules and <b>context</b> <b>saving</b> and restoring are addressed in this paper followed by some examples and preliminary PR overhead measurements...|$|E
40|$|A {{distributed}} system {{is composed of}} multiple independent machines that communicate using messages. Faults in a large {{distributed system}} are common events. Without fault tolerance mechanisms, an application running on a system has to be restarted from scratch if a fault happens {{in the middle of}} its execution, resulting in loss of useful computation. Checkpoint and Recovery mechanisms are used in distributed systems to provide fault tolerance for such applications. A checkpoint of a process is the information about the state of a process at some instant of time. A checkpoint of a distributed application is a set of checkpoints, one from each of its processes, satisfying certain constraints. If a fault occurs, the application is started from an earlier checkpoint instead of being restarted from scratch to save some of the computation. Several checkpoint and recovery protocols have been proposed in the literature. The performance of a checkpoint and recovery protocol depends upon the amount of computation it can save against the amount of overhead it incurs. Checkpointing protocols should not add much overhead to the system. Checkpoiniting overhead is mainly due to the coordination among processes and their <b>context</b> <b>saving</b> in stable storage. In coordination checkpointing, for taking single checkpoint, it will coordinate with other processes. Checkpoint initiating process coordinates with other processes through messages. If more number of messages are used for coordination then it increases the network tra±c. Which is not desirable. It is better {{to reduce the number of}} messages that are needed for checkpoint coordination. In this thesis, we present an algorithm which reduces the number of messages per process, that are needed for checkpoint Coordination and there by decreasing the network tra±c. The total running time of an application is depend on the execution time of the application and the amount of checkpointing overhead that incurs with the application. We should minimize this checkpointing overhead. Checkpointing overhead is the combination of <b>context</b> <b>saving</b> overhead and coordination overhead. Storing the context of application over stable storage also increases the overhead. In periodic interval checkpointing, sometimes processes takes checkpoints though it is not much useful. These unnecessary checkpoints increase the application's running time. We have proposed an algorithm which determines checkpointing interval dynamically, based on expected recovery time, to avoid unnecessary checkpoints. By eliminating unnecessary checkpoints, we can reduce running time of a process signi¯cantly...|$|E
40|$|Checkpoint {{is defined}} as a {{designated}} place in a program at which normal processing is interrupted specifically to preserve the status information necessary to allow resumption of processing at a later time. Checkpointing is the process of saving the status information. This paper surveys the algorithms which {{have been reported in the}} literature for checkpointing parallel=distributed systems. It has been observed that most of the algorithms published for checkpointing in message passing systems are based on the seminal article by Chandy and Lamport. A large number of articles have been published in this area by relaxing the assumptions made in this paper and by extending it to minimise the overheads of coordination and <b>context</b> <b>saving.</b> Checkpointing for shared memory systems primarily extend cache coherence protocols to maintain a consistent memory. All of them assume that the main memory is safe for storing the context. Recently algorithms have been published for distributed shared memory systems, which extend the cache coherence protocols used in shared memory systems. They however also include methods for storing the status of distributed memory in stable storage. Most of the algorithms assume that there is no knowledge about the programs being executed. It is however felt that in development of parallel programs the user has to do a fair amount of work in distributing tasks and this information can be effectively used to simplify checkpointing and rollback recover...|$|E
40|$|Abstract. Context-aware {{computing}} has to {{deal with}} a huge amount of context data. Taking into account the quality of these data becomes a corner stone of an efficient context management solution. Information on the quality of context helps taking appropriate decisions and allows to identify uncertain <b>context</b> information <b>saving</b> processing time for de-riving a pertinent description of the observed phenomenon. This paper presents a work in progress for integrating Quality of Con-text in COSMOS (COntext entitieS coMpositiOn and Sharing) [4, 13], a component-based framework for managing context data in ubiquitous environments, and illustrates it throughout the example of the composi-tion of context information to implement a network connectivity vs energy adaptation situation. Key words: context-aware computing, quality of context, component-based middleware. ...|$|R
40|$|Population ageing raises {{questions}} about the sustainability of the public pillars of the retirement income system and about inter-generational equity. In response to this, a number of countries have raised the normal retirement age in an attempt to reduce projected future expenditures on their state pension system. In this <b>context,</b> private <b>savings</b> and later retirement represent the best ways of avoiding a major fall in living standards when retiring. Increased life expectancy at age 65 appears to justify this policy trend. But there are substantial differences in life expectancy and healthy life expectancy between people of different socioeconomic status, and these seem to be widening. There is a danger that in the name of inter-generational equity, we will in fact be moving towards increased social inequality among the pensioners of the future...|$|R
40|$|This study brings {{together}} both consumer behaviour and economic psychology literature to gain insights {{and understanding of}} the consumer decision-making process in the <b>context</b> of <b>saving</b> for retirement. Three research questions concerning the reasons that consumers delay saving for retirement; use a financial planner; and save but do not use a financial planner, directed the research. A factor analysis of 194 usable questionnaires led to a typology of 10 components divided between three groups correlating directly with the research questions. A key component that emerged in the factor analysis is the role of risk in delaying decision-making when financially planning for retirement. This exploratory research suggests that there are at least 11 factors associated with pre-purchase decision-making that cause consumers to delay decision-making or to take action with regard to saving for retirement. 7 page(s...|$|R
40|$|Checkpointing is a {{technique}} widely used in parallel/distributed computers for rollback error recovery. Checkpointing {{is defined as the}} coordinated saving of process state information at specified time instances. Checkpoints help in restoring the computation from the latest saved state, in case of failure. In addition to fault recovery, checkpointing has applications in fault detection, distributed debugging and process migration. Checkpointing in uniprocessor systems is easy {{due to the fact that}} there is a single clock and events occur with respect to this clock. There is a clear demarcation of events that happens before a checkpoint and events that happens after a checkpoint. In parallel computers a large number of computers coordinate to solve a single problem. Since there might be multiple streams of execution, checkpoints have to be introduced along all these streams simultaneously. Absence of a global clock necessitates explicit coordination to obtain a consistent global state. Events occurring in a distributed system, can be ordered partially using Lamport's happens before relation. Lamport's happens before relation ->is a partial ordering relation to identify dependent and concurrent events occurring in a distributed system. It is defined as follows: ·If two events a and b happen in the same process, and if a happens before b, then a->b ·If a is the sending event of a message and b is the receiving event of the same message then a -> b ·If neither a à b nor b -> a, then a and b are said to be concurrent. A consistent global state may have concurrent checkpoints. In the first chapter of the thesis we discuss issues regarding ordering of events in a parallel computer, need for coordination among checkpoints and other aspects related to checkpointing. Checkpointing locations can either be identified statically or dynamically. The static approach assumes that a representation of a program to be checkpointed is available with information that enables a programmer to specify the places where checkpoints are to be taken. The dynamic approach identifies the checkpointing locations at run time. In this thesis, we have proposed algorithms for both static and dynamic checkpointing. The main contributions of this thesis are as follows: 1. Parallel computers that are being built now have faster communication and hence more efficient clock synchronisation compared to those built a few years ago. Based on efficient clock synchronisation protocols, the clock drift in current machines can be maintained within a few microseconds. We have proposed a dynamic checkpointing algorithm for parallel computers assuming bounded clock drifts. 2. The shared memory paradigm is convenient for programming while message passing paradigm is easy to scale. Distributed Shared Memory (DSM) systems combine the advantage of both paradigms and can be visualized easily on top of a network of workstations. IEEE has recently proposed an interconnect standard called Scalable Coherent Interface (SCI), to con 6 gure computers as a Distributed Shared Memory system. A periodic dynamic checkpointing algorithm has been proposed in the thesis for a DSM system which uses the SCI standard. 3. When information about a parallel program is available one can make use of this knowledge to perform efficient checkpointing. A static checkpointing approach based on task graphs is proposed for parallel programs. The proposed task graph based static checkpointing approach has been implemented on a Parallel Virtual Machine (PVM) platform. We now give a gist of various chapters of the thesis. Chapter 2 of the thesis gives a classification of existing checkpointing algorithms. The chapter surveys algorithm that have been reported in literature for checkpointing parallel/distributed systems. A point to be noted is that most of the algorithms published for checkpointing message passing systems are based on the seminal article by Chandy & Lamport. A large number of checkpointing algorithms have been published by relaxing the assumptions made in the above mentioned article and by extending the features to minimise the overheads of coordination and <b>context</b> <b>saving.</b> Checkpointing for shared memory systems primarily extend cache coherence protocols to maintain a consistent memory. All of them assume that the main memory is safe for storing the context. Recently algorithms have been published for distributed shared memory systems, which extend the cache coherence protocols used in shared memory systems. They however also include methods for storing the status of distributed memory in stable storage. Chapter 2 concludes with brief comments on the desirable features of a checkpointing algorithm. In Chapter 3, we develop a dynamic checkpointing algorithm for message passing systems assuming that the clock drift of processors in the system is bounded. Efficient clock synchronisation protocols have been implemented on recent parallel computers owing to the fact that communication between processors is very fast. Based on efficient clock synchronisation protocols, clock skew can be limited to a few microseconds. The algorithm proposed in the thesis uses clocks for checkpoint coordination and vector counts for identifying messages to be logged. The algorithm is a periodic, distributed algorithm. We prove correctness of the algorithm and compare it with similar clock based algorithms. Distributed Shared Memory (DSM) systems provide the benefit of ease of programming in a scalable system. The recently proposed IEEE Scalable Coherent Interface (SCI) standard, facilitates the construction of scalable coherent systems. In Chapter 4 we discuss a checkpointing algorithm for an SCI based DSM system. SCI maintains cache coherence in hardware using a distributed cache directory which scales with the number of processors in the system. SCI recommends a two phase transaction protocol for communication. Our algorithm is a two phase centralised coordinated algorithm. Phase one initiates checkpoints and the checkpointing activity is completed in phase two. The correctness of the algorithm is established theoretically. The chapter concludes with the discussion of the features of SCI exploited by the checkpointing algorithm proposed in the thesis. In Chapter 5, a static checkpointing algorithm is developed assuming that the program to be executed on a parallel computer is given as a directed acyclic task graph. We assume that the estimates of the time to execute each task in the task graph is given. Given the timing at which checkpoints are to be taken, the algorithm identifies a set of edges where checkpointing tasks can be placed ensuring that they form a consistent global checkpoint. The proposed algorithm eliminates coordination overhead at run time. It significantly reduces the <b>context</b> <b>saving</b> overhead by taking checkpoints along edges of the task graph. The algorithm is used as a preprocessing step before scheduling the tasks to processors. The algorithm complexity is O(km) where m is the number of edges in the graph and k the maximum number of global checkpoints to be taken. The static algorithm is implemented on a parallel computer with a PVM environment as it is widely available and portable. The task graph of a program can be constructed manually or through program development tools. Our implementation is a collection of preprocessing and run time routines. The preprocessing routines operate on the task graph information to generate a set of edges to be checkpointed for each global checkpoint and write the information on disk. The run time routines save the context along the marked edges. In case of recovery, the recovery algorithms read the information from stable storage and reconstruct the context. The limitation of our static checkpointing algorithm is that it can operate only on deterministic task graphs. To demonstrate the practical feasibility of the proposed approach, case studies of checkpointing some parallel programs are included in the thesis. We conclude the thesis with a summary of proposed algorithms and possible directions to continue research in the area of checkpointing...|$|E
40|$|People {{systematically}} underestimate exponential growth. This article {{illustrates this}} phenomenon, its implications, and some potential inter-ventions in the <b>context</b> of <b>saving</b> for retirement, where savings grow exponentially {{over long periods}} of time. Experiment 1 shows that a majority of participants expect savings over 40 years to grow linearly rather than exponentially, leading them to grossly underestimate their account balance at retirement. Experiment 2 demonstrates that this mis-understanding leads to underestimates of the cost of waiting to save, which makes putting off saving more attractive than it should be. Finally, Experiments 3 – 5 show that highlighting the exponential growth of sav-ings motivates both college students and employees to save more for retirement. Making clear to employees the exponential growth of savings before they make crucial decisions about how much to save may be a simple and effective means of increasing retirement savings...|$|R
50|$|Despite their {{remarkable}} {{performance in}} the Basque and Spanish <b>context,</b> the Basque <b>savings</b> banks have got directly entangled in the general measures exacted by the Spanish Government on banking. The 2013 governmental decisions, reportedly meant to target bankrupt and mismanaged financial institutions, made no operative distinctions between healthy or corrupt banks. The central government's measures also point to additional political implications in that they may overrule existing Basque attributions and powers on banking and foundations, as {{set out on the}} Basque Statute of Autonomy.|$|R
40|$|Saving {{energy at}} work might be {{considered}} altruistic, because often no personal benefits accrue. However, we {{consider the possibility that}} it can be a form of impure-altruism in that the individual experiences some rewards. We develop a scale to measure motivations to save energy at work and test its predictive power for energy-saving intentions and sustainable choices. In two studies (N = 293 and N = 94) motivations towards helping their organization and the planet were rated as important motivations, as was warm-glow (feeling good), indicating that impure-altruism does exist in this <b>context.</b> Energy <b>saving</b> was predicted by environmental concern and the desire to help one's organization. Notably, the stronger the motivations to promote one's reputation were, the weaker was the intention to save energy. Promoting motivations, particularly those that focus on benefits to the organization, may be an effective addition to environmental messages typically used as motivations in campaigns...|$|R
40|$|AbstractIn {{this paper}} we discuss multiperiod {{portfolio}} selection problems related to a specific provisioning problem. Our results are an extension of Dhaene et al. (2005)  [14], where optimal constant mix investment strategies are obtained in a provisioning and <b>savings</b> <b>context,</b> using an analytical approach based {{on the concept of}} comonotonicity. We derive convex bounds {{that can be used to}} estimate the provision to be set up at a specified time in future, to ensure that, after having paid all liabilities up to that moment, all liabilities from that moment on can be fulfilled, with a high probability...|$|R
40|$|The {{ability to}} operate factory {{buildings}} as free running {{will be very}} useful in the <b>context</b> of <b>saving</b> energy needed for providing adequate thermal comfort for workers in warm humid tropical climatic conditions. The upper limits of thermally comfortable temperatures were established with comfort surveys carried out in three factory buildings without much ventilation. The surveys were then repeated {{to determine the effects}} of ventilation as well. The comfort surveys indicated that workers acclimatized to warm humid climatic condition could tolerate up to 30 1 C without much ventilation when engaged in light factory work. This comfort temperature limit can be increased up to 34 1 C when indoor air velocities are maintained as high as 0. 6 ms 1. It is also shown that these studies validate the earlier predictions of adaptive models for warm humid climates. The ability of workers to tolerate elevated temperatures could be used to highlight some concepts that can be considered in the planning of large-scale industrial parks, so that factories could be operated with minimum energy allocated for providing thermal comfor...|$|R
5000|$|A kernel thread is a [...] "lightweight" [...] unit of kernel scheduling. At {{least one}} kernel thread exists within each process. If {{multiple}} kernel threads exist within a process, then {{they share the}} same memory and file resources. Kernel threads are preemptively multitasked if the operating system's process scheduler is preemptive. Kernel threads do not own resources except for a stack, {{a copy of the}} registers including the program counter, and thread-local storage (if any), and are thus relatively cheap to create and destroy. Thread switching is also relatively cheap: it requires a <b>context</b> switch (<b>saving</b> and restoring registers and stack pointer), but does not change virtual memory and is thus cache-friendly (leaving TLB valid). The kernel can assign one thread to each logical core in a system (because each processor splits itself up into multiple logical cores if it supports multithreading, or only supports one logical core per physical core if it does not), and can swap out threads that get blocked. However, kernel threads take much longer than user threads to be swapped.|$|R
40|$|People {{can choose}} {{and they make}} many choices each and every day. However, most people are unaware of how strong their {{environment}} influences the choices they make. In his inaugural address, Bas Donkers highlights the impact of what people see (and what they don’t see), what people experience (and what they don’t experience), or more general, the impact of salient decision characteristics. Evidence will be provided {{in a number of}} applications that range from online consumer search behavior to physician prescription behavior. The lessons to be learned from this for marketers and policymakers are highlighted in the <b>context</b> of pension <b>savings</b> decisions and health state valuations...|$|R
30|$|A {{number of}} server/broker-based context {{provisioning}} {{systems have been}} developed, e.g. CoBrA [2], SOCAM [3], JCAF [4], PACE [5], and MobiLife [6] but caching contextual information has not been targeted in these systems explicitly. The MobiLife architecture specifies context caching at the context provider component but this approach creates distributed context caches at each <b>context</b> provider, potentially <b>saving</b> computational load at the providers but not reducing the communication cost. The query from the context consumer has to traverse the complete round trip from the context provider via the context broker. This mechanism can be improved by building a collective cache based on the smaller caches at context provider level.|$|R
40|$|We {{conduct a}} field {{experiment}} designed to test theories of time-inconsistency, namely a "Beta-Delta" model of present bias. The experiment {{takes place in}} the <b>context</b> of a <b>saving</b> decision made by low-income tax filers who can deposit their income tax refund into an illiquid account. We find qualitative evidence consistent with present-biased preferences. The tradeoff between an earlier payment or a later one is much more skewed toward taking the early payment when the decision is made on the spot than when the decision is made in advance. We estimate a β and δ of 0. 34 and 1. 08 over an 8 -month horizon, respectively, which translates into an annual discount rate of 164 %...|$|R
40|$|Abstract: The {{capability}} to safely interrupt business process activities {{is an important}} requirement for advanced process-aware information systems. Indeed, exceptions stemming from the application environment often appear while one or more application-related process activities are running. Safely interrupting an activity consists of preserving its <b>context,</b> i. e., <b>saving</b> the data associated with this activity. This is important since possible solutions for an exceptional situation are often based on the current data context of the interrupted activity. In this paper, a data classication scheme based on data relevance and on data update frequency is proposed and discussed with respect to two different real-world applications. Taking into account this classication, a correctness criterion for interrupting running activities while preserving their context is proposed and analyzed. ...|$|R
40|$|Expensive {{internet}} facilities require prudent in its {{use both}} {{as a source of}} information and communication media. This paper discusses observations of the perceived burden of network bandwidth when accessing some of the mail server using a webmail application. Mail server in question consists of three commercial server and 2 non-commercial server. Data when it download home page, while logged in, open the email, and during idle logout recorded with sniffer Wireshark. Observations in various situations and scenarios indicate that access Yahoo email gives the network load is very high while the SquirrelMail gives the network load is very low than 5 other mail servers. For an institution, use a local mail server (institutional) is highly recommended in the <b>context</b> of banddwidth <b>savings...</b>|$|R
