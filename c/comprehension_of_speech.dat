61|10000|Public
25|$|Conduction aphasia {{is another}} speech {{disorder}} {{that is similar}} to, but not the same as, apraxia of speech. Although {{patients who suffer from}} conduction aphasia have full <b>comprehension</b> <b>of</b> <b>speech,</b> as do AOS sufferers, there are differences between the two disorders. Patients with conduction aphasia are typically able to speak fluently, but {{they do not have the}} ability to repeat what they hear.|$|E
2500|$|Recent {{classification}} schemes adopting this approach, {{such as the}} [...] "Boston-Neoclassical Model", also group these classical aphasia subtypes {{into two}} larger classes: the nonfluent aphasias (which encompasses Broca's aphasia and transcortical motor aphasia) and the fluent aphasias (which encompasses Wernicke's aphasia, conduction aphasia and transcortical sensory aphasia). These schemes also identify several further aphasia subtypes, including: anomic aphasia, which {{is characterized by a}} selective difficulty finding the names for things; and global aphasia, where both expression and <b>comprehension</b> <b>of</b> <b>speech</b> are severely compromised.|$|E
5000|$|... aphasia (a {{language}} disorder {{in which there}} is an impairment of speech and of <b>comprehension</b> <b>of</b> <b>speech,</b> caused by brain damage) ...|$|E
40|$|This {{dissertation}} examines training {{methodology for}} improving native English speakers’ <b>comprehension</b> <b>of</b> foreign-accented <b>speech.</b> The training tasks, imitating and paraphrasing accented speech, were developed out of theoretical considerations about bottom-up and top-down processes in speech perception. Paraphrasing speech encourages {{a focus on}} the meaning and leads to practice of top-down processing, whereas imitating speech promotes attention to the accented pronunciation and allows practice of bottom-up processing. Additionally, the tasks support active, implicit learning. Results show an improvement in the <b>comprehension</b> <b>of</b> accented <b>speech</b> after about an hour of training. The imitation task primarily improves understanding of relatively short, decontextualized utterances with few semantic and syntactic cues, which suggests that attention to accented pronunciation helps with perception of discrete segments <b>of</b> <b>speech.</b> In contrast, the paraphrase task tends to improve perception <b>of</b> longer <b>speech</b> samples, implying that attention to meaning may be more beneficial for <b>comprehension</b> <b>of</b> conversational <b>speech.</b> There is evidence that training is durable and transferable, but the exact nature of its durability and transferability needs to be explored in future experiments...|$|R
40|$|We report two {{experiments}} {{investigating the}} <b>comprehension</b> <b>of</b> speeded <b>speech.</b> In the first experiment it is shown that acceleration <b>of</b> <b>speech</b> {{has no effect}} on the <b>comprehension</b> <b>of</b> text spoken by a male speaker but causes substantial reduction in the <b>comprehension</b> <b>of</b> a female voice. The second experiment shows that the <b>comprehension</b> <b>of</b> the female voice at high speed can be significantly improved if the speech is processed through a commercially available compression device...|$|R
40|$|Objective: The effects <b>of</b> {{estrogen}} on <b>comprehension</b> <b>of</b> metaphoric <b>speech,</b> word fluency, {{and verbal}} ability were investigated in women suffering from schizophrenia. The issue of estrogen-dependent neuropsychological perfor-mance could be highly relevant because women with schizo-phrenia frequently suffer from hypoestrogenism. Method: A placebo-controlled, double-blind, crossover study using 17 b-estradiol for replacement therapy {{and as an}} adjunct to a naturalistic maintenance antipsychotic treatment was carried out over a period of 8 months. Nineteen women (mean age 5 38. 0 years, SD 5 9. 9 years) with schizophre-nia were included in the study. <b>Comprehension</b> <b>of</b> meta-phoric <b>speech</b> was measured by a lexical decision paradigm, word fluency, and verbal ability by a paper-and-pencil test. Results: Significant improvement wa...|$|R
50|$|Intonation {{is said to}} have {{a number}} of {{perceptually}} significant functions in English and other languages, contributing to the recognition and <b>comprehension</b> <b>of</b> <b>speech.</b>|$|E
5000|$|Auditory verbal agnosia - <b>Comprehension</b> <b>of</b> <b>speech</b> is lost but hearing, speaking, reading, {{and writing}} ability is retained. This {{is caused by}} damage to the {{posterior}} superior temporal lobes, again not allowing the brain to process auditory input correctly.|$|E
50|$|Conduction aphasia {{is another}} speech {{disorder}} {{that is similar}} to, but not the same as, apraxia of speech. Although {{patients who suffer from}} conduction aphasia have full <b>comprehension</b> <b>of</b> <b>speech,</b> as do AOS sufferers, there are differences between the two disorders. Patients with conduction aphasia are typically able to speak fluently, but {{they do not have the}} ability to repeat what they hear.|$|E
5000|$|Other {{topics that}} Fox Tree has {{researched}} {{include the use}} of expressions such as ‘you know’ and ‘I mean’, the effects of false starts and repetitions in the <b>comprehension</b> <b>of</b> spontaneous <b>speech,</b> the use <b>of</b> prosody in syntactic disambiguation, the interpretation of pauses in spontaneous speaking, and the recognition of verbal irony in spontaneous speech.|$|R
40|$|In {{speech signal}} {{extraction}} {{the aim is}} to extract human speech in a physical environment by using microphones. In any real world environment there are many disturbance sources that cause unwanted sound pressure, which in turn may degrade the <b>comprehension</b> <b>of</b> the <b>speech</b> at the microphones. This licentiate thesis deals with the solution to this problem. Different approaches are proposed to solve the problem for many accounted scenarios in real life...|$|R
40|$|Objective: The effects <b>of</b> {{estrogen}} on <b>comprehension</b> <b>of</b> metaphoric <b>speech,</b> word fluency, {{and verbal}} ability were investigated in women suffering from schizophrenia. The issue of estrogen-dependent neuropsychological performance could be highly relevant because women with schizophrenia frequently suffer from hypoestrogenism. Method: A placebo-controlled, double-blind, crossover study using 17 β-estradiol for replacement therapy {{and as an}} adjunct to a naturalistic maintenance antipsychotic treatment was carried out over a period of 8 months. Nineteen women (mean age = 38. 0 years, SD = 9. 9 years) with schizophrenia were included in the study. <b>Comprehension</b> <b>of</b> metaphoric <b>speech</b> was measured by a lexical decision paradigm, word fluency, and verbal ability by a paper-and-pencil test. Results: Significant improvement was seen for the activation of metaphoric meaning during estrogen treatment (P =. 013); in contrast, no difference was found for the activation of concrete meaning under this condition. Verbal ability and word fluency did not improve under estrogen replacement therapy either. Conclusions: This is the very first study based on estrogen intervention instead of the physiological hormone changes to examine the estrogen effects on neuropsychological performance in women with schizophrenia. In addition, {{it is the first time}} that the effect of estrogen on metaphoric speech comprehension was investigated in this context. While in a previous study estrogen therapy as adjunct to a naturalistic maintenance treatment with antipsychotics did not show an effect on psychopathology measured by a rating scale, a significant effect of estrogen on the <b>comprehension</b> <b>of</b> metaphoric <b>speech</b> and/or concretism, a main feature of schizophrenic thought and language disturbance, was found in the present study. Because the improvement of formal thought disorders and language disturbances is crucial for social integration of patients with schizophrenia, the results may have implications for the treatment of these individuals...|$|R
50|$|Much of Nusbaum's {{research}} {{is on the}} mechanisms of speech perception and production but recent studies have also examined the development of concepts, emotional processing, and social interaction. Notably, Nusbaum has examined the role of sleep in consolidating perceptual learning of speech sounds, the cortical mechanisms that mediate perception of audio-visual speech, the role of gesture in production and <b>comprehension</b> <b>of</b> <b>speech,</b> and how listeners adjust to differences among talkers.|$|E
5000|$|Recent {{classification}} schemes adopting this approach, {{such as the}} [...] "Boston-Neoclassical Model", also group these classical aphasia subtypes {{into two}} larger classes: the nonfluent aphasias (which encompasses Broca's aphasia and transcortical motor aphasia) and the fluent aphasias (which encompasses Wernicke's aphasia, conduction aphasia and transcortical sensory aphasia). These schemes also identify several further aphasia subtypes, including: anomic aphasia, which {{is characterized by a}} selective difficulty finding the names for things; and global aphasia, where both expression and <b>comprehension</b> <b>of</b> <b>speech</b> are severely compromised.|$|E
5000|$|As with {{agreement}} in morphology, phonologically conditioned alternation, such as coarticulation and assimilation add redundancy on the phonological level. The redundancy of phonological rules may clarify some vagueness in spoken communication. According to psychologist Steven Pinker, [...] "In the <b>comprehension</b> <b>of</b> <b>speech,</b> the redundancy conferred by phonological rules can compensate {{for some of}} the ambiguity of the sound wave. For example, a speaker may know that thisrip must be this rip and not the srip because in English the initial consonant cluster sr is illegal." ...|$|E
50|$|Other {{studies have}} {{determined}} {{that the ability to}} comprehend highly time-compressed speech tends to fall off with increased age, and is also reduced when the language <b>of</b> the time-compressed <b>speech</b> is not the listener's native language. Non-native speakers can, however, improve their <b>comprehension</b> level <b>of</b> time-compressed <b>speech</b> with multiday training.|$|R
30|$|Why did {{students}} learn less {{when the teacher}} gestured to the equations? This finding {{flies in the face}} of abundant past research demonstrating that gesture contributes to <b>comprehension</b> <b>of</b> the accompanying <b>speech</b> (see Hostetter, 2011), and that teachers’ gestures are beneficial for students’ learning (e.g., Church et al., 2004; Cook et al., 2013).|$|R
40|$|We {{report in}} this paper {{the results of a}} series <b>of</b> <b>comprehension</b> tests run with the aim of {{investigating}} the contribution of visual information to the process <b>of</b> <b>comprehension</b> <b>of</b> conversational <b>speech.</b> The methodology we designed was presented in a previous work [1] in which we also showed the results of a pilot test to confirm our original hypothesis that the <b>comprehension</b> <b>of</b> conversational <b>speech</b> decreases passing from bimodal transmission to uni-modal transmission. In order to further investigate the contribution of visual information to the process <b>of</b> <b>speech</b> <b>comprehension,</b> we run a new series <b>of</b> <b>comprehension</b> tests, that consisted of the following three phases: 1. submission <b>of</b> the multi-modal <b>speech</b> signal (auditory + visual); 2. submission of the sample only in the auditory modality (i. e. without the integration of visual cues); 3. submission of the sample only in the visual modality (without the integration of auditory cues). We used as sample material a short conversation held by two male speakers, edited from an Italian TV soap opera. We tested 3 groups of 12 people with no sight and hearing pathologies and also a smaller group of 5 congenitally deaf people, that served as a kind of “control ” group in the third phase. It is clear from our results that the visual cues help the subjects to understand the main topic of conversation and to remember some of the details of the conversation. Moreover they seem {{to play an important role}} for the interpretation of the emotional state of the speakers. In some cases visual cues appear to be misleading. 1...|$|R
50|$|In a study {{conducted}} by Masaaki Nagafuchi et al. (1993), a 7-year-old girl began taking a dose of 2 mg diazepam orally every day. She demonstrated major improvements in behavior and <b>comprehension</b> <b>of</b> <b>speech</b> while under diazepam therapy. Within a month, conversation problems were eliminated. After a year of therapy, her repetition ability was almost normal. After two years, her ability to discriminate monosyllabic words was within the normal range. Her audiological recognition had remained normal from the time of onset (i.e., she could recognize familiar noises such as a baby crying or a telephone ringing).|$|E
5000|$|Two {{areas of}} the brain, Broca’s area and Wernicke’s area, are {{responsible}} for various disruptions in speech when damaged. Each is defined by their distinct characteristics. Broca’s aphasia is characterized by non-fluent or telegraphic-type speech - where articles, conjunctions, prepositions, auxiliary verbs, pronouns and morphological inflections (plurals, past tense) are omitted. [...] The word substitutions are infrequent and distortion of consonants and simplification of consonant clusters is frequent. Content words such as nouns, verbs and adjectives may be preserved. Subjects of this aphasia are aware of their errors in speech. Damage to the Broca’s area does not affect <b>comprehension</b> <b>of</b> <b>speech.</b>|$|E
5000|$|Anosognosia {{may occur}} {{as part of}} {{receptive}} aphasia, a language disorder that causes poor <b>comprehension</b> <b>of</b> <b>speech</b> {{and the production of}} fluent but incomprehensible sentences. A patient with receptive aphasia cannot correct his own phonetics errors and shows [...] "anger and disappointment with the person with whom s/he is speaking because that person fails to understand her/him". This may be a result of brain damage to the posterior portion of the superior temporal gyrus, believed to contain representations of word sounds. With those representations significantly distorted, patients with receptive aphasia are unable to monitor their mistakes. Other patients with receptive aphasia are fully aware of their condition and speech inhibitions, but cannot monitor their condition, which {{is not the same as}} anosognosia and therefore cannot explain the occurrence of neologistic jargon.|$|E
40|$|Hughlings Jackson noted that, {{although}} some aphasic patients {{were unable to}} use propositional speech, affective speech appeared to be spared. The purpose of this experiment was to study patients with unilateral hemispheric disease in order to ascertain if there are hemispheric asymmetries in the <b>comprehension</b> <b>of</b> affective <b>speech.</b> Six subjects had right temporoparietal lesions (left unilateral neglect) and six subjects had left temporoparietal lesions (fluent aphasias). These subjects were presented with 32 tape recorded sentences. In 16 trials the patients were asked to judge the emotional mood of the speaker (happy, sad, angry, indifferent) and in 16 trials the patients were asked to judge the content. Line drawings containing facial expressions of the four emotions or line drawings corresponding with the four basic contents were displayed with each sentence and the patient responded by pointing. All 12 subjects made perfect scores on the content portion of the test. On the emotional portion the right hemispheric patients scored a mean of 4 - 17 and the left hemispheric group scored a mean 10 - 17. The difference between these means is significantly (P less than 0 - 01) and suggests that patients with right hemispheric dysfunction and neglect have a defect in the <b>comprehension</b> <b>of</b> affective <b>speech...</b>|$|R
40|$|This study {{investigates the}} <b>comprehension</b> <b>of</b> {{indirect}} request <b>speech</b> act used by Iranian people in daily communication. The study {{is an attempt}} to find out whether different cultural backgrounds and the gender of the speakers affect the <b>comprehension</b> <b>of</b> the indirect request <b>of</b> <b>speech</b> act. The sample includes thirty males and females in Gachsaran(a city in the province of Kohgiloye va Boyerahmad in Iran) and thirty participants (males and females) in Farokhshahr(a city in the province of Chaharmahal va Bakhtiyari in Iran). A questionnaire is used to elicit data related to the responses used by each group. The questionnaire consists of twenty situations. The participants write their reaction to each situation. The results reveal that culture has significant effect on the interpretation of indirect request <b>of</b> <b>speech</b> act. But gender doesn’t affect the <b>comprehension</b> <b>of</b> indirect request <b>of</b> <b>speech</b> act. </p...|$|R
40|$|This paper {{describes}} two empirical experiments {{investigating the}} perception of embedded audible hyperlinks, designed using speech and non-speech cues, and their effect on the <b>comprehension</b> <b>of</b> synthetic <b>speech.</b> Results from the first experiment showed high accuracy levels of hyperlink perception and differences in comprehension performance between sentences with hyperlinks and sentences without hyperlinks. Results from the second experiment also showed high accuracy levels of hyperlink perception as well as differences in comprehension performance between two hyperlink designs using different configurations <b>of</b> <b>speech</b> and non-speech cues. The results demonstrate that speech and non-speech cues may be effective {{in the design of}} audible hyperlinks however their presence within synthetic sentences may reduce overall comprehensibility. Results also demonstrate that different configurations <b>of</b> <b>speech</b> and non-speech cues used to represent audible hyperlinks effect comprehension processes. 1...|$|R
50|$|There is {{evidence}} supporting both the mass action principle and functional specialization within the brain. Functional specialization {{is the idea}} that functions are localized within the brain and can only be carried out by particular area(s) of the brain. Some tasks appear to work on the mass action principle, with lesions causing less drastic effects than would be expected if the tasks were localized within the brain. This was shown in Lashley's rat maze experiments, in which the amount of tissue removed was more important to the rat's performance than where the tissue was removed from within the brain. There are, however, examples of highly specialized areas of the brain in which even small amounts of damage can cause dramatic effects on people's abilities to perform certain tasks. Two such areas effect the <b>comprehension</b> <b>of</b> <b>speech</b> and the ability to produce coherent speech, Wernicke's area and Broca's area, respectively.|$|E
50|$|Emergence is {{the return}} to {{baseline}} physiologic function of all organ systems after the cessation of general anaesthetics. This stage may be accompanied by temporary neurologic phenomena, such as agitated emergence (acute mental confusion), aphasia (impaired production or <b>comprehension</b> <b>of</b> <b>speech),</b> or focal impairment in sensory or motor function. Shivering is also fairly common and can be clinically significant because it causes an increase in oxygen consumption, carbon dioxide production, cardiac output, heart rate, and systemic blood pressure. The proposed mechanism {{is based on the}} observation that the spinal cord recovers at a faster rate than the brain. This results in uninhibited spinal reflexes manifested as clonic activity (shivering). This theory is supported by the fact that doxapram, a CNS stimulant, is somewhat effective in abolishing postoperative shivering. Cardiovascular events such as increased or decreased blood pressure, rapid heart rate, or other cardiac dysrhythmias are also common during emergence from general anaesthesia, as are respiratory symptoms such as dyspnoea.|$|E
40|$|Please {{contact the}} {{publisher}} for further reprinting or re-use. A rapidly ageing population {{has led to}} the development of Interactive Domestic Alarm Systems (IDASs) to assist older adults with independent living. This research considers the use of speech as IDAS output and the impact the domestic environment may have on older adults’ <b>comprehension</b> <b>of</b> <b>speech</b> outputs. This paper introduces IDASs, the benefits of employing speech as a mode of system output and the critical design issue of user comprehension. Extending previous laboratory studies (see Lines & Hone, 2002 a, Lines & Hone, 2002 b, Lines & Hone, 2002 c) a field investigation is reported that considers older adults’ <b>comprehension</b> <b>of</b> <b>speech</b> gender and speech type [natural/synthetic] within the domestic environment. The main findings are discussed and future research directions explored...|$|E
40|$|Presented at the 11 th International Conference on Auditory Display (ICAD 2005) This paper {{describes}} two empirical experiments {{investigating the}} perception of embedded audible hyperlinks, designed using speech and non-speech cues, and their effect on the <b>comprehension</b> <b>of</b> synthetic <b>speech.</b> Results from the first experiment showed high accuracy levels of hyperlink perception and differences in comprehension performance between sentences with hyperlinks and sentences without hyperlinks. Results from the second experiment also showed high accuracy levels of hyperlink perception as well as differences in comprehension performance between two hyperlink designs using different configurations <b>of</b> <b>speech</b> and non-speech cues. The results demonstrate that speech and non-speech cues may be effective {{in the design of}} audible hyperlinks however their presence within synthetic sentences may reduce overall comprehensibility. Results also demonstrate that different configurations <b>of</b> <b>speech</b> and non-speech cues used to represent audible hyperlinks effect comprehension processes...|$|R
40|$|We used {{functional}} {{magnetic resonance}} imaging (fMRI) to investigate the neural basis <b>of</b> <b>comprehension</b> and perceptual learning of artificially degraded [noise vocoded (NV) ] speech. Fifteen participants were scanned while listening to 6 -channel vocoded words, which are difficult for naive listeners to comprehend, but can be readily learned with appropriate feedback presentations. During three test blocks, we compared responses to potentially intelligible NV words, incomprehensible distorted words and clear speech. Training sessions were interleaved with the test sessions and included paired presentation of clear then noise-vocoded words: a type of feedback that enhances perceptual learning. Listeners' <b>comprehension</b> <b>of</b> NV words improved significantly as a consequence of training. Listening to NV compared to clear speech activated left insula, and prefrontal and motor cortices. These areas, which are implicated in speech production, may play an active role in supporting the <b>comprehension</b> <b>of</b> degraded <b>speech.</b> Elevated activation in the precentral gyrus during paired clear-then-distorted presentations that enhance learning further suggests a role for articulatory representations <b>of</b> <b>speech</b> in perceptual learning <b>of</b> degraded <b>speech...</b>|$|R
40|$|English in Business is {{a course}} for {{learners}} of English at intermediate level who might need the key concepts of business and economics {{to be able to}} use them in their future professional activities and in the business world overall. The learning materials cover the most important topics in business development and environment, management, marketing, finance, communication, etc. This piece of schoolwork is aimed to develop business vocabulary, <b>comprehension,</b> fluency <b>of</b> <b>speech</b> and thought, alongside with reading, writing, and speaking skills, to assist students or adult learners to join the labour market and settle in it more successfully...|$|R
40|$|According to perceptualism, fluent <b>comprehension</b> <b>of</b> <b>speech</b> is a perceptual achievement, {{in as much}} as it is akin to such {{high-level}} perceptual {{states as}} the perception of objects as cups or trees, or of people as happy or sad. According to liberalism, grasp of meaning is partially constitutive of the phenomenology of fluent comprehension. I here defend an influential line of argument for liberal perceptualism, resting on phenomenal contrasts in our <b>comprehension</b> <b>of</b> <b>speech,</b> due to Susanna Siegel and Tim Bayne, against objections from Casey O'Callaghan and Indrek Reiland. I concentrate on the contrast between the putative immediacy of meaning-assignment in fluent comprehension, as compared with other, less ordinary, perhaps translation-based ways of getting at the meaning of speech. I argue this putative immediacy is difficult to capture on a non-perceptual view (whether liberal or non-liberal), and that the immediacy in question has much in common with that which applies in other, less controversial cases of high-level perception...|$|E
30|$|Emergence: {{the return}} to {{baseline}} physiologic function of all organ systems after the cessation of general anesthetics. It may be accompanied by temporary neurologic phenomena, such as agitated emergence (acute mental confusion), aphasia (impaired production or <b>comprehension</b> <b>of</b> <b>speech),</b> or focal impairment in sensory or motor function. Shivering is also fairly common and can be clinically significant because it causes an increase in oxygen consumption; carbon dioxide production; cardiovascular events such as increased or decreased blood pressure, rapid heart rate, and cardiac dysrhythmias; and respiratory symptoms such as dyspnea Stoelting and Miller (2006).|$|E
40|$|In {{this paper}} we {{describe}} the importance of intonation in human <b>comprehension</b> <b>of</b> <b>speech</b> and in creation of computer-based systems for analysis, synthesis and understanding of speech signals. We lay out fundamental principles of intonational theory of speech {{that is based on}} the concept of universal melodic portraits. In addition, {{we describe the}} main algorithms of analysis and interpretation of intonation in an utterance that underlie the developed computer-based system for teaching of speech intonation. We further show the system’s output and discuss its usefulness in teaching foreign language intonation...|$|E
60|$|He {{tried to}} give her yet another idea {{of the size of}} the universe; never was there a more ardent {{endeavour}} to bring down the immeasurable to human <b>comprehension!</b> By figures <b>of</b> <b>speech</b> and apt comparisons he took her mind into leading-strings, compelling her to follow him into wildernesses of which she had never in her life even realized the existence.|$|R
40|$|The present {{research}} examined the coordination <b>of</b> <b>speech</b> production and speech comprehension. Whilst conversing with others we must coordinate the planning <b>of</b> our own <b>speech</b> output with the <b>comprehension</b> <b>of</b> our <b>speech</b> partner(s) ’s utterances. However, {{very little is}} known about the coordination. Through examining participants’ speech and eye-movements, this research questioned how people manage to coordinate their speaking and listening in dialogue. In 6 studies I demonstrate that tracking prediction processes offers an effective measure <b>of</b> online <b>comprehension.</b> When employing an appropriate dual-task, where two linguistic tasks competed for attention, cognitive resources had to be shared between the two tasks. Where necessary, participants actively engaged in strategies that helped to reduce processing demands including separation <b>of</b> production and <b>comprehension,</b> comparable processing <b>of</b> simple and complex syntactic structures, and using online prediction to preserve capacity. These capacity saving processes and strategy use enabled speech production to be effectively coordinated with speech comprehension in an experimental setting...|$|R
50|$|Wernicke's aphasia is {{characterized}} as impaired <b>comprehension</b> <b>of</b> incoming <b>speech</b> stimuli (Ropper, Samuels & Klein, 2014). An aphasic patient’s speech output is fluent and has normal prosody. Patients with aphasia will produce {{an equal number}} of words in their spontaneous speech output compared to a normal speaker, but their speech contains several paraphasias, circumlocutions, and repetitions (Andreetta & Marini, 2014, p. 715). When speaking, a patient will often produce jargon, or nonsense utterances (ASHA, 2016). Patients are unable to appropriately express their thoughts as well as lack the ability to decode meaning within the incoming speech stimuli (Marsel, 2014). The damage is associated with the posterior portion of the left hemisphere of the brain.|$|R
