4|233|Public
40|$|A long-standing {{problem on}} the {{classical}} capacity of bosonic Gaussian channels has recently been resolved by proving the minimum output entropy conjecture. It is also known that the ultimate <b>capacity</b> <b>quantified</b> by the Holevo bound can be achieved asymptotically by using {{an infinite number of}} channels. However, it is less understood to what extent the communication capacity can be reached if one uses a finite number of channels, which is a topic of practical importance. In this paper, we study the capacity of Gaussian communication, i. e., employing Gaussian states and Gaussian measurements to encode and decode information under a single-channel use. We prove that the optimal capacity of single-channel Gaussian communication is achieved by one of two well-known protocols, i. e., coherent-state communication or squeezed-state communication, depending on the energy (number of photons) as well as the characteristics of the channel. Our result suggests that the coherent-state scheme known to achieve the ultimate information-theoretic capacity is not a practically optimal scheme for the case of using a finite number of channels. We find that overall the squeezed-state communication is optimal in a small-photon-number regime whereas the coherent-state communication performs better in a large-photon-number regime. Comment: 9 pages, 4 figures, published versio...|$|E
40|$|Background Echocardiographic {{optimization}} of pacemaker settings is {{the current}} standard of care for patients treated with cardiac resynchronization therapy. However, the process requires considerable time of expert staff. The BRAVO study is a non-inferiority trial comparing echocardiographic optimization of atrioventricular (AV) and interventricular (VV) delay with an alternative method using non-invasive blood pressure monitoring that can be automated to consume less staff resources. Methods/Design BRAVO is a multi-centre, randomized, cross-over, non-inferiority trial of 400 patients with a previously implanted cardiac resynchronization device. Patients are randomly allocated to six months in each arm. In the echocardiographic arm, AV delay is optimized using the iterative method and VV delay by maximizing LVOT VTI. In the haemodynamic arm AV and VV delay are optimized using non-invasive blood pressure measured using finger photoplethysmography. At {{the end of each}} six month arm, patients undergo the primary outcome measure of objective exercise <b>capacity,</b> <b>quantified</b> as peak oxygen uptake (VO 2) on a cardiopulmonary exercise test. Secondary outcome measures are echocardiographic measurement of left ventricular remodelling, quality of life score and N-terminal pro B-type Natriuretic Peptide (NT-pro BNP). The study is scheduled to complete recruitment in December 2013 and to complete follow up in December 2014. Discussion If exercise capacity is non-inferior with haemodynamic optimization compared with echocardiographic optimization, it would be proof of concept that haemodynamic optimization is an acceptable alternative which {{has the potential to be}} more easily implemented...|$|E
40|$|Objective: to {{determine}} the medication management capacity of independently living older people (>= 75 years) on polypharmacy (>= 5 medications) {{in relation to their}} cognitive- and self-management skills. Design: Cross-sectional study. Setting: two homecare organizations in the Netherlands. Participants: homecare clients aged 75 and older on polypharmacy (N= 95). Measurements: the primary outcome measure was medication management <b>capacity,</b> <b>quantified</b> as the number of 'yes' answers (range = 0 - 17) on the Medication Management Capacity (MMC) questionnaire. other measures included self-management ability (assessed with the SMAS 30) and cognitive skills (assessed with the clock drawing test). Results: overall, 48. 4 % (n= 46) of the participants were able to manage their medication by themselves at home. about 40 % of the participants were unable to state the names of their medications, even {{with the aid of a}} medication list, and about 25 % reported having problems with opening medication packages. Correlations were found between self-management ability (Rs = 0. 473; p < 0. 001), cognitive skills (Rs = 0. 372; p < 0. 001), and age (Rs = 0. 216; p < 0. 005) and Medication Management Capacity score. Self-management ability and medication management support were significantly associated with medication management capacity. Conclusion: a considerable proportion of independently living older people who receive home care and regularly use five or more medications lack the knowledge and skills needed to independently manage their own medications. Cognition and self management ability were related to medication management capacity. Self-management ability and medication management support were predictors of medication management capacity...|$|E
40|$|Conference PaperFading channels, {{often seen}} in {{wireless}} systems, provide an unfavorable environment for reliable communications. Current methods for evaluating the performance of fading channels include ergodic capacity and epsilon -capacity. Ergodic <b>capacity</b> <b>quantifies</b> the ultimate reliable communication limit of the fading channel. It is only achievable with infinite coding delay, {{making it impossible to}} achieve in practice. epsilon -capacity, achievable with finite coding delay, does not provide a measure of error-free communications performance. Since practical communication systems are delay-constrained, it is possible to retransmit codewords when errors occur. We provide a new analysis framework that accounts for codeword retransmission in the analysis of fading channels. We introduce new measures, maximum zero-outage throughput and maximum epsilon -throughput, that predict the performance of practical systems and show that ergodic capacity and epsilon -capacity are special cases of our definitions. We also provide a measure that characterizes the performance of a system with more complex receiver design, using "incremental diversity" to improve throughput...|$|R
40|$|The Mesoamerican {{region is}} {{considered}} {{to be one of the}} areas in the world most vulnerable to climate change. We developed a framework for quantifying the vulnerability of the livelihoods of coffee growers in Mesoamerica at regional and local levels and identify adaptation strategies. Following the Intergovernmental Panel on Climate Change (IPCC) concepts, vulnerability was defined as the combination of exposure, sensitivity and adaptive <b>capacity.</b> To <b>quantify</b> exposure, changes in the climatic suitability for coffee and other crops were predicted through niche modelling based on historical climat...|$|R
40|$|In most {{communication}} scenarios, {{sending a}} symbol encoded in a quantum state requires spending {{resources such as}} energy, which can be quantified by a cost of communication. A standard approach {{in this context is}} to quantify the performance of communication protocol by classical <b>capacity,</b> <b>quantifying</b> the maximal amount of information that can be transmitted through a quantum channel per single use of the channel. However, different figures of merit are also possible, and a particularly well-suited one is the classical capacity per unit cost, which quantifies the maximal amount of information that can be transmitted per unit cost. I generalize this concept to account for the quantum nature of the information carriers and communication channels and show that if there exists a state with cost equal to zero, e. g. a vacuum state, the capacity per unit cost can be expressed by a simple formula containing maximization of the relative entropy between two quantum states. This enables me to analyze the behavior of photon information efficiency for general communication tasks and show simple bounds on the capacity per unit cost in terms of quantities familiar from quantum estimation theory. I calculate also the capacity per unit cost for general Gaussian quantum channels. Comment: 11 pages, 2 figures, final version, updated reference...|$|R
40|$|BACKGROUND: High aerobic {{capacity}} is {{inversely related to}} cardiovascular disease morbidity and mortality. Recent studies suggest greater improvements in aerobic capacity with high-intensity interval training (interval) compared to moderate-intensity continuous aerobic exercise (continuous). Therefore we perform a meta-analysis of randomised controlled trials comparing the effectiveness of INTERVAL versus CONTINUOUS in aerobic capacity, amongst patients with stable coronary artery disease (CAD) and preserved ejection fraction METHODS: We searched PubMed, EMBASE, CINAHL, the Australia and New Zealand Clinical Trials Register, clinicaltrials. gov and TROVE for randomised controlled trials comparing INTERVAL with CONTINUOUS in patients with CAD. Studies published in the English language up to December 2013 were eligible for inclusion. Aerobic <b>capacity,</b> <b>quantified</b> by peak oxygen consumption (VO 2 peak) post exercise training was extracted and compared post-intervention between INTERVAL and CONTINUOUS {{by way of a}} fixed model meta-analysis. Secondary outcomes including anaerobic threshold, blood pressure and high-density lipoproteins (HDL) were also analysed. RESULTS: Six independent studies with 229 patients (n= 99 randomised to INTERVAL) were included in the meta-analysis. There was a significantly higher increase in VO 2 peak following INTERVAL compared to CONTINUOUS (Weighted Mean Difference= 1. 53 ml•kg(- 1) min(- 1), 95 % CI 0. 84 to 2. 23) with homogeneity displayed between studies (Chi Squared= 2. 69; P= 0. 7). Significant effects of INTERVAL compared to CONTINUOUS were also found for anaerobic threshold but not systolic blood pressure. CONCLUSION: In patients with CAD, INTERVAL appears more effective than CONTINUOUS for the improvement of aerobic capacity in patients with CAD. However, long-term studies assessing morbidity and mortality following INTERVAL are required before this approach can be more widely adopted. Adrian D. Elliott, Kanchani Rajopadhyaya, David J. Bentley, John F. Beltrame, Edoardo C. Aromatari...|$|E
40|$|There are (at least) three {{approaches}} to quantifying information. The first, algorithmic information or Kolmogorov complexity, takes events as strings and, given a universal Turing machine, quantifies the information {{content of a}} string as {{the length of the}} shortest program producing it [1]. The second, Shannon information, takes events as belonging to ensembles and quantifies the information resulting from observing the given event {{in terms of the number}} of alternate events that have been ruled out [2]. The third, statistical learning theory, has introduced measures of capacity that control (in part) the expected risk of classifiers [3]. These <b>capacities</b> <b>quantify</b> the expectations regarding future data that learning algorithms embed into classifiers. Solomonoff and Hutter have applied algorithmic information to prove remarkable results on uni-versal induction. Shannon information provides the mathematical foundation for communication and coding theory. However, both approaches have shortcomings. Algorithmic information is not computable, severely limiting its practical usefulness. Shannon information refers to ensembles rather than actual events: it makes no sense to compute the Shannon information of a single string – or rather, there are many answers to this question depending on how a related ensemble is con-structed. Although there are asymptotic results linking algorithmic and Shannon information, it i...|$|R
40|$|Here, {{we report}} {{simultaneous}} surface profile measurements of several bacterial species involved in microbially influenced corrosion and their solid-surface interfaces by using vertical scanning interferometry. The <b>capacity</b> to nondestructively <b>quantify</b> microscale topographic changes beneath a single bacterium without its removal offers {{a unique opportunity}} to examine in vivo microbe-surface interactions...|$|R
40|$|This article {{describes}} an ongoing {{effort to reach}} consensus {{on the notion of}} capacity credit for solar power electrical generation. The article presents different methodologies <b>quantifying</b> <b>capacity</b> credit and reports on their intercomparison through experimental case studies. It concludes by reporting the initial results of a consensus-building effort involving the utility industry, the solar industry and government...|$|R
40|$|This paper {{presents}} {{a method for}} allocating production capacity among flexible and dedicated machines based on uncertain demand forecasts of products in a production portfolio. Given multiple scenarios of future demands with the associated probabilities, the method provides alternative <b>capacity</b> allocations by <b>quantifying</b> the expected values of the product quality and cost. The product quality is estimated as the total performance variations from the nominal design for each product in a portfolio. The production cost is estimated as the total annual equivalent of investment and operation costs for each production period. A multi-objective genetic algorithm is utilized to compute the Pareto-optimal <b>capacity</b> allocations that <b>quantify</b> the tradeoffs between the expected product quality and cost. Case studies on an automotive valvetrain production are presented, where, under the demand forecasts with low uncertainty, the allocation of flexible machines is encouraged only at production steps critical to quality and cost...|$|R
30|$|This paper {{presents}} the derivation {{and analysis of}} the PDF, CDF, LCR, and ADF of the instantaneous channel capacityc of spatially correlated Nakagami-m channels, for both MRC and EGC. The PDF of the channel capacity is helpful to study the mean channel capacity (or the ergodic capacity) [26], while the CDF of the channel capacity is useful for the derivation {{and analysis of the}} outage capacity [26]. The mean channel capacity and the outage capacity are very widely explored by the researchers due to their importance for the system design and performance analysis. The ergodic capacity provides the information regarding the average data rate offered by a wireless link (where the average is taken over all the realizations of the channel capacity) [27, 28]. On the other hand, the outage <b>capacity</b> <b>quantifies</b> the <b>capacity</b> (or the data rate) that is guaranteed with a certain level of reliability [27, 28]. However, these two aforementioned statistical measures do not provide insight into the temporal behavior of the channel capacity. For example, the outage capacity {{is a measure of the}} probability of a specific percentage of capacity outage, but it does not give any information regarding the spread of the outage intervals or the rate at which these outage durations occur over the time scale. Whereas, the information regarding the temporal behavior of the channel capacity is very useful for the improvement of the system performance [29].|$|R
40|$|Spatial {{modelling}} {{is increasingly}} being embraced by conservation practitioners {{and community groups}} to guide natural-asset management. Despite this boom in popularity, little guidance is often available on choosing the most applicable technique, and the relative merits and drawbacks of each approach. We present {{a case study in}} the biodiversity hotspot of south-Western Australia where five forms of spatial modelling have previously been used by community conservation managers in this region: realistic GIS modelling, focal species, proximity analysis, Marxan and MaxEnt. We developed a set of criteria for effective spatial modelling and then evaluated each of these spatial-modelling techniques using these criteria. The criteria used in evaluating spatial-modelling tools were as follows: (1) <b>capacity</b> to <b>quantify</b> barriers to movement; (2) <b>capacity</b> to <b>quantify</b> habitat; (3) <b>capacity</b> to accurately predict target responses; (4) capacity to demonstrate how change will happen over differing time frames; (5) effectiveness of the tool within data limitations of a project; (6) ease to which outputs are understood; (7) utility of the tool within skill limitations of a project; and (8) efficacy within resource limitations of a project. None of the applications used met all criteria. When selecting spatial-modelling applications, a hybrid approach is advocated by using criteria that will reflect both the landscape-level conservation requirements and the capacity and objectives of conservation managers. To do this, we advocate using multiple modelling techniques to identify, quantify and ameliorate threats {{to meet the needs of}} regional biota. © CSIRO 2016...|$|R
40|$|Spino{{cerebellar}} ataxia type 6 (SCA 6) is {{a genetic}} disease that causes pure cerebellar degeneration affecting walking, balance, and coordination. One {{of the main}} symptoms of SCA 6 is dysmetria. The magnitude of dysmetria {{and its relation to}} functional capacity in SCA 6 has not been studied. Our purpose was to quantify dysmetria and determine the relation between dysmetria and functional capacity in SCA 6. Ten individuals diagnosed and genetically confirmed with SCA 6 (63. 7 ± 7. 02 yrs) and nine age-matched healthy controls (65. 9 ± 8. 5 yrs) performed goal-directed isometric contractions with the ankle joint. Dysmetria was quantified as the force and time error during goal-directed contractions. SCA 6 functional capacity was determined by ICARS and SARA clinical assessments. We found that SCA 6 participants exhibited greater force dysmetria than healthy controls (P < 0. 05), and reduced time dysmetria than healthy controls (P < 0. 05). Only force dysmetria was significantly related to SCA 6 functional capacity, as measured with ICARS kinetic score (R 2 = 0. 63), ICARS total score (R 2 = 0. 43), and SARA total score (R 2 = 0. 46). Our findings demonstrate that SCA 6 exhibit force dysmetria and that force dysmetria is associated to SCA 6 functional <b>capacity.</b> <b>Quantifying</b> force and time dysmetria in individuals with SCA 6 could provide a more objective evaluation of the functional capacity and disease state in SCA 6...|$|R
40|$|A quantum {{communication}} channel {{can be put}} to many uses: it can transmit classical information, private classical information, or quantum information. It can be used alone, with shared entanglement, or together with other channels. For each of these settings there is a <b>capacity</b> that <b>quantifies</b> a channel's potential for communication. In this short review, I summarize {{what is known about}} the various capacities of a quantum channel, including a discussion of the relevant additivity questions. I also give some indication of potentially interesting directions for future research. Comment: This review of quantum channel capacities is the basis for my upcoming talk at ITW 2010 in Dubli...|$|R
40|$|We {{describe}} an experimental {{implementation of a}} free-space 11 -dimensional communication system using orbital angular momentum (OAM) modes. This system has a maximum measured OAM channel capacity of 2. 12 bits/photon. The effects of Kolmogorov thin-phase turbulence on the OAM channel <b>capacity</b> are <b>quantified.</b> We find that increasing the turbulence leads to a degradation of the channel capacity. We are able to mitigate the effects of turbulence by increasing the spacing between detected OAM modes. This study has implications for high-dimensional quantum key distribution (QKD) systems. We describe the sort of QKD system that could be built using our current technology. Comment: 6 pages, 5 figure...|$|R
40|$|One of {{the main}} figures of merit for quantum {{memories}} and quantum communication devices is their quantum capacity. It has been studied for arbitrary kinds of quantum channels, but its practical estimation {{has so far been}} limited to devices that implement independent and identically distributed (i. i. d.) quantum channels, where each qubit is affected by the same noise process. Real devices, however, typically exhibit correlated errors. Here, we overcome this limitation by presenting protocols that estimate a channel's one-shot quantum capacity for the case where the device acts on (an arbitrary number of) qubits. The one-shot quantum <b>capacity</b> <b>quantifies</b> a device's ability to store or communicate quantum information, even if there are correlated errors across the different qubits. We present a protocol which is easy to implement and which comes in two versions. The first version estimates the one-shot quantum capacity by preparing and measuring in two different bases, where all involved qubits are used as test qubits. The second version verifies on-the-fly that a channel's one-shot quantum capacity exceeds a minimal tolerated value while storing or communicating data, therefore combining test qubits and data qubits in one protocol. We discuss the performance of our method using simple examples, such as the dephasing channel for which our method is asymptotically optimal. Finally, we apply our method to estimate the one-shot capacity in an experiment using a transmon qubit. Comment: 9 + 13 pages, 10 figures, see dataAnalysisScript (analysis. py and readme. txt) for a Python script that applies this method to your experimental dat...|$|R
40|$|Throughout the world, {{historic}} drainage {{of wetlands}} {{has resulted in}} a reduction in the area of wet habitat and corresponding loss of wetland plant and animal species. In an attempt to reverse this trend, water level management in some drained areas is trying to replicate a more natural ‘undrained’ state. The resulting hydrological regime is likely to be more suitable to native wetland species; however the raised water levels also represent a potential reduction in flood water storage <b>capacity.</b> <b>Quantifying</b> this reduction is critical if the arguments for and against wetland restoration are to be discussed in a meaningful way. We present a simple model to quantify the hydrological storage capacity of a drainage ditch network under different water level management scenarios. The model was applied to the Somerset Levels and Moors, UK, comparing areas with and without raised water level management. The raised water level areas occupy 11 % of the maximum theoretical storage but when put {{in the context of the}} recent severe flooding of winter 2013 / 2014 occupy only 0. 6 % of the total flood volume and represent an average increase in flood level of 7 mm. These results indicate that although the raised water level scheme does occupy an appreciable volume of the maximum possible ditch storage, in relation to a large flood event the volume is very small. It therefore seems unlikely that the severity of such large flood events would be significantly reduced if the current water level management for ecological benefit ceased...|$|R
40|$|Pulse shape {{analysis}} (PulSA) is a flow cytometry-based method {{that can be}} used to study protein localization patterns in cells. Examples for its use include tracking the formation of inclusion bodies of polyglutamine-expanded proteins and other aggregating proteins. The method can also be used for phenomena relating to protein movements in cells such as translocation from the cytoplasm to the nucleus, trafficking from the plasma membrane to the Golgi, and stress granule formation. An attractive feature is its <b>capacity</b> to <b>quantify</b> these parameters in whole-cell populations very quickly and in high throughput. We describe the basic experimental details for performing PulSA using expression of GFP-tagged proteins, endogenous proteins labelled immunofluorescently, and organelle dyes. Restricted Access: Metadata Onl...|$|R
40|$|In this study, {{a design}} method of a bio-retention pond for {{reducing}} suspended solids at an industrial area is proposed. After simulating suspended solid loads at a study drainage catchment using SWMM calibrated with the unit load estimation method which is recently {{suggested by the}} National Institute of Environmental Research, the non-point pollutant reduction efficiency {{with respect to the}} bioretention <b>capacity</b> is <b>quantified.</b> Based on various simulation results, the stormwater captured ratio curve and the average annual fraction of suspended solid loads controlled by a bio-retention pond are derived. Using the regression analysis, coefficients of the formula for the average annual captured fraction of suspended solid loads, which is missing in the Korean TMDL technical guide, is proposed. clos...|$|R
40|$|We {{detail the}} {{management}} uses {{and implications of}} fish-based, multimetric indices for assessing the ecological health of nearshore (1. 5 m) waters of the Swan-Canning Estuary. Having outlined {{the development of these}} indices in an accompanying poster presentation, here we focus specifically on how the health indices can be used to quantify, classify, communicate and report on the health of the estuary. We also present analyses of index responses to recent and historical algal blooms, to demonstrate the sensitivity of the indices and their <b>capacity</b> to <b>quantify</b> and track ecological degradation. In so doing, we discuss the implications of our results in terms of our understanding of spatial and temporal changes in the health of the Swan-Canning Estuary...|$|R
40|$|Grid {{integration}} of large scale renewable energy {{is one of}} the biggest challenges facing the electricity industry. Network congestion due to insufficient capacity has been identified as one of the key impediments to renewable integration. This thesis proposes novel techniques for incorporating dynamic transmission line ratings which involve temporarily relaxing line thermal constraints to release latent network <b>capacity.</b> It hence <b>quantifies</b> the risks and benefits of using dynamic ratings in decision making...|$|R
40|$|Recent {{advances}} in wireless communications have {{made use of}} MC-CDMA and OFDM techniques to allow for high data rate transmission. Rapid time variations of the wireless communication channel have a effect {{on the performance of}} multicarrier modulation. In this paper, we emphasis the Doppler spread and Computes its effect on the bit error rate (BER) for multicarrier code division multiple access (MC-CDMA) and orthogonal frequency division multiplexing (OFDM). Also, we evaluate the channel <b>capacity</b> to <b>quantify</b> the potential of MC-CDMA and OFDM. We evaluate the effect of Doppler spread with Doppler shift at various carrier frequencies. We also evaluate the capacity of LTI, OFDM, MC-CDMA and RAYLEIGH channels. Keywordss: Doppler effect, fading channels, intercarrier interference, multicarrier code division multiple access (MC-CDMA), multicarrier modulation, orthogonal frequency division multiplexing (OFDM), Raleigh fading. 1...|$|R
40|$|AIM: To {{study the}} effect of NS- 398, a {{selective}} cyclooxygenase- 2 (COX- 2) inhibitor, on invasion of colon cancer cell line HT- 29 in vitro and to explore its mechanisms. METHODS: Invasive behaviors of the malignant colon cancer cell line HT- 29 were investigated in this study. Expressions of COX- 2 and CD 44 v 6 in HT- 29 cells were detected by flow cytometry. Cellular survival rate was determined by MTT assay. The invasive <b>capacity</b> was <b>quantified</b> by a modified Boyden chamber model. Alterations of cytoskeleton component F-actin were observed by confocal laser scanning microscope. RESULTS: Flow cytometry analysis showed that COX- 2 was highly expressed in HT- 29 cells. The invasive capability of HT- 29 cells could be greatly inhibited by NS- 398 at th...|$|R
40|$|Accurate {{and precise}} protein {{quantification}} remains an important fundamental methodology and represents {{a critical component}} in identifying biomarkers and early detection of diseases. 1 The <b>capacity</b> to <b>quantify</b> relative changes in proteins from complex biological samples is a central challenge to understanding the response of protein expression to genomic or environmental factors. Surface Enhanced Resonance Raman Spectroscopy (SERRS) {{has proven to be}} a useful spectroscopic tool for diagnostic applications, 2 – 5 explosive detection, 6 monitoring events in enzyme catalysis, 7 detection of metabolites, 8 and detection of bioanalytes during capillary electrophoresis. 9 However, SERRS suffers from variability in enhancement of Raman intensity depending upon the nanomor-phology of the substrate (typically silver colloids), thereby affecting the reproducibility of the measurement. In our previous work, we have demonstrated the improved reproducibility and accuracy o...|$|R
40|$|This thesis {{outlines}} {{the results of}} an occupational hygiene monitoring program implemented at Minara Resources 2 ̆ 7 Murrin Murrin mine site. The research was conducted as part of a collaborative agreement between Edith Cowan University and Minara Resources, the title of which was 2 ̆ 2 Establishing best practice protocols in the management of occupational and environmental health in a high risk mining and ore processing environment 2 ̆ 2. To form the basis of this research it was hypothesised that chemical hazards had not been adequately identified, that existing occupational hygiene monitoring programs did not adequately quantify employee exposures to these hazards, and that the implementation of a comprehensive hazard identification and monitoring program would greatly improve the <b>capacity</b> to <b>quantify</b> the health risks posed to employees...|$|R
40|$|Excess {{capacity}} can {{be viewed}} as wasteful (an unnecessary cost) or as prudential (a ready source of supply). The role of excess capacity is an important issue at the individual firm level {{as well as at the}} community level. In this paper we explore hospital capacity for a sample hospitals operating in the 15 largest SMSAs in the U. S. during 2002. Using Johanson’s (1968) notion of capacity as the maximum rate of output possible from fixed inputs (i. e., without restrictions on variable inputs), we measure capacity in a frontier setting using directional distance functions. Rather than attempt to determine the “optimal” level of hospital <b>capacity,</b> we instead <b>quantify</b> <b>capacity</b> and capacity utilization rates at both the individual hospital and, by aggregating, SMSA levels. After determining capacity and capacity utilization rates, we then explore the changes in variable inputs that would be needed to utilize excess capacity. Finally, we perform simulations to determine whether each SMSA has enough “excess ” hospital capacity to accommodate the loss of one of its five largest hospitals. The approach developed in this paper should be of value to decision makers and planners in a variety of fields. ...|$|R
40|$|Extended {{research}} {{has been carried out}} to clarify the ecological role of plant secondary metabolites (SMs). Although their primary ecological function is self-defence, bioactive compounds have long been used in alternative medicine or in biological control of pests. One single plant may contain a wide variety of bioactive compounds, making analytics rather costly. The total bactericide <b>capacity</b> can be <b>quantified</b> by either microbiological or ecotoxicological methods. Here, the principle and possible applications of a specific bacterial bioluminescence inhibition based ecotoxicological assay are reviewed...|$|R
30|$|In this paper, we {{characterize}} the β-galactosidase encoded by bgaB from G. stearothermophilus for molecular applications in thermophiles and under anaerobic conditions. The bgaB gene {{has previously been}} applied as a reporter to monitor heat/stress response in Bacillus subtilis (Schrogel and Allmansberger 1997; Yuan and Wong 1995), {{as well as to}} gain expression profiles of various promoters in Geobacillus kaustophilus HTA 426 (Suzuki et al. 2013), thus it is considered suited for the purpose. Since G. thermoglucosidans is a facultative anaerobe and capable of growing at a broad range of temperatures, it is a suitable platform for testing this and other systems, which require various conditions. We demonstrate bgaB as an efficient tool for colony screening of thermophilic aerobic and anaerobic microorganisms. Furthermore by showing its <b>capacity</b> in <b>quantifying</b> promoter strength in a randomized library we highlight the versatility of the tool.|$|R
30|$|A {{comprehensive}} {{treatment of}} multiaccess fading channels {{can be found}} in [1, 2]. In these papers, Tse and Hanly have characterized the so-called throughput capacity and delay-limited capacity of the multiaccess block fading channel with Gaussian noise assuming that perfect channel state information (CSI) is causally available at the transmitters and the receiver. The throughput <b>capacity</b> region <b>quantifies</b> the achievable rate region with average power constraint for ergodic fading. For the delay limited capacity, each user must be given the required rate irrespective of its fading state. The aim is to obtain a coding and power allocation scheme to minimize the energy while guaranteeing the rate in every slot. Here, slot refers to the time duration required to transmit a block of symbols over which the fading state remains unaltered. Thus, the slot duration is smaller than the channel coherence time.|$|R
40|$|This article {{investigates the}} {{prominent}} dilemma between capacity and reliability in heterogeneous ultra-dense distributed networks, and advocates a new measure of effective <b>capacity</b> to <b>quantify</b> the maximum sustainable data rate of a link while preserving the quality-of-service (QoS) {{of the link}} in such networks. Recent breakthroughs are brought forth in developing {{the theory of the}} effective capacity in heterogeneous ultra-dense distributed networks. Potential applications of the effective capacity are demonstrated on the admission control, power control and resource allocation of such networks, with substantial gains revealed over existing technologies. This new measure is of particular interest to ultra-dense deployment of the emerging fifth-generation (5 G) wireless networks in the unlicensed spectrum, leveraging the capacity gain brought by the use of the unlicensed band and the stringent reliability sustained by 5 G in future heterogeneous network environments...|$|R
40|$|We {{study the}} effect of {{topology}} variation on the dynamic behavior of a system with local update rules. We implement one-dimensional binary cellular automata on graphs with various topologies by formulating two sets of degree-dependent rules, each containing a single parameter. We observe that changes in graph topology induce transitions between different dynamic domains (Wolfram classes) without a formal change in the update rule. Along with topological variations, we study the pattern formation capacities of regular, random, small-world and scale-free graphs. Pattern formation <b>capacity</b> is <b>quantified</b> in terms of two entropy measures, which for standard cellular automata allow a qualitative distinction between the four Wolfram classes. A mean-field model explains the dynamic behavior of random graphs. Implications for our understanding of information transport through complex, network-based systems are discussed. Comment: 16 text pages, 13 figures. To be published in Physica...|$|R
30|$|The rest of {{this article}} is {{structured}} as follows. An overview of related work is presented in Section 2. In Section 3, the capacity performance of multibeam joint processing is examined, focusing on the forward link (FL) of fixed services. In Section 4 the RL of a satellite system serving mobile users and jointly decodes all the received signals is investigated. Finally, in Section 5, the <b>capacity</b> performance is <b>quantified</b> through numerical simulations and compared to the performance of conventional systems, while Section 6 concludes the article.|$|R
40|$|Relay {{deployment}} in orthogonal {{frequency division}} multiple access (OFDMA) based cellular networks helps in coverage extension and/or <b>capacity</b> improvement. To <b>quantify</b> <b>capacity</b> improvement, blocking probability of voice call is typically calculated using Erlang B formula. This calculation {{is based on the}} assumption that all users require same amount of resources to satisfy their rate requirement. However, in an OFDMA system, each user requires different number of subcarriers to meet its rate requirement. This resource requirement depends on the signal to interference ratio (SIR) experienced by a user. Therefore, the Erlang B formula can not be employed to compute blocking probability in an OFDMA network. In this paper, we determine an analytical expression to compute the blocking probability in a relay based cellular OFDMA network. We determine an expression of the probability distribution of the user's resource requirement based on its experienced SIR. Then, we classify the users into various classes depending upon their subcarrier requirement. We consider the system to be a multi-dimensional system with different classes and evaluate the blocking probability using the multi-dimensional Erlang loss formulas. This model is useful in the performance evaluation, design, planning of resources and call admission control in a relay based cellular OFDMA networks like long term evolution...|$|R
40|$|Minimum-mean squared error (MMSE) {{receivers}} {{are designed}} and analyzed for multiple data rate direct-sequence code-division multiple-access (DS-CDMA) systems. The inherent cyclostationarity of the DS-CDMA signal is exploited to construct receivers for asynchronous multipath channels. Multiple- and single-bandwidth access are treated for both single and multicarrier scenarios. In general, the optimal receiver is periodically time-varying. When {{the period of}} the optimal receiver is large, suboptimal receivers are proposed to achieve a lower complexity implementation; the receivers are designed {{as a function of the}} cyclic statistics of the signals. In multiple chipping rate systems, complexity of receivers for smaller bandwidth users can also be controlled by changing their front-end filter bandwidth. The effect of front-end filter bandwidth on receiver performance and system <b>capacity</b> is <b>quantified</b> for a variable chipping rate system. Analysis and simulation show that significant performance gains are realized by the periodically time-varying MMSE receivers over their time-invariant counterparts...|$|R
40|$|Background: Human adipose-derived stem (stromal) {{cells are}} {{promising}} as a regenerative therapy tool for defective tissues of mesenchymal lineage, includ-ing fat, bone, and cartilage, and blood vessels. In potential future clinical applications, adipose-derived stem cell cryopreservation {{could be an}} indispens-able fundamental technology, as has occurred in other fields involving cell-based therapies using hematopoietic stem cells and umbilical cord blood cells. Methods: The authors examined the proliferative capacity and multipotency of human adipose-derived stem cells isolated from lipoaspirates of 18 patients in total before and after a 6 -month cryopreservation following their defined pro-tocol. Proliferative <b>capacity</b> was <b>quantified</b> by measuring doubling time in cell culture, and multipotency was examined with differentiation assays for chon-drogenic, osteogenic, and adipogenic lineages. In addition, expression profiles of cell surface markers were determined by flow cytometry and compared between fresh and cryopreserved adipose-derived stem cells. Results: Cryopreserved adipose-derived stem cells fully retained the potentia...|$|R
