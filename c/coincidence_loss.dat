18|10|Public
40|$|The {{calibration}} {{of the two}} UVOT grisms {{which provide}} slitless spectroscopy in the 170 - 500 nm (UV grism) and 295 - 660 nm (visible grism) ranges has been completed. The UV grism has a spectral resolution (λ/Δλ) of 75 at λ 2600 Å for source magnitudes of u= 10 - 16 mag, while the visible grism has a spectral resolution of 100 at λ 4000 Å for source magnitudes of b= 12 - 17 mag. For brighter spectra, <b>coincidence</b> <b>loss</b> (pile-up) occurs in the photon-counting detector. A correction for the <b>coincidence</b> <b>loss</b> in grism spectra has been developed, and limits have been established above which that correction fails. After discussing the UVOT grisms and their calibration, an illustration is given of {{the breadth of the}} UVOT grism spectroscopy. Comment: to appear in "Swift: 10 years of discovery", Proceedings of Scienc...|$|E
40|$|The {{dynamic range}} of photon {{counting}} micro-channel-plate (MCP) intensified charged-coupled device (CCD) instruments {{such as the}} Swift Ultraviolet/Optical Telescope (UVOT) and the XMM-Newton Optical Monitor (XMM-OM) is limited at the bright end by <b>coincidence</b> <b>loss,</b> the superposition of multiple photons in the individual frames recorded by the CCD. Photons which arrive during the brief {{period in which the}} image frame is transferred for read out of the CCD are displaced in the transfer direction in the recorded images. For sufficiently bright sources, these displaced counts form read-out streaks. Using UVOT observations of Tycho- 2 stars, we investigate the use of these read-out streaks to obtain photometry for sources which are too bright (and hence have too much <b>coincidence</b> <b>loss)</b> for normal aperture photometry to be reliable. For read-out-streak photometry, the bright-source limiting factor is <b>coincidence</b> <b>loss</b> within the MCPs rather than the CCD. We find that photometric measurements can be obtained for stars up to 2. 4 magnitudes brighter than the usual full-frame coincidence-loss limit by using the read-out streaks. The resulting bright-limit Vega magnitudes in the UVOT passbands are UVW 2 = 8. 80, UVM 2 = 8. 27, UVW 1 = 8. 86, u= 9. 76, b= 10. 53, v= 9. 31 and White= 11. 71; these limits are independent of the windowing mode of the camera. We find that a photometric precision of 0. 1 mag can be achieved through read-out streak measurements. A suitable method for the measurement of read-out streaks is described and all necessary calibration factors are given. Comment: 11 pages, accepted for publication in MNRAS. Code available from the calibration link at [URL]...|$|E
40|$|The Swift UVOT grisms (uv: 170 - 500 nm; visible: 285 - 660 nm) {{spectral}} reduction {{package is}} {{a replacement for}} the uvotimgrism Ftool from the HEADAS Swift software. Requires a recent HEADAS Swift installation. Recently the <b>coincidence</b> <b>loss</b> correction was redeveloped and is now formulated in a fully consistent manner to the theory as used successfully for point sources. Updates to the calibration files were made consistent with the reformulated correction. A program was added to help shift the wavelengths due to uncertainties in anchor position. This version fixes {{a problem with the}} background extraction in uvotpy- 2. 0. 2...|$|E
40|$|Development of {{a sensor}} {{incorporating}} a CCD and photocathode for {{operation in the}} electron bombarded mode in both a magnetic and an electrostatic focussed, gated configuration is described. Initial format size is 100 x 160 pixels with eventual growth to 400 x 400 pixels. The sensor {{is part of a}} digital camera system which includes the low level video conditioning electronics, a camera controller, a high speed buffer memory, and digital recording and display electronics. The memory uses CMOS/SOS and has a capacity of 1. 6 Mbits with operating rates of 48 Mbits/sec. Individual frames are co-added to provide wide dynamic range and photometric precision better than 1 %. A 4 -bit video quantization is used to increase the photon counting detection rate before <b>coincidence</b> <b>losses</b> become serious...|$|R
5000|$|It {{was not a}} <b>coincidence</b> {{that the}} <b>loss</b> was a little under £315,000: just enough to cover an {{unrelated}} taxable capital gain Mr Rawling had made in the same year.|$|R
40|$|Compton {{suppressed}} high-purity germanium (HPGe) detector is {{well suited}} {{to the analysis of}} low levels of radioactivity in environmental samples. The difference in geometry, density and composition of environmental calibration standards (e. g. soil) can contribute to excessive experimental uncertainty to the measured efficiency curve. Furthermore multiple detectors, like those used in a Compton suppressed system, can add complexities to the calibration process. Monte Carlo simulations can be a powerful complement in calibrating these types of detector systems, provided enough physical information on the system is known. A full detector model using the Geant 4 simulation toolkit is presented and the system is modelled in both the suppressed and unsuppressed mode of operation. The full energy peak efficiencies of radionuclides from a standard source sample is calculated and compared to experimental measurements. The experimental results agree relatively well with the simulated values (within similar to 5 - 20 %). The simulations show that <b>coincidence</b> <b>losses</b> in the Compton suppression system can cause radionuclide specific effects on the detector efficiency, especially in the Compton suppressed mode of the detector. Additionally since low energy photons are more sensitive to small inaccuracies in the computational detector model than high energy photons, large discrepancies may occur at energies lower than similar to 100 keV. Crown Copyright (C) 2011 Published by Elsevier Ltd. All rights reserved...|$|R
40|$|The Swift UVOT grisms (uv: 170 - 500 nm; visible: 285 - 660 nm) {{spectral}} reduction {{package is}} {{a replacement for}} the uvotimgrism Ftool from the HEADAS Swift software. Requires a recent HEADAS Swift installation. Recently the <b>coincidence</b> <b>loss</b> correction was redeveloped and is now formulated in a fully consistent manner to the theory as used successfully for point sources. Updates to the calibration files were made consistent with the reformulated correction. Minor updates {{to keep up with}} API changes in numpy, astropy, small bug fixes. A paper describing the calibration of, and the UVOT grisms has been published, see the Readme file...|$|E
40|$|We {{present the}} {{calibration}} of the Swift UVOT grisms, {{of which there}} are two, providing low-resolution field spectroscopy in the ultraviolet and optical bands respectively. The UV grism covers the range 1700 - 5000 Angstrom with a spectral resolution of 75 at 2600 Angstrom for source magnitudes of u= 10 - 16 mag, while the visible grism covers the range 2850 - 6600 Angstrom with a spectral resolution of 100 at 4000 Angstrom for source magnitudes of b= 12 - 17 mag. This calibration extends over all detector positions, for all modes used during operations. The wavelength accuracy (1 -sigma) is 9 Angstrom in the UV grism clocked mode, 17 Angstrom in the UV grism nominal mode and 22 Angstrom in the visible grism. The range below 2740 Angstrom in the UV grism and 5200 Angstrom in the visible grism never suffers from overlapping by higher spectral orders. The flux calibration of the grisms includes a correction we developed for <b>coincidence</b> <b>loss</b> in the detector. The error in the <b>coincidence</b> <b>loss</b> correction is less than 20 %. The position of the spectrum on the detector only affects the effective area (sensitivity) by a few percent in the nominal modes, but varies substantially in the clocked modes. The error in the effective area is from 9 % in the UV grism clocked mode to 15 % in the visible grism clocked mode. Comment: 27 pages, 31 figures; MNRAS accepted 23 February 201...|$|E
40|$|A laser-light {{scattering}} {{method was}} evaluated {{from the viewpoint}} of the measurement ability of concentration and size distribution of microparticles in molten ice core samples. It was demonstrated that analysis can be performed with 10 % accuracy by diluting the sample with ultrapure water by 50 times to eliminate <b>coincidence</b> <b>loss.</b> Using this method, the concentration and size distribution of microparticles were determined on 2829 samples from a 2503 m deep ice core drilled at Dome Fuji, Antarctica. The present paper shows the profiles of number and volume concentrations through the whole depth and the changes in the size distribution through three glacial cycles in the past 320 k-years...|$|E
40|$|The {{mechanism}} of {{secondary electron emission}} by impact of 100 -eV electrons on an Al(100) surface has been investigated by measuring the secondary electron spectrum in <b>coincidence</b> with <b>loss</b> features in the spectrum of reflected electrons. Distinct peaks are observed at energies corresponding accurately {{to the surface and}} bulk plasmon energies minus the work function of the analyzer, demonstrating that plasmons excited by electron energy losses predominantly decay via creation of single-electron-hole pairs that act as a source for the secondary electron spectrum. These findings suggest a mechanism for emission of secondary electrons very similar to photoelectron (PE) emission, the difference being the step leading to electron liberation, i. e., plasmon decay in the present case versus photoionization in the case of PE...|$|R
30|$|Small-animal PET was {{performed}} on a microPET® Focus 220 system (Siemens Preclinical Solutions). Starting {{at the time of}} injection, the acquired list mode data were binned into 30 image frames (15 × 0.5, 1 × 2, 1 × 4, 1 × 6, 1 × 15, 3 × 30, 1 × 60, 1 × 120, 3 × 180, 3 × 900 s). Reconstruction incorporated a filtered backprojection algorithm with a ramp filter and a cutoff frequency of 0.5 of the Nyquist frequency to obtain an image pixel size of 0.4 × 0.4 × 0.8 mm and an inter-plane spacing and slice thickness of 0.8 mm in a 128 × 128 matrix. The image reconstruction software provided for correction of radioactivity decay, random <b>coincidences,</b> dead-time <b>losses,</b> and photon attenuation (microPET® Manager v. 2.1. 5.0; Siemens Preclinical Solutions). Photon attenuation was corrected for by CT-derived attenuation maps as described previously [12].|$|R
40|$|AbstractThe {{dissociation}} {{rates of}} phenetole ions have been measured {{as a function}} of the ion internal energy by the method of photoelectron photoion <b>coincidence</b> spectrometry. The <b>loss</b> of ethylene to produce the phenol ion is the only dissociation pathway from its onset at 9. 17 eV up to at least 12 eV. An activation energy of 1. 64 ± 0. 06 eV with an assumed activation entropy of + 1. 8 ± 4 cal/mol-K is derived from fitting the statistical theory decay rates to the measured rates. The transition state energy lies ≈ 1 eV below the thermochemical dissociation limit to the C 2 H+ 5 + C 6 H 5 O· products. It is thus unlikely that an ion-radical complex is involved in the production of the phenol ion...|$|R
40|$|Accepted??? Received????; in {{original}} form We present the photometric calibration of the Swift UltraViolet/Optical Telescope (UVOT) which includes: optimum photometric and background apertures, effective area curves, colour transformations, conversion factors for count rates to flux, and the photometric zero points (which are accurate to better than 4 per cent) {{for each of}} the seven UVOT broadband filters. The calibration was performed with observations of standard stars and standard star fields that represent a wide range of spectral star types. The calibration results include the position dependent uniformity, and instrument response over the 1600 – 8000 ˚A operational range. Because the UVOT is a photon counting instrument, we also discuss the effect of <b>coincidence</b> <b>loss</b> on the calibration results. We provide practical guidelines for using the calibration in UVOT data analysis. The results presented here supersede previous calibration results...|$|E
40|$|The Swift UVOT grisms (uv: 170 - 500 nm; visible: 285 - 660 nm) {{spectral}} data reduction package is {{a replacement for}} the uvotimgrism Ftool from the HEADAS Swift software. This requires a recent HEADAS Swift installation and CALDB as available from HEASARC. Recently the <b>coincidence</b> <b>loss</b> correction was redeveloped and is now formulated in a fully consistent manner to the theory as used successfully for point sources. Updates to the calibration files were made consistent with the reformulated correction. Recent software updates have been described in the Release notes for 2. 1. 0. Tthe latest calibration files that were missing in the previous versions were added in 2. 1. 1, while 2. 12 and 2. 13 fixes small typos affecting the uvotgrism script and output. Documentation sources are described in the Readme {{as well as how}} to cite this software...|$|E
40|$|We {{present the}} {{photometric}} calibration of the Swift UltraViolet/Optical Telescope (UVOT) which includes: optimum photometric and background apertures, effective area curves, colour transformations, conversion factors for count rates to flux, and the photometric zero points (which are accurate to better than 4 per cent) {{for each of}} the seven UVOT broadband filters. The calibration was performed with observations of standard stars and standard star fields that represent a wide range of spectral star types. The calibration results include the position dependent uniformity, and instrument response over the 1600 - 8000 A operational range. Because the UVOT is a photon counting instrument, we also discuss the effect of <b>coincidence</b> <b>loss</b> on the calibration results. We provide practical guidelines for using the calibration in UVOT data analysis. The results presented here supersede previous calibration results. Comment: Minor improvements after referees report. Accepted for publication in MNRA...|$|E
40|$|Source: [URL] Toya Maru {{might have}} been the end of me. The train ferry lost power and turned over in a typhoon between the islands of Honshu and Hokkaido. More than a {{thousand}} people died at sea that night. I was lucky. Our battalion had been ordered, at the last minute, to remain on the northern island and bivouac in the pristine Imperial National Forest. "The vessel carried soldiers of the United States First Cavalry Division transferring from Hokkaido to new posts on Honshu," reported The New York Times on 27 September 1954. "The typhoon did widespread damage over the main islands of Japan. " The Toya Maru carried my typewriter and copies of my first stories to the bottom of Tsugaru Strait. I was wise to haiku that summer and would tote no more than a notebook. Naturally, that <b>coincidence,</b> and the <b>loss</b> of my typewriter, were trivial at the time...|$|R
30|$|Small animal PET FDG imaging was {{conducted}} with the InveonTM DPET small animal scanner (Siemens, Knoxville, TN, USA). Mice (TGwt n = 3, TGmut n = 7) were scanned under anesthetic (1 % to 2 % isoflurane, 2 to 2.5 mL/min oxygen) at baseline and 1 week later, 30 min following an acute intraperitoneal injection with short-acting insulin (8 mU/g body weight; Novolin ge Toronto, Novo Nordisk, Denmark) [15]. A 60 -min list-mode acquisition was started together with a 10 - to 20 -s tail vein injection of FDG (25.3 ± 7.9 MBq in 150 μL). List data were sorted into 26 dynamic frames (12 × 10, 3 × 60, 11 × 300 s) and reconstructed using OSEM 3 D with 10 iterations, 16 subsets, and zoom of 2.5 with a 128 × 128 matrix, resulting in 0.35 mm transaxial pixel size. Images were corrected for radioactive decay, random <b>coincidences,</b> and dead-time <b>losses</b> using the vendor software (IAW version 1.5). Blood glucose concentration was measured (mmol/L) prior to FDG injection with a small drop of blood from the saphenous vein using Advantage blood glucose strips (AccuChek, Roche Diagnostics, Laval, QC, Canada).|$|R
40|$|The Associative Memory (AM) chip {{is special}} device that allows to find {{coincidence}} patterns, or just patterns, between the incoming data {{in up to}} 8 parallel streams. The latest AM chip {{has been designed to}} receive silicon clusters generated in 8 layers of the ATLAS silicon detector sensor, to perform parallel track pattern matching at high rate and it will be the core of the FTK project. Data going through each of the busses are compared with a bank of patterns and AM chip looks for matches in each line, like commercial content addressable memory (CAM). The high density of hits expected in the ATLAS inner detector from 2015 put a challenge in the capability of the AM chip in rejecting random coincidences, requiring either an extremely high number of high precision patterns, with increasing costs and complexity of the system, or more flexible solutions. For this reason in the most recent prototype of the AM chip ternary cells have been added in the logic, allowing “don’t care” (DC) bits in the match. Having DC-bits in the least significant bits of the match allows to change the precision of the match, varying the resolution of the match for each pattern and each detector layer. In order to tune the use of the DC-bits we have carried out detailed simulation studies to define: 1) the best procedure to build the pattern bank and set the DC bits to obtain the best rejection of random <b>coincidences</b> without <b>loss</b> in efficiency 2) the best precision that satisfies the hardware constraints with the expected pileup conditions. We will present the result we have obtained and methods we have developed to train and generate the pattern bank and setup the DC-bits content up to 3 bits, showing how this affects the system performance in terms of dataflow within the system and efficiency in the track reconstruction. We will also present preliminary results for new ideas that in the future will allow to use more DC-bits...|$|R
40|$|Eberline's new microoomputer-based {{radiation}} survey instrument, Model ESP-I, {{is designed to}} correct for <b>coincidence</b> <b>loss</b> and thus extend the range of each detector probe. It provides an "OVERRAN(G " display when the ooincidence correction factor emceeds 5 or when the count rate exceeds 2. 5 X 106 cpm. With Eberline's HP- 290 probe, this indication should occur at about 80 R/h, and it is triggered when the count rate from the GM tube exceeds 2. 5 X 106 cpF. We have discovered {{that some of the}} (24 tubes which can be used in the HP- 290 probe may not reach 2. 5 X 106 cpm. In such cases, the detector probe can be in a radiation field considerably above 80 R/h and still provide a reading below 80 R/h. Replacement tubes that have not been selected in accordance with Eberline's overrange criterion my create this problem even if the original GM tube functioned properly. We recommend that you take {{one or more of the}} following precautions if you are using a HP- 290 probe with an ESP-l...|$|E
40|$|The Ultraviolet/Optical Telescope (UVOT) is one {{of three}} {{instruments}} onboard the Swift observatory. The photometric calibration has been published, and this paper follows up with details on other aspects of the calibration including a measurement of the point spread function with an assessment of the orbital variation and the effect on photometry. A correction for large scale variations in sensitivity over the field of view is described, as well as a model of the <b>coincidence</b> <b>loss</b> which is used to assess the coincidence correction in extended regions. We have provided a correction for the detector distortion and measured the resulting internal astrometric accuracy of the UVOT, also giving the absolute accuracy with respect to the International Celestial Reference System. We have compiled statistics on the background count rates, and discuss the sources of the background, including instrumental scattered light. In each case we describe any impact on UVOT measurements, whether any correction is applied in the standard pipeline data processing or whether further steps are recommended. Comment: Accepted for publication in MNRAS. 15 pages, 21 figures, 4 table...|$|E
40|$|NASA is {{investigating}} {{the application of the}} Phase Doppler measurement technique to provide improved drop sizing and liquid water content measurements in icing research. The magnitude of counting errors were analyzed because these errors contribute to inaccurate liquid water content measurements. The Phase Doppler Particle Analyzer counting errors due to data transfer losses and coincidence losses were analyzed for data input rates from 10 samples/sec to 70, 000 samples/sec. Coincidence losses were calculated by determining the Poisson probability of having more than one event occurring during the droplet signal time. The magnitude of the <b>coincidence</b> <b>loss</b> can be determined, and for less than a 15 percent loss, corrections can be made. The data transfer losses were estimated for representative data transfer rates. With direct memory access enabled, data transfer losses are less than 5 percent for input rates below 2000 samples/sec. With direct memory access disabled losses exceeded 20 percent at a rate of 50 samples/sec preventing accurate number density or mass flux measurements. The data transfer losses of a new signal processor were analyzed and found to be less than 1 percent for rates under 65, 000 samples/sec...|$|E
6000|$|These things {{made their}} whole {{relation}} so impersonal that they hadn’t the rules or reasons people found in ordinary friendships. They didn’t {{care for the}} things it was supposed necessary to care for in the intercourse of the world. They ended one day—they never knew which of them expressed it first—by throwing out {{the idea that they}} didn’t care for each other. Over this idea they grew quite intimate; they rallied to {{it in a way that}} marked a fresh start in their confidence. If to feel deeply together about certain things wholly distinct from themselves didn’t constitute a safety, where was safety to be looked for? Not lightly nor often, not without occasion nor without emotion, any more than in any other reference by serious people to a mystery of their faith; but when something had happened to warm, as it were, the air for it, they came as near as they could come to calling their Dead by name. They felt it was coming very near to utter their thought at all. The word “they” expressed enough; it limited the mention, it had a dignity of its own, and if, in their talk, you had heard our friends use it, you might have taken them for a pair of pagans of old alluding decently to the domesticated gods. They never knew—at least Stransom never knew—how they had learned to be sure about each other. If it had been with each a question of what the other was there for, the certitude had come in some fine way of its own. Any faith, after all, has the instinct of propagation, and it was as natural as it was beautiful that they should have taken pleasure on the spot in the imagination of a following. If the following was for each but a following of one it had proved in the event sufficient. Her debt, however, of course was much greater than his, because while she had only given him a worshipper he had given her a splendid temple. Once she said she pitied him for the length of his list—she had counted his candles almost as often as himself—and this made him wonder what could have been the length of hers. He had wondered before at the <b>coincidence</b> of their <b>losses,</b> especially as from time to time a new candle was set up. On some occasion some accident led him to express this curiosity, and she answered as if in surprise that he hadn’t already understood. “Oh for me, you know, the more there are the better—there could never be too many. I should like hundreds and hundreds—I should like thousands; I should like a great mountain of light.” ...|$|R
40|$|The {{prevailing}} unqualified use of {{the term}} â€œdead timeâ€•is ambiguous. The term must be defined, and the values measured and applied for data correction in a manner consistent either with a paralyzable or with a nonparalyzable system. To clearly maintain this distinction, we use r for the deadtime of a para lyzable system and T for that of a nonparalyzable one. In either system, deadtime varies with a number of factors which include counting rate, analyzer win dow width, scatter, and {{the presence or absence of}} a collimator. It may also vary slightly with source posi tion. â€œDeadtimeâ€•may be considered a term of mathematical convenience for the correction of all sources of <b>coincidence</b> <b>loss</b> from an entire scintilla tion camera and data-processing system. The nu merical values of deadtime may be considerably greater than indicated from oscilloscope wave forms. We have developed a two-source method protocol for the measurement of deadtime (1). For mathe matical convenience the system is treated as non paralyzable (2). The protocol is rapid, accurate, and eliminates error from radioactive decay when em ploying short-lived sources such as oomTc or 113 In. On request, the authorswill be pleased to. provid...|$|E
40|$|Swift/UVOT has the {{capability}} to provide critical insight into the physics of the early afterglows of gamma-ray bursts (GRBs). But without precise calibration of the UVOT to standard photometric systems, {{it is impossible to}} leverage late-time, ground-based follow-up data to the early-time UVOT observations. In this paper we present an empirical determination of the photometric zero points and the optimal photometry parameters to analyze U-, B-, and V-band images obtained with Swift/UVOT. We base our analysis on aperture photometry performed on the local standard stars in the field of SN 2005 am and Landolt standards. We achieve a consistency of about 0. 05 mag between the UVOT photometry and our ground-based calibration when the photometry aperture radius is small (2 ". 5 for unbinned data, 3 ". 0 for 2 x 2 binned data), and when a correction factor is applied to the measured instrumental magnitudes. Preliminary photometry corrections caused by the <b>coincidence</b> <b>loss</b> for bright stars are estimated. A step-by-step photometry procedure is also presented. We analyze the UVOT UBV photometry of SN 2005 am, and find that the UVOT photometry is generally consistent with the ground-based observations. We discuss the limitations of our photometric calibrations and the possible causes of the correction factor. There is also an intrinsic scatter of about 0. 04 [...] 0. 06 mag in our final UVOT photometry that cannot be easily accounted for and removed...|$|E
40|$|Abridged] We {{present an}} {{integrated}} photometric spectral energy distribution (SED) of the Magellanic-type galaxy NGC 4449 from the far-ultraviolet (UV) to the submillimetre, including new observations {{acquired by the}} Herschel Space Observatory. We include integrated UV photometry from the Swift Ultraviolet and Optical Telescope using a measurement technique which is appropriate for extended sources with <b>coincidence</b> <b>loss.</b> In this paper, we examine the available multiwavelength data to infer a range of ages, metallicities and star formation rates for the underlying stellar populations, {{as well as the}} composition and the total mass of dust in NGC 4449. We present an iterative scheme, which allows us to build an in-depth and multicomponent representation of NGC 4449 `bottom-up', taking advantage of the broad capabilities of the photoionization and radiative transfer code MOCASSIN (MOnte CArlo SimulationS of Ionized Nebulae). We fit the observed SED, the global ionization structure and the emission line intensities, and infer a recent SFR of 0. 4 Msolar/yr and a total stellar mass of approximately 1 e 9 Msolar emitting with a bolometric luminosity of 5. 7 e 9 Lsolar. Our fits yield a total dust mass of 2. 9 e 6 Msolar including 2 per cent attributed to polycyclic aromatic hydrocarbons. We deduce a dust to gas mass ratio of 1 / 190 within the modelled region. While we do not consider possible additional contributions from even colder dust, we note that including the extended HI envelope and the molecular gas is likely to bring the ratio down to as low as ~ 1 / 800. Comment: 22 pages, 11 figures, 8 tables, published in MNRAS, 431, 2493 (2013...|$|E
40|$|The {{dynamic range}} of the XMM-Newton Optical Monitor (XMM-OM) is limited at the bright end by <b>coincidence</b> <b>loss,</b> the {{superposition}} of multiple photons in the individual frames recorded from its micro-channel-plate (MCP) intensified charge-coupled device (CCD) detector. One way to overcome this limitation is to use photons that arrive during the frame transfer of the CCD, forming vertical read-out streaks for bright sources. We calibrate these read-out streaks for photometry of bright sources observed with XMM-OM. The bright source limit for read-out streak photometry is set by the recharge time of the MCPs. For XMM-OM {{we find that the}} MCP recharge time is 0. 55 ms. We determine that the effective bright limits for read-out streak photometry with XMM-OM are approximately 1. 5 magnitudes brighter than the bright source limits for normal aperture photometry in full-frame images. This translates into bright-source limits in Vega magnitudes of UVW 2 = 7. 1, UVM 2 = 8. 0, UVW 1 = 9. 4, U= 10. 5, B= 11. 5, V= 10. 2 and White= 12. 5 for data taken early in the mission. The limits brighten by up to 0. 2 magnitudes, depending on filter, {{over the course of the}} mission as the detector ages. The method is demonstrated by deriving UVW 1 photometry for the symbiotic nova RR Telescopii, and the new photometry is used to constrain the e-folding time of its decaying UV emission. Using the read-out streak method, we obtain photometry for 50 per cent of the missing UV source measurements in version 2. 1 of the XMM-Newton Serendipitous UV Source Survey (XMM-SUSS 2. 1) catalogue. Comment: Accepted for publication in MNRA...|$|E
40|$|We {{present an}} {{integrated}} photometric spectral energy distribution (SED) of the Magellanic-type galaxy NGC 4449 from the far-ultraviolet (UV) to the submillimetre, including new observations {{acquired by the}} Herschel Space Observatory. We include integrated UV photometry from the Swift Ultraviolet and Optical Telescope using a measurement technique which is appropriate for extended sources with <b>coincidence</b> <b>loss.</b> In this paper, we examine the available multiwavelength data to infer a range of ages, metallicities and star formation rates for the underlying stellar populations, {{as well as the}} composition and the total mass of dust in NGC 4449. Our analysis of the global optical spectrum of NGC 4449 fitted using the spectral fitting code STARLIGHT suggests that the majority of stellar mass resides in old (≳ 1 Gyr old) and metal-poor (Z/Z⊙ ∼ 0. 2) populations, with the first onset of star formation activity deduced to have taken place at an early epoch, approximately 12 Gyr ago. A simple chemical evolution model, suitable for a galaxy continuously forming stars, suggests a ratio of carbon to silicate dust mass comparable to that of the Large Magellanic Cloud over the inferred time-scales. We present an iterative scheme, which allows us to build an in-depth and multicomponent representation of NGC 4449 ‘bottom-up’, taking advantage of the broad capabilities of the photoionization and radiative transfer code MOCASSIN (MOnte CArlo SimulationS of Ionized Nebulae). We fit the observed SED, the global ionization structure and the emission line intensities, and infer a recent star formation rate of 0. 4 M⊙[*]yr− 1 and a total stellar mass of ≈ 1 × 109 [*]M⊙ emitting with a bolometric luminosity of 5. 7 × 109 [*]L⊙. Our fits yield a total dust mass of 2. 9 ± 0. 5 × 106 [*]M⊙ including 2 [*]per[*]cent attributed to polycyclic aromatic hydrocarbons. We deduce a dust to gas mass ratio of 1 / 190 within the modelled region. While we do not consider possible additional contributions from even colder dust, we note that including the extended H I envelope and the molecular gas is likely to bring the ratio down to as low as ∼ 1 / 800...|$|E
40|$|International audienceWe {{present an}} {{integrated}} photometric spectral energy distribution (SED) of the Magellanic-type galaxy NGC 4449 from the far-ultraviolet (UV) to the submillimetre, including new observations {{acquired by the}} Herschel Space Observatory. We include integrated UV photometry from the Swift Ultraviolet and Optical Telescope using a measurement technique which is appropriate for extended sources with <b>coincidence</b> <b>loss.</b> In this paper, we examine the available multiwavelength data to infer a range of ages, metallicities and star formation rates for the underlying stellar populations, {{as well as the}} composition and the total mass of dust in NGC 4449. Our analysis of the global optical spectrum of NGC 4449 fitted using the spectral fitting code STARLIGHT suggests that the majority of stellar mass resides in old (greater than or similar to 1 Gyr old) and metal-poor (Z/Z(circle dot) similar to 0. 2) populations, with the first onset of star formation activity deduced to have taken place at an early epoch, approximately 12 Gyr ago. A simple chemical evolution model, suitable for a galaxy continuously forming stars, suggests a ratio of carbon to silicate dust mass comparable to that of the Large Magellanic Cloud over the inferred time-scales. We present an iterative scheme, which allows us to build an in-depth and multicomponent representation of NGC 4449 `bottom-up', taking advantage of the broad capabilities of the photoionization and radiative transfer code MOCASSIN (MOnte CArlo SimulationS of Ionized Nebulae). We fit the observed SED, the global ionization structure and the emission line intensities, and infer a recent star formation rate of 0. 4 M-circle dot yr(- 1) and a total stellar mass of approximate to 1 x 10 (9) M-circle dot emitting with a bolometric luminosity of 5. 7 x 10 (9) L-circle dot. Our fits yield a total dust mass of 2. 9 +/- 0. 5 x 10 (6) M-circle dot including 2 per cent attributed to polycyclic aromatic hydrocarbons. We deduce a dust to gas mass ratio of 1 / 190 within the modelled region. While we do not consider possible additional contributions from even colder dust, we note that including the extended H I envelope and the molecular gas is likely to bring the ratio down to as low as similar to 1 / 800...|$|E

