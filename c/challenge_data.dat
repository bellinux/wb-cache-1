244|5869|Public
5000|$|From 2014 digital <b>challenge</b> <b>data,</b> NetSafe {{identified}} 3 {{key issues}} that NZ small businesses {{need to be}} aware of: ...|$|E
50|$|Since the NHTS-PR is {{technically}} an information management system, {{it is very}} reliant on technology. It uses Open Technologies as the primary software backbone and the latest multiple processor servers available at the time. A major challenge inherent to data sharing is porting since different agencies are using different proprietary software. To overcome such <b>challenge,</b> <b>data</b> porting software are developed in-house from existing Open Source systems.|$|E
50|$|In the new program, Dr. Pulaski is kidnapped, and Data investigates. They soon {{discover}} that Professor Moriarty is responsible, {{but when they}} find him with Pulaski in his hideout, they are shocked when they learn that Moriarty {{is aware of the}} Holodeck program being a simulation, and is able to access the Holodeck computer, showing them a sketch of the Enterprise he has drawn based on the computer's description. Data and Geordi leave the Holodeck to alert the Captain, and Geordi realizes that when he asked the computer to create the program he had asked for an adversary who could defeat Data, not Sherlock Holmes; as a result, the computer gave the Holodeck character Professor Moriarty the knowledge and sentience needed to <b>challenge</b> <b>Data.</b> When Moriarty gains access to the ship's stabilizer controls, Data returns to the Holodeck with Captain Picard.|$|E
5000|$|... 2. Creation of a {{more fair}} and {{transparent}} process for individuals who are <b>challenging</b> <b>data</b> that has been processed by INTERPOL.|$|R
5000|$|Challenges: Consistently {{across the}} years, dirty data, {{explaining}} data mining to others, and difficult {{access to data}} are the top <b>challenges</b> <b>data</b> miners report facing. Participants in the 2010 survey shared best practices for overcoming these challenges.|$|R
5000|$|Data Mining & Information Analysis: Integrates the collection, analysis, and {{visualization}} of complex data and its {{critical role in}} research, business, and government {{to provide students with}} practical skills and a theoretical basis for approaching <b>challenging</b> <b>data</b> analysis problems.|$|R
40|$|Abstract. The VOLCANO’ 09 Challenge invited {{participants}} {{to evaluate the}} change in size of pulmonary nodules in CT images; the <b>challenge</b> <b>data</b> set consisted of 50 pairs of CT scans each scan containing a single nodule. This is the first challenge for CAD methods on pulmonary nodules in which size change rather than volume estimation is the primary endpoint. Responses from 13 teams were received with size change results {{for a total of}} 17 different methods. In this paper the <b>challenge</b> <b>data</b> set is described and statistical results computed from the submissions are presented. The dataset consisted of several subgroups: (a) zero-change cases, cases with different slice thickness scans...|$|E
40|$|This paper {{presents}} a localized coarse-to-fine algorithm for efficient and accurate pedestrian localization and silhouette extraction for the Gait <b>Challenge</b> <b>data</b> sets. The coarse detection phase {{is simple and}} fast. It locates the target quickly based on temporal differences and some knowledge on the human target. Based on this coarse detection, the fine detection phase applies a robust background subtraction algorithm to the coarse target regions and the detection obtained is further processed to produce the final results. This algorithm has been tested on 285 outdoor sequences from the Gait <b>Challenge</b> <b>data</b> sets, with wide variety of capture conditions. The pedestrian targets are localized very well and silhouettes extracted resemble the manually labeled silhouettes closely. 1...|$|E
30|$|In addition, <b>challenge</b> <b>data</b> such as {{the total}} of rewards, the start of registration, and the {{required}} technologies were also collected and stored. In the platform, each challenge may require multiple technologies. Therefore, we collected and mapped the association between technology and challenge as a many-to-many relationship.|$|E
50|$|These two {{approaches}} are not incompatible; better in vitro systems provide better data to mathematical models. However, increasingly sophisticated in vitro experiments collect increasingly numerous, complex, and <b>challenging</b> <b>data</b> to integrate. Mathematical models, such as systems biology models, are much needed here.|$|R
40|$|This paper {{presents}} two novel (GIST and GEST) networks, which combine unsupervised featureextraction and Hebbian learning, {{for tracking}} emergent correlations {{in the evolution}} of spatiotemporal distributions. The networks were successfully tested on the <b>challenging</b> <b>Data</b> Mapping problem, using an execution driven simulation of their implementation in hardware. ...|$|R
50|$|The {{human genome}} {{consists}} of approximately 3 billion DNA base pairs and {{is estimated to}} carry around 20,000 protein coding genes. In designing the study the consortium needed to address several critical issues regarding the project metrics such as technology <b>challenges,</b> <b>data</b> quality standards and sequence coverage.|$|R
40|$|This report {{presents}} the results of the 2006 PASCAL Visual Object Classes Challenge (VOC 2006). Details of the <b>challenge,</b> <b>data,</b> and evaluation are presented. Participants in the challenge submitted descriptions of their methods, and these have been included verbatim. This document should be considered preliminary, and subject to change...|$|E
3000|$|... 50, a {{particular}} recurrent neural network architecture called BLSTM [36] is trained with these features {{to provide an}} estimation every 10 ms. Since REVERB <b>Challenge</b> <b>data</b> assumes that the room acoustic properties remain unchanged within each utterance, only the temporal average for each utterance of all per frame estimations is considered.|$|E
40|$|This paper {{proposes a}} {{hierarchical}} text categorization (TC) approach to encoding free-text clinical notes with ICD- 9 -CM codes. Preliminary experimental result on the 2007 Computational Medicine <b>Challenge</b> <b>data</b> shows a hierarchical TC system {{has achieved a}} microaveraged F 1 value of 86. 6, which {{is comparable to the}} performance of state-of-the-art flat classification systems. ...|$|E
40|$|Intrathoracic solitary fibrous tumor (SFT) {{is a rare}} disease. Radical {{resection}} is {{the standard}} of care. However, estimating prognosis and planning follow-up and treatment strategies remains <b>challenging.</b> <b>Data</b> were retrospectively collected by five international centers to explore outcome and biomarkers for predicting event-free-survival (EFS). 125 histological proven SFT patients (74 female; 59. 2...|$|R
50|$|The two {{approaches}} {{can be applied}} simultaneously allowing in vitro systems to provide adequate data {{for the development of}} mathematical models. To comply with push for the development of alternative testing methods, increasingly sophisticated in vitro experiments are now collecting numerous, complex, and <b>challenging</b> <b>data</b> that can be integrated into mathematical models.|$|R
5000|$|It is now {{believed}} from a birth certificate, census, war diaries {{and other}} records that John Condon was 18 {{years old at}} the recorded date of his death and that the wrong individual is named on the grave. The headstone in [...] and the CWGC record continue to assert the <b>challenged</b> <b>data.</b>|$|R
40|$|Recently {{the role}} and {{importance}} of database application in supporting the decision making process has been still increasing. Data warehouse can be an answer for this <b>challenge.</b> <b>Data</b> collected in a warehouse deliver different information e. g. about market, demand, selling goods, trends, anomalies on market. The paper presents data warehouse as a potential source of business information...|$|E
40|$|The VOLCANO 0 ̈ 9 Challenge invited {{participants}} {{to evaluate the}} change in size of pulmonary nodules in CT images; the <b>challenge</b> <b>data</b> set consisted of 50 pairs of CT scans each scan containing a single nodule. This is the first challenge for CAD methods on pulmonary nodules in which size change rather than volume estimation is the primary endpoint. Responses from 13 teams were received with size change results {{for a total of}} 17 different methods. In this paper the <b>challenge</b> <b>data</b> set is described and statistical results computed from the submissions are presented. The dataset consisted of several subgroups: (a) zero-change cases, cases with different slice thickness scans, cases with actual size change and a synthetic nodule case. No statistical difference was found between the methods; a slice thickness change was significant and there was an interesting bias observed for some zero-change nodules...|$|E
40|$|To {{assess the}} {{efficacy}} of HIV vaccine candidates or preventive treatment, many research groups have started to challenge monkeys repeatedly with low doses of the virus. Such <b>challenge</b> <b>data</b> provide {{a unique opportunity to}} assess the importance of exposure history for the acquisition of the infection. I developed stochastic models to analyze previously published <b>challenge</b> <b>data.</b> In the mathematical models, I allowed for variation of the animals' susceptibility to infection across challenge repeats, or across animals. In none of the studies I analyzed, I found evidence for an immunizing effect of non-infecting challenges, and in most studies, there is no evidence for variation in the susceptibilities to the challenges across animals. A notable exception was a challenge experiment by Letvin et al. Sci Translat Med (2011) conducted with the strain SIVsmE 660. The <b>challenge</b> <b>data</b> of this experiment showed significant susceptibility variation from animal-to-animal, which is consistent with previously established genetic differences between the involved animals. For the studies which did not show significant immunizing effects and susceptibility differences, I conducted a power analysis and could thus exclude a very strong immunization effect for some of the studies. These findings validate the assumption that non-infecting challenges do not immunize an animal - an assumption that is central in the argument that repeated low-dose challenge experiments increase the statistical power of preclinical HIV vaccine trials. They are also relevant for our understanding of the role of exposure history for HIV acquisition and forecasting the epidemiological spread of HIV...|$|E
30|$|Besides {{technical}} <b>challenges,</b> <b>data</b> {{collection is}} one of the main issues for research on surveillance systems. Privacy laws or policies may prevent surveillance footage being used for research even if the video is already being used for security monitoring. Careful consultation and negotiation should be carried out before any real-life trials of intelligent surveillance systems.|$|R
40|$|Paperback is not available. Overcoming many <b>challenges,</b> <b>data</b> mining {{has already}} {{established}} discipline capability in many domains. “This book provides readers {{the current state}} of knowledge, research results, and innovations in data mining, from different aspects such as techniques, algorithms, and applications, and introduces current development in this area. ”- ABM Shawkat Ali, Central Queenslan...|$|R
40|$|Electronic {{government}} is a challenging domain for software engineering, with complex requirements involving agility,transparency, accuracy, and accessibility. The techniques of semantic frameworks —metadata-based, model-driven development—may help to address these <b>challenges.</b> <b>Data</b> semantics and model transformations are prime application areas for formal methods, and so electronic {{government is}} an exciting new domain for education and training in formal methods...|$|R
40|$|Poster Presentation 9 BACKGROUND AND AIMS: Chromosomal {{microarray}} (CMA) {{has emerged}} as a major tool to identify unbalanced chromosomal aberrations in children and is recommended as the first tiered investigation for intellectual disability, autism spectrum disorders and multiple congenital anomalies. While the clinical interpretation and genetic counseling remain as ongoing <b>challenge,</b> <b>data</b> about potential downstream benefits and harms of CMA is lacking, especially in paediatric [...] . postprin...|$|E
40|$|This talk {{addresses}} {{the next big}} <b>challenge,</b> <b>data</b> sharing of research data – not necessarily tied to journal publication. Addressing the international research landscape where funding agencies have begun to require research data management plans, the talk discusses what steps an academic institution can begin taking, the stakeholders {{who need to be}} at the table, the challenges faced, and the lessons learned thus far...|$|E
40|$|This work {{presents}} {{our team}} solution for task 4 a (Message Polarity Classification) at the SemEval 2016 challenge. Our experiments {{have been carried}} out over the Twitter dataset provided by the challenge. We follow a supervised approach, exploiting a SVM polynomial kernel classifier trained with the <b>challenge</b> <b>data.</b> The classifier takes as input advanced NLP features. This paper details the features and discusses the achieved results...|$|E
40|$|International audienceSegmentation is a {{fundamental}} problem in medical image analysis. The use of prior knowledge is often considered to address the ill-posedness of the process. Such a process consists in bringing all training examples in the same reference pose, and then building statistics. During inference, pose parameters are usually estimated first, and then one seeks a compromise between data-attraction and model-fitness with the prior model. In this paper, we propose a novel higher-order Markov Random Field (MRF) model to encode pose-invariant priors and perform 3 D segmentation of <b>challenging</b> <b>data.</b> The approach encodes data support in the singleton terms that are obtained using machine learning, and prior constraints in the higher-order terms. A dual-decomposition-based inference method is used to recover the optimal solution. Promising results on <b>challenging</b> <b>data</b> involving segmentation of tissue classes of the human skeletal muscle demonstrate the potentials of the method...|$|R
40|$|Abstract. Electronic {{government}} is a challenging domain for software engineering, with complex requirements involving agility, transparency, accuracy, and accessibility. The techniques of semantic frameworks— metadata-based, model-driven development—may help to address these <b>challenges.</b> <b>Data</b> semantics and model transformations are prime application areas for formal methods, and so electronic {{government is}} an exciting new domain for education and training in formal methods. ...|$|R
40|$|The {{vast amount}} of data {{available}} on the Internet introduces new <b>challenging</b> <b>data</b> quality problems, such as accessibility and usability. Low information quality is common in various Web applications, including Web 2. 0 tools. Consequently, information quality on the Internet {{is one of the}} most crucial requirements for an effective use of data from the Web and pervasive deployment of Web-based applications...|$|R
40|$|Abstract. The {{hepatitis}} database {{contains the}} results of laboratory examinations taken on the patients of hepatitis B and C during 1982 - 2001, and recently was given to <b>challenge</b> <b>data</b> mining research. This paper presents our approach to two problems of distinguishing hepatitis B and C, and the relations between laboratory data and fibrosis stages. The approach is based on temporal abstraction and the visual data mining system D 2 MS. ...|$|E
40|$|With the {{advances}} in telecommunications, {{and the introduction}} of the Internet, information systems achieved physical connectivity, but have yet to establish logical connectivity. Lack of logical connectivity is often inviting disaster {{as in the case of}} Mars Orbiter, which was lost because one team used metric units, the other English while exchanging a critical maneuver data. In this Thesis, we focus on the two intertwined sub problems of logical connectivity, namely data extraction and data interpretation in the domain of heterogeneous information systems. The first <b>challenge,</b> <b>data</b> extraction, is about making it possible to easily exchange data among semi-structured and structured information systems. We describe the design and implementation of a general purpose, regular expression based Camdldon wrapper engine with an integrated capabilities-aware planner/optimizer/executioner. The second <b>challenge,</b> <b>data</b> interpretation, deals with the existence of heterogeneous contexts, whereby each source of information and potential receiver of that information may operate with a different context, leading to large-scale semantic heterogeneity. We extend the existing formalization of the COIN framework with new logical formalisms and features to handle large...|$|E
40|$|The {{submission}} {{related to}} this article was awarded the First Prize at the associated tractography challenge. International audienceIn this paper, we present a tractography paradigm that addresses the challenge of tracking through edema as well as regions of complex white matter. It involves the fitting of a multi-compartment model to a multi-shell acquisition, with one compartment pertaining to free water that characterizes the edema, and the second compartment, a higher order diffusion model that captures the underlying fiber structure. This is then incorporated into a probabilistic streamline tracking algorithm. This paradigm has been validated using cortical stimulation data acquired on patients. We applied the tracking paradigm to the datasets of the MICCAI Tractography Challenge. As the data comprised four shells, b = 200, 500, 1000 and 3000 s/mm 2 respectively, {{we were able to}} successfully fit a two-compartment model to the data that combines edema correction with a fiber orientation distribution (FOD) scheme to create a new higher order diffusion model. We then used this higher order diffusion model for tracking the cortico-spinal tract (CST) in the two patients with brain tumor. The tract was reconstructed using inclusion regions in the cerebral peduncle provided with the <b>Challenge</b> <b>data,</b> as well as regions defining the motor cortex segmented in the two subjects using an atlas. The results of fiber tracking showed {{that we were able to}} track through the edema, as well as complex white matter to reconstruct the CST, obtaining not only the main trunk of the CST, but also the lateral fibers to the hand and face regions. The results on the <b>Challenge</b> <b>data</b> were evaluated for anatomical correctness by two neurosurgeons, as well as for overlap with the motor strip provided with the <b>Challenge</b> <b>data...</b>|$|E
3000|$|RQ 6. Is it {{possible}} to differentiate hyperspecialists and non-specialists based on <b>challenges</b> participation <b>data?</b> [...]...|$|R
5000|$|RealStream Real-World <b>Challenges</b> for <b>Data</b> Stream Mining Workshop-Discussion at the ECML PKDD 2013, Prague, Czech Republic.|$|R
30|$|Finally, {{although}} {{the development of}} an algorithm that can reduce the detrimental effect of reverberation {{is considered one of the}} toughest remaining challenges in this research field, the REVERB challenge confirmed that significant progress has recently been made and has identified a number of effective and practical solutions. We are confident that the <b>challenge’s</b> <b>data</b> and achievements will fuel future research on reverberant speech enhancement and recognition.|$|R
