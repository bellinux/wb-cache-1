132|118|Public
500|$|The use {{of motion}} capture {{to control the}} {{position}} and orientation of a virtual camera enables the operator to intuitively move and aim the virtual camera by simply walking about and turning the virtual <b>camera</b> <b>rig.</b> [...] A virtual <b>camera</b> <b>rig</b> consists of a portable monitor or tablet device, motion sensors, optional support framework, and optional joystick or button controls that are commonly used to start or stop recording and adjust lens properties. [...] In 1992, Michael McKenna of MIT's Media Lab demonstrated the earliest documented virtual <b>camera</b> <b>rig</b> when he fixed a Polhemus magnetic motion sensor and a 3.2 inch portable LCD TV to a wooden ruler. [...] The Walkthrough Project at the University of North Carolina at Chapel Hill produced a number of physical input devices for virtual camera view control including dual three-axis joysticks and a billiard-ball shaped prop known as the UNC Eyeball that featured an embedded six-degree of freedom motion tracker and a digital button.|$|E
500|$|MPC {{handled the}} visual effects for the [...] "Smallville encounter" [...] sequence. Before {{providing}} the visual effects, the shots were previsualized {{for the fight}} choreography. After the previsualizations, live action portions of the scene would be filmed in small pieces. [...] "If say Superman was being punched and would land 50 meters away, we would shoot our start position and end position, and then bridge that gap with the CG takeovers," [...] says Guillaume Rocheron, the MPC visual effects supervisor. A <b>camera</b> <b>rig</b> would then obtain key frames of the choreographed actor. [...] "It's a six-still <b>camera</b> <b>rig</b> that's built on a pipe rig {{so that you can}} run it in {{at the end of a}} setup and get stills of key frames of a performance or an expression," [...] said Desjardin, [...] "and then we could use those hi-res stills to project onto the CG double and get really accurate transition lighting and color—right from the set." ...|$|E
500|$|Several {{aspects of}} Within the Woods were later {{presented}} in future Raimi films, {{including the use}} of the [...] "Raimi-cam", a <b>camera</b> <b>rig</b> that creates a fluent flow of camera movement. Other elements, such as graphic imagery, bleak endings, and mutilations, defined many of Raimi's other films. Raimi has put Campbell in cameo roles in all three of Raimi's Spider-Man trilogy, as well as several other films.|$|E
40|$|Start Race. zip: codec mp 4 (60 MB/S), {{taken from}} 7 <b>camera</b> GOPRO <b>rig,</b> raw {{material}} suitable for stitching software (Videostitch) 	 	 	Bend in the climb: codec mp 4 (60 MB/S), taken from 7 <b>camera</b> GOPRO <b>rig,</b> raw material suitable for stitching software (Videostitch) 	 	 	Bend 2. zip: codec mp 4 (60 MB/S), taken from 7 <b>camera</b> GOPRO <b>rig,</b> raw material suitable for stitching software (Videostitch...|$|R
50|$|On December 30, 2010, NewTek shipped LightWave 10. It {{added an}} {{interactive}} viewport renderer (VPR), interactive stereoscopic <b>camera</b> <b>rigs,</b> linear color-space workflow, real time interactive physical teleoperation input (Virtual Studio Tools), and data interchange upgrades.|$|R
50|$|Kerner also {{continued}} {{several years of}} significant research and development {{in the areas of}} 3D <b>camera</b> <b>rigs</b> and consumer products. Kerner's creature shop manufactured lifelike, servo-controlled dummies with simulated injuries used for training military medics.|$|R
500|$|On set, a <b>camera</b> <b>rig</b> {{was used}} to capture the {{environment}} of the sequence. Dubbed [...] "enviro-cam", the visual effects crew would mount a Canon EOS 5D and a motorized nodal head, allowing the crew to capture the environment at a 360-degree angle with 55k resolution for every shot, the process would take approximately two to four minutes. The set capture resulted in lighting and textures that could be reprojected onto geometry. Full-screen digital doubles were a major component for the fighting sequences. Digital armor was also added, along with the energy-based Kryptonian helmets. Cyberscan and FACS were conducted with the actors, and polarized and non-polarized reference photos were taken. Superman's cape and costume were scanned in high detail—the cape in particular became a direct extensions of Superman's actions.|$|E
500|$|Cuarón's initial {{idea for}} {{maintaining}} continuity during the roadside ambush scene was dismissed by production experts as an [...] "impossible shot to do". Fresh from the visual effects-laden Harry Potter and the Prisoner of Azkaban, Cuarón suggested using computer-generated imagery to film the scene. Lubezki {{refused to allow}} it, reminding the director that they had intended {{to make a film}} akin to a [...] "raw documentary". Instead, a special <b>camera</b> <b>rig</b> invented by Gary Thieltges of Doggicam Systems was employed, allowing Cuarón to develop the scene as one extended shot. A vehicle was modified to enable seats to tilt and lower actors {{out of the way of}} the camera, and the windshield was designed to tilt out of the way to allow camera movement in and out through the front windscreen. A crew of four, including the director of photography and camera operator, rode on the roof.|$|E
500|$|U2 3D {{production}} {{featured the}} first 3D multiple-camera setup and was shot using every digital 3D camera and recording deck in existence. The crew had {{two days to}} set up the filming equipment before each concert, which required running optical fiber cables and hooking up an electrical generator to supply power at each venue. The filming equipment consisted of nine custom-built 3D rigs. The project's large scale prompted 3ality Digital to work with director James Cameron—their chief competitor at the time. 3ality used their own 3flex TS1 camera rigs for filming, in addition to five Fusion 3D rigs, designed by Cameron and camera operator Vincent Pace. [...] A total of 18 Sony CineAlta HDC-F950 cameras were used for filming, with two cameras on each rig. The cameras were fitted with Zeiss digital zoom lenses, making U2 3D the first 3D film shot using a zoom lens. One of the Fusion 3D camera rigs was used as a Spydercam and became the first 3D aerial camera. [...] The cameras on each rig were spaced eye-distance apart to create a 3D effect in post-production. Using a beam splitter mounted to the <b>camera</b> <b>rig,</b> one camera shot through a 50/50 mirror, while the other shot the image reflected from that mirror. Each rig weighed an average of [...] All of the concert footage was shot with twin-camera setups, except for the two Melbourne shoots, where a single CineAlta camera with a Steadicam was also used to capture close-ups. The cameras captured high-definition video onto HDCAMSR recording decks, which enabled the crew to capture an entire concert.|$|E
5000|$|Step Up Revolution {{was filmed}} in [...] "native" [...] / [...] "true 3D" [...] without post {{production}} conversion using Red Epic cameras, Zeiss Ultra Prime and Angenieux Optimo DP Lenses and 3ality Technica TS-5 <b>camera</b> <b>rigs</b> and Stereo Image Processor (SIP) technology systems.|$|R
5000|$|... earthmine, inc. is {{a company}} located in Berkeley, California devoted to [...] "indexing reality". The company uses vehicle mounted <b>camera</b> <b>rigs</b> to capture imagery and three {{dimensional}} data of the urban environment. It was founded in 2006 by John Ristevski and Anthony Fassero.|$|R
50|$|Mark Roberts Motion Control {{designs and}} {{manufactures}} motion control equipment (robotic <b>camera</b> <b>rigs)</b> {{for both the}} TV and Film industry. The company, based in Sussex in the UK, received an Academy Award in 1999 for its contribution to the special effects industry in feature films.|$|R
2500|$|The film {{features}} computer-animated {{creatures in}} live-action settings. Live-action footage was filmed in New Zealand {{and in the}} southern part of the U.S. state of Alaska. Director Nightingale said, [...] " [...] have that kind of temperate climate which represents the period very well. The world was a bit warmer then, so they would have had 24 hours of sunshine in the summer and 24 hours of darkness in the winter." [...] Filming began in 2011 in Alaska, where Evergreen Films is headquartered. In the second half of 2011, more than [...] were working out of Evergreen's office in the Alaskan city of Anchorage. While the film's dinosaurs lived in Alaska during the Late Cretaceous period approximately [...] years ago, they lived more in the northern part of the state due to the climate at the time. Filmmakers considered Southeast Alaska's rainforests below the Arctic Circle close to the climate that the dinosaurs experienced, so they filmed there and in Southcentral Alaska. Specific locations included Crow Creek Mine near Girdwood, Alaska and the Kenai Peninsula. In 2012, the state government of Alaska awarded the production companies a subsidy of [...] Additional filming also took place on South Island in New Zealand. For a river chase scene, filming was performed at rapids in New Zealand using a helicopter and with a 3D <b>camera</b> <b>rig</b> in a rubber boat. At the locations, the crew built dinosaur shapes out of PVC drain pipes to give the filmmakers a sense of the dinosaurs' scale when filming the live-action backdrop.|$|E
5000|$|... #Caption: Yilmaz {{with the}} <b>camera</b> <b>rig</b> for the live {{part of the}} show in Paris.|$|E
5000|$|... #Caption: Production shot of Boat Trip 3D {{showing the}} boat {{containing}} the 3D <b>camera</b> <b>rig</b> {{on the right}} ...|$|E
50|$|Born {{and educated}} in Paris, Tcherevkoff came to America {{to visit his}} sister, who was a fashion model, and decided to stay. With a {{signature}} style that defined shapes and bold color, he played with perspective through in-camera effects and outside <b>camera</b> <b>rigging.</b> Tcherevkoff {{attracted the attention of}} an established agent and became successful immediately.|$|R
50|$|Citing {{constraints}} with 3D <b>camera</b> <b>rigs,</b> Aja shot Piranha in 2D {{and converted}} to 3D in post production using a 3D conversion process developed by Michael Roderick {{and used by}} the company, Inner-D. Unlike some other 3D converted films released in 2010, Piranhas conversion was not done as an afterthought, {{and it was one}} of the first post-conversion processes to be well received by critics.|$|R
40|$|This {{stereoscopic}} {{video is}} created using two cameras side-by-side {{to capture the}} left and right eye images. The data is then linked to a LAPTOP live to analyse the convergence and seperation. Shooting with two cameras might complicates the production and post-production process but speciallise equipment <b>cameras,</b> <b>rigs</b> and connected laptop enables users to see interactively which minimise errors. Further Info: [URL] [URL] [URL]...|$|R
50|$|A <b>camera</b> <b>rig</b> that synchronizes six GoPro HERO4 Black cameras {{allowing}} {{users to}} stitch and make virtual reality 360° videos.|$|E
5000|$|... 3ality Technica {{provides}} {{technology in}} two categories: The company’s 3Flex <b>camera</b> <b>rig</b> systems enable 3D image acquisition, {{and have been}} used in the production of feature films, scripted television shows, and live-action 3D sports broadcasts.|$|E
50|$|The Butler's in Love, a {{short film}} {{directed}} by David Arquette and starring Elizabeth Berkley and Thomas Jane {{was released on}} June 23, 2008. The film was shot at the former Industrial Light & Magic studios using KernerFX's prototype Kernercam stereoscopic <b>camera</b> <b>rig.</b>|$|E
5000|$|In The Washington Post, Vanessa H. Larson wrote, [...] "The camerawork skillfully mimics a cat’s-eye view, with {{extended}} sequences filmed {{just over}} the animals’ shoulders using remote-controlled <b>camera</b> <b>rigs</b> that follow them as they saunter around, forage for meals and get into hissing matches. Interspersed throughout the film are also beautiful drone-captured aerial shots of Istanbul’s sprawling streets and the Bosporus waterway, which impart {{a strong sense of}} place." ...|$|R
50|$|Kite aerial {{photography}} (KAP) is a hobby and {{a type of}} photography. A {{camera is}} lifted using a kite and is triggered either remotely or automatically to take aerial photographs. The <b>camera</b> <b>rigs</b> can range from the extremely simple, consisting of a trigger mechanism with a disposable camera, to complex apparatus using radio control and digital cameras. On some occasions {{it can be a}} good alternative to other forms of aerial photography.|$|R
5000|$|Michael Sragow, {{writing in}} The New Yorker, said: [...] "Working with {{lightweight}} <b>camera</b> <b>rigs</b> they developed themselves, Jeff Kreines and Joel DeMott (who, despite the name, is female) approach {{the subjects of}} their documentary - working-class teenagers in Muncie, Indiana - man-to-man and woman-to-woman. The immediacy is refreshing, and shocking. As searing as it is rambunctious, this film brings out all the middle-class prejudices against the working class that American movies rarely confront." ...|$|R
50|$|The <b>camera</b> <b>rig</b> {{itself is}} {{attached}} to the kite line some distance beneath the kite, preferably with a pulley scheme that will permit the camera to float in a level attitude regardless of the kite's gyrations. The Picavet system is one such scheme.|$|E
5000|$|On the 6th December, 2010 Elphel {{launched}} their first panoramic camera solution (that is publicly available) called [...] "Elphel Eyesis". Eyesis {{can be seen}} as the successor (designed for low parallax) of the <b>camera</b> <b>rig</b> Elphel Inc. developed for Google Street View ...|$|E
50|$|This was {{the first}} {{production}} use of KernerFX's Kernercam stereoscopic 3D <b>camera</b> <b>rig.</b> When the project was brought to Kerner Studios, Kerner requested {{that a number of}} features previously considered 'tricky' for 3D capture be included in the film including fire, crystal glass and motion.|$|E
50|$|While Cameron {{initially}} {{worked on}} <b>camera</b> <b>rigging,</b> he soon {{started working on}} special effects and production design of interior sets. The low-budget led to Cameron designing the spaceship's corridors out of spray-painted McDonald's containers. Cameron paid great attention to detail, and hardly slept for weeks while working on the film; his hard work paid off, as the special effects were {{one aspect of the}} film highly received by both fans and critics, opening the door for his later success.|$|R
5|$|Girlfight {{was filmed}} over 24 days in New York and New Jersey. For scenes inside the gym where Diana and Tiny train, the filmmakers {{shot in a}} {{warehouse}} in Jersey City. The initial boxing sequences were shot from a spectator's view outside of the ring but later sequences were filmed more intimately from inside the ring. Cinematographer Patrick Cady used <b>camera</b> <b>rigs</b> that allowed the actors to hit him or the camera itself to mimic {{the feeling of being}} hit.|$|R
50|$|Abel had {{produced}} many high-end, visually advanced commercials for clients such as 7-Up, {{but it soon}} became apparent that their choice of technology, which featured software-controlled <b>camera</b> <b>rigs</b> and graphics imaging systems very advanced for the day, simply couldn't scale up to the volume of material required. In August 1978, with rumors of an impending meltdown at Abel swirling, Trumbull approached Paramount offering {{to step in and}} do the effects with partner Richard Yuricich. Paramount declined, hoping that Abel could still work a miracle.|$|R
5000|$|Virtual cameras {{have been}} {{developed}} which allow a director to film motion capture and view the digital characters movements in real time in a pre-constructed digital environment, such as a house or spaceship. Resident Evil 5 was the first video game to use the technology, which was developed for the 2009 film Avatar.The use of motion capture to control the position and orientation of a virtual camera enables the operator to intuitively move and aim the virtual camera by simply walking about and turning the virtual <b>camera</b> <b>rig.</b> A virtual <b>camera</b> <b>rig</b> consists of a portable monitor or tablet device, motion sensors, optional support framework, and optional joystick or button controls that are commonly used to start or stop recording and adjust lens properties. [...] In 1992, Michael McKenna of MITs Media Lab demonstrated the earliest documented virtual <b>camera</b> <b>rig</b> when he fixed a Polhemus magnetic motion sensor and a 3.2 inch portable LCD TV to a wooden ruler. [...] The Walkthrough Project at the University of North Carolina at Chapel Hill produced a number of physical input devices for virtual camera view control including dual three-axis joysticks and a billiard-ball shaped prop known as the UNC Eyeball that featured an embedded six-degree of freedom motion tracker and a digital button.|$|E
50|$|VR {{cameras are}} {{panoramic}} cameras that also cover {{the top and}} bottom in their field of view. There have also been camera rigs employing multiple cameras to cover the whole 360° by 360° field of view. The most famous VR <b>camera</b> <b>rig</b> is known as 'Google Jump'.|$|E
5000|$|It is also {{possible}} to create a twin <b>camera</b> <b>rig,</b> together with a [...] "shepherd" [...] device to synchronize the shutter and flash of the two cameras. By mounting two cameras on a bracket, spaced a bit, with a mechanism to make both take pictures at the same time.|$|E
5000|$|A {{steadicam}} operator {{is someone}} who is skilled at operating a Steadicam (trademark for a <b>camera</b> stabilization <b>rig).</b> This person is usually one of the camera operators on the production.|$|R
50|$|For production, Lesnie used Red Digital Cinema's Epic cameras {{as well as}} Carl Zeiss Ultra Prime Lenses to {{photograph}} the film. Jackson and Lesnie decided to shoot the film in 3D {{with as many as}} 15 stereoscopic <b>camera</b> <b>rigs</b> (2 <b>cameras</b> each) with 3ality. They also decided to shoot the film in an uncommon, yet innovative, frame rate of 48 frames per second versus the industry standard of 24 frames per second. This would make Lesnie the first cinematographer to employ such a method that claims to induce more clarity, reduce motion blur, and make 3D easier to watch.|$|R
50|$|Located in the River North {{neighborhood}} of Chicago, Illinois, Zacuto manufactures camera accessories for established and aspiring {{professionals in the}} video, film, and photography industries. Zacuto product designers Jens Bogehegn and Steve Weiss are active filmmakers who create gear that solves common filmmaking problems. Zacuto products are known for being universal between cameras, quick releasable, and long lasting. These accessories allow for full customization of <b>camera</b> <b>rigs.</b> Zacuto gear allows filmmakers to adapt their current equipment into whatever is needed for full versatility. Zacuto camera kits and DSLR optical viewfinders have been said to set the standard within the industry.|$|R
