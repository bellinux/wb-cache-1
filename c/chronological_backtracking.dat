63|6|Public
2500|$|Execution of a Prolog {{program is}} {{initiated}} by the user's posting of a single goal, called the query. Logically, the Prolog engine tries to find a resolution refutation of the negated query. The resolution method used by Prolog is called SLD resolution. If the negated query can be refuted, {{it follows that the}} query, with the appropriate variable bindings in place, is a logical consequence of the program. In that case, all generated variable bindings are reported to the user, and the query is said to have succeeded. Operationally, Prolog's execution strategy {{can be thought of as}} a generalization of function calls in other languages, one difference being that multiple clause heads can match a given call. In that case, the system creates a choice-point, unifies the goal with the clause head of the first alternative, and continues with the goals of that first alternative. If any goal fails in the course of executing the program, all variable bindings that were made since the most recent choice-point was created are undone, and execution continues with the next alternative of that choice-point. This execution strategy is called <b>chronological</b> <b>backtracking.</b> For example: ...|$|E
5000|$|... #Caption: [...] CDCL: conflict-driven clause {{learning}} and non - <b>chronological</b> <b>backtracking.</b>|$|E
50|$|Beam Stack Search {{uses the}} beam stack as a data {{structure}} to integrate <b>chronological</b> <b>backtracking</b> with beam search {{and can be}} combined with the divide and conquer algorithm technique, resulting in divide-and-conquer beam-stack search.|$|E
40|$|A {{new method}} for {{developing}} good value-ordering strategies in constraint satisfaction search is presented. Using an evolutionary technique called SANE, in which individual neurons evolve {{to cooperate and}} form a neural network, problem-speci c knowledge can be discovered that results in better value-ordering decisions than those based on problem-general heuristics. A neural network was evolved in a <b>chronological</b> <b>backtrack</b> search to decide the ordering of cars in a resource-limited assembly line. The network required 1 / 30 of the backtracks of random ordering and 1 / 3 of the backtracks of the maximization of future options heuristic. The SANE approach should extend well to other domains where heuristic information is either di cult to discover or problem-speci c. ...|$|R
40|$|Abstract: Constraint {{programming}} {{is the study}} of system which is based on constraints. The solution of a constraint satisfaction problem is a set of variable value assignments, which satisfies all members of the set of constraints in the CSP. In this paper the application of constraint satisfaction {{programming is}} used in predicting the path loss of various indoor propagation models using <b>chronological</b> <b>backtrack</b> algorithm, which is basic algorithm of CSP. After predicting the path loss at different set of parameters such as frequencies (f), floor attenuation factor (FAF), path loss coefficient (n), we find the optimum set of parameter frequency (f), floor attenuation factor (FAF), path loss coefficient(n) at which the path loss is minimum. The Branch and bound algorithm is used to optimize the constraint satisfaction problem...|$|R
40|$|Abstract- Constraint {{satisfaction}} programming(CSP) is an emergent {{software technology}} for declarative description and effective solving of large particularly combinational problem especially {{in term of}} planning and scheduling. Constraint programming {{is the study of}} computational system based on constraints. The idea of constraint programming is to solve problem by stating constraints about the problem and consequently finding the solution satisfying all the constraints. In this paper the application of constraint satisfaction programming is used in predicting the path loss of various empirical propagation models using <b>chronological</b> <b>backtrack</b> algorithm, which is basic algorithm of CSP. After predicting the path loss at different set of parameter such as frequencies), floor attenuation factor (faf), path loss coefficient(n), penetration attenuation factor (paf), we find the optimum set of parameter (frequency (f), floor attenuation factor (faf), path loss coefficient(n), penetration attenuation factor (paf) at which path loss is minimum with the help of Branch and bound algorithm, which is used to optimized the constraint satisfaction problem...|$|R
50|$|Beam Search Using Limited Discrepancy Backtracking (BULB) is {{a search}} {{algorithm}} that combines limited discrepancy search with beam search and thus performs non-chronological backtracking, which often outperforms the <b>chronological</b> <b>backtracking</b> done by Beam Stack Search and Depth-First Beam Search.|$|E
50|$|Beam Stack Search is {{a search}} {{algorithm}} that combines <b>chronological</b> <b>backtracking</b> (that is, depth-first search) with beam search and {{is similar to}} Depth-First Beam Search. Both search algorithms are anytime algorithms that find good but likely sub-optimal solutions quickly, like beam search, then backtrack and continue to find improved solutions until convergence to an optimal solution.|$|E
5000|$|Execution of a Prolog {{program is}} {{initiated}} by the user's posting of a single goal, called the query. Logically, the Prolog engine tries to find a resolution refutation of the negated query. The resolution method used by Prolog is called SLD resolution. If the negated query can be refuted, {{it follows that the}} query, with the appropriate variable bindings in place, is a logical consequence of the program. In that case, all generated variable bindings are reported to the user, and the query is said to have succeeded. Operationally, Prolog's execution strategy {{can be thought of as}} a generalization of function calls in other languages, one difference being that multiple clause heads can match a given call. In that case, the system creates a choice-point, unifies the goal with the clause head of the first alternative, and continues with the goals of that first alternative. If any goal fails in the course of executing the program, all variable bindings that were made since the most recent choice-point was created are undone, and execution continues with the next alternative of that choice-point. This execution strategy is called <b>chronological</b> <b>backtracking.</b> For example: ...|$|E
40|$|CCP (CLIPS Constraint Programming) is {{a generic}} {{knowledge}} base which enables CLIPS to solve CSPs (Constraint Satisfaction Problems). CCP {{is composed of}} three modules. The MAIN module contains the top level loop including the I/O rules. The SEARCH module implements a classical <b>Chronological</b> <b>Backtrack</b> algorithm. The PROPAGATION module implements the Forward Checking algorithm. CCP has been extensively tested with well known puzzles as N-queens, graph colouring, crosswords, etc. To implement any particular problem, the users only need to declare each variable with its domain {{and they have to}} define specific domain description and rules of propagation. So that all specific knowledge is encapsulated in the PROPAGATION module. CCP is a generic tool that can be embedded in a knowledge based system like a work horse for local CSPs solving. CCP is compact, since it contains only a dozen rules. Moreover, CCP {{can be seen as a}} pedagogical tool illustrating many advanced features of CLIPS (logical [...] ...|$|R
40|$|Abstract. The {{heavy-tailed}} {{phenomenon that}} characterises the runtime distributions of backtrack search procedures has received considerable attention {{over the past}} few years. Some have conjectured that heavy-tailed behaviour is largely due to the characteristics of the algorithm used. Others have conjectured that problem structure is a significant contributor. In this paper we attempt to explore the former hypothesis, namely we study how variable and value ordering heuristics impact the heavy-tailedness of runtime distributions of backtrack search procedures. We demonstrate that heavy-tailed behaviour can be eliminated from particular classes of random problems by carefully selecting the search heuristics, even when using <b>chronological</b> <b>backtrack</b> search. We also show that combinations of good search heuristics can eliminate heavy tails from quasigroups with holes of order 10 and 20, and give some insights into why this is the case. These results motivate a more detailed analysis of the effects that variable and value orderings can have on heavy-tailedness. We show how combinations of variable and value ordering heuristics can result in a runtime distribution being inherently heavy-tailed. Specifically, we show that even if we were to use an oracle to refute insoluble subtrees optimally, for some combinations of heuristics we would still observe heavy-tailed behaviour. Finally, we study the distributions of refutation sizes found using different combinations of heuristics and gain some further insights into what characteristics tend to give rise to heavy-tailed behaviour. ...|$|R
40|$|The {{translation}} of Spanish Noun + preposition + Noun (NPN) constructions into English Noun-Noun (NN) compounds {{in many cases}} produces output with {{a higher level of}} fluency than if the NPN ordering is preserved. However, overgeneration of NN compounds can be dangerous because it may introduce ambiguity in the translation. This paper presents the strategy implemented in SPANAM to address this issue. The strategy involves dictionary coding of key words and expressions that allow or prohibit NN formation as well as an algorithm that generates NN compounds automatically when no dictionary coding is present. Certain conditions specified in the algorithm may also override the dictionary coding. The strategy makes use of syntactic and lexical information. No semantic coding is required. The last step in the strategy involves post-editing macros that allow the posteditor to quickly create or undo NN compounds if SPANAM did not generate the desired result. Keywords Noun-Noun compounds, Spanish-English machine translation and SPANAM system SPANAM today SPANAM has been operational at the Pan American Health Organization since 1980. The program, along with its English-Spanish counterpart Engspan, was ported from the mainframe to the PC in 1992 and then to the Windows environment in 2000 (León, 2000). The basic architecture of the program hasn't changed since 1985 : it is a transfer system with an ATN that generates a top-down, left-to-right sequential parse with <b>chronological</b> and explicit <b>backtracking</b> (Vasconcellos and León, 1988; Amores, 1996). Dictionary entries are rich in morphological, syntactic, and semantic information. The grammar and dictionaries have grown considerably in the past 15 years. SPANAM dictionaries currently contain over 95, 000 source entries and 85, 000 translations. Source entries include single words (65, 000 stem forms), multiple word entries or SUs 1 (11, 000), analysis rules or AUs (8, 500), and context-sensitive translation rules (10, 000). In several MT evaluation experiments sponsored by th...|$|R
50|$|Execution of a Prolog {{program is}} {{initiated}} by the user's posting of a single goal, called the query. Logically, the Prolog engine tries to find a resolution refutation of the negated query. The resolution method used by Prolog is called SLD resolution. If the negated query can be refuted, {{it follows that the}} query, with the appropriate variable bindings in place, is a logical consequence of the program. In that case, all generated variable bindings are reported to the user, and the query is said to have succeeded. Operationally, Prolog's execution strategy {{can be thought of as}} a generalization of function calls in other languages, one difference being that multiple clause heads can match a given call. In that case, the system creates a choice-point, unifies the goal with the clause head of the first alternative, and continues with the goals of that first alternative. If any goal fails in the course of executing the program, all variable bindings that were made since the most recent choice-point was created are undone, and execution continues with the next alternative of that choice-point. This execution strategy is called <b>chronological</b> <b>backtracking.</b> For example:mother_child(trude, sally). father_child(tom, sally).father_child(tom, erica).father_child(mike, tom). sibling(X, Y) :- parent_child(Z, X), parent_child(Z, Y). parent_child(X, Y) :- father_child(X, Y).parent_child(X, Y) :- mother_child(X, Y).|$|E
40|$|The most {{advanced}} implementation of adaptive constraint processing with Constraint Handling Rules (CHR) allows {{the application of}} intelligent search strategies to solve Constraint Satisfaction Problems (CSP). This presentation compares an improved version of conflict-directed backjumping and two variants of dynamic backtracking with respect to <b>chronological</b> <b>backtracking</b> {{on some of the}} AIM instances which are a benchmark set of random 3 -SAT problems. A CHR implementation of a Boolean constraint solver combined with these different search strategies in Java is thus being compared with a CHR implementation of the same Boolean constraint solver combined with <b>chronological</b> <b>backtracking</b> in SICStus Prolog. This comparison shows that the addition of "intelligence" to the search process may reduce the number of search steps dramatically. Furthermore, the runtime of their Java implementations is in most cases faster than the implementations of <b>chronological</b> <b>backtracking.</b> More specifically, conflict-directed backjumping is even faster than the SICStus Prolog implementation of <b>chronological</b> <b>backtracking,</b> although our Java implementation of CHR lacks the optimisations made in the SICStus Prolog system...|$|E
40|$|Abstract. Multi-Point Constructive Search {{maintains}} a small set of “elite solutions” {{that are used}} to heuristically guide constructive search through periodically restarting search from an elite solution. Empirical results indicate that for job shop scheduling optimization problems, multi-point constructive search leads to significantly better solutions for equivalent search effort when compared to <b>chronological</b> <b>backtracking</b> and bounded backtracking with random restart. For satisfaction problems (quasigroup with holes completion), significant reduction in the magnitude of mean search effort (the number of fails and run-time) is also achieved versus <b>chronological</b> <b>backtracking</b> and bounded backtracking with random restart. Two conjectures about the relationship between the clustering of good solutions in a search tree and the performance of multi-point constructive search are made. Preliminary empirical results are consistent with the conjectures, suggesting directions for future work to develop {{a deeper understanding of the}} observed performance. ...|$|E
40|$|In this paper, a new search {{technique}} over numeric csps is presented: dynamic domain splitting. The usual search technique over numeric csps is a dichotomic search interleaved with a consistency filtering, {{which is}} called domain splitting. This paper proposes to replace <b>chronological</b> <b>backtracking</b> {{at the core of}} domain splitting by a non destructive backtracking technique...|$|E
40|$|Abstract. Multi-Point Constructive Search {{maintains}} a small set of “elite solutions” {{that are used}} to heuristically guide constructive search through periodically restarting search from an elite solution. Empirical results indicate that for job shop scheduling optimization problems and quasi-group completion problems, multi-point constructive search performs significantly better than <b>chronological</b> <b>backtracking</b> and bounded backtracking with random restart. ...|$|E
40|$|We {{propose a}} new {{backtracking}} method called constraint-directed backtracking (CDBT) for solving constraint-satisfaction problems (CSPs). CDBT and <b>chronological</b> <b>backtracking</b> (BT) share a similar style of instantiating variables (forward) and re-instantiating variables (backward). They differ in that CDBT searches instantiations of variables in a variable set from a given constraint posed on that variable set and appends it to a partial solution, whereas BT searches the instantiation of one variable from its domain. The search space of CDBT {{is much more}} limited than that of <b>chronological</b> <b>backtracking.</b> The similarity between CDBT and BT enables us to incorporate other tree search techniques, such as BJ, CBJ, FC, into CDBT to improve its performance further. 1 Introduction Backtracking search {{is one of the}} most popular methods for solving constraint satisfaction problems ([4, 15, 17]). The original backtracking BT [9, 2] (often referred to as chronological or generic backtracking) suffer [...] ...|$|E
40|$|Dynamic domain {{splitting}} for numeric CSPs Abstract. In this paper, a new search technique over numeric csps is presented: dynamic domain splitting. The usual search technique over numeric csps is a dichotomic search interleaved with a consistency filtering, {{which is}} called domain splitting. This paper proposes to replace <b>chronological</b> <b>backtracking</b> {{at the core of}} domain splitting by a non destructive backtracking technique. ...|$|E
40|$|Programming PearlThis paper {{illustrates}} how a Prolog program, using <b>chronological</b> <b>backtracking</b> {{to find a}} solution in some search space, can be enhanced to perforin intelligent backtracking. The enhancement crucially relics on the impurity of Prolog that allows a program to store information when a dead end is reached. To illustrate the technique, a simple search program is enhanced. status: publishe...|$|E
40|$|Many {{practical}} problems in Artificial Intelligence have search trees {{that are too}} large to search exhaustively {{in the amount of}} time allowed. Systematic techniques such as <b>chronological</b> <b>backtracking</b> can be applied to these problems, but the order in which they examine nodes makes them unlikely to find a solution in the explored fraction of the space. Nonsystematic techniques have been proposed to alleviate the problem by searching nodes in a random order. A technique known as iterative sampling follows random paths from the root of the tree to the fringe, stopping if a path ends at a goal node. Although the nonsystematic techniques do not suffer from the problem of exploring nodes in a bad order, they do reconsider nodes they have already ruled out, a problem that is serious when the density of solutions in the tree is low. Unfortunately, for many {{practical problems}} the order of examing nodes matters and the density of solutions is low. Consequently, neither <b>chronological</b> <b>backtracking</b> [...] ...|$|E
40|$|International audienceIn this paper, {{we propose}} {{mechanisms}} to improve instantiation heuristics by incorporating weighted factors on variables. The proposed weight-based heuristics are evaluated on several tree search {{methods such as}} <b>chronological</b> <b>backtracking</b> and discrepancy-based search for both constraint satisfaction and optimization problems. Experiments are carried out on random constraint satisfaction problems, car sequencing problems, and jobshop scheduling with time-lags, considering various parameter settings and variants of the methods...|$|E
40|$|A nonsystematic {{iterative}} search algorithm {{for hard}} or overconstrained problems is proposed. This linear time complexity algorithm seeks a (partial) assignment {{of the problem}} variables. One step of the algorithm is a special incomplete version of <b>chronological</b> <b>backtracking</b> with constraint propagation. Subsequent searches try to improve the last computed partial assignment. This is done by developing variable and value heuristics {{based on the results}} of previous iterations. The algorithm was applied to solve random problems and a large scale timetabling problem from Purdue University...|$|E
40|$|Abstract. This paper {{presents}} a generalisation {{of the well}} known <b>chronological</b> <b>backtracking</b> algorithm. The algorithm is a generalisation {{in the sense that}} it can use any kind of constraint (as opposed to just unary constraints—the domains of the variables) to decompose a problem into smaller problems. This choice keeps the height of the search tree less than or equal to the number of variables. Most importantly, however, this choice will never increase the local branching factor of the search tree but will frequently make it smaller. ...|$|E
40|$|This paper {{illustrates}} how a Prolog program, using <b>chronological</b> <b>backtracking</b> {{to find a}} solution in some search space, can be enhanced to perform intelligent backtracking. The enhancement crucially relies on the impurity of Prolog that allows a program to store information when a dead end is reached. To illustrate the technique, a simple search program is enhanced. To appear in Theory and Practice of Logic Programming. Keywords: intelligent backtracking, dependency-directed backtracking, backjumping, conflict-directed backjumping, nogood sets, look-back. Comment: To appear in Theory and Practice of Logic Programmin...|$|E
40|$|This paper {{presents}} a generalisation {{of the well}} known <b>chronological</b> <b>backtracking</b> algorithm. The algorithm is a generalisation {{in the sense that}} it can use any kind of constraint (as opposed to just unary constraints [...] the domains of the variables) to decompose a problem into smaller problems. This choice keeps the height of the search tree less than or equal to the number of variables. Most importantly, however, this choice will never increase the local branching factor of the search tree but will frequently make it smaller...|$|E
40|$|Non-deterministic LISP {{can be used}} to {{describe}} a search problem without specifying the method used to solve the problem. We show that SCHEMER, a non-deterministic dialect of SCHEME, can support dependency-directed backtracking as well as <b>chronological</b> <b>backtracking.</b> Full code for a working SCHEMER interpreter that provides dependency-directed backtracking is included. This is a greatly revised version of a thesis submitted to the Massachusetts Institute of Technology Department of Electrical Engineering and Computer Science on January 2, 1987, in partial fulfillment of the requirements for the degree of Master of Science. MIT Artificial Intelligence Laborator...|$|E
40|$|Multi-point {{constructive}} search (MPCS) {{performs a}} series of resource-limited backtracking searches where each search begins either from an empty solution (as in randomized restart) or from a solution that has been encountered during the search. We perform a systematic study of MPCS to evaluate the performance impact of various parameter settings. Results using job shop scheduling instances with two different optimization criteria, demonstrate that MPCS-based search is significantly better than standard <b>chronological</b> <b>backtracking</b> and randomized restart while raising {{a number of questions}} as to the underlying reasons for the observed performance...|$|E
40|$|Most studies {{concerning}} {{constraint satisfaction}} problems (CSPs) involve variables that take values from small domains. This paper deals {{with an alternative}} form of temporal CSPs; the number of variables is relatively small and the domains are large collections of intervals. Such situations may arise in temporal databases where several types of queries can be modeled and processed as CSPs. For these problems, systematic CSP algorithms {{can take advantage of}} temporal indexing to accelerate search. Directed search versions of <b>chronological</b> <b>backtracking</b> and forward checking are presented and tested. Our results show that indexing can drastically improve search performance. ...|$|E
40|$|AbstractCurrent Web {{technologies}} {{provide the}} basis for publishing and composing large number of Web Services which are char–acterized by functional, non-functional, and transactional properties. Although the research community has proposed several approaches to effciently solve problems as service selection and composition, some of these solutions may be incomplete, i. e., they may fail producing a solution when solutions exist. In this paper we propose a non-chronological backtracking strategy which is implemented in a state-of-the-art composition algorithm named PT-SAM, and complete–ness is achieved in the context of transactional web service composition. Empirical results suggest that the proposed approach may overcome the <b>chronological</b> <b>backtracking</b> strategy by up one order of magnitude...|$|E
40|$|Our {{research}} has been motivated by the task of forming a solution subgraph which satisfies given constraints. The problem is represented by an A/O graph. Our approach is to apply a suitably modied technique of dependency-directed backtracking. We present our formulation of the standard <b>chronological</b> <b>backtracking</b> algorithm in Prolog. Based on it, we have developed an enhanced algorithm which makes use of special heuristic knowledge. It involves also the technique of node marking. We have gathered experience with the prototype Prolog implementation of the algorithm in applying it to (one step of) the problem of building a software conguration. Our experience shows that Prolog programming techniques offer a considerable flexibility in implementing the above outlined tasks...|$|E
40|$|Backtracking is {{necessary}} when design alternatives are explored or dead ends are reached. Unfortunately, current approaches support <b>chronological</b> <b>backtracking</b> only (undo or version control), where the designer {{is forced to}} undo intermittent changes {{even if they are}} not related to what should be backtracked. This work introduces an approach for selective backtracking during software modeling where previously discarded design changes are recovered without having to undo intermittent changes. Selective backtracking is a challenge because during multi-view modeling, we must understand how changes across multiple views are connected – in order to undo them together and thus avoid undesired inconsistencies. Our approach automatically discovers dependencies among design changes and is thus able to guide the designer during selective backtracking. 1...|$|E
40|$|Abstract. Adaptive {{constraint}} processing with Constraint Handling Rules (CHR) {{allows the}} application of intelligent search strategies to solve Constraint Satisfaction Problems (CSP), but these search algorithms have to be implemented in the host language of adaptive CHR, which is currently Java. On the other hand, CHR ∨ enables to explicitly formulate search in CHR, using disjunctive bodies to model choices. However, a naive implementation for handling disjunctions, in particular <b>chronological</b> <b>backtracking</b> (as implemented in Prolog) might cause “thrashing ” due to an inappropriate order of decisions. To avoid this, a first combination of adaptive CHR and CHR ∨ is presented to offer a more efficient embedded search mechanism to handle disjunctions. Therefore the refined operational semantics of CHR is extended for disjunctions and adaptation. ...|$|E
40|$|We propose two new online {{methods for}} {{estimating}} {{the size of}} a backtracking search tree. The first method is based on a weighted sample of the branches visited by <b>chronological</b> <b>backtracking.</b> The second is a recursive method based on assuming that the unexplored part of the search tree will be similar to the part we have so far explored. We compare these methods against an old method due to Knuth based on random probing. We show that these methods can reliably estimate the size of search trees explored by both optimization and decision procedures. We also demonstrate that these methods for estimating search tree size can be used to select the algorithm likely to perform best on a particular problem instance...|$|E
40|$|Adaptive {{constraint}} processing with Constraint Handling Rules (CHR) {{allows the}} application of intelligent search strategies to solve Constraint Satisfaction Problems (CSP), but these search algorithms have to be implemented in the host language of adaptive CHR which is currently Java. On the other hand, CHRv enables to explicitly formulate search in CHR, using disjunctive bodies to model choices. However, a naive implementation for handling disjunctions, in particular <b>chronological</b> <b>backtracking</b> (as implemented in Prolog), might cause "thrashing" due to an inappropriate order of decisions. In order to avoid this, a first combination of adaptive CHR and CHRv is presented to offer a more efficient embedded search mechanism to handle disjunctions. Therefore, the refined operational semantics of CHR is extended for disjunctions and adaptation...|$|E
40|$|Two {{variants}} of an incremental and adaptive unification algorithm are presented. Both variants decide incrementally {{the consistency of}} conjunctions of syntactical equations over rational trees after any additions or deletions of syntactical equations. In the positive case, a rational solved form equivalent to the given conjunction is computed incrementally. Contrary to other incremental implementations, our approach uses a simplified form of justifications used in truth maintenance systems instead of a trail. Thus, arbitrary additions and especially arbitrary deletions are supported without <b>chronological</b> <b>backtracking.</b> This flexibility requires set manipulations instead of simple stack operations. This additional effort pays off in dynamic application domains, e. g. the solution of Dynamic Constraint Satisfaction Problems realized with Constraint Handling Rules, where syntactical equations depend on others and {{on the results of}} calculations. 1 Introduction The application of Constrain [...] ...|$|E
