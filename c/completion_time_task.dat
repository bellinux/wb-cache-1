8|10000|Public
40|$|Abstract. Task {{schedule}} algorithms {{directly related}} to the speed and quality of schedule. Min-Min algorithm always completes the shortest total <b>completion</b> <b>time</b> <b>task</b> first, and has the characteristic of simple and shortest completion time. This paper research scheduling algorithm based on Min—Min algorithm. The result shows that the proposed algorithm is efficient in the cloud computing environment...|$|E
40|$|We discuss our {{proposed}} {{approach to}} handling uncertainty and constraints in job-shop scheduling. Specifically {{we deal with}} uncertainty in the duration of a task, as well as constraints on task <b>completion</b> <b>time,</b> <b>task</b> separation, etc. We discuss both offline and adaptive scheduling strategies. Our approach is to synthesize fast schedulers that handle uncertainty by calculating them from formal specifications...|$|E
30|$|Video: Task <b>{{completion}}</b> <b>time.</b> <b>Task</b> {{completion time}} {{was defined as}} the time from the moment participants first pressed the voice activation button to the time that the same button was pressed to terminate a task, {{or in the case of}} radio tuning, the moment when the system accurately carried out the requested task. Task completion time reflects the average task duration across the six tasks in the IVIS condition.|$|E
40|$|In this paper, we {{performed}} a comparative evaluation to show the effectiveness of two interface tools, one a floating text-based menu (Floating-Menu) {{and the other a}} more interactive iconic tool (Interactive-Icon). We evaluated the use and human performance of both tools within one highly interactive visual analytics system. During task performance we tracked <b>completion</b> <b>times,</b> <b>task</b> errors, and captured coarsegrained interactive behaviors. 1...|$|R
40|$|In this paper, {{we study}} {{the problem of}} {{scheduling}} a set of tasks with known execution times and arbitrary precedence constraints to computing systems. The objective function {{used to measure the}} performance of a schedule in this paper is the total <b>completion</b> <b>time</b> (the sum of <b>completion</b> <b>times</b> of all <b>tasks).</b> Finding the minimum total <b>completion</b> <b>time</b> of <b>tasks</b> with precedence constraints on the uniprocessor system is known to be NP-complete, let alone on the multiprocessor system (Garey et al. 1979). Based on the well-known A* algorithm proposed [...] ...|$|R
30|$|V* {{denotes the}} {{expected}} {{value of the}} remaining <b>completion</b> <b>time</b> when no <b>task</b> has yet been completed i.e., all tasks are in the running state.|$|R
40|$|This paper {{presents}} on-going work on constructing bilingual multimodal corpora {{of referring}} expressions in collaborative problem solving for English and Japanese. The corpora {{were collected from}} dialogues in which two participants collaboratively solved Tangram puzzles with a puzzle simulator. Extra-linguistic information such as operations on puzzle pieces, mouse cursor position and piece positions were recorded in synchronisation with utterances. The speech data was transcribed and time-aligned with the extra-linguistic information. Referring expressions in utterances that refer to puzzle pieces were annotated {{in terms of their}} spans, their referents and their other attributes. The Japanese corpus has already been completed, but the English counter-part is still undergoing annotation. We have conducted a preliminary comparative analysis of both corpora, mainly with respect to task <b>completion</b> <b>time,</b> <b>task</b> success rates and attributes of referring expressions. These corpora showed significant differences in task completion time and success rate...|$|E
40|$|In {{this paper}} we {{investigate}} the usability of speech-centric multimodal interaction by comparing two systems {{that support the}} same unfamiliar task, viz. bathroom design. One version implements a conversational agent (CA) metaphor, while the alternative one is based on direct manipulation (DM). Twenty subjects, 10 males and 10 females, none of whom had recent experience with bathroom (re-) design completed the same task with both systems. After each task we collected objective measures (task <b>completion</b> <b>time,</b> <b>task</b> completion rate, number of actions performed, speech and pen recognition errors) and subjective measures {{in the form of}} Likert Scale ratings. We found that the task completion rate for the CA system is higher than for the DM system. Nevertheless, subjects did not agree on their preference for one of the systems: those subjects who were able to use the DM system effectively preferred that system, mainly because it was faster for them, and they felt more in control. We conclude that for multimodal CA systems to become widely accepted substantial improvements in system architecture and in the performance of almost all individual modules are needed...|$|E
40|$|We {{propose a}} spoken dialog {{strategy}} for car navigation systems to facilitate safe driving. To drive safely, drivers need {{to concentrate on}} their driving; however, their concentration may be disrupted due to disagreement with their spoken dialog system. Therefore, we need {{to solve the problems}} of user misunderstandings as well as misunderstanding of spoken dialog systems. For this purpose, we introduced a driver workload level in spoken dialog management in order to prevent user misunderstandings. A key strategy of the dialog management is to make speech redundant if the driver’s workload is too high in assuming that the user probably misunderstand the system utterance under such a condition. An experiment was conducted to compare performances of the proposed method and a conventional method using a user simulator. The simulator is developed under the assumption of two types of drivers: an experienced driver model and a novice driver model. Experimental results showed that the proposed strategies achieved better performance than the conventional one for task <b>completion</b> <b>time,</b> <b>task</b> completion rate, and user’s positive speech rate. In particular, these performance differences are greater for novice users than for experienced users...|$|E
30|$|The {{experimental}} results and analysis show that IMFWA has the feasibility and efficiency {{in solving the}} task scheduling problem. It retains {{the characteristics of the}} basic fireworks algorithm’s accuracy in finding the optimal or suboptimal task scheduling sequence. Meanwhile, it shortens the overall <b>completion</b> <b>time</b> of <b>tasks</b> on multi-processor, where its parallelism and heterogeneity can be fully utilized.|$|R
40|$|In many {{applications}} of wireless sensor actor networks (WSANs) that often run in harsh environments, {{the reduction of}} <b>completion</b> <b>times</b> of <b>tasks</b> is highly desired. We present a new time-aware, energy-aware, and starvation-free algorithm called Scate for assigning tasks to actors while satisfying the scalability and distribution requirements of WSANs with semi-automated architecture. The proposed algorithm allows concurrent executions of any mix of small and large tasks and yet prevents probable starvation of tasks. To achieve this, it estimates the <b>completion</b> <b>times</b> of <b>tasks</b> on each available actor and then takes the remaining energies and the current workloads of these actors into account during task assignment to actors. The results of our experiments with a prototyped implementation of Scate show longer network lifetime, shorter makespan of resulting schedules, and more balanced loads on actors compared to {{when one of the}} three well-known task-scheduling algorithms, namely, the max-min, min-min, and opportunistic load balancing algorithms, is used...|$|R
30|$|Unpaid {{crowdsourcing}} platforms provide functionalities {{similar to}} paid platforms without built-in provision for monetary incentives. They employ volunteers as workers thus the <b>completion</b> <b>time</b> of <b>tasks</b> could {{be difficult to}} estimate. Nevertheless, since running a task in unpaid platforms does not require payment to workers, {{it may be an}} economical alternative for individuals and organizations who are more concerned about the budget than the <b>task</b> turnaround <b>time.</b>|$|R
40|$|This {{research}} {{investigated the}} effects of data presentation formats on technician performance when maintenance procedures are presented on a monocular, head-mounted display (HMD). The maintenance task was a continuity check performed by identifying, selecting, and testing pairs of cannon plug connector pins. Two formats were used to present ask procedure information to the subject: a format hat mimicked the standard technical procedure manual, including the textual and graphical characteristics; a format which provided the same information as the first, while adding visual cues to the graphical portion of the technical information. Two types of cannon plugs were used: ‘few-pin ’ plugs (12 and 13 pins) and ‘many-pm ’ plugs (55 and 79 pins). United States Air Force (USAF) avionics maintenance t chnicians tationed atBarksdale Air Force Base, Louisiana served as subjects. Dependent measures were: task <b>completion</b> <b>time,</b> <b>task</b> error rate, and subjective reports on the usability of the information presentation structure and the HMD. Results indicate that in general, technicians perform tasks more quickly and commit fewer errors when using enhanced graphical data presentation methods. Technicians indicated via post test questionnaire that such data formats, and HMDs in general, could be a useful tool {{in the performance of}} their maintenance duties...|$|E
40|$|In the “third wave” of human-computer {{interaction}} (HCI), {{the advent of}} the conceptual approach of UX broadens and changes the HCI landscape. Methods approved before, mainly within the conceptual approach of usability, are still widely used, and yet their adequacy for UX evaluation remains uncertain in many applications. Laboratory testing is undoubtedly the most prominent example of such a method. Hence, in this study, we investigated how the more comprehensive and emotional scope of UX can be assessed by laboratory testing. In this paper, we report on a use case study involving 70 participants. They first took part in user/laboratory tests and then were asked to evaluate their experience with the two systems (perceived UX) by filling out an AttrakDiff scale and a UX needs fulfillment questionnaire. We conducted post-test interviews to better understand participants’ experiences. We analyzed how the participants’ perceived UX depends on quantitative (e. g., task <b>completion</b> <b>time,</b> <b>task</b> sequence, level of familiarity with the system) and qualitative aspects (think aloud, debriefing interviews) within the laboratory context. Results indicate that the laboratory setting has a strong impact on the participants’ perceived UX, and support a discussion of the quality and limitations of laboratory evaluations regarding UX assessment. In this paper, we have identified concrete challenges and have provided solutions and tips useful for both practitioners and researchers who seek to account for the subjective, situated, and temporal nature of the UX in their assessments...|$|E
30|$|SARS [32] {{is another}} optimal {{scheduling}} policy that manages reduce tasks’ start times in Hadoop. It decreases the <b>completion</b> <b>time</b> of reduce <b>tasks</b> by deciding the start time of each reduce task dynamically according to each job context, {{such as the}} <b>task</b> <b>completion</b> <b>time</b> {{and the size of}} map output.|$|R
30|$|As {{part of the}} study, the {{participants}} were asked to complete the pre-designed scenario with some tasks embedded within. The <b>completion</b> <b>time</b> for these <b>tasks</b> was between 15 and 22 : 30  min with a standard deviation of 1.3  min.|$|R
30|$|Efficiency is a {{usability}} metric {{defined by}} ISO, {{which can be}} evaluated by measuring the <b>completion</b> <b>time</b> of each <b>task</b> and sub-tasks separately [27]. A system is considered efficient, if users are able to complete tasks in a reasonable time.|$|R
40|$|This {{technical}} report presents an innovative interaction technique for simultaneously scrolling {{the content of}} a window in horizontal and vertical dimensions. Scrolling is controlled by head rotation via a non-intrusive computer vision system. Preliminary user studies show that this technique is easy to learn and provides substantial speed and accuracy advantages over scrollbar manipulation. <b>Completion</b> <b>times</b> for <b>tasks</b> including both scrolling and pointing are more than 30 % faster for head-and-mouse than for mouse-and-scrollbar interactions...|$|R
40|$|International audienceTwo {{preemptive}} single-machine bicriteria scheduling {{problems with}} release dates and deadlines are considered in this paper. Each criterion is formulated as a maximum cost. In {{the first problem}} the cost of both criteria depends on the <b>completion</b> <b>time</b> of the <b>tasks.</b> This problem can be solved by enumerating all the Pareto optimal points with an approach proposed by Hoogeveen (1996) for the nonpreemptive problem without release dates. In the second problem, the costs of one criterion are dependent on the <b>completion</b> <b>times</b> of the <b>tasks</b> {{and the costs of}} the other criterion are dependent on the start times. This problem is more difficult but an efficient algorithm is proposed for a sub-problem with heads, tails, release dates and deadlines that appears in the job-shop scheduling problem...|$|R
40|$|An Investigation {{of whether}} or not the font sizes of {{websites}} will improve the users understanding of information and decrease the time taken to read information In this paper, an experiment is conducted on 20 subjects to test the effects of differing font sizes on <b>task</b> <b>completion</b> <b>time</b> and <b>task</b> productiveness. The experiment used 5 different font sizes to present information to subjects before asking them to complete a task concerned with the information. The subjects were measured for <b>task</b> <b>completion</b> <b>time</b> and assigned scores for each task. No significant differences were found between the font size used for the task and the score subjects received, or the <b>task</b> <b>completion</b> <b>time...</b>|$|R
40|$|We {{consider}} a {{setting in which}} a worker and a manager may each have information about the likely <b>completion</b> <b>time</b> of a <b>task,</b> and the worker also affects the <b>completion</b> <b>time</b> by choosing a level of effort. The task itself may further be composed {{of a set of}} subtasks, and the worker can also decide how many of these subtasks to split out into an explicit prediction task. In addition, the worker can learn about the likely <b>completion</b> <b>time</b> of a <b>task</b> as work on subtasks completes. We characterize a family of scoring rules for the worker and manager that provide three properties: information is truthfully reported; best effort is exerted by the worker in completing tasks as quickly as possible; and collusion is not possible. We also study the factors influencing when a worker will split a task into subtasks, each forming a separate prediction target. Categories and Subject Descriptor...|$|R
30|$|According to formula, the {{allocation}} fitness is {{inversely proportional to}} the variance. If the fitness value is greater, the variance is smaller, which means the <b>completion</b> <b>time</b> of <b>tasks</b> in the work {{is closer to the}} mean. So, when recovery entropy takes a maximum value, job execution time is shortest and execution efficiency is the highest. Therefore, we select the worker with the higher load to immigrate the latter task to the worker with the lower load to reach a higher degree of parallelism and allocation fitness.|$|R
40|$|We {{consider}} the classical problem of scheduling n tasks with given processing time on m identical parallel processors {{so as to}} minimizethe maximum <b>completion</b> <b>time</b> of a <b>task.</b> We introduce lower bounds, approximationalgorithms and a branch-and-bound procedure for the exact solution of theproblem. Extensive computational results show that, in many cases, large-sizeinstances of the problem can be solved exactly...|$|R
40|$|Scheduling of real <b>time</b> <b>tasks</b> on cloud {{is one of}} the {{research}} problem, Where the matching of machines and <b>completion</b> <b>time</b> of the <b>tasks</b> are considered. Real <b>time</b> <b>task's</b> matching of machines problem is that, assume number of active hosts are p, number of VMs in each host are q. Maximum number of possible VMs to schedule a single task is (p*q). If we need to schedule r tasks, number of possibilities are (p*q) ^r. So scheduling of tasks is NP Hard problem. <b>Completion</b> <b>time</b> constraint of real <b>time</b> <b>task</b> is that if task complete in dead line then only it is useful else it is not. If it is not useful then it is rejected. Earliest Dead line First(EDF) algorithm is well known algorithm for scheduling of real <b>time</b> <b>tasks.</b> EDF is Event Driven scheduling algorithm with priority assign as dynamically with respect to their deadlines. Real <b>time</b> <b>tasks</b> can be periodic, Sporadic, Aperiodic tasks. We have used Aperiodic and Periodic model to evaluate performance of varies scheduling algorithms. In general EDF Scheduler schedule the tasks such that it assign the task to the free available machine without considering the task on that machine will meet the dead line or not. In this work checked the <b>completion</b> <b>time</b> of <b>task</b> on the free available machines before assigning the task to the machine. To assign the task i have used three dierent techniques. First Fit, Best Fit, Worst Fit. Here Fit of task means that the task will complete it's execution on that machine in it's dead line time. These three techniques and Basic EDF are used in scheduling of aperiodic tasks and also periodic tasks. We have study the perfomance of the techniques First Fit EDF(FFE), Best Fit EDF(BFE), Worst Fit EDF(WFE). The simulation has carried out in house simulator using matlab by taking performance parameters as Guarantee Ratio(GT), VM Utilization (VU), and Through Put(TP). In simulation results it is shown that FFE, BFE and WFE algorithms are better in performance than the Basic EDF algorithm...|$|R
40|$|Abstract. A fair {{scheduling}} algorithm {{accounting for}} the weight and execution <b>time</b> of <b>tasks</b> is critical in the Grid environment. The MTWCT (Minimize Total Weighted <b>Completion</b> <b>Time)</b> has been proved to minimize the total weighted <b>completion</b> <b>time</b> {{of a set of}} independent tasks in a processor, but it results in another problem that the response <b>time</b> of some <b>tasks</b> is far longer. To decrease the incidence of the starvation phenomena, an improved algorithm named CSA (Controlled Scheduling algorithm) based on MTWCT is proposed, which computes the ρ factors of tasks by the execution time and weight of step chains, and selects the unexecuted step chain in terms of ρ factor and the executed <b>time</b> of <b>task.</b> Experimental results exhibit that CSA compared with the MTWCT, decreases the <b>completion</b> <b>time</b> of short <b>tasks</b> and the average turnaround time by sacrificing a little total weighted <b>completion</b> <b>time...</b>|$|R
40|$|AbstractScheduling tasks on {{heterogeneous}} resources distributed over a grid {{computing system}} is an NP-complete problem. The main aim for several researchers {{is to develop}} variant scheduling algorithms for achieving optimality, and they have shown a good performance for tasks scheduling regarding resources selection. However, using of the full power of resources is still a challenge. In this paper, a new heuristic algorithm called Sort-Mid is proposed. It aims to maximizing the utilization and minimizing the makespan. The new strategy of Sort-Mid algorithm is to find appropriate resources. The base step {{is to get the}} average value via sorting list of <b>completion</b> <b>time</b> of each <b>task.</b> Then, the maximum average is obtained. Finally, the task has the maximum average is allocated to the machine that has the minimum <b>completion</b> <b>time.</b> The allocated <b>task</b> is deleted and then, these steps are repeated until all tasks are allocated. Experimental tests show that the proposed algorithm outperforms almost other algorithms in terms of resources utilization and makespan...|$|R
40|$|International audienceWe {{consider}} the following scheduling setting: a set of n tasks have to be executed {{on a set of}} m identical machines. It is well known that shortest processing time (SPT) schedules are optimal for the problem of minimizing the total sum of <b>completion</b> <b>times</b> of the <b>tasks.</b> In this paper, we measure the quality of SPT schedules, from an approximation point of view, with respect to the following optimality criteria: sum of <b>completion</b> <b>times</b> per machine, global fairness, and individual fairness...|$|R
3000|$|... and code {{represents}} {{the code of}} the task to be executed by the resource. We consider that tasks are computationally intensive, that is, the input data transfer for each task is negligible. The code of the task is also small, and thus transferring it does not influence much to the <b>completion</b> <b>time</b> of the <b>task.</b> Hereafter, the terms application and job are used interchangeably.|$|R
40|$|We {{consider}} {{the problem of}} scheduling n independent multiprocessor tasks with release dates on a xed number of processors, where {{the objective is to}} compute a non-preemptive schedule minimizing the average weighted <b>completion</b> <b>time.</b> For each <b>task,</b> in addition to its processing time and release date, there is given a prespeci ed, dedicated subset of processors which are required to process the task simultaneously...|$|R
40|$|In {{order to}} {{seamlessly}} integrate a human computation com-ponent (e. g., Amazon Mechanical Turk) {{within a larger}} pro-duction system, {{we need to have}} some basic understanding of {{how long it takes to}} complete a task posted for comple-tion in a crowdsourcing platform. We present an analysis of the <b>completion</b> <b>time</b> of <b>tasks</b> posted on Amazon Mechanical Turk, based on a dataset containing 165, 368 HIT groups, with a total of 6, 701, 406 HITs, from 9, 436 requesters, posted over a period of 15 months. We model the <b>completion</b> <b>time</b> as a stochastic process and build a statistical method for predict-ing the expected <b>time</b> for <b>task</b> <b>completion.</b> We use a survival analysis model based on Cox proportional hazards regression. We present the preliminary results of our work, showing how time-independent variables of posted tasks (e. g., type of the task, price of the HIT, day posted, etc) affect <b>completion</b> <b>time.</b> We consider this a first step towards building a comprehensive optimization module that provides recommendations for pric-ing, posting time, in order to satisfy the constraints of the requester...|$|R
40|$|We {{examine the}} problem of {{optimizing}} the reallocation and execution of divisible load originating in merent amounts at the sites of an interconnected set of heterogeneous processors characterized by their load computing speeds and II 0 speeds. Each processor imposes, a priori, a hard deadline on its allocated task completion. The objective of load retasking and redistribution, which is implemented at runtime, is twofold: to prescribe feasible load allocations, and to minimize the job execution <b>completion</b> <b>time.</b> We present the necessary and st@cient conditions {{for the existence of}} feasible reallocations, and for a feasible reallocation to be optimal in the sense of minimum <b>completion</b> <b>time.</b> When <b>task</b> <b>completions</b> of an optimal reallocation occur before the specified processor deadlines, the deadlines can be advanced by the amount of laxity to obtain the tightest deadlines. 1...|$|R
40|$|The {{purpose of}} this study is to explore the {{possibility}} of multimodal trivariate thematic maps by utilizing auditory and haptic displays. With two different modes of display (color only displays and multimodal displays with color, audio, and haptic), the <b>completion</b> <b>time</b> of <b>tasks</b> and the recall (retention) rate were measured in two separate experiments. In terms of the <b>completion</b> <b>time,</b> with minimal learning experience, participants could accomplish the tasks at the same level of speed in both modes. For the recall rate, multimodal displays have much higher recall rates. It is speculated that the natural quantitative hierarchies in auditory and haptic displays provide an advantage in the use of multimodal displays. These findings confirmed the possibility of using auditory and haptic displays in visually dominant geographic information systems (GIS) for multi-variate thematic maps...|$|R
40|$|This thesis {{presents}} Cognitive Description and Evaluation of Interaction (CoDeIn), {{a framework}} that allows one to describe, compare, and estimate <b>completion</b> <b>times</b> for <b>tasks</b> that are designed {{in a variety of}} interaction styles. <b>Task</b> <b>time</b> estimates based upon evaluations performed with CoDeIn are consistently more accurate than evaluations carried out using existing modelbased evaluation methods. This accuracy arises from several sources, including separating and distinguishing between different forms of knowledge necessary for performing the task. This distinction allows [...] as not provided by other methods [...] the ability to model non-expert task performance by estimating knowledge and its effect upon <b>task</b> <b>completion</b> <b>time.</b> The accuracy of the CoDeIn methodology is supported by several experiments that compare the predictions produced by CoDeIn to actual measurements and predictions from the GOMSL methodology. To utilize GOMSL, several sub-models must be created, including a model of grasping an...|$|R
30|$|As can be {{seen from}} Fig.  9, the overall {{distribution}} of <b>task</b> <b>completion</b> <b>time</b> in three cases is consistent although the <b>task</b> <b>completion</b> <b>time</b> of ten subjects is slightly different. The guidance force will shorten the <b>task</b> <b>completion</b> <b>time</b> in both two scenarios. In the case of the virtual robot scenario, <b>task</b> <b>completion</b> <b>time</b> was reduced by 15.3 % at most and 8 % on average with 2  N guidance force compared with no guidance force. When 4  N guidance force was available, <b>task</b> <b>completion</b> <b>time</b> was shortened by 20.3 % at most and 12.7 % on average. In the ball tracking scenario, <b>task</b> <b>completion</b> <b>time</b> reduction was 10.77 % at most and 6.7 % on average with 2  N guidance force compared with no guidance force. When 4  N guide force was available, <b>task</b> <b>completion</b> <b>time</b> was shortened by 16.60 % at most and 10.6 % on average. The result indicates that the guidance force can give the operator helpful hint to improve the operation efficiency and to shorten the <b>task</b> <b>completion</b> <b>time.</b> Although <b>task</b> <b>completion</b> <b>time</b> is averagely shortened with 4  N guide force compared with 2  N guide force, further experiments should be carried out to study the optimal guidance force for different subjects and different tasks.|$|R
40|$|This paper {{assumes a}} user-oriented {{point of view}} in {{examining}} the performability of a dependable computing system. The investigated performability measure is the eective <b>time</b> that a <b>task,</b> with an assigned work requirement, takes to be executed by the system. Assuming that the system changes its performance characteristics randomly in time, the stochastic model representing the <b>task</b> <b>completion</b> <b>time</b> is formulated and analysed. Applications and extensions of the basic model are discussed. Finally, the <b>completion</b> <b>time</b> model is reformulated in the language of stochastic Petri nets, and possible computational approaches are examplied. 1 Introduction The <b>completion</b> <b>time</b> of a <b>task</b> measures the <b>time</b> that a <b>task</b> takes to be executed by a computing system. If the system changes its computational power randomly in time during the execution, the <b>task</b> <b>completion</b> <b>time</b> is a random variable. The analytical and numerical computation of the cumulative distribution function (Cdf) of the task co [...] ...|$|R
30|$|It can be {{approximated}} {{that increasing}} the number of microrobots will linearly reduce the <b>completion</b> <b>time</b> of microassembly <b>tasks</b> until a saturation point is reached. Beyond this saturation point, the microrobot density will limit the amount of parallel micromanipulation that can occur. The maximum number of 10 -μm-diameter OFB microrobots that theoretically can be generated in the field of view used here (600  μm by 450  μm) is 2, 700 microrobots. However, the current system does not approach that limit, so the linear relationship can be used to estimate the impact on <b>task</b> <b>completion</b> <b>time.</b>|$|R
