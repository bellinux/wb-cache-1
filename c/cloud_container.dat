3|29|Public
5000|$|It is {{a private}} <b>cloud</b> <b>container</b> to run {{pre-built}} Apps and to use custom apps ...|$|E
40|$|Recent {{years have}} seen an {{increased}} adoption of container technology for software deployment and lightweight virtualization. More recently, container orchestration systems provide a platform for container deployment and management of cluster resources. Software-as-a-Service (SaaS) providers traditionally make use of middleware to facilitate multi-tenancy in a federated <b>cloud.</b> <b>Container</b> orchestration presents many opportunities in achieving scalability and providing cost-efficient multi-tenancy. In this paper, we outline opportunities and challenges for multi-cloud deployment of containerized SaaS applications. status: publishe...|$|E
40|$|Docker {{containers}} are {{an emerging}} standard for deploying software on various platforms {{and in the}} cloud. Containers allow for high velocity of deployment and decrease dif-ferences between different environments. A further abstraction is {{the introduction of a}} cluster layer to transparently distribute a set of Docker containers to multiple hosts. This bachelor thesis is introducing a solution consisting of Mesosphere and Docker, to address the challenges of the cloud model, like ensuring fault-tolerance and providing scaling mechanisms. The self-healing mechanisms of Mesosphere are evaluated and compared, to decide which type of failure is the worst case for the system and for run-ning applications. A concept for an automated instance-scaling mechanism is developed and demonstrated, because this feature is missing in the Mesosphere concept. It is also shown, that applications can use idle resources while respecting given conditions. Docker Container werden mehr und mehr zum Standard bei der Erstellung von Software für verschiedene Plattformen, sowie für die <b>Cloud.</b> <b>Container</b> ermöglichen eine schnelle Bereitstellung von Software und verringern die Abhängigkeit von der Umgebung. Eine weitere Abstraktion ist die Einführung eines weiteren Cluster Layers, um Docker Con-tainer transparent auf die vorhandenen Hosts zu verteilen. Diese Bachelorarbeit stell...|$|E
50|$|ManageIQ is an {{open source}} cloud {{management}} platform. It was founded by Red Hat as a community project in 2014, and forms the basis for its CloudForms product. It allows centralized management of various virtualization, private <b>cloud,</b> public <b>cloud,</b> <b>containers,</b> middleware and software defined networking technologies.|$|R
40|$|Containerisation {{is widely}} {{discussed}} as a lightweight virtualisation solution. Apart from exhibiting benefits over traditional virtual {{machines in the}} <b>cloud,</b> <b>containers</b> are especially relevant for Platform-as-a-Service (PaaS) clouds to manage and orchestrate applications through containers as an application packaging mechanism. We discuss the requirements that arise from having to facilitate applications through distributed multi-cloud platforms...|$|R
40|$|<b>Cloud</b> <b>containers</b> {{represent}} a new, light-weight alternative to virtual machines in cloud computing. A user job may be {{described by a}} container graph that specifies the resource profile of each container and container dependence relations. This work {{is the first in}} the cloud computing literature that designs efficient market mechanisms for <b>container</b> based <b>cloud</b> jobs. Our design targets simultaneously incentive compatibility, computational efficiency, and economic efficiency. It further adapts the idea of batch online optimization into the paradigm of mechanism design, leveraging agile creation of <b>cloud</b> <b>containers</b> and exploiting delay tolerance of elastic cloud jobs. The new and classic techniques we employ include: (i) compact exponential optimization for expressing and handling non-traditional constraints that arise from container dependence and job deadlines; (ii) the primal-dual schema for designing efficient approximation algorithms for social welfare maximization; and (iii) posted price mechanisms for batch decision making and truthful payment design. Theoretical analysis and trace-driven empirical evaluation verify the efficacy of our container auction algorithms...|$|R
40|$|Containerized {{data centers}} {{can improve the}} {{computational}} density of IaaS layers. This intensive high-concurrency environment has high requirements for message scheduling and container processing. In the paper, an elastically scalable strategy for <b>cloud</b> <b>containers</b> based on predictive message scheduling is introduced, {{in order to reduce}} the delay of messages and improve the response time of services and the utilization of container resources. According to the busy degree of different containers, a management strategy of multiple containers at message-granularity level is developed, which gives the containers better elasticity. The simulation results show that the proposed strategy improves service processing efficiency and reduces response latency compared with existing solutions...|$|R
40|$|This paper {{presents}} ESCAPE, {{an informed}} moving target defense mechanism for <b>cloud</b> <b>containers.</b> ESCAPE models {{the interaction between}} attackers and their target containers as a "predator searching for a prey" search game. Live migration of Linux-containers (prey) is used to avoid attacks (predator) and failures. The entire process is guided by a novel host-based behavior-monitoring system that seamlessly monitors containers for indications of intrusions and attacks. To evaluate ESCAPE effectiveness, we simulated the attack avoidance process based on a mathematical model mimicking the prey-vs-predator search game. Simulation results show high container survival probabilities with minimal added overhead. Comment: Published version is available on IEEE Xplore at [URL]...|$|R
5000|$|Orchestration Automation - Otter can spin up <b>cloud</b> servers, build <b>containers,</b> deploy packages, patch servers, or {{any other}} multi-server/service {{automation}} ...|$|R
50|$|Planned 2016 {{events will}} cover various trends in open source, {{including}} Big Data, <b>cloud</b> native applications, <b>containers,</b> IoT, networking, security, and more.|$|R
40|$|At the moment, <b>cloud</b> <b>containers</b> are a {{hot topic}} in the IT world in general, and {{security}} in particular. The world's top technology companies, including Microsoft, Google and Facebook, all use them. Although it's still early days, containers are seeing increasing use in production environments. Containers promise a streamlined, easy-to-deploy and secure method of implementing specific infrastructure requirements, and they also offer an alternative to virtual machines. The key thing to recognize with <b>cloud</b> <b>containers</b> {{is that they are}} designed to virtualize a single application [...] e. g., you have a MySQL container and that's all it does, provide a virtual instance of that application. Containers create an isolation boundary at the application level rather than at the server level. This isolation means that if anything goes wrong in that single container (e. g., excessive consumption of resources by a process) it only affects that individual container and not the whole VM or whole server. It also stops compatibility problems between applications that reside on the same operating system (OS). But despite their success, containers still present challenges. Container scalability, for example, remains somewhat of a mystery. Some organizations struggle when trying to scale Docker, one of the leading container technologies. There are couple of Open Source container cluster management tool. Each cluster management technology has something unique and different to offer. Kubernetes and Docker Swarm are probably two most commonly used tools to deploy containers inside a cluster. Both are created as helper tools {{that can be used to}} manage a cluster of containers and treat all servers as a single unit. When trying to make a choice between Docker Swarm and Kubernetes, think in following terms. Do you want to depend on Docker itself solving problems related to clustering. If you do, choose Swarm. If something is not supported by Docker it will be unlikely that it will be supported by Swarm since it relies on Docker API. On the other hand, if you want a tool that works around Docker limitations, Kubernetes might be the right one for you. Kubernetes was not built around Docker but is based on Google’s experience with containers. It is opinionated and tries to do things in its own wa...|$|R
40|$|This paper {{analyzes}} the I/O and network {{behavior of a}} large class of home, personal and enterprise applications. Through user studies and measurements, we find that users and application developers increasingly {{have to deal with}} a de facto distributed system of specialized storage containers/file systems, each exposing complex data structures, and each having different naming and metadata conventions, caching and prefetching strategies and transactional properties. Two broad dichotomies emerge from this. First, there is tension between the traditional local file system and <b>cloud</b> storage <b>containers.</b> Local file systems have high performance, but they lack support for rich data structures, like graphs, that other storage containers provide. Second, distinct <b>cloud</b> storage <b>containers</b> provide different operational semantics and data structures. Transferring data between these containers is often lossy leading to added data management complexity for users and developers. We believe our analysis directly impacts the way users understand their data, designers build and evaluate the success of future storage systems and application developers program to APIs provided by the storage systems. ...|$|R
30|$|When a task is {{offloaded}} in {{the edge}} <b>cloud,</b> the <b>container’s</b> manager will decide in which container the application will be processed. A container {{is characterized by}} a triplet of allocated resources (CPU, RAM, and network bandwidth). Each offloading request is considered as a set of tasks to instantiate in the Cloud-RRH. Each task has a delay constraint and is characterized by its resource requirements in terms of CPU, RAM, and network bandwidth.|$|R
5000|$|Docker can be {{integrated}} into various infrastructure tools, including Amazon Web Services, Ansible, CFEngine, Chef, Google Cloud Platform, [...] IBM Bluemix, HPE Helion Stackato, Jelastic, Jenkins, Kubernetes, Microsoft Azure, OpenStack Nova, OpenSVC, Oracle <b>Container</b> <b>Cloud</b> Service, Puppet, Salt, Vagrant, and VMware vSphere Integrated Containers.|$|R
5000|$|The project's current vision {{statement}} is new as of October 2010, when the Board worked to synthesize ideas {{from many different}} parts of the community into a concise statement. In spring 2017, the board and Project Leader Matthew Miller in particular began work on drafting an updated mission statement for the project, with a proposal in April reading [...] "Fedora creates an innovative platform that lights up hardware, <b>clouds,</b> and <b>containers</b> for software developers and community members to build tailored solutions for their users." ...|$|R
50|$|On December 18, 2015, Oracle {{signed and}} closed an {{agreement}} to acquire StackEngine. All StackEngine employees joined Oracle as part of Oracle Cloud. Oracle announced the Oracle <b>Container</b> <b>Cloud</b> Service - based on the StackEngine technology and built by the StackEngine team - at Oracle OpenWorld 2016.|$|R
50|$|WaveMaker RAD Platform enables {{organizations}} to deploy applications on {{public or private}} <b>cloud</b> infrastructure, and <b>containers</b> can be deployed on top of virtual machines or on bare metal. At the same time, WaveMaker RAD Platform enables IT to optimize and improve management of its app infrastructure by providing a graphic user interface (GUI) console and capabilities that leverage the power of Docker containerization.|$|R
40|$|We present Asterism, an {{open source}} data-intensive framework, which {{combines}} {{the strengths of}} traditional workflow management systems with new parallel stream-based dataflow systems to run data-intensive applications across multiple heterogeneous resources, without users having to: re-formulate their methods according to different enactment engines; manage the data distribution across systems; parallelize their methods; co-place and schedule their methods with computing resources; and store and transfer large/small volumes of data. We also present the Data-Intensive workflows as a Service (DIaaS) model, which enables easy data-intensive workflow composition and deployment on <b>clouds</b> using <b>containers.</b> The feasibility of Asterism and DIaaS model have been evaluated using a real domain application on the NSF-Chameleon cloud. Experimental results shows how Asterism successfully and efficiently exploits combinations of diverse computational platforms, whereas DIaaS delivers specialized software to execute data-intensive applications in a scalable, efficient, and robust way reducing the engineering time and computational cost...|$|R
40|$|Everyday law {{enforcement}} officers are executing search warrants and encounter digital devices that form part of the evidence. Agencies are now training first responders to handle upper level searches for relevance, prior to seizure. However problems exist, that this may not locate evidence in a <b>cloud,</b> a <b>container</b> or even a virtual machine. This evidence is essentially volatile in that once the device is turned off, connectivity with the cloud will be lost, encrypted containers will close, virtual machines will cease to operate and drive encryption will be invoked. The once accessible data may now become beyond reach of digital forensic staff, when the credentials to access the data are unknown or not available. This paper has focused on scene actions {{that need to be}} considered when staff, specifically first responders are confronted with a device, that could contain evidence that could be lost if the device is shut down. 19 page(s...|$|R
40|$|Operating System-level {{virtualization}} technology, or containers as {{they are}} commonly known, represents {{the next generation of}} light-weight virtualization, and is primarily represented by Docker. However, Docker's current design does not complement the SLAs from Docker-based <b>container</b> <b>cloud</b> offerings promising both reliability and high availability. The tight coupling between the containers and the Docker daemon proves fatal for the containers' uptime during daemon's unavailability due to either failure or upgrade. We present the design and implementation of HYDRA, which fundamentally isolates the containers from the running daemon. Our evaluation shows that HYDRA imposes only moderate overheads even under load, while achieving much higher container availability. Comment: 6 page...|$|R
40|$|This papers {{presents}} {{details on}} deploying the Environmental Fluid Dynamics Code (EFDC) on a container-based cloud environment. Results are {{compared to a}} bare metal deployment. Application-specific benchmarking tests are complemented by detailed network tests that evaluate isolated MPI communication protocols both at intra-node and inter-node level {{with varying degrees of}} self-contention. Cloud-based simulations report significant performance loss in mean run-times. A containerised environment increases simulation time by up to 50 %. More detailed analysis demonstrates that much of this performance penalty is a result of large variance in MPI communciation times. This manifests as simulation runtime variance on <b>container</b> <b>cloud</b> that hinders both simulation run-time and collection of well-defined quality-of-service metrics...|$|R
40|$|Two {{problems}} of similar mathematical structure are presented: the thermocapillary motion of bubbles and the electrophoresis of colloidal particles. For both problems, it is shown {{that in a}} cloud of n particles surrounded by an infinite expanse of fluid, the velocity of each sphere under creeping flow conditions is equal to the velocity of an isolated particle, unchanged by interactions between the particles. However, when the <b>cloud</b> fills a <b>container,</b> conservation of mass shows that this result cannot continue to hold, and the average translational velocity must be calculated subject to a constraint on the mass flux. It is concluded that the average thermocapillary or electrophoretic translational velocity of a particle in the cloud is related to the effective conductivity of the cloud over the whole range of particle volume fractions, provided that the particles are identical, non-conducting and, for the thermocapillary problem, inviscid...|$|R
40|$|Recently, an {{increasing}} number of public <b>cloud</b> vendors added <b>Containers</b> as a Service (CaaS) to their service portfolio. This is an adequate answer to the growing popularity of Docker, a software technology allowing Linux containers to run independently on a host in an isolated environment. As any software can be deployed in a container, the nature of containers differs and thus assorted allocation and orchestration approaches are needed for their effective execution. In this paper, we focus on containers whose execution value for end users varies over time. A baseline and two dynamic allocation algorithms are proposed and compared with the default Docker scheduling algorithm. Experiments show that the proposed approach can increase the total value obtained from a workload up to three times depending on the workload heaviness. It is also demonstrated that the algorithms scale well with the growing number of nodes in a cloud...|$|R
40|$|Abstract—In <b>cloud</b> computing, virtual <b>containers</b> on {{physical}} resources are provisioned to requesting users. Resource providers may pack as many containers as possible onto {{each of their}} physical machines, or may pack specific types and quantities of virtual containers based on user or system QoS objectives. Such elastic provisioning schemes for resource sharing may present major challenges to scientific parallel applications that require task synchronization during execution. Such elastic schemes may also inadvertently lower utilization of computing resources. In this paper, we describe the elasticity constraint effect and ripple effect that cause a negative impact to application response time and system utilization. We quantify the impact using real workload traces through simulation. Then, we demonstrate that some resource scheduling techniques can be effective in mitigating the impacts. We find that a tradeoff is needed among the elasticity of virtual containers, the complexity of scheduling algorithms, and the response time of applications. General Terms: scheduling, virtualization, parallel application I...|$|R
40|$|International audienceThe {{consolidation}} of services {{is a widely}} accepted technique for IaaS Cloud providers to reducing energy consumption and improving the utilization of their resources. This technique is based on distributing all services in the minimum amount of servers. This way, the overall energy consumption of the datacenter is reduced, as less servers are needed to be active. Traditionally, {{research has focused on}} strategies for {{consolidation of}} Virtual Machines (VMs), but containers are changing the landscape of <b>Cloud</b> services. <b>Containers</b> are expected to optimize the consolidation of services by reducing the amount of needed resources, thus allocating more services using less servers. However, while multiple research works have been produced in the Energy Efficiency (EE) achieved through consolidation of VMs, there is yet no experimental work on how consolidation of containers affects EE, when assuming a given Quality-of-Service (QoS) to the user. In this paper we show an experimental analysis on the effects of consolidation of containers in the QoS and EE, compared to the consolidation of VMs. We demonstrate that the consolidation of containers is indeed more optimal than the one of VMs, both in terms of QoS and EE. Consecutively, we analyze how the degradation of the service is produced both in QoS and EE, and we show how QoS is the variable which is more affected by consolidation. This work provides the necessary scientific background on consolidation of two widely used virtualization technologies, and we believe it is useful for future works on the optimization of resources in datacenters...|$|R
40|$|The {{mosquito}} {{virus vector}} Aedes (Ae.) aegypti exploits {{a wide range}} of containers as sites for egg laying and development of the immature life stages, yet the approaches for modeling meteorologically sensitive container water dynamics have been limited. This study introduces the Water Height and Temperature in Container Habitats Energy Model (WHATCH'EM), a state-of-the-science, physically based energy balance model of water height and temperature in containers that may serve as development sites for mosquitoes. The authors employ WHATCH'EM to model container water dynamics in three cities along a climatic gradient in M 9 xico ranging from sea level, where Ae. aegypti is highly abundant, to 2100 m, where Ae. aegypti is rarely found. When compared with measurements from a 1 -month field experiment in two of these cities during summer 2013, WHATCH'EM realistically simulates the daily mean and range of water temperature for a variety of containers. To examine container dynamics for an entire season, WHATCH'EM is also driven with field-derived meteorological data from May to September 2011 and evaluated for three commonly encountered container types. WHATCH'EM simulates the highly nonlinear manner in which air temperature, humidity, rainfall, <b>clouds,</b> and <b>container</b> characteristics (shape, size, and color) determine water temperature and height. Sunlight exposure, modulated by clouds and shading from nearby objects, plays a first-order role. In general, simulated water temperatures are higher for containers that are larger, darker, and receive more sunlight. WHATCH'EM simulations will be helpful in understanding the limiting meteorological and container-related factors for proliferation of Ae. aegypti and may be useful for informing weather-driven early warning systems for viruses transmitted by Ae. aegypti. CC 999999 /Intramural CDC HHS/United StatesR 01 AI 091843 /AI/NIAID NIH HHS/United States 2017 - 12 - 01 T 00 : 00 : 00 Z 29123363 PMC 5672950 vault: 2519...|$|R
40|$|This study {{investigates the}} {{propagation}} of hypervelocity impact fragment clouds in pressure gas. Fragment clouds were generated through perforation of thin aluminium bumper plates by spherical aluminium projectiles. A thick aluminium backwall plate, placed inside a pressure container at a given distance from the bumper plate, caught the fragments {{to act as a}} witness plate for the residual damage potential of the fragments. Crater depth statistics are presented as a function of container pressure. The fragment cloud was photographed by means of an image converter camera. The images showed a strong deformation of the fragment <b>cloud</b> for increased <b>container</b> pressures and were used to extract residual velocities until up to 50 mu s after impact. The deceleration of the velocity as a function of time after impact suggested an exponential decay function as the best fit to the curve. Thus, maximum fragment impact velocities on the backwall plate could be extrapolated from the axial cloud veloc it ites. The extrapolated cruves were compared with experimental time-of-flight measurements, and proved a good match. Fragment impact velocities and maximum crater depths were used to calculate maximum fragment particle sizes {{as a function of the}} container gas pressure...|$|R
40|$|Spatiotemporal data, {{especially}} {{remote sensing}} data, {{are widely used}} in ecological, geographical, agriculture, and military research and applications. With the development of remote sensing technology, more and more remote sensing data are accumulated and stored in the cloud. An effective way for cloud users to access and analyse these massive spatiotemporal data in the web clients becomes an urgent issue. In this paper, we proposed a new scalable, interactive and web-based cloud computing solution for massive remote sensing data analysis. We build a spatiotemporal analysis platform to provide the end-user with a safe and convenient way to access massive remote sensing data stored in the cloud. The lightweight cloud storage system used to store public data and users’ private data is constructed based on open source distributed file system. In it, massive remote sensing data are stored as public data, while the intermediate and input data are stored as private data. The elastic, scalable, and flexible cloud computing environment is built using Docker, which is a technology of open-source lightweight <b>cloud</b> computing <b>container</b> in the Linux operating system. In the Docker container, open-source software such as IPython, NumPy, GDAL, and Grass GIS etc., are deployed. Users can write scripts in the IPython Notebook web page through the web browser to process data, and the scripts will be submitted to IPython kernel to be executed. By comparing the performance of remote sensing data analysis tasks executed in Docker container, KVM virtual machines and physical machines respectively, we can conclude that the cloud computing environment built by Docker makes the greatest use of the host system resources, and can handle more concurrent spatial-temporal computing tasks. Docker technology provides resource isolation mechanism in aspects of IO, CPU, and memory etc., which offers security guarantee when processing remote sensing data in the IPython Notebook. Users can write complex data processing code on the web directly, so they can design their own data processing algorithm...|$|R
40|$|Modern {{technologies}} are enabling scientists to collect extraordinary amounts of complex and sophisticated data across a {{huge range of}} scales like never before. With this onslaught of data, we can allow the focal point to shift towards answering {{the question of how}} we can analyze and understand the massive amounts of data in front of us. Unfortunately, lack of standardized sharing mechanisms and practices often make reproducing or extending scientific results very difficult. With the creation of data organization structures and tools which drastically improve code portability, we now have the opportunity to design such a framework for communicating extensible scientific discoveries. Our proposed solution leverages these existing technologies and standards, and provides an accessible and extensible model for reproducible research, called "science in the cloud" (sic). Exploiting scientific <b>containers,</b> <b>cloud</b> computing and cloud data services, we show the capability to launch a computer in the cloud and run a web service which enables intimate interaction with the tools and data presented. We hope this model will inspire the community to produce reproducible and, importantly, extensible results which will enable us to collectively accelerate the rate at which scientific breakthroughs are discovered, replicated, and extended. Comment: 13 pages, 5 figures, 4 tables, 2 appendice...|$|R
40|$|Cloud {{computing}} is {{a modern}} model for having on demand access to a pool ofconfigurable resources like CPU, storage etc. Despite its relative youth however, it has already {{changed the face of}} present-day IT. The ability to request computing power presents a whole new list of opportunities and challenges. Virtual machines, containers and bare-metal machines are the three possible computing resources which a cloud user can ask from a cloud provider. In the context of this master thesis, we will discuss and benchmark these three different deployment methods for a private OpenStack cloud. We will compare and contrast these systems in terms of CPU, networking behavior, disk I/O and RAM performance {{in order to determine the}} performance deterioration of each subsystem. We will also try to empirically determine if private <b>clouds</b> based on <b>containers</b> and physical machines are viable alternatives to the traditional VM based scenario. To achieve these goals, a number of software suites have been selected to act as benchmarks with the aim of stressing their respective subsystem. The output of these benchmarks is collected and the results are compared against each other. Finally, the different types of overhead which take place between these three types are discussed...|$|R
40|$|AbstractOptimizing {{high-performance}} computing applications requires understanding {{of both the}} application and its parallelization approach, the system software stack and the target architecture. Traditionally, performance tuning of parallel applications involves consideration of the underlying machine architecture, including floating point performance, memory hierarchies and bandwidth, interconnect architecture, data placement – among others. The shift to the utility computing model through cloud has created tempting economies of scale across IT and domains, not leaving HPC as an exception as a candidate beneficiary. Nevertheless, the infrastructure abstraction and multi-tenancy inherent to cloud offerings poses great challenges to HPC workloads, requiring a dedicated study of applicability of cloud computing as a viable time-to-solution and efficiency platform. In this paper, we present the evaluation of a widely used hydro-environmental code, EFDC, on a cloud platform. Specifically, we evaluate the target parallel application on Linux containers managed by Docker. Unlike virtualization- based solutions that {{have been widely used}} for HPC <b>cloud</b> explorations, <b>containers</b> are more fit-for-purpose, sporting among others native execution and lightweight resource consumption. Many-core capability is provided by the OpenMP library in a hybrid configuration with MPI for cross-node data movement, and we explore the combination of these in the target setup. For the MPI part, the work flow is implemented as a data-parallel execution model, with all processing elements performing the same computation, on different sub-domains with thread-level, fine-grain parallelism provided by OpenMP. Optimizing performance requires consideration of the overheads introduced by the OpenMP paradigm such as thread initialization and synchronization. Features of the application make it an ideal test case for deployment on modern cloud architectures, including that it: 1) is legacy code written in Fortran 77, 2) has an implicit solver requiring non-local communication that poses a challenge to traditional partitioning methods, communication optimization and scaling and, 3) is a legacy code across academia, research organizations, governmental agencies, and consulting firms. These technical and practical considerations make this study a representative assessment of migrating legacy codes from traditional HPC systems to the cloud. We finally discuss challenges that stem from the containerized nature of the platform; the latter forms another novel contribution of this paper...|$|R

