13|1148|Public
40|$|<b>Component</b> <b>coding</b> is {{the method}} NeuroInterventionalists have {{used for the}} past 20 years to bill {{procedural}} care. The term refers to separate billing for each discrete aspect of a surgical or interventional procedure, and has typically allowed billing the procedural activity, such as catheterization of vessels, separately from the diagnostic evaluation of radiographic images. This work is captured by supervision and interpretation codes. Benefits of <b>component</b> <b>coding</b> will be reviewed in this article. The American Medical Association/Specialty Society Relative Value Scale Update Committee has been filtering for codes that are frequently reported together. NeuroInterventional procedures {{are going to be}} caught in this filter as our codes are often reported simultaneously as for example routinely occurs when procedural codes are coupled to those for supervision and interpretation. Unfortunately, history has shown that when bundled codes have been reviewed at the RUC, there has been a trend to lower overall RVU value for the combined service compared with the sum of the values of the separate services...|$|E
40|$|Configural and {{holistic}} coding are {{hallmarks of}} face perception. Although {{recent studies have}} shown that own-race faces are coded more holistically than other-race faces, the evidence for better configural coding of own-race faces is equivocal. We directly measured configural and <b>component</b> <b>coding</b> of own- and other-race male faces in Caucasian and Chinese participants. We manipulated individual features (components) or their spatial relations (configurations) using a novel morphing method to vary difficulty parametrically and tested sensitivity to these changes in a sequential matching task. Both configural and <b>component</b> <b>coding</b> were better for upright own-race than for upright other-race faces. Inversion unpaired detection of configural changes more than it did detection of component changes, but also impaired performance more for easier discriminations, independent of type of change. These results challenge explanations of face expertise that rely solely on configural and holistic processing, and also call into question the widespread interpretation of large inversion decrements as diagnostic of configural coding. Copyright 2006 Psychonomic Society, Inc. link_to_subscribed_fulltex...|$|E
40|$|In {{designing}} {{new product}} {{the ability to}} retrieve drawings of existing components is important if costs are {{to be controlled by}} preventing unnecessary duplication if parts. <b>Component</b> <b>coding</b> and classification systems have been used successfully for these purposes but suffer from high operational costs and poor usability arising directly from the manual nature of the coding process itself. A new version of an existing coding system (CAMAC) has been developed to reduce costs by automatically coding engineering drawings. Usability is improved be supporting searches based on a drawing or sketch of the desired component. Test results from a database of several thousand drawings are presented...|$|E
40|$|AbstractA {{classification}} {{theory is}} developed for pairs of simple closed curves (A,B) {{in the sphere}} S 2, assuming that A∩B has finitely many components. Such a pair of simple closed curves is called an SCC-pair, and two SCC-pairs (A,B) and (A′,B′) are equivalent {{if there is a}} homeomorphism from S 2 to itself sending A to A′ and B to B′. The simple cases where A and B coincide or A and B are disjoint are easily handled. The <b>component</b> <b>code</b> is defined to provide a classification of all of the other possibilities. The <b>component</b> <b>code</b> is not uniquely determined for a given SCC-pair, but it is straightforward that it is an invariant; i. e., that if (A,B) and (A′,B′) are equivalent and C is a <b>component</b> <b>code</b> for (A,B), then C is a <b>component</b> <b>code</b> for (A′,B′) as well. It is proved that the <b>component</b> <b>code</b> is a classifying invariant in the sense that if two SCC-pairs have a <b>component</b> <b>code</b> in common, then the SCC-pairs are equivalent. Furthermore <b>code</b> transformations on <b>component</b> <b>codes</b> are defined so that if one <b>component</b> <b>code</b> is known for a particular SCC-pair, then all other <b>component</b> <b>codes</b> for the SCC-pair can be determined via code transformations. This provides a notion of equivalence for component codes; specifically, two <b>component</b> <b>codes</b> are equivalent if there is a code transformation mapping one to the other. The main result of the paper asserts that if C and C′ are <b>component</b> <b>codes</b> for SCC-pairs (A,B) and (A′,B′), respectively, then (A,B) and (A′,B′) are equivalent if and only if C and C′ are equivalent. Finally, a generalization of the Schoenflies theorem to SCC-pairs is presented...|$|R
40|$|Recent {{literature}} presents {{methods for}} the analysis of concatenated coding schemes by solely characterizing the behavior of the <b>component</b> <b>codes</b> [4], [12], [16], [9], [7]. <b>Component</b> <b>codes</b> are analyzed either analytically using unique properties of special <b>component</b> <b>codes,</b> e. g., single [...] parity [...] check code or accumulator, or via simulations...|$|R
40|$|In {{this paper}} we study {{the design of}} low-rate Turbo codes {{efficient}} at very low signal-to-noise ratios (SNRs). The alternative to use low-rate <b>component</b> <b>codes</b> where repeated use of some generator polynomials is allowed is compared to the case when <b>component</b> <b>code</b> generator polynomials are restricted to be unique. It is observed that correlation between the extrinsic information of consecutively transmitted bits, which has {{a negative impact on}} the petformance of the iterative Turbo decoding algorithm, is higher for <b>component</b> <b>codes</b> with repeated generator polynomials than for <b>component</b> <b>codes</b> with unique generator polynomials. It is concluded that correlation of the extrinsic information should be considered as a complement to distance criteria in order to identify <b>component</b> <b>codes</b> that yield efficient low rate turbo codes in the region of very low SNRs...|$|R
40|$|Composite color {{television}} signals are sampled at {{four times the}} color subcarrier and transformed using intraframe two dimensional Walsh functions. It is shown that by properly sampling a composite color signal and employing a Walsh transform the YIQ time signals which sum to produce the composite color signal can be represented, in the transform domain, by three component signals in space. By suitably zonal quantizing the transform coefficients, the YIQ signals can be processed independently to achieve data compression and obtain the same results as <b>component</b> <b>coding.</b> Computer simulations of three bandwidth compressors operating at 1. 09, 1. 53 and 1. 8 bits/ sample are presented. The above results can also {{be applied to the}} PAL color system...|$|E
40|$|The {{purpose of}} this study is to produce a metric to {{accurately}} capture the effects of real time dispatching using object-oriented (00) programming applied in the maintenance phase of the life cycle of hard, real-time systems. The hypothesis presented is that object-oriented programming constructs can be applied in a manner that will have beneficial life-cycle maintenance effects while avoiding adverse timing side effects. This study will use complexity measures instruments that will calculate the Cyciomatic Complexity. This study will examine the dispatching time of each program, and utilize utilities to calculate the number of machine cycles for each program <b>component.</b> <b>Coding</b> techniques will be presented for various program design dilemmas, which examine the object-oriented dispatching features...|$|E
40|$|Zucchini {{yellow mosaic}} virus (ZYMV) is a potyvirus {{transmitted}} by aphids in a non-persistent manner. Isolates having partially or totally lost {{their ability to}} be transmitted by aphids have been isolated and found to be affected in their helper component activities. We have sequenced the helper <b>component</b> <b>coding</b> region of poorly aphid-transmissible (PAT) variants of two strains of ZYMV, E l 5 and R 5 A. Mutations have been identified at the nucleotide level leading to two amino acid changes in the E 15 PAT variant helper component and to one amino acid change located in the cysteine-dch region (well-conserved among potyviruses) in RSA PAT variant helper component. The mutation in the R 5 A variant changes the same amino acid as the one identified in potato virus C, a non-transmissible strain of potat...|$|E
40|$|Classic Low-Density Parity-Check (LDPC) codes have {{recently}} been used as <b>component</b> <b>codes</b> in Multilevel Coding (MLC) due to their impressive BER performance as well as owing to their flexible coding rates. In this paper, we proposed a Multilevel Coding invoking Generalized Low-Density Parity-Check (GLDPC) <b>component</b> <b>codes,</b> which is capable of outperforming the classic LDPC <b>component</b> <b>codes</b> at a reduced decoding latency, when communicating over AWGN and uncorrelated Rayleigh fading channels...|$|R
40|$|The {{concept of}} {{generalized}} concatenated quantum codes (GCQC) provides a systematic way for constructing good quantum <b>codes</b> from short <b>component</b> <b>codes.</b> We introduce a stabilizer formalism for GCQCs, which {{is achieved by}} defining quantum coset codes. This formalism offers a new perspective for GCQCs and enables us to derive a lower bound on the code distance of stabilizer GCQCs from <b>component</b> <b>codes</b> parameters,for both non-degenerate and degenerate <b>component</b> <b>codes.</b> Our formalism also shows how to exploit the error-correcting capacity of <b>component</b> <b>codes</b> to design good GCQCs efficiently. Comment: 5 pages, 2 figures, International Symposium on Information Theory, 7 July - 12 July 2013, Istanbul, Turke...|$|R
40|$|Abstract – Classic Low-Density Parity-Check (LDPC) codes have {{recently}} been used as <b>component</b> <b>codes</b> in Mul-tilevel Coding (MLC) due to their impressive BER perfor-mance as well as owing to their flexible coding rates. In this paper, we proposed a Multilevel Coding invoking Gen-eralized Low-Density Parity-Check (GLDPC) <b>component</b> <b>codes,</b> which is capable of outperforming the classic LDPC <b>component</b> <b>codes</b> at a reduced decoding latency, when com-municating over AWGN and uncorrelated Rayleigh fading channels. 1...|$|R
40|$|This paper {{proposes a}} tonal <b>component</b> <b>coding</b> {{algorithm}} for a codec that employs a transform followed by Human coding, such as MPEG- 2 Audio NBC (Non-Backward Com-patible) [1]. After the input audio signal is mapped onto a frequency domain, the proposed algorithm withdraws local maximum components that degrade coding eciency. By this withdrawal, the atness {{of the spectrum}} increases and the eciency in Human coding is improved. The with-drawn components are encoded separately as side informa-tion. When the frequency resolution of the time/frequency mapping is high, this algorithm works more eectively since local maximum samples appear more frequently with such a mapping. Simulation results show that this algorithm achieves as much as 11 % bit reduction per frame and im-proves the coding eciency in 41 % of all the audio frames. 1...|$|E
40|$|Describes {{the basic}} {{principles}} of a digital television system which has been designed and implemented at the Telecommunication and Microwaves Laboratory of the Universite Catholique de Louvain. The aim of this system was to reach bit rates of the order of 34 Mbit/s. To achieve this, the system uses <b>component</b> <b>coding,</b> expands the signal by removing horizontal blanks, and carries out a combined interframe interpolation and Hadamard transform which roughly equals the vertical and horizontal resolutions. After bit allocation, the signal is converted into a serial stream of data and transmitted. The inverse operations are made at the receiver, where a 625 lines picture is restored. Those principles were implemented and experimented on a transmission via OTS Satellite. Prospects discussed include several sound channels and teletext capabilities and improvements with use of a reduced frame memory. Anglai...|$|E
40|$|ArticleThis article {{introduces}} the new Family of Ethnic Power Relations (EPR) data sets, version 2014, {{which is the}} latest in a series of data sets on ethnicity that have stimulated civil war research in the past decade. The EPR Family provides data on ethnic groups’ access to state power, their settlement patterns, links to rebel organizations, transborder ethnic kin relations, and intraethnic cleavages. The new 2014 version does not only extend the data set’s temporal coverage from 2009 to 2013, but it also offers several new features, such as a new measure of regional autonomy that is independent of national-level executive power and a new data set <b>component</b> <b>coding</b> intraethnic identities and cleavages. Moreover, for the first time, detailed documentation of the EPR data is provided through the EPR Atlas. This article presents these novelties in detail and compares the EPR Family 2014 to the most relevant alternative data sets on ethnicity. Swiss National Science FoundationSwiss Agency for Development and Cooperation (SDC...|$|E
40|$|Abstract — This paper {{gives an}} {{overview}} of three different classes of convolutional codes that are suitable for iterative decoding. They are characterized {{by the type of}} <b>component</b> <b>codes</b> that are used to construct the overall codes, which can be trivial parity-check constraints, block <b>component</b> <b>codes,</b> or convolutional <b>component</b> <b>codes.</b> Distance properties and iterative decoding performance are considered. All three classes of codes are asymptotically good, allow simple encoding, and can be decoded efficiently using iterative pipeline decoding architectures. I...|$|R
40|$|A proven {{means of}} {{communicating}} reliably in a burst-error channel is the code interleaving scheme. Code symbols {{from a number}} of <b>component</b> <b>codes</b> are interleaved before being sent through the channel. This method effectively distributes the error detection and correction burden among the <b>component</b> <b>codes</b> and makes errors occurring in a codeword from each <b>component</b> <b>code</b> more or less independent. Erasure decoding techniques allow further refinement on the code interleaving concept. Their application leads to improved overall code performance when the symbol depth of the lead code is shallow compared to the average error-burst length of the channel. Theoretical formulations derived for predicting the performance of separate decoding and erasure decoding schemes are valuable in providing reasonably good estimates on redundancy requirements of the <b>component</b> <b>codes...</b>|$|R
40|$|We {{present a}} general {{framework}} {{for the construction of}} quantum tensor product codes (QTPC). In a classical tensor product code (TPC), its parity check matrix is con- structed via the tensor product of parity check matrices of the two <b>component</b> <b>codes.</b> We show that by adding some constraints on the <b>component</b> <b>codes,</b> several classes of dual-containing TPCs can be obtained. By selecting different types of <b>component</b> <b>codes,</b> the proposed method enables the construction of a large family of QTPCs and they can provide a wide variety of quantum error control abilities. In particular, if one of the <b>component</b> <b>codes</b> is selected as a burst-error-correction code, then QTPCs have quantum multiple-burst-error-correction abilities, provided these bursts fall in distinct subblocks. Compared with concatenated quantum <b>codes</b> (CQC), the <b>component</b> <b>code</b> selections of QTPCs are much more exible than those of CQCs since only one of the <b>component</b> <b>codes</b> of QTPCs needs to satisfy the dual-containing restriction. We show {{that it is possible to}} construct QTPCs with parameters better than other classes of quantum error-correction codes (QECC), e. g., CQCs and quantum BCH codes. Many QTPCs are obtained with parameters better than previously known quantum codes available in the literature. Several classes of QTPCs that can correct multiple quantum bursts of errors are constructed based on reversible cyclic codes and maximum-distance-separable (MDS) codes. Comment: 18 pages, 4 table...|$|R
40|$|This article {{introduces}} the new Family of Ethnic Power Relations (EPR) data sets, version 2014, {{which is the}} latest in a series of data sets on ethnicity that have stimulated civil war research in the past decade. The EPR Family provides data on ethnic groups ’ access to state power, their settlement patterns, links to rebel organizations, transborder ethnic kin relations, and intraethnic cleavages. The new 2014 version does not only extend the data set’s temporal coverage from 2009 to 2013, but it also offers several new features, such as a new measure of regional autonomy that is independent of national-level executive power and a new data set <b>component</b> <b>coding</b> intraethnic identities and cleavages. Moreover, for the first time, detailed documentation of the EPR data is provided through the EPR Atlas. This article presents these novelties in detail and compares the EPR Family 2014 to the most relevant alternative data sets on ethnicity...|$|E
40|$|An {{approach}} is proposed for automatic fault detection {{in a population}} of mechatronic systems. The idea is to employ self-organizing algorithms that produce low-dimensional representations of sensor and actuator values on the vehicles, and compare these low-dimensional representations among the systems. If a representation in one vehicle is found to deviate from, or to be not so similar to, the representations {{for the majority of}} the vehicles, then the vehicle is labeled for diagnostics. The presented approach makes use of principal <b>component</b> <b>coding</b> and a measure of distance between linear sub-spaces. The method is successfully demonstrated using simulated data for a commercial vehiclepsilas engine coolant system, and using real data for computer hard drives. © 2008 IEEE. Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must be obtained from the IEEE. </p...|$|E
40|$|International Telemetering Conference Proceedings / October 17 - 20, 1988 / Riviera Hotel, Las Vegas, NevadaIn most of {{the initial}} {{applications}} of digital TV telemetry the video source signal is monochrome (typically RS- 170 standard). However color TV is now employed extensively {{in many of the}} government test ranges, and it is likely that it will be required to digitally transmit the NTSC color TV signal for security and other reasons. It is also likely that the bit rates which will be employed for this transmission will range from 1 to 20 mbps depending upon the application. This paper presents the general issues involved in digitizing color TV signals, describes alternative color coding techniques, compares these alternatives, and describes one particularly promising approach in detail. Alternative coding techniques that will be discussed and analyzed include direct coding of the composite NTSC signal as well as several <b>component</b> <b>coding</b> concepts - Y, I, Q; Y, R-Y, B-Y; and the transmission of chroma lines on an alternating basis. Specific techniques for multiplexing the digitized color component signals will be presented. It is desirable that the color coding technique be an incremental expansion relative to existing monochrome coding concepts. One particular technique which shows promise of meeting this objective is presented and discussed...|$|E
40|$|Two error-erasure {{decoding}} algorithms for product {{codes that}} correct all the error-erasure patterns guaranteed correctable by the minimum Hamming {{distance of the}} product code are given. The first algorithm works when {{at least one of}} the <b>component</b> <b>codes</b> is majority-logic decodable. The second algorithm works for any product code. Both algorithms use the decoders of the <b>component</b> <b>codes...</b>|$|R
40|$|Generalized product codes (GPCs) are {{extensions}} of product codes (PCs) where code symbols {{are protected by}} two <b>component</b> <b>codes</b> but not necessarily arranged in a rectangular array. In this tutorial paper, we review a deterministic construction for GPCs that has been previously proposed by the authors together with an accompanying density evolution (DE) analysis. The DE analysis characterizes the asymptotic performance of the resulting GPCs under iterative bounded-distance decoding of the <b>component</b> <b>codes</b> over the binary erasure channel. As an application, we discuss the analysis and design of three different classes of GPCs: spatially-coupled PCs, symmetric GPCs, and GPCs based on <b>component</b> <b>code</b> mixtures...|$|R
40|$|Turbo codes using short BCH <b>codes</b> as <b>component</b> <b>codes</b> are investigated. The {{bit error}} rate (BER) {{performance}} of the turbo codes is evaluated using binary phase shift keying (BPSK) over additive white Gaussian noise (AWGN) channels. The effects of various concatenated <b>component</b> <b>codes,</b> interleaver size, minimum free-distances, weight-distributions as well as puncturing schemes are investigated using both union-bounding and simulations...|$|R
3000|$|... is minimized. Zhou and Pei {{proposed}} the K-neighborhood Algorithm {{to make sure}} that node identity cannot be re-identified by an adversary with a confidence larger than 1 /k, even though the adversary has background knowledge of the neighborhood graph [12]. The whole process is divided into two phases. First, the algorithm extracts the neighborhoods of all nodes in the network. To facilitate the comparisons among neighborhoods of different nodes, the researchers proposed a neighborhood <b>component</b> <b>coding</b> technique to represent the neighborhoods in a concise way. In the second step, the algorithm greedily organizes nodes into groups and anonymizes the neighborhoods of nodes in the same group. The greedy algorithm is guided by an anonymization cost which is measured by the similarity between the neighborhoods of two nodes. Ying and Wu {{proposed the}} Spectrum Preserving Algorithm which preserves the privacy by randomly perturbing edges in the network [16]. The whole process can be divided into three steps: at first, the eigenvalues of the input graph is computed; and then based on some proved theorems, the boundaries of eigenvalues are given; finally the algorithm perturbs the graph by adding, deleting or switching edges of the graph. If the eigenvalues of perturbed graph is within the given boundaries, the perturbation is accepted and continued for next perturbation. The algorithm terminates until the precondition is satisfied.|$|E
40|$|Generalized product codes (GPCs) are {{extensions}} of product codes (PCs), where code symbols {{are protected by}} two <b>component</b> <b>codes</b> but not necessarily arranged in a rectangular array. We consider a deterministic construction of GPCs (as opposed to randomized code ensembles) and analyze the asymptotic performance over the binary erasure channel under iterative decoding. Our code construction encompasses several classes of GPCs previously proposed in the literature, such as irregular PCs, blockwise braided codes, and staircase codes. It is assumed that the <b>component</b> <b>codes</b> can correct a fixed number of erasures and that the length of each <b>component</b> <b>code</b> tends to infinity. We show that this setup is equivalent to studying {{the behavior of a}} peeling algorithm applied to a sparse inhomogeneous random graph. Using a convergence result for these graphs, we derive the density evolution equations that characterize the asymptotic decoding performance. As an application, we discuss the design of irregular GPCs, employing a mixture of <b>component</b> <b>codes</b> with different erasure-correcting capabilities...|$|R
40|$|Tail [...] biting {{codes are}} {{considered}} as <b>component</b> <b>codes</b> for parallel concatenated block codes. Based {{on the two}} [...] dimensional weight distribution of tail [...] biting codes, we calculate the minimum distance of the parallel concatenated code and give guidelines on how to choose good tail [...] biting <b>component</b> <b>codes.</b> We show how to encode tail [...] biting codes using systematic feedback encoders, which is an important design criterion. The performance of codes with different rate, length, and complexity using iterative (turbo) decoding is evaluated by simulation. 1 Introduction Since the introduction of turbo decoding [1] in 1993, there has been considerable research on the investigation of parallel concatenated coding schemes employing convolutional <b>codes</b> (CCs) as <b>component</b> <b>codes.</b> Using block <b>codes</b> (BCs) as <b>component</b> <b>codes</b> has received less attention. Considering the rate loss imposed by terminating the CC, this is surprising particularly for short block lengths, and is mainly due to the favorable pr [...] ...|$|R
40|$|In {{order to}} achieve {{capacity}} approaching performance, the use of partial unit memory (PUM) <b>component</b> <b>codes</b> with good distance properties in turbo codes and woven turbo codes have been suggested. PUM codes are no more complex, but perhaps less well known than traditionally used convolutional <b>component</b> <b>codes.</b> Turbo codes and woven turbo codes based on PUM codes {{have been shown to}} outperform those based on convolutional codes with no extra decoding complexity. In this paper, the convolutional properties of PUM codes are exploited and how these can be used to construct encoder structures and their trellises is described so that they are suitable for use in the aforementioned parallel concatenated structures. The encoder and trellis construction techniques are illustrated by two example PUM codes. The performance of these <b>codes</b> as <b>component</b> <b>codes</b> in a turbo structure is presented to show the influence of the parameters of the PUM code and how this impacts on the design of suitable <b>component</b> <b>codes</b> in a concatenated structure with capacity approaching performance...|$|R
40|$|International audienceLinear quasi-cyclic product codes over finite {{fields are}} investigated. Given the {{generating}} {{set in the}} form of a reduced Gröbner basis of a quasi-cyclic <b>component</b> <b>code</b> and the generator polynomial of a second cyclic <b>component</b> <b>code,</b> an explicit expression of the basis of the generating set of the quasi-cyclic product code is given. Furthermore, the reduced Gröbner basis of a one-level quasi-cyclic product code is derived...|$|R
40|$|I-Q trellis {{codes are}} known to {{increase}} the time diversity of coded systems. When I-Q codes are used with multiple transmit antennas, the decoding and performance evaluation requires {{the construction of the}} high-complexity super-trellis of the <b>component</b> <b>codes.</b> In the paper, the bit error probability and the design criteria of I-Q ST codes are derived using the transfer functions of the <b>component</b> <b>codes.</b> Conditions for the geometrical uniformity of I-Q space-time (ST) codes are derived from the geometrical uniformity of the <b>component</b> <b>codes.</b> In addition, a low-complexity iterative receiver for I-Q ST codes is presented. The receiver essentially performs iterative detection and decoding. Results show that three iterations of the iterative receiver performs very close to the optimal decoding...|$|R
40|$|Recent {{literature}} presents {{methods for}} the analysis of concatenated coding schemes by solely characterizing the behavior of the <b>component</b> <b>codes</b> [4], [12], [16], [9], [7]. <b>Component</b> <b>codes</b> are analyzed either analytically using unique properties of special <b>component</b> <b>codes,</b> e. g., single-parity-check code or accumulator, or via simulations. The goals of this paper are to find fundamental insights into concatenated codes by analyzing the input-output relation of their components from an information-theoretic point of view. We derive the Information Processing Characteristic (IPC), which completely characterizes the behavior of a coding scheme comprising encoder, code and decoder for the general class of linear codes. For time invariant convolutional codes it is studied how the IPC can be obtained in practice...|$|R
30|$|Another powerful, though simple, {{class of}} {{structured}} LDPC codes {{is represented by}} multiple serially concatenated multiple parity-check (M-SC-MPC) codes [24]. These codes exploit the serial concatenation of very simple components, similarly to what is proposed in [25], where single parity-check <b>component</b> <b>codes</b> are used. By employing different <b>component</b> <b>codes,</b> which however remain very simple, M-SC-MPC codes are described through sparse parity-check matrices which ensure good performance under BP decoding.|$|R
40|$|Generalized product codes (GPCs) are {{extensions}} of product codes (PCs) where code symbols {{are protected by}} two <b>component</b> <b>codes</b> but not necessarily arranged in a rectangular array. We consider a deterministic construction of GPCs (as opposed to randomized code ensembles) and analyze the asymptotic performance over the binary erasure channel under iterative decoding. Our code construction encompasses several classes of GPCs previously proposed in the literature, such as irregular PCs, block-wise braided codes, and staircase codes. It is assumed that the <b>component</b> <b>codes</b> can correct a fixed number of erasures and that the length of each <b>component</b> <b>code</b> tends to infinity. We show that this setup is equivalent to studying {{the behavior of a}} peeling algorithm applied to a sparse inhomogeneous random graph. Using a convergence result for these graphs, we derive the density evolution equations that characterize the asymptotic decoding performance. As an application, we discuss the design of irregular GPCs employing a mixture of <b>component</b> <b>codes</b> with different erasure-correcting capabilities. Comment: accepted for publication in IEEE Transactions on Information Theor...|$|R
40|$|Recent {{literature}} presents {{methods for}} the analysis of concatenated coding schemes by solely characterizing the behavior of the <b>component</b> <b>codes</b> [4, 12, 14, 9, 7]. <b>Component</b> <b>codes</b> are analyzed either analytically using unique properties of special <b>component</b> <b>codes,</b> e. g., single [...] parity [...] check code or accumulator, or via simulations. The goals of this paper are to find fundamental insights into concatenated codes by analyzing the input [...] output relation of their components from an information [...] theoretic point of view. We derive a Information Processing Characteristic (IPC), which completely characterizes the behavior of a coding scheme comprising encoder, code and decoder for the general class of linear codes. For time invariant convolutional codes it is studied how the IPC can be obtained in practice. ...|$|R
40|$|Abstract — We {{present a}} bandwidth-efficient channel coding scheme {{that has an}} overall {{structure}} similar to binary turbo codes, but employs trellis-coded modulation (TCM) codes (including multidimensional <b>codes)</b> as <b>component</b> <b>codes.</b> The combination of turbo codes with powerful bandwidth-efficient <b>component</b> <b>codes</b> leads to a straightforward encoder structure, and allows iterative decoding in analogy to the binary turbo decoder. However, certain special conditions {{may need to be}} met at the encoder, and the iterative decoder needs to be adapted to the decoding of the <b>component</b> TCM <b>codes.</b> The scheme has been investigated for 8 -PSK, 16 -QAM, and 64 -QAM modulation schemes with varying overall bandwidth efficiencies. A simple code choice based on the minimal distance of the punctured <b>component</b> <b>code</b> has also been performed. The interset distances of the partitioning tree can be used to fix the number of coded and uncoded bits. We derive the symbol-by-symbol MAP component decoder operating in the log domain, and apply methods of reducing decoder complexity. Simulation results are presented and compare the scheme with traditional TCM as well as turbo codes with Gray mapping. The results show that the novel scheme is very powerful, yet of modest complexity since simple <b>component</b> <b>codes</b> are used. Index Terms—Decoding, iterative methods, trellis-coded modulation. I...|$|R
40|$|The authors {{define and}} study the {{effective}} free distance of a turbo code. If a turbo code is constructed {{from a number of}} <b>component</b> <b>codes,</b> they argue that the effective free distance can be maximised by choosing the <b>component</b> <b>codes</b> to be IIR convolutional code fragments with maximal input weight- 2 free distance. They then present some theoretical bounds for, and some numerical tables of; IIR code fragments with maximal input weight- 2 free distance...|$|R
