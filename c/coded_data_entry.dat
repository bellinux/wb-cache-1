3|10000|Public
40|$|Methods for {{optimizing}} <b>coded</b> <b>data</b> <b>entry</b> {{in clinical}} systems are a frequent topic of system design. We {{have developed a}} new mechanism {{for this type of}} data entry that we call "Pick From Thousands" (PFT). It combines several known methods, including menu selection, keyword entry, and initial character matching, but adds a new string matching algorithm. The PFT method is more selective than initial character matching for a given number of keystrokes if entries in the coded list have more than one word. Collaborative processing between a PC workstation and the central HELP system computer is used to optimize ease of maintenance and increase the flexibility and performance of the system...|$|E
40|$|BACKGROUND: There {{is a lack}} {{of tools}} to {{evaluate}} and compare Electronic patient record (EPR) systems to inform a rational choice or development agenda. OBJECTIVE: To develop a tool kit to measure the impact of different EPR system features on the consultation. METHODS: We first developed a specification to overcome the limitations of existing methods. We divided this into work packages: (1) developing a method to display multichannel video of the consultation; (2) code and measure activities, including computer use and verbal interactions; (3) automate the capture of nonverbal interactions; (4) aggregate multiple observations into a single navigable output; and (5) produce an output interpretable by software developers. We piloted this method by filming live consultations (n = 22) by 4 general practitioners (GPs) using different EPR systems. We compared the time taken and variations during <b>coded</b> <b>data</b> <b>entry,</b> prescribing, and blood pressure (BP) recording. We used nonparametric tests to make statistical comparisons. We contrasted methods of BP recording using Unified Modeling Language (UML) sequence diagrams. RESULTS: We found that 4 channels of video were optimal. We identified an existing application for manual coding of video output. We developed in-house tools for capturing use of keyboard and mouse and to time stamp speech. The transcript is then typed within this time stamp. Although we managed to capture body language using pattern recognition software, we were unable to use this data quantitatively. We loaded these observational outputs into our aggregation tool, which allows simultaneous navigation and viewing of multiple files. This also creates a single exportable file in XML format, which we used to develop UML sequence diagrams. In our pilot, the GP using the EMIS LV (Egton Medical Information Systems Limited, Leeds, UK) system took the longest time to code data (mean 11. 5 s, 95...|$|E
40|$|Background UK general {{practitioners}} largely conduct computer-mediated consultations. Although historically {{there were}} many small general practice (GP) computer suppliers there are now around five widely used electronic patient record (EPR) systems. A new method has been developed for assessing {{the impact of the}} computer on doctor_patient interaction through detailed observation of the consultation and computer use. Objective To pilot the latest version of a method to measure the difference in coding and prescribing times on two different brands of general practice EPR system. Method We compared two GP EPR systems by observing use in real life consultations. Three video cameras recorded the consultation and screen capture software recorded computer activity. We piloted semi-automated user action recording (UAR) software to record mouse and keyboard use, to overcome limitations in manual measurement. Six trained raters analysed the videos using data capture software to measure the doctor_patient_computer interactions; we used interclass correlation coefficients (ICC) to measure reliability. Results Raters demonstrated high inter-rater reliability for verbal interactions and prescribing (ICC 0. 74 to 0. 99), but for measures of computer use they were not reliable. We used UAR to capture computer use and found it more reliable. <b>Coded</b> <b>data</b> <b>entry</b> time varied between the systems: 6. 8 compared with 11. 5 seconds (P = 0. 006). However, the EPR with the shortest coding time had a longer prescribing time: 27. 5 compared with 23. 7 seconds (P = 0. 64). Conclusion This methodological development improves the reliability of our method for measuring the impact of different computer systems on the GP consultation. UAR added more objectivity to the observationof doctor_computer interactions. If larger studies were to reproduce the differences between computer systems demonstrated in this pilot {{it might be possible to}} make objective comparisons between systems...|$|E
30|$|Data {{collection}} {{was carried out}} through a pre-established record where data are noted. The <b>coding</b> <b>data</b> <b>entry</b> and <b>data</b> analysis are performed using the EpiInfo Version 6 software.|$|R
50|$|<b>Coding</b> and <b>data</b> <b>entry</b> {{services}} include editing completed questionnaires, {{developing a}} coding scheme, and transcribing {{the data on}} to diskettes or magnetic tapes for input into the computer. NRC Data Systems provides such services.|$|R
2500|$|In {{software}} development projects, a [...] "mistake" [...] or [...] "fault" [...] may be introduced at any stage. Bugs arise from oversights or misunderstandings {{made by a}} software team during specification, design, <b>coding,</b> <b>data</b> <b>entry</b> or documentation. For example, a relatively simple program to alphabetize a list of words, the design might fail to consider what should happen when a word contains a hyphen. Or when converting an abstract design into code, the coder might inadvertently create an off-by-one error and fail to sort {{the last word in}} a list. Errors may be as simple as a typing error: a [...] "<" [...] where a [...] ">" [...] was intended.|$|R
50|$|Individual {{cases are}} usually <b>coded</b> for <b>data</b> <b>entry</b> {{at the most}} {{specific}} (LLT) level, and outputs of counts or cases are usually provided at the PT level. The higher levels (HLT, HLGT and SOC) as well as SMQ are used for searching and for organisation and subtotalling of outputs.|$|R
50|$|Limited-service {{suppliers}} {{specialize in}} {{one or a few}} phases of the marketing research project. Services offered by such suppliers are classified as field services, <b>coding</b> and <b>data</b> <b>entry,</b> <b>data</b> analysis, analytical services, and branded products. Field services collect data through the internet, traditional mail, in-person, or telephone interviewing, and firms that specialize in interviewing are called field service organizations. These organizations may range from small proprietary organizations which operate locally to large multinational organizations with WATS line interviewing facilities. Some organizations maintain extensive interviewing facilities across the country for interviewing shoppers in malls.|$|R
30|$|The 2012 ELMPS was {{implemented}} by 39 {{teams in the}} field, each consisting of one supervisor, one reviewer, and four enumerators. Additionally, there were two teams undertaking quality control. All interviewers were trained for 10  days by the technical director and CAPMAS prior to fielding the survey. The fielding of the full 2012 survey took place from March 1, 2012 to June 10, 2012, with more than 90 % of households and individuals surveyed during March and April. Desk review, <b>coding,</b> and <b>data</b> <b>entry</b> and validation at CAPMAS occurred after fielding.|$|R
40|$|This report {{describes}} {{the development of}} an integrated, comprehensive system for analysis of ambulatory care practices. The system includes a network of hospital-based and community-based physician practices in the Rochester, New York area. After <b>coding</b> and <b>data</b> <b>entry,</b> routine clinical information from network practices, including demographics, diagnoses, and procedures, is submitted in computer readable form to be integrated with inpatient, emergency department, and outpatient information extracted from a hospital information system. This integrated information is transformed into patient-related and encounter-related SAS files ready for reporting and analysis. This system provides a research laboratory for examination of ambulatory care practices that combines features of both claims-based databases and cooperative practice networks...|$|R
40|$|A novel {{system is}} {{described}} for recording and storing details of water samples collected from rural African households {{and the water}} sources that they use. The system makes use of handheld computers for <b>data</b> <b>entry</b> instead of paper-based records. Bar codes are used to track water samples from the field to the laboratory, where total coliforms and Escherichia coli counts are enumerated for each sample. Participating household members and their water sources are documented using instamatic photography, enabling more rapid identification on subsequent visits. The system significantly reduces the lag-time between data collection and analysis. The use of bar <b>codes</b> and direct <b>data</b> <b>entry</b> reduces transcription errors that occur with paper-based recording...|$|R
40|$|The {{worldwide}} {{adoption of}} the HL 7 Clinical Document Architecture (CDA) is promoting the availability of <b>coded</b> <b>data</b> (CDA <b>entries)</b> within sections of clinical documents. At the moment, {{an increasing number of}} studies are investigating ways to transform the narratives of CDA documents into machine processable CDA entries. This paper addresses the reverse problem, i. e. obtaining linguistic representations (sentences) from CDA entries. The approach presented employs Natural Language Generation (NLG) techniques and deals with two major tasks: content selection and content expression. The current research proposes a formal semantic representation of CDA entries and investigates how expressive domain ontologies in OWL and SPARQL SELECT queries can contribute to NLG. To validate the proposal, the study has focused on CDA entries from the History of Present Illness sections of CDA consultation notes. The results obtained are encouraging, as the clinical narratives automatically generated from these CDA entries fulfil the clinicians’ expectations...|$|R
40|$|Missing {{data are}} an {{unwanted}} reality in most {{forms of social}} science research, including institutional research. Like troublesome “guests ” at a family gathering, missing data are a nuisance; they impose themselves on research designs and undermine the methodological assumptions of an analysis plan. The primary problems associated with missing data are the threats that they pose to a study’s internal validity (primarily issues of statistical power) and external validity (being able to generalize results to a target population). Even when investigators employ appropriate strategies for coping with missing data, different approaches may lead to substantially different conclusions (Cohen, Cohen, West, and Aiken, 2003). In this chapter we focus on one type of missing data – item non-response. Item non-response, as opposed to participant or unit non-response, occurs when only partial data are available for survey participants or subjects. Item non-response can occur for a multitude of reasons. Mistakes {{can be made in}} <b>coding</b> or <b>data</b> <b>entry,</b> respondents may fail or be unable t...|$|R
40|$|This {{study was}} {{performed}} by the WWAMI Center for Health Workforce Studies (CHWS) and the Health Work Force Institute (HWFI) of the Washington State Hospital Association. The survey and questionnaire were jointly designed by the CHWS and the HWFI. Data collection was conducted by the HWFI; <b>data</b> <b>coding</b> and <b>entry,</b> and <b>data</b> analysis and reporting were conducted by the CHWS. The authors want to acknowledge the considerable time and effort that hospital respondents contributed to this survey. In addition, they want to thank Domi Zhou at the HWFI for valuable data collection assistance and Martha Reeves and Thao Nguyen of the CHWS for their valuable report preparation and <b>data</b> <b>entry</b> assistance. Catherine Veninga of the CHWS provided cartographic support. UNIVERSITY OF WASHINGTON • SCHOOL OF MEDICINE • DEPARTMENT OF FAMILY MEDICIN...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis examines {{the use of}} existing bar code technology {{as a means of}} increasing efficiency and accuracy in the performance of administrative tasks within Department of Defense agencies. Motivated by increasing labor costs, both the private and public sectors have implemented bar code based control systems in a myriad of applications. While the public sector has concentrated on the logistics applications of bar coding through LOGMARS, the private sector has expanded their use of bar <b>code</b> based <b>data</b> <b>entry</b> and management control systems. The focus of this study is directed toward a comparative analysis of the non-logistics bar code applications prevalent in the private sector as potential applications within the DoD. Two specific areas at the Naval Postgraduate School are analyzed as potential bar code test applications for reducing manhours and increasing accuracy in the performance of administrative tasks; namely the NPS Attendance Monitoring System and the NPS Bachelor Quarters Inventory Management System. Major recommendations for future research deal with computer support, funding and cost/benefit analysis. [URL] Commander, United States Nav...|$|R
40|$|The {{licensing}} process {{of a nuclear}} power plant is motivated by the need to protect humans and the environment from ionizing radiation and, at the same time, sets out the basis for the design and determining the acceptability of the plant. An important part of the {{licensing process}} is the realization of accident analysis related to the design basis, which should be documented in the Final Safety Analysis Report (FSAR). There are different options on accidents calculation area by combining the use of computer <b>codes</b> and <b>data</b> <b>entry</b> for licensing purposes. One is the Best Estimate Plus Uncertainty (BEPU), which considers realistic input data and associated uncertainties. Applications of BEPU approaches in licensing procedures were initiated in the 2000 s, first to analysis of Loss of Coolant Accident (LOCA), and then to the accident analysis as a whole, documented in Chapter 15 of the FSAR. This work has as main objective the implementation of BEPU methodology in all analyses contained in FSAR, through the homogenization of the analytical techniques and identification of key disciplines and key topics in the licensing proces...|$|R
40|$|Alpha codes, {{abbreviations}} {{of common}} or scientific bird names, {{have long been}} used by ornithologists. The U. S. Bird Banding Laboratory 2 ̆ 7 s employment of alpha codes has {{become an integral part}} of large ornithological programs across the United States and Canada. Rather than using the full English or scientific name of a bird species, alpha <b>codes</b> allow quicker <b>data</b> <b>entry</b> and can also help to cross-reference other data. The content of this article is a list of alpha codes, current through the American Ornithologists 2 ̆ 7 Union Checklist of North American Birds, Seventh Edition (1998), its following supplements (AOU: 2000, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010), and the most recent published 2 ̆ 2 Official List of the Birds of Nebraska: 20092 ̆ 2 (NOU Records Committee 2009) ...|$|R
40|$|AbstractThe Holy Quran is {{the central}} {{religious}} verbal text of Islam. Muslims are expected to read, understand, and apply {{the teachings of the}} Holy Quran. The Holy Quran was translated to Braille code as a normal Arabic text without having its reciting rules included. It is obvious that the users of this transliteration {{will not be able to}} recite the Quran the right way. Through this work, Quran Braille Translator (QBT) presents a specific translator to translate Quran verses and their reciting rules into the Braille code. Quran Extended Finite State Machine (QEFSM) model is proposed through this study as it is able to detect the Quran reciting rules (QRR) from the Quran text. Basis path testing was used to evaluate the inner work for the model by checking all the test cases for the model. Markov Algorithm (MA) was used for translating the detected QRR and Quran text into the matched Braille <b>code.</b> The <b>data</b> <b>entries</b> for QBT are Arabic letters and diacritics. The outputs of this study are seen in the double lines of Braille symbols; the first line is the proposed Quran reciting rules and the second line is for the Quran scripts...|$|R
40|$|Researchers have {{advocated}} the supplementation of coded fields with free-text fields in electronic medical records (EMRs) to provide clinicians with flexibility during <b>data</b> <b>entry.</b> They cite advantages of more complete data capture and improved clinician acceptance {{and use of}} the EMR. However, free text may have the disadvantage of changing the meaning of <b>coded</b> <b>data,</b> which causes lower data accuracy for applications that cannot read free text. We studied the free-text entries that clinicians made during the recording of medication data. We found that these entries changed the meaning of <b>coded</b> <b>data</b> and lowered data accuracy for the medical decision-support system (MDSS) in our EMR. We conclude that supplemental free-text entries made by clinicians frequently alter the meaning of <b>coded</b> <b>data...</b>|$|R
40|$|The problem {{faced by}} the {{officers}} read electricity meter reading {{is still a lot}} of officers who perform duty of PLN-meter manually. This problem arises because the facility Portable Data Terminal (PDT) is not owned by all officers who have read the meter. Condition they should record the electric meter manually from house to house, and still {{have to go back to}} the office to record meter input data to the server. This problem arises from the idea to make an application as a substitute for Portable Data Terminal. Applications that want to be made, of course applications that make it easier and very possible to be held by all of meter reader?s staff. Application will be made with a mobile base using QR Code technology to replace the existing barcode. Why should the QR Code? Since the QR Code is a sort of 2 Dimensional barcode that contains more data than a barcode, and just using the Mobile camera to scan it. Customer data entered into the Mobile Scan using the QR <b>Code</b> and <b>data</b> <b>entry</b> for <b>data</b> that are dynamic or changeable. Input data is then sent to the server via GPRS Connection HTP, save it into the database. Counting applications on the server takes all the data sent, count them and save the results of a calculation to the database again...|$|R
40|$|We {{describe}} a {{clinical information system}} for hospital-based ambulatory care implemented {{in the context of}} the institution's IAIMS Phase III effort. Key features of this application are physician <b>data</b> <b>entry</b> to maintain summary clinical profiles that include medication lists, problem lists, and preventive care, and integration with other components of the Clinical Information System at the levels of the database, the user interface, and data sharing. A goal of this application is to provide <b>coded</b> <b>data</b> as a substrate for computer-based decision support...|$|R
40|$|Structured {{interviews}} or questionnaires often comprise open-ended questions, {{especially to}} obtain additional {{information from the}} interviewee not covered by standardised questions. Ordinarily, the analysis of these open-ended questions cannot be undertaken by the same computer program, in which quantitative data is entered and managed, which impedes the combination of open-ended and closed answer formats. The usage of the database management program Microsoft Access is widespread. It allows for various ways of entering quantitative data, of data management and <b>data</b> export. The <b>entry</b> of text material is convenient and almost unrestricted due to memo-format variables. Given the possibility to manage quantitative and qualitative data with the same computer software, we tried to use the programming properties of MS Access (Visual Basic with MS-Access-supplements) {{for the purpose of}} content analysis. The present paper comprises a description of the construction of <b>data</b> tables, queries, <b>code</b> lists and <b>data</b> <b>entry</b> forms. In addition, the construction of coding units (paraphrasing of text <b>data),</b> the <b>coding</b> process and the restructuring for subsequent statistical analysis is illustrated. In addition, the export of data into the statistical software package SPSS and the analysis of inter-coder reliability are discussed. This is based on the data collected from open-ended quality of life interviews with chronic schizophrenic persons and a paper-pencil assessment of patient satisfaction during a psychiatric hospital stay. URN: urn:nbn:de: 0114 -fqs 020220...|$|R
40|$|Natural {{language}} processing (NLP) systems can {{help solve the}} <b>data</b> <b>entry</b> problem by providing <b>coded</b> <b>data</b> from textual reports for clinical applications. A number of NLP systems have shown promise, but have not yet achieved wide-spread use for practical applications. In order to achieve such use, a system must have broad coverage of the clinical domain and not be restricted to limited applications. In addition, an NLP system must perform satisfactorily for real-world applications. This paper describes methods and issues associated with an ongoing extension of MedLEE, an operational NLP system, from a limited domain to a domain that encompasses comprehensive clinical information...|$|R
50|$|It is a {{well known}} fact in {{signalling}} (military radio operating) {{that the use of}} morse <b>code</b> and later <b>data</b> transmission and reception could extend the range and add to the versatility of the UK/PRC 320. After Market a number of <b>data</b> <b>entry</b> devices were produced as add ons such as MEROD, TDED and Kipling.|$|R
5000|$|<b>Data</b> <b>entry</b> and {{conversion}} services include: academic <b>data</b> <b>entry,</b> database {{content and}} support, survey digitization, and direct marketing support.|$|R
40|$|Routine {{capture of}} patient data for a {{computer-based}} patient record system remains {{a subject of}} study. Time constraints that require fast <b>data</b> <b>entry</b> and maximal expression power {{are in favor of}} free text <b>data</b> <b>entry.</b> However, using patient data directly for decision support systems, for quality assessment, etc. requires structured <b>data</b> <b>entry,</b> which appears to be more tedious and time consuming. In this paper, a prototype clinical <b>data</b> <b>entry</b> application is described that combines free text and structured <b>data</b> <b>entry</b> in one single application and allows clinicians to smoothly switch between these two different input styles. A knowledge base involving a semantic network of clinical <b>data</b> <b>entry</b> terms and their properties and relationships is used by this application to support structured <b>data</b> <b>entry.</b> From structured <b>data,</b> sentences are generated and shown in a text processor together with the free text. This presentation metaphor allows for easy integrated presentation of structured data and free text...|$|R
50|$|While {{this method}} of quality control clearly is not proof against {{systematic}} errors or operator misread entries from a source document, it is very useful in catching and correcting random miskeyed strokes which occur even with experienced <b>data</b> <b>entry</b> operators. However, {{it proved to be}} a fatally tragic flaw in the Therac 25 incident. This method has survived the keypunch and is available in some currently available <b>data</b> <b>entry</b> programs (e.g. PSPP/SPSS <b>Data</b> <b>Entry).</b> At least one study suggests that single-pass <b>data</b> <b>entry</b> with range checks and skip rules approaches the reliability of two-pass data entry; however, it is desirable to implement both systems in a <b>data</b> <b>entry</b> application.|$|R
40|$|This article {{describes}} a technique for <b>data</b> <b>entry</b> of information obtained from inter-views and questionnaires. Often, investigators have someone type information into an electronic computer database. This {{article describes}} the use of electronic scan-ning forms for <b>data</b> <b>entry.</b> Forms and equipment used for grading examinations {{may be used to}} record responses from questionnaires. This method of <b>data</b> <b>entry</b> is com-patible with field research and can be quicker than hand <b>entry</b> of <b>data.</b> While computers have greatly aided data analysis, a key problem that remains is entering the data. Often, with small data sets (sample sizes of less than 100), someone will literally sit and type in the data. With longer ques-tionnaires or larger sample sizes, the data are usually sent to professional <b>data</b> <b>entry</b> services that type in the data. These approaches result in considerable costs and problems of accuracy unless the data are checked carefully or entered twice. This report focuses on a method of <b>data</b> <b>entry</b> we have used with forms for electronic scanning, reducing <b>data</b> <b>entry</b> time and costs while increasing accuracy. This approach is appropriate for demographic data, closed-ended questions, and questions with five or fewer choices (i. e., most types of questions used in structured interviews). We do not recommend it for coding open-ended or in-depth interviews. THE PROJECTS We have now used this approach to <b>data</b> <b>coding</b> in multiple research pro-jects, all of which used local interviewers. The first was a study of lay beliefs We thank Art Rubel for the inspiration to write this based on discussions at the American Anthro...|$|R
5000|$|IBM 3740 <b>Data</b> <b>Entry</b> System was a <b>data</b> <b>entry</b> {{system that}} was {{announced}} by IBM in 1973. It recorded data on a Diskette, a new recording medium from IBM, for fast, flexible, efficient <b>data</b> <b>entry</b> to either high-production, centralized operations or to decentralized, remote operations. The [...] "Diskette" [...] was more commonly known as an 8-inch floppy disk, ...|$|R
40|$|Self-service {{technologies}} have been gaining increasing importance {{in public and}} private organizations over recent years. One of the predominant responsibilities of the customers in the context of self-service is to enter their data on their own. Self-service for <b>data</b> <b>entry</b> can help organizations to further enhance the efficiency of their processes and to make customer experience smoother. However, as self-service for <b>data</b> <b>entry</b> is intended to be handled without intensive employee assistance, inexp erienced <b>data</b> <b>entry</b> can lead to data quality problems. Although academic research has explored several effects of self-service technologies, there is still a lack of research investigating the effect of self-service <b>data</b> <b>entry</b> on <b>data</b> quality. Thus, in an in-depth case study in cooperation with the German Federal Employment Agency we analyzed how customer self-service for <b>data</b> <b>entry</b> affects <b>data</b> quality and found that assisted self-service <b>data</b> <b>entry</b> leads to highest data qualit...|$|R
5000|$|<b>Data</b> <b>entry</b> by geologists in {{the field}} may take less total time than {{subsequent}} <b>data</b> <b>entry</b> in the office, potentially reducing the overall time needed to complete a project.|$|R
5000|$|SuperMICAR automates the MICAR <b>data</b> <b>entry</b> process. This {{program is}} {{designed}} as an enhancement of the earlier PC-MICAR <b>Data</b> <b>Entry</b> program. Super-MICAR is designed to automatically encode cause-of-death data into numeric entity reference numbers.|$|R
40|$|The {{objective}} {{was to determine the}} conditions under which Automatic Speech Recognition (ASR) is an efficient choice for <b>data</b> <b>entry.</b> In particular the focus was on <b>data</b> <b>entry</b> tasks that are part of constructing military messages. The ADF Formatted Messaging System utilises a structured formatting system to constrain the semantics of a message but also includes a field for unlimited and unstructured text. Hence the <b>data</b> <b>entry</b> tasks involved range from form-filling to free dictation of short phrases. In the experiments, ASR and manual input modes are compared for three <b>data</b> <b>entry</b> tasks: textual phrase entry, selection from a list, and numerical <b>data</b> <b>entry.</b> To effect fair comparisons, the tasks minimised the transaction cycle for each input mode and data type and the main comparisons use only times from correct <b>data</b> <b>entry.</b> The results indicate that for inputting short phrases ASR only competes if the typist's speed is below 45 wpm. For selecting an item from a list, ASR offered an advantage only if the list length was greater than 15 items. For entering numerical data, ASR offered no advantage over keypad or mouse. The general conclusion for formatted <b>data</b> <b>entry</b> is that a keyboard/mouse interface designed to match the data to be entered will be more time efficient than any equivalent ASR interface...|$|R
40|$|BACKGROUND: The health {{monitoring}} programme of the European Commission {{has proposed a}} set of health indicators whereby the health status of member states can be measured. As part of that programme we considered how primary care might contribute relevant data. METHODS: Using a questionnaire distributed to personal contacts and health authorities, we investigated the activities of sentinel practice networks and sought opinions on the place of primary care as a provider of information on health indicators. Studies on the prevalence of diabetes mellitus and on the incidence of chickenpox were undertaken within selected networks. RESULTS: 33 networks were found who provided relevant information on a timely and continuing basis. Contributions varied; some were limited to monitoring influenza but others recorded morbidity data from every consultation. Recording methods ranged from the paper based to fully automated systems in which all morbidity was <b>coded</b> electronically at <b>data</b> <b>entry.</b> The study of diabetes mellitus showed less variation between national networks than currently suggested on the WHO database. For chickenpox we estimated the incidence of cases not presenting to general practitioners ranged between 3 and 27 %. CONCLUSIONS: Information on health indicators needs {{to come from the}} place where relevant care is delivered; for many conditions that is from primary care. It can be delivered from appropriately resourced practices where the population is defined, the practice populations are nationally representative and data lection is automated. (aut. ref. ...|$|R
40|$|Introduction: Use of {{electronic}} health record (EHR) systems can place a considerable <b>data</b> <b>entry</b> burden upon {{the emergency department}} (ED) physician. Voice recognition <b>data</b> <b>entry</b> has been proposed as one mechanism to mitigate some of this burden; however, no reports are available specifically comparing emergency physician (EP) time use or number of interruptions between typed and voice recognition data entry-based EHRs. We designed this study to compare physician time use and interruptions between an EHR system using typed <b>data</b> <b>entry</b> versus an EHR with voice recognition. Methods: We collected prospective observational data at 2 academic teaching hospital EDs, one using an EHR with typed <b>data</b> <b>entry</b> {{and the other with}} voice recognition capabilities. Independent raters observed EP activities during regular shifts. Tasks each physician performed were noted and logged in 30 second intervals. We compared time allocated to charting, direct patient care, and change in tasks leading to interruptions between sites. Results: We logged 4, 140 minutes of observation for this study. We detected no statistically significant differences in the time spent by EPs charting (29. 4 % typed; 27. 5 % voice) or the time allocated to direct patient care (30. 7 %; 30. 8 %). Significantly more interruptions per hour were seen with typed <b>data</b> <b>entry</b> versus voice recognition <b>data</b> <b>entry</b> (5. 33 vs. 3. 47; p= 0. 0165). Conclusion: The use of a voice recognition <b>data</b> <b>entry</b> system versus typed <b>data</b> <b>entry</b> did not appear to alter the amount of time physicians spend charting or performing direct patient care in an ED setting. However, we did observe a lower number of workflow interruptions with the voice recognition <b>data</b> <b>entry</b> EHR. Additional research is needed to further evaluate the <b>data</b> <b>entry</b> burden in the ED and examine alternative mechanisms for chart entry as EHR systems continue to evolve. [West J Emerg Med. 2014; 15 (4) : 541 - 547. ]...|$|R
3000|$|<b>Data</b> <b>Entry</b> Methods: The input methods {{available}} for mobile devices {{are different from}} those for desktop computers and require a certain level of proficiency. This problem increases the likelihood of erroneous input and decreases the rate of <b>data</b> <b>entry.</b>|$|R
