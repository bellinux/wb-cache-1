32|56|Public
5000|$|In Cordwainer Smith's Instrumentality {{novels and}} stories, interplanetary and {{interstellar}} communication is normally relayed from planet to planet, presumably at superluminal speed for each stage (at least between solar systems) {{but with a}} <b>cumulative</b> <b>delay.</b> For urgent communication there is the [...] "instant message", which is effectively instantaneous but very expensive.|$|E
30|$|The <b>cumulative</b> <b>delay</b> metric of SORP and DORP {{introduces}} switching delay, {{which is}} later referred by many other works. Switching delay {{is defined as}} the delay caused by switching among frequency bands. Another consideration is backoff delay that is caused by multi-flow interference within a frequency band. <b>Cumulative</b> <b>delay</b> is the sum of switching delay and backoff delay. DORP adds queuing delay caused by the transmission of other flows on the node to the <b>cumulative</b> <b>delay</b> calculation. Since SORP and DORP focus on delays, they are suitable for delay-sensitive application. They result in fairly low <b>cumulative</b> <b>delay</b> and smooth <b>cumulative</b> <b>delay</b> change in handling intersecting flows. On the other hand, WHAT metric claims to be able to capture the overall quality of a path to have multiple considerations and to enhance the network throughput. However, WHAT metric requires a tuning parameter in determining the metric value and path selection. This static, predefined tuning parameter would reduce the cognitive learning capability.|$|E
40|$|Included in this {{viewgraph}} {{presentation on}} intelligent neuroprocessors for launch vehicle health management systems (HMS) are the following: where the flight failures {{have been in}} launch vehicles; <b>cumulative</b> <b>delay</b> time; breakdown of operations hours; failure of Mars Probe; vehicle health management (VHM) cost optimizing curve; target HMS-STS auxiliary power unit location; APU monitoring and diagnosis; and integration of neural networks and fuzzy logic...|$|E
3000|$|As the <b>cumulative</b> {{decoding}} <b>delay</b> is {{an increasing}} function, then for any transmitting device i and packet combination κ [...]...|$|R
5000|$|Asynchronous logic {{components}} {{can be hard}} {{to design}} because all possible states, in all possible timings must be considered. The usual method is to construct a table of the minimum and maximum time that each such state can exist, and then adjust the circuit to minimize the number of such states. Then the designer must force the circuit to periodically wait for all of its parts to enter a compatible state (this is called [...] "self-resynchronization"). Without such careful design, it is easy to accidentally produce asynchronous logic that is [...] "unstable," [...] that is, real electronics will have unpredictable results because of the <b>cumulative</b> <b>delays</b> caused by small variations in the values of the electronic components.|$|R
30|$|We {{recently}} presented evidence-based interrelated hypotheses {{that cancer}} is a severe and <b>cumulative</b> <b>delayed</b> type hypersensitivity reaction in site-specific tissues [1, 19]. Histamine, at low circulating level was suggested as blueprint for maintaining oxidative stress that contributes to tissue necrosis or growth in immune-privileged or immune-responsive tissues and induction of neurological or autoimmune diseases or tissue growth promotion. Histamine, an alkaline, contributes to dysfunction of mitochondrial and ribosomal activities (mitophagy and autophagy), tissue acid–base balance and bioenergetics (e.g., adenosine, ATP/ADP/AMP, Ca+ 2, H+/Na+/K+ transporters and exchangers), membrane structures (e.g., receptor or surface molecules, ionic and water channels). Among key components for future understanding of the effective immunity are the crucial roles that mitochondria and autophagy play in maintenance of Yin-Yang and energy-dependent events in protein/lipid recycling and biosynthesis of structural proteins (e.g., metabolism of branched amino acids) involved in architectural integrity of tissue anchoring and contact inhibition [1, 5, 19, 20].|$|R
30|$|A simple {{modification}} {{to adopt}} AODV into CRAHNs environment is by defining a new routing metric with ‘spectrum awareness’ property. Such protocols are SORP [13], DORP [14], and WHAT routing metric [15]. DORP {{is a continuation}} work of SORP, and both are early works that define the <b>cumulative</b> <b>delay</b> metric. WHAT routing metric considers path length, usage of licensed channel, and channel switching frequency.|$|E
30|$|In {{gradient}} search, a node builds its own gradient {{field in}} response to neighbor nodes {{in the direction of}} a specific sink. Data traffic flows along the direction with the steepest gradient in order to reach the sink. The cost model can be designed in terms of hop count from sink to node, physical distance, energy consumption, or <b>cumulative</b> <b>delay,</b> depending on the objectives of routing such as energy consumption, packet delay, or packet delivery ratio [22].|$|E
30|$|However, further examined, local {{coordination}} routing has a contrasting {{approach with}} MSCRP. In local coordination routing, {{in order to}} balance the load between nodes, it is encouraged to redirect flows to neighboring nodes, thus creating switching nodes occurring side by side. This violates the deafness problem constraint, that is, two consecutive nodes serving the same flow should not be switching nodes. It is difficult to decide which approach is better since MSCRP results in significant network throughput improvement and local coordination-based routing results in low <b>cumulative</b> <b>delay.</b>|$|E
40|$|We {{propose a}} linear {{complexity}} method to estimate robust path delay fault coverage in digital circuits. We adopt a path counting scheme for a true-value simulator that uses flags for each signal line. These flags determine the new path delay faults detected by the simulated vector pair. Experimental {{results are presented}} to show {{the effectiveness of the}} method in estimating path delay fault coverage. I. INTRODUCTION Two commonly used fault models are transition delay faults [5, 6, 10], which represent delay defects at inputs and outputs of gates, and path delay faults [9], which consider <b>cumulative</b> <b>delays</b> along combinational paths. The number of gate delay faults in a circuit is linearly proportional to the number of gates but the number of possible paths can be exponential making it impossible to enumerate all path delay faults in a large circuit. Still, many existing methods for computing fault coverage use some form of path enumeration. Storing of detected path delay faults [8] is [...] ...|$|R
40|$|Abstract — Proportional delay {{differentiation}} (PDD) {{model is}} an important approach for relative differentiated services provisioning on the Internet. It aims to maintain pre-specified packet queueing-delay ratios between different classes of traffic at each hop. Existing PDD packet scheduling algorithms are able to achieve the goal in long time-scales when the system is highly utilized. This paper presents a new PDD scheduling algorithm, called Little’s average delay (LAD), based on a proof of Little’s Law. It monitors the arrival rate and the <b>cumulative</b> <b>delays</b> of the packets from each traffic class, and schedules the packets according to their transient queueing properties so as to achieve the desired class delay ratios in both short and long time-scales. Simulation results show that, in comparison with other PDD scheduling algorithms, LAD can provide no worse level of service quality in long time-scales and more accurate and robust control over the delay ratio in short time-scales. In particular, LAD outperforms its main competitors significantly when the desired delay ratio is large. I...|$|R
40|$|Risk-sensitive {{foraging}} models {{predict that}} choice between fixed and variable food delays should {{be influenced by}} an organism's energy budget. To investigate whether the predictions of these models could be extended to choice in humans, risk sensitivity in 4 adults was investigated under laboratory conditions designed to model positive and negative energy budgets. Subjects chose between fixed and variable trial durations with the same mean value. An energy requirement was modeled by requiring that five trials be completed within a limited time period for points delivered {{at the end of}} the period (block of trials) to be exchanged later for money. Manipulating the duration of this time period generated positive and negative earnings budgets (or, alternatively, "time budgets"). Choices were consistent with the predictions of energy-budget models: The fixed-delay option was strongly preferred under positive earnings-budget conditions and the variable-delay option was strongly preferred under negative earnings-budget conditions. Within-block (or trial-by-trial) choices were also frequently consistent with the predictions of a dynamic optimization model, indicating that choice was simultaneously sensitive to the temporal requirements, delays associated with fixed and variable choices on the upcoming trial, <b>cumulative</b> <b>delays</b> within the block of trials, and trial position within a block...|$|R
40|$|We {{consider}} a general single-server multiclass queueing system that incurs a delay cost Ck (k) for each class k job that resides k units {{of time in}} the system. This paper derives a scheduling policy that minimizes the total <b>cumulative</b> <b>delay</b> cost when the system operates during a nite time horizon. Denote the marginal delay cost and (instantaneous) service rate functions of class k by ck = C 0 k and k, and let ak(t) be the "age" or time that the oldest class k job has been waiting at time t. Wecall the scheduling policy that at time t serves the oldest waiting job of that class k with the highest index k(t) ck(ak(t)), the Generalized c Rule. As a dynamic priority rule that depends on very little data, the Generalized c Rule is attractive to implement. We show that with non-decreasing convex delay costs, the Generalized c Rule is asymptotically optimal if the system operates in heavy tra c, and give explicit expressions for the associated performance characteristics: the delay (throughput time) process and the minimum <b>cumulative</b> <b>delay</b> cost. The optimality result is robust in that it holds for a countable number of classes and several homogeneous servers in a non-stationary, deterministic or stochastic environment where arrival and service processes can be general and interdependent. ...|$|E
40|$|Abstract—We {{consider}} an energy harvesting communication system, where both energy and data packets {{arrive at the}} transmitter {{during the course of}} communication. We determine the optimum packet scheduling scheme that minimizes the average delay experienced by all packets. We show that, different from the existing literature, the optimum transmission power is not constant between the energy harvesting and data arrival events; the transmission power starts high, decreases linearly, and potentially reaches zero between energy harvests and data arrivals. Intuitively, untransmitted bits experience <b>cumulative</b> <b>delay</b> due to the bits to be transmitted ahead of them, and hence the reason for transmission power starting high and decreasing over time between energy harvests and data arrivals. I...|$|E
40|$|The {{present study}} {{considers}} a when-to-schedule policy in online production scheduling, {{which can be}} applicable to the timing of rescheduling under a dynamic environment with unforeseeable events. This paper extends our previous work and proposes a new hybrid policy for rescheduling introducing rescheduling driven by a <b>cumulative</b> <b>delay</b> and a forced rescheduling to maintain {{the quality of a}} current schedule. We examine, through some computational experiments, some properties of the proposed policy by applying it to single-machine dynamic scheduling problems with disturbance where we minimize total tardiness as well as total frequency of rescheduling. It is also demonstrated that the proposed policy can outperform a typical periodic rescheduling policy with less frequency of rescheduling under parallel machine dynamic scheduling. Keywords: when-to-schedule policy, cumulative task delay, scheduling frequency, single machine dynamic scheduling, parallel machine dynamic scheduling...|$|E
30|$|In {{order to}} perform fast device selection, this paper proposes a {{heuristic}} algorithm {{based on an}} approximation of the optimal solution. Instead of computing the optimal packet combination of each device and deciding afterwards which of the devices provides the highest gain, this subsection proposes calculating an upper bound on the achievable maximum-delay reduction. The transmitting device {{is the one that}} possesses both most of the packets that allow to achieve the upper bound and the least <b>cumulative</b> decoding <b>delay.</b>|$|R
40|$|AbstractFor a graph G in {{read-only}} memory on n vertices and m edges and a write-only output buffer, we give two algorithms using only O(n) rewritable space. The first algorithm lists all minimal a−b separators of G with a polynomial delay of O(nm). The second lists all minimal vertex separators of G with a <b>cumulative</b> polynomial <b>delay</b> of O(n 3 m). One consequence {{is that the}} algorithms can list the minimal a−b separators (and minimal vertex separators) spending O(nm) time (respectively, O(n 3 m) time) per object output...|$|R
50|$|An {{example of}} the {{modified}} configuration is shown in Fig. 5, the measured phase difference in both a standard fibre optic gyroscope, shown on the left, and a modified fibre optic conveyor, shown on the right, conform to the equation Δt = 2vL/c2, whose derivation {{is based on the}} constant speed of light. It is evident from this formula that the total time delay is equal to the <b>cumulative</b> time <b>delays</b> along the entire length of fibre, regardless whether the fibre is in a rotating section of the conveyor, or a straight section.|$|R
40|$|Companion papers {{develop a}} model of {{real-time}} hierarchical computation of resource allocations by boundedly rational members of an administrative staff. The nodes of a hierarchy are multiperson decision-making units offices. The current paper uses a reduced form to address specific questions about organizational structure and returns to scale. We find {{that the possibility of}} decentralizing decision making within these hierarchical organizations allows for larger hierarchies. However, organization size is still bounded because the combined effect of <b>cumulative</b> <b>delay</b> and administrative costs means that in large enough hierarchies, the value of the root office’s information processing is less than the office’s administrative costs. We also find that as the environment changes more rapidly, optimal hierarchies become smaller and more internally decentralized. A speed-up of managerial processing, such as through improved information technology, has the opposite effect. JEL Classifications: D 83, D 2...|$|E
40|$|Companion papers {{develop a}} model of {{real-time}} hierarchical computation of resource allocations by boundedly rational members of an administrative staff. The nodes of a hierarchy are offices within which information processing may be decentralized. Decision making is decentralized across the nodes of the hierarchy. A version in which the cost functions are quadratic and the cost parameters follow first-order autoregressive processes yields a tractable reduced form. The current paper uses that reduced form to address specific questions about organizational structure and returns to scale. We find {{that the possibility of}} decentralizing decision making within these hierarchical organizations allows for larger hierarchies. However, organization size is still bounded because the combined effect of <b>cumulative</b> <b>delay</b> and administrative costs means that in large enough hierarchies, the value of the root office's information processing is less than the office's administrative costs. We also find t [...] ...|$|E
40|$|We {{discuss a}} new packet service paradigm, called ’Less Impact Better Service ’ (LIBS). In simple terms, LIBS {{primarily}} schedules packets {{based on the}} delay they cause and cancels service differentiation policies when the <b>cumulative</b> <b>delay</b> caused by prioritization becomes significant for non- prioritized packets. Based on LIBS, we evaluate different service policies that prioritize small packets using different service boundaries and we show that, by and large, LIBS satisfies more users with diverse demands in delay and throughput. We emphasize on Voice over IP applications, which are delay-sensitive but also utilize small packets and rates. Among other traditional performance measures, we also define and measure fairness {{in the context of}} LIBS, that is, we address the question whether the delay experienced per flow is proportional to the delay caused by that flow. We obtained very promising analytical and simulation results...|$|E
40|$|Lowering {{the energy}} {{required}} by base stations (BSs) {{is one of}} the hot issues nowadays in order to achieve green cellular networks. The energy consumption of femto BSs can be reduced, by turning off the radio interface when there is no mobile station (MS) under the coverage area of the femto BSs or MSs served by the femto BSs do not transmit or receive data packets for a long time, especially late at night. In the energy-efficient femto BSs, if MSs have any data packet to transmit and the radio interface of femto BSs is in the off state, MSs wake up the radio interface of femto BSs by using an additional low-power radio interface. In this paper, active (data), idle, active (signaling), sleep entering, sleep and waking up states are defined for the state model for the energy-efficient femto BSs, and the state transitions are modeled analytically. The steady-state probability of each state is derived thoroughly using a semi-Markov approach. Then, the performance of the energy-efficient femto BSs is analyzed in detail, from the aspects of energy consumption, <b>cumulative</b> average <b>delay,</b> cost and low-power radio signaling load. From the results, the tradeoff relationship between energy consumption and <b>cumulative</b> average <b>delay</b> is analyzed in detail, and it was concluded that an appropriate inactivity timer value should be selected to balance the tradeoff...|$|R
40|$|Standard dynamic-contrast {{enhanced}} ultrasound (DCE-US) imaging detects {{and estimates}} ultrasound-contrast-agent (UCA) concentration {{based on the}} amplitude of the nonlinear (harmonic) components generated during ultrasound (US) propagation through UCAs. However, harmonic components generation is not specific to UCAs, as it also occurs for US propagating through tissue. Moreover, nonlinear artifacts affect standard DCE-US imaging, causing contrast to tissue ratio reduction, and resulting in possible misclassification of tissue and misinterpretation of UCA concentration. Furthermore, no contrast-specific modality exists for DCE-US tomography; in particular speed-of-sound changes due to UCAs are well within those caused by different tissue types. Recently, a new marker for UCAs has been introduced. A <b>cumulative</b> phase <b>delay</b> (CPD) between the second harmonic and fundamental component is in fact observable for US propagating through UCAs, and is absent in tissue. In this paper, tomographic US images based on CPD are {{for the first time}} presented and compared to speed-of-sound US tomography. Results show the applicability of this marker for contrast specific US imaging, with <b>cumulative</b> phase <b>delay</b> imaging (CPDI) showing superior capabilities in detecting and localizing UCA, as compared to speed-of-sound US tomography. Cavities (filled with UCA) which were down to 1 [*]mm in diameter were clearly detectable. Moreover, CPDI is free of the above mentioned nonlinear artifacts. These results open important possibilities to DCE-US tomography, with potential applications to breast imaging for cancer localizatio...|$|R
30|$|In {{defining}} a reservoir optimization problem, an objective function, optimization variables and their constraints should be specified (Asadollahi 2012). Objective functions for waterflood optimization include net pressure value (NPV), <b>cumulative</b> production or <b>delay</b> in water breakthrough/reduction in water-cut while controlling {{variables such as}} injection rate, oil production rate and/or bottom hole pressure of injectors and producers.|$|R
40|$|Ensuring {{transportation}} systems are efficient {{is a priority}} for modern society. Technological advances {{have made it possible}} for {{transportation systems}} to collect large volumes of varied data on an unprecedented scale. We propose a traffic signal control system which takes advantage of this new, high quality data, with minimal abstraction compared to other proposed systems. We apply modern deep reinforcement learning methods to build a truly adaptive traffic signal control agent in the traffic microsimulator SUMO. We propose a new state space, the discrete traffic state encoding, which is information dense. The discrete traffic state encoding is used as input to a deep convolutional neural network, trained using Q-learning with experience replay. Our agent was compared against a one hidden layer neural network traffic signal control agent and reduces average <b>cumulative</b> <b>delay</b> by 82 %, average queue length by 66 % and average travel time by 20 %...|$|E
40|$|Temporal {{modulation}} transfer functions (tMTFs) {{in response}} to periodic click trains are presented for simultaneous recordings from primary auditory cortex, anterior auditory field, and secondary auditory cortex in 21 cats. The multiunit records could be separated in to 215 single-unit spike trains that allowed a reliable estimate of a group delay, which represents the <b>cumulative</b> <b>delay</b> for responses to repetitive stimuli. For approximately two-thirds of the 215 single units the group delay was within 7. 5 msec of the response latency to the first clicks in the trains. For the remaining units, the group delay was on average � 14 msec higher, and this may result from differences in synaptic properties. These findings were similar in the three cortical areas studied. The findings are modeled based on presynaptic facilitation and depression and pyramidal cell calcium kinetics, and a quantitative description {{of the magnitude of}} the tMT...|$|E
40|$|Several {{studies on}} the {{propagation}} velocity of pressure wave fields through ultrasound contrast agents (UCAs) {{have been reported in}} the literature. However, the variation of propagation velocity between the fundamental and the second harmonic component generated during the propagation of ultrasound through UCAs has, to our knowledge, not been studied yet. To this scope, dedicated transmission and backscattering measurements of pressure wave fields propagating through SonoVue and Definity contrast agents, are analyzed. Results show the occurrence of a <b>cumulative</b> <b>delay</b> between the time signals related to the second harmonic and fundamental component, suggesting a smaller propagation velocity for the second harmonic as compared to the fundamental component. Moreover, this time delay increases with increasing UCA concentration and propagation path length of ultrasound trough microbubbles, depends on mechanical index and frequency, and, most importantly, is not observed in the absence of UCAs. These results may be relevant to contrast-enhanced ultrasonography, opening up to new possibilities to increase contrast-to-tissue ratios and to quantify UCA concentration...|$|E
40|$|Over {{the years}} {{a number of}} {{techniques}} {{have been developed to}} determine the quantity and distribution of radiative isotopes contained in given assay samples through the measurement and analysis of penetrating characteristic radiations. An active technique of particular utility when assaying samples containing very small quantities of fissionable material or when high gamma ray backgrounds are encountered is the delayed neutron nondestructive assay (DN-NDA) technique. Typically, analysis of the delayed neutron signal involves relating the gross delayed neutron count observed following neutron irradiation of an assay sample to total fissionable material present via a linear calibration curve. In this way, the technique is capable of yielding the mass of a single dominant fissionable isotope or the total fissionable mass contained in a sample. Using this approach the only way to determine the mass of individual fissionable isotopes contained in a sample is to correlate total fissionable mass to individual isotopics via calculations or other means, yielding an indirect measure of isotopics. However, there is isotope specific information in the temporal delayed neutron signal due to differences in the delayed neutron precursor yields resulting from the fissioning of different isotopes. The authors present the results of an analysis to evaluate the feasibility of using Kalman filters and genetic algorithms to determine multiple specific fissionable isotopic masses contained in an assay sample from a <b>cumulative</b> <b>delayed</b> neutron signal measured following neutron irradiation of the sample...|$|R
40|$|A {{method of}} the {{determination}} of <b>cumulative</b> yields of <b>delayed</b> neutron precursors is developed. This method {{is based on the}} iterative least-square procedure applied to delayed neutron decay curves measured after irradiation of 235 U sample by thermal neutrons. Obtained cumulative yields in turns were used for deriving the values of the most probable charge in low-energy fission of the above-mentioned nucleus...|$|R
30|$|Finally, {{different}} perspectives can be introduced in rescheduling models. First, as stated above, several works propose passenger-oriented methodologies. In {{addition to the}} already cited contributions, other passenger-centric approaches {{can be found in}} [154, 155, 156, 157, 158, 159, 160]. Typical measures of service quality used for determining passenger satisfaction resulting from rescheduling strategies are: <b>cumulative</b> <b>delays,</b> waiting times, user generalised costs, removed connections, a penalty time of stranded passengers. Obviously, passengers are not the only players in the rescheduling process. Indeed, the other parties involved are infrastructure managers and train operating companies. On the one hand, train operating companies are interested in minimising both passenger discomfort and operational costs associated with the rescheduling strategies implemented. On the other hand, infrastructure managers aim to reduce train delays, even if this means cancelling runs or suppressing connection services. Works which, in addition to passenger needs, considered the operational costs of train companies are those proposed by [106, 161]. In this context, it is also worth citing [162] which computed different measures of costs resulting from the disruption management process, such as total operational cost for passenger services, total operational cost for empty movements and total number of schedule changes (i.e. services, composition and inventory train changes), as indicators of the effort made by rail companies to put recovery strategies in place. The trade-off between the targets pursued by the two above-mentioned stakeholders (i.e. infrastructure managers and train operating companies) is addressed in [87, 163, 164]. In addition, since the reduction in energy consumption {{is one of the main}} goals of railway companies, as already touched upon, rescheduling methods which adopt an energy-saving perspective have also been proposed, confirming the close relationship among the analysed domains. Energy consumption and saving will be discussed in Sect.  5.|$|R
40|$|Preemption {{techniques}} {{are designed to}} provide preferential treatment for buses at signalized intersections. A preemption strategy, if properly designed, can provide continuous green phases for buses at successive intersections, thereby reducing travel times and delays along the bus route. However, the length of delay incurred by all the vehicles in the sys-tem may {{be affected by the}} different bus headways under preemption operation. Unfortunately, no formal technique is available to assess the <b>cumulative</b> <b>delay</b> consequences of bus headways. The application of a simulation model, NETSIM, to test the effect of different headways is presented. NETSIM was selected because it can microscopically simu-late vehicular movements on a street network and because an animation feature within NETSIM is available that allows the user to track an indi-vidual vehicle from the source to the sink. A major bus route in Ann Arbor, Michigan, was used as the experiment site. The major conclusions are that NETSIM can generate delay data at various levels of aggrega...|$|E
40|$|In this paper, {{the role}} of the {{puncturing}} period on the operation of rate compatible punctured turbo (RCPT) code based distributed video coding systems is studied in the context of transmission over IEEE 802. 11 g Wireless Local Area Networks. Reasonably realistic network conditions are considered, with the impact of the Medium Access Control layer retransmissions taken into account. The effect of the puncturing period under such conditions is evaluated by means of rate/distortion results, incurred overhead and <b>cumulative</b> <b>delay.</b> The maximum number of requests permitted is derived for various packet error rates and is shown to be independent of the content. Increasing the puncturing period facilitates a refinement of the codec’s rate/distortion performance at the cost of increased parity bit requests, which in turn lead to an increase in delays. A packet error rate of 10 % with a puncturing period of 64 would only support 61 requests before delays build up...|$|E
40|$|A test-driven {{approach}} for rapidly deploying Voice over LTE (VoLTE) would prove essential, considering the revenues being lost to Internet protocol (IP) based solutions such as Voice over IP (VoIP). Subsequently voice development for LTE networks is indispensable considering that VoIP has no Quality of Service (QoS) guarantee, which consequently renders it unreliable. The thesis project aimed at analysing and describing {{the implementation of}} VoLTE from a programmatic perspective, focusing on end-to-end validation of a basic VoLTE configuration by using industrial test tools to validate functional and logical entities requisite in achieving a <b>cumulative</b> <b>delay</b> of less than 200 ms, widely held and shown to be the minimum acceptable latency for a practically deployable VoLTE system. The test scope primarily centred on signalling, transport methods and call handling functions. Validating deployment scenarios were executed using LTE capable network configuration test emulators that included an R&S CMW 500 development test platform manufactured by Rohde & Schwarz and the Spirent E 2010 S. The final analysis showed that scheduling methods, packet bundling and codecs can improve voice quality. Ultimately the basic VoLTE topology showed finer performance wit...|$|E
40|$|Abstract:In daily operation, {{railway traffic}} always {{deviates}} from the planned schedule {{to a certain}} extent. Initial disturbances of trains at some point along the line may cause a whole cascade of delays over the entire network. Average delay analysis approach indicated {{that the effect of}} delays along the way to the final destination is random, which is dependent on the traffic conditions. Poor performance up to 7 minutes delay, subsequently higher influence to the final destination were seen from trains 453 and 442 for routes from Trondheim and Steinkjer respectively. The better performance of trains from Trondheim at the final destination, confirmed that the influence of delays along the way to the final destination is affected by the train line or route. Route conflicts or disturbance often occur at busy stations and junctions, which may affect the delays of train arrivals and departures at the intermediate stations and subsequently arrivals at the final destination. The correlation analysis revealed that the influence is highly dependent on the distance of highly utilized (bottleneck station) from the destination. There was a considerable variability associated with train delays during the different time attributes more pronounced in the case heterogeneity. Exaggerated <b>cumulative</b> <b>delays</b> were observed on Tuesday during the third week of the study period. Conflicts, passenger alighting and boarding during morning and afternoon peak hours resulted in relatively larger delays at individual stations and subsequently final destination. Delays at long the way, which are not reported as poor performance according to Norwegian punctuality norm, have greater socio-economic impact. At highly utilized stations typically Stj&# 248;rdal and Hell the values of delays were found to be up to twice the values at the final destination. </p...|$|R
40|$|We {{report on}} the first study demonstrating {{the ability of a}} recently-developed, contrast-enhanced, {{ultrasound}} imaging method, referred to as <b>cumulative</b> phase <b>delay</b> imaging (CPDI), to image and quantify ultrasound contrast agent (UCA) kinetics. Unlike standard ultrasound tomography, which exploits changes in speed of sound and attenuation, CPDI is based on a marker specific to UCAs, thus enabling dynamic contrast-specific ultrasound tomography (DCS-UST). For breast imaging, DCS-UST will lead to a more practical, faster, and less operator-dependent imaging procedure compared to standard echo-contrast, while preserving accurate imaging of contrast kinetics. Moreover, a linear relation between CPD values and ultrasound second-harmonic intensity was measured (coefficient of determination = 0. 87). DCS-UST can find clinical applications as a diagnostic method for breast cancer localization, adding important features to multi-parametric ultrasound tomography of the breas...|$|R
40|$|BACKGROUND: The British Thoracic Society (BTS) {{recognises}} {{that it is}} {{of paramount}} importance to ensure that all patients with a working diagnosis of lung cancer have access to first class care [The Lung Cancer Working Party of the British Thoracic Society Standards of Care Committee. BTS recommendations to respiratory physicians for organising the care of patients with lung cancer. Thorax 1998; 53 (Suppl 1) : S 1 - 81. METHODS: A retrospective audit of the time involved in the management of patients with lung cancer referred for consideration of surgery at the Royal Brompton Hospital was carried out. Our performance was compared with the BTS recommendations. RESULTS: The notes from 194 patients were analysed, accounting for 93. 7 % of patients referred with lung cancer in a 1 -year period. A total of 90 patients fulfilled the criteria for analysis as they had potentially resectable disease at referral; 59 (65. 5 %) underwent thoracotomy, and 31 (34. 5 %) were considered inoperable. The median interval between the onset of symptoms and their first chest radiograph was 39 days, and between the onset of symptoms and referral to a surgeon by a chest physician was 112 days. The median interval between referral by a respiratory physician and surgical out-patient attendance was 14 days, and between referral by a respiratory physician and the surgical procedure was 32. 5 days. The median length of time from surgical out-patient attendance to the surgical procedure was 17 days. There was no association between the interval between the onset of symptoms and the surgical procedure with advanced tumour stage at surgery. CONCLUSIONS: There are a number of sources of delay in the referral process for a patient with potentially resectable lung cancer. Most patients referred to our unit were treated within the time scale recommended by the BTS. Our survey has shown that there are <b>cumulative</b> <b>delays</b> in the overall investigation and management of lung cancer patients, which are not covered by the BTS guidelines, and which result in unacceptable delays for most patients...|$|R
