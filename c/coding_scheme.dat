6095|4848|Public
5|$|Given the non-random genetic triplet <b>coding</b> <b>scheme,</b> a tenable {{hypothesis}} for {{the origin}} of genetic code could address multiple aspects of the codon table, such as absence of codons for D-amino acids, secondary codon patterns for some amino acids, confinement of synonymous positions to third position, the small set of only 20 amino acids (instead of a number approaching 64), and the relation of stop codon patterns to amino acid coding patterns.|$|E
5|$|In 2003, {{researchers}} from six different orangutan field sites {{who used the}} same behavioural <b>coding</b> <b>scheme</b> compared the behaviours of the animals from the different sites. They found the different orangutan populations behaved differently. The evidence suggested the differences were cultural: first, {{the extent of the}} differences increased with distance, suggesting cultural diffusion was occurring, and second, the size of the orangutans' cultural repertoire increased according to the amount of social contact present within the group. Social contact facilitates cultural transmission.|$|E
5|$|There was no {{assembly}} language defined for the Mark 1. Programs {{had to be}} written and submitted in binary form, encoded as eight 5-bit characters for each 40-bit word; programmers were encouraged to memorize the modified ITA2 <b>coding</b> <b>scheme</b> to make their job easier. Data was read and written from the papertape punch under program control. The Mark 1 had no system of hardware interrupts; the program continued after a read or write operation had been initiated until another input/output instruction was encountered, {{at which point the}} machine waited for the first to complete.|$|E
30|$|In this section, we {{analyze the}} {{performance}} {{characteristics of the}} proposed spreading <b>code</b> <b>scheme.</b> The spreading <b>code</b> <b>scheme</b> uses system model to analyze the symbol error probability of the spreading <b>code</b> <b>scheme.</b>|$|R
40|$|A data-distribution and bus-structure aware {{methodology}} {{for the design}} of <b>coding</b> <b>schemes</b> for low-power on-chip and interchip communication is presented. A general class of <b>coding</b> <b>schemes</b> for low power, termed transition pattern <b>coding</b> <b>schemes,</b> is introduced. The energy behavior of the schemes is mathematically analyzed in detail. Two algorithms are proposed for deriving such efficient <b>coding</b> <b>schemes,</b> which are optimized for desired bus structures and data distributions. Bus partitioning is proposed and mathematically analyzed as a way to reduce the complexity of the encoder/decoder...|$|R
40|$|Classifications and <b>coding</b> <b>schemes</b> are {{the link}} between the {{vocabulary}} of the computer and that of the human user. The design of appropriate <b>coding</b> <b>schemes,</b> therefore, is of crucial importance for the smooth interaction between man and machine. Various <b>coding</b> <b>schemes</b> and design considerations are discussed, in particular the new eye section in the Ninth Revision of the International Classification of Diseases (ICD) ...|$|R
5|$|Granule cells receive all {{of their}} input from mossy fibers, but outnumber them by 200 to 1 (in humans). Thus, the {{information}} in the granule cell population activity state is the same as {{the information in the}} mossy fibers, but recoded in a much more expansive way. Because granule cells are so small and so densely packed, it is difficult to record their spike activity in behaving animals, so there is little data to use as a basis for theorizing. The most popular concept of their function was proposed in 1969 by David Marr, who suggested that they could encode combinations of mossy fiber inputs. The idea is that with each granule cell receiving input from only 4–5 mossy fibers, a granule cell would not respond if only a single one of its inputs were active, but would respond if more than one were active. This combinatorial <b>coding</b> <b>scheme</b> would potentially allow the cerebellum to make much finer distinctions between input patterns than the mossy fibers alone would permit.|$|E
25|$|Entropy {{encoding}} – a <b>coding</b> <b>scheme</b> that assigns {{codes to}} symbols {{so as to}} match code lengths with the probabilities of the symbols.|$|E
25|$|Sociologist Talcott Parsons, at Harvard University from 1927 forward, {{developed}} a cybernetic theory of action which was adapted to small group research by Parsons' student and colleague, Robert Freed Bales, {{resulting in a}} body of observational studies of social interaction in groups using Bales' behavior <b>coding</b> <b>scheme,</b> Interaction Process Analysis. During his 41-year tenure at Harvard, Bales mentored a distinguished group of sociological social psychologists concerned with group processes and other topics in sociological social psychology.|$|E
40|$|In this paper, we {{introduce}} novel <b>coding</b> <b>schemes</b> for wireless networks with random transmission delays. These <b>coding</b> <b>schemes</b> obviate {{the need}} for synchronicity, {{reduce the number of}} transmissions and achieve the optimal rate region in the corresponding wired model for both multiple unicast and multicast cases with up to three users under the equal rate constraint. The <b>coding</b> <b>schemes</b> are presented in two phases; first, <b>coding</b> <b>schemes</b> for line, star and line-star topologies with random transmission delays are provided. Second, any general topology with multiple bidirectional unicast and multicast sessions is shown to be decomposable into these canonical topologies {{to reduce the number of}} transmissions without rate redundancy. As a result, the <b>coding</b> <b>schemes</b> developed for the line, star and line-star topologies serve as building blocks for the construction of more general <b>coding</b> <b>schemes</b> for all networks. The proposed schemes are proved to be Real Time (RT) for wireless networks in the sense that they achieve the minimal decoding delay. With a negligible size header, these <b>coding</b> <b>schemes</b> are shown to be applicable to unsynchronized networks, i. e., networks with random transmission delays. Finally, we demonstrate the applicability of these schemes by extensive simulations. The implementation of such <b>coding</b> <b>schemes</b> on a wireless network with random transmission delay can improve performance and power efficiency. Comment: 15 pages, 19 figures, submitted to the IEEE/ACM Transactions on Networkin...|$|R
40|$|Abstract: In {{this paper}} we explore tool support for {{categorical}} coding of verbal and chat data. We consider tool support for manual coding, automatic coding by learning algorithms, and derive at a socio-technical approach in which human coders and learning algorithms together address the coding task. Given that a literature study suggests researchers devise, adapt and refine {{a wide variety of}} <b>coding</b> <b>schemes,</b> a categorization support system should handle and accommodate user defined <b>coding</b> <b>schemes.</b> Based on these ideas a prototype of the ChatIC tool was developed and evaluated with three <b>coding</b> <b>schemes.</b> For two <b>coding</b> <b>schemes</b> a sufficient inter-rater agreement between a human coder and the learning algorithms was reached...|$|R
40|$|In this paper, line <b>coding</b> <b>schemes</b> {{and their}} {{application}} to the multiuser adder channel are investigated. The focus is on designing line codes with higher information per channel use rates than time- sharing. We show that by combining short multi-user line codes, {{it is possible to}} devise longer <b>coding</b> <b>schemes</b> with rate sums which increase quite rapidly at each iteration of the construction. Asymptotically, there is no penalty in requiring the <b>coding</b> <b>schemes</b> to be DC-free...|$|R
25|$|A deep {{predictive}} coding network (DPCN) is a predictive <b>coding</b> <b>scheme</b> that uses top-down information to empirically adjust the priors {{needed for a}} bottom-up inference procedure {{by means of a}} deep, locally connected, generative model. This works by extracting sparse features from time-varying observations using a linear dynamical model. Then, a pooling strategy is used to learn invariant feature representations. These units compose to form a deep architecture and are trained by greedy layer-wise unsupervised learning. The layers constitute a kind of Markov chain such that the states at any layer depend only on the preceding and succeeding layers.|$|E
25|$|This energy {{function}} only introduces probability biases {{for a spin}} having a value and {{for a pair of}} spins having the same value. Higher order correlations are unconstrained by the multipliers. An activity pattern sampled from this distribution requires the largest number of bits to store in a computer, in the most efficient <b>coding</b> <b>scheme</b> imaginable, as compared with any other distribution with the same average activity and pairwise correlations. This means that Ising models are relevant to any system which is described by bits which are as random as possible, with constraints on the pairwise correlations and the average number of 1s, which frequently occurs in both the physical and social sciences.|$|E
25|$|If a {{compression}} {{scheme is}} lossless—that is, {{you can always}} recover the entire original message by decompressing—then a compressed message has the same quantity of information as the original, but communicated in fewer characters. That is, it has more information, or a higher entropy, per character. This means a compressed message has less redundancy. Roughly speaking, Shannon's source coding theorem says that a lossless compression scheme cannot compress messages, on average, {{to have more than}} one bit of information per bit of message, but that any value less than one bit of information per bit of message can be attained by employing a suitable <b>coding</b> <b>scheme.</b> The entropy of a message per bit multiplied by the length of that message is a measure of how much total information the message contains.|$|E
30|$|We {{suggested}} a MDP framework {{to analyze the}} <b>coded</b> and uncoded <b>schemes,</b> and showed {{how it can be}} exploited to find good coding strategies. Moreover, we suggested two <b>coding</b> <b>schemes,</b> which although work over a system with an exponentially large state space, do not keep track of the rewards per state (in order to solve optimality equations), yet perform significantly better than uncoded <b>schemes.</b> These <b>coding</b> <b>schemes</b> are based on finding large cliques in graphs, which can be solved efficiently in the graphs relevant to these <b>coding</b> <b>schemes.</b>|$|R
40|$|The {{design of}} uniquely decodable {{multi-user}} <b>coding</b> <b>schemes</b> with good rate sums for the DC-free multiple access adder channel is described. By using the direct sum construction on short multi-user codes, {{it is possible}} to devise longer DC-free <b>coding</b> <b>schemes</b> with rate sums which increase quite rapidly at each iteration of the construction. Asymptotically, there is no penalty in requiring the <b>coding</b> <b>schemes</b> to be DC-free. In addition, the schemes can be efficiently soft decision decoded using a relatively low complexity sectionalised trellis...|$|R
40|$|This paper extends linear-complexity {{concatenated}} <b>coding</b> <b>schemes</b> to fountain communication {{over the}} discrete-time memoryless channel. Achievable fountain error exponents for one-level and multi-level concatenated fountain codes are derived. It is {{also shown that}} concatenated <b>coding</b> <b>schemes</b> possess interesting properties in several multi-user fountain communication scenarios...|$|R
2500|$|The cross entropy {{between two}} {{probability}} distributions measures {{the average number}} of bits needed to identify an event from a set of possibilities, if a <b>coding</b> <b>scheme</b> is used based on a given probability distribution , rather than the [...] "true" [...] distribution [...]|$|E
2500|$|In {{information}} theory, the Kraft–McMillan theorem establishes {{that any}} directly decodable <b>coding</b> <b>scheme</b> for coding {{a message to}} identify one value xi out {{of a set of}} possibilities X can be seen as representing an implicit probability distribution q(xi)=2−li over X, where li is the length of the code for xi in bits. [...] Therefore, the Kullback–Leibler divergence can be interpreted as the expected extra message-length per datum that must be communicated if a code that is optimal for a given (wrong) distribution Q is used, compared to using a code based on the true distribution P.|$|E
2500|$|In modems and {{wireless}} systems, link adaptation (automatic adaption {{of the data}} rate and the modulation and/or error <b>coding</b> <b>scheme</b> to the signal quality) is often applied. In that context, the term peak bitrate denotes the net bitrate of the fastest and least robust transmission mode, used for example when the distance is very short between sender and transmitter. Some operating systems and network equipment may detect the [...] "connection speed" [...] (informal language) of a network access technology or communication device, implying the current net bit rate. Note that the term line rate in some textbooks is defined as gross bit rate, in others as net bit rate.|$|E
50|$|Presented sub-optimal {{universal}} <b>coding</b> <b>schemes</b> {{for video}} <b>coding.</b>|$|R
40|$|International audienceNetwork coding {{is a new}} {{technique}} to improve network capacity and reliability. COPE and DCAR are basic network <b>coding</b> <b>schemes</b> which have been proposed for opportunistic network coding in wireless networks. The performances of these coding mechanisms have been studied by simulations or experiments. There is an interest in modeling the performances of these <b>coding</b> <b>schemes</b> mathematically. In fact, analytical approach can provide quicker performance analysis and comparison between these network <b>coding</b> <b>schemes.</b> In this paper, we propose an analytical model for the DCAR coding gain. The analytical results are validated by simulations in NS- 2...|$|R
40|$|This paper {{reports on}} work {{carried out in}} the ISLE project on natural {{interactivity}} and multimodal resources. Information has been collected on a large number of corpora, <b>coding</b> <b>schemes</b> and <b>coding</b> tools world-wide. The paper focuses on corpora and <b>coding</b> <b>schemes</b> and the purposes for which they were developed or which they could serve...|$|R
2500|$|The old {{version of}} DAB uses {{punctured}} convolutional coding for its ECC. The <b>coding</b> <b>scheme</b> uses {{unequal error protection}} (UEP), which means that parts of the audio bit-stream that {{are more susceptible to}} errors causing audible disturbances are provided with more protection (i.e. a lower code rate) and vice versa. However, the UEP scheme used on DAB results in there being a grey area in between the user experiencing good reception quality and no reception at all, as opposed to the situation with most other wireless digital communication systems that have a sharp [...] "digital cliff", where the signal rapidly becomes unusable if the signal strength drops below a certain threshold. When DAB listeners receive a signal in this intermediate strength area they experience a [...] "burbling" [...] sound which interrupts the playback of the audio.|$|E
2500|$|Information {{reconciliation}} {{is a form}} {{of error}} correction carried out between Alice and Bob's keys, in order to ensure both keys are identical. It is conducted over the public channel and as such it is vital to minimise the information sent about each key, as this can be read by Eve. A common protocol used for information reconciliation is the cascade protocol, proposed in 1994. This operates in several rounds, with both keys divided into blocks in each round and the parity of those blocks compared. If a difference in parity is found then a binary search is performed to find and correct the error. If an error is found in a block from a previous round that had correct parity then another error must be contained in that block; this error is found and corrected as before. This process is repeated recursively, which {{is the source of the}} cascade name. After all blocks have been compared, Alice and Bob both reorder their keys in the same random way, and a new round begins. At the end of multiple rounds Alice and Bob have identical keys with high probability; however, Eve has additional information about the key from the parity information exchanged. However, from a coding theory point of view information reconciliation is essentially source coding with side information, in consequence any <b>coding</b> <b>scheme</b> that works for [...] this problem can be used for information reconciliation. Lately turbocodes, LDPC codes [...] and polar codes [...] have been used for this purpose improving the efficiency of the cascade protocol.|$|E
50|$|For TP-PID = 63 the SC {{converts}} the SM {{from the}} received TP Data <b>Coding</b> <b>Scheme</b> to any data <b>coding</b> <b>scheme</b> supported by that MS (e.g. the default).|$|E
30|$|Further {{work will}} deal with {{evaluating}} the performance considering a more complete set of videos and different combinations of <b>coding</b> <b>schemes.</b> In addition, more robust <b>coding</b> <b>schemes</b> will be considered to transmit I-frames. Finally, {{it is reasonable to}} think that the performance could be improved by choosing the LDPC matrix depending on the specific vehicular channel.|$|R
40|$|Abstract — This paper extends linear-complexity {{concatenated}} <b>coding</b> <b>schemes</b> to fountain communication {{over the}} discretetime memoryless channel. Achievable fountain error exponents for one-level and multi-level concatenated fountain codes are derived. Several important {{properties of the}} concatenated <b>coding</b> <b>schemes</b> in multi-user fountain communication scenarios are demonstrated. Index Terms — coding complexity, concatenated codes, error exponent, fountain communication I...|$|R
40|$|A {{theoretical}} framework is proposed for accurate performance analysis of minimum energy <b>coding</b> <b>schemes</b> in <b>Coded</b> Division Multiple Access (CDMA) wireless sensor networks. Bit error rate and average energy consumption is analyzed for two <b>coding</b> <b>schemes</b> {{proposed in the}} literature: Minimum Energy coding (ME), and Modified Minimum Energy coding (MME). Since CDMA wireless systems are strongly limited by multi access interference, the system model includes all the relevant characteristics of the wireless propagation. Furthermore, a detailed model of the energy consumption is described as function of the <b>coding</b> <b>schemes,</b> the radio transmit powers, {{the characteristics of the}} transceivers, and the dynamics of the wireless channel. A distributed radio power minimization algorithm is also addressed. Numerical results show that ME and MME <b>coding</b> <b>schemes</b> exhibit similar bit error probabilities, whereas MME outperforms ME only in the case of low data rate and large coding codewords. QC 2011011...|$|R
50|$|The least robust, but fastest, <b>coding</b> <b>scheme</b> (CS-4) is {{available}} near a {{base transceiver station}} (BTS), while the most robust <b>coding</b> <b>scheme</b> (CS-1) is used when the mobile station (MS) is further away from a BTS.|$|E
5000|$|AS1344-1972, 1975, 1997 Size <b>coding</b> <b>scheme</b> for women’s {{clothing}} ...|$|E
5000|$|ISCII - the <b>coding</b> <b>scheme</b> {{specifically}} designed to represent Indic scripts ...|$|E
40|$|In {{this paper}} we propose several dirty paper <b>coding</b> <b>schemes</b> for the {{broadcast}} channel when both the transmitter and receivers are equipped with multiple antennas. These <b>coding</b> <b>schemes</b> are based on channel state information at the transmitter and inspired from information-theoretic concepts. The proposed end-to-end algorithms allows us to evaluate {{the performance of the}} broadcast channel in terms of bit error rates and not in terms of coding rates as it is usually the case in the corresponding literature. Different inner <b>coding</b> <b>schemes</b> such as the ZF-DPC and MMSE-DPC and different outer <b>coding</b> <b>schemes</b> such as the THS, SCS and TCQ are compared and discussed. We also consider the DPC idea as a way of implementing a multiple access scheme. In this respect it is compared with the well-know TDMA scheme. Sometimes our conclusions show quite surprising results in comparison to what is expected by pure information-theoretic considerations...|$|R
40|$|We {{study and}} compare three <b>coded</b> <b>schemes</b> for single-server {{wireless}} broadcast of multiple description coded content to heterogeneous users. The users (sink nodes) demand different number of descriptions over links with different packet loss rates. The three <b>coded</b> <b>schemes</b> {{are based on}} the LT codes, growth codes, and randomized chunked <b>codes.</b> The <b>schemes</b> are compared {{on the basis of the}} total number of transmissions required to deliver the demands of all users, which we refer to as the server (source) delivery time. We design the degree distributions of LT codes by solving suitably defined linear optimization problems, and numerically characterize the achievable delivery time for different <b>coding</b> <b>schemes.</b> We find that including a systematic phase (uncoded transmission) is significantly beneficial for scenarios with low demands, and that coding is necessary for efficiently delivering high demands. Different demand and error rate scenarios may require very different <b>coding</b> <b>schemes.</b> Growth <b>codes</b> and chunked codes do not perform as well as optimized LT codes in the heterogeneous communication scenario. Comment: accepted by Elsevier PhyCom NetCod Special Issu...|$|R
50|$|In EGPRS/EDGE, the Modulation and <b>Coding</b> <b>Schemes</b> MCS-1 to MCS-9 {{take the}} place of the <b>Coding</b> <b>Schemes</b> of GPRS, and {{additionally}} specify which modulation scheme is used, GMSK or 8PSK. MCS-1 through MCS-4 use GMSK and have performance similar (but not equal) to GPRS, while MCS-5 through MCS-9 use 8PSK. In all EGPRS Modulation and <b>Coding</b> <b>Schemes,</b> a convolutional <b>code</b> of rate 1/3 is used, and puncturing is used to achieve the desired code rate. In contrast to GPRS, the Radio Link Control (RLC) and Media Access Control (MAC) headers and the payload data are coded separately in EGPRS. The headers are coded more robustly than the data.|$|R
