10000|1|Public
5|$|In {{magnetized}} plasmas, a gyrokinetic {{approach can}} substantially reduce the <b>computational</b> {{expense of a}} fully kinetic simulation.|$|E
5|$|Intelligent Systems for Molecular Biology (ISMB) is {{an annual}} {{academic}} {{conference on the}} subjects of bioinformatics and <b>computational</b> biology organised by the International Society for <b>Computational</b> Biology (ISCB). The principal focus of the conference is on the development and application of advanced <b>computational</b> methods for biological problems. The conference has been held every year since 1993 and has grown {{to become one of}} the largest and most prestigious meetings in these fields, hosting over 2,000 delegates in 2004. From the first meeting, ISMB has been held in locations worldwide; since 2007, meetings have been located in Europe and North America in alternating years. Since 2004, European meetings have been held jointly with the European Conference on <b>Computational</b> Biology (ECCB).|$|E
5|$|Lawrence Hunter is {{the founder}} of the International Society for <b>Computational</b> Biology, the world's oldest and largest {{professional}} organization for bioinformatics and <b>computational</b> biology.|$|E
5|$|Much of Lewis' {{subsequent}} research {{concerned the}} <b>computational</b> complexity {{of problems in}} mathematical logic.|$|E
5|$|A {{vast array}} of <b>computational</b> methods have been {{developed}} to analyze the structure, function, and evolution of proteins.|$|E
5|$|Along {{with its}} use in graph theory, the duality of planar graphs has {{applications}} in several other areas of mathematical and <b>computational</b> study.|$|E
5|$|Leo Franca {{from the}} Department of Mathematical and Statistical Sciences has {{developed}} stabilized finite elements, important in <b>computational</b> mechanics and engineering simulation.|$|E
5|$|The <b>computational</b> {{expense of}} {{dividing}} h-bit numbers scales as O(h(ℓ+1)), where ℓ is {{the length of}} the quotient.|$|E
25|$|The Simons Foundation {{established}} the Flatiron Institute in 2016, to house 4 groups of <b>computational</b> scientists (each with 60 or more PhD level researchers). The institute {{consists of three}} cores or departments: CCB (the center for <b>computational</b> biology), CCA (Center for <b>Computational</b> Astrophysics), CCQ (Center for <b>Computational</b> Quantum mechanics). A fourth, yet to be assembled core, will focus on another branch of applied <b>computational</b> science. The new institute is located in Manhattan and represents a major investment in basic <b>computational</b> science.|$|E
25|$|<b>Computational</b> and Systems Neuroscience (COSYNE) – a <b>computational</b> {{neuroscience}} {{meeting with}} a systems neuroscience focus.|$|E
25|$|<b>Computational</b> {{neuroscience}} data (<b>computational</b> {{models of}} various neuronal systems, from membrane currents, proteins to learning and memory).|$|E
25|$|In academia, <b>computational</b> {{immunology}} is a {{field of}} science that encompasses high-throughput genomic and bioinformatics approaches to immunology. The field's main aim is to convert immunological data into <b>computational</b> problems, solve these problems using mathematical and <b>computational</b> approaches and then convert these results into immunologically meaningful interpretations.|$|E
25|$|The {{success of}} modern {{numerical}} mathematical methods and software {{has led to}} the emergence of <b>computational</b> mathematics, <b>computational</b> science, and <b>computational</b> engineering, which use high-performance computing for the simulation of phenomena and the solution of problems in the sciences and engineering. These are often considered interdisciplinary.|$|E
25|$|Stuart Shapiro divides AI {{research}} into three approaches, {{which he calls}} <b>computational</b> psychology, <b>computational</b> philosophy, and computer science. <b>Computational</b> psychology is used to make computer programs that mimic human behavior. <b>Computational</b> philosophy, is used to develop an adaptive, free-flowing computer mind. Implementing computer science serves the goal of creating computers that can perform tasks that only people could previously accomplish. Together, the humanesque behavior, mind, and actions make up artificial intelligence.|$|E
25|$|SemEval-2014 {{took place}} in 2014. It was {{co-located}} with COLING 2014, 25th International Conference on <b>Computational</b> Linguistics and *SEM 2014, Second Joint Conference on Lexical and <b>Computational</b> Semantics, Dublin, Ireland. There were 10 different tasks in SemEval-2014 evaluating various <b>computational</b> semantic systems.|$|E
25|$|Another {{common theme}} is taking {{facts about the}} <b>computational</b> {{universe}} {{as a whole and}} using them to reason about fields in a holistic way. For instance, Wolfram discusses how facts about the <b>computational</b> universe inform evolutionary theory, SETI, free will, <b>computational</b> complexity theory, and philosophical fields like ontology, epistemology, and even postmodernism.|$|E
25|$|In 1997, Hunter founded {{what has}} become the largest {{professional}} organization in <b>computational</b> biology and bioinformatics, the International Society for <b>Computational</b> Biology (ISCB).|$|E
25|$|SemEval-2015 {{took place}} in 2015. It was {{co-located}} with NAACL-HLT 2015, 2015 Conference of the North American Chapter of the Association for <b>Computational</b> Linguistics – Human Language Technologies and *SEM 2015, Third Joint Conference on Lexical and <b>Computational</b> Semantics, Denver, USA. There were 17 different tasks in SemEval-2015 evaluating various <b>computational</b> semantic systems.|$|E
25|$|As {{the types}} of {{different}} <b>computational</b> semantic systems grew beyond the coverage of WSD, Senseval evolved into SemEval, where more aspects of <b>computational</b> semantic systems were evaluated.|$|E
25|$|Research in <b>computational</b> {{neuroscience}} can {{be roughly}} categorized into several lines of inquiry. Most <b>computational</b> neuroscientists collaborate closely with experimentalists in analyzing novel data and synthesizing new models of biological phenomena.|$|E
25|$|SemEval-2013 was {{associated}} with NAACL 2013, North American Association of <b>Computational</b> Linguistics, Georgia, USA and took place in 2013. It included 13 different tasks targeting at evaluating <b>computational</b> semantic systems.|$|E
25|$|Turbulence {{models can}} be {{classified}} based on <b>computational</b> expense, which corresponds to the range of scales that are modeled versus resolved (the more turbulent scales that are resolved, the finer {{the resolution of the}} simulation, and therefore the higher the <b>computational</b> cost). If a majority or all of the turbulent scales are not modeled, the <b>computational</b> cost is very low, but the tradeoff {{comes in the form of}} decreased accuracy.|$|E
25|$|Warshel {{is known}} for his work on <b>computational</b> {{biochemistry}} and biophysics, in particular for pioneering computer simulations of the functions of biological systems, and for developing what is known today as <b>Computational</b> Enzymology.|$|E
25|$|The {{iterative}} {{methods used}} to solve problems of nonlinear programming differ according to whether they evaluate Hessians, gradients, or only function values. While evaluating Hessians (H) and gradients (G) improves the rate of convergence, for functions for which these quantities exist and vary sufficiently smoothly, such evaluations increase the <b>computational</b> complexity (or <b>computational</b> cost) of each iteration. In some cases, the <b>computational</b> complexity may be excessively high.|$|E
25|$|<b>Computational</b> {{complexity}} theory is {{a branch of}} the theory of computation in theoretical computer science that focuses on classifying <b>computational</b> problems according to their inherent difficulty, and relating those classes to each other. A <b>computational</b> problem is understood to be a task that is in principle amenable to being solved by a computer, which is equivalent to stating that the problem may be solved by mechanical application of mathematical steps, such as an algorithm.|$|E
25|$|There {{are also}} some <b>computational</b> models which focus on protein–protein {{interactions}} and networks. There are also tools which are used for T and B cell epitope mapping, proteasomal cleavage site prediction, and TAP– peptide prediction. The experimental data is very much important to design and justify the models to predict various molecular targets. <b>Computational</b> immunology tools is the game between experimental data and mathematically designed <b>computational</b> tools.|$|E
25|$|Founded in 1997, the International Society for <b>Computational</b> Biology (ISCB) is a {{scholarly}} society for researchers in <b>computational</b> biology and bioinformatics working towards advancing understanding of living systems through computation and for communicating scientific advances worldwide.|$|E
25|$|The {{development}} of <b>computational</b> sociology involves such scholars as Nigel Gilbert, Klaus G. Troitzsch, Joshua M. Epstein, and others. The foci of methods {{in this field}} include social simulation and data-mining, {{both of which are}} sub-areas of <b>computational</b> sociology. Social simulation uses computers to create an artificial laboratory for the study of complex social systems; data-mining uses machine intelligence to search for non-trivial patterns of relations in large, complex, real-world databases. The emerging methods of socionics are a variant of <b>computational</b> sociology.|$|E
25|$|<b>Computational</b> {{sociology}} {{is influenced}} {{by a number of}} micro-sociological areas as well as the macro-level traditions of systems science and systems thinking. The micro-level influences of symbolic interaction, exchange, and rational choice, along with the micro-level focus of <b>computational</b> political scientists, such as Robert Axelrod, helped to develop <b>computational</b> sociology's , agent-based approach to modeling complex systems. This is what Joshua M. Epstein calls generative science. Other important areas of influence include statistics, mathematical modeling and computer simulation.|$|E
25|$|Dr. Oden is the {{founding}} Director of the Institute for <b>Computational</b> Engineering and Sciences (ICES), which {{was started in}} January 2003 as {{an expansion of the}} Texas Institute for <b>Computational</b> and Applied Mathematics, also directed by Oden for over a decade.|$|E
25|$|In general, stylized <b>computational</b> phantom is a {{mathematical}} {{representation of the}} human body which, when coupled with a Monte Carlo radiation transport computer code, can be used to track the radiation interactions and energy deposition in the body. The feature of stylized <b>computational</b> phantom is finely tuned by adjusting individual parameters of the mathematical equations, which describes the volume, position, and shape of individual organs. Stylized <b>computational</b> phantom {{has a long history of}} development through the 1960s to 1980s.|$|E
25|$|The main {{impetus for}} the {{development}} of <b>computational</b> geometry as a discipline was progress in computer graphics and computer-aided design and manufacturing (CAD/CAM), but many problems in <b>computational</b> geometry are classical in nature, and may come from mathematical visualization.|$|E
25|$|Theoretical and <b>computational</b> {{neuroscience}} {{is concerned}} with the theoretical analysis and the <b>computational</b> modeling of biological neural systems. Since neural systems attempt to reflect cognitive processes and behavior, the field is closely related to cognitive and behavioral modeling.|$|E
25|$|The Blum axioms {{can be used}} {{to define}} an {{abstract}} <b>computational</b> complexity theory on the set of computable functions. In <b>computational</b> complexity theory, the problem of determining the complexity of a computable function is known as a function problem.|$|E
25|$|However, some <b>computational</b> {{problems}} {{are easier to}} analyze in terms of more unusual resources. For example, a non-deterministic Turing machine is a <b>computational</b> model that is allowed to branch out to check many different possibilities at once. The non-deterministic Turing machine has {{very little to do}} with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing <b>computational</b> problems.|$|E
25|$|Over {{the last}} 20 years, {{the field of}} <b>computational</b> finance has {{expanded}} into virtually every area of finance, {{and the demand for}} practitioners has grown dramatically. Moreover, many specialized companies have grown up to supply <b>computational</b> finance software and services.|$|E
