11|8699|Public
40|$|Deep neural {{networks}} have advanced {{the state of}} the art in named entity recognition. However, under typical training procedures, advantages over classical methods emerge only with large datasets. As a result, deep learning is employed only when large public datasets or a large budget for manually labeling data is available. In this work, we show that by <b>combining</b> <b>deep</b> <b>learning</b> with active learning, we can outperform classical methods even with a significantly smaller amount of training data...|$|E
40|$|The project aims to {{research}} on <b>combining</b> <b>deep</b> <b>learning</b> specifically Long-Short Memory (LSTM) and basic statistics in multiple multistep time series prediction. LSTM can dive {{into all the}} pages and learn the general trends of variation in a large scope, while the well selected medians for each page can keep the special seasonality of different pages so that the future trend will not fluctuate too much from the reality. A recent Kaggle competition on 145 K Web Traffic Time Series Forecasting [1] is used to thoroughly illustrate and test this idea...|$|E
40|$|Recent {{advances}} in <b>combining</b> <b>deep</b> <b>learning</b> and Reinforcement Learning {{have shown a}} promising path for designing new control agents that can learn optimal policies for challenging control tasks. These new methods address the main limitations of conventional Reinforcement Learning methods such as customized feature engineering and small action/state space dimension requirements. In this paper, we leverage one of the state-of-the-art Reinforcement Learning methods, known as Trust Region Policy Optimization, to tackle intersection management for autonomous vehicles. We show that using this method, we can perform fine-grained acceleration control of autonomous vehicles in a grid street plan to achieve a global design objective. Comment: Accepted in IEEE Smart World Congress 201...|$|E
5000|$|In May 2016, Invincea {{launched}} X by Invincea. X protects endpoints by detecting {{and blocking}} known and unknown malware—without signatures in real-time. X <b>combines</b> <b>deep</b> <b>learning,</b> {{which is an}} advanced form of machine learning, behavioral analysis and isolation technology in one lightweight agent.|$|R
50|$|AlphaGo, {{developed}} by Google DeepMind, {{made a significant}} advance by beating a professional human player in October 2015, using techniques that <b>combined</b> <b>deep</b> <b>learning</b> and Monte-Carlo tree search. AlphaGo is significantly more powerful than other previous Go programs, {{and the first to}} beat a 9 dan human professional in a game without handicaps on a full-sized board.|$|R
50|$|This {{algorithm}} {{was later}} <b>combined</b> with <b>deep</b> <b>learning,</b> {{as in the}} DQN algorithm (see above), resulting in Double DQN which was shown to outperform the original DQN algorithm.|$|R
40|$|This thesis {{explores the}} {{exciting}} {{new field of}} deep reinforcement learning (Deep RL). This field combines well known reinforcement learning algorithms with newly developed deep learning algorithms. With Deep RL {{it is possible to}} train agents that can perform well in their environment, without the need for prior knowledge. Deep RL agents are able to learn solely by the low level percepts, such as vision and sound, they observe when interacting with the environment. <b>Combining</b> <b>deep</b> <b>learning</b> and reinforcement learning is not an easy task, and many different methods have been proposed. In this thesis I explore a novel method for combining these two techniques that matches the performance of a state of the art deep reinforcement learning algorithm in the Atari domain for the game of Pong, while requiring fewer samples...|$|E
40|$|Faced with {{continuously}} increasing {{scale of}} data, original back-propagation neural network based {{machine learning algorithm}} presents two non-trivial challenges: huge amount of data {{makes it difficult to}} maintain both efficiency and accuracy; redundant data aggravates the system workload. This project is mainly focused on the solution to the issues above, <b>combining</b> <b>deep</b> <b>learning</b> algorithm with cloud computing platform to deal with large-scale data. A MapReduce-based handwriting character recognizer will be designed in this project to verify the efficiency improvement this mechanism will achieve on training and practical large-scale data. Careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data, how MapReduce is implemented on deep learning neural network, and why this combination accelerates computation. Besides performance, the scalability and robustness will be mentioned in this report as well. Our system comes with two demonstration software that visually illustrates our handwritten digit recognition/encoding application...|$|E
40|$|In recent years, deep neural {{networks}} have yielded state-of-the-art performance on several tasks. Although some recent works {{have focused on}} <b>combining</b> <b>deep</b> <b>learning</b> with recommendation, we highlight three issues of existing works. First, most works perform deep content feature learning and resort to matrix factorization, which cannot effectively model the highly complex user-item interaction function. Second, due to the difficulty on training deep {{neural networks}}, existing models utilize a shallow architecture, and thus limit the expressiveness potential of deep learning. Third, neural network models are easy to overfit on the implicit setting, because negative interactions are not taken into account. To tackle these issues, we present a novel recommender framework called Deep Collaborative Autoencoder (DCAE) for both explicit feedback and implicit feedback, which can effectively capture the relationship between interactions via its non-linear expressiveness. To optimize the deep architecture of DCAE, we develop a three-stage pre-training mechanism that combines supervised and unsupervised feature learning. Moreover, we propose a popularity-based error reweighting module and a sparsity-aware data-augmentation strategy for DCAE to prevent overfitting on the implicit setting. Extensive experiments on three real-world datasets demonstrate that DCAE can significantly advance the state-of-the-art...|$|E
40|$|In this paper, {{we address}} the shape-from-shading problem by {{training}} deep networks with synthetic images. Unlike conventional approaches that <b>combine</b> <b>deep</b> <b>learning</b> and synthetic imagery, we propose {{an approach that}} does not need any external shape dataset to render synthetic images. Our approach consists of two synergistic processes: the evolution of complex shapes from simple primitives, and the training of a deep network for shape-from-shading. The evolution generates better shapes guided by the network training, while the training improves by using the evolved shapes. We show that our approach achieves state-of-the-art performance on a shape-from-shading benchmark...|$|R
40|$|This {{work has}} {{previously}} been published [LDS 16] and this extended abstract provides a synopsis for further discussion at the UK CGVC 2016 conference. We introduce the concept of tactile mesh saliency, where tactile salient points on a virtual mesh are those that a human {{is more likely to}} grasp, press, or touch if the mesh were a real-world object. We solve the problem of taking as input a 3 D mesh and computing the tactile saliency of every mesh vertex. The key to solving this problem is in a new formulation that <b>combines</b> <b>deep</b> <b>learning</b> and learning-to-rank methods to compute a tactile saliency measure. Finally, we discuss possibilities for future work...|$|R
30|$|Le et al. [48] {{demonstrate}} that <b>Deep</b> <b>Learning</b> {{can be used}} for action scene recognition as well as video data tagging, by using an independent variant analysis to learn invariant spatio-temporal features from video data. Their approach outperforms other existing methods when <b>combined</b> with <b>Deep</b> <b>Learning</b> techniques such as stacking and convolution to learn hierarchical representations. Previous works used to adapt hand designed feature for images like SIFT and HOG to the video domain. The Le et al. [48] study shows that extracting features directly from video data is a very important research direction, which can be also generalized to many domains.|$|R
40|$|In this paper, we {{tackle the}} {{real-world}} problem of predicting Yelp star-review rating based on business features (such as images, descriptions), user features (average previous ratings), and, of particular interest, network properties (which businesses has a user rated before). We compare multiple models on {{different sets of}} features [...] from simple linear regression on network features only to deep learning models on network and item features. In recent years, breakthroughs in deep learning have led to increased accuracy in common supervised learning tasks, such as image classification, captioning, and language understanding. However, the idea of <b>combining</b> <b>deep</b> <b>learning</b> with network feature and structure appears to be novel. While the problem of predicting future interactions in a network has been studied at length, these approaches have often ignored either node-specific data or global structure. We demonstrate that taking a mixed approach combining both node-level features and network information can effectively be used to predict Yelp-review star ratings. We evaluate on the Yelp dataset by splitting our data along the time dimension (as would naturally occur in the real-world) and comparing our model against others which do no {{take advantage of the}} network structure and/or deep learning. Comment: 10 pages, 17 figures, manuscrip...|$|E
40|$|In {{this work}} {{we show that}} {{adapting}} Deep Convolutional Neural Network training {{to the task of}} boundary detection can result in substantial improvements over the current state-of-the-art in boundary detection. Our contributions consist firstly in combining a careful design of the loss for boundary detection training, a multi-resolution architecture and training with external data to improve the detection accuracy of {{the current state of the}} art. When measured on the standard Berkeley Segmentation Dataset, we improve theoptimal dataset scale F-measure from 0. 780 to 0. 808 - while human performance is at 0. 803. We further improve performance to 0. 813 by <b>combining</b> <b>deep</b> <b>learning</b> with grouping, integrating the Normalized Cuts technique within a deep network. We also examine the potential of our boundary detector in conjunction with the task of semantic segmentation and demonstrate clear improvements over state-of-the-art systems. Our detector is fully integrated in the popular Caffe framework and processes a 320 x 420 image in less than a second. Comment: The previous version reported large improvements w. r. t. the LPO region proposal baseline, which turned out to be due to a wrong computation for the baseline. The improvements are currently less important, and are omitted. We are sorry if the reported results caused any confusion. We have also integrated reviewer feedback regarding human performance on the BSD benchmar...|$|E
40|$|Convolutional {{neural network}} (CNN) -based systems are {{increasingly}} used in autonomous vehicles for detecting obstacles. CNN-based object detection and per-pixel classification (semantic segmentation) algorithms are trained for detecting and classifying a predefined set of object types. These algorithms have difficulties in detecting distant and heavily occluded objects and are, by definition, {{not capable of}} detecting unknown object types or unusual scenarios. The visual characteristics of an agriculture field is homogeneous, and obstacles, like people, animals and other obstacles, occur rarely and are of distinct appearance compared to the field. This paper introduces DeepAnomaly, an algorithm <b>combining</b> <b>deep</b> <b>learning</b> and anomaly detection to exploit the homogenous characteristics of a field to perform anomaly detection. We demonstrate DeepAnomaly as a fast state-of-the-art detector for obstacles that are distant, heavily occluded and unknown. DeepAnomaly is compared to state-of-the-art obstacle detectors including “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks” (RCNN). In a human detector test case, we demonstrate that DeepAnomaly detects humans at longer ranges (45 – 90 m) than RCNN. RCNN has a similar performance at a short range (0 – 30 m). However, DeepAnomaly has much fewer model parameters and (182 ms/ 25 ms =) a 7. 28 -times faster processing time per image. Unlike most CNN-based methods, the high accuracy, the low computation time and the low memory footprint make it suitable for a real-time system running on a embedded GPU (Graphics Processing Unit) ...|$|E
30|$|Identifying and {{predicting}} user’s {{behavior and}} interested content {{are often more}} valuable than simply providing services to users. Traditional caching decisions are driven by user requests. Statistical decision-making based on the popularity, size, type, and location of content has high requirements on hardware resources and poor flexibility. Its algorithm does not offer long-term memory and intelligence. Recently, Mnih et al. [12] <b>combine</b> <b>deep</b> <b>learning</b> and reinforcement learning algorithms, using game video images (high-dimensional sensory information) and game scores as inputs to simulate a human player playing the Atari 2600 game. In the absence of explicitly defined game rules and human experience, the intelligent agent, through studying human behavior, ultimately attains the level of human professional players and surpasses all similar algorithms. Besides, Silver et al. [13] propose a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, their program AlphaGo achieved a 99.8 % winning rate against other Go programs and defeated the human European Go champion by 5 games to 0. The above two achievements have aroused great concern of AI researchers.|$|R
40|$|While {{the concept}} of visual {{saliency}} has been previously explored {{in the areas of}} mesh and image processing, saliency detection also applies to other sensory stimuli. In this paper, we explore the problem of tactile mesh saliency, where we define salient points on a virtual mesh as those that a human is more likely to grasp, press, or touch if the mesh were a real-world object. We solve the problem of taking as input a 3 D mesh and computing the relative tactile saliency of every mesh vertex. Since it is difficult to manually define a tactile saliency measure, we introduce a crowdsourcing and learning framework. It is typically easy for humans to provide relative rankings of saliency between vertices rather than absolute values. We thereby collect crowdsourced data of such relative rankings and take a learning-to-rank approach. We develop a new formulation to <b>combine</b> <b>deep</b> <b>learning</b> and learning-to-rank methods to compute a tactile saliency measure. We demonstrate our framework with a variety of 3 D meshes and various applications including material suggestion for rendering and fabricatio...|$|R
40|$|With the {{development}} of state-of-art <b>deep</b> reinforcement <b>learning,</b> we can efficiently tackle continuous control problems. But the <b>deep</b> reinforcement <b>learning</b> method for continuous control is based on historical data, which would make unpredicted decisions in unfamiliar scenarios. <b>Combining</b> <b>deep</b> reinforcement <b>learning</b> and safety based control can get good performance for self-driving and collision avoidance. In this passage, we use the Deep Deterministic Policy Gradient algorithm to implement autonomous driving without vehicles around. The vehicle can learn the driving policy in a stable and familiar environment, which is efficient and reliable. Then we use the artificial potential field to design collision avoidance algorithm with vehicles around. The path tracking method is also taken into consideration. The combination of <b>deep</b> reinforcement <b>learning</b> and safety based control performs well in most scenarios...|$|R
40|$|Current domain-independent, {{classical}} planners require symbolic {{models of}} the problem domain and instance as input, resulting in a knowledge acquisition bottleneck. Meanwhile, although deep learning has achieved significant success in many fields, the knowledge is encoded in a subsymbolic representation which is incompatible with symbolic systems such as planners. We propose LatPlan, an unsupervised architecture <b>combining</b> <b>deep</b> <b>learning</b> and classical planning. Given only an unlabeled set of image pairs showing a subset of transitions allowed in the environment (training inputs), {{and a pair of}} images representing the initial and the goal states (planning inputs), LatPlan finds a plan to the goal state in a symbolic latent space and returns a visualized plan execution. The contribution of this paper is twofold: (1) State Autoencoder, which finds a propositional state representation of the environment using a Variational Autoencoder. It generates a discrete latent vector from the images, based on which a PDDL model can be constructed and then solved by an off-the-shelf planner. (2) Action Autoencoder / Discriminator, a neural architecture which jointly finds the action symbols and the implicit action models (preconditions/effects), and provides a successor function for the implicit graph search. We evaluate LatPlan using image-based versions of 3 planning domains: 8 -puzzle, Towers of Hanoi and LightsOut. Comment: This is an extended manuscript of the paper accepted in AAAI- 18. The contents of AAAI- 18 paper itself is significantly extended from what has been published in Arxiv or previous workshops. Over half of the paper describing (2) is new. Additionally, this manuscript contains the supplemental materials of AAAI- 18 submissio...|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 2017 - 07 Reinforcement {{learning}} {{refers to}} a class of algorithms that aim at learning a good policy in a dynamic environment. Recently, by <b>combining</b> <b>deep</b> <b>learning</b> with reinforcement learning, researchers have made significant breakthroughs in many artificial intelligence applications. The most notable applications are Atari games and game of Go. However, natural language applications involving deep reinforcement learning are still rare. This thesis studies deep reinforcement learning in natural language scenarios with three contributions. First we introduce a novel architecture for reinforcement learning with deep neural networks designed to handle state and action spaces characterized by natural language. The architecture represents state and action spaces with separate embedding vectors, which are combined with an interaction function to approximate the Q-function in reinforcement learning. Second, we investigate reinforcement learning with a combinatorial, natural language action space. Novel deep reinforcement learning architectures are studied for effective modeling of the value function associated with actions comprised of interdependent sub-actions, accounting for redundancy among sub-actions. In addition, a two-stage Q-learning framework is introduced as a strategy for reducing the cost to search the combinatorial action space. Third, we augment the state representation to incorporate global context using an external unstructured knowledge source with temporal information. This approach is inspired by the observation that in a real-world decision making process, it is usually beneficial to consider background knowledge and popular current events relevant to the current local context. We experiment on two types of tasks, text-based games and predicting popular Reddit discussion threads. We show that all contributions help reinforcement learning in natural language scenarios. Specifically, experiments with paraphrased action descriptions on text games show that separate modeling of state and action spaces is extracting meaning rather than simply memorizing strings of text. For a combinatorial action space, our proposed model, which represents dependence between sub-actions through a bi-directional LSTM, gives the best performance for predicting popular Reddit threads across different domains. The two-stage Q-learning achieves significant performance gain compared to random sampling a subspace of the combinatorial action space. For tracking the most popular thread, incorporating external knowledge {{in the form of}} discussions about world news also leads to significant improvements with a 34 % gain for discussions about topic (politics) for which world news is particularly relevant...|$|E
40|$|Numerous {{groups have}} applied {{a variety of}} <b>deep</b> <b>learning</b> {{techniques}} to computer vision problems in highway perception scenarios. In this paper, we presented a number of empirical evaluations of recent <b>deep</b> <b>learning</b> advances. Computer vision, <b>combined</b> with <b>deep</b> <b>learning,</b> {{has the potential to}} bring about a relatively inexpensive, robust solution to autonomous driving. To prepare <b>deep</b> <b>learning</b> for industry uptake and practical applications, neural networks will require large data sets that represent all possible driving environments and scenarios. We collect a large data set of highway data and apply <b>deep</b> <b>learning</b> and computer vision algorithms to problems such as car and lane detection. We show how existing convolutional neural networks (CNNs) can be used to perform lane and vehicle detection while running at frame rates required for a real-time system. Our results lend credence to the hypothesis that <b>deep</b> <b>learning</b> holds promise for autonomous driving. Comment: Added a video for lane detectio...|$|R
40|$|The {{ever-increasing}} {{demand for}} seamless high-definition video streaming, {{along with the}} widespread adoption of the Dynamic Adaptive Streaming over HTTP (DASH) standard, {{has been a major}} driver of the large amount of research on bitrate adaptation algorithms. The complexity and variability of the video content and of the mobile wireless channel make this an ideal application for learning approaches. Here, we present D-DASH, a framework that <b>combines</b> <b>Deep</b> <b>Learning</b> and Reinforcement Learning techniques to optimize the Quality of Experience (QoE) of DASH. Different learning architectures are proposed and assessed, combining feed-forward and recurrent deep neural networks with advanced strategies. D-DASH designs are thoroughly evaluated against prominent algorithms from the state-of-the-art, both heuristic and learning-based, evaluating performance indicators such as image quality across video segments and freezing/rebuffering events. Our numerical results are obtained on real and simulated channel traces and show the superiority of D-DASH in nearly all the considered quality metrics. Besides yielding a considerably higher QoE, the D-DASH framework exhibits faster convergence to the rate-selection strategy than the other learning algorithms considered in the study. This makes it possible to shorten the training phase, making D-DASH a good candidate for client-side runtime learning...|$|R
40|$|We {{propose a}} novel <b>deep</b> <b>learning</b> model for joint document-level entity disambiguation, which leverages learned neural representations. Key {{components}} are entity embeddings, a neural attention mechanism over local context windows, and a differentiable joint inference stage for disambiguation. Our approach thereby <b>combines</b> benefits of <b>deep</b> <b>learning</b> with more traditional approaches such as graphical models and probabilistic mention-entity maps. Extensive experiments {{show that we}} are able to obtain competitive or state-of-the-art accuracy at moderate computational costs. Comment: Conference on Empirical Methods in Natural Language Processing (EMNLP) 2017 long pape...|$|R
40|$|The International Symposium on Biomedical Imaging (ISBI) held a grand {{challenge}} to evaluate computational {{systems for the}} automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0. 925 for the task of whole slide image classification and a score of 0. 7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0. 966 and a tumor localization score of 0. 733. <b>Combining</b> our <b>deep</b> <b>learning</b> system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0. 995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using <b>deep</b> <b>learning</b> to produce significant improvements in the accuracy of pathological diagnoses...|$|R
40|$|In recent years, {{more and}} more machine {{learning}} algorithms have been applied to odor recognition. These odor recognition algorithms usually assume that the training dataset is static. However, for some odor recognition tasks, the odor dataset is dynamically growing where not only the training samples but also the number of classes increase over time. Motivated by this concern, we proposed a deep nearest class mean (DNCM) model which <b>combines</b> the <b>deep</b> <b>learning</b> framework and nearest class mean (NCM) method. DNCM not only can leverage deep neural network to extract deep features, but also well suited for integrating new classes. Experiments demonstrate that the proposed DNCM model is effective and efficient for incremental odor classification, especially for new classes with {{only a small number}} of training examples. Comment: 15 pages, 6 figure...|$|R
40|$|In this paper, {{we explore}} {{the use of}} deep {{convolution}} and deep belief networks as potential functions in structured prediction models for the segmentation of breast masses from mammograms. In particular, the structured prediction models are estimated with loss minimization parameter learning algorithms, representing: a) conditional random field (CRF), and b) structured support vector machine (SSVM). For the CRF model, we use the inference algorithm based on tree re-weighted belief propagation with truncated fitting training, and for the SSVM model the inference is based on graph cuts with maximum margin training. We show empirically the importance of <b>deep</b> <b>learning</b> methods in producing state-of-the-art results for both structured prediction models. In addition, we show that our methods produce results that can be considered the best results to date on DDSM-BCRP and INbreast databases. Finally, we show that the CRF model is significantly faster than SSVM, {{both in terms of}} inference and training time, which suggests an advantage of CRF models when <b>combined</b> with <b>deep</b> <b>learning</b> potential functions. © Springer International Publishing Switzerland 2015...|$|R
40|$|Recent {{years have}} seen a great {{interest}} in using deep architectures for feature learning from data. One drawback of the commonly used unsupervised <b>deep</b> feature <b>learning</b> methods is that for supervised or semi-supervised learning tasks, the information in the target variables are not used until the final stage when the classifier or regressor is trained on the learned features. This could lead to over-generalized features that are not competitive on the specific supervised or semi-supervised learning tasks. In this work, we describe a new <b>learning</b> method that <b>combines</b> <b>deep</b> feature <b>learning</b> on mixed labeled and unlabeled data sets. Specifically, we describe a weakly supervised learning method of a prior supervised convolutional stacked auto-encoders (PCSA), of which information in the target variables is represented probabilistically using a Gaussian Bernoulli restricted Boltzmann machine (RBM). We apply this method to the decoding problem of an ECoG based Brain Computer Interface (BCI) system. Our experimental results show that PCSA achieves significant improvement in decoding performance on benchmark data sets compared to the unsupervised feature learning {{as well as to the}} current state-of-the-art algorithms that are based on manually crafted features...|$|R
40|$|Background. Protein {{dihedral}} angles {{provide a}} detailed description of protein local conformation. Predicted dihedral angles can be used to narrow down the conformational space of the whole polypeptide chain significantly, thus aiding protein tertiary structure prediction. However, direct angle prediction from sequence alone is challenging. Method. In this study, we present a novel method to predict real-valued angles by <b>combining</b> clustering and <b>deep</b> <b>learning.</b> That is, we first generate certain clusters of angles (each assigned a label) and then apply a deep residual neural network to predict the label posterior probability. Finally, we output real-valued prediction by a mixture of the clusters with their predicted probabilities. At the same time, we also estimate the bound of the prediction errors at each residue from the predicted label probabilities. Result. In this article, we present a novel method (named RaptorX-Angle) to predict real-valued angles by <b>combining</b> clustering and <b>deep</b> <b>learning.</b> Tested on a subset of PDB 25 and the targets in the latest two Critical Assessment of protein Structure Prediction (CASP), our method outperforms the existing state-of-art method SPIDER 2 in terms of Pearson Correlation Coefficient (PCC) and Mean Absolute Error (MAE). Our result also shows approximately linear relationship between the real prediction errors and our estimated bounds. That is, the real prediction error can be well approximated by our estimated bounds. Conclusions. Our study provides an alternative and more accurate prediction of dihedral angles, which may facilitate protein structure prediction and functional study. Comment: 23 pages, 6 figures, has been accepted by The Sixteenth Asia Pacific Bioinformatics Conferenc...|$|R
40|$|In this {{research}} project, {{a system is}} proposed to aid the visually impaired by providing partial contextual information of the surroundings using 360 ° view camera <b>combined</b> with <b>deep</b> <b>learning</b> is proposed. The system uses a 360 ° view camera with a mobile device to capture surrounding scene information and provide contextual information to the user {{in the form of}} audio. The system could also be used for other applications such as logo detection which visually impaired users can use for shopping assistance. The scene information from the spherical camera feed is classified by identifying objects that contain contextual information of the scene. That is achieved using convolutional neural networks (CNN) for classification by leveraging CNN transfer learning properties using the pre-trained VGG- 19 network. There are two challenges related to this paper, a classification and a segmentation challenge. As an initial prototype, we have experimented with general classes such restaurants, coffee shops and street signs. We have achieved a 92. 8 % classification accuracy in {{this research}} project...|$|R
50|$|His recent {{research}} focuses on <b>combining</b> techniques in <b>Deep</b> <b>Learning</b> and Computer Graphics to facilitate the creation of 3D avatars and to enable true immersive face-to-face communication and telepresence in Virtual Reality. In collaboration with Oculus / Facebook, he developed in 2015, the first facial performance sensing head-mounted display, which allows users to transfer their facial expressions onto their digital avatars while being immersed in a virtual environment. In the same year, he founded the company Pinscreen, Inc. in Santa Monica, which introduced a technology that can generate realistic 3D avatars of a person including the hair from a single photograph. Their innovation includes {{the development of a}} deep neural network that can infer photorealistic facial textures from a low resolution still.|$|R
40|$|Recognition of {{handwritten}} words {{continues to}} be an important problem in document analysis and recognition. Existing approaches extract hand-engineered features from word images [...] which can perform poorly with new data sets. Recently, <b>deep</b> <b>learning</b> has attracted great attention because of the ability to learn features from raw data. Moreover they have yielded state-of-the-art results in classification tasks including character recognition and scene recognition. On the other hand, word recognition is a sequential problem where we need to model the correlation between characters. In this paper, we propose using deep Conditional Random Fields (deep CRFs) for word recognition. Basically, we <b>combine</b> CRFs with <b>deep</b> <b>learning,</b> in which <b>deep</b> features are <b>learned</b> and sequences are labeled in a unified framework. We pre-train the deep structure with stacked restricted Boltzmann machines (RBMs) for feature learning and optimize the entire network with an online learning algorithm. The proposed model was evaluated on two datasets, and seen to perform significantly better than competitive baseline models. The source code is available at [URL] 5 pages, published in ICIP 2016. arXiv admin note: substantial text overlap with arXiv: 1412. 339...|$|R
40|$|Diabetic {{retinopathy}} {{is one of}} {{the leading}} causes of preventable blindness in the world. Its earliest sign are red lesions, a general term that groups both microaneurysms and hemorrhages. In daily clinical practice, these lesions are manually detected by physicians using fundus photographs. However, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. Computer-assisted diagnosis of DR based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. Several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. <b>Deep</b> <b>learning</b> based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually. In this paper we propose a novel method for red lesion detection based on <b>combining</b> both <b>deep</b> <b>learned</b> and domain knowledge. Features learned by a CNN are augmented by incorporating hand crafted features. Such ensemble vector of descriptors is used afterwards to identify true lesion candidates using a Random Forest classifier. We empirically observed that combining both sources of information significantly improve results with respect to using each approach separately. Furthermore, our method reported the highest performance on a per-lesion basis on DIARETDB 1 and e-ophtha, and for screening and need for referral on MESSIDOR compared to a second human expert. Results highlight the fact that integrating manually engineered approaches with <b>deep</b> <b>learned</b> features is relevant to improve results when the networks are trained from lesion-level annotated data. An open source implementation of our system is publicly available online. Comment: Accepted for publication in Computer Methods and Programs in Biomedicin...|$|R
40|$|We {{introduce}} {{a model that}} learns to convert simple hand drawings into graphics programs written in a subset of. The model <b>combines</b> techniques from <b>deep</b> <b>learning</b> and program synthesis. We learn a convolutional neural network that proposes plausible drawing primitives that explain an image. These drawing primitives are like a trace of the set of primitive commands issued by a graphics program. We learn a model that uses program synthesis techniques to recover a graphics program from that trace. These programs have constructs like variable bindings, iterative loops, or simple kinds of conditionals. With a graphics program in hand, we can correct errors made by the deep network, measure similarity between drawings by use of similar high-level geometric structures, and extrapolate drawings. Taken together these results are a step towards agents that induce useful, human-readable programs from perceptual input...|$|R
50|$|A deep Q-network (DQN) {{is a type}} of <b>deep</b> <b>learning</b> {{model that}} <b>combines</b> a <b>deep</b> CNN with Q-learning, a form of {{reinforcement}} learning. Unlike earlier reinforcement learning agents, DQNs can learn directly from high-dimensional sensory inputs.|$|R
40|$|Monte Carlo Tree Search (MCTS) {{methods have}} proven {{powerful}} in planning for sequential decision-making {{problems such as}} Go and video games, but their performance can be poor when the planning depth and sampling trajectories are limited or when the rewards are sparse. We present an adaptation of PGRD (policy-gradient for reward-design) for learning a reward-bonus function to improve UCT (a MCTS algorithm). Unlike previous applications of PGRD in which the space of reward-bonus functions was limited to linear functions of hand-coded state-action-features, we use PGRD with a multi-layer convolutional neural network to automatically learn features from raw perception {{as well as to}} adapt the non-linear reward-bonus function parameters. We also adopt a variance-reducing gradient method to improve PGRD's performance. The new method improves UCT's performance on multiple ATARI games compared to UCT without the reward bonus. <b>Combining</b> PGRD and <b>Deep</b> <b>Learning</b> in this way should make adapting rewards for MCTS algorithms far more widely and practically applicable than before. Comment: In 25 th International Joint Conference on Artificial Intelligence (IJCAI), 201...|$|R
40|$|Large scale {{duplicate}} detection, clustering {{and mining}} of documents or images has been conventionally treated with seed detection via hashing, followed by seed growing heuristics using fast search. Principled clustering meth-ods, especially kernelized and spectral ones, have higher complexity and {{are difficult to}} scale above millions. Under the assumption of documents or images embedded in Eu-clidean space, we revisit recent advances in approximate k-means variants, and borrow their best ingredients to in-troduce a new one, inverted-quantized k-means (IQ-means). Key underlying concepts are quantization of data points and multi-index based inverted search from centroids to cells. Its quantization {{is a form of}} hashing and analogous to seed detection, while its updates are analogous to seed growing, yet principled in the sense of distortion minimization. We further design a dynamic variant that is able to determine the number of clusters k in a single run at nearly zero ad-ditional cost. <b>Combined</b> with powerful <b>deep</b> <b>learned</b> rep-resentations, we achieve clustering of a 100 million image collection on a single machine in less than one hour. 1...|$|R
