100|80|Public
50|$|This {{property}} only holds if {{the vacuum}} {{is a pure}} state. If the vacuum is degenerate {{and we have a}} mixed state, the <b>cluster</b> <b>decomposition</b> property fails.|$|E
50|$|In physics, the <b>cluster</b> <b>decomposition</b> {{property}} {{is related to}} locality in quantum field theory. In a quantum field theory having this property, the vacuum expectation value of a product of many operators - each of them being either in region A or in region B where A and B are very separated - asymptotically equals {{the product of the}} expectation value of the product of the operators in A, times a similar factor from the region B. Consequently, sufficiently separated regions behave independently.|$|E
5000|$|One {{can also}} prove {{fundamental}} theorems for relativistic quantum field theories using the front form, including: (a) the <b>cluster</b> <b>decomposition</b> theoremand (b) the vanishing of the anomalous gravitomagnetic moment for any Fock state of a hadron;one also {{can show that}} a nonzero anomalous magnetic moment of a bound state requires nonzero angular momentum of the constituents. The cluster propertiesof light-front time-ordered perturbation theory, together with [...] conservation, {{can be used to}} elegantly derive the Parke-Taylor rules for multi-gluon scattering amplitudes.The counting-rulebehavior of structure functions at large [...] and Bloom-Gilman duality ...|$|E
40|$|A {{decomposition}} of a generalized Kendall's [tau] into three components ("within", "between" and "remainder" terms) is presented. We {{show how the}} maximization of the "between" term {{can be used in}} clustering and that the optimal decomposition {{in the case of a}} regular dependence of variables is non-overlapping ([tau]R = 0). Characterization of admissible solutions to maximization problem is provided. Concentration index <b>Clustering</b> <b>Decomposition</b> Kendall's [tau]...|$|R
40|$|Background: Protein {{rigidity}} {{analysis is}} an efficient computational method for extracting flexibility information from static, X-ray crystallography protein data. Atoms and bonds are modeled as a mechanical structure and analyzed with a fast graph-based algorithm, producing a decomposition of the flexible molecule into interconnected rigid clusters. The result depends critically on noncovalent atomic interactions, primarily on how hydrogen bonds and hydrophobic interactions are computed and modeled. Ongoing research {{points to the}} stringent need for benchmarking rigidity analysis software systems, towards the goal of increasing their accuracy and validating their results, either against each other and against biologically relevant (functional) parameters. We propose two new methods for modeling hydrogen bonds and hydrophobic interactions that more accurately reflect a mechanical model, without being computationally more intensive. We evaluate them using a novel scoring method, based on the B-cubed score from the information retrieval literature, which measures how well two <b>cluster</b> <b>decompositions</b> match. Results: To evaluate the modeling accuracy of KINARI, our pebble-game rigidity analysis system, we use a benchmark data set of 20 proteins, each with multiple distinct conformations deposited in the Protein Data Bank. <b>Cluster</b> <b>decompositions</b> for them were previously determined with the RigidFinder method from Gerstein’s lab an...|$|R
40|$|Decomposition of any N-partite state (density operator) into {{clusters}} (that do not overlap) is {{studied in}} detail {{with a view}} {{to learn as much as}} possible about the correlations implied by the state. The Wootters-Mermin theorem, stating that the totality of all strings of cluster events (projectors) determines the state in any finite- or infinite-dimensional state space, is a slightly sharpened and generalized form of the original results of Wootters and Mermin. It is applied to tensor factorization of the state into states of <b>clusters</b> (uncorrelated <b>decomposition)</b> and it is shown that a finest uncorrelated decomposition always exists, and that its coarsenings and only they are other possible uncorrelated <b>cluster</b> <b>decompositions.</b> Distant effects witin homogeneous cluster states, which are, by definition, the tensor factors in the finest uncorrelated decomposition, are discussed. The entire study is viewed by the author as a possible further elaboration of Mermin's Ithaca program. Comment: LaTeX 2 E, 31 page, no figur...|$|R
5000|$|Just as Z is {{interpreted}} as the generating functional (aka characteristic function(al)/moment-generating function(al) of the probability distribution function(al) e&minus;Sφ/Z) of the time ordered VEVs/Schwinger function (aka moments) (see path integral formulation), E (a.k.a. the second characteristic function(al)/cumulant-generating function(al)) is the generator of [...] "connected" [...] time ordered VEVs/connected Schwinger functions (i.e. the cumulants) where connected here {{is interpreted}} {{in the sense of}} the <b>cluster</b> <b>decomposition</b> theorem which means that these functions approach zero at large spacelike separations, or in approximations using Feynman diagrams, connected components of the graph.|$|E
5000|$|Thus the Klein-Gordon {{equation}} (spin [...] ) and the Dirac equation (spin [...] ) in this guise {{remain in}} the theory. Higher spin analogues include the Proca equation (spin [...] ), Rarita - Schwinger equation (spin [...] ), and, more generally, the Bargmann - Wigner equations. For massless free fields two examples are the free field Maxwell equation (spin [...] ) and the free field Einstein equation (spin [...] ) for the field operators. All of them are essentially {{a direct consequence of}} the requirement of Lorentz invariance. Their solutions must transform under Lorentz transformation in a prescribed way, i.e. under a particular representation of the Lorentz group and that together with few other reasonable demands, e.g. the <b>cluster</b> <b>decomposition</b> principle, with implications for causality is enough to fix the equations.|$|E
40|$|The <b>cluster</b> <b>decomposition</b> {{principle}} {{is used to}} derive Ward-Takahashi-like identities in QCD. Comparison with published calculations of QCD vertices finds that these new identities are overconstrained Slavnov-Taylor identities, thus demonstrating by contradiction {{the failure of the}} <b>cluster</b> <b>decomposition</b> principle in the perturbative and far-infrared regimes...|$|E
40|$|Description This package {{implements}} propensity <b>clustering</b> and <b>decomposition.</b> Propensity decomposition can {{be viewed}} {{on the one hand}} as a generalization of the eigenvector-based approximation of correlation networks, {{and on the other hand}} as a generalization of random multigraph models and conformity-based decompositions...|$|R
40|$|We {{study the}} chiral condensates and the eta^prime meson correlators {{of the massive}} Schwinger model in non-zero theta vacuum. Our {{data suggest that the}} pseudoscalar {{operator}} does condense in a fixed topological sector and gives long range correlations of the eta^prime meson. We find that this is well understood from the <b>clustering</b> <b>decomposition</b> and statistical picture. Our result also indicates that even in theta= 0 case, the long range correlation of eta^prime meson receives non-zero contributions from all the topological sectors and that their cancellation is non-trivial and requires accurate measurement of the reweighting factors as well as the expectation values. It is then clear that the fluctuation of the disconnected diagram originates from the pseudoscalar condensates. Comment: Lattice 2004 (topology), 3 pages, 3 figure...|$|R
40|$|Abstract. Searching objects {{within a}} catalog {{is a problem}} of {{increasing}} importance, as the general public has access to increasing volumes of data. Constraint programming has addressed the case of searching databases of complex products that can be customized and build from components, through constraint-based configurators. We address the issue of searching objects within catalogs of simpler items for which no logic description is available. We propose to embed constraint technology in a search assistant supporting dynamic and concise dialogs based on the exchange of constraint formulations between the client and the server. At each iteration, the server analyses the data available in the catalog, computes abstractions, <b>cluster</b> <b>decompositions</b> and relaxations in order to provide the user with alternative for either explicitly focusing the search (adding constraints to the user’s wish) or enlarging it (relaxing, to some extent, a subset of the user’s constraints). This cooperative system is currently used for Intranets, customer relationship management systems and e-commerce websites. 1...|$|R
40|$|Applying the thermo-field double {{formalism}} to extremal {{black holes}} in AdS with a macroscopic horizon, {{we show that}} (1) there exists a natural basis for the degenerate microstates of an extremal black hole, and (2) <b>cluster</b> <b>decomposition</b> in the bulk implies that all correlators {{are exactly the same}} for every microstate of the extremal black hole. The latter statement can be interpreted in two ways. First, at the fully non-perturbative level of AdS/CFT at finite N, it means that <b>cluster</b> <b>decomposition</b> does not hold in the bulk. This may be viewed as a sharp manifestation of the bulk non-locality at finite N. Second, {{at the level of the}} perturbation theory in 1 /N, in which case we expect the bulk <b>cluster</b> <b>decomposition,</b> no measurement of either boundary operators or bulk field operators can distinguish the different microstates. The latter interpretation may exclude some versions of the fuzzball conjecture that assert that different microstates of a black hole are realized in the bulk as different metric and field configurations. Comment: 17 pages. Clarified some statement...|$|E
40|$|Recently David Albert {{presented}} {{an argument that}} relativistic quantum theories are non–narratable. That is, specifying the state on every space–like hypersurface in a given foliation of space–time is not in general sufficient to determine the states on other hyper-surfaces, so {{the history of the}} universe cannot be told as a narration of states at successive times. We show that the system Albert examined to arrive at this conclusion violates <b>cluster</b> <b>decomposition</b> of the S–matrix, a locality requirement satisfied by relativistic quantum field theories. We formulate the general requirements for a system to display non–narratability, and argue that a large class of systems satisfying them violate the <b>cluster</b> <b>decomposition</b> principle. ...|$|E
40|$|A {{solvable}} {{model is}} presented for multiproduction of distinguishable particles. The scattering amplitude satisfies many-particle unitarity, <b>cluster</b> <b>decomposition</b> {{with respect to}} the produced particles and Lorentz invariance. The analytic properties and the high-energy limit of the model are discussed. (15 refs) ...|$|E
40|$|The {{studies in}} the field of quantum {{statistic}} mechanics were conducted. The aim to be attained is to construct Sibbs limited states and prove their analyticity for quantum lattice systems with finite and far-actin potential, as well as study of theiar some properties. The modifications for a quantum case of the methods of transfer-matrices an <b>cluster</b> <b>decompositions</b> of classical statistic systems are used in the work. Existence of Gibbs state and free energy for one-dimensional quantum lattice systems with finite and far-acting potential was proposed. Properties of Gibbs state and free energy for systems being studied including analyticity by reverse temperature were studied. The results of the work can be used in Moscow State University; Institute of Problems of Data Transfer of the Russian Academy of Sciences, Tashkent State University, St. -Petersburg State University. The field of application covers quantum statistic mechanicsAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Dealing {{with large}} amounts of data and {{reasoning}} in real time {{are some of the}} challenges that our every day life poses to us. The answer to these questions can be given by advanced methods in signal processing and data mining which is the scope of this book. The book presents theoretical and application achievements on some of the most efficient statistical and deterministic methods for information processing (filtering, <b>clustering,</b> <b>decomposition,</b> modelling) in order to extract targeted information and find hidden patterns. The techniques presented range from Bayesian approaches such as sequential Monte Carlo methods, Markov Chain Monte Carlo filters, Rao Blackwellization, to the biologically inspired paradigm of Neural Networks and decomposition techniques such as Empirical Mode Decomposition, Independent Component Analysis (ICA) and Singular Spectrum Analysis. Advances and new theoretical interpretations related with these techniques are detailed and illustrated on a variety of real life problems as multiple object tracking, group object tracking, localization in wireless sensor networks, brain source localization, behavior reasoning, classification, clustering, video sequence processing, and others...|$|R
40|$|Abstract A copper cluster {{protected}} with 2 -phenylethanethiol (PET) exhibiting distinct optical {{features in}} UV/Vis spectroscopy is reported. Matrix-assisted laser desorption ionisation mass spectrometry {{of the cluster}} shows a well-defined molecular ion peak at m/z 5, 800, assigned to *Cu 38 (PET) 25. Fragmented ions from the cluster show the expected isotope patterns in electrospray ionisation mass spectrometry. The as-synthesized cluster was well-characterised using other tools as well. <b>Clusters</b> undergo <b>decomposition</b> in about 2 h after synthesis as a metallic fewatom core of copper is highly unstable. The products of decomposition were also characterised...|$|R
40|$|In {{this paper}} we study CFT’s {{associated}} to gerbes. These theories {{suffer from a}} lack of <b>cluster</b> <b>decomposition,</b> but this problem can be resolved: the CFT’s are the same as CFT’s for disconnected targets. Such theories also lack <b>cluster</b> <b>decomposition,</b> but in that form, the lack is manifestly not very problematic. In particular, we shall see that this matching of CFT’s, this duality between noneffective-gaugings and sigma models on disconnected targets, is a worldsheet duality related to T-duality. We perform a wide variety of tests of this claim, ranging from checking partition functions at arbitrary genus to D-branes to mirror symmetry. We also discuss a number of applications of these results, including predictions for quantum cohomology and Gromov-Witten theory and additional physical understandin...|$|E
40|$|In {{this article}} we present a {{priority}} rule construction algorithm couopled with a <b>cluster</b> <b>decomposition</b> method in order to construct feasible solutions for general scheduling problems with minimal and maximal time lag constraints. Algorithm performances have been tested on job shop scheduling problems and also a real chemical freeze-drying process...|$|E
40|$|We {{begin by}} explicating a recent {{proof of the}} <b>cluster</b> <b>decomposition</b> {{principle}} in AdS ≥ 4 from the CFT ≥ 3 bootstrap. The CFT argument also computes the leading interactions between distant objects in AdS ≥ 4, and we confirm the universal agreement between the CFT bootstrap and AdS gravity in the semi-classical limit...|$|E
30|$|Coreness {{has been}} {{employed}} in previous literature as a metric of {{the resilience of}} a network [24]. The resilience of a social network {{is the ability of}} a social group to withstand external stresses. To measure coreness of the intra-network of each <b>cluster</b> the k-core <b>decomposition</b> is applied in order to evaluate the distributions of the nodes within each k-core.|$|R
50|$|Processes {{related to}} {{functional}} decomposition are prevalent throughout {{the fields of}} knowledge representation and machine learning. Hierarchical model induction techniques such as Logic circuit minimization, decision trees, grammatical inference, hierarchical <b>clustering,</b> and quadtree <b>decomposition</b> are all examples of function decomposition. A review of other applications and function decomposition {{can be found in}} , which also presents methods based on information theory and graph theory.|$|R
40|$|We {{present a}} new {{mechanism}} for detecting shared bottlenecks between end-to-end paths in a network. It only needs one-way delays from endpoints as an input {{and is based}} on the well known linear algebraic approach SVD (Singular Value <b>Decomposition).</b> <b>Clusters</b> of flows which share a bottleneck are extracted from SVD results by outlier detection. Simulations with varying topologies and different network conditions show the high accuracy of our technique. 1...|$|R
40|$|M. L. Walker Abstract: We utilise a non-local gauge {{transform}} which {{renders the}} entire action of SUSY QED invariant and respects the SUSY algebra modulo the gauge-fixing condition, to derive two- and three-point ghost-free SUSY Ward identities in SUSY QED. We use the <b>cluster</b> <b>decomposition</b> principle {{to find the}} Green’s function Ward identities and then takes linea...|$|E
40|$|Infinite {{statistics}} {{in which all}} representations of the symmetric group can occur {{is known as a}} special case of quon theory. Our previous work has built a relativistic quantum field theory which allows interactions involving infinite statistics particles. In this paper, a more detailed analysis of this theory is available. Topics discussed include <b>cluster</b> <b>decomposition,</b> CPT symmetry and renormalization. Comment: 7 page...|$|E
40|$|The upper {{estimate}} of the percolation threshold of the Bernoulli random field on the hexagonal lattice is found. It is done {{on the basis of}} the <b>cluster</b> <b>decomposition.</b> Each term of the decomposition is estimated using the number {{estimate of}} cycles on the hexagonal lattice which represent external borders of possible finite clusters containing the fixed lattice vertex. Comment: 23 pages; 7 figure...|$|E
40|$|The {{craftsmanship}} {{concept in}} vehicle interior design is explored in a quantitative manner. A proprietary process by Johnson Controls, Inc. {{was used as}} a basis to investigate customer perceptions through surveys. A list of vehicle interior characteristics and perceived craftsmanship attributes was developed and analyzed using multidimensional scaling, <b>cluster</b> analysis, and <b>decomposition.</b> Designers can use this list to guide their work and anticipate customer satisfaction due to high quality craftsmanship...|$|R
40|$|We {{propose a}} new {{clustering}} based low-rank matrix approximation method, <b>Cluster</b> Indicator <b>Decomposition</b> (CID), which yields more accurate lowrank approximations than previous commonly used singular value decomposition and other Nyström style decompositions. Our model utilizes the intrinsic structures {{of data and}} theoretically be more compact and accurate than the traditional low rank approximation approaches. The reconstruction in CID is extremely fast leading to a desirable advantage of our method in large-scale kernel machines (like Support Vector Machines) in which {{the reconstruction of the}} kernels needs to be frequently computed. Experimental results indicate that our approach compress images much more efficiently than other factorization based methods. We show that combining our method with Support Vector Machines obtains more accurate approximation and more accurate prediction while consuming much less computation resources. ...|$|R
40|$|Pure {{hydroxyapatite}} (HA) and hydroxyapatite {{decorated with}} silver (HA@Ag) nanoparticles were synthesized and characterized. The antifungal effect of HA@Ag nanoparticles in a distilled water {{solution was evaluated}} against Candida albicans. The origin of the antifungal activity of the HA@Ag is also discussed. The results obtained showed that the HA nanorod morphology remained the same with Ag ions decorations on the HA structure which were deposited {{in the form of}} nanospheres. Interaction where occurred between the structure and its defect density variation in the interfacial HA@Ag and intrafacial HA region with the fungal medium resulted in antifungal activity. The reaction mechanisms involved oxygen and water adsorption which formed an active complex <b>cluster.</b> The <b>decomposition</b> and desorption of the final products as well as the electron/hole recombination process have an important role in fungicidal effects. © 2013 C. A. Zamperini et al...|$|R
40|$|Approximate full {{configuration}} interaction (FCI) calculations {{have recently}} become tractable for systems of unforeseen size thanks to stochastic and adaptive approximations to the exponentially scaling FCI problem. The {{result of an}} FCI calculation is a weighted set of electronic configurations, which can also be {{expressed in terms of}} excitations from a reference configuration. The excitation amplitudes contain information on the complexity of the electronic wave function, but this information is contaminated by contributions from disconnected excitations, i. e. those excitations that are just products of independent lower-level excitations. The unwanted contributions can be removed via a <b>cluster</b> <b>decomposition</b> procedure, making it possible to examine the importance of connected excitations in complicated multireference molecules which are outside the reach of conventional algorithms. We present an implementation of the <b>cluster</b> <b>decomposition</b> analysis and apply it to both true FCI wave functions, as well as wave functions generated from the adaptive sampling CI (ASCI) algorithm. The <b>cluster</b> <b>decomposition</b> is useful for interpreting calculations in chemical studies, as a diagnostic for the convergence of various excitation manifolds, as well as as a guidepost for polynomially scaling electronic structure models. Applications are presented for (i) the double dissociation of water, (ii) the carbon dimer, (iii) the π space of polyacenes, as well as (iv) the chromium dimer. While the cluster amplitudes exhibit rapid decay with increasing rank for the first three systems, even connected octuple excitations still appear important in Cr_ 2, suggesting that spin-restricted single-reference coupled-cluster approaches may not be tractable for some problems in transition metal chemistry. Comment: 15 pages, 5 figure...|$|E
40|$|A spacetime {{theory of}} matter, based on general relativity, {{is shown to}} provide, as a special case, {{standard}} electroweak theory. Although the necessity of employing quantum fields {{in order to satisfy}} the <b>cluster</b> <b>decomposition</b> principle and Lorentz invariance has been made clear, there is still no understanding as to if and why quantum fields are basic and what, if anything, they have to do with elementarity. 1 Moreover, despit...|$|E
40|$|We {{present the}} general {{structure}} of two-photon S matrix for a waveguide coupled {{to a local}} quantum system that supports multiple ground states. The presence of the multiple ground states results in a non-commutative aspect of the system {{with respect to the}} exchange of the orders of photons. Consequently, the two-photon S matrix significantly differs from the standard form as described by the <b>cluster</b> <b>decomposition</b> principle in the quantum field theory...|$|E
40|$|High-level {{semantic}} {{understanding of}} vehicle motion be-haviors is {{often based on}} vehicle motion trajectory clus-tering. In this paper, we propose an effective trajectory clustering framework in which a coarse-to-fine strategy is taken. Our framework consists of four stages: trajectory smoothing, feature extraction, trajectory coarse clustering and trajectory fine <b>clustering.</b> Wavelet <b>decomposition</b> is im-posed on raw trajectories to reduce noise in the trajectory smoothing stage. Besides the commonly used positional fea-ture, a novel feature called trajectory directional histogram is proposed to describe the statistic directional distribution of a trajectory in the feature extraction stage. Both coarse clustering and fine clustering {{are based on a}} novel graph-theoretic clustering algorithm called dominant-set cluster-ing, but they deal with different trajectory features. Exper-iments in our pre-labeled trajectory database demonstrate that the proposed trajectory clustering framework possesses a very high accuracy. 1...|$|R
40|$|A major {{limitation}} of exact inference algorithms for probabilistic graphical models is their extensive memory usage, which often puts real-world problems {{out of their}} reach. In this paper we show how we can extend inference algorithms, particularly Bucket Elimination, a special case of <b>cluster</b> (join) tree <b>decomposition,</b> to utilize disk memory. We provide the underlying ideas and show promising empirical results of exactly solving large problems not solvable before. Comment: Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty in Artificial Intelligence (UAI 2010...|$|R
40|$|AbstractThe {{estimation}} of membership functions from data {{is an important}} step in many applications of fuzzy theory. In this paper, we provide a general overview of several methods for generating membership functions for fuzzy pattern recognition applications. We discuss methods based on heuristics, probability to possibility transformations, histograms, nearest neighbor techniques, feed-forward neural networks, <b>clustering,</b> and mixture <b>decomposition.</b> We also illustrate these membership generation methods using synthetic and real data sets, and discuss the suitability and applicability of these membership function generation techniques to particular situations...|$|R
