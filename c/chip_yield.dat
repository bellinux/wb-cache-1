37|105|Public
40|$|Abstract—Defect {{inspection}} {{is required}} for process control and to enhance <b>chip</b> <b>yield.</b> Electrical measurements of test structures are commonly used to detect faults. To improve accuracy of electrically based determination of defect densities and defect size distributions, we present a novel NEST structure. There, many nested serpentine lines will be placed within a single layer only. This mask {{will be used as}} a short flow to guarantee a short turn around time for fast process data extraction. Data analysis procedures will provide densities and size distributions of killer defects that {{will have an impact on}} product <b>chip</b> <b>yield.</b> Index Terms—Semiconductor devices, test structures, yield estimation, yield optimization. I...|$|E
40|$|This paper {{describes}} an ASIC yield model {{based on the}} CMOS bridge fault model. The model predicts defect sensitive area early in the design cycle {{as a function of}} number of gates and nets. 1 INTRODUCTION The semiconductor industry has continuously been looking for ways to improve yield and reduce manufacturing cost. Although <b>chip</b> <b>yield</b> is the key element of IC manufacturing economics, the estimation of yield early in the design cycle still remains a challenging problem. Early prediction of yield is important for costing and capacity estimations. An early warning of low yield may trigger design modifications while there is still time, thus meeting the cost and quality goals. Previous research proposed various IC yield models, and Cunningham [1] summarized popular IC yield models. Popular yield models include Poisson, Murphy, Seeds, Moore, Price, and negative binomial. Table 1 summarizes <b>chip</b> <b>yield</b> models. All the above yield models are function of defect spectrum(defect density) D 0 a [...] ...|$|E
40|$|Technology {{advances}} continuously shrink on-chip devices. Consequently, {{the number}} of cores in a single chip multiprocessor (CMP) {{is expected to grow}} in coming years. Unfortunately, with smaller device size and greater integration, <b>chip</b> <b>yield</b> degrades significantly. Guaranteeing that all chip components function correctly leads to an unrealistically low yield. Chip vendors have adopted a design strategy to market partially functioning processor chips to combat this problem. The two major components in a multicore chip are compute cores and on-chip memory such as L 2 cache. From the viewpoint of the <b>chip</b> <b>yield,</b> the compute cores have a much lower yield than the on-chip memory due to their logic complexity and well-established memory yield enhancing techniques. Therefore, future CMPs are expected to have more available on-chip memories than working cores. This paper introduces a novel on-chip memory utilization scheme called StimulusCache, which decouples the L 2 caches of faulty compute cores and employs them to assist applications on other working cores. Our extensive experimental evaluation demonstrates that StimulusCache significantly improves the performance of both single-threaded and multithreaded workloads. 1...|$|E
2500|$|... "Corn <b>Chips</b> <b>Yield</b> Grist for Her Mill." [...] By Wayne Warga. Los Angeles Times. January 30, 1981. Sec. 5: 15.|$|R
5000|$|The Kickstarter {{campaign}} raised US$898,921. Raising US$3 million {{goal was}} unsuccessful, so no 64-core version of Parallella will be mass-produced. Kickstarter users having donated more than US$750 will get [...] "parallella-64" [...] variant with 64-core coprocessor (made from initial prototype manufacturing with 50 <b>chips</b> <b>yield</b> per wafer).|$|R
50|$|The {{company is}} known for {{developing}} protein chip capable of detecting at once multiple biomarkers, biomarker signatures (including markers for cancer, allergies, age related macular degeneration AMD, or infectious diseases) from a small biological sample. The protein <b>chip</b> <b>yields</b> large amounts of data, being primarily aimed for use in biomedical research in academia, clinic and industry.|$|R
40|$|Abstract – Systems-on-Chip(SoC) s are {{now moving}} from logic {{dominant}} to memory dominant chips {{in order to}} satisfy high functionality and short development cycle. This means that the yield of memory part is the most important factor for the entire <b>chip</b> <b>yield.</b> In this paper, two word-oriented memory test algorithms are proposed newly. The one is an efficient writing NPSF test algorithm and the other is an efficient disturb test algorithm. Finally, we describe an BIST architecture for word-oriented embedded memory that detects basic FFMs, DFs, NPSFs...|$|E
40|$|Unlike {{traditional}} {{design rule}} checks (DRCs), {{which have a}} clear pass or fail definition, yield issues, such as density and antenna checks, are dependent {{on a number of}} variables, resulting in a yes, no or maybe paradigm. These issues, which {{have a major impact on}} total <b>chip</b> <b>yield,</b> have typically been identified as design constraints and embedded in DRC rule files. But there is little in the way of information on how a change in layout relates to overall improvement in yield. With advanced processes of 130 nm and smaller, designs that are verified DRC clean can still result in poorly yielding or even non-functioning silicon. For this reason, a new method of communication is needed between designer and manufacturer for determining yield issues. Rather than being provided information on a simple pass/fail basis, designers need immediate access from the manufacturer to how various layout characteristics impact <b>chip</b> <b>yield.</b> This new communication loop is the first and necessary step in adopting and implementing a design for manufacture (DFM) flow. Such an approach identifies trouble spots and provides the important data that allows the designer to determine a cost/yield analysis. Designers will be deciding on and implementing a "fix or fab" methodology, resulting in greater yield and control...|$|E
40|$|This paper {{presents}} a practical realization of a binary-to-thermometer decoder with redundant output switching sequences. Its particular application is to decode the DAC segmented MSB part. In the presented realization, 4 MSB binary bits are decoded to 15 thermometer bits through 2 different thermometer switching sequences. The end-user {{can choose the}} decoding switching sequence, according to {{the distribution of the}} mismatch errors of the DAC signal current sources. Therefore, the <b>chip</b> <b>yield</b> INL Yield, which is defined as the percentage of DAC samples that meet some specifications, is expected to improve by more than 12...|$|E
40|$|The {{objectives}} of good chip design have traditionally included issues like performance, power and reliability. Yield is rarely considered during the design process, {{except in the}} design of memory ICs, where specic defect-tolerance techniques are incorporated into the architecture for yield enhancement. In order {{to make the case for}} establishing yield as another design objective we must rst prove that a <b>chip's</b> <b>yield</b> can not only be aected, but consistently improved, by decisions made during the design process. 1...|$|R
5000|$|Unhealthy foods {{tend to be}} {{inexpensive}} {{when compared}} to their healthy counterparts. Because fruits and vegetables are not subsidized, the real cost of such crops have risen nearly 40 percent. On the other hand, the prices for soda, sweets, and fats and oils have declined due to the subsidy that the government provides for commodity crops. “Currently the least expensive food available {{is also the most}} caloric and the least nutritious: a dollar’s worth of cookies or potato <b>chips</b> <b>yields</b> 1200 calories, while a dollar’s worth of carrots yields only 250 calories." ...|$|R
40|$|VLSI {{performance}} {{has increased by}} five orders of magnitude {{in the last three}} decades, made possible by continued technology scaling. This trend will continue, providing an integration capacity of billions of transistors; however, power, energy, variability, and reliability are barriers to future scaling. Die size, <b>chip</b> <b>yields,</b> and design productivity have so far limited transistor integration in a VLSI design. Now the focus has shifted to energy consumption, power dissipation, and power delivery. 1 Transistor subthreshold leakage continues to increase, and those of us in this industry have devised leakage avoidance, tolerance, and control techniques for circuits. ...|$|R
40|$|Abstract – In this paper, {{based on}} the {{equivalent}} circuit of on-track or off-track redundant via insertion and the timing delay of each net in as the timing constraint, an enhanced timing-constrained two-phase insertion approach for yield optimization is proposed to insert on-track and off-track redundant vias. For the Poisson yield model in redundant via insertion, the experimental results show that our proposed enhanced two-phase insertion approach can further reduce 0. 006 % total wire length on the average with the reduction of 0. 0002 % <b>chip</b> <b>yield</b> to maintain 100 % timing constraints for the tested benchmarks. I...|$|E
40|$|Abstract – This paper {{addresses}} {{the fact that}} memory yield will be the dominant issue affecting overall yield in nano-scale devices. It illustrates that by treating yield as a system design parameter, tremendous gains in effective <b>chip</b> <b>yield</b> can be achieved. The techniques outlined are especially suited for applications that have inherent system re dundancy such as multimedia. In that context, the paper illustrates a dramatic tolerance of up to 4 % bit errors in memory while meeting acceptable standard system specifications metrics such as Peak Signal to Noise Ratio (PSNR) in a JPEG 2000 encoding System-on-Chip (SoC) ...|$|E
40|$|With growing {{of memory}} capacity, to detect memory faults {{is more and}} more difficult, and its cost {{increases}} rapidly. Since these faults seriously decrease the yield rate of memories, it is necessary to find an effective test algorithm for memory to improve the <b>chip</b> <b>yield</b> rate. In these days, as word-oriented memories are broadly used, testing for word-oriented memory becomes more important. In this paper, a new word-oriented memory test methodology is proposed. Using small circuitry as switches, the new test methodology can apply bit-oriented memory test algorithm to word-oriented memory. In addition, the proposed methodology can detect faults effectively without increasing of test sequences. I...|$|E
2500|$|PlayStation 3 {{uses the}} Cell microprocessor, {{designed}} by Sony, Toshiba and IBM, as its CPU, {{which is made}} up of one 3.2GHz PowerPC-based [...] "Power Processing Element" [...] (PPE) and eight Synergistic Processing Elements (SPEs). The eighth SPE is disabled to improve <b>chip</b> <b>yields.</b> Only six of the seven SPEs are accessible to developers as the seventh SPE is reserved by the console's operating system. Graphics processing is handled by the NVIDIA RSX 'Reality Synthesizer', which can produce resolutions from 480i/576i SD up to 1080p HD. PlayStation 3 has 256MB of XDR DRAM main memory and 256MB of GDDR3 video memory for the RSX.|$|R
40|$|Abstract. Torrefaction is {{a thermal}} process that {{improves}} biomass {{performance as a}} fuel by property enhancements such as decreased moisture uptake and increased carbon density. Most studies to date have used very small amounts of finely ground biomass. This study reports the testing of a crucible furnace retort that was fabricated to produce intermediate quantities of torrefied material and to allow processing of wood <b>chips.</b> <b>Yields</b> ranging from 51 to 96 % were impacted {{to a greater extent}} by differences in temperature than time of treatment. Although temperature-control issues (gradients, slow heating) were experienced with the crucible furnace retort, this equipment proved to be useful for its intended purpose...|$|R
5000|$|PlayStation 3 {{uses the}} Cell microprocessor, {{designed}} by Sony, Toshiba and IBM, as its CPU, {{which is made}} up of one 3.2 GHz PowerPC-based [...] "Power Processing Element" [...] (PPE) and eight Synergistic Processing Elements (SPEs). The eighth SPE is disabled to improve <b>chip</b> <b>yields.</b> Only six of the seven SPEs are accessible to developers as the seventh SPE is reserved by the console's operating system. Graphics processing is handled by the NVIDIA RSX 'Reality Synthesizer', which can produce resolutions from 480i/576i SD up to 1080p HD. PlayStation 3 has 256 MB of XDR DRAM main memory and 256 MB of GDDR3 video memory for the RSX.|$|R
40|$|Since Field {{programmable}} gate arrays (FPGAs) are reprogrammable, faults in {{them can}} be easily tolerated once fault sites are located. In this paper we present a method for the testing and diagnosis of faults in FPGAs. The proposed method imposes no hardware overhead, and requires minimal support from external test equipments. Test time depends only {{on the number of}} faults, and is independent of the chip size. With the help of this technique, chips with faults can still be used. As a result, the <b>chip</b> <b>yield</b> can be improved and chip cost is reduced. Experimental results are given to show the feasibility of this method. 1...|$|E
40|$|As {{transistor}} feature sizes {{continue to}} shrink into the sub- 90 nm range and beyond, {{the effects of}} process variations on critical path delay have amplified. A common concept to remedy the effects of variation is speed-binning, by which chips from a single batch are rated by a discrete range of frequencies. In this paper, we argue that under these conditions, architectural optimizations should consider their effect on the “batch ” of microprocessors rather than aiming at increasing {{the performance of a}} single processor. We first show that the critical paths are mostly determined by the level 1 data caches on a set of manufactured microprocessors. Then, we propose three new microarchitectural techniques aimed at masking the effects of process variations on level 1 caches. The first two techniques allow individual highlatency cache lines spanning single or multiple sets to be disabled at the post-manufacture testing stage. The third approach introduces a small substitute cache associated with each cache way to replicate the data elements stored in the high latency lines. Our new schemes can be effectively used to boost up the overall <b>chip</b> <b>yield</b> and also shift the chip binning distribution towards higher frequencies. To make a quantitative comparison between the different schemes, we first define a metric called batchperformance that takes into account the <b>chip</b> <b>yield</b> and frequency of chips in each bin. We then analyze our proposed schemes and show that the resizing schemes and the substitute cache can increase the batch-performance by as much as 5. 8 % and 11. 6 %, respectively...|$|E
40|$|Dependability is an {{important}} attribute for microfluidic biochips that are used for safety-critical applications such as point-of-care health assessment, air-quality monitoring, and food-safety testing. Therefore, these devices must be adequately tested after manufacture and during bioassay operations. We propose a parallel scan-like testing methodology for digital microfluidic devices. A diagnosis method based on test outcomes is also proposed. The diagnosis technique is enhanced such that multiple defect sites can be efficiently located using parallel scan-like testing. Defect diagnosis {{can be used to}} reconfigure a digital microfluidic biochip such that faults can be avoided, thereby enhancing <b>chip</b> <b>yield</b> and defect tolerance. We evaluate the proposed method using complexity analysis as well as applying it to a fabricated biochip...|$|E
50|$|A similar {{approach}} {{can be used to}} program digital logic circuits. In this case, fuses are blown by the laser, enabling or disabling various logic circuits. An example of this is the IBM POWER4 microprocessor where the chip contains five banks of cache memory but only requires four banks for full operation. During testing, each cache bank is exercised. If a defect is found in one bank, that bank can be disabled by blowing its programming fuse. This built-in redundancy allows higher <b>chip</b> <b>yields</b> than would be possible if all cache banks had to be perfect in every chip. If no bank is defective, a fuse can be blown arbitrarily, leaving just four banks.|$|R
40|$|Fluctuation {{effects are}} {{becoming}} important in advanced VLSI devices {{because of their}} increasing impact on circuit performance and <b>chip</b> <b>yields.</b> Accurate modelling of these effects generally requires full 3 D simulation, which is used here to analyse four of the primary such effects. Polysilicon line edge roughness causes excess device leakage, which can be reduced {{at the cost of}} decreased performance. Phase-shift mask defects can reduce current drive and increase capacitance. Random dopant fluctuation, which causes variation in threshold voltage, is evaluated for three technology generations and it is shown that proper tip scaling can reduce these variations. Finally, a study of alpha particle strikes evaluates the effectiveness of SOI in improving soft error reliability...|$|R
50|$|A Radeon 8500 {{running at}} 300 MHz clock speeds would have hardly {{defeated}} the GeForce 4 Ti4600, {{let alone a}} newer card from NVIDIA. At best {{it could have been}} a better performing mid-range solution than the lower-complexity Radeon 9000 (RV250, see below), but it would also have cost more to produce and would have been poorly suited to the Radeon 9000's dual laptop/desktop roles due to die size and power draw. Notably, overclockers found that Radeon 8500 and Radeon 9000 could not reliably overclock to 300 MHz without additional voltage, so undoubtedly R250 would have had similar issues because of its greater complexity and equivalent manufacturing technology, and this would have resulted in poor <b>chip</b> <b>yields,</b> and thus, higher costs.|$|R
40|$|This paper {{describes}} a new architecture for binary-to-thermometer decoders used in segmented D/A converters. To improve basic converter characteristics, the architecture features redundant output thermometer code. The main concept offers two modes of operation. Each mode generates a different thermometer output, i. e. a different switching sequence for the DAC MSB thermometer analog elements. This results {{in two different}} transfer characteristics of the whole DAC for the same mismatch errors of its elements. After on-chip or off-chip measurements, the more linear transfer characteristic can be selected. In this way, <b>chip</b> <b>yield</b> is improved and the design requirements can be relaxed. Ultimately, the advantages introduced by the proposed decoder will lead to cheaper and smaller D/A Converters...|$|E
40|$|Processing {{quality of}} potato tubers is {{determined}} by high dry matter, and low reducing sugar and phenol contents (Kadam et al., 1991; Abong et al., 2009). High dry matter content increases <b>chip</b> <b>yield,</b> crispy-consistency, and reduces oil absorption during cooking (Pedreschi et al., 2005; Rommens et al., 2010). Low reducing sugars and phenol contents are required to avoid dark color and bitter taste of processed products, which negatively affect consumer acceptance (Wiltshire & Cobb, 1996; Wang-Pruski & Nowak, 2004). Dry matter of potato tubers and chip color are genetically controlled and influenced by environmental conditions during growing season and storage temperature (Kawchuk et al., 2008). Potato tubers grown in spring have higher dry matter content and shorter dormancy than tubers grown in autum...|$|E
40|$|Recent {{progress}} in process technology {{makes it possible}} to vertically stack multiple integrated chips. In three dimensional integration circuits (3 D ICs), through silicon vias (TSVs) are used to communicate signals between layers. However, TSVs act as obstacles during placement and routing and {{have a negative impact on}} <b>chip</b> <b>yield.</b> Therefore, TSV number minimization is an important topic in 3 D IC design. However, previous high-level synthesis approach only tries to maximize the number of same-layer operation-level data-transfers. In fact, a TSV should correspond to a cross-layer resource-level data-transfer. Therefore, in this paper, we propose an integer linear programming (ILP) approach to perform TSV number minimization by minimizing the number of cross-layer resource-level data-transfers. Experimental results consistently show that our approach is more effective than the previous approach in TSV number minimization. Keywords...|$|E
40|$|The {{two-dimensional}} discrete convolution operator {{is targeted}} for performance improvement {{in order to}} speed up image processing work loads. Since the large computation requirements for this operation are especially taxing to single processor computers, the approach is to consider parallel processing alternatives. Of the parallel processor classes considered, systolic arrays are singled out as the preferred parallel processing solution for the convolution problem. Therefore, {{the design of a}} pipelined double precision floating point VLSI systolic cell for convolution is described. The arithmetic operations are distributed into three pipelined stages, enabling the cell to process each set of operands within 16 clock cycles. Once fabricated and tested, the systolic <b>chip</b> <b>yielded</b> an 80 MFLOPS performance which is a remarkable improvement over available general purpose computers...|$|R
40|$|One of {{the most}} {{important}} hurdles of technology scaling is process variations, i. e., variations in device characteristics. Process variations cause large fluctuations in performance and power consumption in the manufactured chips. In addition, these fluctuations cause reductions in the <b>chip</b> <b>yields.</b> In this work, we present an analysis of a representative high-performance processor architecture and show that the caches have the highest probability of causing yield losses under process variations. We then propose a novel selective wordline voltage boosting mechanism that aims at reducing the latency of the cache lines that are affected by process variations. We show that our approach can eliminate over 80 % of the yield losses under medium level of variations, while incurring less than 1 % per-access energy overhead on average and less than 4. 5 % area overhead...|$|R
40|$|Abstract—As {{transistor}} feature sizes {{continue to}} shrink into the sub- 90 nm range and beyond, {{the effects of}} process variations on critical path delay and <b>chip</b> <b>yields</b> have amplified. A common concept to remedy the effects of variation is speed-binning, by which chips from a single batch are rated by a discrete range of frequencies and sold at different prices. In this paper, we discuss strategies to modify the number of chips in different bins and hence enhance the profits obtained from them. Particularly, we propose a scheme that introduces a small Substitute Cache associated with each cache way to replicate the data elements that will be stored in the high latency lines. Assuming a fixed pricing model, this method increases the revenue {{by as much as}} 13. 8 % without any impact on the performance of the chips...|$|R
40|$|Abstract—Memories {{are one of}} {{the most}} {{universal}} cores. On average embedded RAMs occupy 90 % area in system-on-chip (SOC), so embedded memory test design has become an essential part of the SOC development infrastructure. Here we designed reusable memory built in self test (MBIST) engine for memory test, which also gives useful information for fault diagnosis. A simple architecture for built in self repair is implemented. Integrating BISR in MBIST improves the <b>chip</b> <b>yield.</b> SOC consists of many memory models. Like, SRAM, FLASH, ROM etc, we consider here only SRAM type of memory core. Here we will see what the functional model of SRAM is and what types of Functional Faults, Fault Models and Defects exist in SRAM cores due to process variation and manufacturing. xilinx spartan 3 E tool used for synthesise and simulation...|$|E
40|$|Redundant via {{insertion}} {{is highly}} effective in improving <b>chip</b> <b>yield</b> and reliability. In this paper, we study {{the problem of}} double-cut via insertion (DVI) in a postrouting stage, where a single via can have, at most, one redundant via inserted next to it and {{the goal is to}} insert as many redundant vias as possible. The DVI problem can be naturally formulated as a zero–one integer linear program (0 – 1 ILP). Our main contributions are acceleration methods for reducing the problem size and the number of constraints. Moreover, we extend the 0 – 1 ILP formulation to handle via density constraints. Experimental results show that our 0 – 1 ILP is very efficient in computing an optimal DVI solution, with up to 73. 98 times speedup over existing heuristic algorithms...|$|E
40|$|Abstract The {{ability to}} reconfigure around {{manufacturing}} defects and operational faults increases FPGA <b>chip</b> <b>yield,</b> reduces system downtime and maintenance in field operation, and increases reli-abilities of mission- and life-critical systems. The fault reconfigu-ration technique {{discussed in this}} work use the principle of node covering in which reconfiguration is achieved by constructing re-placement chains of cells from faulty cells to spare/unused ones. A key issue in such reconfiguration is efficient incremental rerouting in the FPGA. Previous methods for node-covering based reconfig-uration are “static ” {{in the sense that}} extra interconnects are added a-priori as part of the initial circuit routing so that a specific fault pattern (e. g., one fault per row) can be tolerated [1]. This, however, results in worst-case track overheads and also in an inflexibility to tolerate other realistic fault patterns. In this paper, we develop dynamic reconfiguration and incremental rerouting techniques tha...|$|E
40|$|Bio-refining in {{this work}} {{consists}} of the production of chip (fibre) and meal fractions from winter wheat (Triticum sativum) straw and oilseed rape (Brassica napus) straw, canary reed (Phalaris arundinacea) and miscanthus (Miscanthus sinensis) in a 1 t h(- 1) capacity pilot plant. Chip fractions were evaluated as raw materials for fibre and pulp production following delignification using aqueous NaOH (0. 25 - 2. 5 N) at 100 - 150 degrees C for 60 - 180 min, with a solid-to-liquid ratio of 1. 10 (w/v). Miscanthus and winter wheat straw were fractionated to give high <b>chip</b> <b>yields</b> (66 - 70 %). The introduction of a biorefining step {{was found to be}} justified in the case of winter wheat straw and canary reed due to positive effects on pulp yield and mechanical properties. Meal fractions were also enriched in protein by this process...|$|R
40|$|The {{effect of}} {{spearmint}} {{oil on the}} storage and processing qualities of two potato varieties Diamant and Sinora was investigated and compared with the sprout inhibitor, isopropyl - N 3 -chlorophenyl carbamate (CIPC). Potatoes were stored at 10 ± 1 ºC and (73 - 78 % RH) for 6 months. Results showed spearmint oil was as effective as CIPC in checking the break of dormancy, fast sprout growth, high fresh weight loss but unlike CIPC did not kill the eye buds; so {{can be used for}} seed tubers. The oil had no adverse effects on reducing sugars, dry matter, specific gravity and <b>chips</b> <b>yield.</b> After storage for six months both varieties were still suitable for making chips and French fries. Consumers preferred chips prepared from Sinora tubers and French fries prepared from Diamant tubers treated with spearmint oil...|$|R
40|$|Abstract—Yield {{enhancement}} {{through the}} acceptance of partially good chips is a well-known technique [1], [2], [3]. In this paper, we derive a yield model for single-chip VLSI processors with partially good on-chip cache. Also, we investigate how the yield enhancement of VLSI processors with on-chip CPU cache relates {{with the number of}} acceptable faulty cache blocks, the percentage of the cache area with respect to the whole chip area, and various manufacturing process parameters as defect densities and the fault clustering parameter. One of the main conclusions is that the maximum effective yield is achieved by accepting as good, caches with {{a very small number of}} faulty cache blocks. One of the main conclusions is that the maximum effective yield is achieved by accepting as good, processor chips containing caches with a very small number of faulty cache blocks. Index Terms—Fault tolerance, on-chip CPU caches, partially good <b>chips,</b> <b>yield</b> enhancement. æ...|$|R
