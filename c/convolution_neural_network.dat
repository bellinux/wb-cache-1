155|10000|Public
30|$|To {{overcome}} {{the shortcomings of}} traditional LOGO recognition technology, this paper proposes a LOGO detection and recognition technology based on <b>convolution</b> <b>neural</b> <b>network.</b> This method uses <b>convolution</b> <b>neural</b> <b>network</b> to extract features of key frames of video and then matches the features of sample LOGO to complete the LOGO detection and recognition.|$|E
40|$|We build a set {{of human}} {{behavior}} recognition system based on the <b>convolution</b> <b>neural</b> <b>network</b> constructed for the specific human behavior in public places. Firstly, video of human behavior data set will be segmented into images, then we process the images by the method of background subtraction to extract moving foreground characters of body. Secondly, the training data sets are trained into the designed <b>convolution</b> <b>neural</b> <b>network,</b> and the depth learning network is constructed by stochastic gradient descent. Finally, the various behaviors of samples are classified and identified with the obtained network model, and the recognition results are compared with the current mainstream methods. The result show that the <b>convolution</b> <b>neural</b> <b>network</b> can study human behavior model automatically and identify human’s behaviors without any manually annotated trainings...|$|E
30|$|There {{are three}} {{main reasons for}} using an {{abstract}} neural network to abstract feature computation and extraction: Firstly, because of the inherent characteristics of convolution layer and pool layer of <b>convolution</b> <b>neural</b> <b>network,</b> image translation and other operations will not cause changes in convolution characteristics. Secondly, the use of <b>convolution</b> <b>neural</b> <b>network</b> to extract the independent learning features can avoid the use of artificial selection of fixed features, thus avoiding feature extraction as the bottleneck and ceiling of the later enhancement algorithm. Third, the size of eigenvectors of convolution layer, pool layer, and output layer can be controlled freely. The dimension of eigenvectors can be reduced when overfitting occurs in training, and the output of convolution layer can be improved when underfitting. Compared with other networks, <b>convolution</b> <b>neural</b> <b>network</b> has higher flexibility.|$|E
40|$|The {{aim of the}} {{bachelor}} thesis is the latest knowledge of <b>convolution</b> <b>neural</b> <b>networks</b> and their application. The thesis describes the history, biological neuron and analogous mathematical model of a neuron. It also deals with the areas where <b>neural</b> <b>networks</b> are used, {{as well as the}} areas in which they expand gradually, the ways of learning and training, the differences between <b>convolution</b> <b>neural</b> <b>networks</b> and classical <b>neural</b> <b>networks</b> and their architecture. The thesis consists of two parts. The first part is the selection of the framework for working with <b>convolution</b> <b>neural</b> <b>networks,</b> which is suitable for implementation in the Windows operating system, the installation of the framework and its troubleshooting. The second part is aimed at creating an automated installation tool for the Windows 7 and Windows 10 operating system, created in JavaFX...|$|R
40|$|In {{the article}} the {{question}} of designing of new training algorithm for the <b>convolution</b> <b>neural</b> <b>networks.</b> The study found the new rule for calculation of neuron?s error. ? ?????? ?????????? ?????? ?????????? ?????? ????????? ???????? ??? ?????????? ????????? ?????. ? ???? ???????????? ?????????? ????? ??????? ??? ?????????? ?????? ???????...|$|R
50|$|The {{family of}} Darkforest {{computer}} go programs {{is based on}} <b>convolution</b> <b>neural</b> <b>networks.</b> The most recent advances in Darkfmcts3 combined convolutional <b>neural</b> <b>networks</b> with more traditional Monte Carlo tree search. Darkfmcts3 is the most advanced version of Darkforest, which combines Facebook's most advanced convolutional <b>neural</b> <b>network</b> architecture from Darkfores2 with a Monte Carlo tree search.|$|R
30|$|<b>Convolution</b> <b>neural</b> <b>network</b> (CNN) is an {{artificial}} neural network developed {{on the basis of}} human learning ability for knowledge and computer network. The <b>convolution</b> <b>neural</b> <b>network</b> has more applicability for deep learning. The feature extraction and feature classification of image characters can be carried out simultaneously, and it also has the advantages of strong generalization ability and less training parameters for global optimization. It is one of the pioneering research achievements in the field of machine autonomous learning.|$|E
30|$|The feature {{extraction}} stage mainly {{refers to the}} process of extracting the eigenvalue of the image input into <b>convolution</b> <b>neural</b> <b>network.</b> In the {{feature extraction}} stage, each candidate region will undergo several convolution operations and pooling operations in <b>convolution</b> <b>neural</b> <b>network,</b> so as to compute and extract the target features. Convolution can effectively extract the invariant features from the image, while pooling can reduce the dimension of the input image without changing the features. Finally, the network will use these invariant features to classify the target.|$|E
30|$|The basic network {{structure}} of <b>convolution</b> <b>neural</b> <b>network</b> {{can be divided}} into four parts: input layer, convolution layer, full connection layer, and output layer. The following sections describe the network parts in detail.|$|E
40|$|This thesis tackles {{fine-grained}} image recognition, {{the task}} of sub-category or species classification. It explores general methods to improve fine-grained image classification {{including the use of}} generative models and deep convolutional <b>neural</b> <b>networks</b> leading to novel models such as a Mixture of deep <b>convolution</b> <b>neural</b> <b>networks.</b> This work led to 9 peer reviewed publications and a Best Paper Award...|$|R
40|$|Provides a {{consistent}} interface to the 'Keras' Deep Learning Library directly from within R. 'Keras' provides specifications for describing dense <b>neural</b> <b>networks,</b> <b>convolution</b> <b>neural</b> <b>networks</b> (CNN) and recurrent <b>neural</b> <b>networks</b> (RNN) running {{on top of}} either 'TensorFlow' or 'Theano'. Type conversions between Python and R are automatically handled correctly, even when the default choices would otherwise lead to errors. Includes complete R documentation and many working examples...|$|R
40|$|Similar to <b>convolution</b> <b>neural</b> <b>networks,</b> {{recurrent}} <b>neural</b> <b>networks</b> (RNNs) typically {{suffer from}} over-parameterization. Quantizing bit-widths of weights and activations results in runtime efficiency on hardware, yet it often {{comes at the}} cost of reduced accuracy. This paper proposes a quantization approach that increases model size with bit-width reduction. This approach will allow networks to perform at their baseline accuracy while still maintaining the benefits of reduced precision and overall model size reduction...|$|R
30|$|The {{number of}} neural nodes in the output layer is set {{according}} to specific application tasks. If it is a classification task, the output layer of <b>convolution</b> <b>neural</b> <b>network</b> {{is usually a}} classifier.|$|E
40|$|In recent years, video super {{resolution}} techniques becomes mandatory {{requirements to}} get high resolution videos. Many super resolution techniques researched but still video super resolution or scaling is a vital challenge. In this paper, we have presented a real-time video scaling based on <b>convolution</b> <b>neural</b> <b>network</b> architecture to eliminate the blurriness in the images and video frames and to provide better reconstruction quality while scaling of large datasets from lower resolution frames to high resolution frames. We compare our outcomes with multiple exiting algorithms. Our extensive results of proposed technique RemCNN (Reconstruction error minimization <b>Convolution</b> <b>Neural</b> <b>Network)</b> shows that our model outperforms the existing technologies such as bicubic, bilinear, MCResNet and provide better reconstructed motioning images and video frames. The experimental results shows that our average PSNR result is 47. 80474 considering upscale- 2, 41. 70209 for upscale- 3 and 36. 24503 for upscale- 4 for Myanmar dataset which is very high in contrast to other existing techniques. This results proves our proposed model real-time video scaling based on <b>convolution</b> <b>neural</b> <b>network</b> architecture’s high efficiency and better performance...|$|E
30|$|The {{image taken}} by UAV in this {{experiment}} is JPEG image. The simulation experiment is carried out for the image target location and recognition system based on <b>convolution</b> <b>neural</b> <b>network</b> model. The <b>convolution</b> <b>neural</b> <b>network</b> is used for image recognition. The main process of image target localization and recognition includes three steps: image segmentation, feature extraction, and object classification. Because the network will automatically extract features that are beneficial to classification and recognition during the training process, {{it is not necessary}} to pay too much attention to the image preprocessing work, just to design the network structure and adjust the network parameters. Therefore, the simulation process is mainly to see the recognition effect of the system.|$|E
40|$|We {{study the}} {{application}} of <b>neural</b> <b>networks</b> to modeling the blood glucose metabolism of a diabetic. In particular we consider recurrent <b>neural</b> <b>networks</b> and time series <b>convolution</b> <b>neural</b> <b>networks</b> which we compare to linear models and to nonlinear compartment models. We include a linear error model {{to take into account}} the uncertainty in the system and for handling missing blood glucose observations. Our results indicate that best performance can be achieved by the combination of the recurrent <b>neural</b> <b>network</b> and the linear error model...|$|R
40|$|This paper {{presents}} an empirical {{evaluation of a}} number of recently developed Automatic Target Recognition algo-rithms for Forward-Looking InfraRed(FLIR) imagery using a large database of real second-generation FUR images. The algorithms evaluated are based on <b>convolution</b> <b>neural</b> <b>networks</b> (CNN), principal component analysis (PCA), linear discriminant analysis (LDA), learning vector quantization (LVQ), and modular <b>neural</b> <b>networks</b> (MNN). Two model-based algorithms, using Rausdorff metric based matching and geometric hashing, are also evaluated. A hi-erarchical pose estimation system using CNN plus either PCA or LDA, developed by the authors, is also evaluated using the same data set...|$|R
40|$|Handwritten {{character}} is gaining {{a lot of}} attention in the area of pattern recognition as its applications in various fields are increasing day by day. HCR system is providing us with a key factor to a paperless environment. Feature Extraction is a key part for a cost effective model for handwritten character recognition. Effective features improve the recognition rate and misclassification. A hybrid model provides better performance in comparison of the individual. <b>Convolution</b> <b>neural</b> <b>networks</b> are viewed to be more efficient to optimize the recognition ability of HCR system...|$|R
30|$|Therefore, {{this paper}} applies the {{advantage}} of depth mining <b>convolution</b> <b>neural</b> <b>network</b> to image classification, tests the loss function constructed by M 3 [*]CE on two depth learning standard databases MNIST and CIFAR- 10, and pushes forward the new direction of image classification research.|$|E
40|$|In {{the article}} the {{question}} of influence {{the parameters of the}} <b>convolution</b> <b>neural</b> <b>network</b> for pattern recognition problem in human portraits was considered. The study found the optimal set of parameters {{to solve the problem of}} recognizing a person on ORL Faces dataset. ? ?????? ?????????? ?????? ??????? ?????????? ?????????? ????????? ???? ??? ?????? ????????????? ???????? ?? ?????????????. ? ???? ???????????? ?????? ??????????? ????? ?????????? ??? ??????? ?????? ????????????? ???????? ?? ???? ORL Faces...|$|E
40|$|A part-based {{approach}} for spontaneous expression recognition using audio-visual feature and deep <b>convolution</b> <b>neural</b> <b>network</b> (DCNN) is proposed. The ability of <b>convolution</b> <b>neural</b> <b>network</b> to handle variations in translation and scale is exploited for extracting visual features. The sub-regions, namely, eye and mouth parts {{extracted from the}} video faces are given as an input to the deep CNN (DCNN) inorder to extract convnet features. The audio features, namely, voice-report, voice intensity, and other prosodic features are used to obtain complementary information useful for classification. The confidence scores of the classifier trained on different facial parts and audio information are combined using different fusion rules for recognizing expressions. The effectiveness of the proposed approach is demonstrated on acted facial expression in wild (AFEW) dataset...|$|E
40|$|In this paper, {{we present}} a comment {{labeling}} system based on a deep learning strategy. We treat the answer selection task as a sequence labeling problem and propose recurrent <b>convolution</b> <b>neural</b> <b>networks</b> to recognize good comments. In the recurrent architecture of our system, our approach uses 2 -dimensional convolutional <b>neural</b> <b>networks</b> to learn the distributed representation for question-comment pair, and assigns the labels to the comment sequence with a recurrent <b>neural</b> <b>network</b> over CNN. Compared with the conditional random fields based method, our approach performs better performance on Macro-F 1 (53. 82 %), and achieves the highest accuracy (73. 18 %), F 1 -value (79. 76 %) on predicting the Good class in this answer selection challenge. ...|$|R
40|$|We {{show that}} both single-component and two-component Bose-Einstein condensates' (BECs) ground states can be {{simulated}} by deep convolutional <b>neural</b> <b>networks</b> {{of the same}} structure. We trained the <b>neural</b> <b>network</b> via inputting the coupling strength in the dimensionless Gross-Pitaevskii equation (GPE) and outputting the ground state wave-function. After training, the <b>neural</b> <b>network</b> generates ground states faster than the method of imaginary time evolution, while the relative mean-square-error between predicted states and original states is in the magnitude between $ 10 ^{- 5 }$ and $ 10 ^{- 4 }$. We compared the eigen-energies based on predicted states and original states, it is shown that the <b>neural</b> <b>network</b> can predict eigen-energies in high precisions. Therefore, the BEC ground states, which are continuous wave-functions, can be represented by deep <b>convolution</b> <b>neural</b> <b>networks...</b>|$|R
40|$|In this paper, {{the answer}} {{selection}} problem in community question answering (CQA) {{is regarded as}} an answer sequence labeling task, and a novel approach is proposed based on the recurrent architecture for this problem. Our approach applies <b>convolution</b> <b>neural</b> <b>networks</b> (CNNs) to learning the joint representation of question-answer pair firstly, and then uses the joint representation as input of the long short-term memory (LSTM) to learn the answer sequence of a question for labeling the matching quality of each answer. Experiments conducted on the SemEval 2015 CQA dataset shows the effectiveness of our approach. Comment: 6 page...|$|R
30|$|UAV {{remote sensing}} {{has been widely}} used in {{emergency}} rescue, disaster relief, environmental monitoring, urban planning, and so on. Image recognition and image location in environmental monitoring has become an academic hotspot {{in the field of}} computer vision. <b>Convolution</b> <b>neural</b> <b>network</b> model is the most commonly used image processing model. Compared with the traditional artificial neural network model, <b>convolution</b> <b>neural</b> <b>network</b> has more hidden layers. Its unique convolution and pooling operations have higher efficiency in image processing. It has incomparable advantages in image recognition and location and other forms of two-dimensional graphics tasks. As a new deformation of <b>convolution</b> <b>neural</b> <b>network,</b> residual neural network aims to make convolution layer learn a kind of residual instead of a direct learning goal. After analyzing the characteristics of CNN model for image feature representation and residual network, a residual network model is built. The UAV remote sensing system is selected as the platform to acquire image data, and the problem of image recognition based on residual neural network is studied, which is verified by experiment simulation and precision analysis. Finally, the problems and experiences in the process of learning and designing are discussed, and the future improvements in the field of image target location and recognition are prospected.|$|E
30|$|With {{the rapid}} {{development}} {{of information technology}} and network technology and the rapid popularization of computers and intelligent devices, network video media have gradually replaced traditional media and became the main carrier of information production, storage, dissemination, sharing, and use. However, digital information can be easily copied, modified, and disseminated, {{which leads to the}} problem of network video copyright theft which is very prominent. Aiming at the copyright problem of sports video, this paper proposes an idea of using LOGO to identify the copyright of sports video, which can automatically and effectively detect whether the video is genuine or not. Firstly, encrypted LOGO is added to the video by encryption technology, and then, LOGO recognition technology is used to distinguish whether the LOGO is missing in the video, so as to distinguish the legitimacy of the video. In addition, aiming at the shortcomings of traditional LOGO recognition technology, this paper proposes a LOGO detection and recognition technology based on <b>convolution</b> <b>neural</b> <b>network.</b> This method improves the traditional histogram algorithm, proposes an analysis algorithm based on non-uniform block HSV histogram, and introduces region weighting coefficients to extract key frames from the video. Then, the <b>convolution</b> <b>neural</b> <b>network</b> is used to extract the features of the key frames of the video. Finally, the features of the sample LOGO are matched to complete the LOGO detection and recognition. Simulation results show that the effect of feature extraction using <b>convolution</b> <b>neural</b> <b>network</b> is better. Compared with the traditional LOGO recognition technology, the LOGO detection and recognition technology based on <b>convolution</b> <b>neural</b> <b>network</b> proposed in this paper has better detection and recognition performance. It effectively detects the LOGO information in the video and realizes the recognition of whether the video is genuine or not.|$|E
30|$|In the future, {{we believe}} that {{investigating}} more sophisticated techniques for improving the accuracy, including the deep <b>convolution</b> <b>neural</b> <b>network</b> [38], will be beneficial. Moreover, since it is time-consuming for fitting parameters of model, we propose the share feature method between object detection using CNNs {{in order to further}} improve the efficiency of model training.|$|E
40|$|In this paper, {{we propose}} a generic and simple {{algorithmic}} framework for first order optimization. The framework essentially contains two consecutive steps in each iteration: 1) computing and normalizing the mini-batch stochastic gradient; 2) selecting adaptive step size {{to update the}} decision variable (parameter) towards the negative of the normalized gradient. We show that the proposed approach, when customized to the popular adaptive stepsize methods, such as AdaGrad, can enjoy a sublinear convergence rate, if the objective is convex. We also conduct extensive empirical studies on various non-convex <b>neural</b> <b>network</b> optimization problems, including multi layer perceptron, <b>convolution</b> <b>neural</b> <b>networks</b> and recurrent <b>neural</b> <b>networks.</b> The results indicate the normalized gradient with adaptive step size can help accelerate the training of <b>neural</b> <b>networks.</b> In particular, significant speedup can be observed if the networks are deep or the dependencies are long...|$|R
40|$|Dense and low {{dimensional}} word embeddings {{opened up}} the possibility to analyze text polarity with highly successful deep learning techniques like <b>Convolution</b> <b>Neural</b> <b>Networks.</b> In this paper we utilize pretrained word vectors in combination with simple <b>neural</b> <b>networks</b> of stacked <b>convolution</b> and max-pooling layers, to explore the role of dataset size and document length in sentiment polarity prediction. We experiment with song lyrics and reviews of products or movies and see that convolution-pooling combination is very fast and yet quiet effective. We also find interesting relations between dataset size, text length and length of feature maps with classification accuracy. Our next goal is {{the design of a}} generic neural architecture for analyzing polarity of various text types, with high accuracy and few hyper-parameter changes...|$|R
40|$|Recently, {{inspired}} {{by the power of}} deep learning, <b>convolution</b> <b>neural</b> <b>networks</b> can produce fantastic images at the pixel level. However, a significant limiting factor for previous approaches is that they focus on some simple datasets such as faces and bedrooms. In this paper, we propose a multiscale deep <b>neural</b> <b>network</b> to transform sketches into Chinese paintings. To synthesize more realistic imagery, we train the generative network by using both L 1 loss and adversarial loss. Additionally, users can control the process of the synthesis since the generative network is feed-forward. This network can also be treated as neural style transfer by adding an edge detector. Furthermore, additional experiments on image colorization and image super-resolution demonstrate the universality of our proposed approach...|$|R
40|$|Abstract. In this paper, {{we propose}} a fast <b>convolution</b> <b>neural</b> <b>network</b> {{architecture}} to solve image document recognition problem, {{and this is}} a difficult problem because of ambient lighting conditions, and the images are usually noisy, broken or incomplete. We applied to license plate recognition and also analyzed the results of this mapping process and the number of different features. ...|$|E
40|$|Object {{recognition}} {{is a process}} of identifying a specific object in an image or video sequence. This task is still a challenge for computer vision systems. Many different approaches of object recognition including the traditional classifier or deep neural network were proposed. The objective of this thesis is to implement a deep <b>convolution</b> <b>neural</b> <b>network</b> for object classification. Different architecture and different parameters have been tested in order to improve the classification accuracy. This thesis propose a very simple deep learning network for object classification which comprises only the basic data processing. In the proposed architecture, deep <b>convolution</b> <b>neural</b> <b>network</b> has a total of five hidden layers. After every convolution, there is a subsampling layer which consists of a 2 × 2 kernel to do average pooling. This can help to reduce the training time and compute complexity of the network. For comparison and better understanding, this work also showed how to fine tune the hyper-parameters of the network in order to obtain a higher degree of classification accuracy. This work achieved a good performance on Cifar- 10 dataset where the accuracy is 76. 19 %. In challenging image databases such as Pascal and ImageNet, this network might not be sufficient to handle the variability. However, deep <b>convolution</b> <b>neural</b> <b>network</b> can be a valuable baseline for studying advanced deep learning architectures for large-scale image classification tasks. This network can be further improved by adding some validation data and dropout to prevent overfittin...|$|E
40|$|As a mainly {{network of}} Internet naval activities, the {{deceptive}} opinion spam {{is of great}} harm. The identification of deceptive opinion spam is of great importance because of the rapid and dramatic development of Internet. The effective distinguish between positive and deceptive opinion {{plays an important role}} in maintaining and improving the Internet environment. Deceptive opinion spam is very short, varied type and content. In order to effectively identify deceptive opinion, expect for the textual semantics and emotional polarity that have been widely used in text analysis, we need to further summarize the deep features of deceptive opinion in order to characterize deceptive opinion effectively. In this paper, we use the traditional <b>convolution</b> <b>neural</b> <b>network</b> and improve it from the point of the word order by using the method called word order-preserving k-max pooling, which makes <b>convolution</b> <b>neural</b> <b>network</b> more suitable for text classification. The experiment can get better deceptive opinion spam detection...|$|E
40|$|We {{present a}} method for {{explaining}} the image classification predictions of deep <b>convolution</b> <b>neural</b> <b>networks,</b> by highlighting the pixels in the image which influence the final class prediction. Our method requires the identification of a heuristic method to select parameters hypothesized to be most relevant in this prediction, and here we use Kullback-Leibler divergence to provide this focus. Overall, our approach helps in understanding and interpreting deep network predictions and we hope contributes to a foundation for such understanding of deep learning networks. In this brief paper, our experiments evaluate the performance of two popular networks in this context of interpretability. Comment: Presented at NIPS 2017 Symposium on Interpretable Machine Learnin...|$|R
40|$|This master thesis {{describes}} {{the design and}} development of the system for detection and recognition of whole coat of arms as well as each heraldic parts. In the thesis are presented methods of computer vision for segmentation and detection of an object and selected methods that are the most suitable. Most of the heraldic parts are segmented using a <b>convolution</b> <b>neural</b> <b>networks</b> and the rest using active contours. The Histogram of the gradient method was selected for coats of arms detection in an image. For training and functionality verification is used my own data set. The resulting system can serve as an auxiliary tool used in auxiliary sciences of history...|$|R
30|$|This paper {{exploits}} four {{machine learning}} classifiers for sentiment analysis using three manually annotated datasets. The mean of 29 epochs of experimentation recorded in Table  4 shows that OneR is more precise {{in terms of}} percentage of correctly classified instances. On the other hand, Naïve Bayes exhibits faster learning rate and J 48 reveals adequacy in the true positive and false positive rates. Table  5 reveals the truth that J 48 and OneR are better for smaller dataset of woodland’s wallet reviews. The preprocessing of proposed methodology is limited to extract foreign words, emoticons and elongated words with their appropriate sentiments. The future work in the task of sentiment analysis has scope to improve preprocessing with word embeddings using deep <b>neural</b> <b>networks</b> and can also extend this study through <b>convolution</b> <b>neural</b> <b>networks.</b>|$|R
