22|35|Public
50|$|For example, {{when the}} <b>clock</b> <b>interrupt</b> is generated, the <b>clock</b> <b>interrupt</b> handler {{generally}} increments the counter {{of the current}} thread to calculate the total execution time of that thread, and decrements its quantum time remaining by 1. When the counter drops to zero, the thread scheduler has to be invoked to choose the next thread to be executed on that processor and dispatcher to perform a context switch. Since the <b>clock</b> <b>interrupt</b> occurs {{at a much higher}} IRQL, it will be desirable to perform this thread dispatching which is a less critical task at a later time when the processor's IRQL drops. So the <b>clock</b> <b>interrupt</b> handler requests a DPC object and adds it {{to the end of the}} DPC queue which will process the dispatching when the processor's IRQL drops to DPC/Dispatch level.|$|E
5000|$|... level 24 {{is for the}} <b>clock</b> <b>interrupt.</b> Note this is {{a higher}} {{priority}} than I/O interrupts.|$|E
5000|$|An Interprocessor bus - {{used for}} {{distribution}} of system-wide <b>clock,</b> <b>interrupt</b> and process control messaging among the CMs ...|$|E
5000|$|Time-sharing - {{switches}} tasks on {{a regular}} <b>clocked</b> <b>interrupt,</b> and on events; called round robin.|$|R
40|$|The {{afterburner}} ATM link Adapter {{has allowed}} us to evaluate three event-signaling schemes: polling, traditional <b>interrupts</b> and the <b>clocked</b> <b>interrupts</b> first investigated in our operating system work in AURORA. The schemes are evaluated {{in the context of}} a single-copy TCP/IP stack. The experimental results indicate that <b>clocked</b> <b>interrupts</b> can provide throughput comparable with traditional interrupts for dedicated machines (up to over 144 Mbps, the highest TCP/IP/ATM throughput reported), and better performance when the machines are loaded with an artificial workload. Polling, implemented to be used with an unmodified netperf measurement tool, was competitive for small TCP/IP socket buffer sizes (¡ 32 KB). We concluded that <b>clocked</b> <b>interrupts</b> may be preferable for applications requiring high throughput on systems with heavy processin...|$|R
40|$|Operating Systems Support for End-to-End Gbps Networking This paper {{argues that}} {{workstation}} host interfaces and operating systems are a crucial element in achieving end-to-end Gbps bandwidths for applications in distributed environments. We describe several host interface architectures, discuss {{the interaction between}} the interface and host operating system, and report on an ATM host interface built at the University of Pennsylvania. Concurrently designing a host interface and software support allows careful balancing of hardware and software functions. Key ideas include use of buffer management techniques to reduce copying and scheduling data transfers using <b>clocked</b> <b>interrupts.</b> <b>Clocked</b> <b>interrupts</b> also aid with bandwidth allocation. Our interface can deliver a sustained 130 Mbps bandwidth to applications, roughly OC- 3 c link speed. Ninety-three percent of the host hardware subsystem throughput i...|$|R
50|$|In this mode, {{the device}} {{acts as a}} divide-by-n counter, which is {{commonly}} used to generate a real-time <b>clock</b> <b>interrupt.</b>|$|E
50|$|In computing, a jiffy was {{originally}} {{the time between}} two ticks of the system timer interrupt. It is not an absolute time interval unit, since its duration depends on the <b>clock</b> <b>interrupt</b> frequency of the particular hardware platform.|$|E
5000|$|OTHER: This {{policy is}} defined by POSIX1003.4a as implementation-defined. In AIX Version 4, this policy is defined to be {{equivalent}} to RR, except that it applies to threads with non-fixed priority. The recalculation of the running thread's priority value at each <b>clock</b> <b>interrupt</b> means that a thread may lose control because its priority value has risen above that of another dispatchable thread. This is the AIX Version 3 behavior.|$|E
40|$|This paper {{argues that}} {{workstation}} host interfaces and operating systems are a crucial element in achieving end-to-end Gbps bandwidths for applications in distributed environments. We describe several host interface architectures, discuss {{the interaction between}} the interface and host operating system, and report on an ATM host interface built at the University of Pennsylvania. Concurrently designing a host interface and software support allows careful balancing of hardware and software functions. Key ideas include use of buffer management techniques to reduce copying and scheduling data transfers using <b>clocked</b> <b>interrupts.</b> <b>Clocked</b> <b>interrupts</b> also aid with bandwidth allocation. Our interface can deliver a sustained 130 Mbps bandwidth to applications, roughly OC- 3 c link speed. Ninety-three percent of the host hardware subsystem throughput is delivered to the application with a small measured impact on other applications processing. 1...|$|R
2500|$|A {{real-time}} {{operating system}} is an operating system that guarantees to process events or data by a specific moment in time. A real-time operating {{system may be}} single- or multi-tasking, but when multitasking, it uses specialized scheduling algorithms so that a deterministic nature of behavior is achieved. An event-driven system switches between tasks based on their priorities or external events while time-sharing operating systems switch tasks based on <b>clock</b> <b>interrupts</b> ...|$|R
50|$|A {{real-time}} {{operating system}} (RTOS) is an operating system (OS) intended to serve real-time applications that process data {{as it comes}} in, typically without buffer delays. Processing time requirements (including any OS delay) are measured in tenths of seconds or shorter increments of time.They either are event driven or time sharing. Event driven systems switch between tasks based on their priorities while time sharing systems switch the task based on <b>clock</b> <b>interrupts.</b>|$|R
5000|$|In {{addition}} to the aforementioned alarm <b>clock</b> <b>interrupt</b> bug, many CIAs exhibited a defect in which the part would fail to generate a timer B hardware interrupt if the interrupt control register (ICR) was read one or two clock cycles before {{the time when the}} interrupt should have actually occurred. This defect, as well as logic errors in the Commodore provided (8 bit [...] ) operating system, caused frequent pseudo-RS-232 errors in the Commodore 64 and Commodore 128 computers when running at higher baud rates.|$|E
50|$|It had {{somewhat}} better video display possibilities {{than the average}} CGA card (8 colors at 640x200 resolution, vs CGA's 4 colors at 320x200 or 2 colors at 640x200), {{but it was not}} completely compatible with the IBM-PC. It lacked a standard BIOS, having only a minimal bootloader in ROM that accessed hardware directly to load a RAM-based BIOS. The (FM rather than MFM) diskette format used was not completely compatible with the IBM PC, but special software on an original PC or PC/XT (but not PC/AT) could read and write the diskettes, and software expecting a standard 18.2 Hz <b>clock</b> <b>interrupt</b> had to be rewritten.|$|E
5000|$|CTSS used a {{modified}} IBM 7094 mainframe computer that had two 32,768 (32K) 36-bit-word banks of core memory {{instead of the}} normal one. [...] One bank was reserved for the time-sharing supervisory program, the other for user programs. CTSS had a protected-mode kernel, the supervisor's functions in the A-core (memory bank A) could only be called by software interrupts, like in the modern operating systems. Causing memory-protection interrupts were used for software interrupts. Processor allocation scheduling with a quantum time unit 200 ms, was controlled by a multilevel feedback queue. It also had some special memory-management hardware, a <b>clock</b> <b>interrupt</b> {{and the ability to}} trap certain instructions.|$|E
5000|$|Basic {{resource}} virtualization: <b>clock</b> and timers, <b>interrupts,</b> memory, CPU {{and special}} devices.|$|R
50|$|The 80186 {{series was}} {{generally}} intended for embedded systems, as microcontrollers with external memory. Therefore, {{to reduce the}} number of integrated circuits required, it included features such as <b>clock</b> generator, <b>interrupt</b> controller, timers, wait state generator, DMA channels, and external chip select lines.|$|R
5000|$|Sensitive {{register}} instructions: read {{or change}} sensitive registers or memory locations {{such as a}} <b>clock</b> register or <b>interrupt</b> registers: ...|$|R
5000|$|The {{preemptive}} scheduler has a <b>clock</b> <b>interrupt</b> {{task that}} can provide the scheduler with options to switch after the task has had a given period to execute—the time slice. This scheduling system {{has the advantage of}} making sure no task hogs the processor for any time longer than the time slice. However, this scheduling scheme is vulnerable to process or thread [...] lockout: since priority is given to higher-priority tasks, the lower-priority tasks could wait an indefinite amount of time. One common method of arbitrating this situation is aging, which gradually increments the priority of waiting processes and threads, ensuring that they will all eventually execute. Most Real-time operating systems (RTOSs) have preemptive schedulers. Also turning off time slicing effectively gives you the non-preemptive RTOS.|$|E
5000|$|The {{short-term}} scheduler (also {{known as}} the CPU scheduler) decides which of the ready, in-memory processes is to be executed (allocated a CPU) after a <b>clock</b> <b>interrupt,</b> an I/O interrupt, an operating system call or another form of signal. Thus the short-term scheduler makes scheduling decisions much more frequently than the long-term or mid-term schedulersa scheduling decision will at a minimum {{have to be made}} after every time slice, and these are very short. This scheduler can be preemptive, implying that it is capable of forcibly removing processes from a CPU when it decides to allocate that CPU to another process, or non-preemptive (also known as [...] "voluntary" [...] or [...] "co-operative"), in which case the scheduler is unable to [...] "force" [...] processes off the CPU.|$|E
40|$|Abstract. This paper {{discusses}} {{the problem of}} program execution time measurement. Program execution time measurement is problematic because the conventional measurement method, based on the real-time <b>clock</b> <b>interrupt</b> counting, is prone to inherent errors. These errors are caused by discrete nature of real-time clock interrupts and by the overhead of <b>clock</b> <b>interrupt</b> processing. Ways of reducing relative magnitude of these errors are described. The program execution time measurement and error estimation are illustrated by the measurement of real-time kernel operations’ execution time on the Intel 80386 EX micro-controller...|$|E
50|$|The PBI is {{implemented}} as a rectangular 50-pin edge connector {{on the back}} of XL machines. The pins include all 16 address lines (A0 through A15) and 8 data lines (D0 through D7). Other pins include various electrical supplies, <b>clock</b> signals, <b>interrupts,</b> memory strobes, and even an analog audio input.|$|R
40|$|The Afterburner ATM Link Adapter {{has allowed}} us to {{evaluate}} three event-signaling schemes: polling, traditional <b>interrupts</b> and the <b>clocked</b> <b>interrupts</b> first investigated in our operating system work in AURORA. The schemes are evaluated {{in the context of}} a single-copy TCP/IP stack, and experimental results reported. 1 Introduction 1. 1 Background This research is one of a series of results from an exploration of Asynchronous Transfer Mode (ATM) computer/network host interface architectures at the University of Pennsylvania, begun in 1990 [Traw 93 a], as part of the ATM/SONET infrastructure of the AURORA Gigabit Testbed [Clark 93]. The initial research goal of the interface work was to identify and experimentally verify a kernel of services that were suitable for hardware implementation. These data movement and formatting intensive services include ATM Adaptation Layer (AAL) processing, segmentation-andreassembly (SAR) and ATM demultiplexing. The architecture partitioned the protocol [...] ...|$|R
40|$|This paper {{presents}} a method based on formal specifications for building robust real-time microkernels. Temporal logic {{is used to}} specih the functional and temporal properties of real-time kernels {{with respect to their}} main services (e. g., scheduling, time, synchronization, and <b>clock</b> <b>interrupts).</b> As an example of a synchronization mechanism, the specification of the Priority Ceiling Protocol is provided The objective is to veri & kernel properties at runtime in order to improve the internal kernel’s detection mechanisms and complement their weaknesses. The core of this paper is a complete description of the temporal logic formulas corresponding to real-time kernel specifications. The formulas developed in this paper are the basis for the implementation of fault containment wrappers. The combination of COTS microkernels and wrappers leak to the notion of robust microkernels. The provided case study illustrates the approach on top of an instance of the Chorus microkernel. ...|$|R
40|$|CPU clock speeds grow at an {{exponential}} rate, {{and already}} surpass 2 GHz. At {{the same time}} operating system <b>clock</b> <b>interrupt</b> rates remain at a typical 100 Hz, with scheduling quanta of 50 - 200 ms. As operating systems measure time in these clock ticks, this leads to loss of resolution. One consequence of this situation is that the operating system scheduler can no longer differentiate between processes that do not use too much CPU, because they all use less than a single tick. Another consequence is that the system unnecessarily gives up the opportunity to support applications that require relatively fine-grain real-time support, because the latencies involved are by necessity multiples of a clock tick. The solution is therefore to increase the <b>clock</b> <b>interrupt</b> rate substantially, and reduce the scheduling quantum length. We analyze the overheads and benefits involved in this, and show that a general-purpose system {{can go a long}} way towards providing soft real-time support, at the cost of only modest overheads...|$|E
40|$|It is {{commonly}} agreed that scheduling mechanisms in general purpose operating systems {{do not provide}} adequate support for modern interactive applications, notably multimedia applications. The common {{solution to this problem}} is to devise specialized scheduling mechanisms that take the speci c needs of such applications into account. A much simpler alternative is to better tune existing systems. In particular, we show that conventional scheduling algorithms typically only have little and possibly misleading information regarding the CPU usage of processes, because increasing CPU rates have caused the common 100 Hz <b>clock</b> <b>interrupt</b> rate to be coarser than most application time quanta. We therefore conduct an experimental analysis of what happens if this rate is signi cantly increased. Results indicate that much higher <b>clock</b> <b>interrupt</b> rates are possible with acceptable overheads, and lead to much better information. In addition we show that increasing the clock rate can provide a measure of support for soft real-time requirements, even when using a general-purpose operating system. For example, we achieve a sub-millisecond latency under heavily loaded conditions...|$|E
40|$|Modern {{processors}} used in {{embedded systems}} {{are becoming increasingly}} powerful, having features like caches and pipelines to speedup execution. While execution speed of embedded software is generally increasing, it {{becomes more and more}} complex to verify the correct temporal behavior of software, running on this high-end embedded computer systems. To achieve time-predictability the authors introduced a very rigid software execution model with distribution being realized based on the time-triggered communication model. In this paper we analyze the timepredictability of a preempting task-activation, running on a hardware with direct-mapped instruction caches. As one result we analyze why a task-preemption driven by a <b>clock</b> <b>interrupt</b> is not suitable to guarantee timepredictability. As a second result, we present a timepredictable task-preemption driven by an instruction counter. ...|$|E
50|$|The 80188 {{series was}} {{generally}} intended for embedded systems, as microcontrollers with external memory. Therefore, {{to reduce the}} number of chips required, it included features such as <b>clock</b> generator, <b>interrupt</b> controller, timers, wait state generator, DMA channels, and external chip select lines.While the N80188 was compatible with the 8087 numerics co-processor, the 80C188 was not. It didn't have the ESC control codes integrated.|$|R
6000|$|... "Staying at {{the farm}} to look after your interests. We expect {{him to come back}} to-day. Ah, Herbert, what do we not all owe to that dear good brother of yours? There is really no end to his kindness. The last of our poor Highland {{families}} who have emigrated to America have had their expenses privately paid by Randal. The wife has written to me, and has let out the secret. There is an American newspaper, among the letters that are waiting your brother's return, sent to him as a little mark of attention by these good grateful people." [...] Having alluded to the neighbors who had left Scotland, Mrs. Linley was reminded of other neighbors who had remained. She was still relating events of local interest, when the <b>clock</b> <b>interrupted</b> her by striking the hour of the nursery dinner. What had become of Kitty? Mrs. Linley rose and rang the bell to make inquiries.|$|R
40|$|As {{parallel}} jobs {{get bigger}} {{in size and}} finer in granularity, “system noise ” is increasingly becoming a problem. In fact, fine-grained jobs on clusters with thousands of SMP nodes run faster if a processor is intentionally left idle (per node), thus enabling a separation of “system noise ” from the com-putation. Paying a cost in average processing speed at a node {{for the sake of}} eliminating occasional processes delays is (unfortunately) beneficial, as such delays are enormously magnified when one late process holds up thousands of peers with which it synchronizes. We provide a probabilistic argument showing that, under certain conditions, the effect of such noise is linearly pro-portional {{to the size of the}} cluster (as is often empirically observed). We then identify a major source of noise to be indirect overhead of periodic OS <b>clock</b> <b>interrupts</b> (“ticks”), that are used by all general-purpose OSs as a means of main-taining control. This is shown for various grain sizes, plat-forms, tick frequencies, and OSs. To eliminate such noise, we suggest replacing ticks with an alternative mechanism we call “smart timers”. This turns out to also be in line with needs of desktop and mobile computing, increasing the chances of the suggested change to be accepted. 1...|$|R
40|$|The VERTEX {{message passing}} system {{provided}} with NCUBE hypercubes is unsafe. The system can fail under high message loads. We have implemented a message passing {{system with the}} same “look and feel” as VERTEX but which is instead based upon the crystal_router running at <b>clock</b> <b>interrupt</b> time. The system is written mostly in C with a few bits of assembly code to run the DMA devices. This implies that safety checks (are the buffers full?) and complex error handling mechanisms can be easily implemented at the C level. A first version works, is safe, and is faster than VERTEX in the high volume limit, slower in the low volume case. At the very least, this system will be interesting for high message traffic applications, such as disk backup...|$|E
40|$|With decades development, RTLinux/GPL was {{widespread}} applied to both scientific research realm and industry. RTLinux/GPL {{has made a}} grate success in these realm, But has little affection in education, especially the undergraduate education. Most of the RTLinux/GPL documentation are focus on the practicability, other than emphasizing the basic RealTime Operatiing System theory. So RTLinux/GPL {{is very hard to}} applied to education realm. This article aimed at RTOS education, containing real time principle of RTLinux/GPL and the RTLinux/GPL modules implementation in detail. It would make the realtime operating system learning process easier with both theory and real source code analyze, and would attract more people to interested in RTLinux/GPL. This article presented RTLinux/GPL principle and implementation details, containning realtime <b>clock,</b> <b>interrupt,</b> realtime schedule strategy. We hope this article can help people to apprehend RTOS, especially the RTLinux/GPL. ...|$|E
40|$|An {{important}} {{barrier to}} the use of profile-based optimization is the generation of high-quality profile data. In this paper we describe our experience with a prototype system for continuous and automatic generation of profile data. Our system collects profile data continuously for all computation on a system by sampling the program counter once per hardware <b>clock</b> <b>interrupt.</b> We have found that the overhead of our prototype monitor is negligible, making it practical to collect profile information continuously for all activity on the system. We used several qualitative and quantitative methods to explore how the quality of these sampled profiles improves over time, and demonstrate that profiles of adequate quality for optimization can be obtained after a small number of monitored runs. For a selection of instruction-cache intensive benchmarks, statistical monitoring provides profiles of a quality comparable to that of complete profiles obtained with program instrumentation while avoiding [...] ...|$|E
5000|$|An {{important}} aspect of the Pluribus software was the [...] "STAGE" [...] system, which detected system errors and took steps to recover from them. The processor <b>clocks</b> had <b>interrupt</b> handlers which implemented watchdog timers on all processors. If a processor stopped running, another processor would detect it and initiate a recovery. The recovery process would unlock any locks placed on shared resources, release allocated storage, and restart all processing on all processors. This was acceptable on an ARPANET routing node, since any lost packets would eventually be retransmitted.|$|R
40|$|Abstract. As network {{transmission}} speeds increase, packet streams increasingly uncover fine {{details of}} the interior behavior of router hardware and software. This behavior reveals itself {{as a set of}} harmonic effects, as interior <b>clocks</b> periodically <b>interrupt</b> packet forwarding, and interior queues periodically empty and fill. We examine this behavior with a Linux-based router employing a variety of gigabit Ethernet interfaces, with a view toward two goals: the creation of harmonic models of router forwarding performance which are accurate and yet mathematically simple and fast; and the analysis of the potential for an undesirable succession of positively reinforcing router “reverberations. ”...|$|R
40|$|Hardware {{interrupt}} {{management method}} based on field {{programmable gate array}} is proposed in this study according to the requirement of embedded real-time operating system for real-time performance and the structure model of interrupt management module is also given. Interrupt is subdivided into system and user interrupts owing to different characteristics of interrupt request and response method. Interrupt source management, interrupt vector management, <b>interrupt</b> nesting and <b>clock</b> tick <b>interrupt</b> management have all been implemented by hardware. The simulation results show the feasibility and stability of this kind of interrupt management method. In a word, the implementation of interrupt management by hardware improves not only the utilization rate of CPU, but also the real-time performance of the whole system...|$|R
