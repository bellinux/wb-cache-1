1572|186|Public
5|$|During Oblivions development, Bethesda {{concentrated}} on creating {{a system with}} a more realistic storyline, believable characters, and meaningful quests than had {{been done in the}} past. In comparison with previous titles in the series, the game features improved artificial intelligence thanks to the use of Bethesda proprietary Radiant A.I. software, and enhanced physics facilitated by the Havok physics engine. The graphics take advantage of advanced lighting and shader routines such as high dynamic range rendering (HDR) and specular mapping. Bethesda developed and implemented procedural <b>content</b> <b>creation</b> tools in the building of Oblivions terrain, leading to the expedited creation of landscapes that are more complex and realistic than in past titles.|$|E
5|$|Developers {{working on}} Oblivion focused on {{providing}} a tighter storyline, with fewer filler quests and more developed characters. The developers {{sought to make}} information in the game world more accessible to players, making the game easier {{to pick up and}} play. Oblivion features improved AI (courtesy of Bethesda's proprietary Radiant AI), improved physics (courtesy of the Havok physics engine), and impressive graphics, taking advantage of advanced lighting and shader routines like high dynamic range rendering (HDR) and specular mapping. Bethesda developed and implemented procedural <b>content</b> <b>creation</b> tools in the creation of Oblivions terrain, leading to landscapes that are more complex and realistic than those of past titles, with less of a drain on Bethesda's staff.|$|E
5|$|In 2012, Booker and tech {{executives}} Sarah Ross and Nathan Richardson formed Waywire, {{a company}} focused on video sharing technology. Early investors included Oprah Winfrey, Eric Schmidt, Jeff Weiner, and Troy Carter. After Booker's relationship to Waywire was discussed in a front-page New York Times story, board member Andrew Zucker {{stepped down from}} his position. Shortly thereafter, Waywire CEO Nathan Richardson departed the business as the company shifted its focus from <b>content</b> <b>creation</b> to content curation. In August 2013, Booker told NBC News he intended to resign from the Waywire board and put his holdings in a trust if elected to the Senate; by September, he had resigned his place {{on the board and}} donated his share of the company to charity. Waywire was sold to another video curation business the following month.|$|E
5000|$|Storyhelper (2010-): Developed Korea's first {{storytelling}} SW {{that supports}} writers <b>contents</b> <b>creation</b> {{in collaboration with}} Digital Storytelling Laboratory of Ewha Womans University.|$|R
40|$|The recent {{developments}} of internet applications are showing new paradigms of interactions among users and between users and available contents. In sev-eral social {{applications such as}} Twitter, Wikipedia or Facebook the paradigm of <b>contents</b> <b>creation</b> and filtering follows a bottom up process in which content...|$|R
5000|$|... bianca.com, informally {{known as}} Bianca's Smut Shack, was an online {{community}} created on February 14, 1994, {{by a group}} of Chicago, later moved to San Francisco, dot-com software developers, including David Thau and Chris Miller. bianca was one of the web's first 500 <b>content</b> <b>creations</b> and was the world's first web-based chat room. [...] It later also became a popular theme camp at Burning Man.|$|R
25|$|The {{popularity}} of Web 2.0 was acknowledged by 2006 TIME magazine Person of The Year (You). That is, TIME selected {{the masses of}} users who were participating in <b>content</b> <b>creation</b> on social networks, blogs, wikis, and media sharing sites.|$|E
25|$|Founded in June 2009, the University of Waterloo Stratford Campus {{is part of}} the Faculty of Arts, {{established}} to provide programs that focus on digital media, digital technologies, <b>content</b> <b>creation</b> and user experience. September 2010 marked the official opening of the Stratford campus.|$|E
25|$|Andreyev's art is {{concerned}} with issues surrounding new media, social media, technology and human/nonhuman relationships. The Animal Lover projects are often produced in collaboration with companion dogs Tom and Sugi where respect, fun and challenge are employed in the process. The dogs participate directly in the research and <b>content</b> <b>creation</b> of the work by suggesting ideas for projects and by determining the material for production. Also, aleatoric and improvisational methods are used that provide for a chance, open-ended expectation, surprise and learning.|$|E
50|$|After {{graduating from}} Waseda University, {{he became a}} {{photographer}} and a director of television programs. In 2007 he attended the <b>Contents</b> <b>Creation</b> Science Program at the University of Tokyo. There he directed his first film entitled Blue Symphony. The film is about Jacques Mayol, the famous diver, who often visited Karatsu before his suicide. The documentary shows his relationship with nature. Blue Symphony had its world premiere at the 2008 Tokyo International Film Festival.|$|R
40|$|This paper {{shows the}} {{evolution}} of the first internet search engines, indexes and service providers towards their conversion into portals. Thesecan be grouped into three classifications: general, vertical, and corporate. Some distinguishing characteristics of portals are analyzed as well as the reasons behind their existence in internet. Also discussed are the main elements which favour their success, including: generation of <b>contents,</b> <b>creation</b> of virtual communities, promotion of user loyalty and development of e-commerce...|$|R
40|$|Abstract—One of new {{applications}} {{on a new}} generation network (NwGN) is a contents centric network (CCN). The target of CCN is contents based networking. We enhanced a concept of CCN to machine-to-machine communications, streaming communications, and <b>contents</b> <b>creation</b> services within the network. This is called an enhanced-type data-centric network (E 3 -DCN). To develop E 3 -DCN, orchestration between packet switching and circuit switching is important. This paper provides an E 3 -DCN concept and architecture to realize energy efficient optical networking. Keywords-component; enegy effcient; data-centric; network virtualization I...|$|R
25|$|Virtual goods include buildings, vehicles, {{devices of}} all kinds, animations, clothing, skin, hair, jewelry, flora and fauna, and works of art. Services include {{business}} management, entertainment, and custom <b>content</b> <b>creation</b> (which {{can be broken}} up into the following six categories: building, texturing, scripting, animating, art direction, and the position of producer/project funder). L$ can be purchased using US dollars and other local currencies on the LindeX exchange provided by Linden Lab. Customer USD wallets obtained from Linden Dollar sales on the Lindex are most commonly used to pay Second Lifes own subscription and tier fees; only {{a relatively small number}} of users earn enough profit to request a refund to PayPal. According to figures published by Linden Lab, about 64,000 users made a profit in Second Life in February 2009, of whom 38,524 made less than US$10, while 233 made more than US$5000. Profits are derived from selling virtual goods, renting land, and a broad range of services.|$|E
500|$|A trailer {{released}} March 3, 2010, showcased the game's multiplayer. Bungie revealed {{parts of}} the game's campaign and Firefight at E3 2010. The game reached the [...] "zero bug release" [...] milestone on June 23, signifying a shift from <b>content</b> <b>creation</b> to troubleshooting; buggy artificial intelligence or other elements would be removed rather than fixed at this point because of time constraints. Bungie released the complete list of achievements for the game on July 30, including their titles, symbols, and requirements, and completed Reach [...] {{between the end of}} July and beginning of August 2010.|$|E
500|$|Microsoft {{announced}} the fourth stable build of Windows 10 on October 26, 2016. Officially branded as the [...] or version 1703, and codenamed [...] "Redstone 2" [...] (RS2), {{it was released}} on April 11, 2017 for general availability, and on April 5, 2017 for manual installation via Windows 10 Upgrade Assistant and Media Creation Tool tools. This update primarily focuses on <b>content</b> <b>creation,</b> productivity, and gaming features—with a particular focus on {{virtual and augmented reality}} (including HoloLens and virtual reality headsets) and on aiding the generation of three-dimensional content.|$|E
40|$|This work {{is devoted}} to {{analyzing}} the syntax contents of an animation. In the paper we present the ANIMATION system - a system for animation scene and <b>contents</b> <b>creation,</b> retrieval and display. The object recognition mechanism in the ANIMATION system includes three steps: (1) Low level animation images analysis - element recognition based on the Attribute Relational Graphs (ARG); (2) Object recognition, based on production rules with degree of recognition; (3) Image interpretation, based on the Dempster-Shafer theory of evidence. An example of {{the functioning of the}} ANIMATION system is also given...|$|R
5000|$|<b>Content</b> {{management}} - <b>creation,</b> storage, {{access to}} and use of learning resources ...|$|R
50|$|LEIA Inc has {{developed}} a Unity 3D plug-in to facilitate the conversion of existing 3D or VR <b>content</b> or <b>creation</b> of new <b>content</b> for its holographic platform. A WebGL API is also available {{as an extension of}} Three.js.|$|R
500|$|The {{game was}} first {{conceived}} as a prototype to Gravity Bone, and was scrapped because it was [...] "too dialogue heavy." [...] However, Chung revived the idea after being contacted by Idle Thumbs to develop a game for their Kickstarter campaign. The main development phase, in which <b>content</b> <b>creation</b> took place, was finished within three months. Several more months were spent polishing the game and fixing software bugs. Chung brought multiple existing assets from Gravity Bone to develop Thirty Flights of Loving, and used a diverse set of tools to create {{the elements of the}} game. Blender was picked for the creation of models, while Audacity and Adobe Photoshop were used for audio and texture work. Another tool, GtkRadiant, was used to create the game's levels.|$|E
500|$|Yankovic {{announced}} {{that there would}} be no pre-album single for Mandatory Fun, and instead he would let the listeners decide which songs are the hits. He also revealed that he would participate in a Reddit [...] "Ask Me Anything" [...] session on the day of the album release. Yankovic explained that the pre-release campaign deliberately withheld song information, since he felt it has become more difficult to establish a unique take on a parody in the age of YouTube <b>content</b> <b>creation.</b> He later made an appearance on the Hulu sitcom The Hotwives of Orlando that coincided with the Mandatory Fun launch. After the album was released, he elaborated that putting out singles was technically unnecessary, since customers can buy the songs individually from digital vendors.|$|E
500|$|During its lifetime, Rise of Mana entered {{multiple}} collaborations {{with other}} games both for mobiles and other platforms: these included Final Fantasy Agito, Bravely Default, , Final Fantasy Adventure and Diffusion Million Arthur. In January 2016, {{it was announced}} that Rise of Mana would cease operation on all platforms on March 31. In the release, Square Enix said that a developing imbalance between content quality and revenue, in addition to problems with future <b>content</b> <b>creation,</b> had convinced them that Rise of Mana was no longer a profitable concern. Despite it ending service as a free-to-play title, the company is looking into alternative ways of distributing the title. [...] A final story episode was released prior to the game's closure, and its final cinematic was released online through Square Enix Japan's YouTube channel on March 28.|$|E
5000|$|In [...] Soulcalibur V Klonoa {{appears as}} a keychain as Downloadable <b>Content</b> for Character <b>Creation.</b>|$|R
40|$|Abstract. This paper {{presents}} {{an approach to}} the automatic generation and use of web-based learning materials (WLMs). It consists in three phases: <b>contents</b> <b>creation,</b> division and browsing. The use of XML in the creation phase allows achieving independence between contents and their presentation, in addition to contents reuse. The splitting phase is an automatic process whose output {{can be used as}} WLMs for different user interfaces. In the browsing phase, the interfaces are generated; we have implemented two: a user-adaptative interface and a non-adaptative one. The main features of our approach enables users to create learning contents without XML technical knowledge and also enables to effectively navigate the material to their needs...|$|R
40|$|Due to {{improvements}} in imaging technologies and {{the ease of}} digital <b>contents</b> <b>creation</b> and manipulation, today there is a pressing need for the copyright protection of digital contents. It is also essential to have techniques for authentication of the content {{as well as the}} owner. This paper examines the suitability of color channel to be used for hiding a monochromatic watermark in a 24 bit colored BMP image. This paper uses the scheme which is based on comparison of middle band DCT coefficients exchange scheme [13]-[14]. This paper also proposes a way to improve the robustness against JPEG attack. Experimental results show that proposed scheme is very robust against JPEG compression along various kinds of image processing attacks. 1...|$|R
500|$|Observing that {{face-to-face}} communication {{of the type}} that online videos convey has been [...] "fine-tuned by {{millions of years of}} evolution", TED curator Chris Anderson referred to several YouTube contributors and asserted that [...] "what Gutenberg did for writing, online video can now do for {{face-to-face communication}}". Anderson asserted that it's not far-fetched to say that online video will dramatically accelerate scientific advance, and that video contributors may be about to launch [...] "the biggest learning cycle in human history." [...] In education, for example, the Khan Academy grew from YouTube video tutoring sessions for founder Salman Khan's cousin into what Forbes Michael Noer called [...] "the largest school in the world", with technology poised to disrupt how people learn. YouTube was awarded a 2008 George Foster Peabody Award, the website being described as a Speakers' Corner that [...] "both embodies and promotes democracy." [...] The Washington Post reported that a disproportionate share of YouTube's most subscribed channels feature minorities, contrasting with mainstream television in which the stars are largely white. A Pew Research Center study reported the development of [...] "visual journalism", in which citizen eyewitnesses and established news organizations share in <b>content</b> <b>creation.</b> The study also concluded that YouTube was becoming an important platform by which people acquire news.|$|E
500|$|Twitterbots {{are capable}} of {{influencing}} public opinion about culture, products and political agendas by automatically generating mass amounts of tweets through imitating human communication. The New York Times states, [...] "They have sleep-wake cycles so their fakery is more convincing, making them less prone to repetitive patterns that flag them as mere programs." [...] The tweets generated vary anywhere from a simple automated response to <b>content</b> <b>creation</b> and information sharing, all of which depends on {{the intention of the}} person purchasing or creating the bot. The social implications these Twitterbots potentially have on human perception are sizeable according to a study published by the ScienceDirect Journal. Looking at the Computers as Social Actors (CASA) paradigm, the journal notes, [...] "people exhibit remarkable social reactions to computers and other media, treating {{them as if they were}} real people or real places." [...] The study concluded that Twitterbots were viewed as credible and competent in communication and interaction making them suitable for transmitting information in the social media sphere. While the technological advances have enabled the ability of successful Human-Computer Interaction, the implications are questioned due to the appearance of both benign and malicious bots in the Twitter realm. Benign Twitterbots may generate creative content and relevant product updates whereas malicious bots can make unpopular people seem popular, push irrelevant products on users and spread misinformation, spam and/or slander.|$|E
500|$|They {{waited to}} license a game engine until after preproduction, expecting the {{benefits}} of licensing to be more time for the content and gameplay. They chose the Unreal engine as it did 80% of what they needed from an engine and was more economical than building from scratch. Their small programming team allowed for a larger design group. The programmers also found the engine accommodating, though it took about nine months to acclimate to the software. Spector estimated that {{six to nine months}} of playing with the engine were necessary {{to learn how to use}} it properly, and even still, their ideas did not always implement as planned. Spector thought it would have been much harder to have written the interfaces, skill systems, and conversations on their own. Despite the savings, the time Spector thought they would save not writing an engine was lost learning the engine, though they did have more time to work on <b>content</b> <b>creation</b> and gameplay systems. Spector also felt that they would have understood the code better had they built it themselves, instead of [...] "treating the engine as a black box" [...] and coding conservatively. He acknowledged that this precipitated into the Direct3D issues in their final release, which slipped through their quality assurance testing. Spector also noted that the artificial intelligence, pathfinding, and sound propagation were designed for shooters and should have been rewritten from scratch instead of relying on the engine. He thought the licensed engine worked well enough that he expected to use the same for [...] and Thief 3. He added that developers should not attempt to force their technology to perform in ways it was not intended, and should find a balance between perfection and pragmatism.|$|E
5000|$|Mapping the {{semantics}} of user {{with that}} of content {{for the purpose of}} <b>content</b> retrieval, management, <b>creation,</b> etc.|$|R
40|$|There is an {{increasing}} interest in the computer animation. The most of the current animation software tools are described by Richard Parent in [5]. The driving ideas behind animation in general and computer animation in particular are presented in [6]. More and more animations are available in various places on the Internet. The increasing availability of potentially interesting materials makes the search extremely difficult especially when the search is by the animation contents. This work is devoted to analyzing the syntax contents of the animations. In the paper we present the ANIMATION system a system for animation scene and <b>contents</b> <b>creation,</b> retrieval and display. The system is based on MPEG- 4 standard [3, 4]. MPEG- 4 is an ISO/IEC standard developed by MPEG (Moving Picture Experts Group). These standard makes interactive video on CD-ROM and Digital Television possible...|$|R
50|$|He {{leads the}} Information and Language Processing {{group at the}} University of Amsterdam, the Intelligent Systems Lab Amsterdam and the Center for <b>Creation,</b> <b>Content</b> and Technology.|$|R
500|$|Titan Quest was {{the brainchild}} of game {{designer}} Brian Sullivan: while he was working on Age of Empires, which sported a Grecian setting, he came up with the concept of creating a similar game while including the region's mythology. The concept work for Titan Quest began in 2000, when its developer Iron Lore Entertainment was formed by Sullivan and Paul Chieffo. The two brought together a skeleton team to create a demo with which to find a publisher. During this time, the game was described by producer Jeff Goodsill as being [...] "on the drawing board". The creative leads on the project were Sullivan, Chieffo, programmer Max McGuire, and artists Rich Sullivan and Josh McHugh. According to Sullivan, the pre-production process lasted over a year. Iron Lore's January 2004 pitch to THQ was successful, and development began once they had secured a contract in 2004. The initial staff up to that time was just nine people working in a small office area: when production started and further staff were hired, the team size grew to 38, which included temporary and late development additions. Sullivan was involved in multiple areas of the development, but his main responsibility was game design and overseeing <b>content</b> <b>creation.</b> Titan Quest was aimed at both casual and hardcore gamers, as the necessary prices for games necessitated reaching out to a wide audience to get a profit. For this reason, the team chose the action role-playing genre. Developing the game was made more difficult by the necessity to create Iron Lore around it, recruiting and training new staff. Other studios were also involved with development. Towards the end of development, Demiurge Studios was brought in to help with the final stages during the alpha-beta-ship stages. Demiurge first helped with memory optimization; then worked on the level editor and modification functions so they worked as an independent function; and finally created installers for both the demo and the main game. Demiurge's involvement gave Iron Lore more time and energy to devote to fixing bugs and polishing gameplay. The CGI opening cinematic was created by Blur Studio.|$|E
500|$|The game used a specially-developed {{proprietary}} engine {{developed by}} Iron Lore staff. This was done as, when development started, no third-party engines existed that could support the team's {{vision for the}} game: in Sullivan's words, there were [...] "plenty of technology solutions for someone creating a shooter, {{but not as much}} for a role-playing game". One of the key parts of the new engine was an environmental creation tool dubbed [...] "the editor" [...] by staff. This tool combined a tile-based horizontal plain with a height-based map, and allowed for subtle adjustments to environments and terrain with easy-to-use developer tools. Level and plain boundaries were set using cliffs and plateaus within the environment. Objects such as chest and enemies could be then [...] "dropped" [...] into environments using a point-and-click system, some of which could be directly integrated using special [...] "tile" [...] elements which stitched into the wider environment for objects such as bridges and crags. All of this necessitated a large amount of research on multiple subjects, including the flora of Egypt and the appearance of Ancient Greek roads and paths. This development tool was the version released with the retail version so players could create and share their own levels. Level and map creation was handled by a three-person team, with each one needing to agree upon a specific layout and design before it went into full production. While early builds used a high amount of detail along level boundaries, the team switched to simple boundary designs as they [...] "read better" [...] for players and allowed better technical performance. The challenge the <b>content</b> <b>creation</b> team set themselves was creating these areas while making boundaries seem natural. This combination of height and grid-based navigation and environments had not been done when the system was being designed in 2002: most of the map was shaped using the height map, while specialist features and horizontal navigation used the grid. In a preview about the game, the developers said the game was built around [...] "database driven modular proxies", a system where different elements within environments were seamlessly interacted and could interact freely. The artificial intelligence (AI) was designed so individual units would behave differently depending on situation and combat ability. The pathfinding for AI units such as NPCs and enemy units was handled using the PathEngine, a licensed middleware engine dedicated to this task. Titan Quest {{was one of the first}} major Western titles to use PathEngine.|$|E
2500|$|It was {{originally}} intended that players {{would be able}} to use the <b>content</b> <b>creation</b> mode with other players online however this feature was dropped before the game's release. [...] Online Create [...] was added to the game via software update 1.21 [...]|$|E
40|$|International audienceWe {{present a}} new method for blind {{document}} bleed through removal based on separate Markov Random Field (MRF) regularization for the recto {{and for the}} verso side, where separate priors are derived from the full graph. The segmentation algorithm is based on Bayesian Maximum a Posteriori (MAP) estimation. The advantages of this separate approach are the adaptation of the prior to the <b>contents</b> <b>creation</b> process (e. g. superimposing two hand written pages), and {{the improvement of the}} estimation of the recto pixels through an estimation of the verso pixels covered by recto pixels; Moreover, the formulation as a binary labeling problem with two hidden labels per pixels naturally leads to an efficient optimization method based on the minimum cut/maximum flow in a graph. The proposed method is evaluated on scanned document images from the 18 $^{th}$ century, showing an improvement of character recognition results compared to other restoration methods...|$|R
5000|$|Collections {{of works}} (e.g. anthologies) and other {{collections}} of data which, {{by reason of}} the selection or arrangement of the <b>contents,</b> constitute intellectual <b>creations</b> are also protected (art. 12) ...|$|R
50|$|The National Magazine Awards Foundation (NMAF) is a bilingual, not-for-profit {{institution}} {{whose mission}} is to recognize excellence in the <b>content</b> and <b>creation</b> of Canadian magazines through an annual program of awards. The National Magazine Awards gala takes place each June in Toronto. Each year the NMAF relies on over 100 volunteer judges to evaluate the entries and award gold and silver winners in the written, visual, integrated and special categories.|$|R
