509|120|Public
5|$|The {{project has}} pioneered {{the use of}} {{graphics}} processing units (GPUs), PlayStation3s, Message Passing Interface (used for computing on multi-core processors), and some Sony Xperia smartphones for distributed computing and scientific research. The project uses statistical simulation methodology that is a paradigm shift from traditional computing methods. As part of the <b>client–server</b> <b>model</b> network architecture, the volunteered machines each receive pieces of a simulation (work units), complete them, and return them to the project's database servers, where the units are compiled into an overall simulation. Volunteers can track their contributions on the Folding@home website, which makes volunteers' participation competitive and encourages long-term involvement.|$|E
25|$|The Domain Name System is {{maintained}} by a distributed database system, which uses the <b>client–server</b> <b>model.</b> The nodes of this database are the name servers. Each domain {{has at least}} one authoritative DNS server that publishes information about that domain and the name servers of any domains subordinate to it. The top of the hierarchy is served by the root name servers, the servers to query when looking up (resolving) a TLD.|$|E
25|$|The {{protocol}} {{is usually}} {{described in terms}} of a <b>client-server</b> <b>model,</b> but can as easily be used in peer-to-peer relationships where both peers consider the other to be a potential time source. Implementations send and receive timestamps using the User Datagram Protocol (UDP) on port number 123. They can also use broadcasting or multicasting, where clients passively listen to time updates after an initial round-trip calibrating exchange. NTP supplies a warning of any impending leap second adjustment, but no information about local time zones or daylight saving time is transmitted.|$|E
5000|$|The {{designers}} of distributed applications must {{determine the best}} placement of the application's programs and data {{in terms of the}} quantity and frequency of data to be transmitted, along with data management, security, and timeliness considerations. There are three <b>client-server</b> <b>models</b> for the design of distributed applications: ...|$|R
40|$|Abstract. We {{describe}} Community Grids {{built around}} Integration of technologies from the peer-to-peer and Grid fields. We {{focus on the}} implications of Web Service ideas built around powerful event services using uniform XML interfaces. We go through collaborative systems in detail showing how one can build an environment that can use either P 2 P approaches like JXTA or more conventional <b>client-server</b> <b>models.</b> 1...|$|R
40|$|Simulation is {{used for}} many purposes: for example, to analyse a complex system, to visualise the {{functioning}} of a system, and to optimise or tune a system. While there is no limitation {{on the use of}} simulation, the general consensus is that an analytical solution, if one is possible, is always to be preferred to simulation as a methodology. In the field of information systems, <b>client-server</b> <b>models</b> exhibit a degree of complexity and richness not amenable to easy analytical solutions, except for some specific algorithms useful in limited contexts. Simulation could, therefore, be a good strategy to analyse the client-server systems and help in better implementation of feasible solutions. This paper examines the current state of <b>client-server</b> <b>models</b> and use of simulation in dealing with the problems encountered. The paper then compares the seven-layer OSI model for communications architecture and recommends that a similarly layered approach is likely to prove useful in simulating client-server systems. In the process, the paper also points out that the simulation models bring into a sharp focus the importance of software metrics, an area of vital importance in software development 1...|$|R
25|$|The {{application}} layer is the scope within which applications create user data and communicate this data to other applications on another {{or the same}} host. The applications, or processes, {{make use of the}} services provided by the underlying, lower layers, especially the Transport Layer which provides reliable or unreliable pipes to other processes. The communications partners are characterized by the application architecture, such as the <b>client-server</b> <b>model</b> and peer-to-peer networking. This is the layer in which all higher level protocols, such as SMTP, FTP, SSH, HTTP, operate. Processes are addressed via ports which essentially represent services.|$|E
2500|$|In December 2009, {{the project}} {{evolved into a}} {{commercial}} software business owned and developed by a single for-profit startup company, Plex, Inc., a U.S.-based high tech firm {{that is responsible for}} the development of the Plex Media Server and media player app front- and back-ends, its <b>client–server</b> <b>model,</b> all accompanying software under the Plex brand name, as well as the exclusive, copyrighted, proprietary parts, whether distributed on its own or as a third-party software component in products manufactured via a strategic partnership. [...] Elan Feingold, Scott Olechowsi and Cayce Ullman were the three founders, with Ullman and Feingold taking on full-time roles as the CEO and CTO, respectively.|$|E
2500|$|The {{application}} {{was designed to}} allow non-technical users to understand system and network status information through a simple interface and presentation, using a matrix to display status information for overhead displays in Network Operations Centers (NOCs). [...] It was designed to monitor computer systems and networks, {{and for this reason}} does not use SNMP natively, instead using a <b>client–server</b> <b>model</b> and its own network communications protocol. [...] Clients send status information over port TCP port 1984 every 5 minutes. [...] Since the clients only send information to a specific monitoring server, its creators claim it is more secure than SNMP-based protocols which poll clients for information. [...] For this reason, Big Brother was featured at SANS Institute security conferences in 1998. 1999, and at a SANSFIRE conference in 2001.|$|E
50|$|Later, in the 1970s, packet-based {{computer}} networking technology {{began to}} mature. Between 1973 and 1975, Xerox PARC developed Local Area Networks based on Ethernet. Additionally, the Wide Area Network ARPANET further developed from its 1969 roots, {{lead to the}} creation of the Internet on January 1, 1983. These LANs and WANS allowed for network games, where the game created and received network packets; Systems located across LANs or the Internet could run games with each other in peer-to-peer or <b>client-server</b> <b>models.</b>|$|R
5000|$|... metadata-driven {{components}} {{which can}} bind to metadata formats such as XML schema, allowing a shared <b>client-server</b> data <b>model</b> with extensible types, validation rules and editing constraints ...|$|R
5000|$|The {{relationship}} between SCSI devices {{is described by}} a <b>client-server</b> service-delivery <b>model.</b> The client is called a SCSI initiator and the server is called a SCSI target.|$|R
2500|$|Diablo II was {{released}} in 2000 to much fanfare. The main highlight of Diablo II {{as it relates to}} Battle.net was that the game used the <b>client–server</b> <b>model.</b> The game was no longer simulated on each player's computer, but instead was run on Blizzard's server. This also meant that all of the character data for the game was stored on the Battle.net servers. The game also has an open character feature on Battle.net which stored the player's character on the client. This allowed players to play characters locally or on a LAN, and then use those same characters on Battle.net. However, any open games played on Battle.net were not protected from cheating by other players since they could have modified their characters locally. Diablo II also had a unique feature that would show the players in the Battle.net chat room as avatars who looked like their characters did in the game. It also used a different Battle.net interface than previous games, where previously there were mainly only color differences. [...] There was also expanded ladder support including a [...] "Hardcore" [...] ladder which listed players whose characters would be removed permanently if they died in-game. Again, with Diablo II usage of Battle.net increased steadily, climbing even higher with the release of the expansion pack [...] in 2001.|$|E
5000|$|<b>Client-server</b> <b>model</b> of {{distributed}} computing using three-tier architecture ...|$|E
5000|$|... #Subtitle level 2: <b>Client-server</b> <b>model</b> {{and network}} {{transparency}} ...|$|E
40|$|Abstract—Since early days, {{peer-to-peer}} (P 2 P) protocols {{have proven}} significant improvements over traditional <b>client-server</b> <b>models.</b> On the other hand, the Session Initiation Protocol (SIP) {{is a popular}} protocol for establishing multimedia sessions, and uses a client-server approach. P 2 PSIP is an architecture for deploying SIP services over a P 2 P network overlay, and thus leverages the limitations of client-server architectures for SIP. In this work, we present a novel scheme for a secured and distributed P 2 PSIP model. Our architecture allows a ad-hoc deployment, with a scalable design for a completely distributed security infrastructure...|$|R
50|$|If the {{application}} architecture has no explicit {{distinction between the}} business layer and the presentation layer (i.e., the presentation layer is {{considered part of the}} business layer), then a traditional <b>client-server</b> (two-tier) <b>model</b> has been implemented.|$|R
50|$|Hybrid {{models are}} a {{combination}} of peer-to-peer and <b>client-server</b> <b>models.</b> A common hybrid model {{is to have a}} central server that helps peers find each other. Spotify {{is an example of a}} hybrid model. There are a variety of hybrid models, all of which make trade-offs between the centralized functionality provided by a structured server/client network and the node equality afforded by the pure peer-to-peer unstructured networks. Currently, hybrid models have better performance than either pure unstructured networks or pure structured networks because certain functions, such as searching, do require a centralized functionality but benefit from the decentralized aggregation of nodes provided by unstructured networks.|$|R
5000|$|General {{understanding}} of distributed computing architectures, e.g. <b>Client-server</b> <b>model</b> ...|$|E
50|$|SAP Business One is {{a typical}} <b>Client-server</b> <b>model</b> {{software}} product.|$|E
50|$|In the <b>client-server</b> <b>model,</b> {{downstream}} {{can refer}} to the direction from the server to the client.|$|E
40|$|<b>Client-server</b> <b>models</b> enable {{computations}} to be hosted remotely on quantum servers. We {{present a}} novel protocol for realizing this task, with practical advantages when using technology feasible {{in the near}} term. Client tasks are realized as linear combinations of operations implemented by the server, where the linear coefficients are hidden from the server. We report on an experimental demonstration of our protocol using linear optics, which realizes linear combination of two single-qubit operations by a remote single-qubit control. In addition, we explain when our protocol can remain efficient for larger computations, {{as well as some}} ways in which privacy can be maintained using our protocol. Comment: 26 pages, 9 figure...|$|R
50|$|The {{software}} {{is composed of}} an executive binary which uses a <b>client-server</b> communication <b>model</b> between libraries and service engines. Loadable modules, called service engines, are loaded into the Corosync Cluster Engine and use the services provided by the Corosync Service Engine internal API.|$|R
40|$|The {{combination}} of agent technology and mobility is viewed increasingly {{as an alternative}} to <b>client-server</b> <b>models.</b> This approach suffers from a lack of robustness, especially on the server side. In this paper we propose a decentralised approach. Static agents, mobile agents and Object Request Broker (ORB) mechanism are combined into a cooperation framework. Mobile agents possess some autonomy that enables them to observe situations locally and to filter data on site. The ORB mechanism is incorporated in order to provide a robust framework to support interoperability and to optimise processes by reducing unnecessary communication. Within the framework, control is distributed between agents and ORB through a dual mode of observation. This approach has the advantage that it enhances fault-tolerance, flexibility and the integration of heterogeneous systems...|$|R
50|$|In {{addition}} to the <b>client-server</b> <b>model,</b> distributed computing applications often use the peer-to-peer (P2P) application architecture.|$|E
5000|$|... #Caption: A {{network based}} on the <b>client-server</b> <b>model,</b> where {{individual}} clients request services and resources from centralized servers ...|$|E
50|$|A {{database}} server {{is a computer}} program that provides database services to other computer programs or to computers, {{as defined by the}} <b>client-server</b> <b>model.</b> The term may also refer to a computer dedicated to running such a program. Database management systems frequently provide database-server functionality, and some database management systems (DBMSs) (such as MySQL) rely exclusively on the <b>client-server</b> <b>model</b> for database access (while others e.g. SQLite are meant for using as an embedded database).|$|E
40|$|This project {{presents}} {{the design and}} development of a prototype for controlling the illumination and security of a smart home {{through the use of}} a <b>client–server</b> network <b>model.</b> For this we developed an application in Visual Basic for the client–server communication using TCP/IP network protocol. Key words...|$|R
50|$|Simraceway Is {{an online}} racing {{simulation}} that hosted live, multiplayer racing events. The race environment {{was developed by}} Ignite Game Technologies, Inc. The service used a <b>client-server</b> software <b>model</b> similar to popular online games such as World of Warcraft allowing the racing environment to be continually updated.|$|R
40|$|Autonomous {{agents are}} mobile {{applications}} that are launched on data warehouses to perform specific queries or {{to search for}} patterns in data. With mobile agent technology, a developer is not bound by more traditional distributed computing models, for example, two-tier <b>client-server</b> <b>models,</b> three-tier middleware-oriented models, and so on. The Mobile Agent technology facilitates flexible code distribution, i. e., factoring functionality and communications using the most appropriate strategies for the task at hand. Moreover, this functionality can move to the most appropriate network host, as needed, on demand. In this paper, we investigate the suitability of mobile agent technology for distributed computing applications. Our discussion and observations are based on two practical case studies i. e. distributed sorting and searching using IBM-ASDK (Aglet Software Development Kit) framework for employing mobile agents...|$|R
5000|$|In the <b>client-server</b> <b>model,</b> {{the server}} is {{responsible}} for information security and enforcing game rules. (See [...] "Anti-cheating methods and limitations" [...] below for drawbacks.) In the peer-to-peer gaming model, clients run equal code but are still subject {{to most of the}} same type of cheats found in the client-server multiplayer model; however, the peer-to-peer multiplayer model has deprecated in favor of the <b>client-server</b> <b>model</b> with the wider adoption of high-speed networks.|$|E
5000|$|Uses the WebSocket {{networking}} protocol, if available, for <b>Client-server</b> <b>model</b> of communication, with fallbacks to Ajax or plain {{web page}} rendering ...|$|E
5000|$|... #Caption: Stacheldraht botnet diagram {{showing a}} DDoS attack. (Note {{this is also}} {{an example of a}} type of <b>client-server</b> <b>model</b> of a botnet.) ...|$|E
40|$|There are two {{emerging}} {{trends in}} distributed computing. The first trend is evolving because programming high performance client-server applications is a challenge. Client-server architectures must be designed {{from the ground}} up for good performance. Increasingly, we are seeing <b>client-server</b> <b>models</b> evolving away from traditional client-server structures into new structures such as three-tier systems and distributed object systems. Consequently, as the typical architecture used for distributed systems evolves to increase performance, we must also recognize that the complexity of developing software for cost-effective distributed systems increases as we distribute functionality. Error handling must be more robust and messaging more efficient as we move away from centralized server models. As the pressure to decentralize for better performance rises, the increasing number of decentralized servers increases management/administrative complexity. The second converging trend associated with [...] ...|$|R
25|$|By {{the early}} 1980s users began seeing Unix as a {{potential}} universal operating system, suitable for computers of all sizes. The Unix environment and the <b>client–server</b> program <b>model</b> were essential elements {{in the development of}} the Internet and the reshaping of computing as centered in networks rather than in individual computers.|$|R
40|$|The {{implications}} of random methodologies {{have been far}} far-reaching reaching and pervasive [28]. Given {{the current status of}} <b>client-server</b> server <b>models,</b> experts clearly desire the synthesis of lambda calculus. In order to answer this question, we discover how cache coherence [31] {{can be applied to the}} development of consistent hashing...|$|R
