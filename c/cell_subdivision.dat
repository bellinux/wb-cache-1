16|46|Public
40|$|A new {{progressive}} lossless 3 D triangular mesh encoder {{is proposed}} in this work, which can encode any 3 D triangular mesh with an arbitrary topological structure. Given a mesh, the quantized 3 D vertices are first partitioned into an octree (OT) structure, {{which is then}} traversed from the root and gradually to the leaves. During the traversal, each 3 D cell in the tree front is subdivided into eight childcells. For each <b>cell</b> <b>subdivision,</b> both local geometry and connectivity changes are encoded, where the connectivity coding is guided by the geometry coding. Furthermore, prioritized <b>cell</b> <b>subdivision</b> is performed in the tree front to provide better rate-distortion (R-D) performance. Experiments show that the proposed mesh coder outperforms the kd-tree algorithm in both geometry and connectivity coding efficiency. For the geometry coding part, the range of improvement is typically around 10 %∼ 20 %, but may go up to 50 %∼ 60 % for meshes with highly regular geometry data and/or tight clustering of vertices...|$|E
40|$|Two {{overlapping}} vesica shapes {{are apparent}} in the building composition—one creating the building enclosure, the other forming an enclosing fence to a garden space adjacent the building. This overlapping of two vesica shapes is metaphorically representative of the metaphase of <b>cell</b> <b>subdivision</b> where two cells emerge from one. The second vesica shape begins within {{the heart of the}} building enclosure and emerges to create an enclosing wall to the first of the surrounding ‘garden’ spaces...|$|E
40|$|In this paper, we {{will discuss}} {{subjects}} related to virtual multipliers in the cone-ratio model in DEA. Usually, there exists ambiguity in the virtual multipliers in the polyhedral cone-ratio method when some exemplary efficient DMUs 2 ̆ 7 multipliers are employed as the admissible directions of the cone. Firstly, we will show a <b>cell</b> <b>subdivision</b> of the multiplier simplex. Then, three practical methods for resolving this ambiguity will be presented with an example. Revised version of "An Observation on the Cone-Ratio Model in Data Envelopment Analysis"(94 -B- 7) [URL]...|$|E
40|$|Currently,many global {{subdivision}} {{models and}} spatial data don't match seriously in their storage structure. The extended model based on mapping division(EMD) {{is designed to}} effectively implement management,organization and use of huge spatial data. This model made the hierarchical subdivision by longitude and latitude interval,based on traditional mapping division way to achieve the objectives of direct storage and index for exis-ting spatial data. After the characteristics of these global subdivision models have been analyzed,the hierarchical structure of <b>subdivision</b> <b>cell</b> is introduced. Based on this structure,the multi-resolution address coding of <b>subdivision</b> <b>cell</b> is designed taking advantage of Hilbert curve and its address coding space is established. Theoretical research and experiment indicated that this subdivision model can represent and manage global multi-resolution spatial data more effectively...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references: p. 59 - 61. An adaptive mesh method for the simulation of parallel ics. Blade Vortex Interaction (BV 1) with an active Trailing Edge Flap (TEF) is presented. The two-dimensional 1111 -steady problem is solved by a higher order upwind Euler method for an unstructured mesh. A local mesh adaptation technique is employed to maintain vortex strength by capturing the details of the convecting vortex. The computational technique does not require any assumption on the vortex structure, and, therefore is suitable for close interaction of the vortex and the blade. The adaptive method is based on <b>cell</b> <b>subdivisions</b> and allows for frequent mesh adaptation due to its fast speed. To demonstrate the reduction of numerical dissipation of a vortex via mesh adaptation, we first consider a simple case with a convecting vortex in freestream. Finally, we apply tile techniques to examine the effectiveness of an active TEF on BVI in reducing the pressure perturbations at the airfoil leading edge. For the boundary motion due to TEF deployment, a local recessing procedure is utilized to maintain mesh quality by avoiding distorted mesh elements near the flap...|$|R
40|$|FIGURE 3. Shell and SEM details. A – D. Monilearia loweana; A. from Valle Chico; B – D. from Mirador de Malpaso; C. Some {{bristles}} {{of third}} whorl rectangular “ cells ”; D. “ <b>cell</b> ” <b>subdivisions</b> {{and a line}} of bristles between second and third whorls; E – F, Monilearia multipunctata; E. from Barranco de Gran Valle; F. from Rosa de Zapata; G – H, Monilearia tubaeformis sp. nov. G. Holotype, from Lomo del Aceituno; H. Paratype, from Vega de Río Palmas, detail of shell ventrallateral side. Scale bar (2 mm) applies to A, E, F, G...|$|R
40|$|The {{generation}} of a hybrid grid system for discretizing complex three dimensional (3 D) geometries is described. The primary grid system is an unstructured Cartesian grid automatically generated using recursive <b>cell</b> <b>subdivision.</b> This grid system {{is sufficient for}} computing Euler solutions about extremely complex 3 D geometries. A secondary grid system, using triangular-prismatic elements, may be added for resolving the boundary layer region of viscous flows near surfaces of solid bodies. This paper describes the grid generation processes used to generate each grid type. Several example grids are shown, demonstrating {{the ability of the}} method to discretize complex geometries, with very little pre-processing required by the user...|$|E
40|$|A {{parallel}} tetrahedral mesh adaptation code is {{expanded to}} treat general, mixed-element unstructured meshes comprised of {{any combination of}} basic element types. Emphasis is placed on developing conforming mesh modification methods that are solver-independent. Specific developments include {{the implementation of a}} treatment for viscous, high aspect ratio near wall tetrahedra, and <b>cell</b> <b>subdivision</b> methods for prismatic, hexahedral, and pyramid cells. Rebalancing of the adapted grid, and particularly issues associated with processor assignment of parent/child cell sets, is addressed. Validations are performed for decomposed, mixed-element meshes using cell-vertex and cell-centered unstructured solvers. The resulting parallel adaptation package is a powerful, versatile tool for obtaining gridconverged, steady state results, and may readily be applied to other unstructured flow solvers. I...|$|E
40|$|In this paper, we {{will discuss}} {{subjects}} related to virtual multipliers in the cone-ratio model in DEA. Usually, there exists ambiguity in the virtual multipliers in the polyhedral cone-ratio method when some exemplary efficient DMUs 2 ̆ 7 multipliers are employed as the admissible directions of the cone. Firstly, we will show a <b>cell</b> <b>subdivision</b> of the multiplier simplex. Then, three practical methods for resolving this ambiguity will be presented with an example. Finally, {{we will discuss}} possible applications of vertex enumeration software, based on the Double Description Method. Presented at First International Conference of the Society on Computational Economics on "Computing in Economics and Finance" May 21 - 24, 1995 Austin, Texa...|$|E
50|$|Thus, {{we want to}} {{describe}} all the <b>cells</b> of the <b>subdivision,</b> plus all the incidence and adjacency relations between these cells. When all the represented cells are simplexes, a simplicial complex can be used, but when we want to represent any type of cells, we need to use cellular topological models like combinatorial maps or generalized maps.|$|R
40|$|The {{number of}} polygons {{comprising}} interesting architectural models is {{many more than}} can be rendered at interactive frame rates. However, due to occlusion by opaque surfaces (e. g., walls), {{only a small fraction}} of a typical model is visible from most viewpoints. We describe a method of visibility preprocessing that is efficient and effective for axis-aligned or axial architectural models. A model is subdivided into rectangular cells whose boundaries coincide with major opaque surfaces. Non-opaque portals are identified on cell boundaries, and used to form an adjacency graph connecting the <b>cells</b> of the <b>subdivision.</b> Next, the cell-to-cell visibility is computed for each <b>cell</b> of the <b>subdivision,</b> by linking pairs of cells between which unobstructed sightlines exist. During an interactive walkthrough phase, an observer with a known position and view cone moves through the model. At each frame, the cell containing the observer is identified, and the contents of potentially visible cells are [...] ...|$|R
40|$|An {{agglutination}} typing scheme {{has been}} developed for strains of Aeromonas hydrophila. Primary agglutination typing is based on testing agar-grown A. hydrophila cells with human, horse, rat, and guinea pig erythrocytes and Saccharomyces cerevisiae <b>cells.</b> Further <b>subdivision</b> of primary groups is based firstly on whether yeast cell agglutination is inhibited by a D-mannose polymer, yeast mannan, and secondly on patterns of inhibition of hemagglutination by yeast mannan and the monomeric sugars L-fucose, D-galactose, and D-mannose. A total of 320 isolates were tested, and these were divisible into 39 distinct types {{on the basis of}} this scheme. Application of this typing scheme in the future to isolates of A. hydrophila known to be associated with human infection may enable correlations to be made between particular agglutination types and human pathogenicity...|$|R
40|$|We {{introduce}} Bézier projection as an element-based local projection {{methodology for}} B-splines, NURBS, and T-splines. This new approach {{relies on the}} concept of Bézier extraction and an associated operation introduced here, spline reconstruction, enabling the use of Bézier projection in standard finite element codes. Bézier projection exhibits provably optimal convergence and yields projections that are virtually indistinguishable from global L^ 2 projection. Bézier projection is used to develop a unified framework for spline operations including <b>cell</b> <b>subdivision</b> and merging, degree elevation and reduction, basis roughening and smoothing, and spline reparameterization. In fact, Bézier projection provides a quadrature-free approach to refinement and coarsening of splines. In this sense, Bézier projection provides the fundamental building block for hpkr-adaptivity in isogeometric analysis. Comment: 56 pages, 28 figure...|$|E
40|$|Among {{progressive}} 3 D mesh compression algorithms, the kd-tree-based algorithm {{proposed by}} Gandoin and Devillers [1] {{is one of}} the state-of-the-art algorithms. Based on the observation that this geometry coder has a large amount of overhead at high kd-tree levels, we propose an octree-based geometry coder that demands a less amount of coding bits at high octree levels by applying selective <b>cell</b> <b>subdivision</b> at high tree levels, leading to a better rate-distortion performance for the low bit rate coding. Experimental results show that, compared with the kd-tree-based coder, the proposed 3 D geometry coder performs better for an expanded tree of a level {{less than or equal to}} 8 but slightly worse for the full tree expansion with 12 -bit quantization...|$|E
40|$|This paper {{outlines}} {{the development and}} application of a solution-adaptive local grid refinement procedure for numerical fluid dynamic calculations in complex domains involving body-fitted unstructured meshes. A new space discretization practice and an error estimation technique were developed to facilitate adaptive space discretization (h-refinement) using cells of arbitrary topology. The methodology enables implicit, consistent, and uniform treatment throughout the entire computational domain including the interface between refined regions {{and the rest of}} the computational mesh. It is demonstrated on a number of test cases involving both laminar and turbulent flows, in which initially regular hexahedral meshes are refined by <b>cell</b> <b>subdivision.</b> Encouraging results are obtained. � 1997 Academic Press Key Words: finite volume; polyhedral discretization elements; error detection; local grid refinement...|$|E
50|$|Current Biology is a {{scientific}} journal that covers {{all areas of}} biology, especially molecular biology, cell biology, genetics, neurobiology, ecology and evolutionary biology. The journal is published twice a month and includes peer-reviewed research articles, various types of review articles, {{as well as an}} editorial magazine section. Current Biology was founded in 1991 by the Current Science group, acquired by Elsevier in 1998 and has since 2001 been part of <b>Cell</b> Press, a <b>subdivision</b> of Elsevier.|$|R
40|$|Abstract Given a planar {{polygonal}} subdivision S, point location involves preprocessing this subdivisioninto a {{data structure}} so that given any query point q, the <b>cell</b> of the <b>subdivision</b> containing qcan be determined efficiently. Suppose that for each cell z in the subdivision, the probability pz that a query point lies within this cell is also given. The {{goal is to}} design the data structureto minimize the average search time. This problem has been considered before, but existin...|$|R
5000|$|Most of {{the cells}} in {{orientation}} columns are complex cells. Complex cells will respond to a properly orientated line in any location of the receptive field, whereas simple cells have a narrower receptive field where a properly oriented line will excite it. Simple <b>cells</b> have distinct <b>subdivisions</b> of excitatory and inhibitory regions. It is proposed that complex cells receive input from many simple cells, which explains why the complex cells have a slightly wider receptive field.|$|R
40|$|This paper {{presents}} a thorough {{discussion of the}} potential of a new cell-subdivision approach to plan translations of a convex polygon in a cluttered environment, where {{the focus is on}} planning simple motions {{on the basis of a}} fine-grained description of the workspace. A free path is planned in two main stages. The first stage exploits a plane-sweep paradigm in order to build a <b>cell</b> <b>subdivision</b> holding much relevant topological information on the free space and organizing a set of polygonal chains that approximate the boundaries of the configuration space obstacles. Then, the computations in the second stage are driven by an A* scheme designed to search the <b>cell</b> <b>subdivision.</b> During the search the bounding chains are subject to further refinements, but the cell graph is no longer modified. Among the remarkable features of the proposed technique we can mention: simple interface with the geometric modeler, based on two collision-detection primitives; small number of cells and adjacencies; incremental characterization of the free space. A few numerical results suggest that the new technique should be worth considering for applications, where appropriate; in particular, it seems to perform better than other approaches based on quadtrees. Moreover, it is quite interesting to observe that the cost of finding collision-free paths grows with the number of convex obstacles, whereas it is almost independent of the overall number of sides: we can interpret this result as supporting the choice of representing the obstacles decomposed into convex components. A succinct comparison between algorithmic and human intuitive path planning is also discussed in order to appraise the rate of redundant information processed by the algorithm, but we can also see that human planners behave significantly better only when the solutions are easy to find...|$|E
40|$|We {{propose a}} generic point cloud encoder that {{compresses}} geometry data including positions and normals of point samples corresponding to 3 D objects with arbitrary topology. In this work, the coding process {{is led by}} an iterative octree <b>cell</b> <b>subdivision</b> of the object space. At each level of subdivision, positions of point samples are approximated by the geometry centers of all tree-front cells while normals are approximated by their statistical average {{within each of the}} tree-front cells. With this framework, we employ attribute-dependent encoding techniques to exploit different characteristics of various attributes. As a result, significant improvement in the rate-distortion (R-D) performance has been obtained with respect to the prior art. Furthermore, the proposed point cloud encoder can be potentially used for lossless geometry coding of 3 D point clouds, given sufficient levels of octree expansion and normal space partitioning...|$|E
40|$|Abstract — In this paper, {{we propose}} a generic point cloud encoder that {{provides}} a unified framework for compressing different attributes of point samples corresponding to 3 D objects with arbitrary topology. In the proposed scheme, the coding process is led by an iterative octree <b>cell</b> <b>subdivision</b> of the object space. At each level of subdivision, positions of point samples are approximated by the geometry centers of all treefront cells while normals and colors are approximated by their statistical average within each of tree-front cells. With this framework, we employ attribute-dependent encoding techniques to exploit different characteristics of various attributes. All of these have led to significant improvement in the rate-distortion (R-D) performance and a computational advantage over {{the state of the}} art. Furthermore, given sufficient levels of octree expansion, normal space partitioning and resolution of color quantization, the proposed point cloud encoder can be potentially used for lossless coding of 3 D point clouds. Index Terms — Progressive coding, LOD, compression, octree, 3 D point cloud...|$|E
5000|$|Mount {{has also}} worked on point location, which {{involves}} preprocessing a planar polygonal subdivision S of size [...] {{to determine the}} <b>cell</b> of a <b>subdivision</b> that a query point is in. In, the paper gives an [...] time to construct a data structure of [...] space that when asked what cell a query point lies in, takes expected time [...] where [...] is the entropy of the probability distribution of which cells the query points lie in.|$|R
40|$|A graph G=(V,E) is word-representable {{if there}} exists a word w over the {{alphabet}} V such that letters x and y alternate in w {{if and only if}} (x,y) ∈ E. A triangular grid graph is a subgraph of a tiling of the plane with equilateral triangles defined by a finite number of triangles, called <b>cells.</b> A <b>subdivision</b> of a triangular grid graph is replacing some of its cells by plane copies of the complete graph K_ 4. Inspired by a recent elegant result of Akrobotu et al., who classified word-representable triangulations of grid graphs related to convex polyominoes, we characterize word-representable subdivisions of triangular grid graphs. A key role in the characterization is played by smart orientations introduced by us in this paper. As a corollary to our main result, we obtain that any subdivision of boundary triangles in the Sierpiński gasket graph is word-representable...|$|R
40|$|A {{computer}} program, ISOLEV, allows interactive {{visualization of}} CFD scalar and vector functions {{by means of}} user-specified sections of the data. The application is based on table lookups which govern both isosurface generation on hexahedral grid <b>cells</b> and recursive <b>subdivision</b> of the <b>cells.</b> The program supports Gouraud-shaded color maps of the data, surface-on-surface maps, and deformation surfaces of vector fields. The execution of the code for animated sweeps is improved by resorting to the cells in the database and maintaining an active set of cells to be rendered...|$|R
40|$|In this paper, {{we propose}} a generic point cloud encoder that {{provides}} a unified framework for compressing different attributes of point samples corresponding to 3 D objects with arbitrary topology. In the proposed scheme, the coding process is led by an iterative octree <b>cell</b> <b>subdivision</b> of the object space. At each level of subdivision, positions of point samples are approximated by the geometry centers of all treefront cells while normals and colors are approximated by their statistical average within each of tree-front cells. With this framework, we employ attribute-dependent encoding techniques to exploit different characteristics of various attributes. All of these have led to significant improvement in the rate-distortion (R-D) performance and a computational advantage over {{the state of the}} art. Furthermore, given sufficient levels of octree expansion, normal space partitioning and resolution of color quantization, the proposed point cloud encoder can be potentially used for lossless coding of 3 D point clouds...|$|E
40|$|Abstract—In this paper, {{we propose}} a generic point cloud encoder that {{provides}} a unified framework for compressing different attributes of point samples corresponding to 3 D objects with an arbitrary topology. In the proposed scheme, the coding process is led by an iterative octree <b>cell</b> <b>subdivision</b> of the object space. At each level of subdivision, the positions of point samples are approximated by the geometry centers of all tree-front cells, whereas normals and colors are approximated by their statistical average {{within each of the}} tree-front cells. With this framework, we employ attribute-dependent encoding techniques to exploit the different characteristics of various attributes. All of these have led to a significant improvement in the rate-distortion (R-D) performance and a computational advantage over the state of the art. Furthermore, given sufficient levels of octree expansion, normal space partitioning, and resolution of color quantization, the proposed point cloud encoder can be potentially used for lossless coding of 3 D point clouds. Index Terms—Progressive coding, LOD, compression, octree, 3 D point cloud. Ç...|$|E
40|$|We {{discuss a}} {{practical}} motion planning strategy {{based on a}} two-step approach. First, an approximation of the C-space is built by a plane-sweep algorithm. Then, {{the search for a}} solution path drives the necessary refinement steps. Our claim is that an approach based on the incremental characterization of the C-space can be competitive with the best proposed motion planning techniques. We substantiate this claim in the simple case of planning translations of a convex body in the plane. Since the shape of the free space is incrementally recognized by probing the space via collision detection, every item of geometric information is obtained from the analysis of contact configurations involving convex bodies. At any stage the probes provide a partial characterization, represented by a simple <b>cell</b> <b>subdivision</b> and a suitable set of chains approximating the boundaries of the grown obstacles. The cells and their adjacencies do not change during the refinement step, so that the search strategy is straightforward. Although the performances are not optimal in theory, the planning algorithm shows a good behaviour, as demonstrated by a few experiments where it is compared with a quadtree-based strategy...|$|E
40|$|It {{is shown}} {{that for every}} {{subdivision}} of the d-dimensional Euclidean space, d ≥ 2, into n convex cells, there is a straight line that stabs at least Ω((log n / log log n) 1 /(d− 1)) cells. In other words, if a convex subdivision of d-space has the property that any line stabs at most k <b>cells,</b> then the <b>subdivision</b> has at most exp(O(k d− 1 log k)) cells. This bound is best possible apart from a constant factor. It was previously known only in the case d = 2. Keywords. Stabbing number, convex subdivision, space partition, extremal bound...|$|R
40|$|Adaptive isotopic {{approximation}} of nonsingular curves: the parameterizability and nonlocal isotopy approach. (English summary) Discrete Comput. Geom. 45 (2011), no. 4, 760 – 795. 1432 - 0444 In this paper, a new algorithm for computing isotopic approximations of a nonsingular algebraic curve is proposed. It has {{the advantages of}} parameterizability and nonlocal isotopy. It {{can also be used}} in the rectangular case which allows <b>subdivision</b> <b>cells</b> to be rectangles with arbitrary but bounded aspect ratios and it exhibits great speedup. Some experimental results show that the algorithm is practical and more efficient than the existing algorithms of Plantinga-Vegter and Snyder...|$|R
40|$|AbstractWe {{present a}} {{symbolic}} probabilistic algorithm {{to compute the}} isolated roots in Cn of sparse polynomial equation systems. As some already known numerical algorithms solving this task, our procedure is based on polyhedral deformations and homotopies, but it amounts to solving {{a smaller number of}} square systems of equations and in fewer variables. The output of the algorithm is a geometric resolution of a finite set of points including the isolated roots of the system. The complexity is polynomial {{in the size of the}} combinatorial structure of the system supports up to a pre-processing yielding the mixed <b>cells</b> in a <b>subdivision</b> of the family of these supports...|$|R
40|$|Graduation date: 2000 Many diverse {{applications}} {{have begun}} to study processes and patterns at a global scale. To aid in this research, discrete global grid systems (DGGSs) are data models which enable environmental modeling, monitoring and sampling across the earth {{at a variety of}} spatial scales. A DGGS can be evaluated on a set of topological and geometric criteria, two of which, intercell distance and the "cell wall midpoint criterion", form the basis of this study. These two properties have been noted to be important for dynamic modeling applications. This study focuses on results obtained from measurements of ten different global partitioning methods. Each method was further subdivided into different design choices, which included frequency of <b>cell</b> <b>subdivision</b> (2 - or 3 -frequency edge partition), predominant tessellating shape (triangle, hexagon, diamond or quadrilateral), and base modeling solid (octahedron, icosahedron, or sphere). Intercell distance and cell wall midpoint measures were statistically normalized to be comparable among the methods studied. The results were further standardized to a common mean intercell distance (89. 02 km) to determine performance rankings for the methods. Finally, the distortion of each method was presented graphically to understand the underlying spatial pattern. For intercell distances, the Fuller-Gray method had the best performance, while two quadrilateral grids (Tobler-Chen and Equal Angle) performed substantially worse. For the cell wall midpoint criterion, the Equal Angle grid had the lowest overall distortion with the Snyder and Fuller-Gray methods also performing relatively well. The Small Circle subdivision method and Tobler-Chen grid generally had the poorest performance for this property, especially at the higher recursion levels studied. All methods based on the icosahedron outperformed those based on the octahedron for both criteria studied. Aggregation of triangles into hexagons and diamonds seemed to have little impact on intercell distance measurements, although dual hexagon aggregation had markedly different statistics and spatial patterns for the cell wall midpoint property. Frequency of subdivision seemed to account for very little variation. Maps of spatial variation for both criteria show patterns of localized distortion which are unique to each method studied...|$|E
40|$|An {{effective}} method for untangling and optimization of hexahedral unstructured non-conformal meshes is presented. The method {{has been developed}} {{as a part of}} the Numeca new mesh generator (HEXPRESS TM). The untangling algorithm is based on the successive analysis and correction of concave cells, via local untangling of sets of cells referencing a mesh node. The problem of untangling a hexahedral cell can be decomposed into untangling of the tetrahedra that constitute the <b>cell.</b> This <b>subdivision</b> is not unique and must be appropriately chosen to ensure the efficiency of the algorithm. The optimization algorithm is also based on the quality analysis and optimization of the sets of cells attached to a mesh node. Successive optimization of such sets containing valid cells results in an overall mesh quality improvement. The local optimization of hexahedral cells is performed via optimizing a variational functional for the set of tetrahedra representing the cell. It is important that identical patterns for decomposition of a cell into tetrahedra are used in both untangling and optimization. The results of applying the methods to various test cases including many complicated geometries of interest for industry. Some of the advantages and disadvantages are discussed...|$|R
40|$|We treat in {{this paper}} two linked {{subjects}} underlying virtual environment description: topological ab-straction, and the way its precomputed data can be accessed by autonomous agents. The topological ab-straction we propose is composed of three hierarchical layers, the first being the <b>subdivision</b> <b>cells</b> graph, and the two others being successive groupings. Then, we highlight some preprocesses computable with abstraction {{in order to improve}} environment information accessibility, such as potential visibility sets. Agents can then retrieve globally computed data to use them in an egocentric realistic way. Moreover, we constrained our model so that it is usable within the framework of microscopic crowd simulation. Thus, it is sufficiently realistic, very efficient in access time, and can handle small as well as large environments...|$|R
40|$|International audienceThis paper {{presents}} a numerically stable {{solution to a}} point-in-polygon problem by combining the orientation method and the uniform subdivision technique. We define first a quasi-closest point that can be locally found through the uniform <b>subdivision</b> <b>cells,</b> and then we provide the criteria for determining whether a point lies inside a polygon according to the quasi-closest point. For {{a large number of}} points to be tested against the same polygon, the criteria are employed to determine the inclusion property of an empty cell as well as a test point. The experimental tests show that the new method resolves the singularity of a test point on an edge without loss of efficiency. The GIS case study also demonstrates the capability of the method to identify which region contains a test point in a map...|$|R
40|$|The cells {{present in}} the blood {{can be divided into}} three classes - red cells, white cells and platelets. Within the white <b>cell</b> class a <b>subdivision</b> can be made into granulocytes (neutrophils, eosinophils and basophils), {{lymphocytes}} and monocytes. In the normal adult the production of each mature cell type is mainly achieved by proliferation and differentiation of hemopoietic progenitor cells in the bone marrow and, in case of mice, also in the spleen. When morphological and functional differentiation of these progenitor ceils has occurred the maturing cells are usually kept at the site of formation in the hemopoietic tissues for a certain period before they are released to the blood strearn. In addition to these mature cells also immature cells may circulate in the blood in smal! numbers...|$|R
40|$|Peng-Jun Wan ¢ We {{study the}} problem of {{separating}} £ points in the plane, no two of which have the same ¤ or ¥-coordinate using a minimum number of vertical and horizontal lines avoiding the points, so that each <b>cell</b> of the <b>subdivision</b> contains at most one point. We prove that this problem and some variants of it are NP-complete. We give an approximation algorithm with ratio ¦ for the planar problem, and a ratio § approximation algorithm for the §-dimensional variant, in which the points are to be separated using axis-parallel hyperplanes. We reduce the problem to the rectangle stabbing problem studied by Gaur et al [5]. Their approximation algorithm uses LP-rounding. Our algorithm presents an alternative LP-rounding procedure which also works for the rectangle stabbing problem. We also discuss some dual problems suggested by the linear programs used to solve the separation problem. ...|$|R
