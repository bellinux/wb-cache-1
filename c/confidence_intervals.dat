10000|10000|Public
5|$|MOA-2009-BLG-387L is a {{red dwarf}} in the Sagittarius {{constellation}} that is host to the planet MOA-2009-BLG-387Lb. The star {{is estimated to be}} nearly 20,000 light years away and approximately one fifth the mass of the Sun, although large <b>confidence</b> <b>intervals</b> exist, reflecting the uncertainties in both the mass and distance. The star drew the attention of astronomers when it became the lens of gravitational microlensing event MOA-2009-BLG-387L, in which it eclipsed a background star and created distorted caustics, an envelope of reflected or refracted light rays. Analysis of the caustic events and of follow-up observational data led to the planet's discovery, which was reported in February 2011.|$|E
5|$|MOA-2009-BLG-387Lb is a gas giant, with an {{estimated}} mass 2.6 times that of Jupiter's and a radius of 1.75 times that of jupiter and {{an estimated}} mean distance of 0.01 AU from its host star.It gives a temperature of 2200 kelvin It has an orbital period of approximately 18.4 hours. Although the mass and mean distance of MOA-2009-BLG-387Lb is estimated, the <b>confidence</b> <b>intervals</b> are very large, indicating {{that there is a}} large uncertainty present. These uncertainties are largely due to how the exact parameters of the host star are not known.|$|E
5|$|Emphasis {{is placed}} not on actual {{arithmetic}} computation, {{but rather on}} conceptual understanding and interpretation. The course curriculum is organized around four basic themes; the first involves exploring data and covers 20–30% of the exam. Students are expected to use graphical and numerical techniques to analyze distributions of data, including univariate, bivariate, and categorical data. The second theme involves planning and conducting a study and covers 10–15% of the exam. Students {{must be aware of}} the various methods of data collection through sampling or experimentation and the sorts of conclusions that can be drawn from the results. The third theme involves probability and its role in anticipating patterns in distributions of data. This theme covers 20–30% of the exam. The fourth theme, which covers 30–40% of the exam, involves statistical inference using point estimation, <b>confidence</b> <b>intervals,</b> and significance tests.|$|E
50|$|The {{presence}} of anti-thyroid antibodies {{is associated with}} an increased risk of unexplained subfertility (odds ratio 1.5 and 95% <b>confidence</b> <b>interval</b> 1.1-2.0), miscarriage (odds ratio 3.73, 95% <b>confidence</b> <b>interval</b> 1.8-7.6), recurrent miscarriage (odds ratio 2.3, 95% <b>confidence</b> <b>interval</b> 1.5-3.5), preterm birth (odds ratio 1.9, 95% <b>confidence</b> <b>interval</b> 1.1-3.5) and maternal Postpartum thyroiditis (odds ratio 11.5, 95% <b>confidence</b> <b>interval</b> 5.6-24).|$|R
40|$|In {{this paper}} the {{interval}} {{estimation of the}} disturbance variance in a linear regression model is discussed from several view points. Firstly, a brief summary ofthe Stein type point estimation theory and the Stein type interval estimation theory is given. Then, {{the relationship between the}} improvement on the point estimation and the improvement on the interval estimation is discussed. It is shown that substituting the Stein type estimator for the usual estimator in the <b>confidence</b> <b>interval</b> leads to the improvement on the interval estimation. Secondly, the Neyman accuracy of the Stein type <b>confidence</b> <b>interval</b> is considered. The Neyman accuracy is a measure related to the unbiasedness of a <b>confidence</b> <b>interval.</b> It is shown that the Stein type <b>confidence</b> <b>interval</b> is not unbiased. Thirdly, the Wolfowitz accuracy of the Stein type <b>confidence</b> <b>interval</b> is considered. The Wolfowitz accuracy is related to the closeness of the endpoints to. the true parameter. The sufficient condition for the Stein type <b>confidence</b> <b>interval</b> to improve on the usual <b>confidence</b> <b>interval</b> is derived. Finally, the Stein type <b>confidence</b> <b>interval</b> is discussed under the multivariate Student-t distribution. It is shown that so far as the coverage probability and the multivariate Student-t distributions are concerned, the Stein type <b>confidence</b> <b>interval</b> is not robust against nonnormality, but that the superiority over the usual <b>confidence</b> <b>interval</b> still holds against nonnormality. Furthermore, for the case when it is known that error terms have a multivariate Student-t distribution, a Stein type <b>confidence</b> <b>interval</b> which improves on the usual <b>confidence</b> <b>interval</b> is presented...|$|R
5000|$|To {{obtain a}} <b>confidence</b> <b>interval</b> for ρ, we first compute a <b>confidence</b> <b>interval</b> for F(''''): ...|$|R
25|$|The 95% <b>confidence</b> <b>intervals</b> {{should be}} provided.|$|E
25|$|Some criticisms {{have focused}} on the {{relatively}} broad 95% <b>confidence</b> <b>intervals</b> (CI95), resulting from the difficulty and scarcity of reliable sources.|$|E
25|$|Its {{statistical}} properties {{were examined}} by Sanchez et al who recommended a bootstrap procedure to estimate <b>confidence</b> <b>intervals</b> when testing for differences between samples.|$|E
25|$|The {{estimated}} percentage plus {{or minus}} its margin of error is a <b>confidence</b> <b>interval</b> for the percentage. In other words, {{the margin of error}} is half the width of the <b>confidence</b> <b>interval.</b> It can be calculated as a multiple of the standard error, with the factor depending of the level of confidence desired; a margin of one standard error gives a 68% <b>confidence</b> <b>interval,</b> while the estimate {{plus or minus}} 1.96 standard errors is a 95% <b>confidence</b> <b>interval,</b> and a 99% <b>confidence</b> <b>interval</b> runs 2.58 standard errors {{on either side of the}} estimate.|$|R
40|$|Applied statisticians {{commonly}} {{carry out}} preliminary data-based model selection and then construct a <b>confidence</b> <b>interval</b> {{assuming that the}} selected model {{had been given a}} priori, as the true model. The resulting post-model-selection <b>confidence</b> <b>interval</b> has endpoints that are discontinuous functions of the data and typically has very poor coverage properties. As an improvement, Efron 2014 proposed a <b>confidence</b> <b>interval</b> centered on the bootstrap smoothed estimator, with width proportional to the estimated standard deviation. We evaluate this <b>confidence</b> <b>interval</b> in the scenario of two nested linear regression models, the full model and a simpler model, and a preliminary test of the null hypothesis that the simpler model is correct. We derive computationally convenient expressions for the ideal bootstrap smoothed estimator and its standard deviation and the coverage probability and expected length of this <b>confidence</b> <b>interval.</b> In terms of coverage probability, this <b>confidence</b> <b>interval</b> outperforms the post-model-selection <b>confidence</b> <b>interval</b> with the same nominal coverage and based on the same preliminary test. However, the <b>confidence</b> <b>interval</b> centered on the bootstrap smoothed estimator does not perform substantially better, in terms of expected length, than the usual <b>confidence</b> <b>interval,</b> with the same minimum coverage probablility, based on the full model. This suggests that finding a good data-based width for a <b>confidence</b> <b>interval</b> centered on the bootstrap smoothed estimator is still an open problem...|$|R
5|$|Radiocarbon dating tests {{conducted}} on 1QpHab and 4QpPsa at the Arizona Accelerator Mass Spectrometry Facility gave a {{one standard deviation}} <b>confidence</b> <b>interval</b> of 104-43 BCE and a two sigma <b>confidence</b> <b>interval</b> of 120-5 BCE (97%); for 4QpPsa (4Q171) the one standard deviation <b>confidence</b> <b>interval</b> was 22-78 CE and the two sigma <b>confidence</b> <b>interval</b> was 5-111 CE. Earlier paleographic dating of 1QpHab indicated a date range of 30-1 BCE.|$|R
25|$|<b>Confidence</b> <b>intervals</b> can be calculated, {{and so can}} {{margins of}} error, {{for a range of}} {{statistics}} including individual percentages, differences between percentages, means, medians, and totals.|$|E
25|$|This {{transformation}} may {{be useful}} {{as an alternative to}} Chebyshev's inequality or as an adjunct to it for deriving <b>confidence</b> <b>intervals</b> for variates with unknown distributions.|$|E
25|$|Even {{for quite}} large values of n, the actual {{distribution}} of the mean is significantly nonnormal. Because of this problem several methods to estimate <b>confidence</b> <b>intervals</b> have been proposed.|$|E
50|$|Various {{interpretations of}} a <b>confidence</b> <b>interval</b> {{can be given}} (taking the 90% <b>confidence</b> <b>interval</b> as an example in the following).|$|R
5000|$|In other words, {{the lower}} {{endpoint}} of the 95% <b>confidence</b> <b>interval</b> is:and the upper endpoint of the 95% <b>confidence</b> <b>interval</b> is: ...|$|R
40|$|In this paper, {{we first}} re-visit the {{inference}} problem for interval identified parameters orig-inally studied in Imbens and Manski (2004) and later extended in Stoye (2007). We take the general criterion function approach {{and establish a}} new <b>confidence</b> <b>interval</b> that is asymptotically valid under the same assumptions as in Stoye (2007). Like the <b>confidence</b> <b>interval</b> of Stoye (2007), our new <b>confidence</b> <b>interval</b> extends that of Imbens and Manski (2004) {{to allow for the}} lack of a super-efficient estimator of the length of the identified interval. In addition, it shares the natural nesting property of the original <b>confidence</b> <b>interval</b> of Imbens and Manski (2004). A simulation study is conducted to examine the finite sample performance of our new <b>confidence</b> <b>interval</b> and that of Stoye (2007). Finally we extend our <b>confidence</b> <b>interval</b> for interval identified parameters to parameters defined by moment equalities/inequalities...|$|R
25|$|These <b>confidence</b> <b>intervals</b> reflect random error, {{but do not}} {{compensate}} for systematic error, {{which in this case}} can arise from, for example, the reference group not having fasted long enough before blood sampling.|$|E
25|$|The Environmental Protection Agency has {{suggested}} best practices {{for the use}} of Chebyshev's inequality for estimating <b>confidence</b> <b>intervals.</b> This caution appears to be justified as its use in this context may be seriously misleading.|$|E
25|$|A {{principal}} {{benefit of}} modeling {{is the ability}} to explicitly compare models: Rather than simply returning a value for each component, the modeler can compute <b>confidence</b> <b>intervals</b> on parameters, but, crucially, can drop and add paths and test the effect via statistics such as the AIC. Thus, for instance to test for predicted effects of family or shared environment on behavior, an AE model can be objectively compared to a full ACE model. For example, we can ask of the figure above for height: Can C (shared environment) be dropped without significant loss of fit? Alternatively, <b>confidence</b> <b>intervals</b> can be calculated for each path.|$|E
50|$|For N = 100 the 95% <b>confidence</b> <b>interval</b> is {{approximately}} ±4.9595 standard deviations; the 99% <b>confidence</b> <b>interval</b> {{is approximately}} ±140.0 standard deviations.|$|R
50|$|For N = 500 the 95% <b>confidence</b> <b>interval</b> is {{approximately}} ±4.5574 standard deviations; the 99% <b>confidence</b> <b>interval</b> {{is approximately}} ±11.1620 standard deviations.|$|R
50|$|Exponentiation of the {{approximate}} <b>confidence</b> <b>interval</b> for the log diagnostic odds ratio gives {{the approximate}} <b>confidence</b> <b>interval</b> for the diagnostic odds ratio.|$|R
25|$|These same {{formulae}} {{can be used}} {{to obtain}} <b>confidence</b> <b>intervals</b> on the variance of residuals from a least squares fit under standard normal theory, where k is now the number of degrees of freedom for error.|$|E
25|$|I'p ranges between +1 and −1 with 95% <b>confidence</b> <b>intervals</b> of ±0.5. I'p has {{the value}} of 0 if the pattern is random; if the pattern is uniform, I'p < 0 and if the pattern shows aggregation, I'p > 0.|$|E
25|$|Since {{prediction}} intervals {{are only}} concerned with {{past and future}} observations, rather than unobservable population parameters, they are advocated as a better method than <b>confidence</b> <b>intervals</b> by some statisticians, such as Seymour Geisser, following the focus on observables by Bruno de Finetti.|$|E
40|$|Conditional <b>confidence</b> <b>interval</b> {{estimation}} {{procedures for}} the location and scale para-meters of the Cauchy and logistic distributions are discussed. There are two aims: The first is to discuss computational aspects of using the conditional <b>confidence</b> <b>interval</b> approach, {{and the second is}} to give a rough numerical comparison of the conditional <b>confidence</b> <b>interval</b> procedures and the unconditional <b>confidence</b> <b>interval</b> {{procedures for the}} parameters of the Cauchy and logistic distributions, discussed recently by Haas, Bain & Antle (1970), an...|$|R
30|$|Of 813 {{patients}} enrolled, 425 (52.2 %) {{were classified}} as satisfied. Combined spinal–epidural anesthesia (CSEA) (odds ratio, 3.3; 95 % <b>confidence</b> <b>interval,</b> 1.08 – 10.1) was positively associated with satisfaction. Paresthesia during needle insertion (odds ratio, 0.56; 95 % <b>confidence</b> <b>interval,</b> 0.42 – 0.76), lightning pain during neuraxial anesthesia (odds ratio 0.62; 95 % <b>confidence</b> <b>interval,</b> 0.39 – 0.98), failed block (odds ratio 0.28; 95 % <b>confidence</b> <b>interval,</b> 0.09 – 0.87), and intraoperative use of antiemetic (odds ratio 0.71; 95 % <b>confidence</b> <b>interval,</b> 0.53 – 0.94) were negatively associated with satisfaction. In the 792 patients receiving spinal anesthesia only, the same factors except for CSEA were associated with satisfaction.|$|R
50|$|The thin {{horizontal}} lines -- {{sometimes referred}} to as whiskers -- emerging from the box indicate the magnitude of the <b>confidence</b> <b>interval.</b> The longer the lines, the wider the <b>confidence</b> <b>interval,</b> and the less reliable the data. The shorter the lines, the narrower the <b>confidence</b> <b>interval</b> and the more reliable the data.|$|R
25|$|Precision in {{epidemiological}} variables is {{a measure}} of random error. Precision is also inversely related to random error, so that to reduce random error is to increase precision. <b>Confidence</b> <b>intervals</b> are computed to demonstrate the precision of relative risk estimates. The narrower the confidence interval, the more precise the relative risk estimate.|$|E
25|$|The {{t-distribution}} {{plays a role}} in {{a number}} of widely used statistical analyses, including Student's t-test for assessing the statistical significance of the difference between two sample means, the construction of <b>confidence</b> <b>intervals</b> for the difference between two population means, and in linear regression analysis. The Student's t-distribution also arises in the Bayesian analysis of data from a normal family.|$|E
25|$|For example, if {{one makes}} the {{parametric}} {{assumption that the}} underlying distribution is a normal distribution, and has a sample set {X1,...,X'n}, then <b>confidence</b> <b>intervals</b> and credible intervals {{may be used to}} estimate the population mean μ and population standard deviation σ of the underlying population, while prediction intervals may be used to estimate the value of the next sample variable, X'n+1.|$|E
30|$|As shown from Figs.  6, 7, 8 and 9, {{different}} SSCBs in {{the same}} <b>confidence</b> <b>interval</b> can capture different actual wind power values. When the <b>confidence</b> <b>interval</b> is more than 50 %, 100 % SSCB with the highest percentage verifies the forecasting model with better effects. When the <b>confidence</b> <b>interval</b> equals to 30 %, 90 % SSCB occurs with the highest percentage. It illustrates {{that the percentage of}} 100 % SSCB fully captures the actual wind power value occupies less and less with the shrinking of the <b>confidence</b> <b>interval,</b> which means that the <b>confidence</b> <b>interval</b> should not be too narrow in ramp event forecasting model. Especially, the proportion of 100 % SSCB partially equals to the corresponding <b>confidence</b> <b>interval</b> value. After the SSCB is formulated, the ramp event detecting algorithm can be fully used to extract the forecasted characteristics of ramp events.|$|R
40|$|In {{this note}} i t is {{described}} how two distributions arising in a bic-medical investigation are compared {{by means of}} a <b>confidence</b> <b>interval</b> for the difference of appropriate quantiles. It is briefly indicated how an approximation for such a <b>confidence</b> <b>interval</b> is derived. Key words & Phrafes: <b>confidence,</b> <b>interval.</b> quantiles, disiribuiion-free, qmptoi ics 1...|$|R
40|$|Post-poliomyelitis {{syndrome}} (PPS) is {{a clinical}} syndrome of new weakness, fatigue, and pain in {{individuals who have}} previously recovered from acute paralytic poliomyelitis. The primary objective {{of this study was}} to identify factors which predict subsequent PPS. Among patients with prior polio, cases were those with new weakness and fatigue, and controls were those without these complaints. A chart review of 353 patients evaluated at the Montreal Neurological Institute post-polio clinic identified 127 cases and 39 controls. In univariate analyses, significant risk factors for PPS were a greater current age (odds ratio of 1. 8 per decade, 95 % <b>confidence</b> <b>interval</b> 1. 3 to 2. 6), a longer time since acute polio (odds ratio of 1. 6 per decade, 95 % <b>confidence</b> <b>interval</b> 1. 1 to 2. 3), more weakness at acute polio (odds ratio 1. 5, 95 % <b>confidence</b> <b>interval</b> 1. 1 to 2. 0), a recent weight gain (odds ratio 3. 8, 95 % <b>confidence</b> <b>interval</b> 1. 6 to 9. 4), muscle pain with exercise (odds ratio 3. 8, 95 % <b>confidence</b> <b>interval</b> 1. 5 to 9. 5), muscle pain (odds ratio 2. 6, 95 % <b>confidence</b> <b>interval</b> 1. 3 to 5. 5), and joint pain (odds ratio 2. 3, 95 % <b>confidence</b> <b>interval</b> 1. 1 to 5. 3). The multivariate analyses revealed that a model containing current age (odds ratio 1. 7 per decade, 95 % <b>confidence</b> <b>interval</b> 1. 1 to 2. 6), weakness at acute polio (odds ratio 1. 6, 95 % <b>confidence</b> <b>interval</b> 1. 1 to 2. 5), muscle pain with exercise (odds ratio 4. 9, 95 % <b>confidence</b> <b>interval</b> 1. 6 to 15. 6), recent weight gain (odds ratio 6. 4, 95 % <b>confidence</b> <b>interval</b> 2. 02 to 20. 3), and joint pain (odds ratio 2. 33, 95 % <b>confidence</b> <b>interval</b> 0. 8 to 7. 1) was the most effective in predicting who would develop PPS. Age at acute polio, degree of recovery after polio, weakness at best point after polio, physical activity, and sex were not contributing factors...|$|R
