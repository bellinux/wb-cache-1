10|20|Public
5000|$|Incident Management - <b>centralized</b> <b>event</b> and {{incident}} management ...|$|E
40|$|Abstract—In this paper, {{we discuss}} event-triggering scheme with {{sliding mode control}} where sensors are {{distributed}} over network. Here, a decentralized event-triggering mechanism is proposed where event is observed at each sensor nodes with local information for possible triggering and control update is done whenever a <b>centralized</b> <b>event</b> is triggered. In order to achieve this, the states are sampled at {{any one of the}} local triggering instant and then a centralized triggering condition is evaluated for possible control update. The utility of the scheme is analysed through a numerical simulation. Index Terms—Decentralized event-triggering, sliding mode control. I...|$|E
40|$|Applications of inter-vehicle and vehicle-to-roadside {{communication}} that {{make use of}} vehicular ad hoc networks (VANETs) will often require reliable {{communication that}} provides guaranteed real-time message propagation. This paper describes an event-based middleware, called RT-STEAM. Unlike other event systems, RT-STEAM does not rely on a <b>centralized</b> <b>event</b> broker or look-up service while still supporting event channels providing hard real-time event delivery. RT-STEAM event filtering can be based on subject, content and/or proximity. To guarantee real-time communication, we exploit proximitybased event propagation to guarantee real-time constraints within the defined proximities only. The proximity within which realtime guarantees are available is adapted to maintain time bounds while allowing changes to membership and topology, typical of VANETs. This Space-Elastic Model of real-time communication {{is the first to}} directly address adaptation in the space domain to guarantee real-time constraints...|$|E
40|$|This {{paper is}} from the SANS Institute Reading Room site. Reposting is not {{permitted}} without express written permission. <b>Centralizing</b> <b>Event</b> Logs on Windows 2000 This case study will detail how I setup a central repository for server logs and daily notifications of events that might indicate a security incident. This was done on a limited budget using free tools available from the internet and software already in use for other projects. My goal was to consolidate the Eventviewer logs, Internet Information Services (IIS) logs, and Urlscan logs from 15 Windows 2000 web servers into a database I could query against. I would then have {{the results of the}} queries automatically emaile [...] . Copyright SANS Institut...|$|R
40|$|In the Internet world, {{the amount}} of {{information}} available reaches very high quotas. In order to find specific information, some tools were created that automatically scroll through the existing web pages and update their databases with the latest information on the Internet. In order to systematize the search and achieve a result in a concrete form, another step is needed for processing the information returned by the search engine and generating the response in a more organized form. <b>Centralizing</b> <b>events</b> of a certain type is useful first of all for creating a news service. Through this system we are pursuing a knowledge - events from the Internet documents - extraction system. The system will recognize events of a certain type (weather, sports, politics, text data mining, etc.) depending on how it will be trained (the concept it has in the dictionary). These events can be provided to the user, or it can also extract {{the context in which the}} event occurred, to indicate the initial form in which the event was embedded...|$|R
25|$|Police {{force was}} used on {{numerous}} occasions to break up or prevent public gay and lesbian <b>events.</b> <b>Centralized</b> censorship prevented the presentation of homosexuality in print and electronic media, {{as well as the}} import of such materials.|$|R
40|$|International audienceGATE/Geant 4 Monte Carlo {{simulations}} are computationally demanding applications, requiring {{thousands of}} processor hours to produce realistic results. The classical strategy of distributing the simulation of individual events {{does not apply}} efficiently for Positron Emission Tomography (PET) experiments, because it requires a centralized coincidence processing and large communication overheads. We propose a parallel computational model for GATE that handles event generation and coincidence processing in a simple and efficient way by decentralizing event generation and processing but maintaining a <b>centralized</b> <b>event</b> and time coordinator. The model is implemented with {{the inclusion of a}} new set of factory classes that can run the same executable in sequential or parallel mode. A Mann-Whitney test shows that the output produced by this parallel model in terms of number of tallies is equivalent (but not equal) to its sequential counterpart. Computational performance evaluation shows that the software is scalable and well balanced...|$|E
40|$|Data Acquisition (DAQ) {{systems for}} large high-energy physics (HEP) {{experiments}} in the eighties were designed to handle data rates of megabytes per second. The next generation of HEP experiments at CERN (European Laboratory for High Energy Physics), is being designed around the new Large Hadron Collider (LHC) project, {{and will have to}} cope with gigabyte-per-second data flows. As a consequence, LHC experiments will require challengingly new equipment for detector readout, event filtering, event building and storage. The Fastbus and VME-based tree architectures of the eighties run out of steam when applied to LHC's requirements. New concepts and architectures from the nineties have substituted rack-mounting backplane buses for high speed point-to-point links, abandoned <b>centralized</b> <b>event</b> building, and instead use switched networks and parallel architectures. Following these trends, and in the context of DAQ and trigger systems for LHC experiments, this paper summarizes the earlier architectures and presents the new concepts for DAQ...|$|E
40|$|Abstract. Applications of inter-vehicle and vehicle-to-roadside {{communication}} that {{make use of}} vehicular ad hoc networks (VANETs) will often require reliable {{communication that}} provides guaranteed real-time message propagation. This paper describes an event-based middleware, called RT-STEAM, designed to meet these requirements. Unlike other event systems, RT-STEAM does not rely on a <b>centralized</b> <b>event</b> broker or look-up service while still supporting event channels providing hard real-time event delivery. RT-STEAM event filtering can be based on subject, content and/or proximity. Proximity filters define geographical areas within which events are delivered. To guarantee real-time communication, we exploit proximity-based event propagation to guarantee real-time constraints within the defined proximities only. The proximity within which real-time guarantees are available is adapted to maintain time bounds while allowing changes to membership and topology as is typical of VANETs. This Space-Elastic Model of real-time communication {{is the first to}} directly address adaptation in the space domain to guarantee realtime constraints. ...|$|E
40|$|Abstract—We {{present a}} new {{approach}} to event-driven simulation that does not use a <b>centralized</b> run-time <b>event</b> queue, yet is capable of handling arbitrary models, including those with unclocked feedback and nonunit delay. The elimination of the event queue significantly reduces run-time overhead, resulting in faster simulation. We have implemented our algorithm in a prototype Verilog simulator called VeriSUIF. Using this simulator we demonstrate improved performance vs. a commercial simulator on a small set of programs. I...|$|R
40|$|Abstract. At present, many {{domestic}} industries don’t have perfect {{operation and}} maintenance management systems for their IT platform. Most of the daily maintenance work is passive response after the problem occurred rather than discovery in advance, which will bring the potential risks to IT system running smoothly. Therefore {{it is necessary to}} monitor and manage the existing IT core equipment, to improve the security and stability of the core production and enhance the satisfaction of business department. In addition, through the establishment of an association between centralized monitoring and process management platform, the system standardizes the operational work, and improves work efficiency. Maintenance management system based on Tivoli[1] is mainly to complete the monitoring and management of the IT infrastructure, used in finance, electric power, chemical and other industries, which includes room infrastructure, storage, networks, systems, databases and middleware. On one hand, the system <b>centralizes</b> <b>event</b> management platform integrates events from various aspects of the IT infrastructure, takes a rich deal and then provides intuitive monitoring for operational management. Moreover it integrates process management platform so as to complete creating work orders, processing and other operations. On the other hand, the system will integrate the monitorin...|$|R
5000|$|According to {{historian}} Heidi Minning, {{attempts by}} lesbians and gays in East Germany {{to establish a}} visible community were [...] "thwarted at every turn by the G.D.R. government and SED party." [...] She writes:Police force was used on numerous occasions to break up or prevent public gay and lesbian <b>events.</b> <b>Centralized</b> censorship prevented the presentation of homosexuality in print and electronic media, {{as well as the}} import of such materials.|$|R
40|$|Many {{applications}} of {{wireless sensor networks}} (WSNs) require events be detected around moving targets and delivered to a user, whose location may also change over time. Consequently, it is not desirable to have a single sensor node serving as the sink node for <b>centralized</b> <b>event</b> processing. Furthermore, an event usually occurs across different locations and lasts {{for a period of}} time that are unknown in advance. Hence it cannot be detected by a static set of sensor nodes. In this paper, we propose a general framework for such dynamic in-network event detection in WSNs. This framework enables a flexible number of sensor nodes to dynamically collaborate in detecting and delivering any specified event. So far there has been no such work reported in the literature. We have designed a protocol for the sensor nodes to autonomously determine whether they should participate in and which tasks they should perform to collaboratively process an event. We have implemented a prototype of the proposed framework using MicaZ motes and evaluated it through both simulations and experiments. The results demonstrate that our framework is effective and efficient in terms of energy cost and event processing delay. Department of Computin...|$|E
40|$|Abstract: In this paper, {{we propose}} a novel smart {{access control system}} for large enterprises. The {{proposed}} system performs the following functions: (1) limits access to secured areas in a given physical facility only to authorized users, (2) provides authorized users with configurable and differentiated access rights to the same premises based on their assigned credibility and time-schedules, (3) maintains <b>centralized</b> <b>event</b> logs with date/time stamp for all users that have granted access to the system, and (4) keeps track of all their movement activities across the premises, allowing for further analysis of their behaviour during working hours. All of these functions are mainly intended to: (1) be carried out automatically and wirelessly with neither human intervention nor slowing down the organization’s workflow, (2) avoid installation cost overhead,(3) minimize the running cost, (4) simplify system repairs and shorten it downtime, and (5) allow for future upgrades with almost little or no hardware changes along with slight firmware code modifications. The proposed system is implemented as a prototype model that presents both the hardware and the firmware aspects of the design. The built prototype shows success of the proposed system and hence it is promising for physical implementation in real systems at larger scales...|$|E
40|$|Organizations {{are aware}} of the {{importance}} of adequate information security due to various reasons like protection of confidential data based on regulations and legislation. On the other hand modern information systems are becoming very complex and vulnerable, which causes the generation of enormous amount of information and events spread over the systems. Quality management system therefore requires <b>centralized</b> <b>event</b> management. In the bank we {{are aware of}} the problem and are looking forward to finding a solution in the field of information and event security management (SIEM). In the present thesis the decision-making model for the choice of security information and event management is presented. The objective of the thesis is to facilitate the decision-making and the choice of appropriate SIEM; therefore three SIEM offers were chosen to present the pilot installation. The assessment of varieties was based on advantages and disadvantages as well as on architectural solutions. The process of decision-making was based on weight parameter estimation method which belongs to the group of multi-parameter and multi-criteria decision-making. The best results were obtained by ArcSight system for which the final architectural solution was proposed. The final solution is based on high geographic redundancy configuration. The above decision-making process could be repeated and used by diverse enterprises or decision-makers. Despite the chosen offerer the decision-maker can choose any SIEM offerer and use the above methodology. ...|$|E
50|$|The National High School Drill Team Championships is a Drill Team Competition, held in Daytona Beach, Florida in {{the month}} of May each year at the ocean center. Drill teams from across the nation {{converge}} to compete in both the Master's and the Challenge level competitions. This event is currently the largest <b>centralized</b> drill team <b>event.</b> The company which runs the competition is Sports Network International, which hosts football and other Junior ROTC events as well.|$|R
40|$|We {{present a}} new {{approach}} to event-driven simulation that does not use a <b>centralized</b> run-time <b>event</b> queue, yet is capable of handling arbitrary models, including those with unclocked feedback and nonunit delay. The elimination of the event queue significantly reduces run-time overhead, resulting in faster simulation. We have implemented our algorithm in a prototype Verilog simulator called VeriSUIF. Using this simulator we demonstrate improved performance vs. a commercial simulator on a small set of programs. I. Introduction Modern digital system design relies heavily on simulation {{to reduce the number of}} design errors and to improve system efficiency. In large system designs so much time is spent in simulation that it has become a design bottleneck. Event-driven simulation and levelized compiled simulation are two well-known simulation techniques that are currently used in digital system design. In event-driven simulation, events are managed dynamically by an event scheduler. The mai [...] ...|$|R
30|$|Though the {{benefits}} of centralized water systems (e.g. improved publichealth, environmental protection, streamlined operations, economy of scale, reliability) are well known, these systems are not always feasible or appropriate. In developing world settings there has been growing interest by infrastructure experts,researchers, and international lending institutions in decentralized means of improving access to drinking water. While decentralized water systems with independent components may be less vulnerable to systemic failures, hazards, and extreme environmental <b>events,</b> <b>centralized</b> water systems are often associated with a higher quality of life. This study investigates stakeholder preferences regarding water infrastructure issues in Leogane, Haiti (population ~ 300, 000), a town situated at {{the epicenter of the}} January 2010 earthquake.|$|R
40|$|We {{focus on}} Internet of Things (IoT) environments where {{a network of}} sensing and {{computing}} devices are responsible to locally process contextual data, reason and collaboratively infer {{the appearance of a}} specific phenomenon (event). Pushing processing and knowledge inference {{to the edge of the}} IoT network allows the complexity of the event reasoning process to be distributed into many manageable pieces and to be physically located at the source of the contextual information. This enables a huge amount of rich data streams to be processed in real time that would be prohibitively complex and costly to deliver on a traditional centralized Cloud system. We propose a lightweight, energy-efficient, distributed, adaptive, multiple-context perspective event reasoning model under uncertainty on each IoT device (sensor/actuator). Each device senses and processes context data and infers events based on different local context perspectives: (i) expert knowledge on event representation, (ii) outliers inference, and (iii) deviation from locally predicted context. Such novel approximate reasoning paradigm is achieved through a contextualized, collaborative belief-driven clustering process, where clusters of devices are formed according to their belief on the presence of events. Our distributed and federated intelligence model efficiently identifies any localized abnormality on the contextual data in light of event reasoning through aggregating local degrees of belief, updates, and adjusts its knowledge to contextual data outliers and novelty detection. We provide comprehensive experimental and comparison assessment of our model over real contextual data with other localized and <b>centralized</b> <b>event</b> detection models and show the benefits stemmed from its adoption by achieving up to three orders of magnitude less energy consumption and high quality of inference...|$|E
50|$|In 2003, {{the launch}} of the new Campus Center {{on the site of the}} former Hazell Hall <b>centralized</b> campus social <b>events.</b> Construction of a new Atrium, Bookstore, Information Desk, Dining Hall, {{computer}} lab, and new student organization offices continued into 2004. In 2005, a row of automobile chop shops adjacent to campus were demolished. In 2006, construction of a new off-campus residence hall by American Campus Communities commenced in the chop shops' prior location. The new hall which opened in 2007 is dubbed the University Centre. As of Fall 2013 there are 5 residence halls on campus: Redwood Hall, Cypress Hall, Oak Hall, Laurel Hall, and the Dorman Honors Residence, in addition to several Greek houses.|$|R
25|$|Christmas on the Coosa is {{an annual}} {{series of events}} held in {{during the month of}} December. The event {{location}} is the Bibb Graves Memorial Bridge. The main event is the fireworks display and boat show held on the Coosa River. Observers watch from the Bibb Graves Memorial Bridge as a parade of boats decorated with Christmas lights float down the river under the bridge as fireworks go off. This is a unique experience due to the glow of fireworks illuminating the night sky as well as the placid river surface. A host of events proceeds the river show such as Miss Christmas on the Coosa Pageant, Pictures with Santa, tree lighting, and other <b>events</b> <b>centralized</b> around the city's Gold State Park.|$|R
5000|$|Halloween in the Castro {{was tied}} to the LGBT culture of San Francisco and began in the 1950-1960s in the Tenderloin/Polk street area of the city where the {{mainstream}} gay bars were first <b>centralized.</b> The <b>event</b> traces its history to the ostracism of LGBT people {{in the first half}} of the 20th century from mainstream culture which led to community identity and using gay bars as a focal point for socializing, networking and organizing politically. After World War II, in the 1940s, the San Francisco Bay Area became a haven for LGBT military personnel who didn't want to go back to their old lives. In the 1950s, a group of gay bars in San Francisco's Tenderloin area helped create a strip of venues for [...] "sex, drugs and late night fun". There has also been a South-of-Market (SoMa) leather subculture and BDSM bar scene with gay-focussed sex clubs sharing Folsom street, a tradition which is carried on with the annual Folsom Street Fair. The nearby business- and tourist-oriented area, Union Square, was also popular for cruising for sex and was open to gay men whereas the Tenderloin was where drag queens, t-girls and prostitutes of all orientations were known to congregate publicly in the city, because they were unwelcome in gay bars at that time.|$|R
40|$|As cyber attacks become {{increasingly}} distributed and sophisticated, so must our defenses. Collaborative {{processing of data}} produced by independent sources is advantageous for early and accurate detection of Internet-based threats, and instrumental for identifying complex attack patterns that target multiple administratively and geographically disjoint entities. In this paper, we introduce Agilis – a lightweight collaborative event processing platform for sharing and correlating event data generated in real time by multiple widely distributed sources. The primary goal of the Agilis design is to tread the balance between simplicity of use, robustness and scalability on one hand, and reasonable performance in large-scale settings on the other. To this end, Agilis is built upon the open-source Hadoop’s MapReduce infrastructure, which we augmented with a RAM-based data store and various locality-oriented optimizations to improve responsiveness and reduce overheads. The processing logic is specified in a flexible high-level language, called Jaql, which supports data flows and SQL-like query constructs. We demonstrate {{the utility of the}} Agilis framework by showing how it facilitates the collaborative detection of two different exploits: stealthy inter-domain port scans used by hackers for reconnaissance, and a botnet-driven HTTP session hijacking attack. We evaluate the performance of Agilis in both scenarios, and, in the case of interdomain port scans, compare it to a <b>centralized</b> high-end <b>event</b> processing system called ESPER. Our results show that while Agilis is slower than ESPER in a local area network, its relative performance improves substantially as we move towards larger scale distributed deployments. 1...|$|R
40|$|Discrete Event Systems: Diagnosis and Diagnosability {{addresses}} {{the problem of}} fault diagnosis of Discrete Event Systems (DES). This book provides the basic techniques and approaches necessary {{for the design of}} an efficient fault diagnosis system {{for a wide range of}} modern engineering applications. The different techniques and approaches are classified according to several criteria such as: modeling tools (Automata, Petri nets) that is used to construct the model; the information (qualitative based on events occurrences and/or states outputs, quantitative based on signal processing and data analysis) that is needed to analyze and achieve the diagnosis; the decision structure (centralized, decentralized) that is required to achieve the diagnosis. The goal of this classification is to select the efficient method to achieve the fault diagnosis according to the application constraints. This book focuses on the <b>centralized</b> and decentralized <b>event</b> based diagnosis approaches using formal language and automata as modeling tool. The work includes illustrated examples of the presented methods and techniques as well as a discussion on the application of these methods on several real-world problems...|$|R
40|$|Reducing {{emissions}} from deforestation and degradation (REDD+) has gained increasing global attention {{because of its}} potential to reduce carbon emissions and improve forest governance. Reducing {{emissions from}} deforestation and degradation requires successful inclusive decision making and accountability. However, there have been limited empirical studies that examine {{the effectiveness of the}} current participatory mechanism used in REDD+. Our research analyzes the participation of policy actors {{in the development of the}} REDD+ instrument in Vietnam. We are interested in how the political context and the different interests of actors influence the degree of participation in national REDD+ policy decision making. We explored participation through the analysis of the mechanisms, e. g., how actors involve and participate in decision making, and dynamics of participation, e. g., highly <b>centralized</b> policy <b>event</b> vs. donor led event. The study aims to answer three research questions: (1) Who is involved in national REDD+ policy making and what are their interests in participating in core political events? (2) What level of participation do the different political actors have in core political events? and (3) To what extent do the outcomes, e. g., regulations and strategies, of REDD+ policy events incorporate different preferences of policy actors? Our findings highlighted the dominant role of government agencies in REDD+ policy making, which leaves limited political space for nonstate actors, e. g., NGOs and civil society organizations (CSOs), in Vietnam to exert an influence on the final policy outputs. Even in this highly centralized context, however, we found evidence to suggest that some political space in decision making is given to nonstate actors. Within this space, such actors are able to propose alternative policy options. Ensuring inclusive decision making and accountability in the Vietnam context requires a shift in current governance from traditional top-down approaches to a more participatory form of decision making...|$|R
5000|$|Gay social {{clubs and}} groups {{were allowed to}} {{organize}} themselves freely, {{so long as they}} made tenuous links with Protestant Churches. This was because the official position of the Socialist Unity Party of Germany party was to outlaw {{discrimination on the basis of}} sexual orientation, but to otherwise ignore that LGBT relationships existed. On July 1, 1968, the GDR adopted its own code of criminal law. In it § 151 StGB-DDR provided for a sentence up to three years' imprisonment or probation for an adult (18 and over) who engaged in sexual acts with a youth (under 18) of the same sex. This law applied not only to men who have sex with boys but equally to women who have sex with girls. According to historian Heidi Minning, attempts by lesbians and gay men in East Germany to establish a visible community were [...] "thwarted at every turn by the G.D.R. government and SED party." [...] She writes:Police force was used on numerous occasions to break up or prevent public gay and lesbian <b>events.</b> <b>Centralized</b> censorship prevented the presentation of homosexuality in print and electronic media, as well as the import of such materials.|$|R
40|$|Abstract The autobiographical memory {{model of}} PTSD posits that the memory for the {{traumatic}} experience is influential in {{development of the}} disorder (Rubin, Berntsen, 2 ̆ 6 Bohni, 2008). In particular, Berntsen 2 ̆ 6 Rubin (2006) argue {{that the degree of}} event centralization, the incorporation of the memory into the individual 2 ̆ 7 s sense of self and life story, {{is directly related to the}} degree of PTSD symptoms exhibited by the individual. The present series of studies systematically analyzes event centralization and its relationship to PTSD, while taking into account other variables such as cognitive and emotion variables, as well as individual differences. Study one explored event centralization as an additional factor of PTSD symptoms. Results from this study suggest that PTSD is best described by a higher order model that includes the following five lower order factors: event centralization, reexperienceing, effortful avoidance, emotional numbing, and hyperarousal. In study two, predictors of adaptive and maladaptive outcomes were compared in a joint mediation model. The results from this model suggest that Neuroticism is a risk factor for PTSD, and that this may be due to Neuroticism causing increases in event-related rumination and event centralization. Conversely, Agreeableness is a protective factor that increases reflection and emotion-focused coping, which subsequently leads to posttraumatic growth. Finally, study three expanded the centrality of events scale to specify the emotional direction of the centralization. Results from this study suggest that some individuals <b>centralized</b> their traumatic <b>event</b> in a positive way, but negative event centralization was a stronger predictor of PTSD symptoms than was positive event centralization. Combined, the results of these studies support the theorized role of event centralization in the development of PTSD. Given the growing body of evidence for the relationship between event centralization and PTSD symptoms, clinical practices should be updated to better serve the individuals afflicted by PTSD...|$|R
40|$|Today’s Big Data phenomenon, {{characterized}} by huge volumes of data produced {{at very high}} rates by heterogeneous and geographically dispersed sources, is fostering the employment of large-scale distributed systems in order to leverage parallelism, fault tolerance and locality awareness {{with the aim of}} delivering suitable performances. Among the several areas where Big Data is gaining increasing significance, the protection of Critical Infrastructure {{is one of the most}} strategic since it impacts on the stability and safety of entire countries. Intrusion detection mechanisms can benefit a lot from novel Big Data technologies because these allow to exploit much more information in order to sharpen the accuracy of threats discovery. A key aspect for increasing even more the amount of data at disposal for detection purposes is the collaboration (meant as information sharing) among distinct actors that share the common goal of maximizing the chances to recognize malicious activities earlier. Indeed, if an agreement can be found to share their data, they all have the possibility to definitely improve their cyber defenses. The abstraction of Semantic Room (SR) allows interested parties to form trusted and contractually regulated federations, the Semantic Rooms, for the sake of secure information sharing and processing. Another crucial point for the effectiveness of cyber protection mechanisms is the timeliness of the detection, because the sooner a threat is identified, the faster proper countermeasures can be put in place so as to confine any damage. Within this context, the contributions reported in this thesis are threefold * As a case study to show how collaboration can enhance the efficacy of security tools, we developed a novel algorithm for the detection of stealthy port scans, named R-SYN (Ranked SYN port scan detection). We implemented it in three distinct technologies, all of them integrated within an SR-compliant architecture that allows for collaboration through information sharing: (i) in a <b>centralized</b> Complex <b>Event</b> Processing (CEP) engine (Esper), (ii) in a framework for distributed event processing (Storm) and (iii) in Agilis, a novel platform for batch-oriented processing which leverages the Hadoop framework and a RAM-based storage for fast data access. Regardless of the employed technology, all the evaluations have shown that increasing the number of participants (that is, increasing the amount of input data at disposal), allows to improve the detection accuracy. The experiments made clear that a distributed approach allows for lower detection latency and for keeping up with higher input throughput, compared with a centralized one. * Distributing the computation over a set of physical nodes introduces the issue of improving the way available resources are assigned to the elaboration tasks to execute, with the aim of minimizing the time the computation takes to complete. We investigated this aspect in Storm by developing two distinct scheduling algorithms, both aimed at decreasing the average elaboration time of the single input event by decreasing the inter-node traffic. Experimental evaluations showed that these two algorithms can improve the performance up to 30 %. * Computations in online processing platforms (like Esper and Storm) are run continuously, and the need of refining running computations or adding new computations, together with the need to cope with the variability of the input, requires the possibility to adapt the resource allocation at runtime, which entails a set of additional problems. Among them, the most relevant concern how to cope with incoming data and processing state while the topology is being reconfigured, and the issue of temporary reduced performance. At this aim, we also explored the alternative approach of running the computation periodically on batches of input data: although it involves a performance penalty on the elaboration latency, it allows to eliminate the great complexity of dynamic reconfigurations. We chose Hadoop as batch-oriented processing framework and we developed some strategies specific for dealing with computations based on time windows, which are very likely to be used for pattern recognition purposes, like in the case of intrusion detection. Our evaluations provided a comparison of these strategies and made evident the kind of performance that this approach can provide...|$|R

