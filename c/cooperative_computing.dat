90|42|Public
5000|$|In the 1962 President's Report, Jay Stratton wrote (on p. 17) [...] "A faculty {{committee}} {{under the}} chairmanship of Professor John C. Slater has taken primary responsibility for planning the facilities in the new Center for Materials. These include a new <b>Cooperative</b> <b>Computing</b> Laboratory completed this year and equipped with an I.B.M. 709 Computer".|$|E
50|$|The {{interdisciplinary}} research centers {{at the university}} include Heinz Nixdorf Institute, Paderborn center for Parallel Computing, Paderborn Institute for Scientific Computation, <b>Cooperative</b> <b>Computing</b> and Communication Laboratory (C-Lab) and Software quality lab (S-lab). RailCab is a research project by Paderborn University. Its purpose is {{the examination of the}} use of linear engines for the propulsion of autonomous, rail mounted vehicles.|$|E
5000|$|The EFF <b>Cooperative</b> <b>Computing</b> Awards are {{a series}} of four awards meant [...] "to {{encourage}} ordinary Internet users to contribute to solving huge scientific problems," [...] to be awarded to the first individual or group who discovers a prime number with a significant record number of decimal digits. The awards are funded by an anonymous donor.The awards are: ...|$|E
50|$|The GVU Center {{focuses on}} human-computer interaction, {{ubiquitous}} computing, mixed/augmented reality, computer animation/graphics, wearable computing, information visualization, educational technologies (learning sciences and technology), new media, communications, intelligent systems, human robot interaction, computer supported <b>cooperative</b> work, social <b>computing,</b> and online communities.|$|R
40|$|Returns from {{establishing}} closed (defined membership) cooperatives {{owned by}} grain producers to produce hogs in Iowa are evaluated. Using a computer-simulated production model incorporating biological and price factors and statistical techniques, uncertainty {{of production and}} the market environment are modeled. The returns to each farmer-member are analyzed, and the distributions of value added and total payments for each operation are ranked using a stochastic dominance criteria. Additionally, the net present value of each <b>cooperative</b> is <b>computed</b> and these are compared against each other. Agribusiness, Livestock Production/Industries,...|$|R
40|$|In {{this work}} {{the idea of}} {{cooperation}} is applied to wireless communication systems. It is generally accepted that energy consumption is a significant design constraint for mobile handheld systems. We propose a novel method of <b>cooperative</b> task <b>computing</b> by distributing tasks among terminals over the unreliable wireless link. Principles of multi [...] processor energy aware task scheduling are used exploiting performance scalable technologies such as Dynamic Voltage Scaling (DVS). We introduce a novel mechanism referred to as D VS {{and here it is}} shown by means of simulation that savings of 40 % can be achieved...|$|R
50|$|The POLYATOM System was {{the first}} package for ab initio {{calculations}} using Gaussian orbitals that was applied {{to a wide variety}} of molecules. It was developed in Slater's Solid State and Molecular Theory Group (SSMTG) at MIT using the resources of the <b>Cooperative</b> <b>Computing</b> Laboratory. The mathematical infrastructure and operational software were developed by Imre Csizmadia, Malcolm Harrison, Jules Moskowitz and Brian Sutcliffe.|$|E
50|$|In 1958, John Clarke Slater invited Barnett to {{join his}} Solid State and Molecular Theory Group. He was made an Associate Professor of Physics in 1960 and, in 1962, set up an IBM 709 installation, the <b>Cooperative</b> <b>Computing</b> Laboratory (CCL). This {{supported}} heavy computations by several groups at MIT. The SSMTG used {{much of the time}} for molecular and solid state research, attracting many post-doctoral workers from the UK and Canada,.|$|E
50|$|At MIT {{he was an}} Associate Professor of Physics and Director of the <b>Cooperative</b> <b>Computing</b> Laboratory. He {{returned}} to England, to the Institute of Computer Science of the University of London in 1964, {{and then back to}} United States the following year. He worked in industry, and taught at Columbia University 1975-77 and the City University of New York, 1977-96, retiring as an Emeritus Professor. After retirement he focused on symbolic calculation in quantum chemistry and nuclear magnetic resonance.|$|E
40|$|Grid {{computing}} {{for resources}} sharing and distributed computing {{has been researched}} widely in the past. As for distributed spatial datasets, the current centralized administrative scheme may become the system performance bottleneck. This paper presents a distributed <b>cooperative</b> grid <b>computing</b> technology to facilitate complex spatial applications by collaboration among distributed spatial resources. A hierarchical spatial index and communication protocol has been designed for the collaboration, which enables a dynamical choice for the best quality nodes for specified subtasks, synchronized execution, and compensation for a failure to execute a subtask. Also, we present an approach for dynamic resource allocation and distributed transaction mechanics to ensure consistency...|$|R
40|$|This paper {{presents}} {{a method to}} employ particle swarms optimizers in a cooperative configuration. This is achieved by splitting the input vector into several sub-vectors, each which is optimized cooperatively in its own swarm. The application of this technique to neural network training is investigated, with promising results. Keywords: Particle swarms, <b>cooperative</b> learning, optimization <b>Computing</b> Review Categories: G. 1. 6, I. 2. 6...|$|R
50|$|In <b>computing</b> <b>cooperative</b> {{distributed}} {{problem solving}} is a network of semi-autonomous processing nodes working together to solve a problem, typically in a multi-agent system. That {{is concerned with the}} investigation of problem subdivision, sub-problem distribution, results synthesis, optimisation of problem solver coherence and co-ordination. It is closely related to distributed constraint programming and distributed constraint optimization; see the links below.|$|R
50|$|To {{expedite}} their work, Gerard and Sambles {{were sent}} to MIT, to work with Barnett for several months before his return to England, and published several papers with the MIT <b>Cooperative</b> <b>Computing</b> Laboratory as joint affiliation. These included two of the earliest papers that reported the production of built up mathematical formulas, constructed by symbolic calculation, and recorded using computer typesetting software. Gerard and Sambles went on to CERN {{to work on the}} mechanised detection of particle events.|$|E
50|$|The <b>Cooperative</b> <b>Computing</b> Laboratory (CCL) was used, in {{its first}} year by some 400 faculty, {{students}} and staff. These included (1) members of the SSMTG and the CCL running quantum mechanical calculations and non-numeric applications directed by Slater, Koster, Wood and Barnett, (2) the computer-aided design team of Ross, Coons and Mann, (3) members of the Laboratory for Nuclear Science, (4) Charney and Phillips in theoretical meteorology, and (5) Simpson and Madden in geophysics (from 1964 President's report, p. 336-337).|$|E
5000|$|The record passed {{one million}} digits in 1999, earning a $50,000 prize. [...] In 2008 the record passed ten million digits, earning a $100,000 prize and a <b>Cooperative</b> <b>Computing</b> Award from the Electronic Frontier Foundation. Time {{called it the}} 29th top {{invention}} of 2008. Additional prizes are being offered for the first prime number found {{with at least one}} hundred million digits and the first with at least one billion digits. Both the $50,000 and the $100,000 prizes were won by participation in GIMPS.|$|E
40|$|Abstract—ATLAS is a {{particle}} physics experi-ment that will operate, starting in spring 2009 throughout a ten years planned period, at LHC (Large Hadron Collider) at CERN. LHC will achieve a luminosity of 1034 cm− 2 s− 1 {{and will be}} able to explore a large amount of particle physics fields. Its main goal is to detect Higgs boson, the only Standard Model particle yet to be observed. ATLAS is a large international collabo-ration, made up of more than 2000 physicists from thousands of Research Institutes and Universities all over the world. This complexity requires a very <b>cooperative</b> distributed <b>computing</b> and data analysis model, so the emergent GRID Computing technology has been adopted. One of the mai...|$|R
40|$|Abstract- In this paper, {{we present}} a {{condensed}} survey of multiagent systems, with special emphasis on cooperation coordination, conflict resolution and closely related issues; issues that are critical {{for the development of}} large-scale, distributed complex software systems. We then present three different cooperative MAS architecture types, discuss their drawbacks and propose the need for a service driven framework for the development of cooperative multi agent systems. Keywords: Multi-agent systems, <b>cooperative</b> systems, service <b>computing,</b> coordination, conflict resolution. 1...|$|R
40|$|Harvard IL; Darien WI; Short Course; University of Wisconsin-Madison; Vietnam War; College of Agricultural and Life Sciences (CALS); Wisconsin Alumni Research Foundation (WARF); student protests; Ag Hall; Internal Review Board (IRB) and Human Subjects Clearance; Glenn Pound; Ken Shapiro; Leo Walsh; Irving Shain; Madison Area <b>Computing</b> <b>Cooperative</b> (MACC); computers; Roger Wyse; Gambia; US Agency for International Development (USAID); Hays-Hill retitling; {{academic}} staff; Extension Merger (1965); Michael Pollan; food systems; Molly Jahn; Neil Jorgenson; Donna Shalala; John Wiley; David Ward; Carolyn ?Biddy? Martin...|$|R
50|$|The Fürstenallee {{campus is}} located 5 km {{from the main}} campus and is {{connected}} to the main campus via the 'uni-line' bus. Some academic activities of the computer science and Systems engineering departments are held at the Fürstenallee campus. Next to the Fürstenallee building is the world's biggest computer museum, the Heinz Nixdorf Museum Forum. The museum exhibits historic computing technologies used during different eras of human civilization starting from 3000 BC to world war. The Fürstenallee campus houses the research centers such as Heinz Nixdorf Institute, <b>Cooperative</b> <b>Computing</b> and Communication Laboratory (C-Lab) and Software quality lab (S-lab).|$|E
5000|$|To {{begin the}} work of the group, Slater [...] "distilled his {{experience}} with the Hartree self-consistent field method" [...] into (1) a simplification that became known as the Xα method, and (2) a relationship between a feature of this method and a magnetic property of the system. These required computations that were excessive for [...] "pencil and paper" [...] work. Slater was quick to avail the SSMTG of the electronic computers that were being developed. An early paper on augmented plane waves used an IBM card programmed calculator. The Whirlwind was used heavily, then the IBM 704 in the MIT Computation Center and then the IBM 709 in the <b>Cooperative</b> <b>Computing</b> Laboratory (see below).|$|E
50|$|Chalermek Intanagonwiwat is a {{computer}} scientist {{best known for his}} work on directed diffusion under the supervision of Deborah Estrin, Ramesh Govindan, and John Heidemann. In 2013 he moved to San Jose, California to work at Cisco Systems, Inc.Intanagonwiwat earned his bachelor's degree in Computer Engineering from King Mongkut's Institute of Technology Ladkrabang in Thailand and pursued his M.S. and Ph.D. degrees in Computer Science at the University of Southern California, USA. He worked as postdoc researcher at Rutgers University, USA. His research interests include computer networks and distributed systems (particularly, large-scale wireless networks of distributed embedded systems, sensor networks, ad hoc networks, <b>cooperative</b> <b>computing,</b> mobile computing, pervasive computing, and ubiquitous computing). From 2003 - 2013, he taught in the Department of Computer Engineering, Chulalongkorn University.|$|E
40|$|Computing motion on {{the basis}} of the {{time-varying}} image intensity is a difficult problem for both artificial and biological vision systems. We show how gradient models, a well known class of motion algorithms, can be implemented within the magnocellular pathway of the primate’s visual system. Our <b>cooperative</b> algorithm <b>computes</b> optical flow in two steps. In the first stage, assumed to be located in primary visual cortex, local motion is measured while spatial integration occurs in the second stage, assumed to be located in the middle temporal area (MT). The final optical flow is extracted in this second stage using population coding, such that the velocity is represented by the vector sum of neurons coding for motion in different directions. Our theory, relating the single-cell to the perceptual level, accounts for a number of psychophysical and electrophysiological observations and illusions. ...|$|R
40|$|In {{this chapter}} {{we discuss the}} {{advantages}} of a structured model of documents in a cooperative editor. The discussion {{is based on the}} experience gained in developing and using Alliance, a groupware application that allows several users distributed on a network to cooperate for producing documents in a structured way. In addition to the local editing functions made available on each site by a structured editor, the application provides such basic functionalities as management of document storage and remote access to distributed documents. It offers services for managing user interaction and cooperation, for dynamically distributing roles to users, for showing documents through multiple views, for controlling the consistency of modifications, for updating automatically all copies of shared documents, etc. Keywords: cooperative editing, structured documents, distributed documents, group awareness, <b>cooperative</b> mobile <b>computing,</b> computer-supported <b>cooperative</b> work, world-wide web, wide [...] ...|$|R
40|$|This paper {{presents}} a new message-passing algorithm, called Do-UM, for distributed <b>cooperative</b> task <b>computing</b> in synchronous settings where processors may crash, and where any multicasts (or broadcasts) performed by crashing processors are unreliable. We specify the algorithm, prove its correctness and analyse its complexity. We show that its worst case available processor steps is S=Î 9 ̆ 8 t+n [Formula presented] +f(nâ 8 ̆ 89 ̆ 2 f) {{and that the}} number of messages sent is less than n 2 t+ [Formula presented], where n is the number of processors, t is the number of tasks to be executed and f is the number of failures. To assess the performance of the algorithm in practical scenarios, we perform an experimental evaluation on a planetary-scale distributed platform. This also allows us to compare our algorithm with the currently best algorithm that is, however, explicitly designed to use reliable multicast; the results suggest that our algorithm does not lose much efficiency in order to cope with unreliable multicast...|$|R
50|$|An {{enormous}} advance {{was made}} by the mid-1960s with the development of equipment that projects the characters from CRT screens. Alphanumeric Corporation (later Autologic) produced the APS series. Rudolf Hell developed the Digiset machine in Germany. The RCA Graphic Systems Division manufactured this in the U.S. as the Videocomp, later marketed by Information International Inc.. Software for operator-controlled hyphenation was a major component of electronic typesetting. Early work on this topic produced paper tape to control hot-metal machines. C. J. Duncan, at the University of Durham in England, was a pioneer. The earliest applications of computer-controlled phototypesetting machines produced the output of the Russian translation programs of Gilbert King at the IBM Research Laboratories, and built-up mathematical formulas and other material in the <b>Cooperative</b> <b>Computing</b> Laboratory of Michael Barnett at MIT.|$|E
40|$|In {{this paper}} we {{introduce}} <b>Cooperative</b> <b>Computing.</b> <b>Cooperative</b> <b>Computing</b> exploits the physical proximity of nodes in distributed systems. It enables nearby nodes {{to cooperate with}} each other in a controlled manner when a node gets temporarily overloaded. We envision <b>Cooperative</b> <b>Computing</b> to be applicable to MapReduce and Consistent Hashing. We attempt to incorporate <b>Cooperative</b> <b>Computing</b> to the Hadoop MapReduce framework, which results in encouraging performance improvement in job completion times in certain scenarios. ...|$|E
40|$|Grid {{has been}} {{proposed}} to be a promising service-oriented platform for increasingly complex <b>cooperative</b> <b>computing.</b> The platforms of service-oriented Grids are often web-based where participants collaborate to achieve a common goal by sharing scarce Web-Based Computational/Computing Resources (WBCR). To effectively share the WBCR is a challenging problem in boundary-spanning grid environments, particularly when these resources are subject to both static and dynamic usage. To set up a certificate-based usage policy in this paper, we firstly explore a workflow engine-driven SOA-based resource access control mechanism. Then, aiming at setting up a <b>cooperative</b> <b>computing</b> paradigm from the resource sharing perspective, a infrastructure derived from a specific project of SOA&EDSCCE (SOA-Based&Engine-Driven Structured <b>Cooperative</b> <b>Computing</b> Environment) is proposed for promoting its <b>cooperative</b> <b>computing</b> in grid environments based on the control disciplines and the WBCR usage policy. The main contributions of this paper are twofold: 1) a workflow engine-driven SOA-based WBCR sharing mechanism is presented according to the certificate-based usage policy; and 2) a specific infrastructure of <b>cooperative</b> <b>computing</b> is put forward for the collaboration based on the WBCR sharing mechanism...|$|E
40|$|As people {{participate}} in the thousands of global conversations that comprise Usenet news, one thing they do is post their opinions of web resources. Phoaks is a collaborative filtering system that continuously parses, classifies, abstracts and tallies those opinions. About 3, 500 users per day consult Phoaks web pages that reflect the results. Phoaks also features a general architecture for building similar collaborative filtering interfaces to conversational data. We report here on the Phoaks resource recommendation interface, the architecture, and the issues and experience that make up its rationale. Keywords human-computer interaction, human interface, computersupported <b>cooperative</b> work, organizational <b>computing,</b> social filtering, collaborative filtering, data mining...|$|R
40|$|Automated {{cooperative}} {{collision avoidance}} of multiple vehicles is a promising approach to increase road {{safety in the}} future. This approach requires a real-time motion planner which <b>computes</b> <b>cooperative</b> maneuvers of multiple cognitive vehicles. As motion planning is a task of high computational complexity, computing times of the planner have to be traded off against solution quality. This contribution compares several cooperative motion planning algorithms with respect to these criteria. The considered algorithms are a tree search algorithm relying on precomputed lower bounds, the elastic band method, mixed-integer linear programming, and a priority-based approach. Success rates and computing times on various simulated scenarios are reported...|$|R
40|$|Cluster {{computation}} power {{provides a}} promising {{way to improve}} response time in large data warehouses. On the other hand, the use of sampling summaries on the cluster for approximate answering of OLAP queries provides a very flexible system that can provide response time guarantees. In this paper we explore the cluster computation paradigm for data warehouses and summaries. The use of cluster computation in a network with N computers can speedup query processing about N times and further speedup can be obtained using samples instead of the full data. Sampling summaries have been proposed before {{in the context of}} OLAP queries to avoid query processing times that leave users and applications waiting too long when only exploration analysis is required over more or less aggregated data. But while a typical one-node sampling summary is either too small to answer more detailed queries or too slow to provide almost instant response time, summaries over a cluster are extremely fast and are sufficiently large to answer most aggregation query patterns. We explore the implementation and processing of the data warehouse and sampling summaries over a set of nodes for <b>cooperative</b> cluster <b>computing</b> and present experimental results on the subject. 1...|$|R
40|$|The {{utility of}} {{pollination}} for autonomic computing / Holger Kasinger, Bernhard Bauer. - In: Biologically inspired <b>cooperative</b> <b>computing</b> : IFIP 19 th World Computer Congress, TC 10 : 1 st IFIP International Conference on Biologically Inspired <b>Cooperative</b> <b>Computing,</b> August 21 - 24, 2006, Santiago, Chile / ed. by Yi Pan [...] . - New York : Springer, 2006. - S. 55 - 64. - (IFIP International Federation for Information Processing; 216...|$|E
40|$|We {{envision}} {{that during}} the next decade the advances in technology will make sensor networks more powerful. Therefore, they will become part of a larger class of networks of embedded systems that have sufficient computing, communication, and energy resources to support distributed applications. The current software architectures and programming models are not suitable for these new computing environments. We present a distributed computing model, <b>Cooperative</b> <b>Computing,</b> and the Smart Messages software architecture for programming large networks of embedded systems. In <b>Cooperative</b> <b>Computing,</b> distributed applications are dynamic collections of migratory execution units, called Smart Messages, working to achieve a common goal. Virtually, any userdefined distributed application can be implemented using our model. To illustrate this flexibility, we describe the implementation, using Smart Messages, of two previously proposed applications for sensor networks, SPIN and Directed Di#usion. The simulation results for these applications together with micro-benchmark results for our prototype implementation demonstrate that <b>Cooperative</b> <b>Computing</b> is a viable solution for programming networks of embedded systems...|$|E
40|$|The grid {{has been}} {{proposed}} as a promising service-oriented platform for increasingly complex <b>cooperative</b> <b>computing.</b> The platforms of service-oriented grids are often Web-based where participants collaborate to achieve a common goal by sharing scarce Web-Based Computational/ Computing Resources (WBCR). To share the WBCR effectively is a challenging problem in boundary-spanning grid environments, particularly when these resources are subject to both static and dynamic usage. To set up the certificate-based usage policy described in this paper, we first explore a workflow engine-driven SOA-based resource access control mechanism. Then, aiming at setting up a <b>cooperative</b> <b>computing</b> paradigm from the resource sharing perspective, an infrastructure derived from a specific projec...|$|E
40|$|Efficient {{distributed}} {{concurrency control}} {{is one of}} the most significant challenges in building real-time cooperative editing systems. In this paper, we focus on the definition and verification of an integrated set of distributed concurrency control schemes based on a novel consistency model for solving three inconsistency problems: divergence, causality-violation, and intention-violation in real-time cooperative editing systems. Keywords: concurrency control, consistency models, <b>cooperative</b> editing, distributed <b>computing,</b> CSCW. 1 Introduction Cooperative editing systems are very useful and intensively used tools in the rapidly expanding area of CSCW (Computer Supported Cooperative Work) [5, 8, 10, 11, 15, 16]. A cooperative editing system allows multiple users to view and edit a shared document simultaneously from different sites, which are connected by a communication network. Each site typically contains an user interface for generating editing operations and displaying sha [...] ...|$|R
40|$|The {{proliferation}} of sensing and display technologies creates opportunities for proactive displays that can sense and respond appropriately {{to the people}} and activities taking place in their vicinity. A conference provides an ideal context in which to explore the use of proactive displays, as attendees come together for the purpose of mutual revelation, eager both to learn more about others and what others are doing and to tell others about themselves and what they are doing. We will deploy a suite of proactive display applications that can aid and abet this desire for mutual revelation {{in the context of a}} paper presentation session, a demonstration and poster session, and informal break areas at the conference. Keywords Ubiquitous computing, proactive computing, humancomputer interaction, computer-supported <b>cooperative</b> work, social <b>computing,</b> community computing, RFID, public displays, ambient displays...|$|R
40|$|PHOAKS is {{a system}} that {{automatically}} recognizes URLs recommended in Usenet messages and continuously updates a large web site that summarizes the recommendation data. We view the automatically generated pages as "rough drafts" that users help to refine. We report here on the mechanisms that allow users to do this, our rationale for these mechanisms, and the issues raised by involving thousands of remote anonymous users in the continuous design of web content. Keywords human-computer interaction, human interface, computersupported <b>cooperative</b> work, organizational <b>computing,</b> social filtering, collaborative filtering, resource discovery, World Wide Web, Usenet, participatory design, remote evaluation, end user modification. INTRODUCTION The main goal of participatory design [13] is to involve users in the process of system design. It focuses on a specific common design process and style of participation. First, the approach assumes that design (and thus user participation) occurs mos [...] ...|$|R
