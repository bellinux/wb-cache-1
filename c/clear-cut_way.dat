44|7|Public
25|$|Though {{there is}} no <b>clear-cut</b> <b>way</b> to prevent dysthymia from occurring, some {{suggestions}} have been made. Since dysthymia will often first occur in childhood, {{it is important to}} identify children who may be at risk. It may be beneficial to work with children in helping to control their stress, increase resilience, boost self-esteem, and provide strong networks of social support. These tactics may be helpful in warding off or delaying dysthymic symptoms.|$|E
2500|$|The {{rapid growth}} in {{diversity}} of {{school districts in the}} United States has proven that there is an increasing need for new guidelines and standards to be put into practice in able to provide nondiscriminatory assessment procedures to students. [...] Although there is no <b>clear-cut</b> <b>way</b> to appropriately evaluate bias in the assessment of students who are culturally and linguistically diverse, the examiner must carefully consider each situation individually in order to develop an appropriate hypothesis {{that can be used in}} the testing procedure. [...] In developing a hypothesis the school psychologist must eliminate any personal or professional bias that may affect their ability to make informative decisions based on the psychometric data obtained during the assessment process. [...] Best practices prove that school psychologists who are culturally and linguistic competent are more effective in communicating to the individual or student in their native language and thus, eliminating the need for an interpreter. [...] The use of standardized testing also must be taken into account when assessing those who are of minority and lower socioeconomic status since they are so culturally loaded. [...] One must be able to recognize that the difference between the scores is not actually related to the ability or aptitude of the child, but to the incorrect interpretations that have been made based on the result of the scores and the significantly different standardized sample. [...] Another important factor in nondiscriminatory assessment is the ability for a school psychologist to recognize the difference in a bilingual assessment and how to assess bilingual individuals. [...] The apparent preference lies in using well-constructed, theoretically comprehensive, native language tests to non-native test takers rather than using limited and poor tests that are available in the test taker's native language.|$|E
5000|$|... an ethos {{in which}} “work”, as paid employment, has been {{separated}} {{out in a}} <b>clear-cut</b> <b>way</b> from other domains of life.|$|E
40|$|Abstract—Accurate {{power control}} is an {{essential}} requirement {{in the design of}} cellular code-division multiple-access (CDMA) systems. In this paper, we contribute three main themes to the power control problem. First, we derive an efficient algorithm for computing minimal power levels for large-scale networks within seconds. Nice and intuitive conditions for the existence of feasible power solutions follow from this approach. Second, we define the capacity region of a network by the set of effective spreading gains, or data rates, respectively, which can be supplied by the network. This is achieved by bounding the spectral radius of a certain matrix containing system parameters and mutual transmission gain information. It is shown that the capacity region is a convex set. Finally, we reveal an interesting duality between the uplink and downlink capacity region. In a <b>clear-cut</b> analytical <b>way,</b> it substantiates the fact that the uplink is the more restricting factor in cellular radio networks. The same methods carry over to certain models of soft handover. In the case that the channel gains are subject to log-normal shadowing, we introduce the concept of level- capacity regions. Despite the complicated structure, it can still be shown that this set is sandwiched by two convex sets coming arbitrarily close as variance decreases. Index Terms—Capacity region, cellular networks, code-divi-sion multiple access (CDMA), convexity, log-normal fading, soft handover. I...|$|R
40|$|Although {{treatment}} {{guidelines for}} both asthma and {{chronic obstructive pulmonary disease}} (COPD) follow a stepwise, severity-based approach, and share a r epertoire of drugs, {{they have different}} characteristics. While asthma treatment focuses on infl ammation, COPD therapy is symptom-focused. • Asthmatics generally respond better than COPD patients to broncho dilators, but the differences are not necessarily <b>clear-cut</b> – the <b>way</b> in which patients respond is more informative about their disease than whether they respond. • While the use of i nhaled corticosteroids (ICS) as a fi rst-line therapy in asthma i s uncontroversial and backed by a substantial body of evidence, their value in COPD may be restricted to particular phenotypes of the disease. • Combination therapy with ICS and long-acting 2 -agonist (LABA) is the pr fe erred treatment when medium-dose ICS alone does not achieve asthma control. In COPD, combina-tion therapy has been benefi cial in many patients, but the heterogeneity of the disease complicates the picture...|$|R
40|$|Forests are {{becoming}} increasingly fragmented world-wide, creating forest patches with reduced area and greater exposure to human land uses along fragment edges. In this study, we predict the future impacts of anthropogenic edges and fragment size on the future occupancy of deadwood-dwelling fungi in boreal old-growth forest fragments. We used Bayesian models fitted to empirical data to predict 40 years of occupancy dynamics of logs {{by a group of}} old-growth forest indicator fungi and two common fungi under different scenarios of clear-cutting in adjacent forest (0 %, 25 %, 50 % and 100 %) and fragment sizes (1 - 20 ha). Small fragment size (1 - 3 14 ha) and intensified forestry with 50 - 100 % clear-cutting of forest around old-growth forest fragments lead to lower predicted occupancy of old-growth indicator fungi while common generalist species like Fomitopsis pinicola increased. There was a trade-off between fragment size and management, where increasing fragment size buffered the negative long-term effects from increased adjacent clear-cutting. These changes in fungal occupancy at the edge should be accounted for when working towards conservation targets for protected areas, such as the Aichi target 11. Synthesis and applications. Preserve what is left - but buffer for change. Small forest fragments often represent the last vestiges of high habitat quality (i. e. species, structures) in managed forest landscapes. As effective area-based conservation measures for the long-term occupancy of old-growth fungi, small fragments need to be managed to protect species from degrading transient edge effects. Management should focus on increasing the size of conservation areas with permanent buffer zones. Alternatively, non-simultaneous adjacent <b>clear-cutting</b> in a <b>way</b> that reduces the edge effect over time (i. e. dynamic buffers) may increase the effective area and improve performance of set-asides in protecting species of special concern for conservation. Preserve what is left - but buffer for change. Small forest fragments often represent the last vestiges of high habitat quality (i. e. species, structures) in managed forest landscapes. As effective area-based conservation measures for the long-term occupancy of old-growth fungi, small fragments need to be managed to protect species from degrading transient edge effects. Management should focus on increasing the size of conservation areas with permanent buffer zones. Alternatively, non-simultaneous adjacent <b>clear-cutting</b> in a <b>way</b> that reduces the edge effect over time (i. e. dynamic buffers) may increase the effective area and improve performance of set-asides in protecting species of special concern for conservation...|$|R
5000|$|In late 2015 Nassim, {{along with}} Robert J. Frey and Raphael Douady, formed the Real World Risk Institute “to build the {{principles}} and methodology for what we call real-world rigor in decision making and codify a <b>clear-cut</b> <b>way</b> to approach… to provide executive education courses and issue two certificates.” ...|$|E
50|$|Though {{there is}} no <b>clear-cut</b> <b>way</b> to prevent dysthymia from occurring, some {{suggestions}} have been made. Since dysthymia will often first occur in childhood, {{it is important to}} identify children who may be at risk. It may be beneficial to work with children in helping to control their stress, increase resilience, boost self-esteem, and provide strong networks of social support. These tactics may be helpful in warding off or delaying dysthymic symptoms.|$|E
5000|$|After forced {{moves on}} both sides, Kasparov made a desperado move with his knight {{to cause the}} World Team to have doubled pawns. [...] the game was still even, with a knight and two pawns {{balancing}} a rook. Positionally, the World Team had the disadvantages of doubled pawns and a centralized king, but {{the advantage of a}} lead in development and a central pawn mass. With no central pawns, Kasparov had no <b>clear-cut</b> <b>way</b> to expose the black king. In the judgment of many commentators, the World Team was at least equal, and it was perhaps Kasparov who was fighting uphill.|$|E
40|$|This Diploma Thesis called "NATO and WMD: Evolution of {{the threat}} {{construction}} and Alliance's response" deals with the evolution of understanding of Weapons of Mass Destruction (WMD) within the North Atlantic Treaty Organization (NATO). WMD, especially the nuclear ones, have preoccupied NATO since its establishment. However, {{it was only after}} the end of the Cold War that NATO started to focus on WMD as a specific overarching category, consisting of chemical, biological and nuclear (since 9 / 11 also radiological) weapons. Despite the conspicuousness of the concept and increased use of the WMD term, the definition of weapons of mass destruction is not <b>clear-cut.</b> However, the <b>way</b> the actors understand WMD is very important. For this reason, NATO's official discourse is studied as an indicator of how is WMD understood in the Alliance, which will allow to fulfill objectives of this thesis. First, the work intends to analyze how has the WMD threat been constructed and interpreted within the Alliance since the year 1991 until this day. Secondly, this thesis aims to find out what is NATO's response to the dangers posed by the identified WMD threats (i. e. proliferation and terrorism) and identify the concrete measures the Allies undertook to tackle the evolving WMD threat. This thesis is based on [...] ...|$|R
40|$|The {{objective}} {{of this paper is}} to survey what is actually known about the finance-growth relationship based on theory and empirical work. We point out that traditional theoretical models linking financial development and economic growth do not pay sufficient attention to insights emerging from modern information economics. Markets with asymmetric information are not in general constrained Pareto efficient; and increased banking sector competition, following financial liberalization, will not necessarily induce efficient financial intermediation. Increased competition is likely to erode franchise values, which may, in turn, generate an unstable banking environment where gambling behaviour on the part of the banks is prevalent. Increased competition can also discourage relationship-banking, and it disturbs what may actually be a constrained efficient mode of contracting in a dynamic setting characterized by asymmetric information. We argue that these problems are further aggravated by the massive task of building an appropriate institutional and regulatory framework designed to effectively curb imprudent bank behaviour. Turning to the empirical evidence, it is shown that the alledged first-order effect whereby financial development causes growth is not adequately supported by econometric work. The empirical evidence on the finance-growth nexus does not yield any <b>clear-cut</b> picture. By <b>way</b> of conclusion, we question whether financial development, in the sense of increased formal financial sector intermediation in a deregulated environment can be expected to act as 'engine of growth' in the development process; and we argue in favour of a more cautious approach to financial sector reform. Copyright © 2003 John Wiley & Sons, Ltd. ...|$|R
40|$|A {{well known}} {{result in the}} {{economics}} of tort law {{is that in the}} case of a unilateral stochastic externality both a negligence rule and strict liability are in general able to achieve socially optimal precaution. It will be shown in this paper that this equivalence result does no longer hold if imperfect information and multidimensional pollution control activities are considered. It will turn out that a negligence rule may in fact have an adverse effect on the incentives of a potential polluter, causing an uncertain environmental damage, to take appropriate precaution. The change in incentives can be attributed to two effects: immunisation from potential liability and sharpening of incentives for observable precaution diverting effort from unobservable to observable precaution. A standard of negligence tends to distort the choice among different > strategies available in reduction of environmental risks, when pollution control efforts are imperfectly observable to differing degrees. This distortionary effect prevails to an even larger extent if there is no uncertainty with respect to the findings of negligence. Hence, in contrast to one-dimensional models of uncertain negligence, the model presented in this paper implies that when the set of possible strategies in reducing environmental risk is somewhat richer than just a onedimensional decision, uncertainty in verifying the negligent behaviour may actually improve incentives to take preventive pollution control measures compared to a certain standard of due care. Moreover, the polluter's response to changes in the policy parameters are no longer <b>clear-cut</b> in the <b>way</b> that is indicated by the standard model. Under some circumstances, an increase in the standard of negligence may lead to a decline in the level of precautionary pollution control. Therefore, the environmental policy maker has to be very careful when deciding on an optimal second best policy consisting of a divergence of the standard of negligence from the socially optimal level. ...|$|R
5000|$|Previously Cystoderma {{comprised}} a {{wider range}} of species but in 2002 Harmaja separated some of them off into the new genus Cystodermella (for instance Cystoderma cinnabarinum, C. elegans and C. granulosum). [...] The separation was made largely on the basis that the spores in the new genus were not at all amyloid. Those remaining in Cystoderma have weakly to strongly amyloid spores, tend to have a persistent ring and to have arthroconidia. DNA analysis supports the division into the two groups, but further investigation has shown that none of the morphological characteristics distinguish between them in a consistent <b>clear-cut</b> <b>way.</b>|$|E
5000|$|After {{granting}} a writ of certiorari {{and accepting}} {{a case for}} review, the justices may decide against further review of the case. For example, the Court may feel the case presented during oral arguments did not present the constitutional issues in a <b>clear-cut</b> <b>way,</b> and that adjudication of these issues is better deferred until a suitable case comes before the court. In this event the writ of certiorari is [...] "dismissed as improvidently granted" [...] (DIG)—saying, in effect that the Court should not have accepted the case. As with the granting or denial of cert, this dismissal is customarily made using a simple per curiam decision without explanation.|$|E
5000|$|According to Girard, {{the origin}} of {{language}} is also related to scapegoating. After the first victim, after {{the murder of the}} first scapegoat, there were the first prohibitions and rituals, but these came into being before representation and language, hence before culture. And that means that [...] "people" [...] (perhaps not human beings) [...] "will not start fighting again". Girard says: [...] If mimetic disruption comes back, our instinct will tell us to do again what the sacred has done to save us, which is to kill the scapegoat. Therefore it would be the force of substitution of immolating another victim instead of the first. But the relationship of this process with representation is not one that can be defined in a <b>clear-cut</b> <b>way.</b> This process would be one that moves towards representation of the sacred, towards definition of the ritual as ritual and prohibition as prohibition. But this process would already begin prior the representation, you see, because it is directly produced by the experience of the misunderstood scapegoat.|$|E
40|$|International audienceInstructional process {{management}} (encompassing instructional design and classroom management) {{is known to}} be very complex, mainly due to its context and the large and diverse amount of knowledge driving it: content knowledge, pedagogical knowledge (PK), curriculum knowledge, knowledge of learners and their characteristics, knowledge of educational contexts, pedagogical content knowledge, and knowledge of educational ends (Shulman, 1987). This complexity makes researchers unable to detect well-defined practices, and a knowledge base leading to efficient teaching with low training cost is missing (Koedinger, Booth, & Klahr, 2013). The attempts so far to investigate these pieces of knowledge can be categorised in two paths. The first path considers novice vs. expert knowledge comparisons to model knowledge growth across experience (Hogan, Rabinowitz, & Craven, 2003). The second path considers knowledge bases every teacher needs in order to work efficiently. These two paths both have some concerns. Teachers' expertise is not so <b>clear-cut</b> and the <b>way</b> teachers develop it through experience is difficult to model and diagnose. Further, specifying a comprehensive knowledge base about teaching is often externally-driven (Hattie, 2009; Wang, Haertel, & Walberg, 1993), listing a superficial knowledge base of 'what works', often unrelated to teachers' beliefs and knowledge and/or their cognitive abilities. Pedagogical Content Knowledge (PCK), as Shulman (1987, p. 8) argued, is " that special amalgam of content and pedagogy that is uniquely the province of teachers, their own special form of special understanding ". This proposition, as well as Shulman's professional knowledge development model, has become widespread in the educational sciences research field. However, some problems can be raised, notwithstanding its vagueness (" special amalgam ", also see Kind, 2015). First, teaching is mainly seen as a " learned profession " (see Shulman, 1987, p. 9), while the social and informal facet of this activity, relying on mainly innate abilities, remains unaddressed. Second, we refer to van Driel et al. 's (2001) definition of PCK: " the knowledge the teachers must have in order to teach science " (emphasis added) to highlight that the orientation of such a knowledge base is highly prescriptive in nature: it states appropriate knowledge so that anyone having it can be a good teacher, and many research lines have been oriented to differentiating novices from experts with regard to PCK. Third, this model emphasises a unidirectional way in which teachers' beliefs and knowledge 2 influence his or her social behaviour, whereas bidirectional ways are more likely to occur (Rimm-Kaufman & Hamre, 2010). The aim {{of this paper is to}} explore a cognitive way to define teachers' professional knowledge (TPK), arguing that some 'natural' knowledge, stemming from several human social abilities – and, for many of them, animal – is thus engaged in teaching as well. The actions grounded on such knowledge are undertaken automatically or at a low cognitive load due to the nature of the latter. Some theoretical views on teaching include such an assumption (Csibra, 2007; Csibra & Gergely, 2011; Strauss, 2005; Strauss & Ziv, 2012), but so far, little research has investigated teachers' cognitive processes in relation to both natural cognition and Cognitive Load Theory (CLT) (see however Feldon, 2007; Moos & Pitton, 2013). The remainder of this paper seeks firstly to consider teachers' actions through the lens of natural cognition and pedagogy, then to set up a framework for teacher cognition and knowledge, showing that several social abilities and knowledge can be used for teaching purposes, and with a low cognitive load. Then, we describe the abilities for teaching as primary vs. secondary knowledge. Eventually, we use this framework to assess or predict which cognitive load is in relation with teachers' performances according to the CLASS, a renowned classroom observation system...|$|R
50|$|The {{rapid growth}} in {{diversity}} of {{school districts in the}} United States has proven that there is an increasing need for new guidelines and standards to be put into practice in able to provide nondiscriminatory assessment procedures to students. Although there is no <b>clear-cut</b> <b>way</b> to appropriately evaluate bias in the assessment of students who are culturally and linguistically diverse, the examiner must carefully consider each situation individually in order to develop an appropriate hypothesis {{that can be used in}} the testing procedure. In developing a hypothesis the school psychologist must eliminate any personal or professional bias that may affect their ability to make informative decisions based on the psychometric data obtained during the assessment process. Best practices prove that school psychologists who are culturally and linguistic competent are more effective in communicating to the individual or student in their native language and thus, eliminating the need for an interpreter. The use of standardized testing also must be taken into account when assessing those who are of minority and lower socioeconomic status since they are so culturally loaded. One must be able to recognize that the difference between the scores is not actually related to the ability or aptitude of the child, but to the incorrect interpretations that have been made based on the result of the scores and the significantly different standardized sample. Another important factor in nondiscriminatory assessment is the ability for a school psychologist to recognize the difference in a bilingual assessment and how to assess bilingual individuals. The apparent preference lies in using well-constructed, theoretically comprehensive, native language tests to non-native test takers rather than using limited and poor tests that are available in the test taker's native language.|$|E
30|$|The actual {{availability}} of the technology, however, cannot be described in any <b>clear-cut</b> <b>way,</b> as it {{will be determined by}} the laws and regulations of a given country, the international and national guidelines of the professional associations, and the prevailing social and cultural norms in a population.|$|E
40|$| Conclusions. The {{feeding regime}} did not affect, in any <b>clear-cut</b> <b>way,</b> the sensory {{characteristics}} of the test yoghurts. However, those yoghurts manufactured from the TMR-fed cow milk contained more acetaldehyde and, in most cases, showed higher hardness, compared to the yoghurts made from milk produced by the cows kept on the traditional feeding regime...|$|E
40|$|SUMMARY We {{present a}} very simple model for realizing {{directed}} transport with cold atoms {{in a pair of}} periodically flashed optical lattices. The origin of this ratchet effect is explained and its robustness demonstrated under imperfections typical of cold atom experiments. We conclude that our model offers a <b>clear-cut</b> <b>way</b> to implement directed transport in an atom optical experiment. ...|$|E
40|$|Symbolic {{sequences}} {{arising from}} the coarse graining of deterministic dynamical systems continuous in phase space are considered. The extent to which signatures of the time irreversibility and of the nonequilibrium constraints {{at the level of}} the original system, such as fluxes or dissipation, can be identified at the coarse-grained level is analyzed. The roles of the partition, of the time window, and of time averaging in distinguishing in a <b>clear-cut</b> <b>way</b> the equilibrium versus nonequilibrium character of the sequence are brought out. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|Continuing the {{analysis}} in a unified scheme for treating generalized superselection sectors {{based upon the}} notion of selection criteria for states of relevance in quantum physics, we extend the Doplicher-Roberts superselection theory for recovering the field algebra and the gauge group (of the first kind) from the data of group invariant observables to the situations with spontaneous symmetry breakdown: in use of the machinery proposed, the basic structural features of the theory with spontaneously broken symmetry, are clarified in a <b>clear-cut</b> <b>way,</b> such as the degenerate vacua parametrized by the variable belonging to the relevant homogeneous space, the Goldstone modes and condensates. ...|$|E
40|$|Measured by {{share of}} deposits, 83 {{percent of the}} banking {{business}} in India {{is in the hands}} of state or nationalizedbanks, which are banks that are owned by the government, in some, increasingly less <b>clear-cut</b> <b>way.</b> Moreover, eventhe non-nationalized banks are subject to extensive regulations on who they can lend to, in addition to the morestandard prudential regulations. Government control over banks has always had its fans, ranging from Lenin toGerschenkron. While there are those who have emphasized the political importance of public control over banking,most arguments for nationalizing banks are based on the premise that profit maximizing lenders do not necessarilydeliver credit where the social returns are the highes...|$|E
40|$|International audienceWe have {{determined}} by polarized neutron diffraction (PND) the low-temperature molecular magnetic susceptibility tensor of the anisotropic low-spin complex PPh 4 [Fe(III) (Tp) (CN) 3]⋅H 2 O. We found {{the existence of}} a pronounced molecular easy magnetization axis, almost parallel to the C 3 pseudo-axis of the molecule, which also corresponds to a trigonal elongation direction of the octahedral coordination sphere of the Fe(III) ion. The PND results are coherent with electron paramagnetic resonance (EPR) spectroscopy, magnetometry, and ab initio investigations. Through this particular example, we demonstrate the capabilities of PND to provide a unique, direct, and straightforward picture of the magnetic anisotropy and susceptibility tensors, offering a <b>clear-cut</b> <b>way</b> to establish magneto-structural correlations in paramagnetic molecular complexe...|$|E
40|$|Chiroptical spectra such as {{electronic}} circular dichroism (ECD) {{are said}} to be much more sensitive to conformation than their non-chiroptical counterparts, however, it is difficult to demonstrate such a common notion in a <b>clear-cut</b> <b>way.</b> We run DFT and TDDFT calculations on two closely related 1, 1 -diarylmethanols which show mirror-image ECD spectra for the same absolute configuration. We demonstrate that the main reason for the different chiroptical response of the two compounds lies in different conformational ensembles, caused by a single hydrogen-to-methyl substitution. We conclude that two compounds, having the same configuration but different conformation, may exhibit mirror-image ECD signals, stressing the importance and impact of conformational factors on ECD spectra...|$|E
40|$|Forty-three tumors were {{investigated}} {{by means of}} immunofluorescence {{with the use of}} antibodies against the following different classes of intermediate-sized (10 nm) filament proteins: 1) cytokeratins, 2) vimentin, and 3) desmin. In general, the immunologic features of tumor-cell intermediate filaments are those present in their tissue of origin. It can be seen, therefore, that, during neoplastic transformation, there are no major changes in the synthesis of the type of intermediate filament proteins when compared to normal tissues. Immunologic identification of these proteins furnishes the surgical pathologist with a quick and <b>clear-cut</b> <b>way</b> to differentiate tumors of mesenchymal origin from epithelial neoplasms, and in particular to distinguish between malignant lymphomas and lymph node metastases of undifferentiated carcinomas...|$|E
40|$|A lot of {{attention}} has been directed towards recent 8 ̆ 5 nancial crises around the world. It seems that 8 ̆ 5 nancial markets are prone to herding, panics, con-tagion and boom-bust cycles. Empirical {{studies have found that}} short-term ows increase 8 ̆ 5 nancial fragility and also increase the probability of 8 ̆ 5 nancial crises. This study takes a macro-oriented approach and shows that large and volatile short-term ows may be growth inhibiting for emerging markets. This is not the case though for rich countries, where short-term capital ows have no e¤ect on growth. The results in this study indicate that opening up emerging markets capital accounts, which imply increased short-term capital ows, is not a <b>clear-cut</b> <b>way</b> to prosperity...|$|E
40|$|A lot of {{attention}} has been directed towards recent financial crises around the world. Empirical {{studies have found that}} short-term flows increase financial fragility and increase also the probability of financial crises. This study takes a macro-oriented approach and shows that while large and volatile short-term flows have no effect on growth for rich countries, they are growth inhibiting for emerging markets. These results are robust to a large variety of estimation methods and pass stringent extreme bound analysis criteria. Moreover, their magnitude turns out to be of economic importance. The analysis indicates that opening up emerging markets' capital accounts, which implies increased short-term capital flows, is not a <b>clear-cut</b> <b>way</b> to prosperity. Capital flows; Growth; Financial crises; Panel data...|$|E
40|$|We {{study the}} {{relationship}} between chiral symmetry breaking and baryons in holographic QCD. We construct a soliton with unit baryon charge {{in the presence of}} a nonzero mean value of the scalar bifundamental field, which is dual to the chiral condensate. We obtain a relation between the chiral condensate and the mass of the baryon and find in a <b>clear-cut</b> <b>way</b> that at large values of the condensate the holographic soliton is no longer located on the IR wall. Instead it is split into two halves, which are symmetrically located on the left and right flavor branes. On the other hand we find that the local value of the quark condensate is suppressed in the core of the soliton, which is evidence for a partial chiral symmetry restoration inside the baryon. Comment: 26 pages, 8 figure...|$|E
40|$|How {{should an}} {{organization}} be designed {{in order to}} provide its members with minimal incentives to defect? And how does the optimal design depend on the type of strategic interaction between defectors and remaining organizational members? This paper addresses such issues in a game theoretic model of cooperation, in which an organization is formally represented by a connected network, and where gains from cooperation are given by a partition function. We show that critical structural features of the organization depend in a <b>clear-cut</b> <b>way</b> on the sign of spillovers. In particular, positive spillovers favor the adoption of dispersed and centralized forms, while negative spillovers favor cohesive and horizontal ones. Moreover, if the organizational form determines all the communication possibilities of members, a highly centralized organization - the star - emerges under positive spillovers, whereas two horizontal architectures - the circle and the complete - emerge under negative spillovers. Organizational design, networks, group stability, spillovers. ...|$|E
40|$|In the U. S., the Sarbanes-Oxley Act {{made the}} audit {{committee}} responsible for the appointment, compensation and oversight of the auditor. We examine whether this institutional change resolves the alleged problem of an unconscious favoring of the management (Bazerman et al. 1997, 2002, 2006). In our experimental design, we {{make use of the}} particular features of the German institutional setting as it enables us to manipulate the client of the auditor in a realistic and <b>clear-cut</b> <b>way.</b> First, we find that auditors demonstrate professional scepticism in the evaluation of evidence while they issue unbiased audit opinions. Second, we confirm that perceiving financial incentives to be high may bias the audit opinion. Making the auditor accountable to a supervisory board proved helpful in reducing this risk. Third, we show that auditors who perceive the psychological incentives to be high tend to favor the judgment of the management. This effect disappears for experienced auditors...|$|E
30|$|Because not all {{decisions}} are merely rational calculations, {{the theory of}} self-concept maintenance (Mazar et al. 2008) expands this view by adding a further decision criterion: {{the maintenance of a}} person’s self-concept, notably as a good or bad person. According to this approach, people cope with situations, including deviant behavior that generally would negatively impact their self-concept, for instance, by re-categorizing the situation. This means that if the deviant behavior falls below a certain limit, people will deviate without compromising their self-concept in a negative way (Mazar et al. 2008). Transferred to the design of a code, a code of conduct, which defines its regulations in a <b>clear-cut</b> <b>way,</b> for instance by setting forth specific values of accepting and granting gifts, constitutes clear behavioral limits. Such a clear and straightforward code makes it more difficult for people to ‘bend’ the regulations of the code by leaving little to no room for interpretation. Thus, when violating a code’s norm, {{it is more likely that}} a person’s self-concept is negatively affected. As persons strive for maintaining a self-concept as a moral person (Mazar et al. 2008), it is more likely that they abide by the code.|$|E
40|$|When {{researchers}} {{in the field of}} Applied Linguistics or L 2 teachers try to carry out any kind of research, several problems arise. The first one is knowing how to start the process of ‘researching’. The second problem, perhaps more frustrating, arises when one finds out that one cannot grasp the complexities {{to be taken into account}} when getting started on the research task at hand. Third, one has to find out how to adapt the different steps of the research to one’s own situation, context, and degree of knowledge, so that data can later be able appropriately coded and analysed in order to establish some sort of conclusion. Last but not least, a further struggle tends to appear on discovering that what should have been done and what has actually been done are two very different things. This paper aims at improving this situation by establishing in a <b>clear-cut</b> <b>way</b> the three levels any investigation should include –conceptual, methodological and empirical–. Then each framework –level– is described, producing a very specific and up-to-date research agenda in which every specific notion is defined and justified...|$|E
40|$|Abstract. —We {{evaluated}} {{two methods}} for assessing Pacific lamprey Lampetra tri-dentata spawning populations (visual counts of spawning adults and redds) and one method for assessing larval production (emergent ammocoete counts from drift nets) in the South Fork Coquille River, Oregon in 2004 and 2005. All three methods gen-erally provided similar portrayals of timing, duration, {{and magnitude of}} spawning, including greater abundance in 2004 and seasonally bimodal spawning in 2005. We found a linear relationship between adult and redd counts but a high redd to adult ratio that varied seasonally in both years. The high redd to adult ratio {{can be attributed to}} short residence time in spawning areas and temperature or habitat-dependent dif-ferences in detection of adults, both of which can undermine adult count data. Redds had relatively longer persistence and larger numbers compared to adults and therefore may be a more practical survey method, but variable redd shape, size, and age, as well as superimposition, presented significant counting errors. Both adult and redd counts had no <b>clear-cut</b> <b>way</b> to quantify errors. Sampling emergent ammocoetes in the drift allowed detection of low density early and late season spawning and would be the pre...|$|E
40|$|In the aphasic production, the verb-noun (V-N) {{dissociation}} (a condition whereby {{brain damage}} selectively affects {{one of the}} two categories, while sparing the other) may have a different nature in different cases, reflecting semantic, syntactic or grammatical class effects. The observation that the V-N dissociations have a different nature goes in hand with the fact that in Linguistics it is hard to spot out the differences between nouns and verbs in a <b>clear-cut</b> <b>way.</b> In this regard, the nominalization phenomenon is explicative since nominalizations share both nominal and verbal properties. In the literature on aphasia, only few have studies tested how verbal and nominal selective deficits impact on closely related pairs involving verbs and the corresponding nominalizations. The present study aims at verifying whether the aphasic production of nominalizations can be affected by class selective impairments or by semantic/syntactic deficits. It will be showed that the aphasic speakers’ errors enlighten the crucial role played by the event structure, the Aktionsart and the grammatical aspect in the retrieval of the nominalizations. Such conclusions provide neurolinguistic evidence in favour of the idea that some features and properties can cross the boundaries of the verb-noun class distinction...|$|E
40|$|Three {{experiments}} {{were designed to}} clarify the perplexing ability of subjects to discriminate between to-be-remembered (TBR) and to-be-forgotten (TBF) items in memory. After the presentation of each pair of words in a list, sub-jects were first required to solve one to four arithmetic problems and were then cued whether to remember or forget that pair. When subjects were free to use a remember (R) or forget (F) cue in any way they saw fit, their subsequent ability to differentiate TBR and TBF items was impressive, but when subjects were required to retrieve both TBR and TBF word pairs {{in response to an}} R or F cue, respectively, their subsequent ability to differen-tiate TBR and TBF items deteriorated. The results implicate within-list retrieval of TBR items as a potent tagging or strengthening operation that provides a basis on which those items may later be discriminated from TBF items. The "potency " of such events, in terms of their influence on later recall, depends in a <b>clear-cut</b> <b>way</b> on the "depth " (i. e., delay) of retrieval involved, but there are no such comparable effects on later recognition...|$|E
