830|179|Public
25|$|From its {{inception}} in July 1991 to 2006, ICE has transported roughly 550 million passengers, including 67 million in 2005. The <b>cumulative</b> <b>sum</b> of passengers is roughly 1.25 billion in 2015.|$|E
25|$|The Undergraduate {{admission}} test {{is one of}} the most intensive written examinations in Bangladesh. After completion of higher secondary education or A level, a student can submit her or his application for undergraduate admission if he/she fulfills the minimum requirements. Students with the best grades in Mathematics, Physics, Chemistry and English of their higher secondary examination are allowed to sit in the {{admission test}}. The screening process allows 7000 students to sit for the admission test, based on the <b>cumulative</b> <b>sum</b> of grade points in these four subjects. Students have to sit for both a written and an MCQ test for admission. They have to seat for an additional free-hand drawing test in order to get admitted in Architecture. After the admission test, only about 700 students get admitted.|$|E
2500|$|The main {{parameter}} affecting varistor {{life expectancy}} is its energy (Joule) rating. [...] Increasing the energy rating raises the number of (defined maximum size) transient pulses that it can accommodate exponentially {{as well as the}} <b>cumulative</b> <b>sum</b> of energy from clamping lesser pulses. [...] As these pulses occur, the [...] "clamping voltage" [...] it provides during each event decreases, and a varistor is typically deemed to be functionally degraded when its [...] "clamping voltage" [...] has changed by 10%. Manufacturer's life-expectancy charts relate current, severity and number of transients to make failure predictions based on the total energy dissipated {{over the life of the}} part.|$|E
5000|$|Lin, D. Y., Wei, L. J., & Ying, Z. (1993). Checking the Cox {{model with}} <b>cumulative</b> <b>sums</b> of martingale-based residuals. Biometrika, 80(3), 557-572.|$|R
30|$|The CU calculates {{the output}} X-mean, Y-mean {{position}} of the object as well as I-mean gray level intensity of the object as <b>cumulative</b> <b>sums.</b>|$|R
40|$|We {{consider}} some tests {{to detect a}} change-point in a multiple linear regression model. The tests {{are based on the}} maxima of the weighted <b>cumulative</b> <b>sums</b> processes. The limit distributions may be double exponential or maxima of Gaussian processes depending on the set where the maximum of the weighted <b>cumulative</b> <b>sums</b> of residuals is taken. The design-points can be fixed or random. We also give a few applications of our results. linear model change-point strong approximation Wiener process Ornstein [...] Uhlenbeck process...|$|R
50|$|Before the sort, {{create a}} histogram, sorted by hash, {{counting}} {{the number of}} occurrences of each hash in the array. Then create a table with the <b>cumulative</b> <b>sum</b> of each entry in the histogram. The <b>cumulative</b> <b>sum</b> table will then contain the position in the array of each element. The proper place of elements can then be found by a constant-time hashing and <b>cumulative</b> <b>sum</b> table lookup rather than a linear search.|$|E
5000|$|The {{next step}} is {{calculate}} the <b>cumulative</b> <b>sum</b> of the log-likelihood ratio, , as new data arrive: with , then, for i=1,2,..., ...|$|E
5000|$|Thus any {{potential}} dimension reduction may {{be achieved by}} choosing , the number of principal components to be used, through appropriate thresholding on the <b>cumulative</b> <b>sum</b> of the eigenvalues of [...] Since the smaller eigenvalues do not contribute significantly to the <b>cumulative</b> <b>sum,</b> the corresponding principal components may be continued to be dropped {{as long as the}} desired threshold limit is not exceeded. The same criteria may also be used for addressing the multicollinearity issue whereby the principal components corresponding to the smaller eigenvalues may be ignored as long as the threshold limit is maintained.|$|E
5000|$|Multiplication of {{ordinary}} generating functions yields a discrete convolution (the Cauchy product) of the sequences. For example, {{the sequence of}} <b>cumulative</b> <b>sums</b> (compare to the slightly more general Euler-Maclaurin formula) ...|$|R
30|$|In step 4, new prototypes are {{generated}} by calculating <b>cumulative</b> <b>sums</b> of the vectors in each cluster. To simplify the implementation, the <b>cumulative</b> <b>sums</b> are calculated already during the steps 2 and 3. One addition and one subtraction are needed per each vector that changes its cluster. The sums {{of the affected}} clusters (the removed, the new and their neighbors) are then divided {{by the size of}} the cluster. There are N/k vectors both in the removed and in the new cluster, on average. Thus, the number of calculations sums up to 2 N/k[*]+[*] 2 N/k[*]+[*] 2 α[*]=[*]O(N/k) where α denotes to the neighborhood size (see “Neighborhood size” section).|$|R
40|$|Statistical {{process control}} methods and {{possibility}} of their use to solve quality {{problems of the}} output products have been discussed in the article. Variability of the technological process {{and its effect on}} the output products quality have been characterized. Situations which claim interference in the technological process have been described. Different types of Shewhart control cards have been considered: simple control cards by variables and alternative attributes, cards with warning boundaries, <b>cumulative</b> <b>sums</b> cards, exponentially weighed moving averages cards. Besides univariate control cards, Hotteling multivariate control cards and <b>cumulative</b> <b>sums</b> cards which are used to control multi-parameter technological process are discussed in the article. Fields of application of different types of control cards are described...|$|R
5000|$|Using a Fenwick tree it {{requires}} only [...] operations to compute any desired <b>cumulative</b> <b>sum,</b> or more generally {{the sum of}} any range of values (not necessarily starting at zero).|$|E
50|$|From its {{inception}} in July 1991 to 2006, ICE has transported roughly 550 million passengers, including 67 million in 2005. The <b>cumulative</b> <b>sum</b> of passengers is roughly 1.25 billion in 2015.|$|E
50|$|In general, the CUSUM (<b>cumulative</b> <b>sum)</b> and CUSUM-sq (CUSUM squared) {{tests can}} be used to test the {{constancy}} of the coefficients in a model. The bounds test can also be used.|$|E
40|$|For random {{walks in}} which jumps are scaled by <b>cumulative</b> <b>sums</b> of i. i. d. r. v. 's, we {{establish}} the strong law of large numbers, CLT-type theorems, and two results {{related to the}} distributions of the first hitting times. Gambling system Strong law of large numbers Functionals of Wiener processes Boundary crossing...|$|R
40|$|We {{consider}} {{a system of}} difference equation {{similar to those that}} appear as description of <b>cumulative</b> <b>sums.</b> Using Hamel bases, we construct pathological solutions to this system for constant right-hand sides. Also we show that bounded so- lutions do not exist for non-zero right-hand sides, while only constants can be solutions in the homogeneous case...|$|R
40|$|We propose {{tests for}} {{structural}} change in conditional distributions via quantile regressions. To avoid misspecification on the conditioning relationship, we construct the tests {{based on the}} residuals from local polynomial quantile regressions. In particular, the tests are based upon the <b>cumulative</b> <b>sums</b> of generalized residuals from quantile regressions and have power against local alternatives at rat...|$|R
5000|$|As {{its name}} implies, CUSUM {{involves}} {{the calculation of}} a <b>cumulative</b> <b>sum</b> (which {{is what makes it}} [...] "sequential"). Samples from a process [...] are assigned weights , and summed as follows: ...|$|E
5000|$|... where [...] {{denotes the}} mean {{value of the}} time series. [...] is called <b>cumulative</b> <b>sum</b> or profile. This process converts, for example, an i.i.d. white noise process into a random walk.|$|E
5000|$|In {{computer}} science, the prefix sum, <b>cumulative</b> <b>sum,</b> inclusive scan, {{or simply}} scan of {{a sequence of}} numbers [...] is a second sequence of numbers , the sums of prefixes (running totals) of the input sequence: ...|$|E
40|$|AbstractWe obtain limit theorems for {{likelihood}} ratio and <b>cumulative</b> <b>sums</b> tests. In {{the case of}} the {{likelihood ratio}} the centralising and normalising sequences go to infinity and the limit is the Gumbel (double exponential) distribution. The first and the last few observations determine the limit, which also explains why the likelihood ratio test is very powerful on the tails...|$|R
40|$|If X 1, X 2, [...] . are {{independent}} random variables with zero expectation and finite variances, the <b>cumulative</b> <b>sums</b> Sn are, on the average, {{of the order of}} magnitude Sn, where Sn 2 = E(Sn 2). The occasional maxima of the ratios Sn/Sn are surprisingly large and the problem is to estimate the extent of their probable fluctuations...|$|R
40|$|Tests for change-points for {{location}} or regression models are {{often based on}} <b>cumulative</b> <b>sums</b> of recursive residuals. In the context of general estimable parameters (functionals of the underlying distributions), such recursive residuals may be {{defined in terms of}} recursive U-statistics. Along with some invariance principles for recursive U-statistics, asymptotic properties of some proposed tests for change-points are studied...|$|R
5000|$|... #Caption: Each square {{represents}} a pixel, with the top-left value in red representing the energy {{value of that}} said pixel. The value in black represents the <b>cumulative</b> <b>sum</b> of energies leading {{up to and including}} that pixel.|$|E
5000|$|One form of {{tracking}} signal is {{the ratio of}} the <b>cumulative</b> <b>sum</b> of forecast errors (the deviations between the estimated forecasts and the actual values) to the mean absolute deviation. The formula for this tracking signal is: ...|$|E
5000|$|For {{fractional}} Brownian motion (FBM), we have , {{and thus}} , and , where [...] is the Hurst exponent. [...] for FBM {{is equal to}} [...] In this context, FBM is the <b>cumulative</b> <b>sum</b> or the integral of FGN, thus, the exponents of theirpower spectra differ by 2.|$|E
40|$|The {{problem of}} change point in autoregressive process is studied in this article. We propose a Bayesian {{information}} criterion-iterated <b>cumulative</b> <b>sums</b> of squares algorithm {{to detect the}} variance changes in an autoregressive series with unknown order. Simulation results and two examples are presented, where it is shown to have good performances when the sample size is relatively small. ...|$|R
40|$|Minimal area {{regions are}} {{constructed}} for Brownian paths and perturbed Brownian paths. While the theoretical optimal region cannot be obtained in closed form, we provide practical confidence regions based on numerical approximations and local time arguments. These regions {{are used to}} provide informal convergence assessments for both Monte Carlo and Markov Chain Monte Carlo experiments, via the Brownian asymptotic approximation of <b>cumulative</b> <b>sums...</b>|$|R
40|$|Computationally {{inexpensive}} algorithm {{for detecting}} of dispersed transients {{has been developed}} using <b>Cumulative</b> <b>Sums</b> (CUSUM) scheme for detecting abrupt changes in statistical characteristics of the signal. The efficiency of the algorithm is demonstrated on pulsar PSR J 0835 - 4510. Comment: 4 pages, 1 figure, The XXX General Assembly and Scientific Symposium of the International Union of Radio Science, 2011, accepte...|$|R
50|$|In {{statistical}} quality control, the CUSUM (or <b>cumulative</b> <b>sum</b> control chart) is a sequential analysis technique developed by E. S. Page of the University of Cambridge. It is typically used for monitoring change detection.CUSUM {{was announced in}} Biometrika, in 1954, {{a few years after}} the publication of Wald's SPRT algorithm.|$|E
50|$|The {{next step}} is to monitor the {{difference}} between the expected consumption and the actual measured consumption. One of the tools most commonly used for this is the CUSUM, which is the <b>CUmulative</b> <b>SUM</b> of differences. This consists in first calculating the difference between the expected and actual performances (the best fit line previously identified and the points themselves).|$|E
5000|$|The advance-decline {{line is a}} plot of the <b>cumulative</b> <b>sum</b> of {{the daily}} {{difference}} {{between the number of}} issues advancing and the number of issues declining in a particular stock market index. Thus it moves up when the index contains more advancing than declining issues, and moves down when there are more declining than advancing issues. The formula for ADL is: ...|$|E
40|$|We {{describe}} {{the design and}} initial steps to implementation of a computational framework for evaluating outbreak detection methods. The framework will include components for combining simulated and historical data to create artificial outbreaks and components that implement various outbreak detection algorithms. The first algorithms to be implemented are the three <b>Cumulative</b> <b>Sums</b> (cusum) methods described in the CDC Early Aberration Reporting System 1...|$|R
40|$|Goodness-of-fit {{testing is}} {{addressed}} in the stratified proportional hazards model for survival data. A test statistic based on within-strata <b>cumulative</b> <b>sums</b> of martingale residuals over covariates is proposed and its asymptotic distribution is derived under the null hypothesis of model adequacy. A Monte Carlo procedure is proposed to approximate the critical value of the test. Simulation studies are conducted to examine finite-sample performance of the proposed statistic...|$|R
40|$|We obtain limit theorems for {{likelihood}} ratio and <b>cumulative</b> <b>sums</b> tests. In {{the case of}} the {{likelihood ratio}} the centralising and normalising sequences go to infinity and the limit is the Gumbel (double exponential) distribution. The first and the last few observations determine the limit, which also explains why the likelihood ratio test is very powerful on the tails. changepoint likelihood ratio test partial sums Brownian bridge extreme value distribution...|$|R
