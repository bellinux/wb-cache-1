279|419|Public
5000|$|If a <b>centralized</b> <b>architecture</b> {{is used in}} {{a sensor}} network and the central node fails, then the entire network will collapse, however the {{reliability}} of the sensor network can be increased by using a distributed control architecture. Distributed control is used in WSNs for the following reasons: ...|$|E
5000|$|The CMS {{software}} is a <b>centralized</b> <b>architecture</b> using n-tier Java EE architecture with Web Services/Struts framework which works in online mode. All the stakeholders access the applications after user authentication and authorization. The solution has high scalability, flexibility, reliability and is complaint to industry Open Standard specifications. The software solution is :- ...|$|E
50|$|Central server {{architecture}} {{consists of}} a set of 13 server which work in unison. Users access the CMS applications via browser interface. As per the CMS application requirements, the application is deployed in centralized environments with online LAN/WAN (FOIS) connectivity. The CMS system supports the stakeholders and has a <b>centralized</b> <b>architecture</b> based on the deployment pattern. The CMS system supports the browser-based clients originated from respective places.|$|E
5000|$|Cloud Computing: Legal Issues in <b>Centralized</b> <b>Architectures,</b> with Primavera de Filippi, in Net Neutrality {{and other}} {{challenges}} {{for the future of}} the Internet ...|$|R
40|$|Entities {{have been}} {{deserved}} special {{attention in the}} latest years, however their identification is still troublesome. Existing approaches exploit ad hoc services or <b>centralized</b> <b>architectures.</b> In this paper we present a novel approach to recognize naturally emerging entity identifiers built on top of Linked Data concepts and protocols...|$|R
40|$|Learning {{systems are}} {{evolving}} from component based and <b>centralized</b> <b>architectures</b> towards service oriented and decentralized architectures. The standardization of e-learning content and interoperability {{is a powerful}} force in this evolution. In this chapter we put in perspective the evolution of e-learning systems and standards, and argue that specialized services will {{play an important role}} in future learning systems, especially in those targeted for competitive learning. European Commissio...|$|R
50|$|Windows Workgroups, by contrast, is {{the other}} model for {{grouping}} computers running Windows in a networking environment which ships with Windows. Workgroup computers {{are considered to be}} 'standalone' - i.e. there is no formal membership or authentication process formed by the workgroup. A workgroup does not have servers and clients, and hence represents the peer-to-peer (or client-to-client) networking paradigm, rather than the <b>centralized</b> <b>architecture</b> constituted by Server-Client. Workgroups are considered difficult to manage beyond a dozen clients, and lack single sign on, scalability, resilience/disaster recovery functionality, and many security features. Windows Workgroups are more suitable for small or home-office networks.|$|E
3000|$|Considering the JT scheme {{under the}} <b>centralized</b> <b>architecture,</b> {{based on the}} control channel model {{described}} in Section 3.2, TN n will stay silent if [...]...|$|E
40|$|The {{most common}} type of {{photovoltaic}} installation in residential applications is the <b>centralized</b> <b>architecture,</b> but the performance of a <b>centralized</b> <b>architecture</b> is adversely affected when it is subject to partial shading effects due to clouds or surrounding obstacles, such as trees. An alternative modular approach can be implemented using several power converters with partial throughput power processing capability. This paper presents a detailed study of these two architectures for the same throughput power level and compares the overall efficiencies using a set of rapidly changing real solar irradiance data collected by the Solar Radiation Research Laboratory at the National Renewable Energy Laboratory...|$|E
40|$|For the Semantic Web {{vision to}} come true, {{the power of}} {{distributed}} applications needs to be leveraged. But the World Wide Web and its services, {{as we know them}} today, are still largely based on <b>centralized</b> <b>architectures</b> (e. g., client/server). This is the case of recommender systems, which are gaining considerable impact in e-commerce, providing people with recommendations that are personalized and tailored to their very needs. Our ai...|$|R
40|$|The {{decentralized}} {{and distributed}} nature of workflow in organizations demands for support from decentralized and distributed computational systems. However, most conventional workflow applications use <b>centralized</b> <b>architectures.</b> Agent technology {{has proved to}} be an adecuate approach for supporting distributed systems. Research done in the area has tried to improve workflow applications, but paying no attention neither to the structure of the organization nor to the decentralized business process execution. In thi...|$|R
40|$|Decentralized social {{networks}} are an emerging {{solution to the}} privacy issues plaguing mainstream <b>centralized</b> <b>architectures.</b> Social overlays [...] -overlay networks mirroring the social relationships among node owners [...] -are particularly intriguing, as they limit communication within one's friend circle. Previous work investigated efficient protocols for peer-to-peer (P 2 P) dissemination in social overlays, but also showed that the churn induced by users, combined with the topology constraints posed by these overlays, may yield unacceptable latency. In this paper, we combine P 2 P dissemination on the social overlay with occasional access to the cloud. When updates from a friend are not received for a long time, the cloud serves as an external channel to verify their presence. The latter acts as an external channel to check for friend updates, when these are not received for a long time. The outcome is disseminated in a P 2 P fashion, quenching cloud access from other nodes and, if an update exists, speeding dissemination. We show that our protocol performs close to mainstream <b>centralized</b> <b>architectures</b> and incurs only modest monetary costs...|$|R
40|$|Push-to-Talk over Cellular (PoC) is a "walkie-talkie" like voice {{communication}} service over mobile wireless networks, based on Voice over IP (VoIP) technology. The traditional PoC {{defined in the}} Open Mobile Alliance (OMA) specification is a <b>centralized</b> <b>architecture.</b> In this architecture, servers need to be deployed for the PoC service to work and be widely available, presenting a substantial cost to ISPs. Meanwhile, the problem of network congestion and one point failure existing in the <b>centralized</b> <b>architecture</b> may degrade system performance and cause the failure of an entire system. In addition, the traditional floor control based on the <b>centralized</b> <b>architecture,</b> also suffers from the drawbacks of using a centralized controller. In this article, we propose a full-distributed architecture for PoC application (FDPoC) in data packet {{voice communication}}. In the full-distributed architecture, we propose an ALM-based distributed data packet transmission mechanism and a distributed floor control (DFC) algorithm to alleviate the above issues. In terms of average end to end delay, average max end to end delay and average floor determination delay, {{the performance of the}} proposed FDPoC and DFC algorithm are investigated through our analytical model. Â© 2011 IEEE...|$|E
3000|$|... a, {{blackboards}} {{covered by}} {{a thin layer of}} colour with non-zero conductance). In the previous paragraphs of this section, we have shown that two-node UWB sensor network with <b>centralized</b> <b>architecture</b> completely solves the mutual shielding problem in scenario 1 represented by two moving persons.|$|E
40|$|International audienceThis {{research}} work proposes an enriched human perception-based distributed architecture for the multi-party video conferencing services. Rich theoretical {{models of the}} three different architectures: the proposed perception-based distributed architecture, the conventional <b>centralized</b> <b>architecture</b> and perception-based <b>centralized</b> <b>architecture</b> have been constructed by using queuing theory to reflect the traffic generated, transmitted and processed on all three architectures. The performance of these three different architectures has been considered in different aspects from the total waiting time, the point- to-point delay and the required service rates to the total throughput. Together, the modelling tools, the analysis, and the numerical results help to answer the common concern about advantages and disadvantages between the centralized and distributed architectures for the video conferencing service architectur...|$|E
40|$|Abstract. Four {{different}} {{multi-agent system}} architectures for a {{dynamic resource allocation}} problem are presented and evaluated. Although all the architectures use three types of agents, i. e., quantifiers that act on the behalf the providers, allocators that act on the behalf of the customers, and distributors that decide how the available resources should be divided between the customers, they differ {{with respect to the}} degree of distribution of control and the degree of synchronization. The architectures are evaluated through simulation experiments concerning load balancing and overload control of Intelligent Networks. A number of aspects are compared, e. g., how fast the system re-allocates the resources when there are sudden changes in demand, how well the load is balanced between the providers, how well the resources are utilized, how fast a customer gets response, how fairly the system treats the customers, how robust the system is, and the amount of communication overhead. Some of the conclusions are that the asynchronous architectures react faster and that the <b>centralized</b> <b>architectures</b> balance the load better. On the other hand, the <b>centralized</b> <b>architectures</b> have a single point of failure and the asynchronous architectures tend to use more communication overhead. ...|$|R
40|$|Abstract- In {{the current}} global market, {{traditional}} hierarchical approaches for manufacturing scheduling and control donât produce the desired results. It occurs especially in Job-Shop manufacturing configurations. In order {{to overcome the}} limitations that hierarchical and <b>centralized</b> <b>architectures</b> show in new manufacturing systems, many decentralized schemes have been proposed. Most of those proposals are based either on dispatching rules or on market mechanisms. While dispatching rules approximations provide a good solution to manage large number of disturbances, market approaches provide efficiency. This paper presents a multiagent architecture which combines both types of ideas...|$|R
40|$|Conference PaperWe {{apply the}} recent theory of {{information}} processing to a hybrid distributed detection architecture that combines the traditional parallel and tandem architectures. Central to this theory is the Kullback-Leibler discrimination distance and quantity {{known as the}} information transfer ratio, defined as defined as {{the ratio of the}} KL distances between the distributions characterizing the input and output of a system. We characterize the asymptotic performance of proposed hybrid system and compare it with the performance of the parallel, tandem and <b>centralized</b> <b>architectures.</b> We conclude with an illustrative example. National Science Foundatio...|$|R
40|$|In business, the {{retrieval}} of up-to-date, or fresh, information is very important. It {{is difficult for}} conventional search engines based on a <b>centralized</b> <b>architecture</b> to retrieve fresh information, because they {{take a long time}} to collect documents via Web robots. In contrast to a <b>centralized</b> <b>architecture,</b> a search engine based on a distributed architecture does not need to collect documents, because each site makes an index independently. As a result, distributed search engines can be used to retrieve fresh information. However, fast indexing alone is not enough to retrieve fresh information, as support for temporal information based retrieval is also required. In this paper, we describe temporal information retrieval in distributed search engines. In particular, we propose an implementation of temporal ranking. 1...|$|E
30|$|As for {{the network}} loadâs {{comparative}} performance measurements, we observed linear growth patterns for both the centralized and the distributed architectures, with a smaller change rate (slope) for the <b>centralized</b> <b>architecture</b> {{with respect to the}} distributed one. In fact, for discovery of resources related to 10 PIPs, the network load generated in the distributed architecture was 868.9 KB, vs. 197.4 KB generated in the <b>centralized</b> <b>architecture</b> for the same scenario â i.e. a performance improvement of 77.3 %. We also noticed that the generated network load for the case of 1 PIP is higher in the distributed architecture, when compared to the centralized one. This {{is due to the fact}} that, in the <b>centralized</b> <b>architecture,</b> the intermediary broker node performs an initial selection operation, in order to return the most relevant resources (satisfying functional requirements and constraints on dynamic attributes), which results in a more refined resources list and thus a reduction in the size of the resourcesâ description document returned to the VIP. In the distributed scenario case, since the selection is performed by the VIP, the PIP only performs a simple matching operation (based on functional attributes only), thus returning a less refined and larger list of resources to the VIP.|$|E
40|$|We {{describe}} {{the design and}} implementation of SWORD, a scalable resource discovery service for wide-area distributed systems. In contrast to previous systems, SWORD allows users to describe desired resources as a topology of interconnected groups with required intragroup, intergroup, and per-node characteristics, along with the utility that the application derives from specified ranges of metric values. This design gives users the flexibility to find geographically distributed resources for applications that are sensitive to both node and network characteristics, and allows the system to rank acceptable configurations based on their quality for that application. Rather than evaluating a single implementation of SWORD, we explore a variety of architectural designs that deliver the required functionality in a scalable and highly available manner. We discuss the trade-offs of using a <b>centralized</b> <b>architecture</b> as compared to a fully decentralized design to perform wide-area resource discovery. To summarize our results, we found that a <b>centralized</b> <b>architecture</b> based on 4 -node server cluster sites at network-peering facilities outperforms a decentralized DHT-based resource discovery infrastructure with respect to query latency {{for all but the}} smallest number of sites. However, although a <b>centralized</b> <b>architecture</b> shows significant promise in stable environments, we find that our decentralized implementation has acceptable performanc...|$|E
40|$|The first {{generation}} of peer-to-peer file sharing systems followed the traditional client-server paradigm. However, legality and scalability issues have driven the development of decentralized file sharing protocols; {{the most popular of}} these being Gnutella. To date, such systems have been unable to match the quality of service (QoS) offered by <b>centralized</b> <b>architectures.</b> AGnuS improves QoS on Gnutella by increasing file availability, improving network friendliness and increasing file quality. This is achieved by layering caching, load balancing, content-based routing and filtering services on top of the core Gnutella protocol. status: publishe...|$|R
40|$|Search {{engines are}} {{currently}} the standard medium for locating and accessing {{information on the}} Web. However, they may not scale to match the anticipated explosion of Web content since they support only extremely coarse-grained queries and axe based on <b>centralized</b> <b>architectures.</b> In this paper, we discuss how database technology can be successfully utilized to address the above problems. We also present the main features of a prototype Web database system called DIASPORA that we have developed and tested on our campus network. This system supports fine-grained querying and implements a distributed processing architecture...|$|R
40|$|In this paper, {{we present}} the {{implementation}} of an autonomous mobile robot controller developed according {{to the principle of}} a multi-layered hybrid architecture. This architecture is composed of four layers: sensori-motor, behavioral, sequencing, and strategic. The paper describes its general structure and the function of its main elements. It further analyses the development of an example task presenting the advantages of the hybrid architecture. Keywords: Mobile Robotics, Multi-layered Architecture, Behavior-Based Control 1 INTRODUCTION The ability of a mobile robot to achieve reliably tasks in a real environment depends essentially on the architecture of its controller. We use a multi-layered hybrid architecture that combines the advantages of both the behavioral and the <b>centralized</b> <b>architectures.</b> This architecture distributes distinct competence levels on several layers: the top layer is responsible for symbolic planning, the intermediate layers are behavioral-based, and, finally [...] ...|$|R
3000|$|We can {{see that}} in the region where the UEs are close to their serving TNs, a certain TN will stay silent with a {{significantly}} higher probability under the <b>centralized</b> <b>architecture</b> with both JT and CS schemes. From Equations 30 to 33, {{it can be seen that}} [...]...|$|E
40|$|Nowadays, {{real-time}} applications become {{immensely popular}} and available over wireless devices. An emerging technology IEEE 802. 11 Wireless Local Area Network (WLAN) has brought users to have trendy gadgets like smart phones, tablets and laptops. These applications require a fast and efficient handover that guarantee a service {{of security and}} Quality of Service (QoS). However, the users will face disruption which can cause high transition delay while running multimedia services. This paper presents an overview of Control and Provisioning Wireless Access Point (CAPWAP) protocol; a solution to overcome security problem during handover within a large network. Furthermore, we conducted a survey in this paper {{in order to find}} an algorithm that can support seamless handover in <b>centralized</b> <b>architecture.</b> Overall, the paper ends with further work by suggesting a design of CAPWAP protocol using predictive context transfer in <b>centralized</b> <b>architecture...</b>|$|E
30|$|As {{far as we}} are concerned, due to {{a simple}} architecture, <b>centralized</b> <b>architecture</b> is the most popular. In this architecture, the {{interaction}} between mobile terminal and anonymous severs is encrypted to guarantee the security of user requests. The data interaction between anonymous severs and an LBS server adopts plaintext transmission to save system resource.|$|E
40|$|Abstract. The {{decentralized}} {{and distributed}} nature of workflow in organizations demands for support from decentralized and distributed computational systems. However, most conventional workflow applications use <b>centralized</b> <b>architectures.</b> Agent technology {{seems to be}} an adequate approach for supporting distributed systems. We have extended the capacities of a multiagent system for knowledge and information distribution {{in such a way that}} it can handle general workflow processes in a decentralized way. A working prototype is reported, and quantitative experiments have been conducted to show that the distributed workflow process flow control makes possible better scalability than the centralized counterpart. ...|$|R
40|$|This paper {{provides}} an extensive study, from definitions and concepts to a concrete extensible object-oriented software framework, for the challenging application domain represented by virtual worlds. Traditional solutions {{are based on}} <b>centralized</b> <b>architectures</b> and do not scale well. MaD-ViWorld, the prototypal software framework already implemented using Java and RMI by our group, allows for distributing the subspaces (rooms) of a given world on an arbitrarily large number of machines, each running a small server application. This very decentralized implementation strategy, {{as well as the}} simple and systematic way provided in order to populate the world wit...|$|R
40|$|As {{a result}} of {{constant}} demand for the increasing amount of information, traditional <b>centralized</b> computing <b>architectures</b> suffer from lack of robustness, duplication of information, and inadequate system scalability and flexibility. Distributed Intelligent Systems (DIS) show potential in developing management of smart buildings, intelligent transportation, and many other application domains. Peer-to-Peer (P 2 P) information sharing system, a distributed system {{that is based on}} collaboration of peers and efficient use of local computing resources, has the potential to elegantly solve performance issues associated with <b>centralized</b> <b>architectures.</b> In this thesis, we described a prototype based on the Kademlia P 2 P protocol and a geographic binary tree to illustrate the potential of P 2 P networks in a distributed intelligent system for control. We implemented a six-node embedded test bed and used it to evaluate the information publishing/querying functionalities. Three sensing peripherals were utilized to demonstrate the flexibility and robustness of the system. These contributions were combined to demonstrate that P 2 P networks offer a valuable technology for the development of distributed intelligent systems...|$|R
30|$|Most Volunteer Computing {{systems have}} a <b>centralized</b> <b>architecture,</b> with {{communication}} {{going through a}} single server. There are few exceptions and they were created with a smaller scope or environment in mind [9]. In BOINC [3], XtremWeb [10] and Folding@home [2], the server or coordinator must fulfill the role of job scheduler, by handling task distribution and result validation.|$|E
40|$|This paper {{presents}} {{the main components}} of the decision assisting systems. Further on three types of architectures of these systems are described, analyzed, and respectively compared, namely: the network architecture, the <b>centralized</b> <b>architecture</b> and the hierarchical architecture. Comment: 8 pages, exposed on 5 th International Conference "Actualities and Perspectives on Hardware and Software" - APHS 2009, Timisoara, Romani...|$|E
30|$|However, current VC {{systems have}} a <b>centralized</b> <b>architecture</b> that follows a master/worker model, {{as a small}} number of servers is {{responsible}} for task distribution and result validation. This limitation has prevented Volunteer Computing from reaching its true potential. In addition, the single point of failure inevitably creates a bottleneck, as projects expand and storage and network requirements become more demanding.|$|E
40|$|International audienceFault {{tolerance}} is {{a challenging}} requirement in virtualized data centers. While distributed layer 2 routing TRILL-like protocols are robust and scalable, they still lack efficiency upon a link failure. In this paper, we propose a hybrid architecture that achieves the best tradeoff between efficiency of <b>centralized</b> <b>architectures</b> and robustness of distributed ones. This architecture {{is based on}} a centralized controller that ephemerally configures the routing table with alternative paths already computed by the TRILL IS-IS protocol. This ephemeral entry enables service continuity while the TRILL. IS-IS recomputes the definitive route. The experimental evaluation shows that the recovery from the link failure is almost instantanious...|$|R
40|$|P 2 P data {{management}} systems provide a scalable alterna-tive to <b>centralized</b> <b>architectures.</b> Their adoption, however, {{is limited by}} the lack of possibility to control the access to the resources stored in the system. We address this problem in the case of structured P 2 P networks, in particular, when the system is used in a collaborative working environment. We analyze the problem assuming a simple threat model and we systematically explore the solution possibilities. We design and compare access control enforcement techniques which realize the desired functionality by constructing in-dependent networks or by implementing access control at query or at response time. 1...|$|R
40|$|AbstractâMotivated by the {{decentralized}} adaptive {{resource management}} problems, the letter derives recursive expressions for online computation of the conditional decentralized posterior CramÃ©râRao lower bound (PCRLB). Compared to the non-conditional PCRLB, the conditional PCRLB {{is a function}} of the past history of observations made and, therefore, a more accurate representation of the estimatorâs performance and, consequently, a better criteria for sensor selection. Previous algorithms to compute the conditional PCRLB are limited to <b>centralized</b> <b>architectures.</b> Theletteraddressesthisgap. Oursimulations verify the optimality of the conditional dPCRLB by comparing it with the centralized conditional PCRLB in bearing-only tracking applications. Index TermsâBayesian estimation, distributed signal processing, particle filters, PCRLB, sensor resource management. I...|$|R
