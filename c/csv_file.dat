268|358|Public
25|$|The {{statistical}} authorities are also making available bulk data in Comma-separated values (<b>CSV)</b> <b>file</b> format {{which can be}} downloaded from online data warehouse facilities.|$|E
2500|$|The Classification Results (CLR) File Format {{has been}} {{developed}} to exchange the results of manual gating and algorithmic classification approaches in a standard way {{in order to be}} able to report and process the classification. [...] CLR is based in the commonly supported <b>CSV</b> <b>file</b> format with columns corresponding to different classes and cell values containing the probability of an event being a member of a particular class. These are captured as values between 0 and 1. Simplicity of the format and its compatibility with common spreadsheet tools have been the major requirements driving the design of the specification. Although it was originally designed for the field of flow cytometry, it is applicable in any domain that needs to capture either fuzzy or unambiguous classifications of virtually any kinds of objects.|$|E
50|$|Following are {{descriptions}} of the tables required for a valid GTFS data feed. Each table is literally a text <b>CSV</b> <b>file</b> whose filename {{is the name of}} the table, suffixed by '.txt'. So for the 'agency' table below, a <b>CSV</b> <b>file</b> called 'agency.txt' would be included in a valid GTFS feed.|$|E
40|$|An Islandora Solution {{pack for}} the DEFRA DTC archive project to allow users {{to create new}} Measurement objects (see DTC archive data model), upload <b>CSV</b> <b>files</b> to the DTC archive repository, check the {{validity}} of those <b>CSV</b> <b>files</b> against the DTC archive specified formats and generate RDF relating {{to the content of}} the <b>CSV</b> <b>files...</b>|$|R
50|$|Most Delightful Labor {{reports are}} {{available}} for as <b>CSV</b> <b>files.</b>|$|R
5000|$|Data import plugins for plain-text <b>CSV</b> <b>files</b> and MySQL {{database}} ...|$|R
5000|$|Metrics {{and network}} details can be {{exported}} to a <b>CSV</b> <b>file</b> format ...|$|E
5000|$|... {{specifies}} {{a simple}} flat file database table using the <b>CSV</b> <b>file</b> format.|$|E
50|$|Databases {{that include}} {{multiple}} relations cannot be exported {{as a single}} <b>CSV</b> <b>file.</b>|$|E
5000|$|Lists of {{interactions}} can be input using comma-separated-value (<b>CSV)</b> <b>files.</b>|$|R
50|$|<b>CSV</b> <b>files</b> created can {{subsequently}} be exported for import {{into the}} SOTA system.|$|R
5000|$|Import, Export or filter {{data from}} Word, Excel, Project Management or <b>CSV</b> <b>files</b> ...|$|R
5000|$|... email with a CSV (could be zipped) {{attachment}} or an URL to a <b>CSV</b> <b>file</b> (like ShadowServer) ...|$|E
50|$|Data {{download}} allows webmasters {{to access}} the first 1000 results in a <b>CSV</b> <b>file</b> to analyze the results.|$|E
5000|$|Example of a USA/UK <b>CSV</b> <b>file</b> (where the decimal {{separator}} is a period/full stop {{and the value}} separator is a comma): ...|$|E
40|$|The data. tar. gz archive {{contains}} {{data from}} an irradiance monitoring network in Tucson, Arizona {{for the period}} 2014 - 04 - 05 to 2014 - 06 - 30. It includes a sensor metadata <b>csv,</b> <b>csv</b> <b>files</b> for the measurements on each day, and <b>csv</b> <b>files</b> for the clearsky-profiles for each sensor on each day. This data was used to make short-term forecasts of solar irradiance...|$|R
3000|$|The {{datasets}} {{supporting the}} conclusions {{in this article}} have been uploaded to Open Science Framework as <b>CSV</b> <b>files</b> ([URL] [...]...|$|R
50|$|ODI Labs also {{focus on}} {{implementing}} the World Wide Web Consortium's CSV on the Web recommendations via CSVlint, its validator for <b>CSV</b> <b>files.</b>|$|R
5000|$|BlackBerry Domain Administration History Tool — Audits {{configuration}} {{changes to}} the BlackBerry Enterprise Server environment and outputs to a <b>csv</b> <b>file</b> ...|$|E
5000|$|AvailIndex Tool — Analyzes {{log files}} and {{produces}} a snapshot report of user activity {{for a certain}} time in a <b>CSV</b> <b>file.</b>|$|E
50|$|CSVed is a {{freeware}} utility for Windows that loads a <b>CSV</b> <b>file</b> {{with its}} tabular structure and allows editing {{it in an}} efficient way.|$|E
50|$|Oystor {{enables the}} user to import and migrate {{contacts}} from various account and <b>CSV</b> <b>files</b> into one common place to ensure a centralized repository.|$|R
5000|$|Data Access: Web data (e.g., HTML tables, RSS feeds, <b>CSV</b> <b>files),</b> {{external}} databases (e.g., MySQL, Oracle) {{and local}} data files (e.g., Excel, Access, text-delimited data).|$|R
5000|$|Substitution Sections which specify which substitutions {{are used}} {{within the text}} file. Substitutions are similar to Escape Sequences used in some <b>CSV</b> <b>files</b> (e.g. \n).|$|R
50|$|The {{statistical}} authorities are also making available bulk data in Comma-separated values (<b>CSV)</b> <b>file</b> format {{which can be}} downloaded from online data warehouse facilities.|$|E
5000|$|A <b>CSV</b> <b>file</b> {{does not}} require a {{specific}} character encoding, byte order, or line terminator format (some software does not support all line-end variations).|$|E
5000|$|For example, the <b>CSV</b> <b>file</b> format uses a comma as the {{delimiter}} between fields, and an end-of-line indicator as the delimiter between records. For instance: ...|$|E
5000|$|RFC 4180 formalized CSV. It {{defines the}} MIME type [...] "text/csv", and <b>CSV</b> <b>files</b> that follow its rules {{should be very}} widely portable. Among its requirements: ...|$|R
40|$|This {{depository}} {{contains the}} images and associated RSML files used in the paper entitled "Using a structural root system model for an in-depth assessment of root image analysis pipeline" from the same authors. It contains: - 10. 000 simulated root images; - 10. 000 corresponding RSML files; -. <b>csv</b> <b>files</b> containing the ground-truth data for each modelled root system; -. <b>csv</b> <b>files</b> containing the image descriptors extracted using RIA-J; -. tps files containing the shape descriptors data. The codes used with this data is available here: [URL]...|$|R
40|$|These seven files contain online use {{statistics}} for the Joyner Library Collection Guide website ([URL] from 07 / 01 / 2008 - 06 / 30 / 2011. The TSV files have been exported from Google Analytics and uploaded as is. The cleaned up <b>CSV</b> <b>files</b> only contain data for the EAD collection-level pages, not the entire website. All of the <b>CSV</b> <b>files</b> record the number of UPVs (unique page views) received per collection-level page; the FY 2010 file, however, contains additional data {{for the number of}} page views and page view hours...|$|R
5000|$|MessageFlow Tool — Tracks {{the flow}} of mail from the mail server through the BlackBerry Enterprise Server to the BlackBerry {{smartphone}} and provides statistics in a <b>csv</b> <b>file</b> ...|$|E
5000|$|Version 4.2.4.2 of 13. April 2014 {{consolidated}} XML handling {{with one}} single library {{for the whole}} project. It also fixed a possible bug concerning tokens import based on a simple <b>CSV</b> <b>file.</b>|$|E
5000|$|Export {{of texts}} into Microsoft Word with {{automatic}} reference as RTF file, a profile matrix as <b>CSV</b> <b>file</b> {{as well as}} the export of the entire project as MAXQDA (*.mx4) file (Windows only) ...|$|E
40|$|These are {{the scripts}} {{used in the}} Park Notebooks {{digitization}} project. 	copyGoogleDocs. py: python script used to create new Google Spreadsheets from a template via the Python API for Google Docs. 	exportGoogleDocs. py: python script used to download the final spreadsheets to local <b>csv</b> <b>files.</b> Currently has hard-coded paths for download. Should take these as command-line args of from config file. 	checkData. py: python script used to validate the <b>csv</b> <b>files</b> based on columns that we know to be sums of other columns 	checkGoogleDocs. py: python script that uses exportGoogleDocs and checkData to validate the Google Spreadsheets 	checkData. pl: original perl script used to validate the <b>csv</b> <b>files,</b> superseded by checkData. py Final version of scripts etc used for digitization as described in Scientific Data manuscript (in draft stage). This release tag has the 'manuscript' branch from the repository on Github merged into master, and thus includes the last updates to the manuscript draft from that branch...|$|R
50|$|Apache OpenOffice Calc and LibreOffice Calc handle <b>CSV</b> <b>files</b> and pasted {{text with}} a Text Import dialog asking {{the user to}} {{manually}} specify the delimiters, encoding, format of columns, etc.|$|R
50|$|Other table types allow {{access to}} comma-separated values (<b>CSV)</b> <b>files.</b> These tables can participate, for example, in queries with JOINs and simplify {{spreadsheet}} processing and read-write non-durable in-memory data storage.|$|R
