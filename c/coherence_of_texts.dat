11|10000|Public
50|$|Coh-Metrix is a {{computational}} {{tool that}} produces indices of the linguistic and discourse representations of a text. Developed byArthur C. Graesser and Danielle McNamara, Coh-Metrix calculates the <b>coherence</b> <b>of</b> <b>texts</b> on many different measures.|$|E
40|$|Latent Semantic Analysis {{is used as}} a {{technique}} for measuring the <b>coherence</b> <b>of</b> <b>texts.</b> By comparing the vectors for two adjoining segments of text in a high-dimensional semantic space, the method provides a characterization of the degree of semantic relatedness between the segments. We illustrate the approach for predicting coherence through re-analyzing sets of texts from two studies that manipulated the <b>coherence</b> <b>of</b> <b>texts</b> and assessed readers ' comprehension. The results indicate that the method is able to predict the effect of text coherence on comprehension and is more effective than simple term-term overlap measures. In this manner, LSA can be applied as an automated method that produces coherence predictions similar to propositional modeling. We describe additional studies investigating the application of LSA to analyzing discourse structure and examine the potential of LSA as a psychological model of coherence effects in text comprehension...|$|E
40|$|We {{propose a}} simple and {{effective}} metric for automatically evaluating discourse coherence of a text using the outputs of a coreference resolution model. According {{to the idea that}} a writer tends to appropriately utilise coreference relations when writing a coherent text, we introduce a metric of discourse coherence based on automatically identified coreference relations. We empirically evaluated our metric by comparing it to the entity grid modelling by Barzilay and Lapata (2008) using Japanese newspaper articles as a target data set. The results indicate that our metric better reflects discourse <b>coherence</b> <b>of</b> <b>texts</b> than the existing model...|$|E
40|$|We use a {{reliably}} annotated corpus {{to compare}} metrics <b>of</b> <b>coherence</b> based on Centering Theory {{with respect to}} their potential usefulness for text structuring in natural language generation. Previous corpus-based evaluations <b>of</b> the <b>coherence</b> <b>of</b> <b>text</b> according to Centering did not compare the <b>coherence</b> <b>of</b> the chosen <b>text</b> structure with that of the possible alternatives. A corpusbased methodology is presented which distinguishes between Centering-based metrics taking these alternatives into account, and represents therefore a more appropriate way to evaluate Centering from a text structuring perspective...|$|R
40|$|In {{the article}} the author {{discussed}} the problem <b>of</b> <b>coherence</b> <b>of</b> <b>text</b> in German and Polish, namely {{the principle of}} indications on the line <b>of</b> the <b>text.</b> The author established a number of exponents (indicators) of the so called reference <b>of</b> the <b>text</b> whose interpretation has been extended with the aspect of the so called isotopy <b>of</b> the <b>text.</b> The established types of equivalence give a picture of regularity in the structure <b>of</b> the <b>text</b> and point to the systems possibilities and restrictions {{in the field of}} the so called language usage in both languages...|$|R
50|$|For centuries, {{teachers}} and educators {{have seen the}} importance <b>of</b> organization, <b>coherence,</b> and emphasis in good writing. Beginning in the 1970s, cognitive theorists began teaching that reading is really an act of thinking and organization. The reader constructs meaning by mixing new knowledge into existing knowledge. Because {{of the limits of}} the reading ease formulas, some research looked at ways to measure the content, organization, and <b>coherence</b> <b>of</b> <b>text.</b> Although this did not improve the reliability of the formulas, their efforts showed the importance of these variables in reading ease.|$|R
40|$|Many {{theories}} of discourse structure {{rely on the}} idea that the segments comprising the discourse are linked through inferred relations such as causality and temporal contiguity. These theories suggest that the resulting discourse is represented hierarchically. Two experiments examine some of the implications of these hierarchical structures on the perceived <b>coherence</b> <b>of</b> <b>texts.</b> Experiment 1 shows that texts with more levels to their hierarchical structure are judged to be more coherent. Experiment 2 demonstrates that these effects are sensitive to the genre of the text. Specifically, narratives seem to be more affected by manipulation of the discourse structure than procedural texts...|$|E
40|$|Latent Semantic Analysis {{is used as}} a {{technique}} for measuring the <b>coherence</b> <b>of</b> <b>texts.</b> By comparing the vectors for two adjoining segments of text in a highdimensional semantic space, the method provides a characterization of the degree of semantic relatedness between the segments. We illustrate the approach for predicting coherence through re-analyzing sets of texts from two studies that manipulated the <b>coherence</b> <b>of</b> <b>texts</b> and assessed readers' comprehension. The results indicate that the method is able to predict the effect of text coherence on comprehension and is more effective than simple term-term overlap measures. In this manner, LSA can be applied as an automated method that produces coherence predictions similar to propositional modeling. We describe additional studies investigating the application of LSA to analyzing discourse structure and examine the potential of LSA as a psychological model of coherence effects in text comprehension. The Measurement of Textual Coherence with Latent Semantic Analysis. In order to comprehend a text, a reader must create a well connected representation of the information in it. This connected representation is based on linking related pieces of textual information that occur throughout the text. The linking of information is a process of determining and maintaining coherence. Because coherence is a central issue to text comprehension, a large number of studies have investigated the process readers use to maintain coherence and to model the readers' representation of the textual information as well as of their previous knowledge (e. g., Lorch & O'Brien, 1995) There are many aspects of a discourse that contribute to coherence, including, coreference, causal relationships, connectives, and signals. For example, Kintsch and van Dijk [...] ...|$|E
40|$|This paper {{presents}} a theoretical foundation of German intonation. It describes the automatic recognition of focus accents and specifies a recognition algorithm. Results {{of the analyses}} of complex utterances concerning their tonal characteristics are presented. This work {{is based on an}} acoustic-phonetic model of generating the Fo-contour in German. This generative model that contains phonetic and phonological rules is modified in order to recognize focal accents. THE GENERAL FRAMEWORK The present research is carried out in a remarkable and promising context. Through an interdisciplinary research group it has been possible to realize a dream of speech processing: to unite semantics, syntax, speech recognition and the phonetics of intonation. A serious attempt is made to outline a model for the evaluation of focus intonation in spoken dialogue. Semantic focus and its projection into the speech signal, the focus accents, are the common goals of interest. Focussing as coherence of text A typical feature of natural language {{is to be found in}} the <b>coherence</b> <b>of</b> <b>texts,</b> whether they are written or spoken. To be sure, it was relatively late when the insight that natural-language texts are not merely a concatention of grammati-cally permitted sentences became a conscious part of common linguistic knowledge. The natural <b>coherence</b> <b>of</b> <b>texts</b> is achieved by a variety of linguistic and phonetic means. Among these means of expression, the prominence of certain words (contents, semantic parts), the so-called focus, as it appears in texts, re{{presents a}} very important and significant means of clearly marking the connection of semantic parts in consecutive sentences. For the sake of illustra-tion, in the following fragment of text, the focused words are shown as capital letters: Haben Sie schon geHORT? Der alte STRACHSCHEWSKI ist gestorben. Ach [...] . JaJA. Soil wohl ganz PLOTZLICH gekomm ' sein. Im HERBST ha...|$|E
50|$|In LVT, it is {{possible}} for people to rewrite their texts in such a form. This form enables them to reflect on ‘inner connections’ and generate new meanings; but also to experiment with and improve the <b>coherence</b> <b>of</b> the <b>text</b> in doing so. It is, therefore, a method of composition <b>of</b> structured <b>texts.</b>|$|R
40|$|Abstract {{is one of}} the {{important}} parts in one research {{due to the fact that}} it is a kind <b>of</b> short condensed <b>text</b> to represent the whole text. As one research that consists of some aspects such as introduction, objective, methodology, result / discussion, and conclusion, so that an abstract should cover those five aspects. However, in fact many abstracts do not have those five completely. Therefore, an abstract that should be written in 5 separated paragraphs, it is sometimes written in 4, 3, 2, or even 1 paragraph. This might cause the <b>coherence</b> <b>of</b> the <b>text</b> is not good. Besides, in this globalization era, abstract is usually written in two languages, Indonesian and English. Moreover, most of the translators in Indonesia do not focuss on one kind <b>of</b> <b>text</b> but all kinds. As what many experts of translation and linguistics often say that the work of translation is not such an easy job to do. This might cause the result of translation especially related to accuracy, acceptability, and readability is not as good as what it is expected. In line with the background of study above, this research was aimed at investigating the writing format of dissertation abstract, abstract structure and its <b>coherence</b> <b>of</b> <b>text</b> used bot...|$|R
30|$|The {{use of the}} pronoun she in line 5 may {{not cause}} any {{identification}} problems, but certainly disrupts the <b>coherence</b> <b>of</b> the passage and sounds a little odd. In fact, as Vonk et al. point out, the more specific Sally would make “the sentence sound better” (p 304), because it {{marks the beginning of}} a new theme concerning the same discourse referent, i.e. a shift from talking about Sally’s parents’ visit to her weight. The idea of episode boundaries contradicts coherence-based views of reference (e.g. Kehler 2002), which hold that the <b>coherence</b> <b>of</b> a <b>text</b> involving referential terms depends on the salience of the referents. In these accounts, a text is considered coherent if the resolution of reference does not require too much cognitive effort. In line 5 of [9], however, the referent is very clear (i.e. salient) but the use of ‘she’ disrupts the <b>coherence</b> <b>of</b> the <b>text.</b> We can see here that the identifiability of a referent is not the whole story.|$|R
30|$|Understanding as a {{learning}} objective needs more than a comprehension of {{the gist of the}} material carried by the progression of pieces of information: it requires an awareness of the connectivity of these propositions and how they are fashioned to achieve their effects. This directs attention to relational meanings within and between propositions, and to the intentions of the author in expression and design to assist the understanding of readers in ways that enable them to utilize the material within their educational objectives. It is worthwhile to achieve such functional analyses in a principled manner using Rhetorical Structure Theory (RST). This was developed {{from a wide range of}} sources to explain the <b>coherence</b> <b>of</b> <b>texts</b> by considering the functions propositions aim to achieve through the relations they contain. These establish the structural place of each proposition in the text. A key paper is that of Mann and Thompson ([1988]) and RST systems have become well developed and discussed (Taboada and Mann [2008], [2013]).|$|E
40|$|This paper {{proposes a}} method for {{measuring}} semantic similarity between words as a new tool for text analysis. The similarity is measured on a semantic network constructed systematically from {{a subset of the}} English dictionary, LDOCE (Long- man Dictionary of Contemporary English). Spreading activation on the network can directly compute the similarity between any two words in the Longman Defining Vocabulary, and indirectly the similarity of all the other words in LDOCE. The similarity represents the strength of lexical cohesion or semantic relation, and also provides valuable information about similarity and <b>coherence</b> <b>of</b> <b>texts.</b> 1 Introduction A text is not just a sequence of words, but it also has coherent structure. The meaning of each word in a text depends on the structure of the text. Recognizing the structure of text is an essential task in text understanding. [Grosz and Sidner, 1986] One of the valuable indicators of the structure of text is lexical cohesion. [Halliday and Has [...] ...|$|E
40|$|This {{study was}} {{conducted}} in to investigate the relationship of cohesive chains and chain interaction to the <b>coherence</b> <b>of</b> <b>texts.</b> To do this, the following procedure was followed. First, 95 EFL students were asked to write a composition on a particular topic. These texts were scored by three experienced raters based on their perceived degree of coherence. The texts were then ordered from high to low. Thirty high-rated texts were labeled as group A, and thirty low-rated texts were labeled as group B. These texts were analyzed for the presence and frequency of cohesive chain and chain interaction based on the model proposed by Hassan (1989). After collecting the data and statistically analyzing them, the results showed that the texts getting higher coherence scores had a higher proportion of relevant tokens to peripheral ones and a higher proportion of central tokens to non-central ones in comparison to the low-rated texts. Therefore, cohesive chain and chain interaction can be used as an indicator of coherence and has pedagogical and theoretical implications...|$|E
40|$|References {{included}} in multi-document summaries are often problematic. In this paper, {{we present a}} corpus study performed to derive statistical models for the syntactic realization of referential expressions. Our work shows how the syntactic realization of entities can influence the <b>coherence</b> <b>of</b> the <b>text</b> and provides a model for rewriting references in multidocument summaries to smooth disfluencies. ...|$|R
30|$|Apart {{from the}} clause {{complexity}} of the clauses with relevant tokens, {{the study of the}} calibration of cohesive chains with other metafunctions is fore grounded in this analysis. The cohesive chains realize the semantic continuity and the texture <b>of</b> the <b>text.</b> Through the cohesive chains, both identity and similarity, the plot is continuous, with the strings of events and characters under a certain context, in narrative texts. Since the study of cohesive chains reveals the continuity <b>of</b> the <b>text,</b> such a study {{can be seen as the}} basis for further investigation into the textual <b>coherence</b> <b>of</b> a <b>text.</b> As stated in the framework, the realization <b>of</b> <b>coherence</b> at the lexicogrammatical level is reflected in the analysis from the perspectives of the logical and textual metafunctions. In addition, the combination of the logical relations and cohesive chains demonstrates how the semantic continuity <b>of</b> the <b>text</b> is realized grammatically via the progression of the clauses. The different logical relations may have different functions in the creation <b>of</b> the <b>text.</b> The <b>coherence</b> <b>of</b> the <b>text</b> can be expressed by the lexicogrammatical patterns of the combination of the logical and textual.|$|R
5000|$|Coh-Metrix {{can be used}} in many {{different}} ways to investigate the cohesion <b>of</b> the explicit <b>text</b> and the <b>coherence</b> <b>of</b> the mental representation <b>of</b> the <b>text.</b> [...] "Our definition of cohesion consists of characteristics <b>of</b> the explicit <b>text</b> that play some role in helping the reader mentally connect ideas in the text" [...] (Graesser, McNamara, & Louwerse, 2003). The definition <b>of</b> <b>coherence</b> is the subject of much debate. Theoretically, the <b>coherence</b> <b>of</b> a <b>text</b> is defined by the interaction between linguistic representations and knowledge representations. While coherence can be defined as characteristics <b>of</b> the <b>text</b> (i.e., aspects <b>of</b> cohesion) that are likely to contribute to the <b>coherence</b> <b>of</b> the mental representation, Coh-Metrix measurements provide indices of these cohesion characteristics.|$|R
40|$|This article applies a {{methodology}} derived from cognitive semantics, in particular from the theorY of metaphor, {{in order to}} analyse (1) the lexical structures of racist discourse, and (2) their realization {{in a sample of}} French texts representing the spectrum of political parties in the 1980 s. The principal structures rest on the cognitive schema of closed space (container) and on the cognitive schema of physical movement ('path'). From these two schemas emerge, on the one hand, notions of externality, otherness, difference, etc., {{and on the other hand}} notions of exclusion, penetration, assimilation, etc. - notions often linked to a certain conception of the human body. The putting into discourse of these lexical networks contributes to the internal <b>coherence</b> <b>of</b> <b>texts</b> dealing with migration, as well as to the intertextual coherence observable across the domain of public expression. The difference between the political parties in relation to the question of migration seems to lie less in the store of basic concepts than in the degree of explicitness that their texts display. On the basis of the linguistic and textual analyses the article offers, by way of conclusion, five hypotheses on the nature of racist discourse in general and on its relationship to the political evolution of Europe...|$|E
5000|$|Coh-Metrix {{can be used}} in many {{different}} ways to investigate the cohesion <b>of</b> the explicit <b>text</b> and the <b>coherence</b> <b>of</b> the mental representation <b>of</b> the <b>text.</b> [...] "Our definition of cohesion consists of characteristics <b>of</b> the explicit <b>text</b> that play some role in helping the reader mentally connect ideas in the text." [...] The definition <b>of</b> <b>coherence</b> is the subject of much debate. Theoretically, the <b>coherence</b> <b>of</b> a <b>text</b> is defined by the interaction between linguistic representations and knowledge representations. While coherence can be defined as characteristics <b>of</b> the <b>text</b> (i.e., aspects <b>of</b> cohesion) that are likely to contribute to the <b>coherence</b> <b>of</b> the mental representation, Coh-Metrix measurements provide indices of these cohesion characteristics.|$|R
40|$|We {{present a}} novel model to {{represent}} {{and assess the}} discourse <b>coherence</b> <b>of</b> <b>text.</b> Our model assumes that coherent text implicitly favors certain types of discourse relation transitions. We implement this model and apply it towards the text ordering ranking task, which aims to discern an original text from a permuted ordering of its sentences. The experimental results demonstrate that our model is able to significantly outperform the state-ofthe-art coherence model by Barzilay and Lapata (2005), reducing the error rate of the previous approach {{by an average of}} 29 % over three data sets against human upper bounds. We further show that our model is synergistic with the previous approach, demonstrating an error reduction of 73 % when the features from both models are combined for the task. ...|$|R
50|$|His two-volume {{work on the}} New Testament {{argued that}} the Greek text was {{originally}} composed in Hebrew, according to the traditional procedures of midrash. Following Paul Vulliaud, Dubourg emphasised the importance of gematria in showing the <b>coherence</b> <b>of</b> his back-translated <b>text.</b>|$|R
40|$|The constructionist {{theory has}} emerged as a leading {{perspective}} in the field of reading inferences and makes the assumption that readers cannot generate inferences when text is inconsiderate or lacking coherence. The generalization inference has been documented as allowing the reader to condense multiple, consecutive propositions into a singular macroproposition. Research has shown that the genre <b>of</b> a <b>text</b> can affect the perception and the set of processes used by the reader to comprehend text. In the present study, participants read ten short narratives, eight of which contained generalization inference lexical decision tasks with genre and <b>coherence</b> <b>of</b> <b>text</b> manipulated. Participants were shown to be no more likely to draw the generalization inference from incoherent text when primed by genre, but were shown to be capable of drawing the generalization inference from incoherent text. These results do not support the constructionist hypothesis and suggest that further research is needed. Department of Psychological ScienceThesis (M. A. ...|$|R
40|$|The dynamic {{nature of}} modern human social interactions, and the {{increasing}} capability of wireless and mobile devices for creating and sharing contents, open up {{the opportunity for a}} wide dissemination of information through complex knowledge sharing systems. As the shared knowledge components build cognitive ties, there is no real sharing of knowledge without a common understanding of it. In this article, particular emphasis is laid on technologies in Natural Language understanding and knowledge management for providing structured, intelligent access to the continuously evolving content, generated on-line in a pervasive collaborative environment. In detail, robust automated techniques for term extraction and knowledge acquisition are used to tap the information density and the global <b>coherence</b> <b>of</b> <b>text</b> excerpts sampled from both general-purpose and subject-specific social networks. We show empirically that the two sources may exhibit considerable differences in terms of content accessibility and informativeness. Includes: Conference preprint, Powerpoint presentation, Abstract and Biographical notesXAInternationa...|$|R
30|$|Coherence can {{be studied}} from both logical and textual {{perspectives}} in systemic functional linguistics. The logical and textual metafunctions together contribute to the <b>coherence</b> <b>of</b> a <b>text.</b> <b>Coherence</b> is realized through clause complexes and cohesive chains at the lexicogrammatical level from the logical and textual meanings. Clause complex reflects the logical development <b>of</b> the <b>text,</b> while cohesive chains are the threads <b>of</b> a coherent <b>text.</b> The clauses {{that are involved in}} cohesive chains take a more important role in forming a coherent text than others, and thus have the potential to reveal the features <b>of</b> <b>coherence</b> realization.|$|R
40|$|This {{paper is}} focused on use of metal {{materials}} as a bone replacement. For <b>coherence</b> <b>of</b> this <b>text</b> is necessary theoretical preamble which is consisting of describing metal properties, aimed particularly at corrosion, valuation methods of disposition to corrosion and mainly corrosion itself. This paper also includes description of techniques of preparation, which involves selection of material and its procession. Furthermore there are stated results of experiments. Those are amended with pictures...|$|R
40|$|Owners of {{numerous}} quarto {{editions of the}} Geneva Bible, after 1579, were aided by a table of instructions on “Howe to take profite in reading of the holy Scriptures,” which, among other things, invites readers to “Marke and consider the … <b>Coherence</b> <b>of</b> the <b>text,</b> howe it hangeth together. ” The table, compiled by Thomas Grashop of All Souls College, Oxford, {{takes the form of}} a branching diagram of the kind particularly associated with texts by the French logician Petrus Ramus but common in various kinds of early modern book. Such a visual field creates a <b>coherence</b> <b>of</b> hermeneutic techniques to match the supposed <b>coherence</b> <b>of</b> the object of those techniques. Grashop’s choice of words suggests a coherence already present in the text, merely awaiting what Patrick Collinson characterized as a “non-problematical, if strenuous” act of reading. Collinson rightly argued that such a reading, which prioritized doctrinal consistency over historical particularity, was justified by Protestant insistence on the harmony of the Gospels and of the Old Testament and New, on the capacity of the Pauline Epistles (especially Romans) to gloss the rest of the Bible, on the self-interpreting capacity of Scripture; and by a range of less easily formulated assumptions and habits of reading and culture. The terminology of “marking” and “considering” encodes ways of understanding the logical and ontological status <b>of</b> “the <b>coherence</b> <b>of</b> the <b>text.</b> ” This is a category of early modern hermeneutic inquiry and literary experience that deserves our attention...|$|R
40|$|We {{argue in}} this paper that {{sophisticated}} microplanning techniques are required even for mathematical proofs, {{in contrast to the}} belief that mathematical texts are only schematic and mechanical. We demonstrate why paraphrasing and aggregation significantly enhance the flexibility and the <b>coherence</b> <b>of</b> the <b>text</b> produced. To this end, we adopted the <b>Text</b> Structure <b>of</b> Meteer as our basic representation. The type checking mecha- nism <b>of</b> <b>Text</b> Structure allows us to achieve paraphrasing by building comparable combinations of linguistic resources. Specified in terms of concepts in an uniform ontological structure called the Upper Model, our semantic aggregation rules are more compact than similar rules reported in the literature...|$|R
40|$|Database {{indexing}} and retrieval tools can benet enormously {{from the}} automatic detection and processing of textual data in images. We present a new connected-component based method for automatic localization <b>of</b> <b>text</b> in general image database. This technique is robust to font, scale and slant changes and detects superimposed {{as well as}} scene text. We rst use a non linear scale space based on morphological numerical residue (ultimate opening). From this we extract candidate CC using contrast information. We then use a two-step lter to eliminate incorrect CCs: rst by using spatial <b>coherence</b> <b>of</b> <b>text</b> zone to eliminate noise CC then by cor- relation between global geometry and thickness of characters. We then classify the remaining CCs by such criteria as global geom- etry, thickness consistency, contrast and shape regularity. A nal aligning and merging analysis is performed in order to lter out the remaining non-text CCs and to compute the nal bounding boxes <b>of</b> the <b>text</b> zones. The robustness of our approach is proven by the results in the ImagEval evaluation campaign, which database included old postcards, graphic schemes, stamps, indoor and out- door scene images and also images without any textual data. In spite of the wide variety <b>of</b> <b>texts</b> and images our approach obtains interesting results without parameter tuning for each image class. Pages: 177 - 18...|$|R
40|$|Abstract. In {{this paper}} we {{describe}} {{a method to}} obtain summaries focussed on chosen characters <b>of</b> a free <b>text.</b> Summaries are extracted from discourse structures, which resemble rhetorical trees. They are obtained by exploiting cohesion and <b>coherence</b> properties <b>of</b> the <b>text.</b> Evaluation intends to evidence the contribution of each module in the final result. ...|$|R
30|$|Assessment of {{the final}} wiki page: the teacher assesses {{the final version of}} the wiki pages {{developed}} by each group of students. This global assessment is necessary since the actual aim of the task is to produce a good final document for the wiki page. As in any other assignment, it must be assessed by the teacher according to the course syllabus. Furthermore, certain assessment criteria can only be evaluated in {{the final version of the}} page, such as the <b>coherence</b> <b>of</b> the <b>text.</b> From now on, the descriptor for this assessment will be final-assessment.|$|R
40|$|To date, {{researchers}} have proposed {{different ways to}} compute the readability and <b>coherence</b> <b>of</b> a <b>text</b> {{using a variety of}} lexical, syntax, entity and discourse properties. But these metrics have not been defined with special relevance to any particular genre but rather proposed as general indicators of writing quality. In this thesis, we propose and evaluate novel text quality metrics that utilize the unique properties of different genres. We focus on three genres: academic publications, news articles about science, and machine generated text, in particular the output from automatic text summarization systems. ...|$|R
40|$|This paper {{describes}} {{the architecture of}} UAIC 1 ’s Summarization system participating at MultiLing – 2013. The architecture includes language independent text processing modules, but also modules that are adapted for one language or another. In our experiments, the languages under consideration are Bulgarian, German, Greek, English, and Romanian. Our method exploits the cohesion and <b>coherence</b> properties <b>of</b> <b>texts</b> to build discourse structures. The output of the parsing process is used to extract general summaries. obtained as a sequence of discourse clauses extracted from the original text, after obtaining the discourse structure <b>of</b> the <b>text</b> and exploiting the cohesion and coherence properties. ...|$|R
30|$|Coherence is {{referred}} as {{the property of}} “unity” and of “hanging together” (Hasan 1984, p. 181). The study <b>of</b> <b>coherence</b> is always closely related to cohesion. According to Halliday and Hasan (1985 [1989], p. 94), “cohesion is the foundation on which the edifice <b>of</b> <b>coherence</b> is built”, and “the basis for textual coherence lies in cohesion” (Hasan 1984, p. 210). In the present research, cohesion is treated as {{a key factor in}} building up <b>coherence</b> <b>of</b> the <b>text.</b> Cohesion is considered as “the aspect of texture which upholds textuality by making a sequence of sentences hang together as a coherent text” (Hatim & Mason, 1990, p. 210). The cohesive chains serve to connect the units <b>of</b> <b>text,</b> and are taken as threads of semantic sequence <b>of</b> the <b>text.</b> In order to determine how cohesion contributes to coherence, cohesive chains are the focus of this research.|$|R
30|$|According to Higgins et al. [20], the {{semantic}} relationship {{among the various}} rhetorical components dictates the global <b>coherence</b> <b>of</b> the <b>text.</b> Thus, an abstract will not be easily readable and entirely understandable if some rhetorical components are not semantically related to each other. Taking into consideration the rhetorical structure model used for the annotation of our corpus, we expect the Purpose component to present {{a high level of}} semantic similarity to the Methodology, Result and Conclusion components. Conversely, absence of a close relationship between these components and the Purpose may be an indication <b>of</b> a <b>coherence</b> problem.|$|R
2500|$|In 2004, {{the entire}} floor plan of Hauser & Wirth in London was {{given over to}} an {{installation}} by Horn entitled Agua Viva for the exhibition Rings of Lispector [...] The installation consisted of interconnecting rubber tiles into which fragments <b>of</b> <b>text</b> from Hélène Cixous' English translation of Clarice Lispector's Agua Viva (or The Stream of Life) have been embedded in contrasting shades of tan-colored rubber into the floor. Horn manipulated passages <b>of</b> the <b>text</b> to shape partial and overlapping rings and loops, playing with the order and <b>coherence</b> <b>of</b> Lispector's <b>text.</b> The rubber floor's dimensions at Hauser & Wirth London were approximately 1,500 feet square, with each rubber tile 69 inches square. It contained 25 [...] "rubber floor drawings" [...] with additional plain tiles so that the piece would fit wall to wall.|$|R
