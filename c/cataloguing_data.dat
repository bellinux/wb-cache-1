19|733|Public
5000|$|Koha is web-based ILS, with a SQL {{database}} (MySQL preferred) backend with <b>cataloguing</b> <b>data</b> {{stored in}} MARC and accessible via Z39.50 or SRU. The user interface is very configurable and adaptable {{and has been}} translated into many languages. Koha has most of the features that would be expected in an ILS, including: ...|$|E
40|$|Neither the Commission of the European Communities nor {{any person}} acting {{on behalf of}} the {{commission}} is responsible for the use which might be made of the following information This report is published also as a report of the Comittee for the Safety of Nuclear Installation of OECD-NEA Report nr. NEA/CSNI/R(94) 23 <b>Cataloguing</b> <b>data</b> {{can be found at the}} end of this publicatio...|$|E
40|$|Following {{extensive}} international review, version 1. 2 of the ITSEC {{is issued}} for operational use within evaluation and certifications schemes, for a provisional period {{of two years}} from the date of issue. The practical experience acquired {{will be used to}} review and further develop the ITSEC {{at the end of this}} period. In addition, considerations arising from further international harmonisation will also be taken into account. <b>Cataloguing</b> <b>data</b> can be found at the end of this publicatio...|$|E
5000|$|Original <b>catalogue</b> <b>data,</b> 1953-1985, 109293 objects (alternative {{reference}} is Mermilliod, 1987) ...|$|R
5000|$|Z39.83: NISO Circulation Interchange Protocol (NCIP) for library <b>catalogue</b> <b>data</b> {{exchange}} ...|$|R
40|$|Brief {{presentation}} {{about the}} J-PLUS EDR data access web portal ([URL] where the different services available to retrieve images and <b>catalogues</b> <b>data</b> have been presented. J-PLUS Early Data Release (EDR) archive includes {{two types of}} data: images and dual and single <b>catalogue</b> <b>data</b> which include parameters measured from images. J-PLUS web portal offers <b>catalogue</b> <b>data</b> and images through several different online data access tools or services each suited to a particular need. The different services offered are: 	Coverage map 	Sky navigator 	Object visualization 	Image search 	Cone search 	Object list search 	Virtual observatory services: 	 		Simple Cone Search 		Simple Image Access Protocol 		Simple Spectral Access Protocol 		Table Access Protoco...|$|R
40|$|The paper {{presents}} some considerations {{about the}} organisation of catalogues and the functionalities of cataloguing tools {{with respect to}} the role of a public library. The first section focuses on the definition of the public library and its characteristics in a relationship with the catalogue. The second section deals with some problems of cataloguing organisation, specifically with the peculiarity of a public library catalogue as a bibliographic tool, the issue of <b>cataloguing</b> <b>data</b> types in relation to the users and the catalogue language, and catalogue use and its integration with the physical collection management...|$|E
40|$|The {{process of}} {{implementation}} of RDA by Library of Congress, National Agricultural Library, and National Library of Medicine is presented. Each phase of development, test, decision, preparation for implementation of RDA and training about RDA is fully and accurately described and discussed. Benefits from implementation of RDA for the Library of Congress are identified and highlighted: {{more flexibility in}} cataloguing decisions, easier international sharing of <b>cataloguing</b> <b>data,</b> clearer linking among related works; closer cooperation with other libraries in the North American community, production of an online learning platform in order to deliver RDA training {{on a large scale}} in real time to catalogers...|$|E
40|$|Catalogues {{have been}} {{discussed}} for centuries in libraries and it is generally accepted that finding relevant books in any science without a well organised catalogue is almost impossible. Nowadays {{the idea of a}} library with its catalogue entries is transported to all kinds of data, including books, maps, geographic layers, models. The correspondence to the catalogue entries are metadata, i. e. descriptions of the data. In this paper we present the general idea of <b>cataloguing</b> <b>data</b> electronically making them this way searchable for a broader audience. Additionally we present briefly three metadata system for coastal areas developed within the last four years, namely CoastBase, EUROSION and NOKIS. ...|$|E
40|$|Engineers {{frequently}} {{refer to}} catalogues when designing products and by carefully selecting standard components, {{they are able}} to create their own unique systems. Unfortunately, these catalogues tend to serve a limited audience as they favour experienced designers. This research is aimed at developing a software framework that renders <b>catalogue</b> <b>data</b> more accessible to novice designers. The system envisaged is composed of a highly object oriented virtual design environment that allows engineers to develop their products at the conceptual level and then draw on <b>catalogue</b> <b>data</b> as they enter the embodiment and specification phase of the design process. In addition to <b>catalogue</b> <b>data,</b> this design environment must integrate other design aids...|$|R
50|$|All <b>catalogue</b> <b>data</b> are {{available}} online from the Centre de Données astronomiques de Strasbourg.|$|R
5000|$|OPAC-The Online Public Access Catalogue OPAC is {{available}} within university intranet LAN. The building of complete database of library documents is under progress. Hence, presently only the <b>catalogue</b> <b>data</b> of around 2,00,000 old records (Including bound volumes of journals, Thesis & Dissertations, rare books etc.) and <b>catalogue</b> <b>data</b> of new books added w.e.f. Jan 1, 2008 {{is available}}. Now on new books {{data will be}} available only online, it {{will no longer be}} available in the form of Catalogue cards.|$|R
40|$|There {{exists a}} tension between the data {{produced}} in library catalogues presently and the data requirements of an uncertain future. While Linked Data dominates the theoretical and experimental discussion {{of the next generation}} of information discovery, the daily work of the cataloguer remains mostly unchanged. The practice of following standards is essential for <b>cataloguing</b> <b>data,</b> and Resource Description and Access (RDA) attempts {{to bridge the gap between}} legacy data and a future where Linked Data is increasingly important. But in this transitional environment, where cataloguers continue to create MARC records in traditional closed library databases, can cataloguers do something more to prepare for the future to make their data smarter and richer? While Linked Data deals with large aggregations of data, how can the daily work of the cataloguer at present be leveraged to positively impact future aggregate data tasks and requirements? In short, what can the present-day cataloguer do to “prepare the way” for future data needs? To investigate, this paper will discuss several key questions. What does the future, particularly Linked Data, require of <b>cataloguing</b> <b>data?</b> What can cataloguers do to “prepare the way” for this future as they produce granular data on a daily basis? To what extent do current standards, including RDA, help to meet future requirements? Is following standards all that is required, or are there forward-facing data principles and practices that should otherwise inform practice? And, finally, to what extent is creating good data a neutral process independent of specific current or future technologies? The authors will examine these issues in reference to existing data quality models proposed within and outside of the cataloguing literature. Practical suggestions for current cataloguing production practice will be made based on the future needs outlined. ...|$|E
30|$|There was no {{standardized}} login nomenclature {{established for}} those practicing ultrasound in the CSEAC, {{which led to}} difficulty when collating and analyzing the scans due to the differences in information that each person entered upon logging onto an ultrasound machine. Retrospectively cataloguing scans required determination of where each participant was in their medical training {{at the time the}} scan was performed which unfortunately led to a large number of ‘unknown rank’ classifications in the data. In addition, there were some individuals that could not be accurately identified by name so were also given the ‘unknown rank’ designation. A standardized login nomenclature, which includes the student's name and year in training, has now been developed for all participants to ensure consistency throughout the ultrasound programs and assist in <b>cataloguing,</b> <b>data</b> collection, and collating images for each participant's digital portfolio.|$|E
40|$|What is a „Book"? In {{this article}} the author defines {{the book as}} any text carrier {{regardless}} of form. The article starts off with {{an account of the}} Swedish art historian Lars Vilks' activities at Kullaberg in Sweden. Vilks {{is best known for his}} stone sculpture on the beach which was later judged to be a book, given the title Arx, complete with ISBN-number and <b>cataloguing</b> <b>data</b> in the Swedish National Database LIBRIS. The University Library in Lund, which is a deposit library, has claimed a deposit copy, a task which is easier said than done. Arx is 6 meters high and 12 meters wide and weighs 150 tons. With Arx as his starting point the author contends that the definition of a book is not all that simple. He goes on to recount the history of the book starting with oral legends and ending with the electronic book, which he judges to be the next logical step in the cvolutionary proccss of the book. He also cites other examples of unusual books including imaginary books, books that were never written etc...|$|E
50|$|KE EMu is {{considered}} one of the more effective and purpose-designed museum cataloguing programs. particularly in the creation of public interfaces to museum <b>catalogue</b> <b>data.</b>|$|R
30|$|We used {{topographic}} data {{published by}} the Geospatial Information Authority of Japan. Earthquake <b>catalogue</b> <b>data</b> were published by Japan Meteorological Agency. The manuscript was improved by comments from two anonymous reviewers.|$|R
5000|$|... #Caption: London's book market 1700, {{distribution}} of titles according to Term <b>Catalogue</b> <b>data,</b> after dissolving the [...] "Reprinted" [...] section. Poetic and fictional production {{does not yet}} have a unified place.|$|R
40|$|The {{provision}} of multi-lingual web services {{is dependent on}} the creation and maintenance of appropriate multi-lingual metadata. In particular multi-lingual <b>cataloguing</b> <b>data</b> is an essential component of providing access to digital libraries and library catalogues. CAVAL Collaborative Solutions, a consortium of the University Libraries in Victoria and the State Library of Victoria, provides a range of services to the library and information communities throughout Australasia. One of these services is the {{provision of}} multi-language cataloguing, currently CAVAL provides cataloguing services to customer libraries in over sixty languages. Customer libraries come from all sectors- public libraries, state libraries, academic libraries and government and special libraries. Unicode is an international character set developed for the scripts of all the languages of the world. The ability to use the Unicode format was a key factor in the selection of a library management system to support CAVAL’s multi-lingual cataloguing services. The Aleph 500 library management system from Ex Libris was implemented in 2002, and the system was upgraded in 2005. The CAVAL staff involved in the implementation and operation of this system to meet the evolving needs of the CARM (CAVAL Archival and Research Materials...|$|E
40|$|WARNING: you {{may come}} away with ideas not only for {{enriching}} your library system, but for your web site and other web-based library applications as well! Microdata enables search engines and other automated processes {{to make sense of}} the data on a web page — like identifying the title, author, and identification number of a book from all of the other content on a given page. Web pages enhanced with microdata contribute to the semantic web, and in turn are more likely to be incorporated into search engines and advanced web applications. If it sounds like we should publish microdata from Evergreen’s catalogue, you will be pleased to know that Evergreen was (naturally) the first library system to incorporate microdata in its default public catalogue with the 2. 2. 0 release in June 2012. In this session, Dan Scott (the contributor of the schema. org microdata enhancement for Evergreen and a participant in the schemabibex effort to extend schema. org to better support bibliographic data) will discuss the origins of the microdata standards, explain how nominally machine-readable <b>cataloguing</b> <b>data</b> can fit into the machine-actionable semantic web, reflect on the impact that a microdata-enabled catalogue has had at Laurentian University to date, and offer some thoughts about the future of microdata – including the schema. org and RDFa Lite standards...|$|E
40|$|The {{last five}} years have been a period of {{electronic}} revolution in Israeli university libraries. During these years, large scale computerization has been carried out. Introduction of the automated systems to the libraries has improved both local library services {{and the level of}} resource sharing among the libraries. A national network has been created {{under the auspices of the}} governmental office which finances the universities. The aim of this network is to improve co-operation among the libraries. The network is governed by a committee in which library directors are members. This committee is responsible for preparation and supervision of software development. Maintenance of the software is performed centrally. All university libraries use the same software on the same type of hardware. Each participating library had to accept this basic condition in order to receive the special grant for the acquisition of a computer and software. 2 ̆ 7 Aleph 2 ̆ 7, an integrated library system developed in Israel, has been chosen to be the network software. The same search codes are used in all university libraries. This simplifies use for the readers. The libraries 2 ̆ 7 computers are connected by special telecommunication lines. MARC <b>cataloguing</b> <b>data</b> are held on the central network computer. Future plans incIude installation of a facsimile network among university libraries in order to speed up delivery of requested documents. This article deals mainly with the network management...|$|E
40|$|The aim of {{this study}} is to locate {{previously}} unknown stellar clusters from the VISTA variables in the Vía Láctea Survey (VVV) <b>catalogue</b> <b>data.</b> The method, fitting a mixture model of Gaussian densities and background noise using the expectation maximization algorithm to a pre-filtered NIR survey stellar <b>catalogue</b> <b>data,</b> was developed by the authors for the UKIDSS Galactic Plane Survey (GPS). The search located 88 previously unknown mainly embedded stellar cluster candidates and 39 previously unknown sites of star formation in the 562 deg 2 covered by VVV in the Galactic bulge and the southern disk...|$|R
40|$|The paper proposes an {{explicite}} {{formula for}} determining the critical slip value of an induction squirel cage motor based upon five parameters. Three of these parameters - rated slip, rated and breakdown torque are known by <b>catalogue</b> <b>data.</b> Two missing parameters are the arbitrary slip between the rated and critical slip value and the corresponding torque value. These two parameters are to be experimentaly obtained. The breakdown torque value given by <b>catalogue</b> <b>data</b> is usually less accurate than the rated torque value. The proposed formula gives the possibility of analysing the error distribution of the critical slip value obtained from <b>catalogue</b> and measured <b>data</b> {{in comparison with the}} values obtained from the mechanical characteristic based on the physical parameters of an induction motor...|$|R
50|$|The Hipparcos and Tycho-1 Catalogues {{were used}} to create the Millennium Star Atlas: an all-sky atlas of one million stars to visual {{magnitude}} 11. Some 10,000 nonstellar objects are also included to complement the <b>catalogue</b> <b>data.</b>|$|R
40|$|The Urban Regeneration and the Environment Research Programme (URGENT) {{required}} {{a system for}} cataloguing its datasets and enabling its scientific community to discover what data were available to it. This community was multidisciplinary in nature and therefore needed a range of facilities for searching. Of particular importance were facilities to help those unfamiliar with specialist terminology. To meet these needs, four applications were designed and developed: a Metadata Capture Tool for describing datasets {{in compliance with the}} National Geospatial Data Framework (NGDF) standard, a Term Entry Tool for creating an ISO compliant thesaurus, a Thesaurus Builder for merging thesauri and a Search Tool. To encourage users to help in <b>cataloguing</b> <b>data,</b> the capture tools were written as stand alone applications, which users could keep and use to build their own metadatabases. The tools contained export and import facilities that allowed the URGENT Data Centre to build a central database and publish it upon the web. During the development work, it was found necessary to extend the NGDF standard as it could not adequately describe time variant or 3 -D atmospheric datasets. The four applications met their design objectives. However, a number of ergonomic issues will need to be addressed if the system is {{to meet the needs of}} the much larger up coming programmes. The main challenges will be moving from the NGDF standard to the ISO standard, hence bringing the work into line with the recommendations of the INSPIRE Project, and merging the metadatabase with the scientific database, which enable metadata maintenance to be semi-automated. ...|$|E
40|$|Compiling {{and using}} {{information}} about protected areas {{is critical to}} long-term conservation management. Information provides institutional memory, which enables protected areas to critically investigate processes and answer management questions independently. Furthermore, routine collection of information about a protected area highlights priorities and facilitates the wise use of resources. In addition, information collected by protected areas contributes to understanding regional processes and ultimately supports conservation efforts {{in the political arena}} by providing a factual backbone on which assertions and decisions are made. Ideally, a monitoring program for a protected area should reflect the objectives established in the General Management Plan (which also documents the threats the protected area faces). Data can be expensive and tedious to collect; it is important to carefully balance the costs and effort involved in collecting data against its relevance. Forming links to other databases avoids the expense of duplication and strengthens the database’s utility through information sharing. Furthermore, devising ways to include historical data makes new databases immediately useful and additionally strengthens a database. <b>Cataloguing</b> <b>data</b> sources (i. e. metadata) is exceptionally important, as it can save time with editing and can provide indices of data quality. Maintaining links with the original source of the data also facilitates long-term collaborations with other institutions. The Internet provides the largest resource of freely available data and is fundamental for acquiring useful information for park management. Maintaining the flow of information between field staff, managers and donors is important since it boosts morale, provides solidarity, and assists in raising additional funds. There is a tendency for over ambitious projects to become unmanageable and lead to failure. For a database to work it must start very simply and develop with the protected area, growing to fill the niche as it is required...|$|E
40|$|This keynote conference contribution, {{selected}} for the 5 th International Conference on Typography and Visual Communication (University of Nicosia, 3 - 15 June 2013), and published in expanded form on the website [URL] examines current definitions of, and attitudes towards, the Digital Public Space. The research is innovative in setting out a holistic visualisation of key social, economic and technological models underpinning the Digital Public Space, and examining potential ways in which future human interactions and behaviours might be construed within such a framework. The article builds on research undertaken through the Creative Exchange, a £ 4 m Arts and Humanities Research Council Creative Knowledge Exchange Hub for the Creative Economy. This research focuses on two areas, ‘designing the digital public space’ and ‘dynamic structures for growth’, led by Brody with researchers based at the RCA, Lancaster and Newcastle Universities. The text was co-written with John Fass, who contributed research insights in areas of constructionism, narrativity, physical and digital interfaces, and computational thinking, working with Brody to frame key issues raised in the article. The underpinning research was also disseminated through keynote presentations focusing on the modelling of the Digital Public Space and related ethical issues at AHRC ‘Creative Exchange’ events in Manchester and London (2012 - 2013). Drawing on debates associated with ownership, protection, privacy, social applications and governance, the article presents key questions for interrogating contemporary attitudes to the creation and dissemination of human knowledge mediated by digital technologies. Through this approach, the article examines specific issues such as inclusion, learning, community cohesion, memory and social identity, and grounds these in relation to contemporary and historical thought. By expanding current applications of physical, biological and computational models to broadcasting, publishing, exchanging and <b>cataloguing</b> <b>data,</b> the article explores the potential for new approaches to dynamic information, self-organising knowledge spaces, and narrative forms of communication...|$|E
40|$|The HI Parkes All-Sky Survey (HIPASS) Catalogue {{forms the}} largest uniform {{catalogue}} of HI sources compiled to date, with 4, 315 sources identified purely by their HI content. The <b>catalogue</b> <b>data</b> comprise the southern region declination <+ 2 deg of HIPASS, the first blind HI survey {{to cover the}} entire southern sky. RMS noise for this survey is 13 mJy/beam and the velocity range is - 1, 280 to 12, 700 km/s. Data search, verification and parametrization methods are discussed along {{with a description of}} measured quantities. Full <b>catalogue</b> <b>data</b> are made available to the astronomical community including positions, velocities, velocity widths, integrated fluxes and peak flux densities. Also available are on-sky moment maps, position-velocity moment maps and spectra of catalogue sources. A number of local large-scale features are observed in the space distribution of sources including the Super-Galactic plane and the Local Void. Notably, large-scale structure is seen at low Galactic latitudes, a region normally obscured at optical wavelengths. Comment: Accepted for publication in MNRAS. 17 pages, 14 figures. HIPASS <b>catalogue</b> <b>data</b> and paper with higher resolution figures can be downloaded from [URL]...|$|R
40|$|Context. Data mining {{techniques}} must {{be developed}} and applied to analyse the large public data bases containing hundreds to thou-sands of millions entries. Aims. To develop methods for locating previously unknown stellar clusters from the UKIDSS Galactic Plane Survey <b>catalogue</b> <b>data.</b> Methods. The cluster candidates are computationally searched from pre-filtered <b>catalogue</b> <b>data</b> using a method that fits a mixture model of Gaussian densities and background noise using the Expectation Maximization algorithm. The <b>catalogue</b> <b>data</b> contains {{a significant number of}} false sources clustered around bright stars. A large fraction of these artefacts were automatically filtered out before or during the cluster search. The UKIDSS data reduction pipeline tends to classify marginally resolved stellar pairs and objects seen against variable surface brightness as extended objects (or ”galaxies ” in the archive parlance). 10 % or 66 × 106 of the sources in the UKIDSS GPS catalogue brighter than 17 m in the K band are classified as ”galaxies”. Young embedded clusters create variable NIR surface brightness because the gas/dust clouds in which they were formed scatters the light from the cluster members. Such clusters appear therefore as clusters of ”galaxies ” in the catalogue and can be found using only a subset of the <b>catalogue</b> <b>data.</b> The detected ”galaxy clusters ” were finally screened visually to eliminate the remaining false detections due to data artefacts. Besides the embedded clusters the search also located locations of non clustered embedded star formation. Results. The search covered an area of 1302 deg 2 and 137 previously unknown cluster candidates and 30 previously unknown sites of star formation were found...|$|R
40|$|E-Procurement {{solutions}} like ERP {{solutions and}} <b>catalogue</b> <b>data</b> software solutions support materials and product but product service systems (PPS) are treated like exceptions and cannot {{be represented in}} a formal matter. For indirect procurement, different supplier management strategies should be applied, since the involve...|$|R
40|$|Working {{paper about}} the {{implementation}} of Koha at the Biblioteca del Departamento de Física, Facultad de Ciencias Exactas, Universidad Nacional de La Plata, Argentina. This project was subsidized by Foundation Antorchas and the Instituto de Física La Plata (IFLP-CONICET), Argentina. Koha is an open source software. “In open source software, software developers give away {{the fruits of their}} labour in the hopes that others will help them develop the software. ” It is open source software released under the General Public License (GPL), and is distributed under this license. “The gist of the license is that you are free to use, modify and distribute the program at no cost to yourself, provided that modifications you distribute are also released under the GPL… Koha is the world's first open source intergrated library system. Koha is feature-rich but the core features are, and always will be: a library catalogue front end/OPAC; a library system intranet; a circulation tracking system, and, an acquisitions/budgeting system. ” Koha is web-based ILS, with a MySQL database backend with <b>cataloguing</b> <b>data</b> stored in Marc 21 and accessible via Z 39. 50 protocol. The original cataloguing user interface was changed for IsisMarc (Unesco). The user interface is very configurable and adaptable and has been translated into many languages. “Koha has most of the features that would be expected for librarians and members (patrons) are: various web 2. 0 facilities like tagging and RSS feeds; union catalog facility; customizable search circulation and borrower management; full acquisitions system including budgets and pricing information (including supplier and currency conversion); simple acquisitions system for the smaller library;ability to cope with any number of branches, patrons, patron categories, item categories, items, currencies and other data; serials system for magazines or newspapers; reading lists for members. This article is based on a paper that was presented at 3 ª Jornada sobre la Biblioteca Digital Universitaria: "¿Hacia dónde vamos?: avances y desarrollos recientes", Villa María, Córdoba, Argentina, 27 - 28 october, 2005, at Universidad Nacional de Córdoba, Argentina...|$|E
40|$|Merged with {{duplicate}} record 10026. 1 / 737 on 20. 03. 2017 by CS (TIS) This study developed after considerable time spent collating and <b>cataloguing</b> <b>data</b> contained in Ronald Duncan's archive. Familiarisation {{with the material}} led to my identifying a need to explore the elusive nature of the personality that biographical material should hope to uncover. Duncan was prone to mainly confessional writing, a kind of writing that demands a causal inference between life and work. Furthermore, the archive supplies multiple data sources that serve to aid chronology, trace reliability, provide external corroboration and investigate truth-value. My study follows a loosely chronological structure after discerning shifts in his thematic concerns. The years up until the mid-' 60 s are detailed because, from his youth until that time, Duncan is consistently idealistic but expresses preoccupations particularly manifest in society in each period. Chapters 1 and 2 study Duncan's concern with utopian politics (1930 s); Chapter 3, his relationship to religion (1940 s); Chapter 4, his part in West End Theatre in the 1950 s; and Chapters 5 and 6, his tackling of issues of gender and sexuality (1950 s and ' 60 s). Each chapter draws upon the autobiography and-related documents of those years. The thesis refers particularly to Duncan's dramatic writing, avoiding serious analysis of the poetry {{because it has been}} recently researched. Because theatre movements are imbued with popular cultural codes, these and his memoirs are chosen to convey how his texts centralise the idea of authenticity but also manipulate the idea using subjects and characters caught between idealism and despair, the textual and the historical. Consequently, my approach to Duncan's work emphasises subject-hood rather than a pre-textual authorial presence which prompts the reader to seek an explanation for the work in its producer. Theoretical implications emerge from the association of Duncan's autobiographical personalities with the notion of writerly authority and its creations. With Duncan the 'question' of self-hood is ultimately conceived as a process whereby the text is attributed to the author through a complex and disparate set of operations, not referential simply to a real individual, but to several simultaneous selves and subject positions. Displacing a perception of the author as the origin of meaning, webs of intertextual voices are discerned within the texture of discourse. THE RONALD DUNCAN FOUNDATIO...|$|E
40|$|Thesis (MPhil (Rehabilitation) [...] University of Stellenbosch, 2011. ENGLISH ABSTRACT: Research {{evidence}} suggesting {{the link between}} disability and poverty has been increasing {{at an alarming rate}} in recent years. Despite this, there has been very little attention to ensuring representation and inclusion of people with disabilities in poverty reduction processes. However, disability movements and their partners have been increasing pressure to ensure that people with disabilities effectively participate in the development of national development plans targeting poverty reduction. The aim of this qualitative study was to analyze {{the extent to which the}} human rights-based approach can be used as an advocacy tool for mainstreaming disability in the national development processes targeting poverty reduction in Uganda. The study was conducted in Kampala and Kiboga districts, and data were gathered between August and October 2009. Key informant interviews and focus group discussions were used for data collection. Eleven participants were purposively selected to participate in key informant interviews. Using these key informants, the snowballing technique was used to identify twenty people that participated in the two focus group discussions, with each having ten participants. A thematic content analysis was used to analyze data, and this involved coding and <b>cataloguing</b> <b>data</b> into emerging themes and subthemes. The study established that despite several legal frameworks in Uganda, disability mainstreaming is still far from being achieved. Translation of policies into practice was identified as a major challenge, making it difficult for people with disabilities to be meaningfully involved in poverty reduction processes. Negative attitudes and misconception of disability by both policy makers and civil society, were also seen to be contributing to the exclusion of people with disabilities in poverty reduction processes and programmes. Lack of capacity and meaningful political representation of disabled people seem to negatively impact on effective participation, monitoring and evaluation of the poverty-reduction processes in Uganda. The study recommends the need to strengthen capacity and advocacy work among people with disabilities and their promoters to ensure their effective participation and inclusion of disability in the national development agenda. It further recommends the need to adopt the human rights-based approach in any development initiative, ensuring disability mainstreaming in policies and the national development plan, in order to effectively address poverty reduction in Uganda. The researcher also challenges disability and development researchers to engage in more wider-scale studies in order to establish more evidence on the need to adopt the human rights-based approach to national development. AFRIKAANSE OPSOMMING: Navorsingsbewyse wat dui op ‟n verband tussen gestremdheid en armoede het in die afgelope jare onrusbarend toegeneem. Ten spyte hiervan is daar baie min aandag gegee om seker te maak dat gestremde mense by die armoedeverligtingsprosesse verteenwoordig en ingesluit word. Bewegings vir gestremde mense, asook dié bewegings se vennote, het egter al hoe meer druk begin uitoefen om seker te maak gestremde mense neem doeltreffend deel aan nasionale ontwikkelingsplanne wat op armoedeverligting gemik is. Die doel van hierdie kwalitatiewe studie was om te ontleed in watter mate die menseregtebenadering gebruik kan word as ‟n instrument om voorspraak te maak vir die hoofklem wat gestremdheid moet ontvang in die nasionale ontwikkelingsprosesse wat op armoedeverligting in Uganda gemik is...|$|E
40|$|Collaboration {{between the}} music {{librarian}} and data librarian led to these critical questions: What does the intersection between special collections and data management look like? How can libraries use <b>catalogue</b> <b>data</b> to create engaging visualization tools for scholarly investigation? How might we build {{the profile of}} music collections for a wider audience? In this session we will discuss the steps we took to use library <b>catalogue</b> <b>data</b> {{in the context of}} an interactive map and timeline. The <b>catalogue</b> <b>data</b> describes the Saskatchewan Music Collection, a local music collection located at the Education & Music Library, University of Saskatchewan. The collection includes primarily sound recordings and sheet music with a connection to the province, dating from the early 1900 s to the current day. Creating a visualization tool allows us to find evidence of historical narratives and themes within unique or rare library materials. We will speak to some of the challenges faced during the data clean-up process using OpenRefine, the steps taken for geocoding and creating an interactive map in ArcGIS, and the considerations for setting up a data management strategy for this project. A preliminary look at the visualizations will be presented as well as a discussion surrounding the kinds of visualizations that would be appealing for music collections from a discovery perspective...|$|R
50|$|Since 2005 the Design Archives {{has contributed}} <b>catalogue</b> <b>data</b> to the Archives Hub, {{a gateway to}} {{thousands}} of archives across more than 200 UK institutions. Records are added regularly {{as part of the}} Design Archives' ongoing cataloguing programme. Increasingly, digital objects are being added to these records.|$|R
50|$|The ITSD lists all {{available}} <b>catalogue</b> <b>data</b> {{for each individual}} specimen e.g. holding institution, catalogue identification number, sex, date of acquisition, specimen type, source, locality, collector, field number, old or additional catalogue numbers, purchase or exchange information and finally any additional remarks pertaining to the specimen.|$|R
