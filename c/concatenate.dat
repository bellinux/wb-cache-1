553|6631|Public
25|$|It is {{straightforward}} to compute upper bounds for K(s)nbsp&– simply compress the string s with some method, implement the corresponding decompressor in the chosen language, <b>concatenate</b> the decompressor to the compressed string, {{and measure the}} length of the resulting stringnbsp&– concretely, the size of a self-extracting archive in the given language.|$|E
25|$|Galois LFSRs do not <b>concatenate</b> every tap {{to produce}} the new input (the XORing is done within the LFSR, and no XOR gates are run in serial, {{therefore}} the propagation times are reduced to that of one XOR rather than a whole chain), thus {{it is possible for}} each tap to be computed in parallel, increasing the speed of execution.|$|E
500|$|The name [...] of Rule 90 {{comes from}} Stephen Wolfram's binary-decimal {{notation}} for one-dimensional cellular automaton rules. To calculate the notation for the rule, <b>concatenate</b> the new {{states in the}} rule table into a single binary number, and convert the number into decimal: 010110102=9010. Rule 90 has also been called the Sierpiński automaton, due to the characteristic Sierpiński triangle shape it generates, and the Martin–Odlyzko–Wolfram cellular automaton after the early research of [...] on this automaton.|$|E
40|$|Abstract — This paper extends linear-complexity <b>concatenated</b> coding {{schemes to}} {{fountain}} communication over the discretetime memoryless channel. Achievable fountain error exponents for one-level and multi-level <b>concatenated</b> fountain codes are derived. Several important {{properties of the}} <b>concatenated</b> coding schemes in multi-user fountain communication scenarios are demonstrated. Index Terms — coding complexity, <b>concatenated</b> codes, error exponent, fountain communication I...|$|R
40|$|This thesis {{focuses on}} the study of <b>concatenated</b> {{convolutional}} codes and their iterative decoding methodologies. Parallel <b>concatenated</b> convolutional codes (PCCC) and serial <b>concatenated</b> convolutional codes (SCCC) are studied to explore their potential to approximate Shannon's channel capacity with feasible complexity...|$|R
40|$|AbstractWe here {{introduce}} a new formalism for describing <b>concatenated</b> codes. Using this formalism, we show how any generalized <b>concatenated</b> code {{can be viewed as}} a first order <b>concatenated</b> code. Finally, we give an illustrative example: using Jensen's result (1985) which shows that any abelian code has a generalized <b>concatenated</b> structure, we first give the representation of the [49, 18, 12] abelian code introduced by Camion (1971) as a second order <b>concatenated</b> code; then using our description, we show that this code is also equal to the first order concatenation of two linear cyclic codes...|$|R
500|$|Python makes a {{distinction}} between lists and tuples. Lists are written as , are mutable, and cannot {{be used as the}} keys of dictionaries (dictionary keys must be immutable in Python). Tuples are written as (1, 2, 3), are immutable and thus can be used as the keys of dictionaries, provided all elements of the tuple are immutable. The + operator can be used to <b>concatenate</b> two tuples, which does not directly modify their contents, but rather produces a new tuple containing the elements of both provided tuples. Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t, thereby effectively [...] "modifying the contents" [...] of t, while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.|$|E
2500|$|... (<b>concatenate</b> 'string [...] "abc [...] " [...] "def [...] " [...] "ghi") [...] returns [...] "abc def ghi" ...|$|E
2500|$|... {{where the}} {{notation}} aS(aminus&1) means {{take all the}} strings in S(aminus&1) and <b>concatenate</b> them on the left with a.|$|E
40|$|In this paper, {{we compare}} the latency of {{serially}} <b>concatenated</b> convolutional codes. In particular, we compare RSC-RSC   <b>concatenated</b> codes using non-iterative <b>concatenated</b> Viterbi decoding to RS-RSC <b>concatenated</b> codes using concatenation of Viterbi & Berklelamp-Massey decoding. We have also used puncturing to obtain different code rates & analyzed {{the effect of}} code rate on latency. On the basis of simulations, it is shown that RSC-RSC code is better than RS-RSC codes for low latency applications. It is also shown that a trade-off is needed between BER & latency for <b>concatenated</b> codes...|$|R
40|$|This paper extends linear-complexity <b>concatenated</b> coding {{schemes to}} {{fountain}} communication over the discrete-time memoryless channel. Achievable fountain error exponents for one-level and multi-level <b>concatenated</b> fountain codes are derived. It is {{also shown that}} <b>concatenated</b> coding schemes possess interesting properties in several multi-user fountain communication scenarios...|$|R
40|$|A {{parallel}} <b>concatenated</b> {{coding scheme}} {{consists of two}} simple systematic constituent encoders linked by an interleaver. The input bits to the first encoder are scrambled by the interleaver before entering the second encoder. The codeword of the parallel <b>concatenated</b> code consists of the input bits followed by the parity check bits of both encoders. The authors propose a method to evaluate the bit error probability of a parallel <b>concatenated</b> coding scheme {{in a way which}} is independent from the interleaver used. The two cases of parallel <b>concatenated</b> block codes and parallel <b>concatenated</b> convolutional codes are considered...|$|R
2500|$|Dissolving {{uranium oxide}} {{in a strong}} base like sodium {{hydroxide}} forms the doubly negatively charged uranate anion (...) [...] Uranates tend to <b>concatenate,</b> forming diuranate, , or other poly-uranates.|$|E
2500|$|Hungarian and Finnish, in particular, often simply <b>concatenate</b> suffixes. For example, Finnish talossanikinko [...] "in my house, too?" [...] {{consists}} of talo-ssa-ni-kin-ko. However, in the Finnic languages (Finnish, Estonian etc.) and the Sami languages, there are processes which affect the root, particularly consonant gradation. The original suffixes may disappear (and appear only by liaison), {{leaving behind the}} modification of the root. This process is extensively developed in Estonian and Sami, and makes them also inflected, not only agglutinating languages. The Estonian illative case, for example, is expressed by a modified root: maja → majja (historical form *maja-han).|$|E
2500|$|Unlike {{a modern}} stream cipher (such {{as those in}} eSTREAM), RC4 does not take a {{separate}} nonce alongside the key. [...] This means that if a single long-term key {{is to be used}} to securely encrypt multiple streams, the protocol must specify how to combine the nonce and the long-term key to generate the stream key for RC4. [...] One approach to addressing this is to generate a [...] "fresh" [...] RC4 key by hashing a long-term key with a nonce. However, many applications that use RC4 simply <b>concatenate</b> key and nonce; RC4's weak key schedule then gives rise to related key attacks, like the Fluhrer, Mantin and Shamir attack (which is famous for breaking the WEP standard).|$|E
40|$|During {{the period}} June 1, 1986 through November 30, 1986, {{progress}} {{was made in the}} following areas: undetected error probability and throughput analysis of a <b>concatenated</b> coding scheme; capacity and cutoff rate analysis of <b>concatenated</b> codes; <b>concatenated</b> codes using bandwidth efficient trellis inner codes; bounds on the minimum free Euclidean distance of bandwidth efficient trellis codes; and construction of multidimensional bandwidth efficient trellis codes for use as inner codes in a <b>concatenated</b> coding system...|$|R
40|$|A new general <b>concatenated</b> code structure, {{containing}} both parallel and serially <b>concatenated</b> codes {{as special}} cases, is presented. The structure provides a unified {{framework for the}} analysis of <b>concatenated</b> codes and offers new degrees of freedom for code design. Performance analysis based on bounds on the error probability in the error floor region and suggestions for suitable design criteria are provided, together with a design approach for the waterfall region. In contrast to parallel <b>concatenated</b> codes and traditional serially <b>concatenated</b> codes, the proposed structure allows for constructing very high-rate codes with no penalty in the error floor region and good performance in the waterfall region. 1...|$|R
40|$|Worst-case upper bounds {{are derived}} on the minimum {{distance}} of parallel <b>concatenated</b> Turbo codes, serially <b>concatenated</b> convolutional codes, repeat-accumulate codes, repeat-convolute codes, and generalizations of these codes obtained by allowing non-linear and large-memory constituent codes. It is shown that parallel-concatenated Turbo codes and repeat-convolute codes with sub-linear memory are asymptotically bad. It is {{also shown that}} depth-two serially <b>concatenated</b> codes with constant-memory outer codes and sub-linear-memory inner codes are asymptotically bad. Most of these upper bounds hold even when the convolutional encoders are replaced by general finite-state automata encoders. In contrast, it is proven that depth-three serially <b>concatenated</b> codes obtained by <b>concatenating</b> a repetition code with two accumulator codes through random permutations can be asymptotically good...|$|R
2500|$|In any planar graph, the pathwidth is at most {{proportional}} to the square root {{of the number of}} vertices. One way to find a path-decomposition with this width is (similarly to the logarithmic-width path-decomposition of forests described above) to use the planar separator theorem to find a set of O(√n) vertices the removal of which separates the graph into two subgraphs of at most 2n/3 vertices each, and <b>concatenate</b> recursively-constructed path decompositions for each of these two subgraphs. The same technique applies to any class of graphs for which a similar separator theorem holds. Since, like planar graphs, the graphs in any fixed minor-closed graph family have separators of size O(√n), it follows that the pathwidth of the graphs in any fixed minor-closed family is again O(√n). For some classes of planar graphs, the pathwidth of the graph and the pathwidth of its dual graph must be within a constant factor of each other: bounds of this form are known for [...] biconnected outerplanar graphs and for polyhedral graphs. For 2-connected planar graphs, the pathwidth of the dual graph is less than the pathwidth of the line graph. It remains open whether the pathwidth of a planar graph and its dual are always within a constant factor of each other in the remaining cases.|$|E
50|$|<b>Concatenate</b> the buckets {{together}} in order.|$|E
5000|$|Editing via <b>concatenate,</b> trim, pad, repeat, reverse, volume, fade, splice, {{normalise}} ...|$|E
40|$|The {{field of}} <b>concatenated</b> space-time block coding (inner) with trellis coded {{modulation}} (outer) has recently attracted interest {{as a means}} of jointly considering the error correction coding gain and diversity gain possible without bandwidth expansion and power expansion over fading channels. In this research, a <b>concatenated</b> Space-Time Block Coding (STBC) with asymmetric MPSK TCM scheme, based on the design criteria for constructing <b>concatenated</b> space-time block coding with TCM for fast Rayleigh fading channels, is presented by introducing the new optimal signal point assignment. Using parameter comparison and simulation results, the proposed <b>concatenated</b> STBC with asymmetric MPSK TCM is shown to have better coding gain than traditional <b>concatenated</b> STBC with TCM under the same spectral efficiency, decoding complexity...|$|R
40|$|In this paper, we {{show that}} the {{iterative}} decoder for parallel <b>concatenated</b> codes {{can be derived from}} the iterative decoder for serially <b>concatenated</b> codes. In order to show this, we use the observation that any parallel <b>concatenated</b> code (PCC) may be regarded as a serially <b>concatenated</b> code (SCC) with certain code constraints satisfied. By applying these code constraints to the SCC iterative decoder we obtain the PCC iterative decoder, and hence show that the latter {{can be seen as a}} special case of the former...|$|R
40|$|In this work, me {{investigate}} {{the use of}} forward-error correction (FEC) as well as <b>concatenated</b> coding for reliable data transmission in asynchronous direct-sequence code division multiple-access communications over frequency-selective Rayleigh fading channels. The FEC scheme combines antenna diversity with low complexity <b>concatenated</b> codes which consist of a Reed-Solomon outer code and a convolutional inner code. Under this <b>concatenated</b> coding scheme, we analyze the average bit-error rate performance and capacity tradeoffs between various system parameters under a fixed total bandwidth expansion and <b>concatenated</b> codes constraint requirements...|$|R
5000|$|... + {{can be used}} to <b>concatenate</b> strings or for {{mathematical}} addition ...|$|E
50|$|In Smalltalk, the comma {{operator}} {{is used to}} <b>concatenate</b> collections, including strings.|$|E
5000|$|Assemble (<b>concatenate)</b> the headers {{and data}} {{together}} to form an injection packet ...|$|E
40|$|The encoding, {{decoding}} {{and performance}} analysis of <b>concatenated</b> partial unit memory (PUM) code structures for capacity approaching performance are investigated. PUM codes {{are known for}} their excellent distance properties and lower decoding complexity compared to equivalent multi-memory convolutional codes. Two capacity approaching <b>concatenated</b> structures are considered: turbo codes (TCs) and woven turbo codes (WTCs), both initially proposed with component convolutional codes. TCs consist of a number of parallel <b>concatenated</b> encoders. WTCs were originally proposed with outer warp, that is a number of outer encoders are parallel <b>concatenated</b> to one inner encoder. WTCs are also constructed with inner warp, i. e. one outer encoder is parallel <b>concatenated</b> to a number of inner encoders. An iterative max-log-maximum a posteriori decoding scheme is proposed for decoding PUM codes having multiple-input parallel branches in the trellis. The distance properties and bit error rate performance of the novel <b>concatenated</b> PUM codes are compared with known <b>concatenated</b> convolutional codes. It is observed that PUM structures, both TC and WTC with inner and outer warp, have better distance properties and hence improved performance over their equivalent convolutional counterparts. Performance as close as 1. 25 dB from the Shannon limit is obtained for <b>concatenated</b> PUM structures with an interleaver size of only 4800 bits...|$|R
40|$|We discuss long code {{problems}} in the Bennett-Brassard 1984 (BB 84) quantum key distribution protocol and describe {{how they can be}} overcome by concatenation of the protocol. Observing that <b>concatenated</b> modified Lo-Chau protocol finally reduces to the <b>concatenated</b> BB 84 protocol, we give the unconditional security of the <b>concatenated</b> BB 84 protocol. Comment: 4 pages, RevTe...|$|R
40|$|Introduction In {{order to}} achieve highly {{reliable}} communication over an additive white Gaussian noise (AWGN) channel under a restriction of computational complexity of decoding, one of the promising approaches is <b>concatenated</b> coding. The <b>concatenated</b> code consists of two codes: an inner and an outer codes combined in cascaded manner. A short block code or trellis-code with {{a small number of}} states is used for the inner code and an algebraic block code, such as Reed-Solomon(RS) code, is used for the outer code. Forney[1] first proposed the <b>concatenated</b> code and presented the existence of <b>concatenated</b> codes of rate less than the capacity which give an arbitrary small error probability. His work were motivated from a purely theoretical point of view, however, today's state-of-theart technology enables us to exploit the <b>concatenated</b> code for practical use. There are some decoding strategis for such a <b>concatenated</b> coded system. The combination of the softoutput Vite...|$|R
5000|$|Definition: : <b>concatenate</b> two ropes, S1 and S2, into {{a single}} rope.|$|E
5000|$|The Fortran 77 {{standard}} {{introduced the}} ability to slice and <b>concatenate</b> strings: ...|$|E
5000|$|<b>Concatenate</b> (normalized) histograms of all cells. This gives {{a feature}} vector {{for the entire}} window.|$|E
5000|$|... where x {{is now an}} (n + 1)-dimensional vector {{consisting}} of n independent variables <b>concatenated</b> to a vector of ones. Here θ is simply α <b>concatenated</b> to β.|$|R
40|$|International audienceAn {{improved}} <b>concatenated</b> code structure, which generalizes parallel and serially <b>concatenated</b> convolutional codes {{is presented}} and investigated. The structure {{is ideal for}} designing low-complexity rate-compatible code families with good performance in both the waterfall and error floor regions. As an additional feature, the structure provides a unified analysis and design framework, which includes both parallel and serially <b>concatenated</b> codes as particular cases. We derive design criteria for the generalized class of <b>concatenated</b> convolutional codes based on union bounds for the error probability and extrinsic information transfer (EXIT) charts for the decoding threshold...|$|R
5000|$|... {{where the}} {{subscript}} [...] represents the <b>concatenated</b> time-history or combined [...] These combined values of [...] {{can then be}} inversely transformed into raw moments representing the complete <b>concatenated</b> time-history ...|$|R
