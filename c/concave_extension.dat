4|8|Public
40|$|A {{well-known}} linearization {{technique for}} nonlinear 0 - 1 maximization {{problems can be}} viewed as extending any polynomial in 0 - 1 variables to a concave function defined on [0, 1]. Some properties of this "standard" <b>concave</b> <b>extension</b> are investigated. Polynomials for which the standard extension coincides with the concave envelope are characterized in terms of integrality of a certain polyhedron or balancedness of a certain matrix. The standard extension is proved to be identical to another type of <b>concave</b> <b>extension,</b> defined as the lower envelope of a class of affine functions majorizing the given polynomial. Peer reviewe...|$|E
40|$|We {{study the}} cores of non-atomic market games, {{a class of}} {{transferable}} utility co- operative games introduced by Aumann and Shapley [2], and, more in general, of those games that admit a na-continuous and <b>concave</b> <b>extension</b> to the set of ideal coalitions, studied by Einy, Moreno, and Shitovitz [9]. We show that the core of such games is norm compact and some related results. We also give a Multiple Priors interpretation of some of our. ndings. Cores, TU Games, Market Game...|$|E
40|$|This paper investigates core {{stability}} of cooperative (TU) games via a fuzzy {{extension of the}} totally balanced cover of a cooperative game. The {{stability of}} {{the core of the}} fuzzy extension of a game, the <b>concave</b> <b>extension,</b> is shown to reflect the core stability of the original game and vice versa. Stability of the core is then shown to be equivalent to the existence of an equilibrium of a certain correspondence. Cooperative game, core, stable set, fuzzy coalition, fuzzy game, core stability, JEL Classification: C 71...|$|E
40|$|We {{prove that}} any smooth Riemannian {{manifold}} of non-negative scalar curvature {{and with a}} strictly mean convex and compact boundary component can be (C^ 2) extended beyond the component to have non-negative scalar curvature and to enjoy anyone of the following three types of (new) boundary: strictly convex, totally geodesic or strictly <b>concave.</b> The <b>extension</b> procedure can be applied for instance to "positive mass" type of theorems...|$|R
40|$|We {{start with}} an {{overview}} of a class of submodular functions called SCMMs (sums of concave composed with non-negative modular functions plus a final arbitrary modular). We then define {{a new class of}} submodular functions we call deep submodular functions or DSFs. We show that DSFs are a flexible parametric family of submodular functions that share many of the properties and advantages of deep neural networks (DNNs). DSFs can be motivated by considering a hierarchy of descriptive concepts over ground elements and where one wishes to allow submodular interaction throughout this hierarchy. Results in this paper show that DSFs constitute a strictly larger class of submodular functions than SCMMs. We show that, for any integer k> 0, there are k-layer DSFs that cannot be represented by a k'-layer DSF for any k'<k. This implies that, like DNNs, there is a utility to depth, but unlike DNNs, the family of DSFs strictly increase with depth. Despite this, we show (using a "backpropagation" like method) that DSFs, even with arbitrarily large k, do not comprise all submodular functions. In offering the above results, we also define the notion of an antitone superdifferential of a concave function and show how this relates to submodular functions (in general), DSFs (in particular), negative second-order partial derivatives, continuous submodularity, and <b>concave</b> <b>extensions.</b> To further motivate our analysis, we provide various special case results from matroid theory, comparing DSFs with forms of matroid rank, in particular the laminar matroid. Lastly, we discuss strategies to learn DSFs, and define the classes of deep supermodular functions, deep difference of submodular functions, and deep multivariate submodular functions, and discuss where these can be useful in applications...|$|R
40|$|Seminal work by Edmonds and Lovasz {{shows the}} strong {{connection}} between submodularity and convexity. Submodular functions have tight modular lower bounds, and subdifferentials {{in a manner}} akin to convex functions. They also admit poly-time algorithms for minimization and satisfy the Fenchel duality theorem and the Discrete Seperation Theorem, {{both of which are}} fundamental characteristics of convex functions. Submodular functions also show signs similar to concavity. Submodular maximization, though NP hard, admits constant factor approximation guarantees. Concave functions composed with modular functions are submodular, and they also satisfy diminishing returns property. This manuscript provides a more complete picture on the relationship between submodularity with convexity and concavity, by extending many of the results connecting submodularity with convexity to the concave aspects of submodularity. We first show the existence of superdifferentials, and efficiently computable tight modular upper bounds of a submodular function. While we show {{that it is hard to}} characterize this polyhedron, we obtain inner and outer bounds on the superdifferential along with certain specific and useful supergradients. We then investigate forms of <b>concave</b> <b>extensions</b> of submodular functions and show interesting relationships to submodular maximization. We next show connections between optimality conditions over the superdifferentials and submodular maximization, and show how forms of approximate optimality conditions translate into approximation factors for maximization. We end this paper by studying versions of the discrete seperation theorem and the Fenchel duality theorem when seen from the concave point of view. In every case, we relate our results to the existing results from the convex point of view, thereby improving the analysis of the relationship between submodularity, convexity, and concavity. Comment: 38 pages, 10 figure...|$|R
40|$|The {{weighted}} matroid intersection {{problem has}} recently been extended to the valuated matroid intersection problem: given a pair of valuated matroids M_i (V,B_i,#omega#_i) (i = 1, 2) defined on a common ground set V, find a common base B element of B_ 1 intersection B_ 2 that maximizes #omega#_ 1 (B) + #omega#_ 2 (B). This paper develops a Fenchel-type duality theory related to this problem. By {{the way of a}} <b>concave</b> <b>extension</b> of matroid valuations to the base polytopes, the dual problem is derived naturally. This generalizes the well-known primal-dual pair for the ordinary weighted matroid intersection problem. A Fenchel-type min-max theorem and a discrete separation theorem are given. Furthermore, the subdifferentials of matroid valuations are investigated. (orig.) Also published as: SFB- 303 [...] 95839 Available from TIB Hannover: RN 4052 (95839) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|The multilinear {{extension}} of a cooperative game {{was introduced by}} Owen in 1972. In this contribution we study the LovÃ¡sz extension for cooperative games by using the marginal worth vectors and the dividends. First, we prove a formula for the marginal worth vectors with respect to compatible orderings. Next, we consider the direct market generated by a game. This model of utility function, proposed by Shapley and Shubik in 1969, is the <b>concave</b> biconjugate <b>extension</b> of the game. Then we obtain the following characterization: The utility function of a market game is the LovÃ¡sz {{extension of}} the game {{if and only if}} the market game is supermodular. Finally, we present some preliminary problems about the relationship between cooperative games and combinatorial optimization. Copyright Kluwer Academic Publishers 2004 Owen extension, LovÃ¡sz extension, Market games,...|$|R
40|$|In this paper, {{we study}} <b>concave</b> compositions, an <b>extension</b> of {{partitions}} that were considered by Andrews, Rhoades, and Zwegers. They presented several open problems regarding the statistical structure of concave compositions including {{the distribution of}} the perimeter and tilt, the number of summands, and the shape of the graph of a typical concave composition. We present solutions to these problems by applying Fristedt's conditioning device on the uniform measure. Comment: 20 pages, 3 figures. Edited with helpful comment...|$|R
40|$|Tyt. z nagł. References p. 95. Dostępny również w formie drukowanej. ABSTRACT: Some {{conditions}} under which any subadditive function is periodic are presented. It is shown that the boundedness from below in a neighborhood of a point of a subadditive periodic (s. p.) function implies its nonnegativity, and the boundedness from above in a neighborhood of a point implies it nonnegativity and global boundedness from above. A necessary and sufficient condition for existence of a subadditive periodic extension of a function ƒ 0 : [0, 1) ? R is given. The continuity, differentiability of a s. p. function is discussed, and {{an example of a}} continuous nowhere differentiable s. p. function is presented. The functions which are the sums of linear functions and s. p. functions are characterized. The refinements of some known results on the continuity of subadditive functions are presented. KEYWORDS: subadditive function, periodic function, periodic <b>extension,</b> <b>concave</b> function, continuity, continuous nowhere differentiable function...|$|R
40|$|International audienceThe {{notion of}} {{tangential}} cover, based on maximal segments, {{is a well-known}} tool to study the geometrical characteristics of a discrete curve. However, it is not robust to noise, while extracted contours from digital images typically contain noise and this makes the geometric analysis tasks on such contours difficult. To tackle this issue, we investigate in this paper a discrete structure, named Adaptive Tangential Cover (ATC), {{which is based on}} the notion of tangential cover and on a local noise estimator. More specifically, the ATC is composed of maximal segments with different widths deduced from the local noise values estimated at each point of the contour. Furthermore, a parameter-free algorithm is also presented to compute ATC. This study leads to the proposal of several applications of ATC on noisy digital contours: dominant point detection, contour length estimator, tangent/normal estimator, detection of convex and <b>concave</b> parts. An <b>extension</b> of ATC to 3 D curves is also proposed in this paper. The experimental results demonstrate the efficiency of this new notion...|$|R
40|$|This is a {{detailed}} analysis of Wolfe's example[1] to show how the zigzag phenomenon can cause non-convergence of a natural extension of Cauchy's steepest ascent, called the Truncated Gradient Algorithm. First, the algorithm is de ned, then Wolfe's example is presented. Truncated Gradient Algorithm We seek to maximize f(x) onabox, [a; b], and we assume f is in C 1 on (a, "; b + ") for some "> 0. Without the box restriction, Cauchy's steepest ascent uses the iteration: x k+ 1 = x k + skrf(x k); where sk is chosen by the usual optimal line search. Under mild assumptions this converges to a stationary point, say x 1, where rf(x 1) = 0. This is a maximum if f is <b>concave.</b> A natural <b>extension</b> is to project the gradient if a coordinate is at a bound value, and the sign of the associated partial derivative issuchthat the iterate would violate its bound for any positive step size. This is called the truncated gradient: r + f(x) j...|$|R

