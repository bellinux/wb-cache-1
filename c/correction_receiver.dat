4|57|Public
40|$|Abstract [...] An error <b>correction</b> <b>receiver</b> using difference-set {{cyclic code}} has been designed. Highly {{reliable}} operation, short critical path, and small circuit size are key issues. The synchronization circuit is optimized in its circuit size by detecting 10 kinds of bit sequences for synchronization. The circuit action {{is governed by}} state machine combined with a Johnson counter and a timer. The critical path length {{is estimated to be}} 4. 8, which is less than average value...|$|E
40|$|Abstract. Precise Point Positioning (PPP) with GPS {{measurements}} {{has achieved}} a level of success. In order {{to benefit from the}} multiple available constellations, research has been undertaken to combineGPS and BDS measurements in PPP processing. Mathematical models of GPS/BDS combined precise point positioning are introduced in this paper. GPS/BDS combined PPP models are developed based on the GPS-only PPP. The data pre-processing steps include applying satellite orbit and clock corrections, satellite antenna phase offset <b>correction,</b> <b>receiver</b> antenna phase offset correction, differential code bias corrections, troposphere delay corrections and the the Ionosphere-free observation combination is used. The results show that the positioning precision and convergence speed of GPS/BDS combined PPP are improved compared with GPS-only PPP...|$|E
40|$|The {{effects of}} the phase noise (PN) on {{orthogonal}} frequency-division multiplex modems are evaluated. Three receivers are studied: a coherent receiver, a common phase error <b>correction</b> <b>receiver</b> (which is a receiver specially designed to combat PN) and a differential receiver. The impact of the PN on the decision signal-to-noise ratio (SNR) {{of each of these}} receivers is computed {{as a function of the}} PN spectrum. The resulting formulas are extremely simple. The theory is applicable to a wide range of PN models, and unifies and extends previous results on the topic. The conditions under which the decision SNR yields correct symbol error rate predictions are discussed. Simulations are reported that confirm the results...|$|E
50|$|Fountain codes (also {{known as}} rateless erasure codes) are notable {{examples}} of near-optimal erasure codes. They can transform a k symbol message into a practically infinite encoded form, i.e., they can generate an arbitrary amount of redundancy symbols that {{can all be}} used for error <b>correction.</b> <b>Receivers</b> can start decoding after they have received slightly more than k encoded symbols.|$|R
3000|$|The {{binary data}} stream at the {{transmitter}} input of an OFDM system is encoded {{in order to}} generate a parity bit stream. These parity bits are used for the error <b>correction</b> on the <b>receiver</b> side (forward error correction - FEC). L [...]...|$|R
50|$|Metrology {{systems and}} devices may use several basic methods to {{increase}} their basic dynamic range. These methods include averaging {{and other forms of}} filtering, <b>correction</b> of <b>receivers</b> characteristics, repetition of measurements, nonlinear transformations to avoid saturation,, etc. In more advance forms of metrology, such as multiwavelength digital holography, interferometry measurements made at different scales (different wavelengths) can be combined to retain the same low-end resolution while extending {{the upper end of the}} dynamic range of measurement by orders of magnitude.|$|R
40|$|The {{objective}} of this research can be categorised into the following aspects : (a) To present an extensive analysis on Internet Routing - Methods, Protocols, Internals, Issues and Trends. (b) To develop an efficient minimal cut set algorithm in order to extract the minimal paths between any source and destination links in a web link network and use this approach for graphical design of web link structures. Â© To explore optimal web surfing by improvising the classical routing algorithms using fuzzy distance measurers. (d) To present a comprehensive survey of Internet multimedia protocols such as RTP, RTCP, RTSP and TFRCP, and to analyse the performances of SIP and H. 323 for signaling and control of Internet telephony, RSVP and YESSIR for resource reservation in the Internet. (e) To analyse the problems of video streaming over the Internet and to develop qualitative solution models with regard to video streaming based on two architectures (RTP/RTCP and TCP/UDP/IP) and (f) To attain global optimisation through end-to-end congestion control for Internet Routing {{and to develop a}} modified congestion control algorithm for routers in the Internet. In order to study and analyse the internal organisation of links in a web site, a recursive algorithm is used to extract all the links in a specific web-site and link connectivity is represented as a tree structure using graphs and logic gates. Minimal cut sets are extracted to minimise the number of clicks while surfing from the source page to the destination page, that is, to find the minimal path between them. Identifying the presence of minimal cut sets in a web link network positively enhances the reliability and security of the web site. An efficient minimal cut set algorithm is developed to extract the minimal paths between any source and destination links in a web link network. The proposed algorithm is tested on a link tree and the minimal cut sets are obtained. And this approach is found to be effective for the reliability and security of a web site. To explore optimal web surfing (shortest path routing), fuzzy simulation of routing algorithms for finding the optimal path set of links to a target web site in a web link network is implemented. Fuzzy distance measures are derived from the subjective estimation of each link in a web link network by different users with regard to the retrieval rate. Classical routing algorithms (Floyd-Warshall's, Dijkstra's and Bellman-Ford's) are extended using fuzzy hamming distance to explore optimal web surfing. Fuzzy Hurwicz rule is taken into account in establishing the optimistic and pessimistic view of different users for various path sets in the web link network. An optimal surfing path is estimated in a web link network using the implemented fuzzy distance based routing algorithms. A range of protocols are certainly necessary to provide streaming multimedia across the Internet. These protocols include mechanisms for data transfer (RTP), resource reservation (RSVP), session setup for specific applications (SDP, SAP), media-on-demand, control of stored and live multimedia (RTSP), Internet telephony, multimedia conference session initiation, call control (SIP), quality-of-service monitoring (RTCP) and congestion control for time-sensitive multimedia data streams (TFRCP). An extensive survey of Real-time Transport Protocol (RTP), Real-time Transport Control Protocol (RTCP), Real-Time Streaming Protocol (RTSP) and TCP-friendly Rate Control Protocol (TFRCP) are presented. The performances of the Session Initiation Protocol (SIP) and H. 323 standards for signaling and control for internet telephony, Resource ReSerVation Protocol (RSVP) and Yet another Sender Session Internet Reservations (YESSIR) for resource reservation in the Internet have been analysed and compared. Based on the performances of the above protocols, certain improvements are suggested for efficient transfer of real-time continuous media data. The problems of video streaming over the Internet I. e., transferring a video file over an Internetwork effectively without the loss of video data is studied and analysed. Video Streaming architectures based on RTP/RTCP and TCP/UDP/IP are analysed and comparisons have been made about real time video streaming applications. Possible qualitative solutions for the improvement of Video Streaming over an Internet. Environment is developed based on key components such as multicast capability, real time data transport, assured QoS, retransmission, forward error <b>correction,</b> <b>receiver</b> buffering and adaptation. In order to address the steady rise of packet loss rates in real time media streaming, two important destination based congestion control algorithms in packet switched networks are examined. They are Random Early detection (RED) algorithm and modified approach called Derivative Random Drop (DRD) algorithm. The original RED algorithm presents two variants of RED namely RED_VAR- 1 and RED-VAR- 2. A new proposal has been made for the RED algorithm with two more different variants called as RED-VAR- 3 and RED-VAR- 4. The performances and the result of all RED variants have been presented. A modified congestion control algorithm (RED-VAR- 4 algorithm) for real time media streaming applications over an Internet routing environment is proposed...|$|E
5000|$|Japanese NTSC {{never changed}} {{primaries}} and whitepoint to SMPTE [...] "C", continuing {{to use the}} 1953 NTSC primaries and whitepoint. Both the PAL and SECAM systems used the original 1953 NTSC colorimetry as well until 1970; unlike NTSC, however, the European Broadcasting Union (EBU) rejected color <b>correction</b> in <b>receivers</b> and studio monitors that year and instead explicitly called for all equipment to directly encode signals for the [...] "EBU" [...] colorimetric values, further improving the color fidelity of those systems.|$|R
25|$|The {{analysis}} of errors computed using the Global Positioning System {{is important for}} understanding how GPS works, and for knowing what magnitude of errors should be expected. The Global Positioning System makes <b>corrections</b> for <b>receiver</b> clock errors and other effects {{but there are still}} residual errors which are not corrected. The Global Positioning System (GPS) was created by the United States Department of Defense (DOD) in the 1970s. It has come to be widely used for navigation both by the U.S. military and the general public.|$|R
40|$|The {{estimation}} of good quality receiver statics solutions for converted wave data is often problematic. This work applies a technique which uses P-to-S conversions by a refracted P-wave to derive the S-wave receiver statics. When a refracted P-wave converts to an S-wave {{at the base}} of the weathered layer both phases are recorded at surface. The arrival time difference between the two can be used to solve for statics. We estimate the converted wave static <b>correction</b> from <b>receiver</b> functions that are calculated by correlation or deconvolution of early arrivals like refracted energy on the vertical and radial component. This is demonstrated using synthetic and real data...|$|R
50|$|GPS error {{analysis}} examines error sources in GPS {{results and the}} expected size of those errors. GPS makes <b>corrections</b> for <b>receiver</b> clock errors and other effects, but some residual errors remain uncorrected. Error sources include signal arrival time measurements, numerical calculations, atmospheric effects (ionospheric/tropospheric delays), ephemeris and clock data, multipath signals, and natural and artificial interference. Magnitude of residual errors from these sources depends on geometric dilution of precision. Artificial errors may result from jamming devices and threaten ships and aircraft or from intentional signal degradation through selective availability, which limited accuracy to â6-12 m, but has been switched off since May 1, 2000.|$|R
5000|$|With the {{perceived}} vulnerability of GNSS systems, {{and their own}} propagation and reception limitations, renewed interest in LORAN applications and development has appeared. [...] Enhanced LORAN, also known as eLORAN or E-LORAN, comprises an advancement in receiver design and transmission characteristics which increase the accuracy and usefulness of traditional LORAN. With reported accuracy as good as Â± 8 meters, the system becomes competitive with unenhanced GPS. eLORAN also includes additional pulses which can transmit auxiliary data such as DGPS <b>corrections.</b> eLORAN <b>receivers</b> now use [...] "all in view" [...] reception, incorporating signals from all stations in range, not solely those from a single GRI, incorporating time signals and other data from up to 40 stations. These enhancements in LORAN make it adequate {{as a substitute for}} scenarios where GPS is unavailable or degraded.|$|R
40|$|The beacon {{system of}} the International Association of Marine Aids to Navigation and Lighthouse Authorities (IALA) has been the {{standard}} maritime GNSS (Global Navigation Satellite System) augmentation system for many maritime applications since the 90 th. The stations provide differential <b>corrections</b> to GNSS <b>receivers</b> {{in order to improve}} navigation accuracy and monitor the quality of GNSS satellite transmissions. Depending on the rover-to-reference station separation and the age of the corrections being applied, the horizontal accuracy of the system is below 10 metres at more than 95...|$|R
50|$|Although {{trained as}} an observer, Fiala's duties in this {{beginning}} of the war consisted mainly of arming planes with machine guns, and experimenting with aerial cameras. He also rigged a 30 kilogram (66 pound) radio transmitter in an unarmed plane. It was used in May 1915 at the Battle of Gorlice-Tarnow on the Russian Front; by sending <b>corrections</b> to a <b>receiver</b> on the ground, it successfully adjusted mortar fire. Fiala was briefly attached to the testing section of the air arsenal before being reassigned to a flying unit.|$|R
40|$|Given {{research}} work {{presents the results}} of GPS systems dynamic precision estimation, using the real time kinematic (RTK) phase measurements of position with tow receivers. Receiverâs antennas have constant distance between them. The network of base stations EUPOS-Riga and LATPOS was used to correct errors. State estimation results are presented as well. The GPRS data exchange between <b>correction</b> station and <b>receivers</b> was used. The results of precision estimation reveal that centimeter accuracy may be achieved using the fixed solution. Precision of state estimation (course and roll angles) depends of antennas base...|$|R
40|$|Given {{research}} work {{presents the results}} of GPS systems receiver with phase measuring precision estimation in Riga, using the real time kinematic (RTK) measurements of position. The network of base stations EUPOS-Riga was used to correct errors, including five stations. The precision determination was made using the âfloating solutionâ and âfixed solutionâ. The results of precision in DGPS mode are presented as well. The GPRS data exchange between <b>correction</b> station and <b>receiver</b> was used. The results of precision estimation reveal that centimetre accuracy may be achieved using the fixed solution...|$|R
40|$|NASA Goddard Space Flight Center is {{developing}} a direct-detection free-space laser communications transceiver test bed. The laser transmitter is a master-oscillator power amplifier (MOPA) configuration using a 1060 nm wavelength laser-diode with a two-stage multi-watt Ytterbium fiber amplifier. Dual Mach-Zehnder electro-optic modulators provide an extinction ratio greater than 40 dB. The MOPA design delivered 10 -W average power with low-duty-cycle PPM waveforms and achieved 1. 7 kW peak power. We use pulse-position modulation format with a pseudo-noise code header to assist clock recovery and frame boundary identification. We are examining the use of low-density-parity-check (LDPC) codes for forward error <b>correction.</b> Our <b>receiver</b> uses an InGaAsP 1 mm diameter photocathode hybrid photomultiplier tube (HPMT) cooled with a thermo-electric cooler. The HPMT has 25 % single-photon detection efficiency at 1064 nm wavelength with a dark count rate of 60, 000 /s at - 22 degrees Celsius and a single-photon impulse response of 0. 9 ns. We report on progress toward demonstrating a combined laser communications and ranging field experiment...|$|R
40|$|Alzheimer's disease (AD) {{is one of}} {{the most}} {{prominent}} neurodegenerative disorders. The aim of this study is to analyze the magnetoencephalogram (MEG) background activity in AD patients using sample entropy (SampEn) and multiscale entropy (MSE). The former quantifies the signal regularity, while the latter is a complexity measure. These concepts, irregularity and complexity, are linked although the relationship is not straightforward. Five minutes of recording were acquired with a 148 -channel whole-head magnetometer in 20 patients with probable AD and 21 control subjects. Our results show that MEG recordings are less complex and more regular in AD patients than in control subjects. Significant differences between both groups were found in some MEG channels with both methods (p< 0. 01, Student's t-test with Bonferroni's <b>correction).</b> Using <b>receiver</b> operating characteristic curves, accuracies of 75. 6 % with SampEn and of 87. 8 % with MSE were reached. Our findings show the usefulness of these entropy measures to increase our insight into AD...|$|R
40|$|Abstract â Block {{transmission}} {{systems with}} guard periods {{are used for}} high rate transmissions over wireless channels. Removing the guard periods would increase the throughput {{at the price of}} higher computational complexity. Here a method called overlapping is presented that retains the algebraic structure of the block processing stages while the insertion of guard periods can be omitted. The necessary computations of the overlapping method can be performed in the receiver. If they are transfered to the transmitter side, a new system with block wise pre equalization and optional error <b>correction</b> in the <b>receiver</b> is obtained. I...|$|R
2500|$|This led to {{the concept}} of Differential GPS, which used {{separate}} radio systems to broadcast the <b>correction</b> signal to <b>receivers.</b> Aircraft could then install a receiver which would be plugged into the GPS unit, the signal being broadcast on a variety of frequencies for different users (FM radio for cars, longwave for ships, etc.). [...] Broadcasters of the required power generally cluster around larger cities, making such DGPS systems less useful for wide-area navigation. Additionally, most radio signals are either line-of-sight, or can be distorted by the ground, which made DGPS difficult to use as a precision approach system or when flying low for other reasons.|$|R
30|$|We {{will first}} {{demonstrate}} that FBMC/OQAM signals {{are more sensitive}} to phase rotation than OFDM ones. Indeed, if no phase correction is done, or {{in the presence of}} phase estimation errors, the intrinsic interference in FBMC/OQAM will increase the error probability compared to the OFDM case. In the case of a perfect phase <b>correction</b> at the <b>receiver</b> side, both techniques exhibit the same performance. Analytical closed-form expressions of the BER are established based on polynomial decomposition of the HPA NL characteristics. We notice that the proposed method can be applied for any memoryless HPA model and even for real measured ones. In order to validate the obtained BER expressions, various comparisons are made with respect to simulation results.|$|R
30|$|Results are {{expressed}} in mean (SD), median (Q 1, Q 3) or n (%). Normality was assessed {{by means of the}} ShapiroâWilk test. Quantitative variables were compared with qualitative variables by means of the Student t/MannâWhitney tests (2 categories) or ANOVA/KruskalâWallis tests (>Â  2 categories). Qualitative variables were compared by means of the Chi-square test, with Fisherâs <b>correction</b> when necessary. <b>Receiver</b> operating characteristics (ROC) curves were calculated for assessing the prognostic accuracy and for determining the best cutoff points. Sensitivity (Se), specificity (Sp) and positive/negative predictive values (PPV and NPV, respectively) were calculated. A P value less than 0.05 indicated statistical significance, but we applied the Bonferroni correction when multiple comparisons were performed. Statistical analyses were performed using SPSS 19.0 (SPSS, Inc., Chicago, Illinois, USA).|$|R
40|$|Abstract â In {{this paper}} we {{address the issue of}} OFDM and PCC-OFDM systems {{impaired}} by phase noise (PN). PCC-OFDM is a variation of OFDM in which data is mapped onto adjacent subcarrier pairs. As a result intercarrier interference (ICI) in adjacent subcarriers is cancelled. Phase noise in OFDM causes both ICI and common phase error (CPE). PCC-OFDM reduces the ICI component, but the CPE is unchanged. Theoretical and simulations results for bit error rate (BER) are presented for M-QAM OFDM and PCC-OFDM systems over Rayleigh fading channels. The performance with and without CPE <b>correction</b> at the <b>receiver</b> is considered. It is shown that PCC-OFDM has a lower BER in all cases. The theoretical results agree closely with the computer simulations. Index Terms â Orthogonal frequency division multiplexing, phase noise, Intercarrier interference, Rayleigh fading...|$|R
40|$|In the {{previous}} correspondence we introduced a binary double error correcting long code (8 2 5), for 100 % data correction. This paper evaluates the BER performance of UWB system using (8 2 5) code over UWB (SV) channel for image transmission. The simulation results presented here uses BPSK, {{as well as}} 2 -dimensional Hermite pulse modulation. Image to be transmitted over UWB channel is compressed by using Huffman coding to achieve lossless compression. The simulink model is developed to implement the basic UWB system without any means for channel <b>correction</b> (equalizer). The <b>receiver</b> is simple correlator instead of rake receiver, which is generally used to combat multipath. The performance of the double error correcting code for UWB communication is evaluated here to achieve 100 % accurate image at the receiver...|$|R
500|$|The {{broadcast}} media industry is {{at a critical}} turning point in its development, with many countries moving from analog to digital broadcasts. This move is {{made possible by the}} production of cheaper, faster and more capable integrated circuits. The chief advantage of digital broadcasts is that they prevent a number of complaints common to traditional analog broadcasts. For television, this includes the elimination of problems such as snowy pictures, ghosting and other distortion. These occur {{because of the nature of}} analog transmission, which means that perturbations due to noise will be evident in the final output. Digital transmission overcomes this problem because digital signals are reduced to discrete values upon reception and hence small perturbations do not affect the final output. In a simplified example, if a binary message 1011 was transmitted with signal amplitudes [...] and received with signal amplitudes [...] it would still decode to the binary message 1011 â a perfect reproduction of what was sent. From this example, a problem with digital transmissions can also be seen in that if the noise is great enough it can significantly alter the decoded message. Using forward error <b>correction</b> a <b>receiver</b> can correct a handful of bit errors in the resulting message but too much noise will lead to incomprehensible output and hence a breakdown of the transmission.|$|R
40|$|In many {{applications}} of spatial or temporal visualization, glyphs provide {{an effective means}} for encoding mul- tivariate data objects. However, because glyphs are typically small, they are vulnerable to various perceptual errors. In data communication, the concept of Hamming distance underpins the study of codes that support error detection and <b>correction</b> by the <b>receiver</b> {{without the need for}} corroboration from the sender. In this extended abstract, we outline a novel concept of quasi-Hamming distance in the context of glyph design. We discuss the feasibility of estimating quasi-Hamming distance between a pair of glyphs, and the minimal Hamming distance for a glyph set. This measurement enables glyph designers to determine the differentiability between glyphs, facilitating design optimization by maximizing distances between glyphs under various constraints (e. g., the available number of visual channels and their encoding bandwidth) ...|$|R
30|$|Single-frequency {{receivers}} {{can access}} eight ionospheric coefficients, {{located in the}} GPS navigation message to estimate the ionospheric delay based on the Klobuchar model. These coefficients are generated at least once per 6 Â days {{but no more than}} once a day and they are updated by the 5 GPS Ground Control Segment stations. The Klobuchar algorithm is a physical model that considers the changes in latitude, season, solar flux and magnetic activity representing the amplitude change along with the associated diurnal period change of the ionospheric delay. The Klobuchar model permits to correct about 50 % of the ionospheric error for mid-latitudes location and average ionospheric environment. Therefore, the ionospheric modeling has been investigated for last few decades to develop an accurate ionospheric <b>correction</b> for single-frequency <b>receiver</b> applications. To develop a regional ionospheric model, the ionospheric error is estimated using dual frequency receivers distributed in the area under consideration as discussed below.|$|R
40|$|International audienceToday's {{numerical}} methods {{like the}} Spectral Element Method (SEM) allow accurate simulation {{of the whole}} seismic field in complex 3 -D geological media. However, the accuracy of such a method requires physical discontinuities to be matched by mesh interfaces. In many realistic earth models, the design of such a mesh is difficult and quite ineffective in terms of numerical cost. In this paper, we address a limited aspect of this problem: an earth model with a thin shallow layer below the free surface in which the elastic and density properties {{are different from the}} rest of the medium and in which rapid vertical variations are allowed. We only consider here smooth lateral variations of the thickness and elastic properties of the shallow layer. In the limit of a shallow layer thickness very small compared to the smallest wavelength of the wavefield, by resorting to a second order matching asymptotic approximation, the thin layer can be replaced by a vertically smooth effective medium without discontinuities together with a specific Dirichlet to Neumann (DtN) surface boundary condition. Such a formulation allows to accurately take into account complex thin shallow structures within the SEM without the classical mesh design and time step constraints. <b>Corrections</b> at <b>receivers</b> and sourceâwhen the source is located within the thin shallow layerâhave been also derived. Accuracy and efficiency of this formulation are assessed on academic tests. The stability and limitations of this formulation are also discussed...|$|R
40|$|A {{narrow band}} tunable radio {{telemetry}} receiver capable of operating over the license free bands of 26. 9 - 27. 3 MHz and 46 - 50 MHz was designed. The receiver is tuneable within the specified frequency bands, and supports a data rate of 9600 baud. It has link control, flow control and backward error <b>correction</b> capability. The <b>receiver</b> has a synthesised local oscillator, allowing digital tuning and remote system control through an RS- 232 serial interface. The controller {{is capable of}} handling both the receiver and the transmitter and has a 4 kByte buffer each for the transmission and receipt data. The system connects to the external device through an RS- 232 serial interface. The controller was designed around the z 80 microprocessor. The required hardware was constructed and tested completely. The software was also completed but was only partially tested {{for the lack of}} a transmitter to establish a data link...|$|R
40|$|Port-based {{teleportation}} (PBT), {{introduced in}} 2008, {{is a type}} of quantum teleportation protocol which transmits the state to the receiver without requiring any <b>corrections</b> on the <b>receiver's</b> side. Evaluating the performance of PBT was computationally intractable and previous attempts succeeded only with small systems. We study PBT protocols and fully characterize their performance for arbitrary dimensions and number of ports. We develop new mathematical tools to study the symmetries of the measurement operators that arise in these protocols and belong to the algebra of partially transposed permutation operators. First, we develop the representation theory of the mentioned algebra which provides an elegant way of understanding the properties of subsystems of a large system with general symmetries. In particular, we introduce the theory of the partially reduced irreducible representations which we use to obtain a simpler representation of the algebra of partially transposed permutation operators and thus explicitly determine the properties of any PBT scheme for fixed dimension in polynomial time. Comment: 30 pages, 5 figure...|$|R
40|$|In {{wireless}} Code Division Multiple Access (CDMA) system, the use {{of power}} control is indispensable to combat near-far and fading problems. Signals transmitted over a multipath propagation channel which exhibits inter-path interference and fading. The receiver has to employ measures to mitigate these effects or it will incur severe performance degradation. A classic approach in CDMA communications is the rake receiver. In this paper, the downlink performance is estimated for a CDMA mobile system at the vertex of multiple adjacent cells. At the base station the received signal is coherently dispread and demodulated using a rake receiver. The effects of power control, error <b>correction</b> and rake <b>receiver</b> were also investigated {{on the assumption that}} the received signals undergo Rayleigh fading, lognormal shadowing, and frequency selective fading. The evaluation of performance measures of base to mobile link (downlink) of a multiple-cell CDMA mobile system is presented. This study demonstrates that significant performance improvements are achievable with combined use of power control, rake <b>receiver</b> and error <b>correction</b> scheme...|$|R
40|$|Alzheimerâs disease (AD) {{is one of}} {{the most}} {{frequent}} disorders among elderly population and it is considered the main cause of dementia in western countries. This irreversible brain disorder is characterized by neural loss and the appearance of neurofibrillary tangles and senile plaques. The aim of the present study was the analysis of the magnetoencephalogram (MEG) background activity from AD patients and elderly control subjects. MEG recordings from 36 AD patients and 26 controls were analyzed by means of six entropy and complexity measures: Shannon spectral entropy (SSE), approximate entropy (ApEn), sample entropy (SampEn), Higuchiâs fractal dimension (HFD), Maragos and Sunâs fractal dimension (MSFD), and Lempel-Ziv complexity (LZC). SSE is an irregularity estimator in terms of the flatness of the spectrum, whereas ApEn and SampEn are embbeding entropies that quantify the signal regularity. The complexity measures HFD and MSFD were applied to MEG signals to estimate their fractal dimension. Finally, LZC measures the number of different substrings and the rate of their recurrence along the original time series. Our results show that MEG recordings are less complex and more regular in AD patients than in control subjects. Significant differences between both groups were found in several brain regions using all these methods, with the exception of MSFD (p-value < 0. 05, Welchâs t-test with Bonferroniâs <b>correction).</b> Using <b>receiver</b> operating characteristic curves with a leave-one-out cross-validation procedure, the highest accuracy was achieved with SSE: 77. 42 %. We conclude that entropy and complexity analyses from MEG background activity could be useful to help in AD diagnosis...|$|R
40|$|Abstract: Alzheimerâs disease (AD) {{is one of}} {{the most}} {{frequent}} disorders among elderly population and it is considered the main cause of dementia in western countries. This irreversible brain disorder is characterized by neural loss and the appearance of neurofibrillary tangles and senile plaques. The aim of the present study was the analysis of the magnetoencephalogram (MEG) background activity from AD patients and elderly control subjects. MEG recordings from 36 AD patients and 26 controls were analyzed by means of six entropy and complexity measures: Shannon spectral entropy (SSE), approximate entropy (ApEn), sample entropy (SampEn), Higuchiâs fractal dimension (HFD), Maragos and Sunâs fractal dimension (MSFD), and Lempel-Ziv complexity (LZC). SSE is an irregularity estimator in terms of the flatness of the spectrum, whereas ApEn and SampEn are embbeding entropies that quantify the signal regularity. The complexity measures HFD and MSFD were applied to MEG signals to estimate their fractal dimension. Finally, LZC measures the number of different substrings and the rate of their recurrence along the original time series. Our results show that MEG recordings are less complex and more regular in AD patients than in control subjects. Significant differences between both groups were found in several brain regions using all these methods, with the exception of MSFD (p-value < 0. 05, Welchâs t-test with Bonferroniâs <b>correction).</b> Using <b>receiver</b> operating characteristic curves with a leaveone-out cross-validation procedure, the highest accuracy was achieved with SSE: 77. 42 %. We conclude that entropy and complexity analyses from MEG background activity could be useful to help in AD diagnosis. Keywords: Signal processing, entropy, complexity, Alzheimerâs disease, magnetoencephalogram. 1...|$|R
40|$|On-chip {{interconnection}} {{networks for}} future systems on chip (SoC) {{will have to}} deal with the increasing sensitivity of global wires to noise sources such as crosstalk or power supply noise. Hence, transient delay and logic faults are likely to reduce the reliability of across-chip communication. Given the reduced power budgets for SoCs, in this paper, we develop solutions for combined energy minimization and communication reliability control. Redundant bus coding is proved to be an effective technique for trading off energy against reliability, so that the most efficient scheme can be selected to meet predefined reliability requirements in a low signal-to-noise ratio regime. We model on-chip interconnects as noisy channels and evaluate the impact of two error recovery schemes on energy efficiency: <b>correction</b> at the <b>receiver</b> stage versus retransmission of corrupted data. The analysis is performed in a realistic SoC setting, and holds both for shared communication resources and for peer-to-peer links in a network of interconnects. We provide SoC designers with guidelines for the selection of energy efficient error-control schemes for communication architectures...|$|R
40|$|In this paper, a {{mitigation}} {{method for}} minimizing the distortion caused by frequency selective fast fading is illustrated. The proposed system combines between {{two types of}} diversity schemes; frequency diversity represented by the orthogonal frequency division multiplexing (OFDM) scheme and antenna diversity represented by space time block coding (STBC) scheme these are for mitigating the distortion caused by frequency selective fading. The multiplexing technique proposed here is the {{code division multiple access}} (CDMA) scheme which is considered the solution for eliminating the distortion caused by fast fading. The main problem of the OFDM system is the high peak-to-average power ratio (PAR). In the proposed system, three techniques used for reducing the PAR are applied together. And {{in order to reduce the}} bit error rate caused by intersymbol interference (ISI) or multiple access interference (MAI) channel coding is applied which can make error detection and <b>correction</b> at the <b>receiver</b> and simulation results have shown that by applying any of channel coding techniques, the bit error rate (BER) has reached a satisfying level at a low signal-to-noise ratio (SNR) ...|$|R
40|$|In this study, for Istanbul, {{there are}} two Cors Networks (Cors-TR, Iski Cors) {{providing}} Virtual Reference Station (VRS), and Flachen Korrektur Parameter (FKP), <b>corrections</b> to rover <b>receiver</b> for determining 3 -D positions in real time by Global Positioning System (GPS). To determine which method (or technique) provides accurate method for position fixing, a test network consisting of 49 stations {{was set up in}} Yildiz Technical University Davudpasa Campus. The coordinates of the stations in the test network were determined by conventional geodetic, classical RTK, VRS and FKP methods serviced by both Cors-TR and Iski Cors. The results were compared to the coordinates by the conventional method by using total station. The results showed a complex structure as the accuracy differs from one component to another such as in horizontal coordinates, Y components by CorsTR_VRS and Cors_TR_ FKP showed 'best' results while the same technique provided X components consistent accuracy with the Y component but less accurate than by real time kinematic (RTK). In vertical components, of all the techniques used for the h components, CorsTR_VRS showed 'best' accuracy with three outliers...|$|R
