89|147|Public
25|$|Graphics {{can be of}} {{arbitrary}} dimensions, {{resolution and}} <b>colour</b> <b>depth,</b> even on the same screen.|$|E
25|$|Sizes range {{all the way}} up to 7inches (18cm). As well, resolutions also vary, {{going up}} to WVGA. Most screens come with a <b>colour</b> <b>depth</b> of 16-bit, but higher quality video {{oriented}} devices may range all the way to 24-bit, otherwise known as True colour, with the ability to display 16.7million distinct colours. Screens commonly have a matte finish but may also come in glossy to increase colour intensity and contrast. More and more devices are now also coming with touch screen as a form of primary or alternate input. This can be for convenience and/or aesthetic purposes. Certain devices, on the other hand, have no screen whatsoever, reducing costs at the expense of ease of browsing through the media library.|$|E
2500|$|Like the IBM PC {{with the}} {{contemporary}} Color Graphics Adapter, the video {{output of the}} BBC Micro could be switched by software between a number of display modes. These varied between 20 and 40-column text suitable for a domestic TV, to 80-column text best viewed with a high-quality RGB-connected monitor (The 80-column mode was often too blurred to view when using a domestic TV via the UHF output). [...] The variety of modes offered applications a flexible compromise between <b>colour</b> <b>depth,</b> resolution and memory economy. In the first models, the OS and applications were left with the RAM {{left over from the}} display mode.|$|E
40|$|Stereoscopic {{video is}} one of the {{simplest}} forms of multi view video, which can be easily adapted for communication applications. Much current research is based on <b>colour</b> and <b>depth</b> map stereoscopic video, due to its reduced bandwidth requirements and backward compatibility. Existing immersive media research is more focused on application processing than aspects related to transfer of immersive content over communication channels. As video over packet networks is affected by missing frames, caused by packet loss, this paper proposes a frame concealment method for <b>colour</b> and <b>depth</b> map based stereoscopic video. The proposed method exploits the motion correlation of <b>colour</b> and <b>depth</b> map image sequences. The colour motion information is reused for prediction during depth map coding. The redundant motion information is then used to conceal transmission errors at the decoder. The experimental results show that the proposed frame concealment scheme performs better than applying error concealment for <b>colour</b> and <b>depth</b> map video separately in a range of packet error conditions...|$|R
40|$|A new reduced {{reference}} objective {{quality metric}} for stereoscopic video is proposed that incorporates spatial neighbouring information from grey-level co-occurrence matrices and edge properties. Extracted <b>colour</b> and <b>depth</b> features are combined unequally to maximise {{the performance of}} the proposed metric. The performance of this metric is validated through a series of subjective tests and the average correlation 0. 82 is achieved when <b>colour</b> to <b>depth</b> importance ratio is near 0. 80...|$|R
40|$|This {{paper is}} closed access. A new reduced {{reference}} (RR) objective quality metric for stereoscopic video is proposed that incorporates spatial neighbouring information. The contrast measures from grey level co-occurrence matrices (GLCM) for both <b>colour</b> and <b>depth</b> {{are the main}} parts of spatial information. Side information are extracted from edge information of original video and sent through an auxiliary channel. The other {{important factor in the}} proposed metric is the unequal weight of <b>colour</b> and <b>depth</b> views, which can maximise the performance of the proposed metric for some specific values. Performance of the proposed metric is validated through series of subjective tests to show how it correlates subjective quality scores. The average correlation of the proposed metric and subjective quality scores is 0. 82 when <b>colour</b> to <b>depth</b> importance ratio is near 4. © 2012 IEEE...|$|R
50|$|Stage 1 Processing {{of basic}} object components, such as <b>colour,</b> <b>depth,</b> and form.|$|E
5000|$|Graphics {{can be of}} {{arbitrary}} dimensions, {{resolution and}} <b>colour</b> <b>depth,</b> even on the same screen.|$|E
5000|$|Format: Describes {{the layout}} of the {{resource}} data in memory. For example, D3DFMT_R8G8B8 format value means a 24 bits <b>colour</b> <b>depth</b> (8 bits for red, 8 bits for green and 8 bits for blue).|$|E
5000|$|... #Caption: A {{perspective}} {{view of the}} top chalk surface, looking north-east, showing the central crater and its surrounding rings. False <b>colours</b> indicate <b>depth</b> (red/yellow=shallow; blue/purple=deep). (Image credit:Phil Allen (PGL) and Simon Stewart (BP)) ...|$|R
3000|$|... is {{the frame}} index in F and K is {{the set of}} {{resulting}} key-frames with m frames, K={f_l_ 0,f_l_ 1, [...]...,f_l_m- 1 }. Different algorithms {{can be used to}} find the optimal solution, such as logarithmic and stochastic search or a genetic algorithm [4]. The key-frame extraction method for stereoscopic video based on minimum correlation has been presented first by Doulamis et al. in [10]. Here, <b>colour</b> and <b>depth</b> information are combined to summarise stereo video sequences. After the segmentation of the entire video sequence, a shot feature vector is constructed based on size, location, <b>colour</b> and <b>depth</b> of each shot. To limit the number of shot candidates, a shot selection method based on similarly between shots is applied. Finally, the stereo key-frames are extracted from each of the most representative shots. The extraction is achieved by minimising a cross correlation criterion and uses a genetic algorithm [49]. Since this approach selects frames by minimisation of cross correlation, they are not similar to each other in terms of <b>colour</b> and <b>depth.</b>|$|R
50|$|Infant vision {{concerns}} {{the development of}} visual ability in human infants from birth through {{the first years of}} life. The aspects of human vision which develop following birth include visual acuity, tracking, <b>colour</b> perception, <b>depth</b> perception, and object recognition.|$|R
50|$|Movies use 24 frames per second; {{however, the}} rate of the frames can change {{according}} to territories' electrical systems so that there are different kinds of frame rates, for instance, North America is using approximately 30 frames per second where the Europe television frame rate is 25 frames per second. Each digital video has dimensions width and height; when referred to analogue television, the dimension for SDTV is 720×480 pixels, on the other hand, numerous HDTV requires 1920×1080 pixels. Moreover, whilst for SDTV, two bytes (16 bits) is enough to create the <b>colour</b> <b>depth,</b> HDTV requires three bytes (24 bits) to create the <b>colour</b> <b>depth.</b>|$|E
50|$|Other than changes listed above, it is {{technically}} {{the same as}} the 9500, with the same 150 MHz processor, MMC memory card capability, the same amount of memory and the same screen resolution and <b>colour</b> <b>depth.</b> Both phones run the same version 7 of the Symbian OS.|$|E
50|$|The {{reason for}} this high quality {{processing}} is: provide proper realistic up and down sampling of images, and photorealistic display regardless of the monitor gamma, without colour fringing caused by 8-bit gamma correction built into the X server. It also increases the perceived <b>colour</b> <b>depth</b> over 24 bits per pixel.|$|E
50|$|Co-engineered with Leica Camera AG, {{the device}} comes with dual rear cameras - one {{to capture the}} view in the monochrome, the other to capture the colours. The {{pictures}} then get stitched together to create the final images with better <b>colours</b> and <b>depth.</b>|$|R
60|$|In doing this, {{you will}} {{first have to}} meet the {{difficulty}} of representing <b>depth</b> of <b>colour</b> by <b>depth</b> of shade. Thus a pattern of ultramarine blue {{will have to be}} represented by a darker tint of grey than a pattern of yellow.|$|R
50|$|Beaches {{are full}} of subject matter with their lovely bathers and the ever-moving waves, seagulls and sailboats. Everyday is {{different}} and Nada adores painting beach scenes. Her lifelong passion for painting has developed into an expressive, flamboyant style full of texture, <b>colour</b> and <b>depth.</b>|$|R
50|$|Resolution and Color Depth - Unlike many similar systems {{the engine}} {{supports}} virtually any resolution: from 320x200 retro-style to high-res 1024x768 modern looking ones or higher. Both 16bit and 32bit color depths are supported. <b>Colour</b> <b>depth</b> can be also configured by the player at run time - the engine handles the conversion automatically.|$|E
50|$|Codex {{recorders}} are high-resolution media recording systems, {{designed to}} capture pictures and sound from digital cinematography cameras, {{such as the}} ARRI Alexa, the Sony CineAlta series, the Panavision Genesis and the Arriflex D-21. It can record twin 4:4:4 dual-link HD-SDI inputs for A & B camera or stereoscopic 3D work at up to 16-bits <b>colour</b> <b>depth.</b>|$|E
50|$|Wares evolved along Chinese {{lines in}} terms of colour, shape, and technique. Celadon, white porcelain, and storage pottery were similar, but with certain {{variations}} in glazes, incision designs, florality, and weight. The Ming influence in blue and white wares using cobalt-blue glazes existed, but without the pthalo blue range, and the three-dimensional glassine <b>colour</b> <b>depth</b> of Ming Dynasty Chinese works.|$|E
40|$|Abstract. Segmentation is an {{important}} preprocessing step in many ap-plications. Compared to colour segmentation, fusion of <b>colour</b> and <b>depth</b> greatly improves the segmentation result. Such a fusion is easy to do by stacking measurements in different value dimensions, but there are better ways. In this paper we perform fusion using the channel representation, and demonstrate how a state-of-the-art segmentation algorithm can be modified to use channel values as inputs. We evaluate segmentation re-sults on data collected using the Microsoft Kinect peripheral for Xbox 360, using the superparamagnetic clustering algorithm. Our experiments show that depth gradients are more useful than depth values for segmen-tation, and that channel coding both <b>colour</b> and <b>depth</b> gradients makes tuned parameter settings generalise better to novel images. ...|$|R
50|$|Derealization (sometimes {{abbreviated}} as DR) is an alteration in {{the perception}} or experience of the external world so that it seems unreal. Other symptoms include feeling as though one's environment is lacking in spontaneity, emotional <b>colouring,</b> and <b>depth.</b> It is a dissociative symptom of many conditions.|$|R
30|$|In this paper, {{we focus}} on how to {{integrate}} RGB and the additional depth information for RGB-D saliency detection. This saliency-map-level integration is not optimal because it is restricted by the determined saliency values. Conversely, we incorporate <b>colour</b> and <b>depth</b> cues at the feature level within a Bayesian framework.|$|R
50|$|On November 19, 2014, {{rock band}} Linkin Park's concert at Berlin's O2 World Arena was {{broadcast}} live in Ultra HD via an Astra 19.2°E satellite. The broadcast was encoded in the UHD 4K standard with the HEVC codec (50 {{frames per second}} and a 10 bit <b>colour</b> <b>depth),</b> and was a joint enterprise of satellite owner SES, SES Platform Services (now MX1) and Samsung.|$|E
50|$|The phone {{uses the}} UIQ 3 {{software}} platform, {{which is based}} upon Symbian OS 9.1. The M600 has a new special type of full QWERTY keyboard below the display, on the phone itself.The touchscreen displays 262,144 colours (18-bit <b>colour</b> <b>depth)</b> with a resolution of 240x320 pixels at 2.6 inches long in diagonal.The M600 runs the Nexperia PNX4008 ARM9 208 MHz processor from Philips and has 64MB RAM and 128MB Flash ROM.|$|E
5000|$|Compatible with GSM/HSCSD/GPRS/EDGE 900/1800/1900 MHz networks, the 7710 {{features}} a wide, touch-screen colour LCD with {{a resolution of}} 640 x 320 pixels and 16-bit <b>colour</b> <b>depth,</b> which also boasts a special power save mode activating only 640 x 64 pixels of the display. It has 90 MB of internal memory supported by a 128 MB MultiMedia Card (MMC). The external memory can be upgraded up to 2 GB.|$|E
5000|$|Let's have a {{quick look}} at what a lot of science fiction lacks. Briefly, {{these are some of the}} qualities I miss on the whole - passion, subtlety, irony, {{original}} characterization, original and good style, a sense of involvement in human affairs, <b>colour,</b> density, <b>depth,</b> and, on the whole, real feeling from the writer...|$|R
40|$|In {{the near}} future, certain 2 D (2 Dimensional) video {{application}} scenarios are likely {{be replaced by}} 3 D (3 Dimensional) video, {{in order to achieve}} a more involving and immersive representation of visual information, and to provide more natural methods of communication. Stereoscopic video is the simplest form of 3 D video, which renders two slightly different views of a scene to perceive the depth information. Currently much research is being carried out in this area including stereo video capture, coding, transmission, and display technologies. This paper presents a review {{of some of the most}} prominent methods for coding stereoscopic <b>colour</b> and <b>depth</b> video, and investigates their respective coding efficiencies. This paper also proposes a new configuration for encoding <b>colour</b> and <b>depth</b> stereoscopic video, based on the H. 264 /SVC video coding standard. The rate-distortion performance comparison of the <b>colour</b> and <b>depth</b> video obtained using the depth-range cameras vs. left and right video is analyzed at low bitrates using the H. 264 /SVC configuration. The performances are compared in terms of coding efficiency and implementation factors with the MPEG- 4 MAC and H. 264 /AVC configurations. It was found out that the configuration proposed based on H. 264 /SVC performs similar to H. 264 /AVC and outperforms the MPEG- 4 MAC based configuration in terms of coding efficiency. In terms of implementation factors the proposed configuration provides wider flexibility compared to all other configurations. ...|$|R
40|$|We review image {{processing}} techniques for manipulating 2 -D representations of facial images and show {{their potential for}} extension to 3 -D. Techniques for the manipulation of 2 -D images include those used for: (i) averaging images of different faces to form facial ‘prototypes’, (ii) automated caricature exaggeration of the way an individual face differs in shape and colour from a prototype and (iii) transformations manipulating perceived facial qualities while maintaining information about identity (e. g. modifying the apparent sex or age of a face). Each technique relies on 160 feature landmarks allocated to the original 2 -D images (e. g. centre of left eye, tip of nose). These landmarks {{can also be found}} in the 3 -D <b>colour</b> and <b>depth</b> maps obtained from Cyber-scans. Using 2 -D image warping techniques to align <b>colour</b> and <b>depth</b> maps from different faces allows prototypes and caricatures and may similarly allow transformations of faces to be performed in 3 -D. ...|$|R
50|$|Each desktop or 'screen' {{could have}} its own <b>colour</b> <b>depth</b> (number of {{available}} colours) and resolution, including use of interlacing. The display chipset ('graphics card' on a PC) could switch between these desktop modes on the fly, and during the drawing of a single screen, usually with three pixel deep line between each desktop shown on the screen. However, if one interlaced (flickering) desktop was displayed, all desktops onscreen would be similarly affected.|$|E
50|$|The P800 {{uses the}} UIQ (version 2.0) user {{interface}} {{and has a}} touch screen much like a PDA. It is powered by an ARM9 processor running at 156MHz, which was also used for the successive models Sony Ericsson P900, Sony Ericsson P910. It came with a 16MB Memory Stick Duo but supports up to 128MB. The touchscreen displays 4,096 colours (12-bit <b>colour</b> <b>depth).</b> It was succeeded in 2003 by the Sony Ericsson P900.|$|E
50|$|Enterprise {{has five}} {{graphics}} modes: 40- and 80-column text modes, Lo-Res and Hi-Res bit mapped graphics, and attribute graphics. Bit mapped graphics modes allow selection between displays of 2, 4,16 or 256 colours, but horizontal resolution decreases as <b>colour</b> <b>depth</b> increases. Interlaced and non-interlaced modes are available. The maximum resolution is 640×512 pixels interlaced, or 640×256 pixels non-interlaced. These resolutions permit only a 2-colour display. A 256-colour display has a maximum resolution of 80×256. The attribute graphics mode provides a 320×256 pixel resolution with 16 colours, selectable from {{a palette of}} 256.|$|E
40|$|Abstract—In this paper, {{we present}} a model-based video coding method that uses input from <b>colour</b> and <b>depth</b> cameras, such as the Microsoft Kinect. The model-based {{approach}} uses a 3 D representation of the scene, enabling several other applications besides video playback. Some of these applications are stereoscopic viewing, object insertion for augmented reality and free viewpoint viewing. The video encoding step uses computer vision to estimate the camera motion. The scene geometry is represented by keyframes, which are encoded as 3 D quads using a quadtree, allowing good compression rates. Camera motion in-between keyframes is approximated to be linear. The relative camera positions at keyframes and the scene geometry are then compressed and transmitted to the decoder. Our experiments demonstrate that the model-based approach delivers {{a high level of}} detail at competitively low bitrates. (a) <b>Colour</b> image. (b) <b>Depth</b> image...|$|R
30|$|Deep images store {{multiple}} fragments perpixel, each {{of which}} includes <b>colour</b> and <b>depth,</b> unlike traditional 2 D flat images which store only a single colour value and possibly a depth value. Recently, deep images have found use in {{an increasing number of}} applications, including ones using transparency and compositing. A step in compositing deep images requires merging per-pixel fragment lists in depth order; little work has so far been presented on fast approaches.|$|R
30|$|The {{advent of}} the Kinect [28] permits both <b>colour</b> and <b>depth</b> of a scene to be sensed concurrently. This allows extracting the 3 D {{structure}} of the surrounding and creating {{a representation of the}} environment and the use of Kinect data with the PnP algorithm has already been investigated [29] for image-based registration. The analysis involved determining relative and absolute accuracies of the Kinect and another sensor according to the camera pose obtained by using Efficient PnP (EPnP) algorithm [30].|$|R
