0|979|Public
40|$|Approved {{for public}} release, {{distribution}} unlimitedAcoustic backscattering from a random rough water surface {{has been studied}} experimentally to test the application of two scattering theories, a statistical description and a resonance approach. The rough surface was created by wind agitation over an anechoic tank. The wave height distribution was measured with a resistive probe and the wave slope distribution by optical glitter detection using a photocell. The distributions of backscattered sound pressures were recorded for surface roughnesses and sound frequencies corresponding to a very wide range of roughness conditions. Both statistical and resonance theories have regions of applicability and regions where they fail to predict the backscatter. Backscattering may {{be considered to be}} due to these two mechanisms, since a summation of the predictions of the two theories fits the experimental data fairly well over the complete range of angles of incidence studied. A method of analysis is suggested to relate the doppler shifted <b>continuous</b> wave <b>sound</b> <b>spectrum</b> to the surface wave spectrum. [URL] Commander, Royal Canadian NavyLieutenant, United States Nav...|$|R
50|$|<b>Continuous</b> <b>Sound</b> Forms. Alga Marghen, 2000.|$|R
50|$|Recorded at <b>Sound</b> <b>Spectrum</b> Recording, Inc.|$|R
5000|$|... #Subtitle level 3: LAT or Leq: Equivalent <b>continuous</b> <b>sound</b> level ...|$|R
5000|$|... rollDrum rolls {{are various}} {{techniques}} employed {{to produce a}} sustained, <b>continuous</b> <b>sound.</b>|$|R
5000|$|Recorded at <b>Sound</b> <b>Spectrum</b> Recording, Inc. (House of Cash Studios) ...|$|R
5000|$|Recorded at Jack Clement Recordings Studios and <b>Sound</b> <b>Spectrum</b> Studios, Nashville, Tn ...|$|R
5000|$|<b>CONTINUOUS</b> <b>SOUND</b> AND IMAGE MOMENTS, 1966 (with Tjebbe van Tijen and Willem Breuker) Netherlands Film Museum, Amsterdam, Netherlands ...|$|R
5000|$|Transhumance feat. John Kozak - San Francisco <b>Sound</b> <b>Spectrum</b> (under {{the name}} Odyssey Arcane) 12" [...] Twitch Records 1995 ...|$|R
5000|$|... "Kamermuziek #2" [...] 3 hour live concert as a soundtrack {{for a room}} at TENT's <b>Sound</b> <b>Spectrums</b> event, Rotterdam, 2012 ...|$|R
40|$|The {{automatic}} detection {{and recognition of}} sound events by computers is a requirement {{for a number of}} emerging sensing and human computer interaction technologies. Recent advances in this field have been achieved by machine learning classifiers working in conjunction with time-frequency feature representations. This combination has achieved excellent accuracy for classification of discrete sounds. The ability to recognise sounds under real-world noisy conditions, called robust sound event classification, is an especially challenging task that has attracted recent research attention. Another aspect of real-word conditions is the classification of continuous, occluded or overlapping sounds, rather than classification of short isolated sound recordings. This paper addresses the classification of noise-corrupted, occluded, overlapped, <b>continuous</b> <b>sound</b> recordings. It first proposes a standard evaluation task for such sounds based upon a common existing method for evaluating isolated sound classification. It then benchmarks several high performing isolated sound classifiers to operate with <b>continuous</b> <b>sound</b> data by incorporating an energy-based event detection front end. Results are reported for each tested system using the new task, to provide the first analysis of their performance for <b>continuous</b> <b>sound</b> event detection. In addition it proposes and evaluates a novel Bayesian-inspired front end for the segmentation and detection of <b>continuous</b> <b>sound</b> recordings prior to classification...|$|R
5000|$|Make <b>sound</b> <b>spectra</b> {{visible in}} solid {{material}} (powder, iron filings, etc.) as a composed program with renewals and variation in duration of {{about half an}} hour: ...|$|R
30|$|It {{is known}} that the <b>sound</b> {{pressure}} <b>spectrum</b> due to a unit harmonic wheel–rail force multiplied by the actual wheel–rail force spectrum gives the actual <b>sound</b> pressure <b>spectrum,</b> and the <b>sound</b> power <b>spectrum</b> due to a unit harmonic wheel–rail force multiplied by the squared magnitude of actual wheel–rail force spectrum produces the actual <b>sound</b> power <b>spectrum.</b> Thus, to meet {{the purpose of this}} work, it is reasonable to consider a wheel subject to a unit vertical harmonic wheel–rail force at the wheel–rail contact point.|$|R
60|$|The sliding roar ceased; its echo, muffled and hollow, pealed {{from the}} cliffs, then rumbled down the canyon to merge at length in the sullen, dull, <b>continuous</b> <b>sound</b> of the rapids.|$|R
50|$|The {{driving by}} noise {{is quoted as}} an {{absolute}} value in decibel and as a 3 classes sound wave symbol. A <b>continuous</b> <b>sound</b> level above 80 decibel can cause health problems.|$|R
5000|$|M-Series Traditional ("Modern Traditional") - This series {{featured}} {{medium and}} heavy models that {{sit in the}} mid-range of the <b>sound</b> <b>spectrum.</b> They came in a traditional finish.|$|R
5000|$|Note: Track 2 [...] "Don't Take Your Guns To Town" [...] is a re-recording, {{recorded}} 18 June 1974 at <b>Sound</b> <b>Spectrum</b> Recording, House Of Cash, Hendersonville, TN.|$|R
50|$|The <b>sound</b> <b>spectrum</b> of {{the group}} {{contains}} a mixture of electronics, krautrock, disco, noise and pop and their ninth album on Bureau B is scheduled for spring 2018.|$|R
5000|$|... #Caption: Chladni {{diagrams}} for quadratic plates (from E. F. F. Chladni, Die Akustik, 1802), {{as used in}} situation 3 to [...] "make <b>sound</b> <b>spectra</b> {{visible in}} solid material".|$|R
40|$|This paper {{considers}} computer-assisted {{learning of}} <b>sound</b> <b>spectra</b> in environmental recordings to facilitate manual bird species identification. Today, {{a variety of}} automated methods have been successfully applied for acoustic recognition of specific bird species. These methods are more effective for single targeted species detection. For in-field recordings, however, simultaneous vocalisations and unknown species usually make such methods less effective. In this study, we propose a non-negative matrix factorisation based method to facilitate manual bird species identification from environmental recordings. First, distinct <b>sound</b> <b>spectra</b> are extracted from each audio clip by applying non-negative matrix factorisation and clustering techniques. Based on these distinct <b>sound</b> <b>spectra,</b> a greedy algorithm is then designed to sample audio clips. Each sampled audio clip maximises {{the number of new}} spectra. People who follow this sampled sequence of audio clips should be able to identify the most species given a fixed number of audio clips. The efficiency is validated with annotated bird species per minute provided by experienced ornithologists...|$|R
50|$|Together {{with sound}} {{specialist}} Eddy B. Brixen (from DPA) and EBB-consult, there is ongoing research in making spectral {{analysis of the}} <b>sound</b> <b>spectrum,</b> the voice produces with the various modes.|$|R
60|$|He {{broke off}} {{suddenly}} and I started and looked round, half amazed, half frightened. The <b>continuous</b> <b>sound</b> of an electric-bell, {{which seemed to}} come from within a few feet of me, was echoing through the room.|$|R
50|$|Circle Breathing is a {{technique}} characteristic of wind instruments such as the Dizi, in which the performer breathes through the nose while expelling air through the mouth {{at the same time}} to create a <b>continuous</b> <b>sound.</b>|$|R
50|$|After {{receiving}} his PhD, Miranda {{worked at}} the Edinburgh Parallel Computing Centre (EPCC). At EPCC, he developed Chaosynth, an innovative granular synthesis software that uses cellular automata to generate complex <b>sound</b> <b>spectra.</b>|$|R
40|$|In the <b>sound</b> <b>spectrum</b> of flue organ {{pipes in}} {{addition}} to the usual harmonic partials, sometimes a series of equidistant but not harmonic lines can be found. This phenomenon has been observed in the recorded sound of pipes from different pipe ranks. The second set of spectral lines is similar to frequency combs used in optics for accurate measurement of optical frequencies. Analysis of measured <b>sound</b> <b>spectra</b> with and without frequency comb and simulations are presented and discussed in the paper. The appearance of frequency combs in the <b>sound</b> <b>spectrum</b> is explained by a model that assumes the presence of a mouth tone {{in addition to}} the pipe sound. Mouth tone bursts are generated when the oscillating air jet passes the upper lip. The burst repetition frequency is locked to the fundamental frequency of the pipe and the bursts are coherent with a pulse-to-pulse phase shift. The phase shift explains the observed frequency offset of the frequency comb to the harmonic frequencies. The simulations also show that weak and fluctuating mouth tones cannot generate frequency comb {{due to a lack of}} coherence...|$|R
5000|$|Marcussen builds pipe organs for {{churches and}} concert halls, and restores notable {{historical}} organs. Their new organs {{are based on}} classical organ-building traditions, with reliable slider windchests, simple mechanical [...] "tracker" [...] action with precise function, and a wide <b>sound</b> <b>spectrum.</b>|$|R
40|$|This paper {{builds on}} initial {{evidence}} of First Language influence on brass playing presented in Heyne and Derrick (2013) [13] by indicating how tongue positioning might affect trombone timbre. Ultrasound imaging {{of the tongue}} {{was used to compare}} vowel production and sustained trombone notes for three participants, one each of New Zealand English, Tongan and Japanese, whose musical production was also analyzed acoustically. Comparison of the <b>sound</b> <b>spectra</b> produced by two semiprofessional players shows that the player using a higher, more retracted tongue position displays a larger component of high frequencies in the produced <b>sound</b> <b>spectrum.</b> We believe that this could explain why brass players can notice differences between players from different language backgrounds...|$|R
40|$|This work {{focuses on}} the {{problems}} of <b>sound</b> <b>spectrum</b> analysis and directional characteristics of the violin. The beginning of the work deals with the development of the violin, generally about timbre and directional characteristics. The theoretical part also deals with different types of <b>sound</b> <b>spectra</b> and LPC analysis on general. The practical part deals with practical tasks of work such as a description of the application created in MATLAB for examination of the time spectrum of tones, FFT spectra, formants by LPC analysis and display of directional characteristics. It also deals with the describing the methods, the process of sensing and measuring two different violins with different types of strings and age of corpus...|$|R
5000|$|In {{this piece}} I experimented with very unusual non-harmonic <b>sound</b> <b>spectra.</b> In the small {{orchestra}} {{there are four}} natural horns, each of which can produce the 2nd to the 16th overtone. By providing each horn or group of horns with different fundamentals I was able to construct novel <b>sound</b> <b>spectra</b> from the resulting overtones. These harmonies, which had never been used before, sound [...] "weird" [...] in relation to harmonic spectra. I developed both [...] "weird" [...] consonant and dissonant harmonies, with complex beats. Horns blend very well together, and to enrich the sound further, the two clarinettists play basset horns. Even though it is replete with spectra of strange beats, the resulting overall sound is soft and mellow.|$|R
40|$|The blood oxygen level-dependent (BOLD) signal time {{course in}} the {{auditory}} cortex is characterized by two components, an initial transient peak and a subsequent sustained plateau with smaller amplitude. Because the T 2 * signal detected by {{functional magnetic resonance imaging}} (fMRI) depends on at least two counteracting factors, blood oxygenation and volume, we examined whether the reduction in the sustained BOLD signal results from decreased levels of oxygenation or from increased levels of blood volume. We used conventional fMRI to quantify the BOLD signal and fMRI in combination with superparamagnetic contrast agent to quantify blood volume and employed repetition rate-modulated sounds in a silent background to manipulate the response amplitude in the auditory cortex. In the BOLD signal, the initial peak reached 3. 3 with pulsed sound and 1. 9 with <b>continuous</b> <b>sound,</b> whereas the sustained BOLD signal fell to 2. 2 with pulsed sound and to 0. 5 with <b>continuous</b> <b>sound,</b> respectively. The repetition rate-dependent reduction in the sustained BOLD amplitude was accompanied by concordant changes in sustained blood volume levels, which, compared to silence, increased by ∼ 30 with pulsed and by ∼ 10 with <b>continuous</b> <b>sound.</b> Thus, our data suggest that the reduced amplitude of the sustained BOLD signal reflects stimulus-dependent modulation of blood oxygenation rather than blood volume-related effects...|$|R
60|$|She {{began to}} examine the smashed {{fragments}} of chalk that lay about Andoo. For a space she stood still, looking about her and making a low <b>continuous</b> <b>sound</b> that was almost a moan. Then she went back incredulously to Andoo to make one last effort to rouse him.|$|R
5000|$|I {{thought to}} myself, what about {{composing}} {{a piece that}} would be a paradoxically <b>continuous</b> <b>sound,</b> something like Atmosphères, but that would have to consist of innumerable thin slices of salami? A harpsichord has an easy touch; it can be played very fast, almost fast enough to reach the level of continuum, but not quite (it takes about eighteen separate sounds per second to reach the threshold where you can no longer make out individual notes and the limit set by the mechanism of the harpsichord is about fifteen to sixteen notes a second). As the string is plucked by the plectrum, apart from the tone you also hear quite a loud noise. The entire process is a series of sound impulses in rapid succession which create the impression of <b>continuous</b> <b>sound.</b>|$|R
40|$|This paper {{describes}} our submission for {{the audio}} melody extraction {{task of the}} Music Information Retrieval Evalu-ation eXchange (MIREX 2014). Our algorithm first sep-arates the vocal <b>spectra</b> from polyphonic <b>sound</b> <b>spectra.</b> Melody extraction and vocal activity detection are applied to the separated spectra. 1...|$|R
5000|$|Smalley's term {{refers to}} the {{descriptive}} analysis of perceived morphological developments in <b>sound</b> <b>spectra</b> over time, and it implies that the [...] "spectro" [...] cannot exist without the morphology: {{something has to be}} shaped and that something must have sonic content (Smalley, 1986, 1997).|$|R
40|$|International audienceAs {{environmental}} {{sounds are}} used by larval fish and crustaceans to locate and orientate towards habitat during settlement, variations in the acoustic signature produced by habitats could provide valuable information about habitat quality, helping larvae to differentiate between potential settlement sites. However, very {{little is known about}} how acoustic signatures differ between proximate habitats. This study described within-and between-site differences in the <b>sound</b> <b>spectra</b> of five contiguous habitats at Moorea Island, French Polynesia: the inner reef crest, the barrier reef, the fringing reef, a pass and a coastal mangrove forest. Habitats with coral (inner, barrier and fringing reefs) were characterized by a similar <b>sound</b> <b>spectrum</b> with average intensities ranging from 70 to 78 dB re 1 μPa. Hz- 1. Th...|$|R
40|$|We {{investigated}} the {{mechanisms by which}} the barn owl (Tyto alba) determines the azimuth and elevation of a sound source. Our measure of localizing ability was the accuracy with which the owl oriented its head to a sound source. When localizing tonal signals, the owl committed the smallest errors at frequencies between 4 and 8 kHz. The azimuthal component of these errors was frequency independent from 1 to 8 kHz, but the elevational component increased dramatically for frequencies below 4 kHz. The owl's mean error when localizing wide band noise was nearly three times less than its mean error when localizing the optimal frequency for tonal localization (6 kHz). Occluding the right ear caused the owl to orient below {{and to the left}} of the sound source; occluding the left ear caused it to orient above and to the right of the sound source. With ruff feathers (facial ruff) removed, the owl continued to localize sounds accurately in azimuth, but failed to localize sounds in elevation. We conclude from these results that the barn owl uses interaural comparisons of <b>sound</b> <b>spectrum</b> to determine the elevation of a sound source. Both interaural onset time and interaural spectrum are used to identify the azimuth of the sound source. If onset time is not available (as in a <b>continuous</b> <b>sound),</b> the owl can derive the azimuth of the source from interaural spectrum alone, but its spatial resolution is poorer...|$|R
