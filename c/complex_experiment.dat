67|1225|Public
5000|$|In a more <b>complex</b> <b>experiment,</b> {{where the}} {{experimental}} units (or environmental effects) are not homogeneous, row statistics {{are also used}} in the analysis. The model includes terms dependent on [...] Determining the extra terms reduces the number ofdegrees of freedom available.|$|E
50|$|There {{are also}} {{open-source}} software packages providing {{all the necessary}} tools to acquire data from different hardware equipment. These tools come from the scientific community where <b>complex</b> <b>experiment</b> requires fast, flexible and adaptable software. Those packages are usually custom fit but more general DAQ package like the Maximum Integrated Data Acquisition System can be easily tailored and is used in several physics experiments worldwide.|$|E
50|$|There are 3 main {{proteins}} {{thought to}} interact with the human protein encoded by the gene LSMEM1 that were determined via two-hybrid screening (LSMEM2 and MAL) and reconstituted complex (APP) experiments. A reconstituted <b>complex</b> <b>experiment</b> detects interactions between purified proteins in vitro. The 3 proteins thought {{to interact with}} LSMEM1 are: MAL, APP, and LSMEM2. All three of these interacting proteins are integral membrane proteins, just as LSMEM1 is.|$|E
50|$|The {{simplest}} experiment {{suitable for}} ANOVA analysis is the completely randomized experiment {{with a single}} factor. More <b>complex</b> <b>experiments</b> with a single factor involve constraints on randomization and include completely randomized blocks and Latin squares (and variants: Graeco-Latin squares, etc.). The more <b>complex</b> <b>experiments</b> share many of the complexities of multiple factors. A relatively complete discussion of the analysis (models, data summaries, ANOVA table) of the completely randomized experiment is available.|$|R
40|$|Aim: To {{develop a}} {{strategy}} {{for the analysis of}} <b>complex</b> <b>experiments</b> using Bayesian hierarchical models, and demonstrate the advantage of the Bayesian formulation when analysing <b>complex</b> <b>experiments.</b> Methods: There is increased popularity in designing <b>complex</b> experiments; such <b>experiments</b> help amplify the efficiency of clinical research. The Bayesian approach is a natural candidate to tackle complex problems in a straightforward manner as it handles efficiently large amounts of missing data and multivariate responses data. Joint models are formulated {{in order to deal with}} missing data and multivariate data. A strategy is developed for the analysis of <b>complex</b> <b>experiments</b> based on two clinical experiments in dentistry. Data: Two clinical experiments in dental research are selected for analysis. In dentistry, we encounter <b>complex</b> <b>experiments</b> as the individual units are the teeth which are clustered within subjects. Results and Conclusion: The results indicate that using Bayesian joint models improve the parameters estimation while taking into account the entire complexity of the study design. The Bayesian formulation gives us the advantages to estimate complex joint models in a straightforward manner. Bayesian joint models can deal with missing data and multivariate data efficiently given the exibility by the MCMC analysis. The joint model propagates the entire uncertainty in the model into the posterior distribution. We can easily extend the model to account for different types of missing data, and/or account for different correlation structures when dealing with multivariate data. Imperial Users onl...|$|R
5000|$|ANOVA is {{difficult}} to teach, particularly for <b>complex</b> <b>experiments,</b> with split-plot designs being notorious. [...] In some cases the proper application of the method is best determined by problem pattern recognition followed by the consultation of a classic authoritative test.|$|R
5000|$|The Elementary episode [...] "Ears To You" [...] is a loose {{adaptation}} of this story. The setup for this episode {{is very similar}} to that story — two human ears are mailed to someone, packed in salt- but includes several variations, including the twist that the ears were actually sent by the supposed victim, who underwent a <b>complex</b> <b>experiment</b> to literally grow fake ears on her back so as to frame the primary suspect for her murder.|$|E
50|$|The Shattered Chain {{presents}} the Renunciate organization and worldview {{in greater detail}} than previous books in the series. The first free Amazon character that Bradley created, Kyla Raineach in The Planet Savers, was a two-dimensional caricature who ended up rather conventionally {{falling in love with}} her male employer. As the series developed, the Renunciates evolved into a <b>complex</b> <b>experiment</b> in separatist feminism. The Renunciates {{are one of the most}} popular character groups in the Darkover series, resulting in a considerable amount fan fiction, some of which ended up in the 12 short story anthologies.|$|E
5000|$|Reviewing Debut, Heather Phares of AllMusic, {{noted that}} [...] "Björk's playful energy ignites the dance-pop-like [...] "Big Time Sensuality" [...] {{and turns the}} genre on its head with [...] "There's More to Life Than This." [...] Recorded live at the Milk Bar Toilets, it captures the dancefloor's sweaty, claustrophobic groove, but her impish voice gives it an almost alien feel". The website cites the track as an All Media Network-pick, and in a track review, Stacia Proefrock defined the track as an [...] "aggressive, screechy dance number" [...] that [...] "While not {{scraping}} {{the top of the}} charts... was part of an album unusual enough to stand out among its fellow pop releases as a quirky and <b>complex</b> <b>experiment</b> that worked most of the time".|$|E
50|$|Experiments for the {{projects}} selected to the ELIPS pool are implemented {{as soon as}} practical, which {{to a large degree}} depends on the complexity and cost of the experiment. For experiments on ISS it typically takes a couple of years from selection to realisation, in few cases up to a decade. Experiment hardware is normally provided by the ELIPS programme, whereas the participating researchers have to find funds for themselves from national sources. ESA is further responsible for all transport to space, operations costs and crew resources (if on ISS). Increasingly large or <b>complex</b> <b>experiments,</b> co-operation with other ISS partners (i.e. NASA, JAXA, CSA or Roscosmos) is often sought, in particular for large or <b>complex</b> <b>experiments.</b>|$|R
40|$|The {{development}} of the Grid has opened new possibilities for scientists and engineers to execute large-scale modeling experiments. This has stimulated the generation and {{development of}} tools for the creation and management of <b>complex</b> computing <b>experiments</b> in the Grid. Among these, tools for the automation of the programming of experiments play a significant role. In this paper we present GriCoL, which we propose as a simple and efficient language for the description of <b>complex</b> Grid <b>experiments.</b> We also describe the environment within which GriCoL works, namely the Science Experimental Grid Laboratory (SEGL) system for designing and executing <b>complex</b> <b>experiments.</b> As an illustration, the paper includes the description of a biochemical experiment using Molecular Dynamics simulations. 1...|$|R
50|$|The Spacelab 1 {{mission was}} highly successful, proving the {{feasibility}} {{of the concept of}} carrying out <b>complex</b> <b>experiments</b> in space using non-NASA persons trained as payload specialists in collaboration with a POCC. Moreover, the TDRS-1 satellite, now fully operational, was able to relay significant amounts of data through its ground terminal to the POCC.|$|R
50|$|At Medfield College, science buff Dexter Riley and his friends, {{including}} Richard Schuyler and Debbie Dawson, eavesdrop via {{a hidden}} walkie-talkie {{on a board}} meeting led by Dean Eugene Higgins, discussing the small college's continuing precarious finances. Later that afternoon, Professor Lufkin shows Higgins around the science lab where Dexter is working on an experiment with invisibility and another student, Druffle, explores the flight of bumblebees. That night, unknown to anyone, during a powerful thunderstorm, {{the roof of the}} lab is struck by lightning, sending a current of electricity down a metal beam and through Dexter's <b>complex</b> <b>experiment</b> components. The next day, as Dexter examines his burnt equipment with dismay, Higgins meets with A.J. Arno, a recently released prisoner, who had also purchased Medfield's mortgage. When Dexter accidentally drops one half of his glasses into a container of his experimental formula, it appears as if the substance destroys them, but upon closer examination, Dexter realizes the frames are merely partially invisible. After several excited tests, Dexter boldly places his fingers in the liquid and they disappear. Schuyler and Debbie arrive and are horrified to see Dexter with a partial hand, but Dexter insists Schuyler test the substance as well, admitting only afterward that he does not yet have an antidote.|$|E
40|$|In {{accordance}} {{with the ideas of}} I. Hacking and P. Galison, and the “theoretical-operational” structure of experiment of Fock-Lipkin, a symbolic language is developed for the description of structure of a contemporary <b>complex</b> <b>experiment.</b> With its help a particle accelerator-based experiment is analysed as an example of this kind of experiments, where explication and analysis of the following essential features is performed: the roles of instrument, background, data analysis, and their theoretical components. An attempt is made to clarify the concepts of “instrument” and “complexity” of experiment...|$|E
40|$|The {{structure}} and composition of the microbiota are of critical importance {{for a variety of}} areas, including human health, environmental conservation, and bioenergy. To understand the dynamics of the microbiome, interactions between the micobiota and the host or the environment are now frequently studied, but these approaches do not fully take advantage of the phylogenetic structure in the microbiome data and their ad hoc nature make it difficult to accommodate <b>complex</b> <b>experiment</b> designs. Furthermore, the methodology for statistical inference regarding microbiota {{structure and}} composition is still quite limited. In order to provide a formal statistical framework, we proposed a variational Bayesian approach to compute the posterior distribution and make inference on the dynamic effect of the host or environmental factors. This method can be seen {{as an extension of the}} Factorial Hidden Markov Model with the message passing algorithm over continuous Markov processes. In our examples, variables that associate with the phylogenetic tree represent microbiota {{structure and composition}} rather than nucleotide sequences. The computation was performed through a message passing algorithm nested inside the EM algorithm for parameter optimization. We illustrated the application of the proposed method with two actual datasets and used simulation to evaluate its properties. We also proposed further extensions for <b>complex</b> <b>experiment</b> designs and addressed other areas of application. ...|$|E
5000|$|Experimental design {{remains a}} core {{area of study}} in {{chemometrics}} and several monographs are specifically devoted to experimental design in chemical applications. [...] Sound principles of experimental design have been widely adopted within the chemometrics community, although many <b>complex</b> <b>experiments</b> are purely observational, and {{there can be little}} control over the properties and interrelationships of the samples and sample properties.|$|R
30|$|As new {{and more}} <b>complex</b> <b>experiments</b> were {{designed}} [8, 13 – 15], new peripheral equipment {{was added to the}} system, most of it to provide some kind of interaction, such as push buttons included in the steering wheel body or a light barrier detection system. However, in most cases the associated data could only be stored synchronously to be post-processed {{with the rest of the}} session data.|$|R
50|$|Annabella Selloni {{from the}} Princeton University, {{was awarded the}} status of Fellow in the American Physical Society, after they were {{nominated}} by their Division of Computational Physics in 2008, for her pioneering first-principles computational studies of surfaces and interfaces, which made possible the interpretation of <b>complex</b> <b>experiments,</b> and successfully predicted the physical, and chemical properties of broad classes of materials, including materials for photovoltaic applications.|$|R
30|$|Hydroclimatic {{research}} requires highly intensive {{resources in}} terms of computation and data to perform simulations. Setting up <b>complex</b> <b>experiment</b> environment and configurations to submit jobs in computational clusters as well as managing user’s limited storage spaces by transferring big size data into the secondary storage are complicated and time-consuming. As a possible answer to address such issues in hydroclimatic research, new technologies, software-defined storage and containers have been introduced. When the two technologies are combined to support hydroclimatic simulations, we discuss how the software-defined storage data infrastructure strengthens containers {{in terms of}} flexibility of data handling and storage scalability.|$|E
40|$|The ATLAS {{detector}} is a {{large and}} <b>complex</b> <b>experiment.</b> Commissioning of the various components, both separately and together, is a challenging task which requires a methodology and a sustained and detailed plan of work. The commissioning stages of ATLAS will be described, together with an overview of results obtained during the construction and the integration so far. Once installed and functional the {{various parts of the}} detectors are operated with cosmic particles in several combinations. The performance of the detector components, both individually and in combination, has been also measured in a series of test beam data taken over the last years...|$|E
30|$|Towards {{understanding}} and improving forensics analysis processes, in this work, we conduct a <b>complex</b> <b>experiment</b> {{in which we}} systematically monitor the manual forensics analysis of live suspected infections in a large production university network that serves {{tens of thousands of}} hosts. In particular, over a period of 4 weeks, we manually investigate, in coordination with the IT department of our university, 200 security incidents about compromised hosts detected by an IDS alert correlator. The security investigation combines data from four security sources: (1) Snort alerts, (2) reports from four scanning and vulnerability assessment tools, (3) five independent blacklists, and (4) a search engine (Google).|$|E
40|$|In {{recent years}} 2 -dimensional radiation-magneto-hydrodynamic (RMHD) {{calculations}} have done quite well in matching some important observed parameters of a z-pinch implosion. As the authors gain experience, they field more <b>complex</b> <b>experiments</b> {{to compare with}} calculations. Here they discuss both time dependent and time integrated x-ray imaging on Pegasus. Images, using similar filters, are calculated and compared with the data. They also apply some image enhancement to the data...|$|R
50|$|LinguaStream {{is above}} all a virtual {{laboratory}} targeted to researchers in NLP. It allows for <b>complex</b> <b>experiments</b> on corpora to be realised conveniently, using {{various types of}} declarative formalisms, and reducing considerably the development costs. Its uses range from corpora exploration {{to the development of}} fully functional automatic analysers. An integrated environment is provided with the platform, where all the steps of the realisation of an experiment can be achieved.|$|R
40|$|Volunteer desktop grids are {{nowadays}} {{becoming more}} and more powerful thanks to improved high end components: multi-core CPUs, larger RAM memories and hard disks, better network connectivity and bandwidth, etc. As a result, desktop grid systems can run more <b>complex</b> <b>experiments</b> or simulations, but some problems remain: the heterogeneity of hardware architectures and software (library dependencies, code length, big repositories, etc.) make it very difﬁcult for researchers and developers to deploy and maintain a software stack for all the available platforms. In this paper, the employment of virtualization is shown to be the key to solve these problems. It provides a homogeneous layer allowing researchers to focus their efforts on running their experiments. Inside virtual custom execution environments, researchers can control and deploy very <b>complex</b> <b>experiments</b> or simulations running on heterogeneous grids of high-end computers. The following work presents the latest results from CERN’s LHC@home Test 4 Theory project, the ﬁrst BOINC project using virtualization technology, where all the simulations are run inside virtual machines {{on a wide variety of}} volunteers’ platforms...|$|R
40|$|A paraître dans NIMThe ATLAS {{detector}} is a {{large and}} <b>complex</b> <b>experiment.</b> Commissioning of the various components, both separately and together, is a challenging task which requires a methodology and a sustained and detailed plan of work. The commissioning stages of ATLAS will be described, together with an overview of results obtained during the construction and the integration so far. Once installed and functional the {{various parts of the}} detectors are operated with cosmic particles in several combinations. The performance of the detector components, both individually and in combination, has been also measured in a series of test beam data taken over the last years...|$|E
40|$|Reproducibility of Science is {{considered}} {{as one of the}} main principles of the scientific method, and refers to the ability of an experiment to be accurately reproduced, by third person, in <b>complex</b> <b>experiment</b> every detail matters to ensure the correct reproducibility. In the context of the ICCS 2011, Elsevier organized the executable paper grand challenge a contest to improve the way scientific information is communicated and used. While during this contest the focus was on developing methods and technique to realize the idea of executable papers, in this paper we focus on the operational issues related to the creation a viable service with a predefined QoS...|$|E
40|$|The {{development}} of the Skylab M 512 Materials Processing Facility is traced from {{the design of a}} portable, self-contained electron beam welding system for terrestrial applications to the highly <b>complex</b> <b>experiment</b> system ultimately developed for three Skylab missions. The M 512 experiment facility was designed to support six in-space experiments intended to explore the advantages of manufacturing materials in the near-zero-gravity environment of Earth orbit. Detailed descriptions of the M 512 facility and related experiment hardware are provided, with discussions of hardware verification and man-machine interfaces included. An analysis of the operation of the facility and experiments during the three Skylab missions is presented, including discussions of the hardware performance, anomalies, and data returned to earth...|$|E
40|$|Adopting a {{groundbreaking}} approach, the highly regarded author shows how to design methods for planning increasingly <b>complex</b> <b>experiments.</b> He {{begins with a}} brief introduction to standard quality methods and the technology in standard electric circuits. The book then gives numerous examples of how to apply the proposed methodology {{in a series of}} real-life case studies. Although these case studies are taken from the printed circuit board industry, the methods are equally applicable to other fields of engineering...|$|R
40|$|Abstract We {{present a}} novel multi-robot {{simulator}} named ARGoS. ARGoS {{is designed to}} simulate <b>complex</b> <b>experiments</b> involving large swarms of robots of different types. ARGoS is the first multi-robot simulator that {{is at the same time}} both efficient (fast performance with many robots) and flexible (highly customizable for specific experiments). Novel design choices in ARGoS have enabled this breakthrough. First, in ARGoS, it is possible to partition the simulated space into multiple sub-spaces, managed by different physics engine...|$|R
40|$|A {{frequent}} {{problem in}} electronics systems for high energy physics experiments {{is to provide}} protection for personnel and equ&pment. Interlock systems are typically designed as an afterthought and as a result, the working environment around <b>complex</b> <b>experiments</b> with many independent high voltages or hazardous gas subsystems, and {{many different kinds of}} people involved, can be particularly dangerous. A set of modular hardware has been designed which makes possible a standardized, integrated, hierarchical system's approach and which can be easily tailored to custom requirements...|$|R
40|$|The European Union is a {{particularly}} <b>complex</b> <b>experiment</b> {{in the management of}} multilingualism, as compared to other international and supranational organizations, since each Member State has the right to have its own Language recognized as an official language. The 2004 enlargement proved especially challenging, with eight new official languages joining the list. The study compares the ways in which this challenge was met in different EU institutions. Good planning and differentiated managerial solutions, coherent with the mandate and constraints of different institutions, allowed the EU to manage a complex transition in such a way to balance successfully the pressure to control costs and the need to ensure democratic participation to all EU citizens, irrespective of their Language skills...|$|E
40|$|The Emerald Nanosatellite Project is a two-satellite {{mission to}} explore {{enabling}} technology for multi-satellite formation flying. Emerald’s relative positioning sensors and inter-satellite communication systems have limited range specifications, which have motivated {{the need for}} a space tether. The Space Tether team of the Emerald Nanosatellites designed, tested, and analyzed a tether deployment system to be utilized by the Emerald Nanosatellites. The system includes deployment of a Teflon based line called Spiderwire®, attachment of tether, and final cutting of tether. The greatest challenges that correspond to this project are the reduction of initial separation velocity of the two Emerald Nanosatellites, and the prediction of tether performance once in space. A <b>complex</b> <b>experiment</b> and empirical analysis was done to ensure appropriate performance of deployment and to prevent mission failure. ii...|$|E
40|$|In e-Science, {{meaningful}} experiment {{processes and}} workflow engines emerge as important scientific resources. A <b>complex</b> <b>experiment</b> often involves services and processes developed in different scientific domains. Aggregating different workflows into one meta workflow avoids unnecessary rewriting of experiment processes and thus improves the reuse efficiency. Remote workflow engines explore the computing power of distributed environment. However, {{the diversity of}} workflow description and execution models makes the integration between engines difficult. An agent framework uses ontology based communication language and makes the integration to semantic information of resources seamless, it is thus suitable for coupling distributed engines. In this paper, we present our work {{in the context of}} Dutch Virtual Laboratory for e-Science (VL-e) project. A semantic registry for describing workflow engines is implemented, and mobile agents are used to manage distributed workflow coordination...|$|E
30|$|By {{incorporating}} the Roadmap Interpreter and the Experiment Specification Language, Argos {{has turned into}} a sophisticated tool reducing the usual time required to develop experiments and opening up possibilities for designing highly <b>complex</b> <b>experiments,</b> allowing designers to reuse previous work and to concentrate on the experiment target rather than the details of running the experiment. In fact, with the new version of the car (with ESL), the experiment setup takes a few hours instead of several days {{as was the case with}} the previous version.|$|R
40|$|National audienceData mining {{depends on}} the ability to access machine {{readable}} metadata that describe genotypes, environmental conditions, and sampling times and strategy. XEmL interactive Designer provides an interactive graphical interface in which <b>complex</b> <b>experiments</b> can be designed, and conjointly generates machine-readable metadata files. It uses a new eXtensible Mark-up Language (XML) -derived dialect termed XEML. The Designer includes a new ontology for environmental conditions, called XEML Environment Ontology. However, to provide versatility, it is designed to be generic and accepts other commonly used ontology formats (OBO,OWL) ...|$|R
40|$|High {{fidelity}} experimental facilities play {{an important}} role in evaluating new sensornet protocols. In this chapter we will discuss the important elements of designing and implementing high fidelity sensornet testbeds, and we present in detail the elements of NetEye – a testbed with desirable features such as highfidelity wireless environment, cost-effective hardware, web interface, and software tools to enable users to run potentially <b>complex</b> <b>experiments.</b> For instance, we will examine in detail the hardware details, software systems, and implementation (e. g., interference control) of NetEye. 1...|$|R
