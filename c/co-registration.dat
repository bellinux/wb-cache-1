879|10|Public
25|$|In some centers, {{the nuclear}} {{medicine}} scans can be superimposed, using software or hybrid cameras, on images from modalities such as CT or MRI {{to highlight the}} part of the body in which the radiopharmaceutical is concentrated. This practice {{is often referred to as}} image fusion or <b>co-registration,</b> for example SPECT/CT and PET/CT. The fusion imaging technique in nuclear medicine provides information about the anatomy and function, which would otherwise be unavailable or would require a more invasive procedure or surgery.|$|E
2500|$|Registration path or <b>co-registration</b> {{affiliates}} who include {{offers from}} other merchants during the registration process {{on their own}} website ...|$|E
50|$|<b>Co-registration</b> advertising: The {{advertiser}} receives {{some or all}} of {{the standard}} fields collected by a site during the site's registration process.|$|E
40|$|We {{expect to}} {{demonstrate}} {{the reliability of the}} EEG/fMRI technique in identifying the epileptogenic zone and its related neural networks in epilepsy surgery patients. These results could support the clinical application of EEG/fMRI <b>co-registrations</b> in the pre-surgical workup of patients with symptomatic epilepsy and in guiding subsequent planting of intra-cerebral electrodes in complex cases that can’t avoid intra-cerebral recordings...|$|R
30|$|From a {{practical}} point of view, it is well-reasoned to seek alternative implementations for ALS inventories {{relying on the}} availability of both the ALS and image data. Even though aerial images are usually available for the purpose of visual forest stand delineation, using them as additional data complicates the inventory system due to the required <b>co-registrations</b> and calibrations of the radiometric differences of multiple images. Plot-level species-specific predictions based solely on ALS data have also been tested (Ørka et al. 2013; Vauhkonen et al. 2012, 2014 b). The predictions related to the dominant species in particular have been accurate based on ALS data (Ørka et al. 2013), but the availability of the spectral data has generally improved the predictions (Vauhkonen et al. 2012; Ørka et al. 2013).|$|R
40|$|The European Fireball Network (EN) {{has been}} {{continuously}} operating since 1966 (Figure 1). Beginning in 1995, observing stations in Germany have been managed {{and operated by}} the DLR Institute of Planetary Research, Berlin. The stations in Germany are of the classical type, consisting of cameras on a tripod, looking down and taking images of a paraboloidal mirror. Rotating shutters mounted {{in front of the}} camera lens provide velocity information for the fast-moving meteors. Cameras are equipped with film. Typically, one longexposure image is taken every night, covering the whole sky (Figure 1). In 2011, 14 cameras were in regular operation. 59 fireballs on 81 photographs could be recorded, representing an extraordinary “fireball yield”. The number of 78 fireball <b>co-registrations</b> with other central-European camera systems was extraordinary as well. Data reduction and orbit reconstruction (carried out at Ondřejov Observatory, P. Spurný and team) was possible for 6 meteors. The brightest meteor, registered on May 4, had a magnitude of - 10. In the area monitored by the cameras, one fireball was recorded (Figure 1), following which, with high probability, a meteorite fall occurred. Unfortunately, due to terrain conditions within the urban area of Berlin no meteorites could be recovered...|$|R
50|$|The network {{distributes}} targeted campaigns {{on behalf}} of advertisers through its affiliate network of website, paid search, incentive, lead generation, subscriber email, and <b>co-registration</b> publishers. Advertisers are charged on a per-result basis for verified sales, new member signups, qualified leads or other defined transaction.|$|E
50|$|PPA pricing {{models are}} more advertiser-friendly {{as they are}} less {{susceptible}} to fraud and bots. With pay per click, providers can commit fraud by manufacturing leads or blending one source of lead with another (example: search-driven leads with <b>co-registration</b> leads) to generate higher profits for themselves.|$|E
50|$|A {{possible}} drawback of multichannel ScanSAR or TOPS approaches is {{the rather}} high Doppler centroid, {{which is one}} of the most important parameters need to be estimated in computing SAR images. For some of the imaged targets, in case high resolution is desired. Moreover, high squint angles may also challenge <b>co-registration</b> in interferometric applications.|$|E
40|$|BACKGROUND To {{examine the}} {{site-specific}} cancer mortality among deaths registered with Parkinson's disease (PD) and multiple sclerosis (MS). We {{focused on the}} patterns related to the most frequent cancers. METHODS We analyzed Swiss mortality data over a 39 -year period (1969 - 2007), using a statistical approach applicable to unique daabases, i. e. when no linkage with morbidity databases or disease registries is possible. It {{was based on a}} case-control design with bootstrapping to derive standardized mortality ratios (SMR). The cases were defined by the cancer-PD or cancer-MS <b>co-registrations,</b> whereas the controls were drawn from the remaining records with cancer deaths (matching criteria: sex, age, language region of Switzerland, subperiods 1969 - 1981, 1982 - 1994, 1995 - 2007). RESULTS For PD we found lower SMRs in lung and liver cancer and higher SMRs in melanoma/skin cancer, and in cancers of breast and prostate. As for MS, the SMR in lung cancer was lower than expected, whereas SMRs in colorectal, breast and bladder cancer were higher. CONCLUSIONS A common pattern of associations can be observed in PD and MS, with a lower risk of lung cancer and higher risk of breast cancer than expected. Thus, PD and MS resemble other conditions with similar (schizophrenia) or reversed patterns (rheumatoid arthritis, immunosuppression after organ transplantation) ...|$|R
40|$|Abstract: Multimodal {{integration}} {{in the field of}} human brain mapping has evolved from structural-functional <b>co-registrations</b> toward functional-functional combinations. This paper briefly reviews fMRI-EEG, fMRI-NIRS, EEG-NIRS, and fMRI-EEG-NIRS combinations. OCIS codes: Inverse problems (100. 3190); Functional monitoring and imaging (170. 2655); Medical and biological imaging (170. 3880); Physiology (170. 5380); Time-resolved imaging (170. 6920); Tomography (170. 6960). 1. Functional neuroimaging and multimodal integration After years of incubation [1], noninvasive functional imaging of the human brain {{came of age in the}} 1990 s [2] with discovery and utilization of the intrinsic BOLD (blood oxygen level dependent) signal of fMRI (functional magnetic resonance imaging) [3 - 5]; the establishment in 1993 of two journals, NeuroImage and Human Brain Mapping; and the inaugural 1995 meeting in Paris of the Organization of Human Brain Mapping. The field flourished in the 2000 s in an upward trend that shows no sign of abating, e. g., as indexed by PubMed. Queries for each year from 2000 to 2010 indicate that fMRI-related publications increased steadily by about 1660 per year. In the same period, EEG/ERP (electroencephalography and event-related potential) publications increased about 370 per year; those for MEG/ERF (magnetoencephalography and event-related field) increased about 22 per year; and brain NIRS (near-infrared spectroscopy) [6] publications increased about 15 per year...|$|R
40|$|The European Fireball Network (EN) {{has been}} {{continuously}} operating since 1966 (Fig. 1). Beginning in 1995, observing stations in Germany have been {{operated by the}} DLR Institute of Planetary Research. The stations in Germany are of the classical type, consisting of cameras on a tripod, looking down and taking images of a spherical mirror. Rotating shutters mounted {{in front of the}} camera lens provide velocity information for the fast-moving meteors. Cameras are equipped with film. Typically, one long-exposure image is taken every night. In 2010, 15 cameras were in regular operation. 36 fireballs on 82 photographs could be recorded, representing average “fireball yield”. Fireball <b>co-registrations</b> could be made with other EN stations in 20 cases, and in 3 cases with other camera types. Data reduction and orbit reconstruction (carried out at Ondřejov Observatory, P. Spurný and team) was possible for 1 meteor. The brightest meteor that was recorded in 2010 had a magnitude of - 13. Progress has been made in development of a prototype digital camera version. Quite remarkably, in the area monitored by the cameras, 2 meteorite falls were recovered mainly using eyewitness reports to guide the meteorite search. Due to weather and daylight hours, no images from the cameras could be obtained. This contribution will describe the activities and results of 2010. ...|$|R
5000|$|In {{the field}} of direct marketing, the {{subscriber}} list is considered {{the most important part}} of a mailing campaign. Marketers devote a great deal of time and money to collecting a [...] "list" [...] of highly targeted subscribers as a result. Common methods for gathering a mail list include business reply mail, telemarketing, list rentals, and <b>co-registration</b> agreements.|$|E
50|$|Webshots {{has been}} in {{business}} since 1995 and has derived revenue from various services, including banner advertising, paid sponsorships, software bundling, branded downloads, client software advertising, <b>co-registration</b> deals, software sales, premium memberships, and print and gift merchandise sales. In 2010 American Greetings bundled Kiwee Toolbar with the Webshots Desktop and generated some complaints and controversy because of the toolbar's labeling as malware. It was unbundled in 2011.|$|E
50|$|In some centers, {{the nuclear}} {{medicine}} scans can be superimposed, using software or hybrid cameras, on images from modalities such as CT or MRI {{to highlight the}} part of the body in which the radiopharmaceutical is concentrated. This practice {{is often referred to as}} image fusion or <b>co-registration,</b> for example SPECT/CT and PET/CT. The fusion imaging technique in nuclear medicine provides information about the anatomy and function, which would otherwise be unavailable or would require a more invasive procedure or surgery.|$|E
30|$|The CTA volumes (which {{included}} carotid {{arteries and}} neck region) were cropped to include only the brain region. This {{was done to}} decrease memory requirements. To include information from the contralateral hemisphere, an additional set of images was created by flipping {{the left and right}} sides of the original CTA-SI, hereafter called hemispheric comparison volume. This allowed for the inclusion of the information from the approximate contralateral anatomical regions for the CNN training and evaluation. The flipped images and the NCCT images were then matched to the original images using rigid registration. The image <b>co-registrations</b> were done using BRAINSFit tool [18]. Approximate intracranial spaces were identified using an in-house MATLAB (MathWorks, Inc., Natick, MA, USA) script. Then, the data were scaled to zero mean and unit variance in the brain regions. Finally, all the volumes across the data set were resampled to 0.5 [*]×[*] 0.5 [*]×[*] 0.5 [*]mm isotropic resolution. Convert 3 D (part of ITK-SNAP toolkit [19]) command-line tool was used for rescaling and resampling. The consistent voxel size across the data and the intensity shift and rescaling were required for the CNN framework in use. Within each subject, the volumes, including the manual lesion delineations via the nearest neighbor resampling, were in the same image space. All the pre-processing tools had command-line interfaces allowing easy automation and preprocessing multiple subjects in parallel.|$|R
40|$|Spatial {{specificities}} of the calcium-dependent synaptic activ-ity, hemodynamic-based blood oxygenation level-dependent (BOLD) and cerebral {{blood flow}} (CBF) fMRI were quantita-tively compared in the same animals. Calcium-dependent synaptic activity was imaged by exploiting the manganese ion (Mn 11) as a calcium analog and an MRI contrast agent at 9. 4 T. Following forepaw stimulation in a-chloralose anesthe-tized rat, water T 1 of the contralateral forepaw somatosen-sory cortex (SI) was focally and markedly reduced from 1. 99 6 0. 03 sec to 1. 30 6 0. 18 sec (mean 6 SD, N 5 7), resulting from the preferential intracellular Mn 11 accumula-tion. Based on an in vitro calibration, the estimated contralat-eral somatosensory cortex [Mn 11] was; 100 mM, which was 2 – 5 -fold higher than the neighboring tissue and the ipsilateral SI. Regions with the highest calcium activities were localized around cortical layer IV. Stimulus-induced BOLD and CBF changes were 3. 4 6 1. 6 % and 98 6 33 %, respectively. The T 1 synaptic activity maps extended along the cortex, whereas the hemodynamic-based activation maps extended radially along the vessels. Spatial overlaps among the synaptic activity, BOLD, and CBF activation maps showed excellent <b>co-registrations.</b> The cen-ter-of-mass offsets between any two activation maps were less than 200 mm, suggesting that hemodynamic-based fMRI tech-niques (at least at high field) {{can be used to}} accurately map the spatial loci of synaptic activity. Magn Reson Med 43 : 383 – 392...|$|R
40|$|The Extreme-Ultraviolet Normal-Incidence Spectrograph (EUNIS) is a {{sounding}} rocket instrument that obtains imaged high-resolution solar spectra. It has now had two successful flights, on 2006 April 12 and 2007 November 16, providing {{data to support}} underflight calibrations {{for a number of}} orbiting solar experiments on both occasions. A regular part of each campaign is the end-to-end radiometric calibration of the rocket payload carried out at RAL in the UK, using the same facility that provided pre-flight CDS and EIS calibrations. The measurements, traceable to primary radiometric standards, can establish the absolute EUNIS response within a relative uncertainty of 10 % over its full longwave bandpass of 300 - 370 A. During each EUNIS flight, coordinated observations are made of overlapping solar locations by all participating space experiments, and identified by subsequent image <b>co-registrations,</b> allowing the EUNIS calibrations to be applied to these other instruments as well. The calibration transfer is straightforward for wavelengths within the EUNIS LW bandpass, and is extended to other wavelengths by means of a series of 'insensitive' line-ratios, with one line of each pair in the calibrated band and the other in the transfer band. In this way, the EUNIS- 06 flight is able to update the radiometric calibrations of CDS NISl (plus 2 nd order NIS 2 near 2 x 304 A), all four channels of EIT, and the three EUV channels of TRACE. The EUNIS- 07 flight will further update those missions, as well as both channels of Hinode/EIT and all four channels of STEREO/SECCHI/EUVI. Future EUNIS flights have been proposed that will continue this underflight calibration service. EUNIS is supported by the NASA Heliophysics Division through its Low Cost Access to Space Program in Solar and Heliospheric Physics...|$|R
50|$|As {{a theory}} of phonological representation, autosegmental {{phonology}} developed a formal account of ideas that had been sketched in earlier work by several linguists, notably Bernard Bloch (1948), Charles Hockett (1955) and J. R. Firth (1948). On such a view, phonological representations consist {{of more than one}} linear sequence of segments; each linear sequence constitutes a separate tier. The <b>co-registration</b> of elements (or autosegments) on one tier with those on another is represented by association lines. There is a close relationship between analysis of segments into distinctive features and an autosegmental analysis; each feature in a language appears on exactly one tier.|$|E
50|$|The 3D {{processing}} {{is done in}} two steps: the azimuth {{and range}} direction are focused for the generation of 2D (azimuth-range) high-resolution images, after which a digital elevation model (DEM) is {{used to measure the}} phase differences between complex images, which is determined from different look angles to recover the height information. This height information, along with the azimuth-range coordinates provided by 2-D SAR focusing, gives the third dimension, which is the elevation direction. The first step requires only standard processing algorithms, for the second step, an additional pre-processing stage such as image <b>co-registration</b> and phase calibration is used.|$|E
50|$|The {{instantaneous}} wave-free ratio {{can also}} be calculated on a beat-to-beat basis. If performed during the slow withdrawal of a pressure wire (referred to as 'pullback') under resting conditions, {{it is possible to}} plot the change of iFR or trans-stenotic gradient over the wave-free period throughout the vessel. This can help identify focal and diffuse coronary disease potentially amenable to revascularisation. An example of pullback in clinical use can be seen in this video. The pressure wire data can be co-registered with the angiographic findings to aid ease of interpretation. With mechanised pullback approaches which move the pressure wire at a fixed speed, the physiological length of a stenosis can be determined. With advanced live <b>co-registration</b> this is also feasible with during manual pullback.|$|E
40|$|Imaging {{the fetal}} brain in utero is {{challenging}} {{due to the}} unpredictable motion of the fetus. Although ultra-fast MRI sequences are able to image a 2 D slice in under a second, thus limiting the time in which fetal motion can corrupt images, Cartesian sampling makes these sequences sensitive to signal misregistration and motion-corruption. Corruption of a single 2 D slice renders it impossible to reconstruct 3 D volumes from these slices without complex slice-to-volume registration. There {{is a need for}} motion-robust sequences that can produce high-resolution 3 D volumes of the fetal brain. The Siemens Cardiovascular sequence was edited to produce a new radial readout that sampled a 3 D spherical volume of k-space with successive diametric spokes. The diameter end points map a spiral trajectory on the surface of a sphere. The trajectory was modified so that multiple sub-volumes of data are sampled during a single acquisition where M is the number of sub-spirals and N is the number of diametric spokes per sub-spiral. This allows reconstruction of individual sub-volumes of data to produce a series of low-resolution navigator images that can be co-registered to provide information on motion during the acquisition. In this way, a segmented sequence suited to self-navigation was developed. Imaging parameters for the 3 D radial sequence were optimised based on theoretical calculations and scans performed in adult brains and abdomens. Optimum values for M and N needed to be determined. Increasing M for a constant total number of projections improves the temporal accuracy of motion tracking at the expense of decreased signal to noise ratio in the navigator images. The effects of breathing and rigid body motion on image quality were also compared between 3 D radial and equivalent 3 D Cartesian acquisitions. Custom reconstruction code was written to separate the incoming scan data according to the sub-spiral trajectories described within the sequence such that individual navigator images could be reconstructed. Successive sub-spiral images were co-registered to the first navigator image to quantify motion during the acquisition. The resulting transformation matrices were then applied to each sub-spiral image after reconstruction and co-registered sub-spiral images combined in image space to generate the final 3 D volume. To improve the quality of navigator images, a method is presented to perform navigator image reconstruction at a lower base resolution, thus reducing streaking artifacts and improving the accuracy of image <b>co-registrations.</b> Finally, the methods developed were applied to two fetal scans. The radial sequence was shown to be more motion-robust than an equivalent Cartesian sequence. The minimum number of diametric spokes that provided navigator images that could be accurately co-registered when scanning an adult brain was N= 256, which could be acquired in 1. 25 s. For abdominal scans, the minimum number of spokes was N= 1024, which could be acquired in about 6 s when water excitation is applied. However, the latter could potentially be reduced by reconstructing navigator images at a lower base resolution. Although fetal scans demonstrated poor image contrast, navigator images were able to track motion during the acquisition demonstrating the potential use of this method for self-navigation. In conclusion, a motion-robust radial sequence is presented with potential applications for prospective navigation during fetal MRI...|$|R
50|$|Cost per action {{advertising}} (e.g. TalkLocal, Thumbtack) {{addresses the}} risk of CPM and CPC advertising by charging only by the lead. Like CPC, the price per lead can be bid up by demand. Also, like CPC, there are ways in which providers can commit fraud by manufacturing leads or blending one source of lead with another (example: search-driven leads with <b>co-registration</b> leads) to generate higher profits. For such marketers looking to pay only for specific actions, there are two options: CPL advertising (or online lead generation) and CPA advertising (also referred to as affiliate marketing). In CPL campaigns, advertisers pay for an interested lead — i.e. the contact information of a person interested in the advertiser's product or service. CPL campaigns are suitable for brand marketers and direct response marketers looking to engage consumers at multiple touchpoints — by building a newsletter list, community site, reward program or member acquisition program. In CPA campaigns, the advertiser typically pays for a completed sale involving a credit card transaction.|$|E
50|$|A {{fundamental}} {{requirement of}} {{the removal of the}} ground signal is that the sum of phase contributions from the individual targets within the pixel remains constant between the two images and is completely removed. However, there are several factors that can cause this criterion to fail. Firstly the two images must be accurately co-registered to a sub-pixel level to ensure that the same ground targets are contributing to that pixel. There is also a geometric constraint on the maximum length of the baseline - the difference in viewing angles must not cause phase to change over the width of one pixel by more than a wavelength. The effects of topography also influence the condition, and baselines need to be shorter if terrain gradients are high. Where <b>co-registration</b> is poor or the maximum baseline is exceeded the pixel phase will become incoherent - the phase becomes essentially random from pixel to pixel rather than varying smoothly, and the area appears noisy. This is also true for anything else that changes the contributions to the phase within each pixel, for example changes to the ground targets in each pixel caused by vegetation growth, landslides, agriculture or snow cover.|$|E
40|$|International audienceBy definition, as {{they require}} the images to merge to be superimposable, « pixel to pixel » fusion {{processes}} raise {{up the issue}} of the outcome of geometric <b>co-registration</b> quality on the resulting images. Indeed, local errors of geometric <b>co-registration</b> may introduce local errors in the merging process. Hence, we can wonder how can we define and reach the <b>co-registration</b> quality level that is required to minimise errors in « pixel to pixel » merging processes. The aim of this work is to understand, thanks to an example of such fusion process applied to images with different degrees of geometric distortions, the outcome of <b>co-registration</b> error on the fusion quality and, therefore, to measure the efficiency of some <b>co-registration</b> methods for the pre-processing of « pixel to pixel » merging application...|$|E
40|$|International audienceThe {{issue of}} <b>co-registration</b> distortions between images {{is one of}} major {{problems}} involved in data fusion processes. This conclusion can be extended to change detection generally also performing on a pixel basis. Accurate methods are therefore required for <b>co-registration</b> of images in these particular cases. It {{is the reason why}} we present a <b>co-registration</b> method using multi-resolution analysis and local deformation models. This work includes a validation protocol that enables the assessment of the accuracy, the robustness and the quality provided by any <b>co-registration</b> method. This validation protocol has been then applied to the presented method and the results have been compared to those provided by a standard one. According to this validation, this method provides a very fine correction of the geometric distortions that is better than those generally provided by standard <b>co-registration</b> methods. As a conclusion, this method seems to constitute an answer to the need of high quality <b>co-registration</b> as a pre-processing of fusion and change detection processes. Moreover, it is a fully automatic method that potentially enables an operational utilisation of high quality...|$|E
40|$|Coregistration of {{airborne}} laser scanning data and aerial images Abstract This thesis {{is dealing with}} the <b>co-registration</b> of aerial laser scanning and aerial images. Theoretical part with research of current methods puts emphasis on methods suitable for remote sensing datasets. Part of the thesis is about pre-processing data for <b>co-registration</b> and DSM production. Selection of co- registration methods for remote sensing is based on previous researches. Selected <b>co-registration</b> methods are applied on datasets from EuroSDR research project and ČÚZK dataset. Application is realised by programming codes and functions that were created for this purpose in Matlab. Possibilities of usage, advantages and disadvantages of methods are being mentioned in the next parts of the thesis with emphasis on time of the computation and final accuracy. The function programmed in Matlab allows comparison of <b>co-registration</b> methods and allows the user to decide which of the co- registration methods to use on input datasets. Discussion section describes the possibilities of method extensions and problematic parts across the whole <b>co-registration</b> process. Keywords: <b>co-registration,</b> laser, scanning, images, photogrammetry, remote sensing, coordinate, image matching...|$|E
40|$|<b>Co-registration</b> {{is one of}} {{the most}} {{important}} steps in interferometric synthetic aperture radar (InSAR) data processing. The standard offset-measurement method based on cross-correlating uniformly distributed patches takes no account of specific geometric transformation between images or characteristics of ground scatterers. Hence, it is inefficient and difficult to obtain satisfying <b>co-registration</b> results for image pairs with relatively big distortion or large incoherent areas. Given this, an improved <b>co-registration</b> strategy is proposed in this paper which takes both the geometric features and image content into consideration. Firstly, some geometric transformations including scale, flip, rotation, and shear between images were eliminated based on the geometrical information, and the initial <b>co-registration</b> polynomial was obtained. Then the registration points were automatically detected by integrating the signal-to-clutter-ratio (SCR) thresholds and the amplitude information, and a further <b>co-registration</b> process was performed to refine the polynomial. Several comparison experiments were carried out using 2 TerraSAR-X data from the Hong Kong airport and 21 PALSAR data from the Donghai Bridge. Experiment results demonstrate that the proposed method brings accuracy and efficiency improvements for <b>co-registration</b> and processing abilities in the cases of big distortion between images or large incoherent areas in the images. For most co-registrations, the proposed method can enhance the reliability and applicability of <b>co-registration</b> and thus promote the automation to a higher level...|$|E
40|$|Image fusion {{involving}} real-time ultrasound (US) is {{a technique}} where previously recorded computed tomography (CT) or magnetic resonance images (MRI) are reformatted in a projection to fit the real-time US images after an initial <b>co-registration.</b> The <b>co-registration</b> aligns the images by means of common planes or points. We evaluated {{the accuracy of the}} alignment when varying parameters as patient position, respiratory phase and distance from the <b>co-registration</b> points/planes. We performed a total of 80 co-registrations and obtained the highest accuracy when the respiratory phase for the <b>co-registration</b> procedure was the same as when the CT or MRI was obtained. Furthermore, choosing <b>co-registration</b> points/planes close to the area of interest also improved the accuracy. With all settings optimized a mean error of 3. 2 mm was obtained. We conclude that image fusion involving real-time US is an accurate method for abdominal examinations and that the accuracy is influenced by various adjustable factors that should be kept in mind...|$|E
40|$|International audienceThis paper {{deals with}} the <b>co-registration</b> of an MRI scan with EEG sensors. We set out to {{evaluate}} the effectiveness of a 3 D handheld laser scanner, a device that is not widely used for <b>co-registration,</b> applying a semi-automatic procedure that also labels EEG sensors. The scanner acquired the sensors' positions and the face shape, and the scalp mesh was obtained from the MRI scan. A pre-alignment step, using the position of three fiducial landmarks, provided an initial value for <b>co-registration,</b> and the sensors were automatically labeled. <b>Co-registration</b> was then performed using an iterative closest point algorithm applied to the face shape. The procedure was conducted on five subjects with two scans of EEG sensors and one MRI scan each. The mean time for the digitization of the 64 sensors and three landmarks was 53 s. The average scanning time for the face shape was 2 min 6 s for an average number of 5, 263 points. The mean residual error of the sensors <b>co-registration</b> was 2. 11 mm. These results suggest that the laser scanner associated with an efficient <b>co-registration</b> and sensor labeling algorithm is sufficiently accurate, fast and user-friendly for longitudinal and retrospective brain sources imaging studies...|$|E
30|$|An initial <b>co-registration</b> {{between the}} images is {{made on the}} motion-free part of the images. In practice, the motion-free parts, i.e. {{mountains}} on the background, are used to perform it. This initial image <b>co-registration</b> on motion-free areas is realized by a translation without applying sub-pixel offsets.|$|E
40|$|The {{application}} of a new algorithm for the <b>co-registration</b> of interferometric SAR image pairs is presented. It {{is based on the}} spectral diversity properties of the complex SAR signal. The algorithm is applied to airborne repeat-pass interferometric SAR data proving its improved accuracy compared to conventional <b>co-registration</b> methods...|$|E
30|$|Given {{the small}} size (50 – 500 mm 3) of tumors in mice and the {{resolution}} of small-animal PET and fDOT scanners (1 – 2 mm), accurate and reliable <b>co-registration</b> between both modalities is essential. Among different <b>co-registration</b> methods that have been developed, such as geometrical co-calibration [11] and dynamic contrast methods [12], the use of fiducial markers (FM) [8] in close position {{to the body of}} the animal is the most straightforward and universal approach today. The coordinates of the FM in images acquired independently is used for the geometrical transformations leading to the fusion of images. <b>Co-registration</b> of large data sets from different imaging modalities results in time-consuming, tedious and operator-dependant image analyses when performed manually. Therefore, methods for the automatic identification of the FM's coordinates have been developed for <b>co-registration</b> of computed tomography (CT), PET and magnetic resonance imaging (MRI) modalities [13 – 18]. However, so far, these methods have not been adapted to <b>co-registration</b> with fDOT because fDOT reconstructions are spatially restricted and do not cover the FM positioning.|$|E
40|$|Successful change {{detection}} in multi-temporal images {{relies on}} high spatial <b>co-registration</b> accuracy. However, <b>co-registration</b> accuracy alone cannot {{meet the needs}} of change detection when using several ground control points to separately geo-reference multi-temporal images from unmanned aerial vehicles (UAVs). This letter reports on a new approach to perform bundle adjustment—named united bundle adjustment (UBA) —to solve this <b>co-registration</b> problem for change detection in multi-temporal UAV images. In UBA, multi-temporal UAV images are matched with each other to construct a unified tie point net. One single bundle adjustment process is performed on the unified tie point net, placing every image into the same coordinate system and thus automatically accomplishing spatial <b>co-registration.</b> We then perform change detection using both orthophotos and three-dimensional height information derived from dense image matching techniques. Experimental results show that UBA <b>co-registration</b> accuracy is higher than the accuracy of commonly-used approaches for multi-temporal UAV images. Our proposed preprocessing method extends the capacities of consumer-level UAVs so they can eventually meet the growing need for automatic building change detection and dynamic monitoring using only RGB band images...|$|E
40|$|AbstractBackgroundIntracoronary imaging {{provides}} accurate lesion delineation {{and precise}} measurements for sizing and positioning of coronary stents. During percutaneous coronary intervention (PCI), {{it may be}} challenging to identify corresponding segments between intracoronary imaging and angiography. Computer based online <b>co-registration</b> may aid the target segment identification. MethodsThe DOCTOR fusion study was a prospective, single arm, observational study including patients admitted for elective PCI. Optical coherence tomography (OCT) was acquired pre-stent implantation for sizing of stents. The operator subsequently indicated on the angiogram the target area as identified by OCT. Computer based <b>co-registration</b> was performed on-line immediately after pre-stent acquisition to assess feasibility. The cumulated numerical difference between operator based, and computer based <b>co-registration</b> was assessed as the “Operator Registration Error”. The operator implanted the stent blind to the co-registrated angiogram. The difference between the co-registered stent border positions and the actual stent deployment border positions was the “Geographic Miss Distance”. ResultsTwenty-two patients {{were included in the}} study. Two patients were excluded due to missing pre or post-OCT acquisitions. Online <b>co-registration</b> pre-stenting was successful in all analyzed cases. The mean “Operator Registration Error” was 5. 4 ± 3. 5 mm. The mean “Geographic Miss Distance” was 5. 4 ± 2. 6 mm. Without access to the computer-based <b>co-registration,</b> segments of the target lesion indicated on OCT were left uncovered by stent in 14 patients (70 %). ConclusionComputer based online <b>co-registration</b> of OCT and angiography is feasible. Frequent inaccuracies in operator based registration indicate that computer aided <b>co-registration</b> may reduce errors in corresponding OCT findings to the angiogram...|$|E
30|$|As {{shown in}} Fig.  2, {{for the typical}} example, fits {{obtained}} with 2 T 4 k+VB underestimate the 4.5  h p.i. activity concentrations in some patients. This may in part explain the lower correlations between simplified parameters and VT that were observed for 4.5  h data. The discrepancy could {{be the result of}} small differences in image-derived activity concentration due to <b>co-registration</b> errors. Although a laser alignment system together with a dedicated arm-support system were used to ensure proper positioning, and <b>co-registration</b> results were visually verified, small <b>co-registration</b> discrepancies are likely to occur as the thorax area is highly flexible.|$|E
