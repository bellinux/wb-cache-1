2973|2096|Public
25|$|OFDM is {{invariably}} used {{in conjunction}} with <b>channel</b> <b>coding</b> (forward error correction), and almost always uses frequency and/or time interleaving.|$|E
25|$|The AEP for non-stationary discrete-time {{independent}} process {{leads us}} to (among other results) source coding theorem for non-stationary source (with independent output symbols) and <b>channel</b> <b>coding</b> theorem for non-stationary memoryless channels.|$|E
25|$|<b>Channel</b> <b>coding</b> is {{concerned}} with finding such nearly optimal codes {{that can be used}} to transmit data over a noisy channel with a small coding error at a rate near the channel capacity.|$|E
40|$|Achievable {{distortion}} bounds {{are derived}} for the cascade of structured families of binary linear <b>channel</b> <b>codes</b> and binary lattice vector quantizers. It {{is known that}} for the cascade of asymptotically good <b>channel</b> <b>codes</b> and asymptotically good vector quantizers the endto -end distortion decays to zero exponentially fast {{as a function of}} the overall transmission rate, and is achieved by choosing a <b>channel</b> <b>code</b> rate that is independent of the overall transmission rate. We show that for certain families of practical <b>channel</b> <b>codes</b> and binary lattice vector quantizers, the overall distortion can still be made to decay to zero exponentially fast as the transmission rate grows, although the exponent is a sub-linear function of the transmission rate. This is achieved by carefully choosing a <b>channel</b> <b>code</b> rate that decays to zero as the transmission rate grows. Explicit <b>channel</b> <b>code</b> rate schedules are obtained for several well-known families of <b>channel</b> <b>codes.</b> 1 Introduction We exploit results fr [...] ...|$|R
40|$|In {{order to}} {{evaluate}} performance of strong <b>channel</b> <b>codes</b> in presence of imperfect carrier phase tracking for residual carrier BPSK modulation {{in this paper}} an approximate 'brick wall' model is developed which is independent of the <b>channel</b> <b>code</b> type for high data rates. It is shown that this approximation is reasonably accurate (less than 0. 7 dB for low FERs for (1784, 1 / 6) code and less than 0. 35 dB for low FERs for (5920, 1 / 6) code). Based on the approximation's accuracy, it is concluded {{that the effects of}} imperfect carrier tracking are more or less independent of the <b>channel</b> <b>code</b> type for strong <b>channel</b> <b>codes.</b> Therefore, the advantage that one strong <b>channel</b> <b>code</b> has over another with perfect carrier tracking translates to nearly the same advantage under imperfect carrier tracking conditions. This will allow the link designers to incorporate projected <b>channel</b> <b>code</b> performance of strong <b>channel</b> <b>codes</b> into their design tables without worrying about their behavior in the face of imperfect carrier phase tracking...|$|R
30|$|Moreover, {{in order}} to make a fair {{comparison}} among different <b>channel</b> <b>code</b> rates, we have kept fixed the total amount of data sent on the channel, i.e., the combined source and <b>channel</b> <b>code</b> rate R.|$|R
25|$|Coding {{theory is}} one of the most {{important}} and direct applications of information theory. It can be subdivided into source coding theory and <b>channel</b> <b>coding</b> theory. Using a statistical description for data, information theory quantifies the number of bits needed to describe the data, which is the information entropy of the source.|$|E
25|$|Morse Code {{cannot be}} treated as a {{classical}} radioteletype (RTTY) signal when it comes to calculating a link margin or a link budget for the simple reason of it possessing variable length dots and dashes as well as variant timing between letters and words. For the purposes of Information Theory and <b>Channel</b> <b>Coding</b> comparisons, the word PARIS is used to determine Morse Code's properties because it has an even number of dots and dashes.|$|E
25|$|The {{field is}} at the {{intersection}} of mathematics, statistics, computer science, physics, neurobiology, and electrical engineering. The theory has also found applications in other areas, including statistical inference, natural language processing, cryptography, neurobiology, the evolution and function of molecular codes (bioinformatics), model selection in statistics, thermal physics, quantum computing, linguistics, plagiarism detection, pattern recognition, and anomaly detection. Important sub-fields of information theory include source coding, <b>channel</b> <b>coding,</b> algorithmic complexity theory, algorithmic information theory, information-theoretic security, and measures of information.|$|E
2500|$|... {{communications}} - Digital Communications, Error Correcting <b>Codes</b> (<b>Channel</b> <b>Code),</b> Source Code functions, Modulation and Galois Fields ...|$|R
50|$|After DISCUS {{system was}} proposed, more {{sophisticated}} <b>channel</b> <b>codes</b> have been {{adapted to the}} DSC system, such as Turbo Code, LDPC <b>Code</b> and Iterative <b>Channel</b> <b>Code.</b> The encoders of these codes are usually simple and easy to implement, while the decoders have much higher computational complexity {{and are able to}} get good performance by utilizing source statistics. With sophisticated <b>channel</b> <b>codes</b> which have performance approaching the capacity of the correlation channel, corresponding DSC system can approach the Slepian-Wolf bound.|$|R
40|$|Abstractâ€”A novel hybrid genetic {{algorithm}} (GA) for jointly optimizing source and <b>channel</b> <b>codes</b> {{is presented in}} this paper. The algorithm first uses GA for the coarse search of source and <b>channel</b> <b>codes.</b> An iterative search is then followed for the refinement of the coarse search. The hybrid GA enhances the robustness of the design of source and <b>channel</b> <b>codes.</b> The distributed GA scheme {{can also be used}} in conjunction with the proposed hybrid GA algorithm for further performance improvement...|$|R
25|$|The {{resilience}} {{to severe}} channel conditions {{can be further}} enhanced if information about the channel is sent over a return-channel. Based on this feedback information, adaptive modulation, <b>channel</b> <b>coding</b> and power allocation may be applied across all sub-carriers, or individually to each sub-carrier. In the latter case, if a particular range of frequencies suffers from interference or attenuation, the carriers within that range can be disabled or made to run slower by applying more robust modulation or error coding to those sub-carriers.|$|E
25|$|Coding {{theory is}} {{concerned}} with finding explicit methods, called codes, for increasing the efficiency and reducing the error rate of data communication over noisy channels to near the channel capacity. These codes can be roughly subdivided into data compression (source coding) and error-correction (<b>channel</b> <b>coding)</b> techniques. In the latter case, it took many years to find the methods Shannon's work proved were possible. A third class of information theory codes are cryptographic algorithms (both codes and ciphers). Concepts, methods and results from coding theory and information theory are widely used in cryptography and cryptanalysis. See the article ban (unit) for a historical application.|$|E
2500|$|The <b>channel</b> <b>coding</b> theorem for {{discrete}} time non-stationary memoryless channels can {{be found}} here: noisy <b>channel</b> <b>coding</b> theorem ...|$|E
40|$|We {{propose a}} general class of {{concatenated}} errorcorrecting entropy <b>codes</b> and <b>channel</b> <b>codes.</b> In this way we extend and generalize the existing {{body of work}} on iterative decoding of entropy and <b>channel</b> <b>codes.</b> Using the structure and properties of serial concatenated codes, we employ error-correcting entropy codes as the outer code, and a convolutional code as the inner code. The generalization from entropy codes to redundant entropy codes allows powerful error correction similar to turbo codes. We provide upper bounds for the concatenated entropy <b>code</b> and <b>channel</b> <b>code.</b> We also show that iterative decoding of the proposed concatenated code outperforms iterative decoding of previously reported entropy and <b>channel</b> <b>codes</b> that operate at the same overall rate...|$|R
40|$|We {{study the}} {{performance}} of joint source and <b>channel</b> <b>codes</b> designed to minimize end-to-end distortion over a Rayleigh fading channel. We consider two joint code designs. The first joint code uses a sequential design: a standard vector quantizer (VQ) source code is designed for a perfect channel (noiseless and distortionless) and then an RCPC <b>channel</b> <b>code</b> is optimized relative to the VQ and the channel statistics. The second design jointly optimizes a channel optimized VQ (COVQ) and an RCPC <b>channel</b> <b>code</b> through an iterative design process. We consider both hard-decision and soft-decision decoding for the <b>channel</b> <b>codes.</b> In both designs the bit allocation between the source and <b>channel</b> <b>codes</b> is optimized. At this optimal bit allocation, {{the performance of}} the iterative joint design and the simpler sequential design are nearly the same over the range of SNR values that we considered. Both code designs outperform standard COVQ and by up to 6 dB, and this performance improvement is most pronounced at low SNRs...|$|R
40|$|A novel hybrid genetic {{algorithm}} (GA) for jointly optimizing source and <b>channel</b> <b>codes</b> {{is presented in}} this paper. The algorithm first uses GA for the coarse search of source and <b>channel</b> <b>codes.</b> An iterative search is then followed for the refinement of the coarse search. The hybrid GA enhances the robustness of the design of source and <b>channel</b> <b>codes.</b> The distributed GA scheme {{can also be used}} in conjunction with the proposed hybrid GA algorithm for further performance improvement. </p...|$|R
2500|$|Applications of {{fundamental}} topics of information theory include lossless data compression (e.g. ZIP files), lossy data compression (e.g. MP3s and JPEGs), and <b>channel</b> <b>coding</b> (e.g. for Digital Subscriber Line (DSL)). [...] The field {{is at the}} intersection of mathematics, statistics, computer science, physics, neurobiology, and electrical engineering. Its impact has been crucial {{to the success of the}} Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones, the development of the Internet, the study of linguistics and of human perception, the understanding of black holes, and numerous other fields. Important sub-fields of information theory are source coding, <b>channel</b> <b>coding,</b> algorithmic complexity theory, algorithmic information theory, information-theoretic security, and measures of information.|$|E
2500|$|By Directive of the European Commission, all {{television}} services transmitted to viewers in the European Community must use {{a transmission system}} that has been standardized by a recognized European standardization body, and such a standard has been developed and codified by the DVB Project, Digital Video Broadcasting (DVB); Framing structure, <b>channel</b> <b>coding</b> and modulation for digital terrestrial television. [...] Customarily referred to as DVB-T, the standard calls for the exclusive use of COFDM for modulation. DVB-T is now widely used in Europe and elsewhere for terrestrial digital TV.|$|E
2500|$|The {{physical}} layer net bitrate, information rate, [...] useful bit rate, payload rate, [...] net data transfer rate, coded transmission rate, effective data rate or wire speed (informal language) of a digital communication channel is the capacity excluding the {{physical layer}} protocol overhead, for example {{time division multiplex}} (TDM) framing bits, redundant forward error correction (FEC) codes, equalizer training symbols and other <b>channel</b> <b>coding.</b> Error-correcting codes are common especially in wireless communication systems, broadband modem standards and modern copper-based high-speed LANs. The physical layer net bitrate is the datarate measured at a reference point in the interface between the datalink layer and physical layer, and may consequently include data link and higher layer overhead.|$|E
30|$|In most of {{the digital}} {{communication}} systems through a noisy channel, {{the use of an}} error correction code is necessary for protecting the message from noise. In an attack context, the adversary wants to retrieve the message from the intercepted noisy bit stream without any prior knowledge of the <b>channel</b> <b>codes</b> used. For this purpose, finding out the code parameters such as code length, code dimension, and code generator is essential. This process is called the blind recognition of <b>channel</b> <b>codes</b> or the reconstruction of <b>channel</b> <b>codes.</b>|$|R
30|$|We {{investigate}} rotated Walsh-Hadamard spreading matrices for a broadband MC-CDMA {{system with}} robust channel estimation in the synchronous downlink. The similarities between rotated spreading and signal space diversity are outlined. In a multiuser MC-CDMA system, possible performance improvements {{are based on}} the chosen detector, the <b>channel</b> <b>code,</b> and its Hamming distance. By applying rotated spreading in comparison to a standard Walsh-Hadamard spreading code, a higher throughput can be achieved. As combining the <b>channel</b> <b>code</b> and the spreading code forms a concatenated code, the overall minimum Hamming distance of the concatenated code increases. This asymptotically results in an improvement of the bit error rate for high signal-to-noise ratio. Higher convolutional <b>channel</b> <b>code</b> rates are mostly generated by puncturing good low-rate <b>channel</b> <b>codes.</b> The overall Hamming distance decreases significantly for the punctured <b>channel</b> <b>codes.</b> Higher <b>channel</b> <b>code</b> rates are favorable for MC-CDMA, as MC-CDMA utilizes diversity more efficiently compared to pure OFDMA. The application of rotated spreading in an MC-CDMA system allows exploiting diversity even further. We demonstrate that the rotated spreading gain is still present for a robust pilot-aided channel estimator. In a well-designed system, rotated spreading extends the performance by using a maximum likelihood detector with robust channel estimation at the receiver by about 1 dB.|$|R
40|$|We propose {{three new}} design {{algorithms}} for jointly optimizing source and <b>channel</b> <b>codes.</b> Our optimality criterion is {{to minimize the}} average end-to-end distortion. For a given channel SNR and transmission rate, our joint source and <b>channel</b> <b>code</b> designs achieve an optimal allocation of bits between the source and channel coders. Our three techniques include a source-optimized <b>channel</b> <b>code,</b> a channel-optimized source code, and an iterative descent technique combining the design strategies {{of the other two}} codes. The joint designs use channel-optimized vector quantization (COVQ) for the source code and rate compatible punctured convolutional (RCPC) <b>coding</b> for the <b>channel</b> <b>code.</b> The optimal bit allocation reduces distortion by up to 6 dB over suboptimal allocations and by up to 4 dB relative to standard COVQ for the source data set considered. We find that all three code designs have roughly the same performance when their bit allocations are optimized. This result follows from the fact that at the optimal bit allocation the <b>channel</b> <b>code</b> removes most of the channel errors, in which case the three design techniques are roughly equivalent. We also compare the robustness of the three techniques to channel mismatch. We conclude the paper by relaxing the fixed transmission rate constraint and jointly optimizing the transmission rate, source <b>code,</b> and <b>channel</b> <b>code...</b>|$|R
2500|$|Information theory {{studies the}} quantification, storage, and {{communication}} of information. [...] It was originally proposed by Claude E. Shannon in 1948 to find fundamental limits on signal processing and communication operations such as data compression, in a landmark paper entitled [...] "A Mathematical Theory of Communication". Applications of fundamental topics of information theory include lossless data compression (e.g. ZIP files), lossy data compression (e.g. MP3s and JPEGs), and <b>channel</b> <b>coding</b> (e.g. for {{digital subscriber line}} (DSL)). Its impact has been crucial {{to the success of}} the Voyager missions to deep space, the invention of the compact disc, the feasibility of mobile phones, the development of the Internet, the study of linguistics and of human perception, the understanding of black holes, and numerous other fields.|$|E
2500|$|In August 2017, JTC1/SC29/WG1 {{issued a}} Call for {{proposals}} on JPEG XL - {{the next generation}} of image compression standard with substantially better compression efficiency (60% improvement) comparing to JPEG. The standard is expected to follow performance by HEVC HM, Daala and WebP. The core requirements include support for animated images, [...] 8-10 bits per component, and alpha <b>channel</b> <b>coding.</b> [...] The standard should also offer high-quality compression of synthetic images, such as bitmap fonts and gradients, higher bit depths (12-16 bit and floating point) for improved dynamic range, wide color gamut using different color spaces (including Rec.2020/2100 and LogC), and lossless alpha channel encoding. Any patented technologies would be licensed on a royalty-free basis. The proposals should be submitted by April 2018, with current target publication date in early 2020.|$|E
5000|$|The <b>channel</b> <b>coding</b> theorem for {{discrete}} time non-stationary memoryless channels can {{be found}} here: noisy <b>channel</b> <b>coding</b> theorem ...|$|E
3000|$|In all {{measured}} cases, we manually {{selected the}} tuple maximizing the throughput. Our starting point was the theoretical analysis, but this analysis {{does not take}} into account the imperfect <b>channel</b> <b>code</b> and available discrete <b>channel</b> <b>code</b> rates (0.4, 0.5, â€¦, 0.9). We also considered N [...]...|$|R
50|$|Many {{variations}} of DISCUS {{are presented in}} related literature. One such popular scheme is the <b>Channel</b> <b>Code</b> Partitioning scheme, which is an a-priori scheme, to reach the Slepian-Wolf bound. Many papers illustrate simulations and experiments on <b>channel</b> <b>code</b> partitioning using the turbo codes, Hamming codes and irregular repeat-accumulate codes.|$|R
40|$|Abstractâ€”We study a source-channel {{coding scheme}} in which source {{messages}} {{are assigned to}} classes and encoded using a <b>channel</b> <b>code</b> {{that depends on the}} class index. While each class code {{can be seen as a}} concatenation of a source <b>code</b> and a <b>channel</b> <b>code,</b> the overall performance improves on that of separate source-channel coding and approaches that of joint source-channel coding as the number of classes increases. The performance of this scheme is studied by means of random-coding bounds and validated by simulation of a low-complexity implementation using existing source and <b>channel</b> <b>codes.</b> I...|$|R
50|$|In {{addition}} to the actual speech coding of the signal, it is often necessary to use <b>channel</b> <b>coding</b> for transmission, to avoid losses due to transmission errors. Usually, speech coding and <b>channel</b> <b>coding</b> methods have to be chosen in pairs, with the more important bits in the speech data stream protected by more robust <b>channel</b> <b>coding,</b> {{in order to get}} the best overall coding results.|$|E
5000|$|TIA-1040.1.03 Physical Layer Specification; Part 3: <b>Channel</b> <b>Coding</b> ...|$|E
5000|$|... #Subtitle level 2: <b>Channel</b> <b>coding</b> theorem for non-stationary memoryless {{channels}} ...|$|E
50|$|EFMPlus is the <b>channel</b> <b>code</b> used in DVDs and SACDs.|$|R
40|$|We {{optimize}} the diversity-multiplexing tradeoff inherent to MIMO systems to minimize total distortion {{in a joint}} source and <b>channel</b> <b>code</b> design. Our goal {{is to find the}} optimal balance between the increased data rate provided by multiplexing versus the robustness provided by diversity. We first consider concatenation of a vector quantizer and MIMO <b>channel</b> <b>code.</b> We show that in the high SIR regime we can obtain a closed form expression for the optimal multiplexing rate and the resulting end-to-end distortion can be expressed as a simple function of the optimal diversity-multiplexing tradeoff point. The optimization framework can be extended to a broad class of source and <b>channel</b> <b>codes,</b> which we demonstrate using an example of a progressive video source code combined with a spacetime <b>channel</b> <b>code.</b> Similar ideas can be applied to MIMO networks and to delay distortion...|$|R
40|$|We study a source-channel {{coding scheme}} in which source {{messages}} {{are assigned to}} different classes and encoded using a <b>channel</b> <b>code</b> {{that depends on the}} class index. The performance of this scheme is studied by means of random-coding error exponents and validated by simulation of a low-complexity implementation using existing source and <b>channel</b> <b>codes.</b> While each class code {{can be seen as a}} concatenation of a source <b>code</b> and a <b>channel</b> <b>code,</b> the overall performance improves on that of separate source-channel coding and approaches that of joint source-channel coding when the number of classes increases. I...|$|R
