44|223|Public
50|$|Co-op Food Supply Chain Logistics has 8 {{regional}} <b>composite</b> <b>distribution</b> centres and 3 smaller satellite depots {{supporting the}} larger CDCs. The Coventry-based National Distribution Centre (NDC) supplies all distribution centres direct, with slow moving lines.|$|E
5000|$|The {{method of}} moment {{matching}} {{is one of}} the oldest techniques for determining the mixture parameters dating back to Karl Pearson’s seminal work of 1894.In this approach the parameters of the mixture are determined such that the <b>composite</b> <b>distribution</b> has moments matching some given value. In many instances extraction of solutions to the moment equations may present non-trivial algebraic or computational problems. Moreover, numerical analysis by Day [...] has indicated that such methods may be inefficient compared to EM. Nonetheless there has been renewed interest in this method, e.g., Craigmile and Titterington (1998) and Wang.|$|E
40|$|This thesis {{examines}} the reliability analysis of distribution substation by using minimal cut set method and {{fault tree analysis}} (FTA). The five types of distribution substations are adapted from existing literature [2] to illustrate the detailed calculation of the substation reliability indices. The impact of the substation reliability on <b>composite</b> <b>distribution</b> system is also analyzed by using minimal cut set approach. The five types of primary distribution system are taken and modified from RBTS Bus 4 [2] and used for reliability assessment of <b>composite</b> <b>distribution</b> system. The substation reliability models, {{the interaction between the}} distribution substation and primary distribution system model and primary distribution system reliability model are adapted from literature [2] and conduct the detailed calculation by using Microsoft Excel software. In addition to load point reliability indices, system reliability indices of the <b>composite</b> <b>distribution</b> system are also analyzed by using minimal cut set method to illustrate the severity of system failures and the impact of substation reliability upon <b>composite</b> <b>distribution</b> system reliability. Fault tree analysis (FTA) approach is also used to analyze the same substation configuration with same reliability data for comparing with minimal cut set method and to provide as the alternative approach for reliability assessment of distribution substation. ...|$|E
40|$|In this paper, we {{introduce}} the most general <b>composite</b> fading <b>distribution</b> {{to model the}} envelope {{and the power of}} the received signal in such fading channels as millimeter wave (60 GHz or above) fading channels and free-space optical channels, which we term extended generalized-K (EGK) <b>composite</b> fading <b>distribution.</b> We obtain the second-order statistics of the received signal envelope characterized by the EGK <b>composite</b> fading <b>distribution.</b> Expressions for probability density function, cumulative distribution function, level crossing rate and average fade duration, moments, amount of fading and average capacity are derived. Numerical and computer simulation examples validate the accuracy of the presented mathematical analysis. © 2010 IEEE...|$|R
40|$|We {{investigate}} two {{closely related}} nonparametric hypothesis testing problems. In {{the first problem}} (i. e., the existence problem), we test whether a testing data stream is generated by one {{of a set of}} <b>composite</b> <b>distributions.</b> In the second problem (i. e., the association problem), we test which one of the multiple distributions generates a testing data stream. We assume that some distributions in the set are unknown with only training sequences generated by the corresponding distributions are available. For both problems, we construct the generalized likelihood (GL) tests, and characterize the error exponents of the maximum error probabilities. For the existence problem, we show that the error exponent is mainly captured by the Chernoff information between the set of <b>composite</b> <b>distributions</b> and alternative distributions. For the association problem, we show that the error exponent is captured by the minimum Chernoff information between each pair of distributions as well as the KL divergences between the approximated distributions (via training sequences) and the true distributions. We also show that the ratio between the lengths of training and testing sequences {{plays an important role in}} determining the error decay rate. Comment: 12 pages, 10 figure...|$|R
40|$|Noncentral {{distributions}} form {{an integral}} part of statistical inference. For example, the noncentral chisquare distribution is particularly useful as it represents the sampling distribution of the sample variance from a normal distribution with unstable expected value. This study develops bivariate noncentral distributions via the compounding method. Some <b>composite</b> <b>distributions</b> (such as the product, ratio, and proportion) are derived, their properties studied, and applied to rainfall data. A selection of conference proceedings: Student Symposium in Science, 06 and 07 November 2014, Science Campus, University of South Africa. [URL]...|$|R
40|$|The studies {{about the}} effects of {{multipath}} fading and shadowing for wireless cooperative networks are insufficient. Almost all real wireless networks can be modeled by changing the parameters of the <b>composite</b> <b>distribution</b> which models both multipath and shadow fading. This <b>composite</b> <b>distribution</b> makes the analytical calculation of bit error rate (BER) difficult. In this thesis report, an approximation for this <b>composite</b> <b>distribution</b> has been introduced. A cooperative method, based on decode and forward (DF) for forwarding, is studied. For a required BER, for instance 10 ? 2, the gain in terms of power with using the cooperation with one relay is 4 dB in comparison to a case with same amount of energy to send a same message for a non cooperative network. The impact of parameters of <b>composite</b> <b>distribution</b> on the gain of cooperative communications (CC) in terms of power is discussed. In this work, the optimum value for power allocation in the relay and sender for a cooperative network is found in the simulations. The different position of a relay in a parallel line with respect to the line of sight (LOS) of the sender and the receiver; {{and its impact on the}} BER is investigated. The random deployment of the relays in the network is also investigated. Masters in Electrical EngineeringDepartment of Telecommunication, Wireless and Mobile Communications (WMC) GroupElectrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|FIGURE 1. <b>Composite</b> <b>distribution</b> of the Palearctic naked-toed geckos. The genera Alsophylax and Microgecko, which {{fall outside}} this clade (Gamble et al. 2012), are not included, but have largely {{overlapping}} distributions. Shading {{of the base}} map depicts elevation, with high-elevation areas darker. Key geographic and physiographic regions, including countries, mountains, plateaus, deserts, and tectonic plate boundaries, are labeled...|$|E
30|$|Number of {{composite}} {{channel models}} {{have been used in}} literature for the wireless communication systems analysis, for the case when multipath fading and shadowing occur simultaneously. Such are the η−μ/gamma [4], the κ−μ/gamma [5], the K[6], and the generalized- K (KG) [7] distribution models. Similar work has been presented in [8, 9]. Non-linear, non-homogenous, shadowed propagation have been analyzed in [10], but for the case when dominant, line-of-sight (LOS) component is taken into account. Starting from general α−η−μ distribution, closed-form statistics (PDF, CDF and n-th order moments expressions) will be introduced, for novel <b>composite</b> <b>distribution.</b> That is another contribution of this work since this <b>composite</b> <b>distribution</b> has not been reported in literature so far. Obtained mathematical form will allow simple performance analysis of wireless communication systems, operating in composite fading environments. This performance analysis is also accompanied by graphically presented numerical results, which show the influence of various communication system parameters (fading and shadowing parameters), on the standard performance criterions.|$|E
40|$|In this paper, we {{introduce}} a generalized <b>composite</b> fading <b>distribution</b> (termed extended generalized-K (EGK)) {{to model the}} envelope {{and the power of}} the received signal in millimeter wave (60 GHz or above) and free-space optical channels. We obtain the first and the second-order statistics of the received signal envelope characterized by the EGK <b>composite</b> fading <b>distribution.</b> In particular, expressions for probability density function, cumulative distribution function, level crossing rate and average fade duration, and fractional moments are derived. In addition performance measures such as amount of fading, average bit error probability, outage probability, average capacity, and outage capacity are offered in closed-form. Selected numerical and computer simulation examples validate the accuracy of the presented mathematical analysis. Comment: <b>Composite</b> fading <b>distribution,</b> generalized-K distribution, probability density function, cumulative distribution function, fractional moments, level crossing rate, amount of fade duration, moments, amount of fading, average bit error probability, average capacit...|$|R
40|$|Measurements of car-to-car (C 2 C) radio {{channels}} with 60 MHz bandwidth at 5. 3 GHz {{have been}} performed in Helsinki, Finland. We focused on 30 x 30 multiple-input multiple- output (MIMO) measurements, conducted in four environments (urban, sub-urban, campus and highway), under quasi-realistic traffic conditions. As first results, we present in this paper the delay spread statistics for each investigated environment. The largest values of root-mean-square (RMS) delay spread, roughly 2 mu s, were obtained in the urban environment. The narrowband channel fading statistics have also been derived using <b>composite</b> <b>distributions,</b> {{in order to assess}} the global fading statistics. Anglai...|$|R
40|$|In {{this paper}} we propose {{reference}} priors obtained by maximizing the average adivergence from the posterior distribution, when the latter is computed using a composite likelihood. <b>Composite</b> posterior <b>distributions</b> have already been considered in [7] and [8], when a full likelihood for the data is too complex or even not available. The use of a curvature corrected <b>composite</b> posterior <b>distribution,</b> as in [8], allows to apply the method in [6] for maximizing the asymptotic Bayes risk associated to an adivergence. The result is a Jeffreys type prior that {{is proportional to the}} square root of the determinant of the Godambe information matrix...|$|R
40|$|This thesis {{presents}} a new {{method of estimating}} the one-in-N low temperature threshold using a non-parametric statistical method called kernel density estimation applied to daily average wind-adjusted temperatures. We apply our One-in-N Algorithm to local gas distribution companies (LDCs), as they have to forecast the daily natural gas needs of their consumers. In winter, demand for natural gas is high. Extreme low temperature events are {{not directly related to}} an LDCs gas demand forecasting, but knowledge of extreme low temperatures is important to ensure that an LDC has enough capacity to meet customer demands when extreme low temperatures are experienced. We present a detailed explanation of our One-in-N Algorithm and compare it to the methods using the generalized extreme value distribution, the normal distribution, and the variance-weighted <b>composite</b> <b>distribution.</b> We show that our One-in-N Algorithm estimates the one-in-N low temperature threshold more accurately than the methods using the generalized extreme value distribution, the normal distribution, and the variance-weighted <b>composite</b> <b>distribution</b> according t...|$|E
40|$|The model choice {{problem in}} Hydrology is {{illustrated}} {{by means of the}} optimum levee design for flat rivers along a confluence reach. Special attention is given to the selection of a probability distribution for the joint flood stages. The optimality criterion used is the minimization of construction plus expected flood damage costs. The main assumption in the mathematical model is that the levee profile is uniquely determined {{as a function of the}} levee heights at the extremes of the reach; thus the problem is reduced to the determination of the optimum pair of extreme levee heights. The selection of a probability distribution of flood stages, from a set of distributions estimated from the partial duration series, is performed using either one of two selection procedures: likelihood of the Chi -square statistic and sample likelihoods. A <b>composite</b> <b>distribution,</b> taking into account the model uncertainty, is also derived. The methodology presented is applied to the remodeling of the levee on the west bank of the Zagyva River, in Hungary. A sensitivity analysis is performed, using the best ranking distributions according to the two model choice procedures. The <b>composite</b> <b>distribution</b> appears to offer a reasonable choice...|$|E
40|$|In {{this paper}} {{we make a}} {{comparison}} between two composite models: lognormal-Pareto and Weibull-Pareto. The first one was introduced by Cooray and Ananda in 2005. The second <b>composite</b> <b>distribution</b> was constructed {{in the same manner}} as lognormal-Pareto. Here, we prove that these models behave similarly and they could be used in insurance bussiness for modelling actuarial data, especially in the cases where one deals with large loss payments. composite models; lognormal, Weibull and Pareto distributions; maximum likelihood estimation; smooth empirical estimation of percentils. ...|$|E
40|$|Spatial decay {{properties}} of potential were studied for horizontal cell {{responses to a}} small spot of monochromatic lights. The responses of L-type horizontal cells spread laterally attenuating in amplitude with distance; Their spatial distribution was always hyperpolarizing and bell-formed around the recording site, though it was affected by light intensity and wave length. On the other hand, the spatial distribution of C-type horizontal cell responses was monophasic or biphasic depending upon the wave length of the light spot. These spatial {{properties of}} horizontal cell responses were well explained by the <b>composite</b> <b>distributions</b> of different type receptor inputs and some nonlinear interactions among the responses...|$|R
40|$|<b>Composite</b> <b>distributions</b> of {{measured}} total reactive nitrogen NO(y), {{from the}} NASA ER- 2 during the Airborne Arctic Stratospheric Expedition are presented. The observed features of these distributions {{are discussed in}} terms of the controlling dynamical, chemical and microphysical processes. In the latitudinal profile from 58 deg N to within about 4 deg poleward of the polar vortex boundary, NO(y) conforms closely to predictions of NO(y) based on N 2 O measurements. Poleward of 5 deg of latitude within the boundary, the average NO(y) decreases sharply and is significantly lower than that predicted from N 2 O. This feature is consistent with loss of NO(y) through sedimentation of particles containing NO(y) in polar stratospheric clouds...|$|R
40|$|The {{statistical}} uncertainty {{resulting from the}} lack of knowledge of which model represents a given stochastic process is analyzed. This analysis of model uncertainty leads to a <b>composite</b> Bayesian <b>distribution.</b> The <b>composite</b> Bayesian <b>distribution</b> is a linear model of the individual Bayesian probability distributions of the individual models, weighted by the posterior probability that a particular model is the true model. The composite Bayesian probability model accounts for all sources of {{statistical uncertainty}}, both parameter uncertainty and model uncertainty. This model is the one that should be used in applied problems of decision analysis, for it best represents the knowledge, or lack of it, to the decision maker about future events of the process...|$|R
40|$|In {{this work}} we take {{advantage}} of eleven different sunspot group, sunspot, and active region databases to characterize the area and flux distributions of photospheric magnetic structures. We find that, when taken separately, different databases are better fitted by different distributions (as has been reported previously in the literature). However, we find that all our databases can be reconciled by the simple application of a proportionality constant, and that, in reality, different databases are sampling different parts of a <b>composite</b> <b>distribution.</b> This <b>composite</b> <b>distribution</b> is made up by linear combination of Weibull and log-normal distributions [...] where a pure Weibull (log-normal) characterizes the distribution of structures with fluxes below (above) $ 10 ^{ 21 }$Mx ($ 10 ^{ 22 }$Mx). We propose that this is evidence of two separate mechanisms giving rise to visible structures on the photosphere: one directly connected to the global component of the dynamo (and the generation of bipolar active regions), {{and the other with}} the small-scale component of the dynamo (and the fragmentation of magnetic structures due to their interaction with turbulent convection). Additionally, we demonstrate that the Weibull distribution shows the expected linear behavior of a power-law distribution (when extended into smaller fluxes), making our results compatible with the results of Parnell et al. (2009) ...|$|E
40|$|In this work, we take {{advantage}} of 11 different sunspot group, sunspot, and active region databases to characterize the area and flux distributions of photospheric magnetic structures. We find that, when taken separately, different databases are better fitted by different distributions (as has been reported previously in the literature). However, we find that all our databases can be reconciled by the simple application of a proportionality constant, and that, in reality, different databases are sampling different parts of a <b>composite</b> <b>distribution.</b> This <b>composite</b> <b>distribution</b> is made up by linear combination of Weibull and log-normal distributions—where a pure Weibull (log-normal) characterizes the distribution of structures with fluxes below (above) 1021 Mx (1022 Mx). Additionally, we demonstrate that the Weibull distribution shows the expected linear behavior of a power-law distribution (when extended to smaller fluxes), making our results compatible {{with the results of}} Parnell et al. We propose that this is evidence of two separate mechanisms giving rise to visible structures on the photosphere: one directly connected to the global component of the dynamo (and the generation of bipolar active regions), and the other with the small-scale component of the dynamo (and the fragmentation of magnetic structures due to their interaction with turbulent convection) ...|$|E
40|$|A semi-Markov {{model for}} {{equipment}} {{that can be}} repaired and returned to service in a less than new state is developed, where several less than new states are possible before the equipment finally fails. A subclass of phase-type distributions is used to model the times spent {{in each of these}} states. Then, exploiting the phase-type structure, the <b>composite</b> <b>distribution</b> of the entire lifetime of the equipment can be constructed. Data from railway wagon wheel-sets are used to illustrate this modelling and data analysis. (C) 2000 Elsevier Science Ltd. All rights reserved...|$|E
40|$|The {{author has}} {{identified}} the following significant results. The parameter AD (average distance) {{as used in}} the ISODATA program was critically examined. Thresholds of AD {{to decide on the}} splitting of clusters were obtained. For the univariate case, 0. 84 was established as a sound choice, after examining several simple, as well as <b>composite,</b> <b>distributions</b> and also after investigating the probability of misclassification when points have to be reassigned to the newly identified clusters. For the multivariate case, the empirical threshold (N- 0. 16) /square root of N was extrapolated. A final criticism on AD was that AD would lose its effectiveness as a discriminative measure for the present purpose when N was large...|$|R
40|$|AbstractWe {{report that}} the many Eph-related {{receptor}} tyrosine kinases, and their numerous membrane-bound ligands, can each be grouped into only two major specificity subclasses. Receptors in a given subclass bind most members of a corresponding ligand subclass. The physiological relevance of these groupings is suggested by viewing the collective distributions of all members of a subclass. These <b>composite</b> <b>distributions,</b> in contrast with less informative patterns seen with individual members of the family, reveal that the developing embryo is subdivided into domains defined by reciprocal and apparently mutually exclusive expression of a receptor subclass and its corresponding ligands. Receptors seem to encounter their ligands only at the interface between these domains. This reciprocal compartmentalization implicates the Eph family {{in the formation of}} spatial boundaries that may help to organize the developing body plan...|$|R
40|$|The {{experimental}} approach considered {{requires the}} measurement of energy-absorption distributions {{for a set of}} pathlengths which define a biological volume. A suitable folding procedure is necessary to produce <b>composite</b> energy-absorption <b>distributions.</b> The investigation is concerned with the quality of the prediction of energy-deposition distributions, taking into account distributions measured with a proportional counter...|$|R
40|$|When {{implementing}} new statistical procedures, {{there is}} often a need for simple [...] and yet computationally efficient [...] ways of numerically evaluating <b>composite</b> <b>distribution</b> functions. If the statistical procedure must support calculations for censored and noncensored cases, those calculations should be carried out using efficient computational implementations of both definite and indefinite integrals (e. g., calculation of tail areas of distribution functions). We developed a generic function evaluator such that users may specify a function using reverse Polish notation. As its argument the function evaluator takes a matrix of pointers and then applies the rows of this matrix to its internally defined stack of pointers. Accordingly, each row of the argument matrix defines a single operation such as evaluating a function on the current element of the stack, applying an algebraic operation to the two top elements of the stack, or manipulating the stack itself. Defining new <b>composite</b> <b>distribution</b> functions from other (atomic) distribution functions then corresponds to joining two or more function-defining matrices vertically. This approach can further be used to obtain integrals of any defined function. As an example we show how the density and distribution function for the minimum of two Weibull distributed random variables can be numerically evaluated and integrated. The procedure provides a flexible and extensible framework for imple- menting numerical evaluation of general, composite distributions. The procedure is numerically relatively efficient, although not optimal. Copyright 2007 by StataCorp LP. rpnfcn(), RPN, Mata...|$|E
40|$|This thesis {{deals with}} the {{calculation}} of the premium for model of excess of loss reinsurance with reinstatements (XL-reinsurance with reinstatements). In the first part except {{the description of the}} basic model, we devote to derivation of the formula for calculating the pure premium. Furthermore, we show the detailed calculation procedure of the pure premium including the derivation of the probability function for the <b>composite</b> <b>distribution</b> of the total reinsurer's participation in claims here. The thesis also describes the method of PH transformation, which is used to determine the risk adjusted premium. In the second part we show these procedures on concrete examples for various probability distributions of the amount of claims and the number of claims. Powered by TCPDF (www. tcpdf. org...|$|E
40|$|A <b>composite</b> <b>distribution</b> of {{tangential}} and upward {{components of}} air flow {{is determined by}} tracing particles of debris and cloud tag movements in scaled movies of a tornado. The greatest tangential speed measured is 170 m. p. h. and the greatest upward speed derived is 150 m. p. h. A distribution of the convergent radial component of motion in the lower 600 ft. of the vortex is synthesized and used to generate a vertical speed distribution which nearly duplicates the observed vertical speed dist,ribution. The observed radial distribution of the vertical component of relative vorticity at three levels is shown and convergence at the 500 -ft. radius is computed using the synthesized radial speed distribution. Three-dimensional traject>ories of air parcels in the lower portion of the vortex are also shown. 1...|$|E
40|$|We {{investigate}} {{three different}} approaches for fitting the degree distributions of China-, US- and the composite China+US air network, {{in order to}} reveal the nature of such distributions and the potential theoretical background on which they are based. Our first approach is the fitting with q-statistics probability distribution, done separately in two regimes. This yields acceptable outcomes but generates two sets of fitting parameters. The second approach is an entire fitting to all data points with the formula proposed by Tsallis et al. So far, this trial {{is not able to}} produce consistent results. In the third approach, we fit the data with two <b>composite</b> <b>distributions</b> which may lack theoretical support for the moment. Comment: 21 pages, 11 eps figures, to be published in Physica A (2006), PACS: 02. 60. Ed; 89. 40. Dd; 89. 75. Da; 89. 75. -k; 05. 10. -...|$|R
30|$|Sparrow asserts in 1916 {{with its}} “undulation condition” (Sparrow 1916) as the {{resolution}} limit {{the distance between}} point objects for which the second derivative of the <b>composite</b> intensity <b>distribution</b> {{at the center of}} the image just vanishes. This is the ultimate limit for photodetectors (replacing the naked eye) that can resolve arbitrary small intensity differences.|$|R
40|$|OSSE has {{measured}} the galactic longitude distribution {{of both the}} 511 keV annihilation line radiation and the three-photon positronium continuum within ¸ 40 ffi of the center. They have similar shapes, with a <b>composite</b> longitude <b>distribution</b> well represented by an ¸ 11 ffi FWHM Gaussian central bulge together with a possible broad disk component comprising as much as 15...|$|R
40|$|Two-time-scale (TTS) {{distributions}} are introduced. For a {{class of}} stable systems, it is shown that every TTS distribution has a two-frequency-scale (TFS) Laplace transform. Conversely, it is shown that the impulse response of any stable TFS transfer function, and hence any stable (standard) singularly perturbed system, can be characterized {{in terms of a}} stable TTS distribution. A time domain decomposition for TTS distributions is obtained which parallels the slow and fast decomposition of singularly perturbed systems and also the frequency domain decomposition of TFS transfer functions. It is shown that every stable TTS distribution can be decomposed in terms of two simpler distributions represented in two different time scales. A <b>composite</b> <b>distribution</b> is constructed from these two which approximates the TTS distribution arbitrarily closely in the L 1 norm...|$|E
30|$|In this paper, {{performance}} analysis of wireless communication over α−η−μ fading channels has been investigated. First, analysis {{has been carried}} out for the case when communication is subjected to the influence of co-channel interference. Closed-form expressions have been derived for the probability density function and cumulative distribution function of the received signal-to-interference ratio. Outage probability has been obtained for this case, in the function of various values of system parameters, and also for the case when selection diversity has been presented at the reception. Further, simultaneous multipath fading and shadowing occurrence has been analyzed, through deriving novel composite Gamma long-time faded α−η−μ fading distribution. First-order statistical parameters have been obtained in closed form, for this novel <b>composite</b> <b>distribution,</b> and capitalizing on them, standard performance measures have been efficiently evaluated, graphically presented and discussed in the function of system parameters.|$|E
40|$|An {{empirical}} Bayes pooling {{method is}} used to combine and compare estimates {{of the value of}} a statistical life (VSL). The data come from 40 selected studies published between 1974 and 2002, containing 197 VSL estimates. The estimated <b>composite</b> <b>distribution</b> of empirical Bayes adjusted VSL has a mean of $ 5. 4 million and a standard deviation of $ 2. 4 million. The empirical Bayes method greatly reduces the variability around the pooled VSL estimate. The pooled VSL estimate is influenced by the choice of valuation method, study location, and union status of sample but not to the source of data on occupational risk or the consideration of non-fatal risk injury. Copyright Springer 2006 value of a statistical life (VSL), empirical Bayes estimate, environmental policy, health policy, contingent valuation method, hedonic wage method, J 17, C 11, Q 28,...|$|E
40|$|In this paper, {{we focus}} on the {{representation}} of, and the reasoning with, metric bounds with possibilistic distributions. Metric bounds have been used to represent the prepositional quantitative relations between events. For example, the ACM student chapter meeting will take at least 45 minutes and at most 65 minutes is a metric bound on the event meeting. Metric bounds use two extreme bounds for duration of an event even though it rarely occurs. In this paper we show how to associate possibilistic distribution with the metric bounds, and thus makes the model more accurate. When we associate the possibilistic distribution with metric bounds, the composition of metric intervals becomes quite complex as we have shown in this paper. For computational convenience, we provide a method to approximate the distribution and show how to compute the composition of complex <b>composite</b> <b>distributions.</b> The representation can be further enriched by incorporating temporal transition rules. We discuss abo [...] ...|$|R
30|$|In {{order to}} {{superimpose}} {{the influence of}} multipath fading, modelled by general α−η−μ distribution, with shadowing process modelled with Gamma distribution, {{for the first time}} in the literature, we will present in this section novel <b>composite</b> fading <b>distribution.</b> As multipath fading and shadowing simultaneously occur in wireless transmission, there is a need to derive general model which would accurately describe this composite random process.|$|R
40|$|Mineralized hydrogels are {{increasingly}} gaining attention as biomaterials for bone regeneration. The most common mineralization {{strategy has been}} addition of preformed inorganic particles during hydrogel formation. This maintains injectability. One common form of bone cement is formed by mixing particles of the highly reactive calcium phosphate alpha-tricalcium phosphate (α-TCP) with water to form hydroxyapatite (HA). The calcium ions released during this reaction can be exploited to crosslink anionic, calcium-binding polymers such as the polysaccharide gellan gum (GG) to induce hydrogel formation. In this study, three different amounts of α-TCP particles were added to GG polymer solution to generate novel, injectable hydrogel-inorganic <b>composites.</b> <b>Distribution</b> of the inorganic phase in the hydrogel was studied by high resolution microcomputer tomography (µCT). Gelation occurred within 30 min. α-TCP converted to HA. µCT revealed inhomogeneous distribution of the inorganic phase in the composites. These results demonstrate {{the potential of the}} composites as alternatives to traditional α-TCP bone cement and pave the way for incorporation of biologically active substances and in vitro and in vivo testing...|$|R
