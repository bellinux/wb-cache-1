0|10|Public
50|$|Szabo {{proposes that}} smart {{contract}} infrastructure {{can be implemented}} by replicated asset registries and contract execution using <b>cryptographic</b> hash <b>chains</b> and Byzantine fault tolerant replication. Askemos implemented this approachin 2002 using Scheme(later adding SQLite) as contract script language.|$|R
50|$|The Resource Public Key Infrastructure (RPKI) is {{designed}} to authenticate route origins via <b>cryptographic</b> certificate <b>chains</b> demonstrating address block range ownership, but is not widely deployed yet. Once deployed, IP hijacking through errant issues at the origin (via both accident or intent) should be detectable and filterable.|$|R
40|$|The {{security}} of cascade ciphers, in which by definition the keys of the component ciphers are independent, is considered. It {{is shown by}} a counterexample that the intuitive result, formally stated and proved in the literature, that a cascade {{is at least as}} strong as the strongest component cipher, requires the uninterestingly restrictive assumption that the enemy cannot exploit information about the plaintext statistics. It is proved, for very general notions of breaking a cipher and of problem difficulty, that a cascade is at least as difficult to break as the first component cipher. A consequence of this result is that, if the ciphers commute, then a cascade is at least as difficult to break as the most-difficult-tobreak component cipher, i. e., the intuition that a <b>cryptographic</b> <b>chain</b> is at least as strong as its strongest link is then provably correct. It is noted that additive stream ciphers do commute, and this fact is used to suggest a strategy for designing secure practical ci [...] ...|$|R
40|$|Alice, a peer in a {{peer-to-peer}} (P 2 P) network can {{evaluate the}} reputation of another peer, Bob, either based on her own experiences (with Bob) or based on the evaluation (of Bob) by others (say Carol and David). If Alice uses her own experiences only, she will get cheated atleast once for every malicious peer she identifies. If Alice uses third party experiences (Carol and David), she can {{reduce the number of}} times she gets cheated. Besides, Alice will have to verify the third party information receives from other peers. The verification (if at all possible) is likely to be both network and computation intensive. In the propose solution, the reputation holder (Bob) stores its reputation data and protects it from the other peers. The reputation data is stored in a <b>cryptographic</b> <b>chain</b> {{in order to protect the}} reputation data from the reputation holder itself. Bob cannot modify the chain because the head and tail of the chain are public information and all recommendations are digitally signed. We show that the proposed solution reduces the number of malicious transaction experienced by a peer (Alice), along with a reduction in network traffic...|$|R
50|$|Transient-key {{cryptography}} {{is a form}} of {{public-key cryptography}} wherein keypairs are generated and assigned to brief intervals of time instead of to individuals or organizations, and the blocks of <b>cryptographic</b> data are <b>chained</b> through time. In a transient-key system, private keys are used briefly and then destroyed, which is why it is sometimes nicknamed “disposable crypto.” Data encrypted with a private key associated with a specific time interval can be irrefutably linked to that interval, making transient-key cryptography particularly useful for digital trusted timestamping.|$|R
40|$|Abstract: Cryptographic puzzles {{provide an}} elegant {{solution}} in combating denial of services attacks. In this paper we introduce {{the concept of}} <b>chained</b> <b>cryptographic</b> puzzle. We define two kinds of chained puzzle constructions: linearly chained puzzles and randomly chained puzzles. The first construction prove to be very useful in some scenarios, from which the more general is in which a client may choose to solve {{only some of the}} puzzles that were sent by the server and gain resources from the server according to the amount of puzzles that he solved...|$|R
40|$|Networks are {{evolving}} {{toward a}} ubiquitous {{model in which}} heterogeneous devices are interconnected. Cryptographic algorithms are required for developing security solutions that protect network activity. However, the computational and energy limitations of network devices jeopardize the actual implementation of such mechanisms. In this paper, we perform a wide analysis on the expenses of launching symmetric and asymmetric <b>cryptographic</b> algorithms, hash <b>chain</b> functions, elliptic curves cryptography and pairing based cryptography on personal agendas, and compare them with the costs of basic operating system functions. Results show that although cryptographic power costs are high and such operations shall be restricted in time, {{they are not the}} main limiting factor of the autonomy of a device...|$|R
40|$|We {{introduce}} a formalism for designing distributed systems where processes cooperate {{in a group}} to maintain local copies of data with weak consistency. We focus on designs with two distinguishing properties. Firstly, each process in the group acts as a completely equal peer. There is no particular process holding a primary copy that determines how conflicts due to non-causal updates or malicious behavior are resolved. Secondly, no matter how large the fraction of malicious participants grows {{the rest of the}} group can continue to cooperate. There is no quota of processes that must have accepted an update to the data correctly before it becomes finally accepted by the group. Our formalism operates on sets of broadcast messages. Each carries not only a request to update the replicated data, but also captures the entire state of the sending process, including all messages that it has sent and received previously. This can, in practice, be achieved with <b>cryptographic</b> hash <b>chains.</b> Using our formalism, we present an agreement algorithm that decides in each process independently, which update requests to apply and in which order. It ensures eventual convergence of the replicated data to a consistent state on all correct processes...|$|R
40|$|Threshold Proxy Signature (TPS) scheme {{facilitates}} {{a manager}} to delegate his signing capability {{to a group}} of n 2 subordinates without revealing his own private key, such that a subgroup of at least t 2 ≤ n 2 subordinates is required to generate a proxy signature. In reality, the situation can be more complicated. First of all, the subgroup may further delegate their proxy signing capabilities to another group of n 3 subordinates such that at least another subgroup of at least t 3 ≤ n 3 subordinates are of the proxy signing capabilities (in the form of a chain). t 2 can be unequal to t 3 depending on the concrete requirement. This is a group-to-group delegation problem. In addition, a supervising agent (SA) may be introduced in the above chain to supervise the subordinates, such that proxy signing can only be successfully executed with SA’s agreement. This is a delegation with supervision problem in the threshold delegation chain described above. These two extensions of delegation problems are not solved yet. This paper designs two provably secure <b>cryptographic</b> schemes <b>Chained</b> Threshold Proxy Signature (CTPS) scheme and Chained Threshold Proxy Signature with Supervision (CTPSwS) scheme to solve these two delegation problems...|$|R
40|$|The main {{motivation}} {{for this book}} lies in the breadth of applications in which a statistical model is used to represent small departures from, for example, a Poisson process. Our approach uses information geometry to provide a common context but we need only rather elementary material from differential geometry, information theory and mathematical statistics. Introductory sections serve together to help those interested from the applications side in making use of our methods and results. Reported in this monograph is a body of results, and computer-algebraic methods {{that seem to have}} quite general applicability to statistical models admitting representation through parametric families of probability density functions. Some illustrations are given from a variety of contexts for geometric characterization of statistical states near to the three important standard basic reference states: (Poisson) randomness, uniformity, independence. The individual applications are somewhat heuristic models from various fields and we incline more to terminology and notation from the applications rather than from formal statistics. However, a common thread is a geometrical representation for statistical perturbations of the basic standard states, and hence results gain qualitative stability. Moreover, the geometry is controlled by a metric structure that owes its heritage through maximum likelihood to information theory so the quantitative features [...] -lengths of curves, geodesics, scalar curvatures etc. [...] -have some respectable authority. We see in the applications simple models for galactic void distributions and galaxy clustering, amino acid clustering along protein <b>chains,</b> <b>cryptographic</b> protection, stochastic fibre networks, coupled geometric features in hydrology and quantum chaotic behaviour...|$|R

