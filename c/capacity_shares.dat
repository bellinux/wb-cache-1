12|737|Public
25|$|EasyJet, BA and Norwegian are Gatwick's three biggest {{resident}} airlines. They collectively {{accounted for}} 65.43% of Gatwick's total passengers in 2016 (EasyJet: 40.37% / 17.4million; BA: 14.39% / 6.2million; Norwegian: 10.67% / 4.6million). As per Official Airline Guide (OAG) {{data for the}} week of 29 May 2017, their respective international departure seat <b>capacity</b> <b>shares</b> at the airport for summer 2017 are: 42.1%, 15.4% and 9.4%. In terms of passengers carried, EasyJet and BA were also among the five largest airlines operating at Gatwick in 2010 (which also included TUI Airways and Thomas Cook Airlines at the time) and the top 10 in 2015. In terms of total scheduled airline seats at Gatwick in 2014, EasyJet accounted for 18.36million, more than two-and-a-half {{times as many as}} second-placed BA (sevenmillion) and nearly five times the number offered by third-placed Norwegian Air Shuttle (3.74million). Using data sourced from the OAG Schedules Analyser, the following changes in the respective departure seat <b>capacity</b> <b>shares</b> of Gatwick's three biggest airlines occurred from 2010 to 2015: EasyJet's share increased from 26.1% in 2010 to 42.1% in 2015; BA's share dropped from 18.3% in 2010 to 15% in 2015; Norwegian's share rose almost three-fold from less than 3% in 2010 to 8.3% in 2015. EasyJet, BA, Norwegian, TUI Airways, Monarch Airlines, Ryanair, Thomas Cook Airlines, Virgin Atlantic, Emirates and Vueling were Gatwick's top 10 airlines by share of passengers in 2016.|$|E
50|$|EasyJet, BA and Norwegian are Gatwick's three biggest {{resident}} airlines. They collectively {{accounted for}} 65.43% of Gatwick's total passengers in 2016 (EasyJet: 40.37% / 17.4 million; BA: 14.39% / 6.2 million; Norwegian: 10.67% / 4.6 million). As per Official Airline Guide (OAG) {{data for the}} week of 29 May 2017, their respective international departure seat <b>capacity</b> <b>shares</b> at the airport for summer 2017 are: 42.1%, 15.4% and 9.4%. In terms of passengers carried, EasyJet and BA were also among the five largest airlines operating at Gatwick in 2010 (which also included Thomson Airways, Monarch Airlines and Thomas Cook Airlines at the time) and the top 10 in 2015. In terms of total scheduled airline seats at Gatwick in 2014, EasyJet accounted for 18.36 million, more than two-and-a-half {{times as many as}} second-placed BA (seven million) and nearly five times the number offered by third-placed Norwegian Air Shuttle (3.74 million). Using data sourced from the OAG Schedules Analyser, the following changes in the respective departure seat <b>capacity</b> <b>shares</b> of Gatwick's three biggest airlines occurred from 2010 to 2015: EasyJet's share increased from 26.1% in 2010 to 42.1% in 2015; BA's share dropped from 18.3% in 2010 to 15% in 2015; Norwegian's share rose almost three-fold from less than 3% in 2010 to 8.3% in 2015. EasyJet, BA, Norwegian, Thomson Airways, Monarch Airlines, Ryanair, Thomas Cook Airlines, Virgin Atlantic, Emirates and Vueling were Gatwick's top 10 airlines by share of passengers in 2016.|$|E
40|$|Abstract: We {{consider}} a market with three competitors, {{two of which}} decide to cooperate. Firms first choose capacity under demand uncertainty then compete in quantities after the uncertainty has been resolved. We specify strategic alliance (SA) as an agreement where two airlines jointly choose capacity and divide it among themselves. Contrary to the full merger case, after demand is revealed the alliance members market their <b>capacity</b> <b>shares</b> independently. Our main {{result is that the}} profit of the cooperating firms is greater under SA than under full merger...|$|E
40|$|Due to the {{asymmetric}} information problem, inter-temporal water allocation efficiency requires a water allocation institution that allows water right holders to store their allocated water. <b>Capacity</b> <b>sharing</b> has been recommended, {{but the problem}} of internal spillage that may arise in a <b>capacity</b> <b>sharing</b> system causes concerns {{for the implementation of}} such institutions. In this paper, the optimality of water allocation within a <b>capacity</b> <b>sharing</b> system in presence of a spot water market is studied. We show that {{in the presence of a}} spot water market with zero transaction cost, an appropriately designed <b>capacity</b> <b>sharing</b> system will result in optimal water allocation. 7 page(s...|$|R
40|$|International audienceThis paper {{proposes a}} novel {{approach}} to <b>capacity</b> <b>sharing</b> in hybrid networked environments, i. e., environments that consist of infrastructure-based as well as infrastructure-less networks. The proposed framework is based on Software-Defined Networking (SDN) and provides flexible, efficient, and secure <b>capacity</b> <b>sharing</b> solutions {{in a variety of}} hybrid network scenarios. In this paper, we describe the challenges raised by <b>capacity</b> <b>sharing</b> in hybrid networks, describe our framework in detail and how it addresses these challenges, and discuss implementation issues. To the best of our knowledge, this is the first SDN-based <b>capacity</b> <b>sharing</b> solution that targets hybrid networks and that incorporates security {{as an integral part of}} the proposed approach...|$|R
40|$|In a 2 -hop IEEE 801. 11 -based {{wireless}} LAN, the distributed {{coordination function}} (DCF) tends to equally <b>share</b> the available <b>capacity</b> among the contending stations. Recently alternative <b>capacity</b> <b>sharing</b> strategies {{have been made}} possible. We propose a versatile infinite-state Markov reward model to study the bottleneck node in a 2 -hop IEEE 801. 11 -based ad hoc network for different adaptive <b>capacity</b> <b>sharing</b> strategies. We use infinite-state stochastic Petri nets (iSPNs) to specify our model, from which the underlying QBD-type Markov-reward models are automatically derived. The impact of the different <b>capacity</b> <b>sharing</b> strategies is analyzed by CSRL model checking of the underlying infinite-state QBD, for which we provide new techniques. Our modeling approach helps in deciding under which circumstances which adaptive <b>capacity</b> <b>sharing</b> strategy is most appropriate...|$|R
40|$|States {{that the}} Stackelberg {{leadership}} model is rarely {{used to describe}} market price determination {{perhaps because of the}} lack of a theoretical basis for selecting the minimum size necessary for leadership. Provides structural sufficiency conditions for selecting a unique Stackelberg leader based on the concept of Pareto dominance, in which the structural criterion involves the relative <b>capacity</b> <b>shares</b> of the first and second largest market rivals. Suggests that the Stackelberg price game is a viable static equilibrium construct even though the fringe firms are not atomistic. Applies the Stackelberg model to antitrust merger analysis. Anti-trust, Economic theory, Market share, Mergers and acquisitions...|$|E
40|$|We {{examine a}} seat {{allocation}} game between two airlines for flights with two fares with dependent random demands. The strategic variable {{of this game}} is each airline’s booking limit for the low fare. We have shown that there exists an equilibrium booking strategy such that both airlines will protect {{the same number of}} seats for the full fare and the total number of seats available for the discount fare under competition is smaller than the total number of seats that would be available if the two airlines collude. A numerical example is used to illustrate the equilibrium solutions and to examine the impact of the <b>capacity</b> <b>shares</b> and the level of dependency between random demands...|$|E
40|$|In this paper, {{we address}} the problem of {{capacity}} assignment (CA) for latency-sensitive traffic in multi-service IP networks. The CA problem is formulated as an optimization problem with nonlinear constraints, where the total link <b>capacity</b> <b>shares</b> allocated to the given service are minimized subject to performance constraints in terms of end-to-end delay requirements. We introduce a new extension to traditional CA problems by setting a statistical bound on the maximum end-to-end delay experienced by all packets associated with the given latency-sensitive service. For a sample IP network scenario with VoIP traffic, we show that a relatively slight increase in capacity as compared with the classical approach is required to keep the probability of exceeding the maximum end-to-end network delay threshold below 0. 1 %. PublishedN/...|$|E
40|$|The {{divergent}} {{predictions of}} 2 models of dual-task performance are investigated. The central bottleneck and central <b>capacity</b> <b>sharing</b> models {{argue that a}} central stage of information processing is capacity limited, whereas stages before and after are capacity free. The models disagree {{about the nature of}} this central capacity limitation. The central bottleneck model claims that central processing acts on only 1 task at a time and, therefore, constitutes a bottleneck that processes tasks serially. The central <b>capacity</b> <b>sharing</b> model postulates that the central stage is a limited-capacity parallel processor that divides resources among to-be-performed tasks. As a result of this difference, in the psychological refractory period paradigm, the central <b>capacity</b> <b>sharing</b> model predicts that lengthening Task 2 precentral processing will improve Task 1 performance at short stimulus onset asynchronies, whereas the central bottleneck model does not. Results of 2 experiments confirm the prediction of the central <b>capacity</b> <b>sharing</b> model...|$|R
40|$|Abstract. Through the {{analysis}} of the transmission mechanism—distribution beam for large section (side length> 800 mm) concrete-filled rectangular steel tube column by the theory of elastic foundation beam we can obtain, percentage of load-carrying <b>capacity</b> <b>shared</b> by concrete cα is related with vertical spring stiffness of the steel tube sk, rotational spring stiffness of the steel tube θk, the vertical spring stiffness of the core concrete ck and stiffness of the distribution beam. Through analysis of the relationship among percentage of load-carrying <b>capacity</b> <b>shared</b> by concrete cα and the impact factors, we can identify the main factors that affect the percentage of load-carrying <b>capacity</b> <b>shared</b> by concrete cα, to control the design of the distribution beam...|$|R
40|$|Seeing network {{resources}} {{as a public}} good involves to mantain open and shared access to them for any user. Nevertheless, these conditions may be really difficult to achieve in presence of well-endowed users with heavy data flows. Our purpose here {{is to provide a}} two stage game form for managing heavy data flows which may cause network congestion or monopolization. Using an axiomatic approach, we show that the mechanism proposed attains economic efficiency and it implements <b>capacity</b> <b>sharing.</b> Copyright Kluwer Academic Publishers 2004 <b>capacity</b> <b>sharing,</b> congested networks, subgame implementation,...|$|R
40|$|A {{design of}} anautomatic network {{capacity}} markets, oftenreferred to as a bandwidth market, is presented. Three topicsare investigated. First, a network model is proposed. Theproposed model {{is based upon}} a trisection of the participantroles into network users, network owners, and market middlemen. The network capacity is defined {{in a way that}} allows it to betraded, and to have a well defined price. The network devicesare modeled as core nodes, access nodes, and border nodes. Requirements on these are given. It is shown how theirfunctionalities can be implemented in a network. Second, asimulated capacity market is presented, and a statisticalmethod for estimating the price dynamics in the market isproposed. A method for pricing network services based on sharedcapacity is proposed, in which the price of a service isequivalent to that of a financial derivative contract on anumber of simple <b>capacity</b> <b>shares.</b> Third, protocols for theinteraction between the participants are proposed. The marketparticipants need to commit to contracts with an auditableprotocol with a small overhead. The proposed protocol is basedon a public key infrastructure and on known protocols for multiparty contract signing. The proposed model allows networkcapacity to be traded in a manner that utilizes the networkeciently. A new feature of this market model, compared to othernetwork capacity markets, is that the prices are not controlledby the network owners. It is the end-users who, by middlemen,trade capacity among each-other. Therefore, financial, ratherthan control theoretic, methods are used for the pricing ofcapacity. Keywords: Computer network architecture, bandwidthtrading, inter-domain Quality-of-Service, pricing,combinatorial allocation, financial derivative pricing,stochastic modelingNR 2014080...|$|E
40|$|A {{design of}} an {{automatic}} network capacity markets, {{often referred to}} as a bandwidth market, is presented. Three topics are investigated. First, a network model is proposed. The proposed model is based upon a trisection of the participant roles into network users, network owners, and market middlemen. The network capacity is defined in a way that allows it to be traded, and to have a well defined price. The network devices are modeled as core nodes, access nodes, and border nodes. Requirements on these are given. It is shown how their functionalities can be implemented in a network. Second, a simulated capacity market is presented, and a statistical method for estimating the price dynamics in the market is proposed. A method for pricing network services based on shared capacity is proposed, in which the price of a service is equivalent to that of a financial derivative contract on a number of simple <b>capacity</b> <b>shares.</b> Third, protocols for the interaction between the participants are proposed. The market participants need to commit to contracts with an auditable protocol with a small overhead. The proposed protocol is based on a public key infrastructure and on known protocols for multi party contract signing. The proposed model allows network capacity to be traded in a manner that utilizes the network e#ciently. A new feature of this market model, compared to other network capacity markets, is that the prices are not controlled by the network owners. It is the end-users who, by middlemen, trade capacity among each-other. Therefore, financial, rather than control theoretic, methods are used for the pricing of capacity...|$|E
40|$|Abstract — We {{show that}} {{different}} flavors of TCP {{may be viewed}} as implementations of age-based scheduling disciplines. By parameterizing the scheduling disciplines of interest we are able to position variants of TCP in a wide spectrum having FCFS (First-Come First-Served) and LAS (Least Attained Service first) as extremal policies, and including PS (Processor Sharing) as an intermediate case. We argue that for highly loaded systems, providing a fair bandwidth allocation among all users is secondary to ensuring network stability. So as to isolate protocol fairness from congestion effects, we therefore focus on scenarios with infinite buffers. This way, asymmetries in <b>capacity</b> <b>shares</b> are the consequences of the protocol only, and not affected by the packet loss process. The model, however, is flexible enough to include finite buffers with random packet loss as a special case (for example to capture Active Queue Management). The results are helpful in studying fairness and performance concerned with transmission protocols in communication networks. For persistent HTTP connections we study the distributions of the transmission rates and the relative fairness index under various assumptions on the file size distributions and scheduling disciplines. For infinite file sizes, we show that protocols that increase priority more than linearly with the attained service asymptotically behave similar to FCFS. In contrast, protocols with at most linearly increasing (or even decreasing) priority, with TCP’s Congestion Avoidance mechanism as the most prominent example, converge to PS scheduling (even in absence of losses). When the priority is exactly linear in the attained service, such as for Scalable TCP and TCP’s Slow Start phase, the shares remain constant in between file initiations and completions. 1 I...|$|E
40|$|In this paper, we analyze a {{model of}} <b>capacity</b> <b>sharing</b> {{for a set of}} {{independent}} firms, geographically distributed, that often have to implement an opportune tool to integrate their resources and demand forecasts in order to gather a specific production objective. We formulate the problem as a cooperative game and identify a <b>capacity</b> <b>sharing</b> solution using the Gale–Shapley model. The allocation rule takes into account the utility functions of the involved firms, and we show how the capacity allocation rule can be designed to induce all firms to report truthfully their information. Moreover, we show that, under this allocation rule, truth telling is a dominant strategy, with each firm reporting truthfully its private information, regardless of the reporting decisions of other firms. Moreover, the proposed research develops a distributed approach able to facilitate the <b>capacity</b> <b>sharing</b> process by using a multi-agent architecture; then a discrete simulation environment has been developed to compare the proposed approach with a centralized one. Several simulation scenarios were conducted to analyze the performances' trends in various environment conditions...|$|R
40|$|Abstract — Overlay {{networks}} {{have emerged as}} a generic networking paradigm to improve network performance and construct new applications. Although many overlay algorithms have been proposed lately, they {{tend to focus on}} a single overlay, without considering how to <b>share</b> network <b>capacity</b> with other traffic and other overlays. In this paper, we study optimal <b>capacity</b> <b>sharing</b> of network with multiple overlays. We first formulate the problem of optimal <b>capacity</b> <b>sharing</b> of networks with multiple overlays as a nonlinear optimization problem. We show that traditional flow-level rate controllers result in suboptimal sharing results between the different overlays. We design efficient and distributed overlay flows control algorithms and demonstrate the effectiveness of our design. I...|$|R
40|$|This paper {{provides}} a welfare analysis of vertical merger between an input monopolist and downstream firms that compete perfectly in a homogeneous product market. The distinguishing {{feature of the}} present model is that the downstream firms face capacity constraints. As a result of downstream quasi-rents, vertical merger-the extent of merger is gauged by the <b>capacity</b> <b>share</b> of the acquired downstream firm-may either raise or lower final output. An analytical criterion for distinguishing pro- and anti-competitive mergers is derived, which relies entirely on pre-merger market quantities and the <b>capacity</b> <b>share</b> of the downstream target. A common result is that vertical merger is output-increasing even when unaffiliated downstream rivals are completely foreclosed. Copyright © 2008 John Wiley & Sons, Ltd. ...|$|R
40|$|During {{the past}} decade, Grid {{computing}} has gained popularity {{as a means}} to build powerful computing infrastructures by aggregating distributed computing capacity. Grid technology allows computing resources that belong to different organizations to be integrated into a single unified system image – a Grid. As such, Grid technology constitutes a key enabler of large-scale, crossorganizational sharing of computing resources. An important objective for the Virtual Organizations (VOs) that result from such sharing is to tame the distributed capacity of the Grid in order to manage it and make fair and efficient use of the pooled computing resources. Most Grids to date have, however, been completely unregulated, essentially serving as a “source of free CPU cycles” for authorized Grid users. Whenever unrestricted access is admitted to a shared resource there is a risk of overexploitation and degradation of the common resource, a phenomenon often referred to as “the tragedy of the commons”. This thesis addresses this problem by presenting two complementary Grid capacity allocation systems that allow the aggregate computing capacity of a Grid to be divided between users {{in order to protect the}} Grid from overuse while delivering fair service that satisfies the individual computational needs of different user groups. These two Grid capacity allocation mechanisms constitute the core contribution of this thesis. The first mechanism, the SweGrid Accounting System (SGAS), addresses the need for coordinated soft, real-time quota enforcement across Grid sites. The SGAS project was an early adopter of the serviceoriented principles that are now common practice in the Grid community, and the system has been tested in the Swegrid production environment. Furthermore, SGAS has been included in the Globus Toolkit, the de-facto standard Grid middleware toolkit. SGAS employs a credit-based allocation model where research projects are granted quota allowances that can be spent across the Grid resources, which charge users for their resource consumption. This enforcement of usage limits thus produces real-time overuse protection. The second approach, employed by the Fair Share Grid (FSGrid) system, uses a share-based allocation model where project entitlements are expressed in terms of hierarchical share policies that logically divide the Grid capacity between user groups. By coordinating local job scheduling to maintain these global <b>capacity</b> <b>shares,</b> the Grid resources collectively strive to schedule users for a “share of the Grid”. We refer to this cooperative scheduling model as decentralized Grid-wide fairshare scheduling...|$|E
40|$|As {{capacity}} demands vary among simultaneously executed threads in chip multiprocessors, dynamically managing cache resources {{according to}} the run-time demands is effective to improve L 2 cache performance. Differed from existing dynamic cache management schemes based on LRU replacement policy, we propose an adaptive <b>capacity</b> <b>sharing</b> mechanism based on a global reuse replacement policy. This mechanism adopts decoupled tag and data arrays, and partitions the data arrays into private and <b>shared</b> regions. <b>Capacity</b> <b>sharing</b> is accomplished by determining whether to place the incoming data into the private data region or into the shared data region, which is controlled by probabilities. Our mechanism includes: (1) A VMON monitor to predict run-time capacity demands. (2) A PCS algorithm to determine the probabilities. (3) A probabilistic controlled placement scheme to enforce <b>capacity</b> <b>sharing.</b> We evaluated our mechanism with a full system simulation of an 8 -core CMP and used parallel programs from PARSEC benchmark suite. We found that with the same total L 2 cache capacity, our mechanism exceeds the conventional private cache managed by LRU policy, the private cache without sharing managed by reuse replacement policy, and an existing adaptive sharing scheme based on LRU policy...|$|R
5000|$|C. S. K. Vadrevu, M. Tornatore, R. Wang, and B. Mukherjee, [...] "Integrated Design for Backup <b>Capacity</b> <b>Sharing</b> Between IP and Wavelength Services in IP-Over-WDM Networks," [...] IEEE/OSA Journal of Optical Communications and Networking, vol. 4, no. 1, pp. 53-65, Jan. 2012.|$|R
40|$|International audienceIn this paper, {{we discuss}} User Centric Networks (UCNs) {{as a way}} of, if not {{completely}} solving, considerably mitigating the problem of <b>sharing</b> limited network <b>capacity</b> and resources efficiently and fairly. UCNs are self-organizing networks where the end-user plays {{an active role in}} delivering networking functions such as providing Internet access to other users. We propose to leverage the recently proposed Software Defined Networking (SDN) paradigm to enable cooperation between wireless nodes and provide <b>capacity</b> <b>sharing</b> services in UCNs. Our SDN-based approach allows to extend coverage of existing network infrastructure (such as WiFi or 3 GPP) to other end-users or ad hoc networks that would otherwise not be able to have access to network connectivity and services. Moreover, the proposed SDN-based architecture also takes into account current network load and conditions, and quality-of service (QoS) requirements. Another important feature of our framework is that security {{is an integral part of}} the architecture and protocols. We discuss the requirements for enabling <b>capacity</b> <b>sharing</b> services in the context of UCNs (e. g., resource discovery, node admission control, cooperation incentives, QoS, security, etc) and how SDN can aid in enabling such services. The paper also describes the proposed SDN-enabled <b>capacity</b> <b>sharing</b> framework for UCNs...|$|R
50|$|EAD {{seeks to}} reach out to {{communities}} and encourage sustainable and environmentally-friendly practices among Abu Dhabi’s citizens and residents by developing their awareness of environmental issues building their <b>capacity,</b> <b>sharing</b> knowledge with them and providing them with resources, tools and guides to help our communities become sustainable.|$|R
40|$|Abstract—This paper {{extends the}} spare {{capacity}} allocation (SCA) problem from single link failure [1] to dual link failures on mesh-like IP or WDM networks. The SCA problem pre-plans traffic flows with mutually disjoint one working and two backup paths using the shared backup path protection (SBPP) scheme. The aggregated spare provision matrix (SPM) {{is used to}} capture the spare <b>capacity</b> <b>sharing</b> for dual link failures. Comparing to a previous work by He and Somani [2], this method has better scalability and flexibility. The SCA problem is formulated in a non-linear integer programming model and partitioned into two sequential linear sub-models: one finds all primary backup paths first, and the other finds all secondary backup paths next. The results on five networks show that the network redundancy using dedicated 1 + 1 + 1 is {{in the range of}} 313 - 400 %. It drops to 96 - 181 % in 1 : 1 : 1 without loss of dual-link resiliency, but with the trade-off of using the complicated <b>share</b> <b>capacity</b> <b>sharing</b> among backup paths. The hybrid 1 + 1 : 1 provides intermediate redundancy ratio at 187 - 310 % with a moderate complexity. We also compare the passive/active approaches which consider spare <b>capacity</b> <b>sharing</b> after/during the backup path routing process. The active sharing approaches always achieve lower redundancy values than the passive ones. These reduction percentages are about 12 % for 1 + 1 : 1 and 25 % for 1 : 1 : 1 respectively. Index Terms—spare <b>capacity</b> allocation, <b>shared</b> backup path protection, dual link failures, traffic engineering I...|$|R
50|$|Processor sharing: Service <b>capacity</b> is <b>shared</b> equally between customers.|$|R
5000|$|Improve <b>capacity</b> for <b>sharing</b> {{information}} about good CBR practices.|$|R
40|$|It is {{commonly}} noted that Australian water rights, specifically those prevailing within the Murray-Darling Basin, represent {{a significant departure from}} hydrological reality (see for example Young and McColl 2009). Where water rights {{depart from the}} physical realities of water supply networks, water use and water trade decisions may result in external effects and associated allocative inefficiency. This paper examines how a more exclusive set of water property rights based around the concept of <b>capacity</b> <b>sharing</b> (Dudley and Musgrave 1988) might be defined and implemented in complex regulated river systems. In particular, the paper considers how the <b>capacity</b> <b>sharing</b> concept might be generalised to accommodate complex water supply systems (e. g. with multiple storages and or unregulated river flows) and large regulated river basins (e. g. with multiple connected water supply systems). Previous research on water storage rights and <b>capacity</b> <b>sharing</b> (Hughes 2009, Brennan 2008) focused extensively on intertemporal efficiency. In this paper the focus is primarily on spatial efficiency, in particular the potential to improve efficiency by incorporating a more accurate representation of water supply networks into water property rights. The paper also considers some of the challenges that may be associated with implementing such a system of water property rights, including distributional consequences, transaction costs and aspects of ‘jointness’ in the delivery and consumption of water. Resource /Energy Economics and Policy,...|$|R
2500|$|Generation <b>capacity</b> is <b>shared</b> {{among the}} {{different}} companies as follows: ...|$|R
40|$|Information on {{the value}} of water in use is a {{prerequisite}} for the efficient allocation, utilization, trading and transfer thereof. These issues are becoming very important for South Africa. Linear programming (LP) and stochastic dynamic programming (SDP) are two techniques that can be applied to value water. Based on a simulated irrigation farming situation downstream of the Vanderkloof Dam wherein farmers hold a <b>capacity</b> <b>share</b> (CS) this paper draws a comparison between the marginal value products (MVP’s) obtained from applying LP and SDP simultaneously. Linear programming is used to optimize water use on the farm during the immediate season while SDP is used to optimize the use of water in storage in the farmers <b>capacity</b> <b>share</b> (CS) in the Vanderkloof Dam through time. Emphasis is placed on the interpretation of the results which are presented graphically. Resource /Energy Economics and Policy,...|$|R
40|$|This paper {{proposes a}} Framework for <b>Capacity</b> <b>Sharing</b> in Cloud Manufacturing (FCSCM) {{able to support}} the <b>capacity</b> <b>sharing</b> issue among {{independent}} firms. The success of geographical distributed plants depends strongly {{on the use of}} opportune tools to integrate their resources and demand forecast in order to gather a specific production objective. The framework proposed is based on two different tools: a cooperative game algorithm, based on the Gale–Shapley model, and a fuzzy engine. The capacity allocation policy takes into account the utility functions of the involved firms. It is shown how the capacity allocation policy proposed induces all firms to report truthfully their information about their requirements. A discrete event simulation environment has been developed to test the proposed FCSCM. The numerical results show the drastic reduction of unsatisfied capacity obtained by the model of cooperation implemented in this work...|$|R
40|$|A novel {{optical fibre}} LAN with an amplified bus {{topology}} is described. It uses dark signalling, whereby nodes interrupt the light path {{in an otherwise}} continuously bright fibre, and <b>capacity</b> <b>sharing</b> is by optical {{code division multiple access}} (OCDMA). A comprehensive model of the network performance is developed and the results of a numerical simulation are presented. I...|$|R
50|$|BCal {{tried to}} work around these {{restrictions}} by using larger One-Eleven 500s in a low-density configuration featuring a first class section on week days and smaller, single-class One-Eleven 200s on week-ends. This enabled it to offer a higher frequency on week days, resulting in a more competitive schedule for business travellers while keeping within its allocated <b>capacity</b> <b>share.</b>|$|R
40|$|This paper {{extends the}} spare {{capacity}} allocation (SCA) problem from single link failure [1] to dual link failures on mesh-like IP or WDM networks. The SCA problem pre-plans traffic flows with mutually disjoint one working and two backup paths using the shared backup path protection (SBPP) scheme. The aggregated spare provision matrix (SPM) {{is used to}} capture the spare <b>capacity</b> <b>sharing</b> for dual link failures. Comparing to a previous work by He and Somani [2], this method has better scalability and flexibility. The SCA problem is formulated in a non-linear integer programming model and partitioned into two sequential linear sub-models: one finds all primary backup paths first, and the other finds all secondary backup paths next. The results on five networks show that the network redundancy using dedicated 1 + 1 + 1 is {{in the range of}} 313 - 400 %. It drops to 96 - 181 % in 1 : 1 : 1 without loss of dual-link resiliency, but with the trade-off of using the complicated <b>share</b> <b>capacity</b> <b>sharing</b> among backup paths. The hybrid 1 + 1 : 1 provides intermediate redundancy ratio at 187 - 310 % with a moderate complexity. We also compare the passive/active approaches which consider spare <b>capacity</b> <b>sharing</b> after/during the backup path routing process. The active sharing approaches always achieve lower redundancy values than the passive ones. These reduction percentages are about 12 % for 1 + 1 : 1 and 25 % for 1 : 1 : 1 respectively...|$|R
40|$|In two-hop ad hoc {{networks}} {{the available}} radio capacity {{tends to be}} equally shard among the contending stations, which may lead to bottleneck situations in case of unbalanced traffic routing. We propose a generic model for evaluating adaptive <b>capacity</b> <b>sharing</b> strategies. We use infinite-state stochastic Petri nets for modeling the system and use the logic CSRL for specifying the measures of interest...|$|R
40|$|This paper {{proposes a}} novel {{paradigm}} for network congestion control. Instead of perpetual conflict as in TCP, a proof-of-concept first-ever protocol enabling inter-flow communication without infrastructure support thru a side channel constructed on generic FIFO queue behaviour is presented. This enables independent flows passing thru the same bottleneck queue {{to communicate and}} achieve fair <b>capacity</b> <b>sharing</b> and a stable equilibrium state in a rapid fashion...|$|R
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references (leaves 60 - 61). Issued also on microfiche from Lange Micrographics. For handling multiple aperiodic tasks with different temporal requirements, multiple aperiodic servers are used. Since capacity is partitioned statically among the multiple servers, they suffer from heavy capacity exhaustions. Bernat and Burns introduced <b>Capacity</b> <b>sharing</b> protocol, in which a server can use the unused capacity of other servers. Though capacity-sharing protocol minimized the capacity exhaustions in multiple servers, it did not deal with fairness in <b>sharing</b> of <b>capacity</b> among demanding servers, which leads to unfair treatment to low priority jobs. In our research, we propose fair <b>capacity</b> <b>sharing</b> protocol in multiple aperiodic servers, which <b>shares</b> the <b>capacity</b> fairly among the demanding servers based on their priorities. Our research includes implementation of our protocol and performance comparison with previous approaches...|$|R
