25|30|Public
2500|$|The Visitacion Valley Community Resiliency Project (VVCRP) was {{reviewed}} {{by an independent}} evaluator hired by the Pottruck Foundation. [...] Her final report notes that [...] "Early program evaluation...found that the VVCRP was successful in reducing individuals’ feelings of depression and isolation, and increasing their sense of happiness and self-control. The <b>cumulative</b> <b>evaluation</b> research conducted on the VVCRP and the HR model in general concludes that HR is {{a powerful tool for}} changing individuals’ beliefs and behaviors." [...] In the Summary of Case Studies, the report goes on to state, [...] "The VVCRP was effective over a period of five years of sustained involvement in two major neighborhood institutions...at influencing not just individuals, but also organizational policies, practices, and culture. This level of organizational influence is impressive when the relatively modest level of VVCRP staff time and resources invested into making these changes is taken into account. The pivotal levers of change at each organization were individual leaders who were moved by the HR principles to make major changes in their own beliefs, attitudes, and behaviors, and then took the initiative to inspire, enable, and mandate similar changes within their organizations. This method of reaching [...] "critical mass" [...] of HR awareness within these organizations appears to be both efficient and effective when the leadership conditions are right. However, this pathway to change is vulnerable to the loss of the key individual leader." ...|$|E
5000|$|Cumulative Illness Rating Scale (CIRS): Developed in 1968 by B. S. Linn, {{it became}} a revolutionary discovery, because it gave the {{practicing}} doctors a chance to calculate the number and severity of chronic illnesses {{in the structure of}} the comorbid state of their patients. The proper use of CIRS means separate <b>cumulative</b> <b>evaluation</b> of each of the biological systems: [...] "0" [...] The selected system corresponds to the absence of disorders, [...] "1": Slight (mild) abnormalities or previously suffered disorders, [...] "2": Illness requiring the prescription of medicinal therapy, [...] "3": Disease, which caused disability and [...] "4": Acute organ insufficiency requiring emergency therapy. The CIRS system evaluates comorbidity in cumulative score, which can be from 0 to 56. As per its developers, the maximum score is not compatible with the patient's life.|$|E
5000|$|The Visitacion Valley Community Resiliency Project (VVCRP) was {{reviewed}} {{by an independent}} evaluator hired by the Pottruck Foundation. [...] Her final report notes that [...] "Early program evaluation...found that the VVCRP was successful in reducing individuals’ feelings of depression and isolation, and increasing their sense of happiness and self-control. The <b>cumulative</b> <b>evaluation</b> research conducted on the VVCRP and the HR model in general concludes that HR is {{a powerful tool for}} changing individuals’ beliefs and behaviors." [...] In the Summary of Case Studies, the report goes on to state, [...] "The VVCRP was effective over a period of five years of sustained involvement in two major neighborhood institutions...at influencing not just individuals, but also organizational policies, practices, and culture. This level of organizational influence is impressive when the relatively modest level of VVCRP staff time and resources invested into making these changes is taken into account. The pivotal levers of change at each organization were individual leaders who were moved by the HR principles to make major changes in their own beliefs, attitudes, and behaviors, and then took the initiative to inspire, enable, and mandate similar changes within their organizations. This method of reaching [...] "critical mass" [...] of HR awareness within these organizations appears to be both efficient and effective when the leadership conditions are right. However, this pathway to change is vulnerable to the loss of the key individual leader." ...|$|E
40|$|Perceived equity {{is a key}} {{psychological}} {{reaction to}} the value that a service company provides. Yet equity {{research has focused on}} a customer’s satisfaction with relatively well-defined service episodes or transactions. The authors argue and show that equity plays a very different role in affecting customer loyalty as one moves from transaction-specific to <b>cumulative</b> <b>evaluations.</b> Whereas equity is an important driver of transaction-specific satisfaction, equity is more of a post-satisfaction <b>evaluation</b> when modeling <b>cumulative</b> satisfaction. The research also demonstrates the superiority of <b>cumulative</b> <b>evaluations</b> toward explaining service loyalty and providing a balanced view of loyalty drivers. The results have important implications for how equity, satisfaction, and loyalty are modeled and managed in a service context...|$|R
40|$|Services Program and {{requested}} bids from debris removal contractors {{that have been}} chosen via a competitive sealed proposal process by H-GAC. An evaluation committee reviewed and scored {{each of the eight}} proposals received to determine which proposals represented the best value to the City. The criteria used for the evaluation included the following: H-GAC Rating, Experience, Services/Resources, Pricing, and Support/Training. The contractor that received the highest score on the <b>cumulative</b> <b>evaluations</b> was Ashbritt, Inc. Staff recommends Council's authorization and execution of a contract wit...|$|R
40|$|More than 25 {{years have}} passed since Bailar and Kallek, Wolter and Monsour (1986) {{evaluated}} the Economic Census. Twelve {{years have passed}} since the Internal Revenue Service conducted its 1988 Taxpayer Compliance Monitoring Program. In that time much has been learned about data capture, improving business lists, imputation, and editing. However, findings about measurement error in business statistics leave questions about the quality of data that are the foundation for national account estimates. Those questions raise further questions about the quality of models of the economy and forecasts. Each of these facts motivate more frequent, comprehensive, and <b>cumulative</b> <b>evaluations</b> of data collected from business. Understanding the associated variance and biases of those measures assists in improving data quality and creating more valuable official statistics...|$|R
40|$|This paper {{considers}} {{the application of}} reinforcement learning to path finding tasks in continuous state space {{in the presence of}} ob- stacles. We show that <b>cumulative</b> <b>evaluation</b> functions (as Q-Functions [2 S] and V-Functions [4]) may be discontinuous if forbidden regions (as implied by obstacles) exist in state space. As the infinite number of states requires the use of function approximators such as backpropa- gation nets [16, 12, 24], we argue that these discontinuities imply severe difficulties in learning <b>cumulative</b> <b>evaluation</b> functions. The discontinuities we detected might also explain why recent applications of rein- forcement learning systems to complex tasks [12] failed to show desired performance. In our conclusion, we outline some ideas to circumvent the problem...|$|E
40|$|This {{conceptual}} piece {{presents a}} framework to aid libraries in gaining {{a more thorough}} and holistic understanding of their users and services. Through a presentation {{of the history of}} library evaluation, a measurement matrix is developed that demonstrates the relationship between the topics and perspectives of measurement. These measurements are then combined through evaluation criteria, and then different participants in the library system view those criteria for decision-making. By implementing this framework for holistic measurement and <b>cumulative</b> <b>evaluation,</b> library evaluators can gain a more holistic knowledge of the library system and library administrators can be better informed for their decision-making processes...|$|E
40|$|This report {{presents}} the final <b>cumulative</b> <b>evaluation</b> findings for the Jewish Resource Specialist Program (JRS) {{over the three}} years of the JRS pilot, including key achievements and challenges. The evaluation assesses the JRS program overallas a modeland not individual sites. This evaluation addresses the following two distinct evaluation questions: 1. How, and to what extent, are families at JRS schools increasing their engagement in Jewish life and learning within JRS schools and in the community? 2. How, and to what extent, is JRS deepening Jewish learning within the JRS school environment? This evaluation also seeks to document the growth and change of JRS across the three years, providing insights into aspects of the program best poised for replication and scale...|$|E
40|$|In the {{cumulative}} experience with measures {{of individual differences}} over the past 50 years, tests have been accepted as valid or discarded as invalid by research experiences of many sorts. The criteria suggested in this paper are all {{to be found in}} such <b>cumulative</b> <b>evaluations,</b> {{as well as in the}} recent discussions of validity. These criteria are clarified and imple-mented when considered jointly in the context of a multitrait-multi-method matrix. Aspects of the valida-tional process receiving particular emphasis are these: 1. Validation is typically conver-gent, a confirmation by independent measurement procedures. Independ-ence of methods is a common denom-inator among the major types of validity (excepting content validity) 1 The new data analyses reported in this paper were supported by funds from the Graduate School of Northwestern Universit...|$|R
40|$|The {{emerging}} web-based technologies {{can play}} an important role to instill the discipline of Experimental Design and make collaborative planning, executing, reporting, and archiving of experiments with core algorithms in CAD a routine. This paper introduces a user-configurable, cross-platform executable encapsulation environment that supports (1) universal access to distributed archives of equivalence classes as input data sets for the experiments; (2) encapsulation of distributed software that implements specific algorithms; (3) <b>cumulative</b> <b>evaluations</b> and archival of posted results. Keywords: Internet, collaborative computing, design of experiments, circuit equivalence classes, benchmarking. 1 Introduction The web-based access to public domain data sets for the user-defined benchmarking experiments in CAD is now taken for granted. However, as exemplified in the companion papers introduced in [1], the discipline of Experimental Design does require new toolkits that will make scientifi [...] ...|$|R
40|$|Abstract: Systematic <b>evaluation</b> of <b>cumulative</b> {{health risks}} from the {{combined}} effects of multiple environmental stressors {{is becoming a}} vital component of risk-based decisions aimed at protecting human populations and communities. This article briefly examines {{the historical development of}} cumulative risk assessment as an analytical tool, and discusses current approaches for evaluating cumulative health effects from exposure to both chemical mixtures and combinations of chemical and nonchemical stressors. A comparison of stressor-based and effects-based assessment methods is presented, and the potential value of focusing on viable risk management options to limit the scope of <b>cumulative</b> <b>evaluations</b> is discussed. The ultimate goal of cumulative risk assessment is to provide answers to decision-relevant questions based on organized scientific analysis; even if the answers, {{at least for the time}} being, are inexact and uncertain...|$|R
40|$|International audienceIn this {{contribution}} we {{demonstrate that}} European citizens distinguish between political and instrumental Euro-scepticism and indicate {{the extent to}} which these Euro-sceptic positions are endorsed. Data from 143, 367 European citizens in 15 countries and 182 regions show that political Euroscepticism constitutes a <b>cumulative</b> <b>evaluation</b> in each European country. European citizens who are Euro-sceptic on international policies are also Euro-sceptic on joint decisions on immigration policies and sociocultural policies. Moreover, we notice that political Euro-scepticism is modestly correlated with instrumental Euro-scepticism. We explore {{the extent to which}} both forms of Euro-scepticism vary between countries and regions and to what extent the percentages of missing values on these measurements affect the degree of Euro-scepticism at the national and regional level. This contribution shows that research on Euro-scepticism to date is skewed by a focus on instrumental Euro-scepticism...|$|E
40|$|Abstract: In {{this paper}} a new Back-propagation {{algorithm}} appropriately studied for modelling air pollution time series is proposed. The underlying {{idea is that}} of modifying the error definition {{in order to improve}} the capability of the model to forecast episodes of poor air quality. In the paper five different expressions of error definition are proposed and their performances are rigorously evaluated in the framework of a real case study which refer to the modelling of 1 hour average daily maximum Ozone concentration recorded in the industrial area of Melilli (Siracusa, Italy). Results indicate that despite the traditional and the proposed version of Back-propagation performs quite similarly in terms of Success Index which gives a <b>cumulative</b> <b>evaluation</b> of the model, this latter algorithm performs better in terms of the percentage of exceedences correctly forecast. Copyright c© 2005 IFA...|$|E
40|$|In this {{contribution}} we {{demonstrate that}} European citizens distinguish between political and instrumental Euro-scepticism and indicate {{the extent to}} which these Euro-sceptic positions are endorsed. Data from 143, 367 European citizens in 15 countries and 182 regions show that political Euroscepticism constitutes a <b>cumulative</b> <b>evaluation</b> in each European country. European citizens who are Euro-sceptic on international policies are also Euro-sceptic on joint decisions on immigration policies and sociocultural policies. Moreover, we notice that political Euro-scepticism is modestly correlated with instrumental Euro-scepticism. We explore {{the extent to which}} both forms of Euro-scepticism vary between countries and regions and to what extent the percentages of missing values on these measurements affect the degree of Euro-scepticism at the national and regional level. This contribution shows that research on Euro-scepticism to date is skewed by a focus on instrumental Euro-scepticism. ...|$|E
40|$|Nine cultivars Nectared- 4, Nectared- 6, Nectared- 8, Independence, Cherokee, Fairlane, Armking, Starks Red Gold and Summer Super Star {{were used}} in {{adaptation}} experiments. Phenologic observations in the years 1998, 1999 and 2000 and pomologic observations in the years 1999 and 2000 were carried out. It was found that Armking was the earliest cultivar and had the highest pH value while Summer Super Star was the latest cultivar and had the lowest pH value. While the highest average fruit weight was obtained from Summer Super Star the lowest average fruit weight was obtained from Armking cultivar. In terms of yield per tree Cherokee and Summer Super Star cultivars showed the lowest values. Nectared- 6 showed the highest value. Armking followed Nectared- 6. Cumulative yield per 1 cm 2 stem cutting area was also evaluated While Nectared- 4 had the highest cumulative yield per 1 cm 2 stem cutting area, Fairlane had the lowest value. When phenologic, pomologic and <b>cumulative</b> <b>evaluations</b> were considered, Armking, Nectared- 6 and Nectared- 8 cultivars were noticeably found as proper cultivars for adaptation in regional ecology...|$|R
40|$|<b>Cumulative</b> impact <b>evaluation</b> {{is one of}} {{the most}} actual {{problems}} in air quality monitoring. At the same time, it is also the most problematic factor to evaluate due to lack of appropriate methodology. The aim of this study was to assess the opportunity to use a new method – Cumulative Pollution Index (CPI) in cumulative impact calculation from two different sets of data – bioindication survey with Index of Atmospheric Purity method and air pollution dispersion modelling. Results show that the usage of modelling data, instead of measurements, in <b>cumulative</b> impact <b>evaluation</b> can be quite difficult due to the fact that dispersion models not always give sufficiently accurate data. Despite the issues with modelling specifics, the use of dispersion modelling in CPI calculation shows that the use of this approach not only gives plausible data – obtained values correlate with pollution level and forming strong clustering in spatial distribution, but also reveals new facts about cumulative impact – demonstrates the city microclimate importance in forming of cumulative effect due to geometry of street canyons...|$|R
40|$|This article {{proposes a}} discourse-narrative {{approach}} to news making online as a networked practice of storying and sharing. This approach {{is illustrated in}} {{the examination of the}} release of a draft Eurogroup statement via journalist Paul Mason’s Facebook, Scribd and Twitter accounts on the 16 th February 2015. The analysis draws on small story insights (Georgakopoulou, 2015) and the empirical framework of sharing (Androutsopoulos, 2014). It shows how the release of this leak event on Twitter is storied as a breaking news story unfolding moment-by-moment as it happens, {{at the same time as}} making up an incipient record of the event as it happened. It is argued that breaking news (micro) stories are shared as moments of narrative stancetaking, featuring a concise, portable storyline and <b>cumulative</b> <b>evaluation(s)</b> that foreground the relevance of the leak for the ongoing discussions on the Greek bailout negotiations as well as the continued importance of the journalist as the mediator of the leak. In this case of sharing a leaked document with networked participants, narrativity is drawn upon as a key resource for producing and circulating alternative stances on the Greek crisis, creating a range of networked participation positions. This article contributes to the study of news sharing online and digital storytelling based on the qualitative analysis of ‘small’ data...|$|R
40|$|Numerical {{value range}} {{partitioning}} is an inherent part of inductive learning. In classification problems, a common partition ranking {{method is to}} use an attribute evaluation function to assign a goodness score to each candidate. Optimal cut point selection constitutes a potential efficiency bottleneck, which is often circumvented by using heuristic methods. This paper aims at improving the efficiency of optimal multisplitting. We analyze convex and <b>cumulative</b> <b>evaluation</b> functions, which account {{for the majority of}} commonly used goodness criteria. We derive an analytical bound, which lets us filter out [...] -when searching for the optimal multisplit [...] -all partitions containing a specific subpartition as their prefix. Thus, the search space of the algorithm can be restricted without losing optimality. We compare the partition candidate pruning algorithm with the best existing optimization algorithms for multisplitting. For it the numbers of evaluated partition candidates are, on the averag [...] ...|$|E
40|$|The {{aim of this}} {{research}} was to analyze postural disorders and nutritional status in adolescents, and to compare the incidence of postural disorders with regard to category of nutritional status and gender dimorphism. The sample of subjects comprised of 305 adolescents, 11 - 14 years old, of both gender (158 girls and 147 boys), students of the primary school from Vojvodina. Postural status was assessed by Napoleon Volanski method. Body mass index (BMI) was calculated by standard procedure. In establishment of differences in postural status, with regard to the age and the gender dimorphism, we used χ 2 test. In order to establish differences in <b>cumulative</b> <b>evaluation</b> of postural status, we applied rank-sum Mann-Whitney Z-test. In establishment of differences in groups of subjects formed on the basis of degree of nutritional status, we applied Kruskall-Wollis test. The survey results show a statistically significant difference acording to the gender, in subjects aged 13 to 14 years, and a significant positive correlation of these two indicators...|$|E
40|$|Abstract Background Recently {{developed}} {{measures such}} as I 2 and H allow {{the evaluation of the}} impact of heterogeneity in conventional meta-analyses. There has been no examination of the development of heterogeneity {{in the context of a}} cumulative meta-analysis. Methods Cumulative meta-analyses of five smoking cessation interventions (clonidine, nicotine replacement therapy using gum and patch, physician advice and acupuncture) were used to calculate I 2 and H. These values were plotted by year of publication, control event rate and sample size to trace the development of heterogeneity over these covariates. Results The <b>cumulative</b> <b>evaluation</b> of heterogeneity varied according to the measure of heterogeneity used and the basis of cumulation. Plots produced from the calculations revealed areas of heterogeneity useful in the consideration of potential sources for further study. Conclusion The examination of heterogeneity in conjunction with summary effect estimates in a cumulative meta-analysis offered valuable insight into the evolution of variation. Such information is not available in the context of conventional meta-analysis and has the potential to lead to the development of a richer picture of the effectiveness of interventions. </p...|$|E
40|$|Sentiment {{analysis}} (SA) {{has become}} a vibrant area of research {{over the past several}} years. By and large, SA has been used to extract sentiments from an aggregation of numerous contributors’ articles or reviews about a specific subject. For example, the <b>cumulative</b> <b>evaluations</b> of multiple reviewers are often examined en masse to determine whether customers have a positive or negative feeling toward a product or service. Similarly, the aggregated work of hundreds of journalists may be analyzed to estimate the overall political bias of an entire news organization. However, there are relatively few studies in the SA literature which examine the sentiments, and potential biases, of one particular contributor at a time, by taking into account that author’s body of work over a period of time. To address the lack of exploration in this area, a web application was created which has access to all of the more than 650, 000 articles in Guardian News’ database over the past five years, and displays indications of sentiment for a single contributor at a time. Users are able to select a specific author, and view that contributor’s sentiments regarding the themes, entities and aspects that occur most frequently in their most recent work. The ultimate goal of this project is to empower users to utilize the displayed information to draw their own conclusions about the sentiments, and potential biases, that the author may possess...|$|R
40|$|CIE 2017, Commission Internationale de l'Eclairage Midterm Meeting, Jeju, COREE, REPUBLIQUE DE, 23 -/ 11 / 2017 - 24 / 11 / 2017 In a {{previous}} paper, {{the relevance of}} several discomfort glare predictors has been considered for pedestrian ratings (Villa et al., 2017). These results are extended here to the Unified Glare Ratio and the <b>Cumulative</b> Brightness <b>Evaluation</b> System, which do not predict a de Boer rating. Conversion scales are proposed to compare the mean subjective de Boer ratings with the predictions of these models. The UGR leads to a strong overestimation of the glare experienced by pedestrians, while further studies are {{needed in order to}} assess the usefulness of the CBE for pedestrian lighting...|$|R
40|$|Proceedings of the 2003 Georgia Water Resources Conference, held April 23 - 24, 2003, at the University of Georgia. The Apalachicola-Chattahoochee-Flint (ACF) Basin has {{experienced}} three major drought {{events in the}} past 50 years. A <b>cumulative</b> deficit <b>evaluation</b> of the drought events shows that the greatest cumulative rainfall deficit occurred during the mid 1950 ’s event, but the greatest flow deficit occurred during the 1999 – 2002 drought event. An evaluation of the unimpaired flow set, being used to develop an Allocation Formula for the ACF Basin, indicates that this data set is not consistent with these findings, suggesting further evaluation {{may be needed to}} address the adequacy of the dataset as the basis for future policy decisions. Caution should be used in using and in interpreting model results from this time period...|$|R
40|$|The {{teaching}} of writing {{to students who}} speak nonstandard English can be difficult because students ' linguistic differences rarely indicate true incompetence, and students ' writing problems may result from conflicts between the cultures and langauge uses at home and school. Factors found to encourage writing improvement are the following: (1) positive teacher attitudes; (2) regular writing practice; (3) the opportunity to write for personally significant purposes; (4) student experience in writing for many audiences; (5) rich and continuous reading experience; (6) exposure to models of writing in process and writers at work; (7) instruction in the processes of writing; (8) collaborative classroom activities; (9) one-to-one writing conferences with the teacher; (10) direct instruction in specific strategies for writing; (11) reduced formal instruction in grammar and mechanics; (12) moderate marking of the surface structure errors in student papers; (13) flexible and <b>cumulative</b> <b>evaluation</b> of student writing; and (14) writing practiced and used {{as a tool of}} learning across the curriculum. (AA) Reproductions supplied by SDRS are the best that can be made from the original document...|$|E
40|$|The aim of {{the study}} was to assess {{interdependence}} of specific motor abilities (situation karate tests) and motor skills (karate techniques), and karate performance (fighting efficiency) in under-sixteen male karateka aged 11 – 12 and 13 – 14 years. A battery of 5 situation motor tests were applied and 6 basic elements of karate technique evaluated in a sample of 20 male karateka aged 11 – 12 and 20 male karateka aged 13 – 14 years. Three criterion variables were formed: 1) one factor as a factor of general technical efficiency in karate was isolated by factor analysis of 6 karate techniques; 2) <b>cumulative</b> <b>evaluation</b> of 2 kate as kate performance; and 3) total score assessment based on success achieved at national karate championships as contest efficiency (fighting efficiency). Regression analysis revealed the frequency of gedan barai blockade performance to be the superior predictor of technical efficiency, kate performance and contest success in karateka aged 11 – 12, whereas the speed of the gedan barai-jaku zuki (block-kick) combination performance and specific agility (sidewise mobility) were superior predictors of performance in karateka aged 13 – 14. Of the karate techniques (kicks) used, the quality of jaku zuki kick performance was the superior predictor of contest efficiency in karateka aged 11 – 12, and the quality of the jaku zuki-mawashi geri and kizame zuki-jaku zuki combination performance in karateka aged 13 – 14...|$|E
40|$|The {{purpose of}} the study was to {{evaluate}} the expressive-receptive lexical skills gained in bilingual preschool children for both their native language (L 1) and second language (L 2) when provided a bilingual vocabulary intervention and compared to contrasting monolingual and controlled conditions. This group study assessed four treatment conditions: monolingual English intervention, monolingual Spanish intervention, bilingual English-Spanish intervention, and a controlled intervention condition receiving math instruction. English and Spanish expressive and receptive lexical skills were the dependent variables measured at pretest and posttest. After a brief 4 week intervention block, the bilingual group achieved greater gains in Spanish expressive lexical skills when compared to a monolingual language of intervention group or a controlled intervention condition. The Spanish intervention group achieved gains across English expressive and receptive and Spanish expressive and receptive; however, their gains were less than gains seen in the bilingual group. The English intervention group exhibited gains in English receptive and expressive lexical skills but experienced a decrease in Spanish expressive and receptive skills. The controlled condition exhibited gains in English and Spanish receptive skills, a decrease in English receptive skills and no change in Spanish expressive skills. Overall, in a <b>cumulative</b> <b>evaluation</b> of Spanish and English expressive-receptive lexical skills, the bilingual group demonstrated the greatest gains in lexical skills when compared to the Spanish, English and controlled condition within a 4 week intervention block. ...|$|E
40|$|Niosomes (nonionic surfactant-based vesicles) {{containing}} rifampicin {{were prepared}} using various nonionic surfactants of sorbitan ester class and cholesterol in 50 : 50 percent mol fraction ratio. The drug-entrapped vesicles were characterized for their shape, size, drug entrapment efficiency and in vitro release rate. On {{the basis of}} in vitro characterization, the niosomes showing maximum entrapment and minimum release rate were selected for in vivo performance <b>evaluation.</b> <b>Cumulative</b> percent doses of rifampicin recovered in thoracic lymph following intravenous and intraperitoneal administrations of free rifampicin solution and niosome-encapsulated rifampicin were compared. The study revealed that effective compartmentalisation of the drug {{took place in the}} lymphatic system following intraperitoneal administration of niosome-encapsulated rifampicin. Thus rifampicin encapsulated in niosomes could successfully be used for treatment of tuberculosis along lymphatic system...|$|R
40|$|This paper evaluates {{environmental}} externality when {{the structure of}} the externality is <b>cumulative.</b> The <b>evaluation</b> exercise {{is based on the assumption}} that the agents in question form conjectural variations. A number of environments are encompassed within this classification and have received due attention in the literature. Each of these heterogeneous environments, however, possesses considerable analytical homogeneity and permit subscription to a general model treatment. These environments include {{environmental externality}}, oligopoly and the analysis of the private provision of public goods. We highlight the general analytical approach by focusing on this latter context, in which debate centers around four issues: the existence of free-riding, the extent to which contributions are matched equally across individuals, the nature of conjectures consistent with equilibrium, and the allocative inefficiency of alternative regimes. This paper resolves each of these issues, with the following conclusions: A consistent-conjectures equilibrium exists in the private provision of public goods. It is the monopolistic-conjectures equilibrium. Agents act identically, contributing positive amounts of the public good in an efficient allocation of resources. There is complete matching of contributions among agents, no free-riding, and the allocation is independent of the number of members within the community. Thus the Olson conjecture—that inefficiency is exacerbated by community size—has no foundation in a consistent-conjectures, cumulative-externality, context (212 words) ...|$|R
40|$|Abstract—Evaluation metric is an {{essential}} and integral part of a ranking system. In the past several evaluation metrics have been proposed in information retrieval and Web search, among them Discounted Cumulative Gain (DCG) has emerged as one that is widely adopted for evaluating the performance of ranking functions used in Web search. However, {{the two sets of}} parameters, the gain values and discount factors, used in DCG are usually determined in a rather ad-hoc way, and their impacts have not been carefully analyzed. In this paper we first show that DCG is generally not coherent, i. e., comparing the performance of ranking functions using DCG very much depends on the particular gain values and discount factors used. We then propose a novel methodology that can learn the gain values and discount factors from user preferences over rankings, modeled as a special case of learning linear utility functions. We also discuss how to extend our methods to handle tied preference pairs and how to explore active learning to reduce preference labeling. Numerical simulations illustrate the effectiveness of our proposed methods. Moreover, experiments are also conducted over a side-by-side comparison data set from a commercial search engine to validate the proposed methods on real-world data. Index Terms—Discounted <b>cumulative</b> gains, <b>evaluation</b> metric, utility function, user preference, machine learning...|$|R
40|$|Abstract. The {{prevalence}} of Helicobacter pylori (H. pylori) {{was investigated in}} 164 consecutive patients with different degrees of renal function; group I (normal renal function) n = 84, group II (chronic renal failure, CLCR> 5 < 90 ml/min) « = 45, group III (haemodialysis therapy) « = 35, {{to test the hypothesis}} that the resulting different concentrations of urea in the gastric juice would have an influence on the coloniz-ation of the gastric mucosa by these urea-splitting bacteria. As every individual method for the detection of H. pylori shows disadvantages, the results of the detection methods used (urease test, Warthin-Starry stain, bacterial cultivation, direct examination of the processed sample by phase-contrast microscopy) were combined in a <b>cumulative</b> <b>evaluation.</b> These calculated cumulative indices for the antrum and corpus showed no statistically significant differences between the studied groups. The {{prevalence of}} H. pylori ranged from 34 to 54 %. The histopathological findings were similar in all groups. In {{spite of the fact that}} patients with renal dysfunction had significantly higher levels of serum gastrin (P< 0. 05), there was no influence on the gastric juice pH value. The relationship between the cumulative index and ammonia concentration in gastric juice was found to be linear (P< 0. 05). The higher urea levels in the blood and gastric juice of patients with renal failure do not seem to be a risk factor for infection with H. pylori. Key words: gastric juice; gastritis; Gastrospirillum hom-inis; Helicobacter pylori; renal failur...|$|E
40|$|The {{last decade}} is {{characterized}} by the trend of higher prices of non ferrous and precious metals on world markets. Copper, gold and silver are centuries old knows products of mining in Bor. By long years of copper production and procesing have been created flotation tailing dumps. Tailing dumps contain a significant share of metals and can be exploited to evaluate the useful materials. Economic consideration are based on projection the annual evaluation of copper Ostrelj waste dumps and the old flotation tailing dumps for the next ten years in consideration of cost-effectiveness framework to the total production capacity of about 3040 t of cathode copper on the basis of technical and technological research. Preliminary economic consideration showed highly positive results of the success and profitability through profit or loss account, economic cash flow, cost price and so on. Economic analysis and possibility of investement return basis on data for technical possibility to production annual sum of 3040 tone copper cathode. <b>Cumulative</b> <b>evaluation</b> of economic analysis shows: period of project: 10 years,investments in fixed assets 13. 495. 000 USD, average net profit 4. 000. 000 USD, average product price 2884, 2 USD per tone copper cathode, Payable of Investments:Internal rate of return 53, 7 %, Pay back period 2 years,Net present value (10 %) 24. 670. 000 USD. Specify data according to technical elements, shows that starting economic analysis gives very good results. Key words: economic consideration, copper, flotation tailing dumps, 1...|$|E
40|$|Abstract. We {{consider}} multisplitting of {{numerical value}} ranges, {{a task that}} is encountered as a discretization step preceding induction and also embedded into learning algorithms. We are interested in finding the partition that optimizes {{the value of a}} given attribute evaluation function. For most commonly used evaluation functions this task takes quadratic time in the number of potential cut points in the numerical range. Hence, it is a potential bottleneck in data mining algorithms. We present two techniques that speed up the optimal multisplitting task. The first one aims at discarding cut point candidates in a quick linear-time preprocessing scan before embarking on the actual search. We generalize the definition of boundary points by Fayyad and Irani to allow us to merge adjacent example blocks that have the same relative class distribution. We prove for several commonly used evaluation functions that this processing removes only suboptimal cut points. Hence, the algorithm does not lose optimality. Our second technique tackles the quadratic-time dynamic programming algorithm, which is the best schema for optimizing many well-known evaluation functions. We present a technique that dynamically—i. e., during the search—prunes partitions of prefixes of the sorted data from the search space of the algorithm. The method works for all convex and <b>cumulative</b> <b>evaluation</b> functions. Together the use of these two techniques speeds up the multisplitting process considerably. Compared to the baseline dynamic programming algorithm the speed-up is around 50 percent on the average and up to 90 percent in some cases. We conclude that optimal multisplitting is fully feasible on all benchmark data sets we have encountered...|$|E
40|$|The {{benefits}} of marine ecosystems for people {{are increasingly being}} characterized through the concept of ecosystem services, with the promise to aid decision making from marine spatial planning to ecosystem-based management. The characterization of changes in marine ecosystem services {{is central to the}} application of ecological science to policy contexts, and this field is quickly evolving with innovations in frameworks for integrating science, understanding of ecosystems and human benefits, and innovations in tools for the modeling of services. In this article, we review efforts to characterize changes in marine ecosystem services, including recent advances, and we propose five key future directions for research: cultural values, qualitative or semi-quantitative modeling approaches, <b>cumulative</b> impacts, model <b>evaluation,</b> and markets. Introduction and context What are marine ecosystem services? Ecosystem services – the processes whereby ecosystems render benefits to people [1] – are becoming the principal means for communicating ecological chang...|$|R
40|$|This article {{extends the}} work by Armstrong and Shi on CUmulative SUM (CUSUM) person-fit methodology. The authors present new {{theoretical}} considerations concerning {{the use of}} CUSUM person-fit statistics based on likelihood ratios {{for the purpose of}} detecting cheating and random guessing by individual test takers. According to the Neyman–Pearson Lemma, the optimality of such statistics relies on how accurately normal and aberrant behaviors are mod-eled. General and specific models for cheating and random guessing are investigated. The detec-tion rates of several statistics are compared using simulated data. Results showed that the likelihood-based CUSUM statistics that use the proposed models for aberrant behavior per-formed better than some of the more commonly used statistics, especially for cheating behavior. Keywords item response theory model, cheating, random guessing, aberrant behavior detection, likelihood ratio, <b>cumulative</b> sum The <b>evaluation</b> of individual test score validity is important in education and achievement test-ing. For example, a frequently encountered problem is the inflation of test scores due to pre...|$|R
40|$|This {{research}} {{focuses on}} how consumers perceive the quality level of a complex stimulus (in our case, a service encounter) and how this perception affects consumers' overall assessment of the quality level of the firm. As such, it should {{be of interest to}} consumer behavior theorists as well as to those involved in marketing management issues. We start our presentation by developing a normative Bayesian data integration and updating model somewhat similar to that put forth by Rust et al. (1999). The major constructs of interest in this model are the person's belief about the overall service quality level of a firm and what will happen on the next service encounter. Two major results following from this baseline normative model are that the updated means of these two beliefs are identical to the dynamic updating equations put forth by Boulding et al. (1993), and that an underlying assumption of this model is that consumers form unbiased perceptions of the complex stimulus. Next, based on substantial empirical evidence from the behavioral literature, we incorporate into this baseline model a process by which consumers form nonrandom perceptions. Specifically, we postulate that a person's perception of a complex service encounter is a blend of the objective dimensions of the service encounter and the person's prior overall belief about the quality level of the firm. The relative weights placed on these two factors are determined at least in part by the experience level of the customer and the complexity of the service encounter. We then use this expanded model to compare and test different models of service quality and provide deeper insights into the process by which consumers form perceptions of both the service transaction and the overall service quality level of a firm. We test this model using data from two different experiments. In each experiment we manipulate the service provided and the person's initial and. Using both obtrusive and unobtrusive measures of the underlying constructs of our model, we employ multiple tests to determine the veracity of our expanded model relative to the baseline model. These tests support the expanded model specification. As found previously, and as predicted by a Bayesian updating process, consumers' prior beliefs influence their cumulative overall opinion of service quality (e. g., Anderson and Sullivan 1993, Bolton and Drew 1991, Boulding et al. 1993, Rust et al. 1999). Perhaps more importantly, these prior beliefs also influence their perceptions of the data themselves, which in turn affect their new (updated) overall opinion. These two different influences of prior beliefs on <b>cumulative</b> <b>evaluations</b> of quality constitute the “double whammy” referred to in the title. This double whammy effect has major managerial significance. Specifically, we see from our model development that all activities of a firm will be perceived in light of a person's prior beliefs and that these priors will be double counted relative to our baseline model. Thus, any marketing action taken by a firm will be perceived more positively or negatively depending on the person's prior belief about the quality level of the firm. As such, our model provides a formal explanation for the notion of brand equity as “differential leverage” in marketing activities as proposed by Keller (1993). Service Quality, Bayesian Updating, Consumer Behavior, Confirmatory Bias, Brand Equity...|$|R
