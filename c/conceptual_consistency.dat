44|22|Public
40|$|This paper {{addresses}} {{the issue of}} the legitimacy of judicial review from a methodological perspective. It argues that unpredictability of approach is a very serious and dangerous form of judicial activism. It analyses an ambivalent judicial attitude to facts, and the confusion that exists between rules and provisions on the one hand, and interpretation and remedies on the other. It pleads in favour of greater <b>conceptual</b> <b>consistency</b> in the way the Supreme Court of Canada handles methodological issues...|$|E
40|$|This article {{examines}} the doctrine of implied indemnity {{in light of the}} recent decision of the Supreme Court of Florida in Houdaille Industries, Inc. v. Edwards. The authors discuss the meaning of 2 ̆ 2 fault 2 ̆ 2 and 2 ̆ 2 no fault 2 ̆ 2 in terms of the mechanisms of accident law, develop three models for allocating accident losses, and evaluate the change in accident law introduced in Houdaille, concluding that the court achieved <b>conceptual</b> <b>consistency</b> at the expense of equity...|$|E
40|$|The rapid {{evolution}} {{of information technology}} {{over the past several}} decades has opened many new and unique modes of communication. Clearly, the web is one such technology. However, it is quite possible that a fascination with the technology per se can hinder participants from one of its main functions— effective communication. The following essay explores a return to the basics of designing an effective web-based communication strategy. The key components of this strategy are: 1) consistent look and feel, 2) <b>conceptual</b> <b>consistency,</b> and 3) positive attention...|$|E
40|$|Real-world {{changes are}} {{generally}} discovered delayed by computer systems. The typical update patterns for traditional data warehouses on an overnight or even weekly basis enlarge this propagation delay until {{the information is}} available to knowledge workers. The main contribution of {{the paper is the}} identification of two different temporal characterizations of the information appearing in a data warehouse: one is the classical description of the time instant when a given fact occurred, the other represents the instant when the information has been entered into the system. We present an approach for modeling <b>conceptual</b> time <b>consistency</b> problems and introduce a data model that deals with timely delays and supports knowledge workers to determine what the situation was in the past, knowing only the information available at a given instant of time. ...|$|R
40|$|Paper session : Virtual Reality, Virtual Materiality, Virtual Instrumentality - Proceedings of {{the conference}} {{available}} online only - [URL] audienceIn this paper we study the question of interaction with digital technologies by exploring the cognitive mechanisms of embodiment {{in the context of}} multisensory artistic installations. In order to test our hypothesis we observed the visits of an experimental installation which provides <b>conceptual</b> and technological <b>consistency.</b> Our first observations suggest that these conditions result in a strong embodiment for the proposed interactions...|$|R
40|$|Abstract. Using {{graphical}} description {{techniques for}} formal system develop-ment {{has become a}} common approach in many tools. Often multiple description techniques are used to represent different views of the same system, only to-gether forming a complete specification. Here, {{the question of the}} integration of those description techniques and views becomes a major issue, raising ques-tions of consistency and completeness. In this paper, we present an approach to ensuring <b>conceptual</b> and semantic <b>consistency,</b> influenced by experience gained from a first implementation of the AUTOFOCUS tool prototype. Finally, we show how this approach forms the basis for the definition of specification modules. ...|$|R
40|$|According to {{prevailing}} methodological criteria, standard {{economics is}} definitively refuted. Joan Robinson’s wake-up call “Scrap {{the lot and}} start again” has therefore lost nothing of its original freshness and urgency. Yet, how can the restart succeed? This inquiry builds on structural axioms. First, <b>conceptual</b> <b>consistency</b> is assured and the confusion about profit and income is dissolved. The question of interest is then how a recession or depression develops {{as the result of}} the normal functioning of the monetary economy. This involves the identification of positive feedback. A very effective mechanism consists of the circular interaction of profit and distributed profit. ...|$|E
40|$|This work {{intends to}} {{describe}} the theoretical-conceptual design of an investigation whose main aim is to analyse and interpret an ongoing process of reconstruction of a teacher education curricular project (1 st to the 4 th grade teaching) {{as well as its}} bases. We use several theoretical frameworks that form three dimensions of analysis: curricular, organisational and personal / interpersonal. We are seeking to identify points and levels of intersection of these analysis dimensions, in search of a "pluralist" synthesis of several theoretical frameworks, that will provide <b>conceptual</b> <b>consistency</b> to the interpretations of the phenomenon under scrutiny...|$|E
40|$|There is a {{large and}} diverse body of {{empirical}} research on constitutional change and "new constitutionalism" in contemporary societies, yet a general theory of constitutional change is still lacking. Researchers interested in democratic constitutionalism are confronted with various competing assumptions and explanations regarding particular, often unrelated, cases. In order to facilitate cross-referencing and <b>conceptual</b> <b>consistency</b> {{in the study of}} new constitutionalism in Latin America, this chapter provides an overview of the main theoretical perspectives on constitutional change beyond the specific regional context of Latin America, classifies the existing studies on constitutional change, and discusses their individual advantages and shortcomings...|$|E
40|$|Abstract. Real-world {{changes are}} {{generally}} discovered delayed by computer systems. The typical update patterns for traditional data warehouses on an overnight or even weekly basis enlarge this propagation delay until {{the information is}} available to knowledge workers. Typically, traditional data warehouses focus on summarized data (at some level) rather than detail data. For active data warehouse environments, also detailed data about individual entities are required for checking the data conditions and triggering actions. Hence, keeping data current and consistent in that context {{is not an easy}} task. In this paper we present an approach for modeling <b>conceptual</b> time <b>consistency</b> problems and introduce a data model that deals with timely delays. It supports knowledge workers, to find out, why (or why not) an active system responded to a certain state of the data. Therefore the model enables analytical processing of detail data (enhanced by valid time) based on a knowledge state at a specified instant of time. All states that were not yet knowable to the system {{at that point in time}} are consistently ignored. 1...|$|R
40|$|To {{support the}} {{development}} of software products we frequently make use of general-purpose software development models (and tools) such as the Unified Modeling Language (UML). However, software development in general and software architecting in particular (which is {{the main focus of}} our work) require more than what those general-purpose models can provide. Architecting is about: 1) modeling the real problem adequately 2) solving the model problem and 3) interpreting the model solution in the real world In doing so, a major emphasis is placed on mismatch identification and reconciliation within and among architectural views (such as diagrams). We often find that this latter aspect, the analysis and interpretation of (architectural) descriptions, is under-emphasized in most general-purpose languages. We architect not only because we want to build (compose) but also because we want to understand. Thus, architecting {{has a lot to do}} with analyzing and verifying the <b>conceptual</b> integrity, <b>consistency,</b> and completeness of the product model. The emergence of the Unified Modeling Language (UML), which has become a de-facto standar...|$|R
30|$|In addition, {{the impact}} of {{government}} policy documents on this domain was very minimal. This is not surprising since none of the documents outlined specific pedagogy for smart learning. The only smart pedagogy concept included in the government acronym was related to resource-enriched content, which is often considered as another independent element of smart learning rather than part of smart pedagogy (Liu et al. 2017). Therefore, {{it is fair to}} conclude that Korean scholars’ discussion on smart pedagogy proceeded on its own; rich <b>conceptual</b> exploration and <b>consistency</b> as well as discoursal robustness--as evidenced in the steady number of keywords remaining strong in later years--characterize this domain of the smart learning discourse.|$|R
30|$|Overall, Korean scholars’ {{discourse}} on smart learning environments showed both conceptual diversity {{and a clear}} saturation process from 2010 to 2018. Their discourse included {{a wide variety of}} technology requirements and system features necessary for smart learning. Figure  5 a, showing the eleven keywords’ lifespan testifies to the long-lasting discoursal dynamics and <b>conceptual</b> <b>consistency</b> in the smart learning environment discourse. Most importantly, the discussion on smart learning environments exhibited conceptual convergence towards 2016 as evidenced in the saturated list of key-terms repeatedly appearing in publications. Starting from 2014, most scholars defined smart learning environments using following five keywords: smart technology, adaptive/customized, intelligent, real-time/ubiquitous, technology-embedded, and social networks.|$|E
40|$|Nowadays, {{information}} {{is one of}} the main resources for an individual’s development and well-being, so distributing and using information must be a top priority for society. This entails establishing strategies so people can learn to use this resource. Further, scientific progress and present-day educational paradigms stress trans-disciplinary learning. Information and communication sciences are by nature complementary –one focusing on the medium and the other on the process– so there must be greater clarity and <b>conceptual</b> <b>consistency</b> in a number of key shared areas. This -contribution is an effort, from the perspective of library science and information science, to identify some possible meeting-points between these disciplines, regardin...|$|E
40|$|In this {{presentation}} I shall {{explore the}} question of whether or not it is defensible to grant legal group rights through international instruments and national legal systems. I shall proceed in the following way. First, I shall briefly examine the <b>conceptual</b> <b>consistency</b> between group rights and the framework of rights discourse, and I shall conclude that it is conceptually possible to include group rights in ordinary rights talk. Secondly, I shall explore what the basic requirements would be for the recognition of a group right. I shall suggest that the use of rights discourse bears a number of conceptual as well as normative constraints that carry important practical consequences, and that these constraints must be understood as conditions of admissibility for any group right...|$|E
40|$|By {{referring}} to language-pragmatic versions of action theory, I attempt {{in this paper}} to introduce a perspective which overcomes a series of modernistic legacies of earlier action theories in human geography. Such a development allows a nonessentialist stance while preserving the <b>conceptual</b> richness and <b>consistency</b> of action theory. The concept of speech acts will {{be interpreted as a}} blueprint for the analysis of interactions in general [...] not only human communications but also those involving nonhuman entities and physical conditions [...] and is a perspective that is particularly attractive for human geography. However, one of the consequences is that the notion of space and its role for the identity of the discipline need to be reconsidered. ...|$|R
40|$|In recent years, the {{literature}} {{in the area of}} Bayesian asymptotics has been rapidly growing. It is increasingly important to understand the concept of posterior consistency and validate specific Bayesian methods, in terms of consistency of posterior distributions. In this paper, we build up some <b>conceptual</b> issues in <b>consistency</b> of posterior distributions, and discuss panoramic views of them by comparing various approaches to posterior consistency that have been investigated in {{the literature}}. In addition, we provide interesting results on posterior consistency that deal with non-exponential consistency, improper priors and non i. i. d. (independent but not identically distributed) observations. We describe a few examples for illustrative purposes. Comment: Published in at [URL] the IMS Collections ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
40|$|In this article, {{we present}} a {{validation}} approach and method to support the development of database applications. We explain how validation can cope both {{with the need for}} a formalized evaluation of correctness as well as the need for prototyping of conceptual database schemata. We define different levels of correctness for such schemata and show how these levels can be achieved through validation methods. Furthermore, we describe how our validation framework can be applied to other <b>conceptual</b> specifications. Keywords: <b>consistency,</b> correctness, database application, database schema, database specification, extended ER model, test data, validation 1 Introduction One of the main questions for the development of database specifications is: How can we ensure that our specification is correct and reflects the desired portion of reality? In times of increasingly complex specifications of database applications, we need well-structured approaches to handle this complexity and guarantee qua [...] ...|$|R
40|$|Formal {{methods are}} {{necessary}} in achieving correct software: that is, software {{that can be}} proven to fulfil its requirements. Formal specifications are unambiguous and analysable. Building a formal model improves understanding. The modelling of nondeterminism, and its subsequent removal in formal steps, allows design and implementation decisions to be made when most suitable. Formal models are amenable to mathematical manipulation and reasoning, and facilitate rigorous testing procedures. However, formal methods are not widely used in software development. In most cases, this {{is because they are}} not suitably supported with development tools. Further, many software developers do not recognise the need for rigour. Object oriented techniques are successful in the production of large, complex software systems. The methods are based on simple mathematical models of abstraction and classification. Further, the object oriented approach offers a <b>conceptual</b> <b>consistency</b> across all stages of soft [...] ...|$|E
40|$|In {{this article}} we apply a method of proof for <b>conceptual</b> <b>consistency</b> in a long {{historical}} range taking the example of rhetoric and persuasion. We analyze the evidentially present linguistic features of this concept within three linguistic areas: the Indo-European languages, the Semitic languages, and the Afro-Asiatic languages. We have chosen {{the case of the}} concept ‘rhetoric’ / ’persuasion’ as paradigm for this study. With the phenomenon of ‘linguistic dispersion’ we can explain the development of language as undirected, but with linguistic consistency across the borders of language families. We proof that the Semitic and Indo-European languages are related. As a consequence, the strict differentiation between the Semitic and the Indo-European language families is outdated following the research positions of Starostin. In contrast to this, we propose a theory of cultural exchange between the two language families...|$|E
40|$|In {{this article}} we will apply a method of proof for <b>conceptual</b> <b>consistency</b> in a long {{historical}} range taking the example of rhetoric and persuasion. We will analyze the evidentially present linguistic features of this concept within three linguistic areas: The Indo-European languages, the Semitic languages, and the Afro-Asiatic languages. We have chosen {{the case of the}} concept ‘rhetoric’ / ’persuasion’ as a paradigm for this study. With the phenomenon of ‘linguistic dispersion’ we can explain the development of language as undirected, but with linguistic consistency across the borders of language families. We will prove that the Semitic and Indo-European languages are related. As a consequence, the strict differentiation between the Semitic and the Indo-European language families is outdated following the research positions of Starostin. In contrast to this, we will propose a theory of cultural exchange between the two language families...|$|E
40|$|Using {{graphical}} description {{techniques for}} formal system development {{has become a}} common approach in many tools. Often multiple description techniques are used to represent different views of the same system, only together forming a complete specification. Here, {{the question of the}} integration of those description techniques and views becomes a major issue, raising questions of consistency and completeness. In this paper, we present an approach to ensuring <b>conceptual</b> and semantic <b>consistency,</b> influenced by experience gained from a first implementation of the AUTOFOCUS tool prototype. Finally, we show how this approach forms the basis for the definition of specification modules. 1 Introduction Using multiple description techniques has become a common approach for the toolbased system development. Prominent examples are SDL-based tools (e. g., ObjectGeode [19], SDT [18]) and automata-based approaches (e. g., ObjecTime [17]). Here, the specification of a system is spread out ove [...] ...|$|R
40|$|The {{performance}} {{capabilities of}} virtually shared memory (Vsm) systems still fail to seriously refute {{the impression that}} Vsm {{seems to be a}} luxury, which provides conceptual simplicity at the expense of performance. This paper is based on the Vote Vsm system running on top of a crossbar [...] based parallel computer system. Vote's design is a two layer approach, providing conceptual simplicity by means of sequential consistency at default and, moreover, providing a framework of functions to allow performance enhancements. This enables the programmer to use a customized programming style addressing any combination of sequential <b>consistency's</b> <b>conceptual</b> simplicity and the maximum performance achieved through message passing. To validate the approach we discuss the performance overheads present on the Vote system and show {{that it is possible to}} develop analytical performance models. Such models are able to predict the execution time for a generic number of processors and for different architect [...] ...|$|R
40|$|Este Documento es producto del trabajo de Académicos del Departamento de AdministraciónResearch on risk {{is built}} on a complex array of diverse and {{sometimes}} inconsistent definitions, constructs, models, and outcomes. This study examines various literatures to formulate an integrated framework for the conceptualization of perceived-risk processing. The framework specifies three phases (framing, assessment, and evaluation) and their accompanying outcomes of risk attention, perceived risk, and risk-taking propensity. Explicit linkages are specified between situational and individual characteristics. Perceived-risk evaluation is identified as conceptually distinct from assessment of perceived risk, and the construct of risk-taking propensity is separated from those of risk affinity and perceived risk. The framework further presents points of intersection between the literatures on perceived risk and the literatures on consumer decision-making, information search, and satisfaction. Finally, it serves as an anchor for framing future research to promote <b>conceptual</b> and methodological <b>consistency,</b> and to guide progress in directions {{that are consistent with}} some leading edge paradigms outside of marketing...|$|R
40|$|We review 34 {{quantitative}} {{studies that}} have measured individuallevel variations in ethnobotanical knowledge, analyzing how those studies have conceptualized and operationalized ethnobotanical knowledge. We found {{that this type of}} research is recent but growing, and is concentrated in indigenous peoples of developing countries. We also found that studies differ on how they conceptualize and measure individual ethnobotanical knowledge. As it is the case in other interdisciplinary research, the lack of <b>conceptual</b> <b>consistency</b> and comparable data limit the inferences that can be drawn from empirical analyses of ethnobotanical knowledge. Future research should 1) validate the consistency of measures of individual ethnobotanical knowledge; 2) analyze the reliability of data generated by the different methods developed so far; and 3) address the relationship between the various dimensions of ethnobotanical knowledge. Studies of individual ethnobotanical knowledge have the potential to contribute to a systematic understanding of humanity’s most widespread and ancient form of knowledge...|$|E
40|$|Object-oriented {{programming}} {{is presented as}} a paradigm for developing interactive systems for computer animation. Object types, evolved conceptually from graphics turtles, are implemented to provide the animator with familiar metaphors for the specification of motion in three-dimensional space. The intention is to create objects that can represent actors, cameras, and decor that the user can direct and animate in a relatively intuitive manner. Vector and turtle objects support the actors, which respond to messages to orient, accelerate and draw themselves on the screen. The MacApp object libraries are used to implement the standard Macintosh user interface and a unit is developed which implements vectors, actors and three-dimensional graphics turtles as obects. The object-oriented approach encourages a <b>conceptual</b> <b>consistency</b> in the external and internal interfaces and is intended to facilitate the development of extensible characters and tools through the cooperative efforts of animators and programmers...|$|E
40|$|Modern {{groupware}} {{allows us}} to work together, while bridging differences in space and time. However, there exists no standard to design groupware, which {{has resulted in a}} lack of <b>conceptual</b> <b>consistency</b> and interoperability. Additionally, current groupware design methodologies typically focus on implementation details. In contrast, we consider the service a groupware application provides {{to be the most important}} aspect of the system. Dynamic Groupware Services provides a structuring of groupware services. This structuring allows co-operating end users to select and compose groupware modules in order to form groupware services that match their needs. At the same time, this structuring helps designers design tailorable groupware services. Two important results of this structuring are a description of the elementary units of groupware behaviour and a description of the units to compose groupware services. The latter units, as well as the relations between them, are defined in a reference model for tailorable groupware services...|$|E
40|$|We {{compare the}} {{distributional}} effects of austerity measures {{that have been}} introduced in 6 EU countries {{in the period of}} large government budget deficits following the 2007 - 8 financial crisis and subsequent economic downturn. We explore the effects of policy changes presented as â€œausterity measuresâ€ in Estonia, Ireland, Greece, Spain, Portugal and the UK, using the EU microsimulation model EUROMOD and the Irish national model, SWITCH. The six countries have chosen different policy mixes to achieve varying degrees of fiscal consolidation. We focus on the first round effects of increases in personal taxes, cuts in spending on cash benefits and reductions in public sector pay across the distributions of household income. There is a range of important <b>conceptual</b> and <b>consistency</b> issues to be addressed when doing such analysis, particularly in a comparative setting. These include how to identify â€œausterity measuresâ€ in a consistent manner, the relevant time periods to consider, the assumptions behind the counterfactual scenarios and the scope of the policies considered. Using a set of common assumptions we find that the burden of fiscal consolidation brought about through changes in components of household disposable income is shared differently across the income distribution in the six countries. At one extreme, in Greece, the better off lose a higher proportion of their incomes than the poor and at the other, in Portugal, the poor lose a higher proportion than the rich. Bringing increases in indirect taxes into the picture can alter conclusions about the overall distributional effect, increasing the cost most for those with lower income and making the overall incidence of the measures more regressive. ...|$|R
40|$|The {{quality of}} spatial data has always {{represented}} {{a significant problem}} in geomatics. This problem is becoming ever more pressing with the expansion of spatial information services on the Internet and with the increasing availability of spatial data and their use for various applications on many fields. To objectively evaluate the quality of spatial data, clearly defined methods or procedures should exist and be applied consistently. Spatial data quality standards provide only general guidelines and methodologies for evaluating quality, while the standardization of specific methods is still being studied. The thesis starts with presenting the importance of spatial data quality {{and the importance of}} user awareness on spatial data quality. Afterwards the concept of internal and external quality and the criteria for describing spatial data quality are explained. Some of the important standards in the field are presented briefly. The main section describes several methods for automated evaluation of individual quality criteria, with emphasis on methods and algorithms for evaluating the <b>conceptual</b> and topological <b>consistency.</b> The final section provides an example of automated quality evaluation on the digital cadastral plan of Slovenia. ...|$|R
40|$|Transportation-related {{decisions}} of people often {{depend on what}} everybody else is doing. For example, decisions about mode choice, route choice, activity scheduling, etc., can depend on congestion, caused by the aggregated behavior of others. From a <b>conceptual</b> viewpoint, this <b>consistency</b> problem causes a deadlock, since nobody can start planning {{because they do not}} know what everybody else is doing. It is the process of iterations that is examined in this paper as a method for solving the problem. In this paper, the authors concentrate on the aspect of the iterative process that is probably the most important one from a practical viewpoint, and that is the ``uniqueness`` or ``robustness`` of the results. Also, they define robustness more in terms of common sense than in terms of a mathematical formalism. For this, they do not only want a single iterative process to converge, but they want the result to be independent of any particular implementation. The authors run many computational experiments, sometimes with variations of the same code, sometimes with totally different code, in order to see if any of the results are robust against these changes...|$|R
40|$|The {{supply chain}} {{literature}} still largely focuses on asset, alphanumeric {{data and information}} (in the form of documents and files) elements of exchange between supply chain partners, {{despite the fact that}} increased integration and collaboration clearly require development of more complex elements of expertise and knowledge. In this respect, this paper recognizes the knowledge management (KM) literature as a potential source of new insights to add conceptual depth and understanding to managing 21 st century supply chains. Specific KM theories and constructs are identified as potentially contributing to theory and practice in supply chain contexts. An overall framework for supply chain knowledge management is developed, along with literature-based definitions of supply chain knowledge transfer, competence and maturity constructs. The "knowledge lens" theory building approach is applied to import these perspectives into supply chain domains, with efforts to maintain <b>conceptual</b> <b>consistency</b> across the two literature streams. Knowledge Management; Supply Chains; Conceptual Framework;...|$|E
40|$|A growing {{literature}} in public policy, comparative politics and international relations has studied how {{the policies of}} one unit (e. g. country, federal state or city) {{are influenced by the}} policies of other units – that is, how policies diffuse. This article provides a meta-analysis of 114 studies, demonstrating persisting inconsistencies in the measurement of the mechanisms driving policy diffusion processes. Different indicators are used to measure the same mechanism, and the same indicators are used to measure different mechanisms. To improve this state of affairs, this article puts forward a conceptual structure that serves as a guide for the application of diffusion arguments, a starting point for theoretical refinement and a benchmark to assess measurement validity. In addition to paying more attention to the <b>conceptual</b> <b>consistency</b> of indicators, overcoming the problems currently found in the literature requires the construction of original, innovative research designs instead of the replication of widely used templates...|$|E
40|$|Words with {{mathematical}} meanings may be {{used differently}} in different dialects of a language. These may be false friends, sounding alike, but with different meanings or scope of usage. In Australia, many Indigenous children speak Aboriginal English but are taught in Standard Australian English. A study into spatial language in a remote Indigenous community in northern Australia has revealed that children of Iwaidja speaking parents use English spatial terms in ways that more closely resemble the spatial language of their parents than Standard Australian English usage. The words have closely related meanings in the different dialects of English but have different domains of applicability in terms of spatial frames of reference. To support student learning of Standard Australian English and of the mathematics register, teachers may need to appreciate how their students’ <b>conceptual</b> <b>consistency</b> differs from their own. Spatial frames of reference in Iwaidja (Australian Institute of Aboriginal and Torres Strait Islander Studies...|$|E
40|$|The article {{discusses}} {{the contribution of}} archival principles to the definition and implementation of a common methodology for digital heritage curation and protection, and identifies general implications both for the archival science itself and for a meta-science perspective. This theoretical approach has been successfully developed by the international archival community in {{the last fifteen years}} and its outputs have been able to support other disciplines and research projects dedicated to the curation and preservation of digital heritage by strengthening their <b>conceptual</b> frameworks and <b>consistency.</b> More comprehensive research is required in the future to clarify and reinforce the suggestions proposed here, but the experiences of many international projects in this sector – specifically those characterized by large and collaborative research and a cross-disciplinary approach, such as DELOS, ERPANET, InterPARES, CASPAR and APARSEN – can confirm this preliminary analysis. They can also provide basic elements for better exploring the positive role of activities such as integration and cooperation as opposed to ambiguous concepts like convergence. In order to provide support for these suggestions, the article uses the archival concept of evidence of authenticity {{as an example of how}} it has been incorporated into international research outputs in the digital preservation fiel...|$|R
40|$|A genera I, {{though not}} un i que pro-blem in {{simulated}} personal space {{research is the}} Iack of conceptua I operational consistency. I n a re-view of more than fifty studies, marked di screpancies were found in three vital areas: 1) the con-ceptual definition of personal space; 2) the operational proce-dures, {{in the form of}} instruction-al sets; and 3) the instrumenta-t i on used in such resea rch • To determine whether these differen-ces in concept, operation, and in-strumentation affected resu I ts, two experiments were analyzed. One is a replication of the figure place-ment task, common to simulated research. The other is a role en-actment simulation with face to face encounter of subject and the same sex experi. menter. The re-sults indicate that differences in operation and instrumentation do account for much of the differen-ces in research ou tcomes. The varied methodological ap-proaches emp loyed for research in personal space can be divided in-to ethological and laboratory pro-cedures. Most of the laboratory procedures apply simulated person-al space with the figure place-ment task. This task requires the subject to p lace two si I houettes on a background in a given spa-cial arrangement. The measured distance between the two figures presumably indicates the require-ment for personal space, but the fi ndi ngs are often inconsistent. In simulated research, a number of methodological inconsistencies con-found the results. 1) There is considerable variation in the con-ceptual definition of personal space. 2) The instructional sets vary across studies, and thus de-p ict d i fferi ng spa ti a I zones. 3) There is a lack qf <b>conceptual</b> operational <b>consistency.</b> 4) The physical instrument and figure dimensions vary greatly across studi es. To resolve this issue, we must summarize the differences in con-ceptual definitions and the differ-ences in laboratory procedures in simulated personal space re-search. Then we shall show that differences in outcomes can be at-tributed, at least in part, to var-iation in laboratory procedure in research on simulated interperson-al space, and to differences in di stance imp I ici tin the defi nit ion-al concept of personal space, as ref Iec tedin the ins t r u c t i on s...|$|R
40|$|University of Minnesota Ph. D. dissertation. October 2011. Major:Psychology. Advisor: Dr. Jo-Ida Hansen. 1 {{computer}} file (PDF); x, 127 pages, appendix A. The study of career decision-making (CDM) has generated {{a number of}} constructs and assessment tools that have served to inform and facilitate the delivery of effective interventions. With the intention of promoting greater <b>conceptual</b> clarity and <b>consistency,</b> the construct CDM competence is proposed and defined here as success in completing CDM tasks typically required of individuals during certain developmental periods and within a specific sociocultural context. Toward the central goal of developing a valid measurement model of CDM competence, this study first used EFA to explore the structure of CDM competence to guide the formulation of a measurement model and then tested the CDM model in relation to latent constructs of social and general competence with structural equation modeling (SEM). For female (n= 228), male (n = 143), and entire (n = 371) samples, the EFA resulted in the retention of two factors that were interpreted as a general CDM competence factor and a distress and inadequacy of information factor. Comparison of separate EFA results for females and males suggested the variable of self-exploration may play {{a greater role in}} the structure of CDM competence for females than males. From the SEM, fit indices suggested that the data poorly fit the models with scales representing CDM, interpersonal and general competence latent factors for the female, male, and total samples...|$|R
