2722|10000|Public
5|$|Given an iid {{random sample}} {x1, …, x'n} of size n from a {{univariate}} distribution with the <b>cumulative</b> <b>distribution</b> <b>function</b> F(x;θ0), where θ0 ∈ Θ is an unknown parameter to be estimated, let {x(1), …, x(n)} be the corresponding ordered sample, {{that is the}} result of sorting of all observations from smallest to largest. For convenience also denote x(0) = −∞ and x(n+1) = +∞.|$|E
5|$|In statistics, maximum spacing {{estimation}} (MSE or MSP), or maximum {{product of}} spacing estimation (MPS), {{is a method}} for estimating the parameters of a univariate statistical model. The method requires maximization of the geometric mean of spacings in the data, which are {{the differences between the}} values of the <b>cumulative</b> <b>distribution</b> <b>function</b> at neighbouring data points.|$|E
5|$|The concept {{underlying}} {{the method is}} based on the probability integral transform, in that a set of independent random samples derived from any random variable should on average be uniformly distributed with respect to the <b>cumulative</b> <b>distribution</b> <b>function</b> of the random variable. The MPS method chooses the parameter values that make the observed data as uniform as possible, according to a specific quantitative measure of uniformity.|$|E
5000|$|... #Caption: <b>Cumulative</b> <b>distribution</b> <b>functions</b> are {{examples}} of càdlàg functions.|$|R
5000|$|... #Subtitle level 3: Upper Fréchet-Hoeffding {{bound for}} <b>cumulative</b> <b>distribution</b> <b>functions</b> ...|$|R
5000|$|No {{assumption}} of {{continuity of the}} <b>cumulative</b> <b>distribution</b> <b>functions</b> is needed.|$|R
5|$|There {{are certain}} distributions, {{especially}} those with three or more parameters, whose likelihoods may become infinite along certain paths in the parameter space. Using maximum likelihood to estimate these parameters often breaks down, with one parameter tending to the specific value that causes the likelihood to be infinite, rendering the other parameters inconsistent. The method of maximum spacings, however, being dependent on the difference between points on the <b>cumulative</b> <b>distribution</b> <b>function</b> and not individual likelihood points, does not have this issue, and will return valid results over a much wider array of distributions.|$|E
25|$|Some closed-form bounds for the <b>cumulative</b> <b>distribution</b> <b>function</b> {{are given}} below.|$|E
25|$|The <b>cumulative</b> <b>{{distribution}}</b> <b>function</b> of {{the normal}} distribution in mathematics and statistics.|$|E
30|$|Open {{image in}} new window are {{obtained}} from <b>cumulative</b> <b>distribution</b> <b>functions</b> (CDFs).|$|R
50|$|<b>Cumulative</b> <b>distribution</b> <b>functions</b> (cdfs) are {{denoted by}} upper case letters, e.g. F(x).|$|R
40|$|R Version This manual gives {{information}} about the STABLE library, which computes basic quantities for univariate stable distributions: densities, <b>cumulative</b> <b>distribution</b> <b>functions,</b> quantiles, and simulation. Statistical routines are given for fitting stable distributions to data and assessing the fit. Utility routines give {{information about}} the program and perform related calculations. Quick spline approximations of the basic functions are provided. Densities, <b>cumulative</b> <b>distribution</b> <b>functions</b> and simulation for discrete/quantized stable distributions are described. The multivariate module gives functions to compute bivariate stable densities, simulate stable random vectors, and fit bivariate stable data. In the radially symmetric case, the amplitude densities, <b>cumulative</b> <b>distribution</b> <b>functions,</b> quantiles are computed for dimension up to 100...|$|R
25|$|These {{follow from}} the {{definition}} of the Gamma distribution's <b>Cumulative</b> <b>distribution</b> <b>function.</b>|$|E
25|$|For {{information}} on its inverse <b>cumulative</b> <b>distribution</b> <b>function,</b> see quantile function#Student's t-distribution.|$|E
25|$|The last {{expression}} is the <b>cumulative</b> <b>distribution</b> <b>function</b> of an exponential distribution with rateα.|$|E
5000|$|... #Caption: Illustration of the {{difference}} in <b>cumulative</b> <b>distribution</b> <b>functions</b> alluded to in the theorem.|$|R
50|$|A third form of {{the density}} is {{obtained}} using its <b>cumulative</b> <b>distribution</b> <b>functions,</b> as follows.|$|R
50|$|We use <b>cumulative</b> <b>distribution</b> <b>functions</b> (cdf) {{in order}} to {{encompass}} both discrete and continuous distributions.|$|R
25|$|Continuous {{probability}} distributions can {{be described}} in several ways. The probability density function describes the infinitesimal probability of any given value, and the probability that the outcome lies in a given interval can be computed by integrating the probability density function over that interval. On the other hand, the <b>cumulative</b> <b>distribution</b> <b>function</b> describes the probability that the random variable is no larger than a given value; the probability that the outcome lies in a given interval can be computed by taking the difference between the values of the <b>cumulative</b> <b>distribution</b> <b>function</b> at the endpoints of the interval. The <b>cumulative</b> <b>distribution</b> <b>function</b> is the antiderivative of the probability density function provided that the latter function exists.|$|E
25|$|Here FX is the <b>cumulative</b> <b>distribution</b> <b>function</b> of X, and the {{integral}} {{is of the}} Riemann–Stieltjes kind. If random variable X has a probability density function fX, then the characteristic function is its Fourier transform with sign reversal in the complex exponential, and the last formula in parentheses is valid. QX(p) is the inverse <b>cumulative</b> <b>distribution</b> <b>function</b> of X also called the quantile function of X.|$|E
25|$|The {{definition}} {{states that}} a continuous probability distribution must possess a density, or equivalently, its <b>cumulative</b> <b>distribution</b> <b>function</b> be absolutely continuous. This requirement {{is stronger than}} simple continuity of the <b>cumulative</b> <b>distribution</b> <b>function,</b> {{and there is a}} special class of distributions, singular distributions, which are neither continuous nor discrete nor a mixture of those. An example is given by the Cantor distribution. Such singular distributions however are never encountered in practice.|$|E
5000|$|... #Caption: Example of two <b>cumulative</b> <b>distribution</b> <b>functions</b> F(x) and G(x) which {{satisfy the}} single-crossing condition.|$|R
5000|$|Let [...] be two <b>cumulative</b> <b>distribution</b> <b>functions.</b> Define the Lévy {{distance}} between them to be ...|$|R
2500|$|The <b>cumulative</b> <b>distribution</b> <b>functions</b> of the Poisson and chi-squared {{distributions}} {{are related}} {{in the following}} ways: ...|$|R
25|$|It {{is similar}} in shape to the {{log-normal}} distribution but has heavier tails. Unlike the log-normal, its <b>cumulative</b> <b>distribution</b> <b>function</b> can be written in closed form.|$|E
25|$|There {{are several}} {{different}} parameterizations {{of the distribution}} in use. The one shown here gives reasonably interpretable parameters and a simple form for the <b>cumulative</b> <b>distribution</b> <b>function.</b>|$|E
25|$|Any random {{variable}} {{can be described}} by its <b>cumulative</b> <b>distribution</b> <b>function,</b> which describes {{the probability that the}} {{random variable}} will be {{less than or equal to}} a certain value.|$|E
5000|$|Furthermore, let [...] {{denote the}} <b>cumulative</b> <b>distribution</b> <b>functions</b> of the [...] {{one-dimensional}} marginal distributions of , that means ...|$|R
5000|$|<b>Cumulative</b> <b>distribution</b> <b>functions</b> F and G {{satisfy the}} single-crossing {{condition}} if {{there exists a}} [...] such that ...|$|R
5000|$|Let [...] {{denote the}} <b>cumulative</b> <b>distribution</b> <b>functions</b> of the {{variables}} [...] Then by the central limit theorem, ...|$|R
25|$|Inverse {{transform}} sampling (also {{known as}} inversion sampling, the inverse probability integral transform, the inverse transformation method, Smirnov transform, golden rule) {{is a basic}} method for pseudo-random number sampling, i.e. for generating sample numbers at random from any probability distribution given its <b>cumulative</b> <b>distribution</b> <b>function.</b>|$|E
25|$|The uniform {{distribution}} {{is useful for}} sampling from arbitrary distributions. A general method is the inverse transform sampling method, which uses the <b>cumulative</b> <b>distribution</b> <b>function</b> (CDF) of the target random variable. This method is very useful in theoretical work. Since simulations using this method require inverting the CDF of the target variable, alternative methods have been devised for the cases where the cdf is not known in closed form. One such method is rejection sampling.|$|E
25|$|Not every {{function}} is the characteristic {{function of a}} legitimate probability distribution (that is, one whose <b>cumulative</b> <b>distribution</b> <b>function</b> is real and goes from 0 to 1 without decreasing), but the characteristic functions given above will be legitimate {{so long as the}} parameters are in their ranges. The value of the characteristic function at some value t is the complex conjugate of its value at −t as it should be so that the probability distribution function will be real.|$|E
5000|$|Law-Invariance: for all {{portfolios}} X and Y with <b>cumulative</b> <b>distribution</b> <b>functions</b> [...] and [...] respectively, if [...] then ...|$|R
3000|$|... 2 / 2) and Φ(.) {{being the}} density and <b>cumulative</b> <b>distribution</b> <b>functions,</b> respectively, of a {{standard}} normal random variable.|$|R
50|$|The {{first family}} of Mittag-Leffler {{distributions}} {{is defined by}} a relation between the Mittag-Leffler <b>function</b> and their <b>cumulative</b> <b>distribution</b> <b>functions.</b>|$|R
