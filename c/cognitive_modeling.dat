619|5652|Public
2500|$|Clancey, W.J, Sierhuis, M., Damer, B., Brodsky, B. 2005. [...] "Cognitive {{modeling}} of social behaviors". In R. Sun (Ed.), Cognition and Multi-Agent Interaction: From <b>Cognitive</b> <b>Modeling</b> to Social Simulation. New York: Cambridge University Press, pp.151–184.|$|E
5000|$|Human {{processor}} {{model or}} MHP (Model Human Processor) is a <b>cognitive</b> <b>modeling</b> method {{used to calculate}} {{how long it takes}} to perform a certain task. Other <b>cognitive</b> <b>modeling</b> methods include parallel design, GOMS, and KLM (human-computer interaction).|$|E
50|$|Modeling - Jonassen {{describes}} Modeling as {{the most}} commonly used instructional strategy in CLEs. Two types of modeling exist: behavioural modeling of the overt performance and <b>cognitive</b> <b>modeling</b> of the covert cognitive processes. Behavioural modeling in Constructivist Learning Environments demonstrates how to perform the activities identified in the activity structure. <b>Cognitive</b> <b>modeling</b> articulates the reasoning (reflection-in-action) that learners should use while engaged in the activities.|$|E
40|$|Our past {{work has}} {{investigated}} {{the use of}} the <b>Cognitive</b> <b>Model</b> Software Development Kit (SDK) for creating the <b>cognitive</b> <b>models</b> that underlie model-tracing Cognitive Tutors. Though successful at increasing {{the number of people who}} could author such a <b>cognitive</b> <b>model,</b> for certain kinds of situations the <b>Cognitive</b> <b>Model</b> SDK proved cumbersome. The present work discusses a new authoring system, xPST, that allows an example-based tutor to be built on top of existing software. 1 xPST-based tutors have been built for two real-world systems that had existing interfaces. Starting Point: The <b>Cognitive</b> <b>Model</b> SDK We have met with success at developing a SDK for <b>cognitive</b> <b>models</b> (Blessing & Gilbert, 2008). The <b>Cognitive</b> <b>Model</b> SDK allowed authors to develop th...|$|R
40|$|In this study, a {{framework}} {{to model the}} effects of stress on a process control operator is proposed. There exists many <b>cognitive</b> <b>models,</b> each of which attempts to model a specific class of human behaviour. One major effect of stress {{is the cause of}} errors, both physical and cognitive. In order to model the effects of stress, two <b>cognitive</b> <b>models,</b> a <b>cognitive</b> <b>model</b> of human errors and a <b>cognitive</b> <b>model</b> of process control operators are examined in detail. In this thesis, the basic functions of the human cognitive system, its organization and a <b>cognitive</b> <b>model</b> of error commission are first examined. The behaviour of a process control operator and a <b>cognitive</b> <b>model</b> of the behaviour of the operator are then discussed. The known effects of stress on the process control operator's behaviour are described and {{a framework}} for modelling the behaviour of process control operators under stress is proposed. The inadequacies associated with existing <b>cognitive</b> <b>models</b> for process control operators are explained and a modified <b>cognitive</b> <b>model</b> is proposed, which takes into account the <b>cognitive</b> <b>model</b> of error. Finally, an architecture design for the implementation of the <b>cognitive</b> <b>model</b> is provided and suggestions for the next step forward are proposed...|$|R
40|$|For the {{decision}} of a complex scientific problem of creation, system analysis and increase functioning efficiency of the automated training environment with adaptation properties based on <b>cognitive</b> <b>models</b> the new <b>cognitive</b> <b>modelling</b> technology is offered, it includes: technique of its use, algorithm of <b>cognitive</b> <b>models</b> formation, technique of <b>cognitive</b> <b>models</b> parameters research, algorithm of processing aposteriore data of testing, and also a complex of program...|$|R
50|$|R. Sun, Cognition and Multi-Agent Interaction: From <b>Cognitive</b> <b>Modeling</b> to Social Simulation. Cambridge University Press, New York. 2006.|$|E
50|$|In recent years, he {{attempted}} the {{difficult task of}} laying the theoretical and meta-theoretical foundation for computational <b>cognitive</b> <b>modeling</b> (or computational psychology).|$|E
5000|$|Rialle, V and Stip, E. <b>Cognitive</b> <b>modeling</b> in psychiatry: from {{symbolic}} {{models to}} parallel and distributed models J Psychiatry Neurosci. 1994 May; 19(3): 178-192.|$|E
50|$|<b>Cognitive</b> <b>model</b> {{development}} {{comprises the}} first stage in the test design process. During this stage, the cognitive knowledge, processes, and skills are identified and organized into an attribute hierarchy or <b>cognitive</b> <b>model.</b> This stage also encompasses validation of the <b>cognitive</b> <b>model</b> prior to the test development stage.|$|R
50|$|A <b>cognitive</b> <b>model</b> {{tries to}} model the domain {{knowledge}} {{in the same way}} knowledge is represented in the human mind. <b>Cognitive</b> <b>model</b> enables intelligent tutoring systems to respond to problem-solving situations as the learner would. A tutoring system adopting a <b>cognitive</b> <b>model</b> is called a cognitive tutor.|$|R
40|$|The {{purpose of}} this study was to {{evaluate}} the adequacy of three <b>cognitive</b> <b>models,</b> one developed by content experts and two generated from student verbal reports for explaining examinee performance on a Grade 3 diagnostic mathematics test. For this study, the items were developed to directly measure the attributes in the <b>cognitive</b> <b>model.</b> The performance of each <b>cognitive</b> <b>model</b> was evaluated by examining its fit to different data samples: verbal report, total, high-, moderate-, and low ability using the Hierarchy Consistency Index (HCI; Cui, 2009) a model-data fit index. This study utilized cognitive diagnostic assessments developed under the framework of construct-centered test design and analyzed using the Attribute Hierarchy Method (AHM: Gierl, Wang, & Zhou, 2008; Leighton, Gierl, & Hunka, 2004). Both the expert-based and the studentbased <b>cognitive</b> <b>models</b> provided excellent fit to the high ability sample, but moderate to poor fit to the total, moderate and low ability samples. Implications for <b>cognitive</b> <b>model</b> development for <b>cognitive</b> diagnostic assessment are discussed. Testing Expert-Based vs. Student-Based <b>Cognitive</b> <b>Models</b> 2 Testing Expert-Based vs. Student-Based <b>Cognitive</b> <b>Models</b> for a Grade 3 Diagnostic Mathematics Assessmen...|$|R
5000|$|Christopher Myers, The Air Force Research Laboratory's Human Effectiveness Directorate (2004). Winning Paper: [...] "Computational <b>cognitive</b> <b>modeling</b> of {{adaptive}} choice {{behavior in a}} dynamic decision paradigm." ...|$|E
50|$|He has {{published}} more than 100 articles and conference papers, and edited several books {{in the area of}} <b>cognitive</b> <b>modeling,</b> cognitive architectures, human-computer interaction, and learning. He coedited the proceedings of a conference on <b>cognitive</b> <b>modeling</b> and a special issue of the International Journal of Human Computer Studies on cognitive models as users. He is on the editorial board of Proceedings of the Human Factors and Ergonomics Society and Artificial Intelligence and the Simulation of Behaviour Quarterly. He is a series editor for The Oxford Series on Cognitive Models and Architectures.|$|E
50|$|Also he {{has created}} several Web sites, one of which, the Soar-FAQ, won an award for being {{frequently}} cited. He has created software, tutorials, and methodology for <b>cognitive</b> <b>modeling,</b> particularly with Soar and ACT-R....|$|E
40|$|This paper {{describes}} an integrated {{design and implementation}} framework for <b>cognitive</b> <b>models</b> in complex task environments. We propose a task- and humancentered development methodology for deriving the <b>cognitive</b> <b>models,</b> and present a goal-based framework for implementing them. We illustrate our approach by <b>modelling</b> <b>cognitive</b> lockup as an error producing mechanism for pilots, and present the outcomes of the implemented <b>cognitive</b> <b>models</b> that resulted from applying our methods and tools...|$|R
40|$|Psychological {{theory is}} {{advanced}} through empirical tests of predictions derived from quantitative <b>cognitive</b> <b>models.</b> As <b>cognitive</b> <b>models</b> are developed and extended, {{they tend to}} increase in complexity–leading to more precise predictions–which places concomitant demands on the behavioral data used to discriminate between candidate theories. To aid discrimination between <b>cognitive</b> <b>models</b> and, more recently, to constrain parameter estimation, neural data {{have been used as}} an adjunct to behavioral data, or as a central stream of information, in the evaluation of <b>cognitive</b> <b>models.</b> Such a model-based neuroscience approach entails many advantages, including precise tests of hypotheses about brain–behavior relationships. There have, however, been few systematic investigations of the capacity for neural data to constrain the recovery of <b>cognitive</b> <b>models.</b> Through the lens of <b>cognitive</b> <b>models</b> of speeded decision-making, we investigated the efficiency of neural data to aid identification of latent <b>cognitive</b> states in <b>models</b> fit to behavioral data. We studied two theoretical frameworks that differed in their assumptions about the composition of the latent generating state. The first assumed that observed performance was generated from a mixture of discrete latent states. The second conceived of the latent state as dynamically varying along a continuous dimension. We used a simulation-based approach to compare recovery of latent data-generating states in neurally-informed versus neurally-uninformed <b>cognitive</b> <b>models.</b> We found that neurally-informed <b>cognitive</b> <b>models</b> were more reliably recovered under a discrete state representation than a continuous dimension representation for medium effect sizes, although recovery was difficult for small sample sizes and moderate noise in neural data. Recovery improved for both representations when a larger effect size differentiated the latent states. We conclude that neural data aids the identification of latent states in <b>cognitive</b> <b>models,</b> but different frameworks for quantitatively informing <b>cognitive</b> <b>models</b> with neural information have different model recovery efficiencies. We provide full worked examples and freely-available code to implement the two theoretical frameworks...|$|R
40|$|In {{order to}} better {{understand}} how humans acquire knowledge, one of the essential goals in cognitive science {{is to build a}} <b>cognitive</b> <b>model</b> of human learning. Moreover, a <b>cognitive</b> <b>model</b> that better matches student behavior will often yield bet-ter instruction in intelligent tutoring systems. However, man-ual construction of such <b>cognitive</b> <b>models</b> is time consuming, and requires domain expertise. Further, manually-constructed models may still miss distinctions in learning which are impor-tant for instruction. Our prior work proposed an approach that finds <b>cognitive</b> <b>models</b> using a state-of-the-art learning agent, SimStudent, and we demonstrated that, for algebra learning, the agent can find a better <b>cognitive</b> <b>model</b> than human experts. To ensure the generality of that proposed approach, we further apply it to three domains: algebra, stoichiometry, and frac...|$|R
5000|$|Clancey, W.J, Sierhuis, M., Damer, B., Brodsky, B. 2005. [...] "Cognitive {{modeling}} of social behaviors". In R. Sun (Ed.), Cognition and Multi-Agent Interaction: From <b>Cognitive</b> <b>Modeling</b> to Social Simulation. New York: Cambridge University Press, pp. 151-184.|$|E
5000|$|He was {{chair of}} the First International Workshop on Cognition and Culture, the 14th Annual Conference of the North American Association for Computational, Social, and Organizational Sciences, the AAAI-06 Workshop on <b>Cognitive</b> <b>Modeling</b> and Agent-based Social Simulation, ...|$|E
5000|$|Such [...] "Cognitive Tutors" [...] {{are being}} used as a {{platform}} for research on learning and <b>cognitive</b> <b>modeling</b> as part of the Pittsburgh Science of Learning Center. Some of the most successful applications, like the Cognitive Tutor for Mathematics, are used in thousands of schools across the United States.|$|E
40|$|In {{this review}} of Giere's <b>Cognitive</b> <b>Models</b> of Science (1992), {{underlying}} theoretical assumptions of <b>cognitive</b> <b>models</b> are examined from a psychological and philosophical viewpoint. In particular, {{the aim of}} the book to constitute a unified <b>cognitive</b> <b>model</b> for the sciences is addressed. The ambiguity of cognitive processes is discussed as a major problem for cognitive explanations of science theory from a Kantian point of view...|$|R
40|$|Abstract. A <b>cognitive</b> <b>model</b> {{is a set}} of {{production}} rules or skills encoded in intelligent tutors to model how students solve problems. It is usually generated by brainstorming and iterative refinement between subject experts, cognitive scientists and programmers. In this paper we propose a semi-automated method for improving a <b>cognitive</b> <b>model</b> called Learning Factors Analysis that combines a statistical model, human expertise and a combinatorial search. We use this method to evaluate an existing <b>cognitive</b> <b>model</b> and to generate and evaluate alternative models. We present improved <b>cognitive</b> <b>models</b> and make suggestions for improving the intelligent tutor based on those models. ...|$|R
40|$|Abstract: Interactive <b>cognitive</b> <b>modelling</b> {{agents are}} defined here as {{diagnostic}} agents that involve human learners in diagnostic dialogues and extract {{a picture of}} the learner's cognition in terms of beliefs, misunderstandings, misconceptions, and reasoning. This paper is written both as a reflection on our recent work on interactive open learner modelling, which is a specific and fairly simplified interactive <b>cognitive</b> <b>modelling</b> method, and as a proposal for developing a framework for interactive <b>cognitive</b> <b>modelling</b> agents. We discuss advantages of the approach and outline pitfalls with the initial architecture suggesting possible research techniques to tackle these problems. Key words: interactive <b>cognitive</b> <b>modelling,</b> meta-cognition, evaluation. ...|$|R
5000|$|Bayesian Cognitive Science (also {{known as}} Computational Cognitive Science) is {{a rapidly growing}} {{approach}} to cognitive science concerned with the rational analysis of cognition {{through the use of}} Bayesian inference and <b>cognitive</b> <b>modeling.</b> The term [...] "computational" [...] refers to the computational level of analysis as put forth by David Marr.|$|E
50|$|While {{traditional}} <b>cognitive</b> <b>modeling</b> {{approaches have}} assumed symbolic coding schemes {{as a means}} for depicting the world, translating the world into these kinds of symbolic representations has proven to be problematic if not untenable. Perception and action and the notion of symbolic representation are therefore core issues to be addressed in cognitive robotics.|$|E
5000|$|His {{contribution}} in the cognitive modelling {{has been widely}} acknowledged. He received the Best Paper award, at the 16th Conference on Behavior Representation in Modeling and Simulation in 2007. Another of his papers was selected as [...] "Siegel-Wolf Award Winner for best applied modeling paper" [...] at theInternational Conference on <b>Cognitive</b> <b>Modeling</b> in 2004.|$|E
40|$|The {{purpose of}} this paper is to present one method for {{developing}} a <b>cognitive</b> <b>model</b> in Mathematics to promote diagnostic inferences about student performance. The <b>cognitive</b> <b>model</b> is the fundamental basis for developing diagnostic tests and enabling cognitive-based inferences about student performance. We describe the initial approach to developing a <b>cognitive</b> <b>model,</b> the decision-making processes during subsequent iterations of development, and validation of the final <b>cognitive</b> <b>models</b> by content specialists. The strengths and limitations of this method are also discussed and evaluated. Acknowledgements The research reported in this study was conducted, in part, with funds provided to the fourt...|$|R
40|$|Manuscript. Published version {{available}} at [URL] Psychological theory is advanced through empirical tests of predictions derived from quantitative <b>cognitive</b> <b>models.</b> As <b>cognitive</b> <b>models</b> are developed and extended, {{they tend to}} increase in complexity–leading to more precise predictions–which places concomitant demands on the behavioral data used to discriminate between candidate theories. To aid discrimination between <b>cognitive</b> <b>models</b> and, more recently, to constrain parameter estimation, neural data {{have been used as}} an adjunct to behavioral data, or as a central stream of information, in the evaluation of <b>cognitive</b> <b>models.</b> Such a model-based neuroscience approach entails many advantages, including precise tests of hypotheses about brain–behavior relationships. There have, however, been few systematic investigations of the capacity for neural data to constrain the recovery of <b>cognitive</b> <b>models.</b> Through the lens of <b>cognitive</b> <b>models</b> of speeded decision-making, we investigated the efficiency of neural data to aid identification of latent <b>cognitive</b> states in <b>models</b> fit to behavioral data. We studied two theoretical frameworks that differed in their assumptions about the composition of the latent generating state. The first assumed that observed performance was generated from a mixture of discrete latent states. The second conceived of the latent state as dynamically varying along a continuous dimension. We used a simulation-based approach to compare recovery of latent data-generating states in neurally-informed versus neurally-uninformed <b>cognitive</b> <b>models.</b> We found that neurally-informed <b>cognitive</b> <b>models</b> were more reliably recovered under a discrete state representation than a continuous dimension representation for medium effect sizes, although recovery was difficult for small sample sizes and moderate noise in neural data. Recovery improved for both representations when a larger effect size differentiated the latent states. We conclude that neural data aids the identification of latent states in <b>cognitive</b> <b>models,</b> but different frameworks for quantitatively informing <b>cognitive</b> <b>models</b> with neural information have different model recovery efficiencies. We provide full worked examples and freely-available code to implement the two theoretical frameworks...|$|R
40|$|<b>Cognitive</b> <b>modelling</b> is {{a common}} {{component}} of undergraduate psychology degree courses. However, the problem with <b>cognitive</b> <b>modelling</b> is that students must first learn how to program a computer before {{they are able to}} practice <b>cognitive</b> <b>modelling</b> and thereby, appreciate for themselves the contribution <b>cognitive</b> <b>modelling</b> makes to psychology. Learning to program a computer is a non-trivial task, particularly for people from non-technical backgrounds. Overcoming the steep learning curve associated with learning traditional programming languages, such as Prolog or Lisp, is a difficult problem currently facing psychology education. """"Hank"""" is a visual programming language that has been proposed as a solution to the programming overhead associated with teaching <b>cognitive</b> <b>modelling.</b> This paper discusses a programming walkthrough evaluation of the supporting material and modelling exercises used by The Open University for teaching <b>cognitive</b> <b>modelling</b> with Hank. This work is part of an ongoing evaluation project of Hank involving further theoretical and empirical studies. The key issues raised in this paper are: the consistent use of appropriate terminology, and the sufficiency, level and pace of the explanations provided...|$|R
50|$|Ram {{directed}} the Cognitive Computing Lab at the Georgia Institute of Technology starting around 2006. He led research in artificial intelligence (AI) and cognitive science. His projects focused on AI for computer games and virtual worlds, consumer health and wellness, and educational technologies. Topics included knowledge-based machine learning, case-based reasoning, <b>cognitive</b> <b>modeling,</b> and natural language processing.|$|E
50|$|The {{quality of}} the coded speech is judged on the {{differences}} in the internal representation. The difference is used for the calculation of the noise disturbance as a function of time and frequency. Besides perceptual modeling, the PSQM algorithm uses <b>cognitive</b> <b>modeling</b> such as loudness scaling and asymmetric masking in order to get high correlations between subjective and objective measurements.|$|E
5000|$|<b>Cognitive</b> <b>modeling</b> {{involves}} {{creating a}} computational model {{to estimate how}} long it takes people to perform a given task. Models are based on psychological principles and experimental studies to determine times for cognitive processing and motor movements. Cognitive models can be used to improve user interfaces or predict problem errors and pitfalls during the design process. A few examples of cognitive models include: ...|$|E
5000|$|Theories of task {{performance}} {{can be used}} to derive <b>cognitive</b> <b>models</b> of {{task performance}} in a subject domain. However, the availability of these theories of task performance and <b>cognitive</b> <b>models</b> in education are limited. Therefore, other means are used to generate <b>cognitive</b> <b>models.</b> One method is the use of a task analysis of representative test items from a subject domain. A task analysis represents a hypothesized <b>cognitive</b> <b>model</b> of task performance, where the likely knowledge and processes used to solve the test item are specified. A second method involves having examinees think aloud as they solve test items to identify the actual knowledge, processes, and strategies elicited by the task,. [...] The verbal report collected as examinees talk aloud can contain the relevant knowledge, skills, and procedures used to solve the test item. These knowledge, skills, and procedures become the attributes in the <b>cognitive</b> <b>model,</b> and their temporal sequencing documented in the verbal report provides the hierarchical ordering. A <b>cognitive</b> <b>model</b> derived using a task analysis can be validated and, if required, modified using examinee verbal reports collected from think aloud studies.|$|R
30|$|As {{all these}} <b>cognitive</b> <b>models</b> are well-grounded in theory, they provide useful {{insights}} in user behaviour. Although <b>cognitive</b> <b>modelling</b> {{is an active}} research field, {{so far it has}} not been received particularly well by usability practitioners and only rarely finds its way into non-academic evaluations (Engelbrecht et al. 2009; Kieras 2003). Reasons are their often high complexity (Kieras 2003) and possibly the aforementioned low level of the information possible to gain with <b>cognitive</b> <b>modelling.</b>|$|R
50|$|A <b>cognitive</b> <b>model</b> is an {{approximation}} {{to animal}} cognitive processes (predominantly human) {{for the purposes}} of comprehension and prediction. <b>Cognitive</b> <b>models</b> can be developed within or without a cognitive architecture, though the two are not always easily distinguishable.|$|R
