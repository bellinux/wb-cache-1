884|2057|Public
2500|$|The TMU encodes {{the high}} rate data stream with a <b>convolutional</b> <b>code</b> having {{constraint}} length of 7 with a symbol rate equal to twice the bit rate (k=7, r=1/2) ...|$|E
50|$|The example encoder is {{composed}} of a 16-state outer <b>convolutional</b> <b>code</b> and a 2-state inner <b>convolutional</b> <b>code</b> linked by an interleaver. The natural code rate of the configuration shown is 1/4, however, the inner and/or outer codes may be punctured to achieve higher code rates as needed. For example, an overall code rate of 1/2 may be achieved by puncturing the outer <b>convolutional</b> <b>code</b> to rate 3/4 and the inner <b>convolutional</b> <b>code</b> to rate 2/3.|$|E
5000|$|Using the [...] "convolutional" [...] terminology, {{a classic}} <b>convolutional</b> <b>code</b> might be {{considered}} a Finite impulse response (FIR) filter, while a recursive <b>convolutional</b> <b>code</b> {{might be considered}} an Infinite impulse response (IIR) filter.|$|E
40|$|Fundamentals of <b>Convolutional</b> <b>Coding,</b> Second Edition, {{regarded}} as a bible of <b>convolutional</b> <b>coding</b> brings you a clear and comprehensive discussion of {{the basic principles of}} this field * Two new chapters on low-density parity-check (LDPC) <b>convolutional</b> <b>codes</b> and iterative coding * Viterbi, BCJR, BEAST, list, and sequential decoding of <b>convolutional</b> <b>codes</b> * Distance properties of <b>convolutional</b> <b>codes</b> * Includes a downloadable solutions manua...|$|R
40|$|Maximum-distance {{separable}} (MDS) <b>convolutional</b> <b>codes</b> form {{an optimal}} family of <b>convolutional</b> <b>codes,</b> {{the study of}} which is of great importance. There are very few general algebraic constructions of MDS <b>convolutional</b> <b>codes.</b> In this paper, we construct a large family of unit-memory MDS <b>convolutional</b> <b>codes</b> over with flexible parameters. Compared with previous works, the field size q required to define these codes is much smaller. The construction also leads to many new strongly-MDS <b>convolutional</b> <b>codes,</b> an important subclass of MDS <b>convolutional</b> <b>codes</b> proposed and studied in GL 2. Many examples are presented {{at the end of}} the paper...|$|R
40|$|This thesis {{focuses on}} the study of {{concatenated}} <b>convolutional</b> <b>codes</b> and their iterative decoding methodologies. Parallel concatenated <b>convolutional</b> <b>codes</b> (PCCC) and serial concatenated <b>convolutional</b> <b>codes</b> (SCCC) are studied to explore their potential to approximate Shannon's channel capacity with feasible complexity...|$|R
50|$|The channel {{encoding}} {{process in}} GPRS {{as well as}} EGPRS/EDGE consists of two steps: first, a cyclic code is used to add parity bits, which are {{also referred to as}} the Block Check Sequence, followed by coding with a possibly punctured <b>convolutional</b> <b>code.</b> In GPRS, the Coding Schemes CS-1 to CS-4 specify the number of parity bits generated by the cyclic code and the puncturing rate of the <b>convolutional</b> <b>code.</b> In GPRS Coding Schemes CS-1 through CS-3, the <b>convolutional</b> <b>code</b> is of rate 1/2, i.e. each input bit is converted into two coded bits. In Coding Schemes CS-2 and CS-3, the output of the <b>convolutional</b> <b>code</b> is punctured to achieve the desired code rate. In GPRS Coding Scheme CS-4, no convolutional coding is applied.|$|E
50|$|The {{code rate}} of a <b>convolutional</b> <b>code</b> is {{commonly}} modified via symbol puncturing. For example, a <b>convolutional</b> <b>code</b> with a 'mother' code rate n/k=1/2 may be punctured {{to a higher}} rate of, for example, 7/8 simply by not transmitting a portion of code symbols. The performance of a punctured <b>convolutional</b> <b>code</b> generally scales well {{with the amount of}} parity transmitted. The ability to perform economical soft decision decoding on convolutional codes, as well as the block length and code rate flexibility of convolutional codes, makes them very popular for digital communications.|$|E
5000|$|The <b>convolutional</b> <b>code</b> used {{to encode}} CNAV is {{described}} by:where: ...|$|E
40|$|Maximum-distance {{separable}} (MDS) <b>convolutional</b> <b>codes</b> {{are characterized}} through the property {{that the free}} distance attains the generalized Singleton bound. The existence of MDS <b>convolutional</b> <b>codes</b> was established {{by two of the}} authors by using methods from algebraic geometry. This correspondence provides an elementary construction of MDS <b>convolutional</b> <b>codes</b> for each rate and each degree. The construction is based on a well-known connection between quasi-cyclic <b>codes</b> and <b>convolutional</b> <b>codes...</b>|$|R
40|$|Abstract—In {{this paper}} the {{decoding}} capabilities of convolu-tional codes over the erasure channel are studied. Of special interest will be maximum distance profile (MDP) <b>convolutional</b> <b>codes.</b> These are codes {{which have a}} maximum possible column distance increase. It is shown how this strong minimum distance condition of MDP <b>convolutional</b> <b>codes</b> {{help us to solve}} error situations that maximum distance separable (MDS) block codes fail to solve. Towards this goal, two subclasses of MDP codes are defined: reverse-MDP <b>convolutional</b> <b>codes</b> and complete-MDP <b>convolutional</b> <b>codes.</b> Reverse-MDP codes have the capability to recover a maximum number of erasures using an algorithm which runs backward in time. Complete-MDP <b>convolutional</b> <b>codes</b> are both MDP and reverse-MDP codes. They are capable to recover the state of the decoder under the mildest condition. It is shown that complete-MDP <b>convolutional</b> <b>codes</b> perform in many cases better than comparable MDS block codes of the same rate over the erasure channel. Index Terms—Convolutional codes, maximum distance sepa-rable (MDS) block codes, decoding, erasure channel, maximum distance profile (MDP) <b>convolutional</b> <b>codes,</b> reverse-MDP convo-lutional <b>codes,</b> complete-MDP <b>convolutional</b> <b>codes.</b> 1...|$|R
40|$|In {{this thesis}} {{we take a}} {{detailed}} look at the algebraic structure of <b>convolutional</b> and quasi-cyclic <b>codes</b> using the tools and methods of linear systems theory. Let F q be a finite field with q elements. In particular, we define <b>convolutional</b> <b>codes</b> as linear, right shift invariant, compact support behaviors in (F n) Z+. We then examine the concepts of observability, controllability, and minimality for <b>convolutional</b> <b>codes</b> as defined above. We show how <b>convolutional</b> <b>codes</b> are dual to the class of autoregressive behaviors. We compare compact support <b>convolutional</b> <b>codes</b> to non-compact support <b>convolutional</b> <b>codes.</b> In addition, we derive first order representations of <b>convolutional</b> <b>codes</b> on a purely module theoretic. We also examine the properties of these representations and give conditions for observability and minimality. Using the systems theoretic structure of <b>convolutional</b> <b>codes</b> we present two code constructions. For the first one we choose n; k; q and ffi 2 Z+, such that q ffi [...] ...|$|R
50|$|Turbo equalizer: applies turbo {{decoding}} while {{treating the}} channel as a <b>convolutional</b> <b>code.</b>|$|E
5000|$|Forward error {{correction}} (FEC): non-recursive <b>convolutional</b> <b>code</b> with constraint length K=32, rate r=1/2.|$|E
5000|$|Convolutional codes work on bit or symbol {{streams of}} {{arbitrary}} length. They {{are most often}} soft decoded with the Viterbi algorithm, though other algorithms are sometimes used. Viterbi decoding allows asymptotically optimal decoding efficiency with increasing constraint length of the <b>convolutional</b> <b>code,</b> but {{at the expense of}} exponentially increasing complexity. A <b>convolutional</b> <b>code</b> that is terminated is also a 'block code' in that it encodes a block of input data, but the block size of a <b>convolutional</b> <b>code</b> is generally arbitrary, while block codes have a fixed size dictated by their algebraic characteristics. Types of termination for convolutional codes include [...] "tail-biting" [...] and [...] "bit-flushing".|$|E
40|$|In {{this paper}} the {{decoding}} capabilities of <b>convolutional</b> <b>codes</b> over the erasure channel are studied. Of special interest will be maximum distance profile (MDP) <b>convolutional</b> <b>codes.</b> These are codes {{which have a}} maximum possible column distance increase. It is shown how this strong minimum distance condition of MDP <b>convolutional</b> <b>codes</b> {{help us to solve}} error situations that maximum distance separable (MDS) block codes fail to solve. Towards this goal, two subclasses of MDP codes are defined: reverse-MDP <b>convolutional</b> <b>codes</b> and complete-MDP <b>convolutional</b> <b>codes.</b> Reverse-MDP codes have the capability to recover a maximum number of erasures using an algorithm which runs backward in time. Complete-MDP <b>convolutional</b> <b>codes</b> are both MDP and reverse-MDP codes. They are capable to recover the state of the decoder under the mildest condition. It is shown that complete-MDP <b>convolutional</b> <b>codes</b> perform in many cases better than comparable MDS block codes of the same rate over the erasure channel...|$|R
40|$|In {{this paper}} we {{consider}} two models of concatenated <b>convolutional</b> <b>codes</b> {{from the perspective}} of linear sys-tems theory. We present an input-state-output repre-sentation of these models and we study the conditions for control properties for concatenated <b>convolutional</b> <b>codes.</b> Key words <b>Convolutional</b> <b>codes,</b> linear systems, control...|$|R
40|$|ABSTRACT — In {{this article}} we {{introduce}} {{a new class of}} product <b>codes</b> based on <b>convolutional</b> <b>codes,</b> <b>convolutional</b> product <b>codes</b> (CPCs). The structure of product codes en-ables parallel decoding which can significantly increase de-coder speed in practice. The use of <b>convolutional</b> <b>codes</b> in a product code setting lays the ground for utilizing all the flexibility and vast knowledge base for <b>convolutional</b> <b>codes</b> in fast parallel decoders. Interleaving turns out to be criti-cal for the performance of <b>convolutional</b> product <b>codes</b> just as in turbo codes. The practical decoding advantages over serially concatenated <b>convolutional</b> <b>codes</b> are emphasized. I...|$|R
5000|$|... "Sequential algorithm" [...] {{may also}} refer {{specifically}} to an algorithm for decoding a <b>convolutional</b> <b>code.</b>|$|E
50|$|A Viterbi decoder {{uses the}} Viterbi {{algorithm}} for decoding a bitstream that has beenencoded using <b>convolutional</b> <b>code</b> or trellis code.|$|E
50|$|An {{especially}} popular Viterbi-decoded <b>convolutional</b> <b>code,</b> used {{at least}} since the Voyager program has a constraint length k of 7 and a rate r of 1/2.|$|E
40|$|Rate-(n– 2) /n {{unrestricted}} and CSS-type quantum <b>convolutional</b> <b>codes</b> {{with up to}} 4096 {{states and}} minimum distances up to 10 are constructed as stabilizer codes from classical self-orthogonal rate- 1 /n F 4 -linear and binary linear <b>convolutional</b> <b>codes,</b> respectively. These codes generally have higher rate and less decoding complexity than comparable quantum block codes or previous quantum <b>convolutional</b> <b>codes.</b> Rate-(n– 2) /n block stabilizer codes with the same rate and error-correction capability and essentially the same decoding algorithms are derived from these <b>convolutional</b> <b>codes</b> via tail-biting. Index terms: Quantum error-correcting codes, CSS-type <b>codes,</b> quantum <b>convolutional</b> <b>codes,</b> quantum tail-biting codes. I...|$|R
40|$|Abstract—Using a new parity-check matrix, a {{class of}} <b>convolutional</b> <b>codes</b> with a {{designed}} free distance is introduced. This new class of codes has many characteristics of BCH block codes, therefore, we call these <b>codes</b> BCH <b>convolutional</b> <b>codes.</b> Index Terms—BCH <b>codes,</b> <b>convolutional</b> <b>codes,</b> cyclotomic sets, linear systems. I...|$|R
40|$|Maximum {{distance}} separable (MDS) <b>convolutional</b> <b>codes</b> {{are characterized}} through the property {{that the free}} distance attains the generalized Singleton bound. The existence of MDS <b>convolutional</b> <b>codes</b> was established {{by two of the}} authors by methods from algebraic geometry. This paper provides an elementary construction of MDS <b>convolutional</b> <b>codes</b> for each rate k/n and each degree &delta;. The construction is based on a well known connection between quasi cyclic <b>codes</b> and <b>convolutional</b> <b>codes...</b>|$|R
5000|$|It uses forward error {{correction}} (FEC) provided by a rate 1/2 <b>convolutional</b> <b>code,</b> so while the navigation message is 25 bit/s, a 50 bit/s signal is transmitted.|$|E
5000|$|In telecommunication, a Hagelbarger code is a <b>convolutional</b> <b>code</b> {{that enables}} error bursts to be {{corrected}} provided that there are relatively long error-free intervals between the error bursts.|$|E
50|$|A {{recursive}} inner <b>convolutional</b> <b>code</b> {{is preferable}} for turbo decoding of the SCCC. The inner code may be punctured to a rate {{as high as}} 1/1 with reasonable performance.|$|E
40|$|Abstract—In this {{correspondence}} {{the error}} exponent and the decoding complexity of binary woven <b>convolutional</b> <b>codes</b> with outer warp and with binary <b>convolutional</b> <b>codes</b> as outer and inner codes are studied. It is shown that an error probability that is exponentially decreasing with {{the product of}} the outer and inner code memories can be achieved with a nonexponentially increasing decoding complexity. Index Terms—Concatenated <b>convolutional</b> <b>codes,</b> decoding complexity, woven <b>convolutional</b> <b>codes,</b> woven error exponents. I...|$|R
40|$|In {{this paper}} we {{investigate}} {{the properties of}} the generator matrices of a new class of <b>convolutional</b> <b>codes,</b> called product <b>convolutional</b> <b>codes,</b> which were previously defined and investigated by the authors. The new codes are constructed using the well-known method of the direct product for combining block <b>codes.</b> <b>Convolutional</b> <b>codes</b> are considered as block codes over the field of rational functions F(D). The description of <b>convolutional</b> <b>codes</b> as block codes allows the successful application of the direct product method to <b>convolutional</b> <b>codes,</b> and, in addition, leads to a general method to construct new <b>convolutional</b> <b>codes</b> based on already known combining methods for block codes. Expressions for the generator matrices of the product <b>convolutional</b> <b>codes</b> are given and several of their properties, which were not addressed before, are determined. The relationship between {{the properties of the}} direct product encoder generator matrix and the properties of the vertical and horizontal constituent encoders generator matrices is derived. Rational generator matrices, as well as polynomial generator matrices, are addressed...|$|R
40|$|In {{this paper}} we study the {{decoding}} capabilities of <b>convolutional</b> <b>codes</b> over the erasure channel. Of special interest will be maximum distance profile (MDP) <b>convolutional</b> <b>codes.</b> These are codes {{which have a}} maximum possible column distance increase. We show how this strong minimum distance condition of MDP <b>convolutional</b> <b>codes</b> {{help us to solve}} error situations that maximum distance separable (MDS) block codes fail to solve. Towards this goal, we define two subclasses of MDP codes: reverse-MDP <b>convolutional</b> <b>codes</b> and complete-MDP <b>convolutional</b> <b>codes.</b> Reverse-MDP codes have the capability to recover a maximum number of erasures using an algorithm which runs backward in time. Complete-MDP <b>convolutional</b> <b>codes</b> are both MDP and reverse-MDP codes. They are capable to recover the state of the decoder under the mildest condition. We show that complete-MDP <b>convolutional</b> <b>codes</b> perform in certain sense better than MDS block codes of the same rate over the erasure channel. Comment: 18 pages, 3 figures, to appear on IEEE Transactions on Information Theor...|$|R
5000|$|The TMU encodes {{the high}} rate data stream with a <b>convolutional</b> <b>code</b> having {{constraint}} length of 7 with a symbol rate equal to twice the bit rate (k=7, r=1/2) ...|$|E
50|$|Prior to turbo codes, {{the best}} constructions were serial {{concatenated}} codes {{based on an}} outer Reed-Solomon error correction code combined with an inner Viterbi-decoded short constraint length <b>convolutional</b> <b>code,</b> also known as RSV codes.|$|E
5000|$|The free {{distance}} (d) is {{the minimal}} Hamming distance between different encoded sequences. The correcting capability (t) of a <b>convolutional</b> <b>code</b> {{is the number}} of errors that can be corrected by the code. It can be calculated as ...|$|E
40|$|Using a new {{parity check}} matrix {{a class of}} <b>convolutional</b> <b>codes</b> with a {{designed}} free distance is introduced. This new class of codes has many characteristics of BCH block codes, therefore we call these <b>codes</b> BCH <b>convolutional</b> <b>codes.</b> Keywords: <b>Convolutional</b> <b>codes,</b> linear systems, BCH codes, cyclotomic sets. 1 Introduction <b>Convolutional</b> <b>codes</b> having a large free distance and a low complexity are often found by computer searches. Several authors attempted to extend constructions known for block <b>codes</b> to <b>convolutional</b> <b>codes.</b> A survey of some of this work is provided {{in the book of}} Piret [10, Section 3. 5] where more complete references can be found. Most of these constructions are based on some quasi cyclic constructions of block codes and we would like to mention the papers [2, 5, 7, 16]. In [7] and [2], the authors construct good <b>convolutional</b> <b>codes</b> using cyclic codes. In particular, in [2], Justesen constructs binary <b>convolutional</b> <b>codes</b> based on BCH block codes whose distance is lower b [...] ...|$|R
5000|$|<b>Convolutional</b> <b>codes</b> are {{implemented}} as either systematic or non-systematic <b>codes.</b> Non-systematic <b>convolutional</b> <b>codes</b> can provide better performance under maximum-likelihood (Viterbi) decoding.|$|R
40|$|Abstract- We propose an {{analytical}} method to u p per bound the bit error probability of parallel con-catenated block and <b>convolutional</b> <b>codes.</b> The so called turbo codes [l], {{which in the}} following we will call parallel concatenated <b>convolutional</b> <b>codes</b> (PCCC), con-sist of two linear, generally simple <b>convolutional</b> <b>codes</b> (th...|$|R
