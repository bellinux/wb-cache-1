35|10000|Public
50|$|Data models {{provide a}} {{framework}} for data to be used within information systems by providing specific definition and format. If a data model is used consistently across systems then <b>compatibility</b> <b>of</b> <b>data</b> can be achieved. If the same data structures are used to store and access data then different applications can share data seamlessly. The results of this are indicated in the diagram. However, systems and interfaces are often expensive to build, operate, and maintain. They may also constrain the business rather than support it. This may occur when the quality of the data models implemented in systems and interfaces is poor.|$|E
5000|$|The main aim of {{data models}} {{is to support}} the {{development}} of information systems by providing the definition and format of data. According to West and Fowler (1999) [...] "if this is done consistently across systems then <b>compatibility</b> <b>of</b> <b>data</b> can be achieved. If the same data structures are used to store and access data then different applications can share data. The results of this are indicated above. However, systems and interfaces often cost more than they should, to build, operate, and maintain. They may also constrain the business rather than support it. A major cause is {{that the quality of}} the data models implemented in systems and interfaces is poor".|$|E
40|$|A {{framework}} for a multi-attribute multi-source data fusion is described. Uncertainty of data is modeled by fuzzy sets. The problem is considered on a general level. Credibility of sources, <b>compatibility</b> <b>of</b> <b>data,</b> {{as well as}} their reasonableness, are taken into consideration. The proposed method is illustrated by an example. 1...|$|E
50|$|Provides a {{means for}} {{improving}} the consistency and <b>compatibility</b> <b>of</b> various <b>data</b> elements provided by public agencies across the country.|$|R
5000|$|For {{the purpose}} <b>of</b> <b>compatibility,</b> all <b>data</b> refers to Metropolitan France ...|$|R
40|$|This article {{presents}} the <b>compatibility</b> <b>of</b> experimental <b>data</b> from neutrino oscillation experiments with a high- two-neutrino oscillation hypothesis. Data {{is provided by}} the Bugey, Karlsruhe Rutherford Medium Energy Neutrino Experiment 2 (KARMEN 2), Los Alamos Liquid Scintillator Neutrino Detector (LSND), and MiniBooNE experiments. The LSND, KARMEN 2, and MiniBooNE results are 25. 36...|$|R
40|$|Considering the Balitsky-Kovchegov QCD {{evolution}} equation in full momentum space, we derive the {{travelling wave}} solutions expressing the nonlinear saturation {{constraints on the}} dipole scattering amplitude at non-zero momentum transfer. A phenomenological application to elastic vector meson production shows the <b>compatibility</b> <b>of</b> <b>data</b> with the QCD prediction: an enhanced saturation scale at intermediate momentum transfer. ...|$|E
40|$|<b>Compatibility</b> <b>of</b> <b>data</b> {{transfers}} {{between individual}} CAD programs is topical when in another program {{we need to}} use a drawing or a 3 D model created in a program that uses a different modeling kernel. The paper characterizes features and structures of existing CAD formats, problems in their transfer, it notes the export/import conversion through the IGES, SAT, STEP and STL formats. It takes a closer look at using the STL format for visualization and animation...|$|E
40|$|With {{the trend}} for global collaboration, {{there is a}} need for {{collaborative}} design between geographically distributed teams and companies. In particular, this need is inevitable in the companies doing their business based on one-of-a-kind production (OKP). One important problem is the lack of interoperability and <b>compatibility</b> <b>of</b> <b>data</b> between different CAx systems. This problem is further highlighted in data exchange in cloud manufacturing. To the best of authors' knowledge, current studies have limitations in achieving the interoperability and <b>compatibility</b> <b>of</b> <b>data.</b> In this paper, a STEP-based data model is proposed to represent OKP product data/knowledge, which contains four categories of product knowledge (i. e., customer, product, manufacturing, and resource resp.). A STEP-based data modelling approach is proposed to describe each category of knowledge separately and then connect them to form the final integrated model. Compared with most current product models, this model includes the more complete product data/knowledge involved in OKP product development (OKPPD), and thus it can provide more adequate knowledge support for OKPPD activities. Based on the proposed STEP-based data model, a product data exchange and sharing (DES) framework is proposed and developed to enable DES in collaborative OKPPD in the cloud manufacturing environment. Case studies were carried out to validate the proposed data model and DES framework...|$|E
30|$|In this section, {{we first}} present our results on {{localization}} accuracy and power consumption, which {{were collected in}} a realistic testbed incorporating the prototype localization system. Then, we discuss the <b>compatibility</b> <b>of</b> crowdsourced RSSI <b>data.</b>|$|R
40|$|Clustering {{has often}} {{described}} by Ewens Sampling Formula (ESF). Focusing the {{attention on the}} evergreen problem {{of the size of}} firms, we discuss the <b>compatibility</b> <b>of</b> empirical <b>data</b> and ESF. In order to obtain a power law for all sizes in the present paper we shall explore the route inspired by Yule, Zipf and Simon. It differs from the Ewens model both for destruction and creation...|$|R
40|$|The {{recently}} developed "Data Set Diagonalization" method (DSD) {{is applied to}} measure <b>compatibility</b> <b>of</b> the <b>data</b> sets {{that are used to}} determine parton distribution functions (PDFs). Discrepancies among the experiments are found to be somewhat larger than is predicted by propagating the published experimental errors according to Gaussian statistics. The results support a tolerance criterion of Δχ^ 2 ≈ 10 to estimate the 90...|$|R
40|$|This work is {{dedicated}} to methodical questions of analysis and assessment of regional educational systems. We explored modern approaches, Russian and international experience of assessment of subnational educational systems. Approach to analysis and assessment of the regional educational systems as open systems was described, methods of providing of <b>compatibility</b> <b>of</b> <b>data,</b> correct computation and assessment of systems functioning in different conditions were shown. We explored problems and risks of using of ratings in education. On the specific example we describes a scheme of analysis of results of assessment of educational systems and possibilities of using of ratings for a management of realization of educational policy. education, policy, rating, assessment, Russia, data, analysi...|$|E
40|$|A {{comprehensive}} {{compilation of}} all test {{results on the}} insect antifeedant activity of clerodane diterpenes and related model compounds is reported. To increase the <b>compatibility</b> <b>of</b> <b>data</b> from different sources, some of the results {{reported in the literature}} have been converted into a standardized form. The compounds were sorted into groups according to the different types of sidechain attached to C- 9. Despite the wealth of information, collected in 15 tables, it remains difficult to assign importance to separate structural elements in relation to the observed antifeedant activity. A detailed analysis of the structure–activity relationships could not be presented, but some interesting trends can be distinguished based on the structures of the strongest antifeedants. The compilation covers the literature up to December 2001...|$|E
40|$|The study {{reports the}} {{perceptions}} and recommendations of sixty-two experienced survey [...] {{researchers from the}} American Educational Research Association {{regarding the use of}} [...] electronic surveys. The most positive aspects cited for the use of electronic surveys were [...] reduction of costs (i. e., postage, phone charges), the use of electronic mail for pre-notification or [...] follow-up purposes, and the <b>compatibility</b> <b>of</b> <b>data</b> with existing software programs. These [...] professionals expressed limitations in using electronic surveys pertaining to the limited [...] sampling frame as well as issues of confidentiality, privacy, and the credibility of the sample [...] . They advised that electronic surveys designed with the varied technological background and [...] capabilities of the respondent in mind, follow sound principles of survey construction, and be [...] administered to pre-notified, targeted populations with published email addresses...|$|E
50|$|An {{important}} {{consideration in the}} process of developing electronic health records is to plan for the long-term preservation and storage of these records. The field will need to come to consensus on the length of time to store EHRs, methods to ensure the future accessibility and <b>compatibility</b> <b>of</b> archived <b>data</b> with yet-to-be developed retrieval systems, and how to ensure the physical and virtual security of the archives.|$|R
40|$|Abstract: Complicated {{mathematical}} {{models are}} usually used for processing {{measurements of the}} Earth magnetic field carried out onboard an Earth artificial satellite. It is desirable to verify the measurement data by humble tools before such processing. If a few onboard magnetometers made their measurements at the same instants, then one ought to check a simple geometrical <b>compatibility</b> <b>of</b> the measurement <b>data.</b> One can estimate constant shifts in the data and transition matrices between proper coordinate systems for each pair of magnetometers in case the check proved to be successful. Bellow, we described the method for checking the <b>compatibility</b> <b>of</b> the measurement <b>data</b> produced by two magnetometers. We illustrate the method by checking the <b>compatibility</b> <b>of</b> the magnetic measurements produced by the equipment Mirage onboard Foton M- 2. Note: Publication language:russia...|$|R
40|$|Studies of {{the spin}} of the Higgs boson are presented, based on proton-proton {{collision}} {{data collected by}} ATLAS detector at the LHC. The Standard Model spin-parity hypothesis is compared with alternative hypotheses using the Higgs boson decays in the three discovery channels, and the combination of them. All the studies show the <b>compatibility</b> <b>of</b> the <b>data</b> with the Standard Model Higgs boson and reject althernative models with a CLs up to 97. 8 %...|$|R
40|$|We {{present results}} of a model-independent general search for new {{phenomena}} in proton-proton collisions at a centre-of-mass energy of 8 TeV with the ATLAS detector at the LHC. The data set corresponds to a total integrated luminosity of 20. 3. Event topologies involving isolated electrons, photons and muons, as well as jets, including those identified as originating from b-quarks (b-jets) and missing transverse momentum are investigated. The events are subdivided according to their final states into exclusive event classes. For the 697 classes with a Standard Model expectation greater than 0. 1 events, a search algorithm tests the <b>compatibility</b> <b>of</b> <b>data</b> against the Monte Carlo simulated background in three kinematic variables sensitive to new physics effects. No significant deviation is found in data. The number {{and size of the}} observed deviations follow the Standard Model expectation obtained from simulated pseudo-experiments...|$|E
40|$|As {{technology}} advances, {{new types}} of devices and increasing <b>compatibility</b> <b>of</b> <b>data</b> formats {{make it possible to}} use files previously accessible on only one or two devices. For example, a person might wish to access a business file (formerly stored on a work computer or perhaps even in a file cabinet at the office) from her smart phone. Similarly, another might wish to access his MP 3 collection (stored on an iPod or personal computer) from his work computer. Such technological progress has paved the way for innovative digital, cable and Internet services that enable users to enjoy copyrighted content in new ways: from time-shifting via VCRs to place-shifting via new TV devices; from instantly purchasing a movie through video on demand to watching a live stream of sports coverage on the Internet. One type of service that has recently proliferated is the digital storage locker—also known as the cyber locker...|$|E
40|$|Copyright {{owned by}} the author(s) {{under the terms of}} the Creative Commons Attribution-NonCommercial-ShareAlike Licence. Practitioners of lattice QCD/QFT have been some of the primary pioneer users of the state-of-theart high-performance-computing systems, and {{contribute}} towards the stress tests of such new machines as soon as they become available. As with all aspects of high-performance-computing, I/O is becoming an increasingly specialized component of these systems. In order to take advantage of the latest available high-performance I/O infrastructure, to ensure reliability and backwards <b>compatibility</b> <b>of</b> <b>data</b> files, and to help unify the data structures used in lattice codes, we have incorporated parallel HDF 5 I/O into the SciDAC supported USQCD software stack. Here we present the design and implementation of this I/O framework. Our HDF 5 implementation outperforms optimized QIO at the 10 - 20 % level and leaves room for further improvement by utilizing appropriate dataset chunking...|$|E
30|$|Examining the {{correlation}} (Table  5) shows {{the highest level}} of correlation between constructs regulation and top management (0.82). This is followed by correlation between <b>compatibility</b> and size <b>of</b> <b>data</b> (0.72) as well as regulation and increasing providers (0.77).|$|R
40|$|We analyse the {{predictions}} of both Higgs and top masses in a generic MSSM satisfying gauge-coupling unification, radiative electroweak symmetry breaking, with a natural (non-splitted) spectrum of soft-breaking terms, and an arbitrary soft-breaking scale (above a few TeV). This procedure allows us to identify a relatively narrow SUSY-allowed region in the $(m_h, m_t) $ plane. We argue that the <b>compatibility</b> <b>of</b> the measured values of Higgs and top masses with this SUSY-allowed region is not less surprising than the corresponding compatibility with the narrow SM metastability region. As such, it provides a non-trivial signal <b>of</b> the <b>compatibility</b> <b>of</b> present <b>data</b> with a supersymmetric completion of the SM. Comment: 16 page...|$|R
40|$|In {{this study}} we (1) {{synthesized}} 65 yr <b>of</b> odontocete stranding <b>data</b> around the main Hawaiian Islands (1937 – 2002); (2) analyzed stranding patterns and trends over time; and (3) compared occurrence patterns based on sightings of live animals with stranding data and evaluated the <b>compatibility</b> <b>of</b> these <b>data</b> sets. From 1937 to 2002, 202 odontocete strandings were recorded by the National Marine Fisheries Service, Pacific Islands Regional Office. Strandings increased through time due to increased reporting effort and occurred throughout the year. The four most common of 16 species reported were Kogia spp. (18...|$|R
40|$|This paper extends {{pre-existing}} {{digital divide}} conceptualizations to further investigate the important issue of mismatches between the ontologies of state-created information systems and local communities ’ representation of their contexts. Comparability of data {{across time and}} place, as well as <b>compatibility</b> <b>of</b> <b>data</b> with state administrative needs come {{at a cost of}} information loss about the setting and individuals that policymakers are trying to impact. We argue that the reconciliation of community and state logics and framings is critical for effective engagement with communities as well as formulation and implementation of development policies. We suggest several paths toward overcoming mismatched ontologies: education and communications strategies to enable communities and states to translate across ontologies and fill in significant gaps; re-assignment of policy responsibilities to minimize information loss; and several mechanisms that would enable communities to be directly and productively engaged in developing shared ontologies. 1...|$|E
40|$|This paper aims {{to present}} the {{specifics}} of the application of multiple linear regression model. The economic (financial) crisis is analyzed in terms of gross domestic product which is in a function of the foreign trade balance (on one hand) and the credit cards, i. e. indebtedness of the population on this basis (on the other hand), in the USA (from 1999. to 2008). We used the extended application model which shows how the analyst should run the whole development process of regression model. This process began with simple statistical features and the application of regression procedures, and ended with residual analysis, intended for the study of <b>compatibility</b> <b>of</b> <b>data</b> and model settings. This paper also analyzes the values of some standard statistics used in the selection of appropriate regression model. Testing of the model is carried out {{with the use of the}} Statistics PASW 17 program...|$|E
40|$|Practitioners of lattice QCD/QFT {{have been}} some of the primary pioneer users of the {{state-of-the-art}} high-performance-computing systems, and contribute towards the stress tests of such new machines {{as soon as they}} become available. As with all aspects of high-performance-computing, I/O is becoming an increasingly specialized component of these systems. In order {{to take advantage of the}} latest available high-performance I/O infrastructure, to ensure reliability and backwards <b>compatibility</b> <b>of</b> <b>data</b> files, and to help unify the data structures used in lattice codes, we have incorporated parallel HDF 5 I/O into the SciDAC supported USQCD software stack. Here we present the design and implementation of this I/O framework. Our HDF 5 implementation outperforms optimized QIO at the 10 - 20 % level and leaves room for further improvement by utilizing appropriate dataset chunking. Comment: Contribution to the 32 nd International Symposium on Lattice Field Theory (Lattice 2014), 23 - 28 June 2014, Columbia University, New York, NY, US...|$|E
40|$|Following a disaster, geoinformatics {{can provide}} {{critical}} information pinpointing {{the location and}} nature of serious damage. However, using geoinformatics in this situation imposes unusual constraints: opportunistic use of whatever pre- and post-disaster data may be available without regard to quality or sensor <b>compatibility,</b> analysis <b>of</b> <b>data</b> by relatively untrained personnel, and limited data processing facilities. This paper describes an {{approach to dealing with}} these limitations, undertaken by our Remote Sensing Laboratory at the Computer Engineerin...|$|R
40|$|This paper {{presents}} the results of a large analysis <b>of</b> environmental <b>data</b> gaps in countries of the Black Sea catchment performed {{in the context of the}} FP 7 enviroGRIDS project in 2010. We also assessed the level <b>of</b> <b>compatibility</b> <b>of</b> the <b>data</b> to the European directive establishing an Infrastructure for Spatial Information in the European Community (INSPIRE) and to the international standards <b>of</b> <b>data</b> interoperability as advocated by the Group on Earth Obser- vations (GEO) and implemented in the Global Earth Observation System of Systems (GEOSS). Many environmental datasets were analyzed at different scales (national, regional, Euro- pean, and global) and the analysis revealed gaps in spatial and temporal environmental data coverage and problem <b>of</b> <b>data</b> <b>compatibility</b> at different scales. The analysis enabled the identification of areas where further efforts are needed to reinforce the existing observation systems in the region, such as monitoring systems to provide data on water quality in rivers, on the state of marine environments, or on pollution and nutrients loads from land based sources. A significant proportion of environmental datasets is not accessible or has limited access, so further efforts are needed to make them available to decision makers and scientists following the GEO <b>data</b> sharing principles. <b>Compatibilities</b> <b>of</b> many <b>data</b> sets and observation systems to international interoperability standards are low in this region, and we discuss what further efforts are needed to improve the situation and how this is relevant to environmental policies...|$|R
40|$|We present two {{different}} halo-independent methods {{to assess the}} <b>compatibility</b> <b>of</b> several direct dark matter detection data sets for a given dark matter model using a global likelihood consisting {{of at least one}} extended likelihood and an arbitrary number of Gaussian or Poisson likelihoods. In the first method we find the global best fit halo function (we prove that it is a unique piecewise constant function with a number of down steps smaller than or equal to a maximum number that we compute) and construct a two-sided pointwise confidence band at any desired confidence level, which can then be compared with those derived from the extended likelihood alone to assess the joint <b>compatibility</b> <b>of</b> the <b>data.</b> In the second method we define a "constrained parameter goodness-of-fit" test statistic, whose p-value we then use to define a "plausibility region" (e. g. where p ≥ 10 %). For any halo function not entirely contained within the plausibility region, the level <b>of</b> <b>compatibility</b> <b>of</b> the <b>data</b> is very low (e. g. p < 10 %). We illustrate these methods by applying them to CDMS-II-Si and SuperCDMS data, assuming dark matter particles with elastic spin-independent isospin-conserving interactions or exothermic spin-independent isospin-violating interactions. Comment: 31 pages, 6 figures. V 2 : Modified several paragraphs to improve clarify. Modified Fig. 5 and added Fig. 6 to further illustrate methods of Section 5. Added proof of uniqueness of best fit halo function in Appendix...|$|R
40|$|Discussions of {{geographic}} interoperability normally address {{two sets of}} issues: syntactic interoperability, {{having to do with}} <b>compatibility</b> <b>of</b> <b>data</b> formats, and semantic interoperability, {{having to do with the}} meaning ascribed to data by the sender and the receiver. In this paper we propose two additional dimensions, both related to data quality: issues associated with data accuracy, and affecting the ability to work with data from sources of different accuracies; and spatial support, having to do with differences of spatial sampling. The case of areal interpolation is explored, and it is shown that all known methods of areal interpolation can be brought within a single, unified framework based on geostatistics, and defined by the assumptions the user is willing to make about a hypothesized, underlying continuous field. Examples are used to illustrate the approach. The nominal case is discussed, and an empirical method presented that also appears to provide some promise in overcoming differences of spatial support. Key words: Interoperability, areal interpolation, accuracy, spatial support. ...|$|E
40|$|This note {{presents}} a model-independent general {{search for new}} phenomena in proton-proton collisions at a centre-of-mass energy of 8 TeV with the ATLAS detector at the LHC. The data set corresponds to a total integrated luminosity of 20. 3. Event topologies involving isolated electrons, photons and muons, as well as jets, including those identified as originating from b-quarks (b-jets) and missing transverse momentum are investigated. The events are subdivided according to their final states into exclusive event classes. For the 697 classes with a Standard Model expectation greater than 0. 1 events, a search algorithm tests the <b>compatibility</b> <b>of</b> <b>data</b> against the Monte Carlo simulated background in three kinematic variables sensitive to new physics effects. Although this search approach is less sensitive than optimized searches for specific models, it provides a more comprehensive investigation for new physics signals. No significant deviation is found in data. The number {{and size of the}} observed deviations follow the Standard Model expectation obtained from simulated pseudo-experiments. ...|$|E
40|$|The European Nutrition and Health Report is {{the first}} {{comprehensive}} assessment of the present status of nutrition and health in Europe, and of the available resources and requirements for compatible and representative data from different countries. 13 EU member states and Norway have participated in this project, pursuing three main goals: * Compilation of available nutrient intake and health data * Identification of major nutrition and health problems * Identification of problems concerning the methods and <b>compatibility</b> <b>of</b> <b>data</b> collection The main topics include food supply and availability, energy and nutrient intake in different age groups, health indicators and status, obesity, physical activity and smoking. The Appendix offers a detailed publication of national reports and single projects. This book provides a solid basis for the planning of future projects in nutrition and health and should be {{of great interest to}} all professionals in the fields of nutrition, preventive medicine and public health as well as to health policy makers...|$|E
40|$|AbstractA {{singularly}} perturbed convection–diffusion problem posed on {{the unit}} square is considered. Its solution may have exponential and parabolic boundary layers, and corner singularities may also be present. Pointwise bounds on the solution and its derivatives are derived. The dependence of these bounds on the small diffusion coefficient, on the regularity <b>of</b> the <b>data,</b> and on the <b>compatibility</b> <b>of</b> the <b>data</b> {{at the corners of}} the domain are all made explicit. The bounds are derived by decomposing the solution into a sum of solutions of elliptic boundary-value problems posed on half-planes, then analyzing these simpler problems...|$|R
40|$|Even today, the {{convergence}} of the decay widths {{and some of the}} Dalitz plot parameters of the η → 3 π decays seems problematic in low energy QCD. We provide an overview of the current experimental and theoretical situation with historical background and summarize our recent results, which explore the question <b>of</b> <b>compatibility</b> <b>of</b> experimental <b>data</b> with a reasonable convergence of a carefully defined chiral series in the framework of resummed chiral perturbation theory. Comment: Presented at "QCD 16 ", Montpellier, France, July 6, 2016. 5 pages, 2 figure...|$|R
40|$|The plasma-wave {{experiment}} ASPI (analysis of {{spectra of}} plasma waves and instabilities) {{on board the}} INTERBALL spacecraft is a combined wave diagnostics experiment. It performs measurements of the DC and AC magnetic field vector by flux-gate and search-coil sensors, the DC and AC electric field vector by Langmuir double probes and the plasma current by Langmuir split probe. Preliminary data analysis shows the low noise levels of the sensors and the <b>compatibility</b> <b>of</b> new <b>data</b> {{with the results of}} previous missions. During several months of in-orbit operation a rich collection <b>of</b> <b>data</b> was acquired, examples of which at the magnetopause and plasma sheet are presented in second part of the paper...|$|R
