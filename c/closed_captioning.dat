420|390|Public
5|$|On 27 January 2014, {{along with}} the Nine Network, NBN {{switched}} from the Supertext logo to Nine's <b>Closed</b> <b>Captioning</b> logo.|$|E
5|$|The rental {{release of}} the film to Netflix, Blockbuster, and Redbox was {{controversial}} since it failed to include <b>closed</b> <b>captioning.</b> Disney faced a consumer backlash over this and quickly released a statement that this removal was an unfortunate error {{and that it was}} moving to correct the issue.|$|E
5|$|In {{the scene}} where Tracy is on his bacon run, every mention of January 17th is either shot so the actor's mouth is hidden or dubbed over. This can be seen most clearly when Cerie says January 17th. It seems the {{original}} was February 17th but later changed to match the release date of the episode. <b>Closed</b> <b>captioning</b> still shows February 17th.|$|E
40|$|Time lagging {{problem is}} needed to be solved when using <b>closed</b> <b>caption</b> {{as a source of}} {{features}} in video indexing. One of solution is aligning <b>closed</b> <b>caption</b> to transcripts then take the time code from transcripts as new references for <b>closed</b> <b>caption.</b> This paper describes a work using limited resources to generate decent alignment results. 1...|$|R
25|$|Windows Media Video {{can support}} <b>closed</b> <b>captions</b> for both {{video on demand}} {{streaming}} or live streaming scenarios. Typically Windows Media captions support the SAMI file format but can also carry embedded <b>closed</b> <b>caption</b> data.|$|R
30|$|The <b>closed</b> <b>caption</b> {{extraction}} modules {{are used}} to convert the <b>closed</b> <b>caption</b> input streams into a sequence of words in BP. The synchronization module is used to synchronize the <b>closed</b> <b>caption</b> input and the LIBRAS window output. As mentioned earlier, it extracts the reference clock from the input and uses it to generate the timestamps for the signs presentation. The machine translation and encoding modules will be detailed in the next subsections.|$|R
5|$|The Search for Spock was {{released}} on home video in 1985. The initial retail offerings included VHS, Betamax, LaserDisc and CED formats with <b>closed</b> <b>captioning.</b> As {{part of a plan}} to support its push of 8mm video cassette, Sony partnered with Paramount Home Video to bring titles like The Search for Spock to the platform in 1986.|$|E
5|$|AMI-tv is a Canadian, English-language, {{digital cable}} {{specialty}} channel {{owned by the}} non-profit organization Accessible Media. AMI-tv broadcasts a selection of general entertainment programming with accommodations {{for those who are}} visually or hearing impaired, with audio descriptions on the primary audio track and <b>closed</b> <b>captioning</b> available across all programming. Along with acquired content, AMI-tv also broadcasts original series on accessibility- and disability-related topics, and has occasionally broadcast simulcasts of news and sporting events in its open described video format—including, since 2012, the Paralympic Games, an offshoot of the Olympic Games for athletes with disabilities.|$|E
5|$|The {{technology}} company Akamai reported that 5,401,250web users logged on news sites {{in less than}} one minute, the fifth highest peak among news websites since the company started tracking data in 2005. During at-peak usage, news websites served seven million simultaneous video streams, which was {{the highest number of}} simultaneous video streams in Akamai's history. The Obama inaugural ceremony not only achieved the highest Internet viewership for a U.S.presidential inauguration, the inaugural event was the first to feature a live audio description of a swearing-in ceremony and the first to include <b>closed</b> <b>captioning</b> in the live webcast of the event.|$|E
30|$|Synchronization between <b>closed</b> <b>caption</b> input in BP and the LIBRAS window {{output is}} {{performed}} {{by using the}} axis-based synchronization model [5]. This model defines synchronization points that are inserted in the stream using timestamps based on a global timer. In this case, the global timer is the reference clock of the <b>closed</b> <b>caption</b> input stream. This clock is extracted from <b>closed</b> <b>caption</b> and is used to generate the presentation timestamps for the signs in the LIBRAS window.|$|R
2500|$|In mid-2009, Apple {{released}} Final Cut Pro version 7 {{and began}} support for inserting <b>closed</b> <b>caption</b> data into SD and HD tape masters via firewire and compatible video capture cards. [...] Up until this time, {{it was not}} possible for video editors to insert caption data with both CEA-608 and CEA-708 to their tape masters. The typical workflow included first printing the SD or HD video to a tape and sending it to a professional <b>closed</b> <b>caption</b> service company that had a stand-alone <b>closed</b> <b>caption</b> hardware encoder.|$|R
30|$|The <b>closed</b> <b>caption</b> {{extraction}} module {{was developed}} based on definitions of ABNT NBR 15606 - 1 [1]. This module receives an MPEG- 2 TS streaming and extracts BP sentences and synchronization information (i.e., timestamps) from <b>closed</b> <b>captions</b> packets. These timestamps are inserted into DSM-CC stream events.|$|R
5|$|National {{legislation}} {{requires that}} all television programmes broadcasts in Croatia {{are made in}} Croatian language or with appropriate translations either using dubbing or subtitling. In general, all foreign programming is subtitled, except for cartoons and narrated parts of documentaries and similar programmes. An attempt to change this was made by Nova TV in 2006, when a soap opera was dubbed, but the move provoked negative response from viewers and critics, causing the experiment to be abandoned. The legislation does not provide for mutually intelligible languages. That led to formal requests made by the Electronic Media Council demanding language localisation of television programmes made in Serbian language. Ultimately, that issue was resolved through subtitling using teletext service normally used for <b>closed</b> <b>captioning.</b>|$|E
5|$|Nikolas Tomas Stauskas (born October 7, 1993) is a Canadian {{professional}} basketball player for the Philadelphia 76ers of the National Basketball Association (NBA). A native of Mississauga, Ontario, Stauskas played two seasons of National Collegiate Athletic Association (NCAA) {{competition for the}} Michigan Wolverines ending with the 2013–14 team before declaring for the NBA draft. Stauskas was drafted eighth overall in the 2014 NBA draft by the Sacramento Kings, for which he began his NBA career. Towards {{the end of his}} rookie season, Stauskas was tagged with the nickname Sauce Castillo after a <b>closed</b> <b>captioning</b> error resulted in a social media meme. Stauskas, whose family is of Lithuanian heritage, {{is a member of the}} Canadian national basketball team.|$|E
5|$|The HDMI {{standard}} {{was not designed}} to pass closed caption data (for example, subtitles) to the television for decoding. As such, any closed caption stream must be decoded and included as an image in the video stream(s) prior to transmission over an HDMI cable to be viewed on the DTV. This limits the caption style (even for digital captions) to only that decoded at the source prior to HDMI transmission. This also prevents closed captions when transmission over HDMI is required for upconversion. For example, a DVD player that sends an upscaled 720p/1080i format via HDMI to an HDTV has no way to pass <b>Closed</b> <b>Captioning</b> data so that the HDTV can decode it, {{as there is no}} line 21 VBI in that format.|$|E
40|$|We {{describe}} {{an approach to}} Machine Translation of transcribed speech, as found in <b>closed</b> <b>captions.</b> We discuss how the colloquial nature and input format peculiarities of <b>closed</b> <b>captions</b> are dealt with in a pre-processing pipeline that prepares the input for effective processing by a core MT system. In particular, we describe components for proper name recognition and input segmentation. We evaluate the contribution of such modules to the system performance. The described methods have been implemented on an MT system for translating English <b>closed</b> <b>captions</b> to Spanish and Portuguese...|$|R
2500|$|Special {{effort has}} been made to build {{accessibility}} features into digital projection systems (see digital cinema). Through SMPTE, standards now exist that dictate how open and <b>closed</b> <b>captions,</b> as well as hearing-impaired and visually impaired narrative audio, are packaged {{with the rest of the}} digital movie. This eliminates the proprietary caption distributions required for film, and the associated royalties. SMPTE has also standardized the communication of <b>closed</b> <b>caption</b> content between the digital cinema server and 3rd-party <b>closed</b> <b>caption</b> systems (the CSP/RPL protocol). As a result, new, competitive <b>closed</b> <b>caption</b> systems for digital cinema are now emerging that will work with any standards-compliant digital cinema server. These newer <b>closed</b> <b>caption</b> devices include cupholder-mounted electronic displays and wireless glasses which display caption text in front of the wearer's eyes. [...] Bridge devices are also available to enable the use of Rear Window systems. As of mid-2010, the remaining challenge to the wide introduction of accessibility in digital cinema is the industry-wide transition to SMPTE DCP, the standardized packaging method for very high quality, secure distribution of digital movies.|$|R
5000|$|ABC, PBS, and Consumer Electronics Association, For <b>closed</b> <b>caption</b> {{standardization}} ...|$|R
25|$|In 2010, Vegas Pro, the {{professional}} non-linear editor, was updated to support importing, editing, and delivering CEA-608 closed captions. Vegas Pro 10, released on October 11, 2010, added several enhancements to the <b>closed</b> <b>captioning</b> support. TV-like CEA-608 <b>closed</b> <b>captioning</b> {{can now be}} displayed as an overlay when played back in the Preview and Trimmer windows, {{making it easy to}} check placement, edits, and timing of CC information. CEA708 style <b>Closed</b> <b>Captioning</b> is automatically created when the CEA-608 data is created. Line 21 <b>closed</b> <b>captioning</b> is now supported, as well as HD-SDI <b>closed</b> <b>captioning</b> capture and print from AJA and Blackmagic Design cards. Line 21 support provides a workflow for existing legacy media. Other improvements include increased support for multiple <b>closed</b> <b>captioning</b> file types, as well as the ability to export closed caption data for DVD Architect, YouTube, RealPlayer, QuickTime, and Windows Media Player.|$|E
25|$|<b>Closed</b> <b>Captioning</b> must be {{available}} on a television {{in order for a}} deaf person to fully appreciate the audio portion of the broadcast. Conflicts arise when establishments such as restaurants, airlines, or fitness centers fail to accommodate deaf people by turning on <b>Closed</b> <b>Captioning.</b> Movie theaters are increasingly compliant with providing visual access to first-run movies through stand-alone devices, glasses and open caption technology which allow deaf people to attend movies as they are released.|$|E
25|$|In the United States, the National Captioning Institute {{noted that}} English {{as a foreign}} or second {{language}} (ESL) learners were the largest group buying decoders in the late 1980s and early 1990s before built-in decoders became a standard feature of US television sets. This suggested that the largest audience of <b>closed</b> <b>captioning</b> was people whose native language was not English. In the United Kingdom, of 7.5 million people using TV subtitles (<b>closed</b> <b>captioning),</b> 6 million have no hearing impairment.|$|E
25|$|QuickTime video {{supports}} raw 608 caption data via proprietary <b>closed</b> <b>caption</b> track, {{which are}} just EIA-608 byte pairs {{wrapped in a}} QuickTime packet container with different IDs for both line 21 fields. These captions can be turned on and off and appear in the same style as TV <b>closed</b> <b>captions,</b> with all the standard formatting (pop-on, roll-up, paint-on), and can be positioned and split anywhere on the video screen. QuickTime <b>closed</b> <b>caption</b> tracks can be viewed in Macintosh or Windows versions of QuickTime Player, iTunes (via QuickTime), iPod Nano, iPod Classic, iPod Touch, iPhone, and iPad.|$|R
5000|$|... 2004: Slang X Generator (Producer, engineer, mixer) - <b>Closed</b> <b>Caption</b> Radio ...|$|R
5000|$|... 2006 [...] "Constant Dreams" [...] (from The UNDC album <b>Closed</b> <b>captioned)</b> ...|$|R
25|$|On 27 January 2014, the Nine Network {{have stopped}} using the Supertext logo and have {{switched}} {{to their own}} <b>Closed</b> <b>Captioning</b> logo.|$|E
25|$|Apple TV {{with and}} without tvOS {{supports}} <b>closed</b> <b>captioning,</b> so the deaf or hard of hearing can experience TV episodes and feature-length movies. Compatible episodes and movies are denoted with a CC (<b>closed</b> <b>captioning)</b> or SDH (subtitles for the deaf or hard-of-hearing) icon in the iTunes Store either on the Apple TV or in iTunes itself. The viewer can customize the captions in episodes or movies with styles and fonts that are more conducive to their hearing and/or visual impairment.|$|E
25|$|Sky News began {{broadcasting}} in widescreen, {{along with}} its sister channels on 17 May 2009. Sky News Australia only provides <b>closed</b> <b>captioning</b> between 4pm and 5pm (AEST/AEDT) each day.|$|E
40|$|<b>Closed</b> <b>captions</b> in {{television}} broadcasts, intended {{to aid the}} hearing impaired, also have potential as training data for speech-recognition software. Use of <b>closed</b> <b>captions</b> for automatic extraction of virtually unlimited training data has already been demonstrated [1]. This paper reports some preliminary work {{on the use of}} non-speech sound tokens included in <b>closed</b> <b>captions</b> to extract training data to augment a speech recognizer's repertoire of non-speech phonemes. A small experiment was performed to pinpoint laughter sounds {{in television}} news broadcasts using the Informedia Digital Video Library's retrieval capabilities, which automatically exploit <b>closed</b> <b>captions.</b> The snippets found were used to retrain a speech recognizer. A small test showed a small but significant gain in performance. In the future we plan to develop this approach into a fully automatic procedure for extracting training data for non-speech sounds. INTRODUCTION Many television broadcasts are accompanied by closed [...] ...|$|R
5000|$|Access Award - Visual Music: Expanding on <b>Closed</b> <b>Caption</b> Television, Producer: Gregg A. Brokaw ...|$|R
5000|$|Shin-Joh by Alistair Abell (English) a stone-cutter (spelled Shinjo and Shinjoh in <b>closed</b> <b>captions)</b> ...|$|R
25|$|On February 20, 2014, the FCC {{unanimously}} {{approved the}} implementation of quality standards for <b>closed</b> <b>captioning,</b> addressing accuracy, timing, completeness, and placement. This {{is the first time}} the FCC has addressed quality issues in captions.|$|E
25|$|The {{technology}} {{works by}} adding additional {{lines to the}} video signal. In the NTSC video standard, blank lines (vertical blanking intervals) that the user cannot see are used for functions like <b>closed</b> <b>captioning.</b> Rovi Corporation uses these blank lines to implement its ACP technology.|$|E
25|$|The text can be {{displayed}} {{instead of the}} television image, or superimposed on it (a mode commonly called mix). Some pages, such as subtitles (<b>closed</b> <b>captioning),</b> are in-vision, meaning that text is displayed in a block on the screen covering part of the television image.|$|E
25|$|High-definition disc media (HD DVD, Blu-ray Disc) uses SDH {{subtitles}} as {{the sole}} method because technical specifications do not require HD to support line 21 <b>closed</b> <b>captions.</b> Some Blu-ray Discs, however, are said to carry a <b>closed</b> <b>caption</b> stream that only displays through standard-definition connections. Many HDTVs allow the end–user to customize the captions, including the ability to remove the black band.|$|R
30|$|The LIBRAS {{translator}} {{is responsible}} for translating the source input stream (i.e., the <b>closed</b> <b>caption</b> stream) into a textual representation in LIBRAS (sequence of glosses) and for encoding this representation along with synchronization information to be transmitted in a communication channel. According to Fig.  1, it is composed of four basic modules: <b>closed</b> <b>caption</b> extraction, machine translation, synchronization and encoding.|$|R
50|$|High-definition disc media (HD DVD, Blu-ray Disc) uses SDH {{subtitles}} as {{the sole}} method because technical specifications do not require HD to support line 21 <b>closed</b> <b>captions.</b> Some Blu-ray Discs, however, are said to carry a <b>closed</b> <b>caption</b> stream that only displays through standard-definition connections. Many HDTVs allow the end-user to customize the captions, including the ability to remove the black band.|$|R
