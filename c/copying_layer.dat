1|24|Public
40|$|The {{most common}} {{printing}} technique today is lithography. The difference between printing and nonprinting areason a printing plate {{is accomplished by}} opposite {{physical and chemical properties}} of those areas (MacPhee, 1998). The printing areas are made of photoactive layer that attracts oil and chemical substances with oil solvent – printinginks. The nonprinting areas are made of aluminium-oxide which attracts water based substances – the fountainsolution. There are many of various types of photoactive layer which are used for production of offset printing plates, amongothers is silver halide layer. The usage of the silver halide technology in the graphic reproduction is not a novelty. The filmmaking phase is based on the usage of the silver halide as the photographically active ingredient, for instance,AgBr (silver bromide). The new, digital plate making technology (Computer to Plate, CtP) eliminates thefilmmaking phase and therefore enables control of the printing plate’s exposure made by computer. CtP technologyeliminates the filmmaking phase, but it also results with the reduction of needed material quantities and requiredtime for the production (Limburg, 1994; Seydel, 1996). In this paper the basis of the graphic reproduction by using the silver halide digital printing plates was described. The changes of the AgX <b>copying</b> <b>layer</b> and the surface of the aluminium base in the printing process have beenobserved. The surface characteristics were determined by measuring the relevant surface roughness parameters. Inaddition, measurements of coverage values on the prints, detailed at smaller print run, were conducted. Results showed that surface changes on the printing plate are changing during printing process and that thesechanges influence transfer of the printing ink on the printing substrate. These measurements proved to be of greatinterest in the graphic reproduction as they enable us to determine consistency of the printing plates during theprinting process, to predict the endurance as well as to define the print run which will result with optimal qualityprints...|$|E
3000|$|... where I is the {{identity}} matrix. Since interlayer edges only connect each vertex to its <b>copy</b> across <b>layers,</b> we use {{the identity}} matrix for off-diagonal blocks.|$|R
40|$|We {{study the}} effect of {{interlayer}} tunneling in the gauge theory describing a quasitwo-dimensional paramagnetic metal close to a second-order or weakly first-order antiferromagnetic phase boundary. In that theory, two species of fermions have opposite (rather than equal) charges {{with respect to the}} gauge field. We find that single-particle interlayer tunneling is suppressed at low energies. The effect of pair tunneling is analyzed within the (3 − d) expansion. The resulting phase diagram has superconducting and non-Fermi-liquid normal phases, and so is compatible with that of the copper-oxide superconductors. 1 Recently, a non-trivial fixed point and the associated non-Fermi-liquid behavior have been found for a system of two-dimensional (2 d) fermions interacting with a transverse gauge field [1]–[4]; see also [5]–[10]. The idea of non-Fermi-liquid metal has long been proposed [11] to apply to the copper-oxide superconductors. In that case, a study of interactions between two <b>copies</b> (<b>layers)</b> of such 2 d systems is important for at least two reasons. First, the real materials are three-dimensional and one would like t...|$|R
40|$|Atorvastatin {{is one of}} the statins {{which is}} used as the first line therapy for hyperlipidemia. The patent of {{atorvastatin}} innovator ended in 2011. Besides the innovator brand of atorvastatin, several brand and one generic atorvastatin tablet are currently marketed in Indonesia. In this research, dissolution profiles, assay and physical quality were investigated for three atorvastatin tablet samples consist of one innovator sample, two atorvastatin <b>copy</b> <b>layer</b> products (branded generic atorvastatin sample and atorvastatin generic sample). The dissolution testing were done using FDA (Food and Drug Administration) method. The result shows that the innovator and branded generic samples meet all the requirements for physical quality, meanwhile the generic sample failed to meet the disintegration test criteria. The branded generic sample has similar dissolution profile with the innovator, while the generic tablet was not similar. The assay were conducted using High Performance Liquid Chromatography (HPLC) method. The assay result of the innovator, branded generic, and generic samples respectively were 97, 54 %, 106, 36 % and 97, 65 % which means that all samples comply with general requirement of active pharmaceutical ingredient in tablet. </em...|$|R
40|$|We {{describe}} an architecture for invariant visual detection and recognition. Learning is {{performed in a}} single central module. The architecture makes use of <b>copies</b> of retinotopic <b>layers</b> of local features, with a particular design of inputs and outputs, {{that allows them to}} be primed either to attend to a particular location, or to attend to a particular object representation. In the forme...|$|R
40|$|Object {{recognition}} {{is important to}} understand the content of video and allow flexible querying in a large number of cameras, especially for security applications. Recent benchmarks show that deep convolutional neural networks are excellent approaches for object recognition. This paper describes an approach of domain transfer, where features learned from a large annotated dataset are transferred to a target domain where less annotated examples are available as is typical for the security and defense domain. Many of these networks trained on natural images appear to learn features similar to Gabor filters and color blobs in the first layer. These first-layer features appear to be generic for many datasets and tasks while the last layer is specific. In this paper, we study the effect of <b>copying</b> all <b>layers</b> and fine-tuning a variable number. We performed an experiment with a Caffe-based network on 1000 ImageNet classes that are randomly divided in two equal subgroups for the transfer from one to the other. We <b>copy</b> all <b>layers</b> and vary the number of layers that is fine-tuned {{and the size of the}} target dataset. We performed additional experiments with the Keras platform on CIFAR- 10 dataset to validate general applicability. We show with both platforms and both datasets that the accuracy on the target dataset improves when more target data is used. When the target dataset is large, it is beneficial to freeze only a few layers. For a large target dataset, the network without transfer learning performs better than the transfer network, especially if many layers are frozen. When the target dataset is small, it is beneficial to transfer (and freeze) many layers. For a small target dataset, the transfer network boosts generalization and it performs much better than the network without transfer learning. Learning time can be reduced by freezing many layers in a networ...|$|R
40|$|Is it {{possible}} to create a simple physical system {{that is capable of}} replicating itself? Can such a system evolve interesting behaviors, thus allowing it to adapt {{to a wide range of}} environments? This paper presents a design for such a replicator constructed exclusively from synthetic DNA. The basis for the replicator is crystal growth: information is stored in the spatial arrangement of monomers and <b>copied</b> from <b>layer</b> to layer by templating. Replication is achieved by fragmentation of crystals, which produces new crystals that carry the same information. Crystal replication avoids intrinsic problems associated with template-directed mechanisms for replication of one-dimensional polymers. A key innovation of our work is that by using programmable DNA tiles as the crystal monomers, we can design crystal growth processes that apply interesting selective pressures to the evolving sequences. While evolution requires that copying occur with high accuracy, we show how to adapt error-correction techniques from algorithmic self-assembly to lower the replication error rate as much as is required...|$|R
30|$|Since all {{the edges}} are undirected, each hidden layer nodes except {{those in the}} last hidden layer of the DBM accept signals from the upper and the lower layer nodes as {{indicated}} in Eq. (32). Hence, the training algorithm must account for the top-down and the bottom-up interaction terms while learning the parameters of DBM. With this objective, Salakhutdinov and Hinton [25] modified {{the structure of the}} RBMs in the entire stack before the actual training begins. For instance, the following changes have been made to the structure of RBMs while training a DBM with three hidden layers as shown in Fig.  5 b. Initially, the first layer RBM is altered to have two <b>copies</b> of visible <b>layer</b> nodes along with tied weights. The newly added visible layer nodes compensate for the lack of top-down interaction terms from the second layer. Similarly, the structure of the third layer RBM is modified {{in such a way that}} it involves two <b>copies</b> of hidden <b>layer</b> units h^(3) and the respective weight matrix W^(3) to compensate for the lack of bottom-up interactions from RBM- 2. For the intermediate layer, the RBM is restructured such that only the connection strengths W^(2) are doubled. Salakhutdinov and Hinton [25] were able to show that the layer-wise training of DBM with this type of structural modification is guaranteed to yield optimal values for the model parameters.|$|R
40|$|Multilayer and {{multiplex}} networks {{represent a}} good proxy for {{the description of}} social phenomena where social structure is important and can have different origins. Here, we propose a model of opinion competition where individuals are organized according to two different structures in two layers. Agents exchange opinions according to the Abrams-Strogatz model in each layer separately and opinions can be <b>copied</b> across <b>layers</b> by the same individual. In each layer a different opinion is dominant, so each layer has a different absorbing state. Consensus in one opinion {{is not the only}} possible stable solution because of the interaction between the two layers. A new mean field solution has been found where both opinions coexist. In a finite system there is a long transient time for the dynamical coexistence of both opinions. However, the system ends in a consensus state due to finite size effects. We analyze sparse topologies in the two layers and the existence of positive correlations between them, which enables the coexistence of inter-layer groups of agents sharing the same opinion...|$|R
40|$|In layered P 2 P {{streaming}} system, how {{to allocate}} {{number of the}} <b>copies</b> for each <b>layer</b> is a challenging problem. In this paper, we present a substream allocation scheme in layered P 2 P streaming. The proposed allocation scheme is adaptive to the request rate and number of the qualified peers. The simulation {{results show that the}} proposed allocation scheme enables the system to achieve an overall better quality compared to the general allocation schemes with fixed allocation percentages. In addition, the proposed allocation scheme can accelerate the growth of peer population in the initial stage of hybrid P 2 P streaming systems. 1...|$|R
30|$|From Fig. 4 we can see, when ω = 0, {{the layers}} show great {{divergence}} {{due to the}} value of resolution parameter γ _s. As γ _s grows, the network is inclined to split into subcommunities. By comparing with standard community label, we see the detection result with parameter γ _s setting from 0.5 to 0.9 matches the ground truth, while there are misclassifications in the rest. As ω increases, we see the nodes in different layers tend to be assigned to the same community. When ω = 1, we see that every node has the same community label as its <b>copies</b> in other <b>layers,</b> and the detection result consistent with the ground truth.|$|R
40|$|This paper {{describes}} a large set of electricity {{data for the}} IEEE 24 bus system generated on a test bed that <b>copies</b> the cyber <b>layer</b> of the electricity infrastructure in some detail. This data has been filtered and corrupted with natural noise and a realistic set of failure-induced and attack-induced corruptions. One of the main applications of this data {{is the development of}} novel anomaly-detecting techniques, which could {{play a vital role in}} the identification and repair of problems in the cyber layer of the electricity infrastructure. To encourage work in this area, this data is made freely available online. electricity data; critical infrastructure protection; electric power systems; critical infrastructure vulnerabilities; anomaly detection; state estimation; SCADA; artificial ants; invariants; artificial immune systems; electricity infrastructure...|$|R
40|$|Abstract — The {{commercial}} success of Cloud computing and {{recent developments in}} Grid computing have brought platform virtualization technology into the field of high performance computing. Virtualization offers both more flexibility and security through custom user images and user isolation. In this paper, {{we deal with the}} problem of distributing virtual machine (VM) images to a set of distributed compute nodes in a Cross-Cloud computing environment, i. e., the connection of two or more Cloud computing sites. Ambrust et al. [3] identified data transfer bottlenecks as one of the obstacles Cloud computing has to solve to be a {{commercial success}}. Several methods for distributing VM images are presented, and optimizations based on <b>copy</b> on write <b>layers</b> are discussed. The performance of the presented solutions and the security overhead is evaluated. I...|$|R
40|$|International audienceThis paper {{proposes a}} {{functional}} management architecture for Cognitive Radio systems. It {{relies on a}} previously defined configuration management architecture for multi-standard SDR systems, and complement it to support cognitive radio features. This paper explains the requirements of Cognitive Radio systems in terms of reconfiguration, smartness and sensing capabilities. A configuration management architecture capable {{of dealing with the}} hardware heterogeneity and a wide range of reconfiguration scenarios expected with SDR systems is presented. The management is distributed over the system and a hierarchical dependency is set on 3 layers, each having a different level of knowledge of the system and the associated hardware constraints of the elements it supervises. Then a cognitive management functional architecture is derived from the previous one, <b>copying</b> the 3 <b>layers</b> of hierarchy. The roles of the elements of each layer are discussed, as well as their respective interactions and their relationships with the elements of the configuration management architecture...|$|R
40|$|Abstract—This paper {{proposes a}} {{functional}} management architecture for Cognitive Radio systems. It {{relies on a}} previously defined configuration management architecture for multi-standard SDR systems, and complement it to support cognitive radio features. This paper explains the requirements of Cognitive Radio systems in terms of reconfiguration, smartness and sensing capabilities. A configuration management architecture capable {{of dealing with the}} hardware heterogeneity and a wide range of reconfiguration scenarios expected with SDR systems is presented. The management is distributed over the system and a hierarchical dependency is set on 3 layers, each having a different level of knowledge of the system and the associated hardware constraints of the elements it supervises. Then a cognitive management functional architecture is derived from the previous one, <b>copying</b> the 3 <b>layers</b> of hierarchy. The roles of the elements of each layer are discussed, as well as their respective interactions and their relationships with the elements of the configuration management architecture. Index Terms—cognitive radio, cognitive management, configuration management, multi-standard termina...|$|R
40|$|AbstractWe {{describe}} an architecture for invariant visual detection and recognition. Learning is {{performed in a}} single central module. The architecture makes use of a replica module consisting of <b>copies</b> of retinotopic <b>layers</b> of local features, with a particular design of inputs and outputs, {{that allows them to}} be primed either to attend to a particular location, or to attend to a particular object representation. In the former case the data at a selected location can be classified in the central module. In the latter case all instances of the selected object are detected in the field of view. The architecture is used to explain a number of psychophysical and physiological observations: object based attention, the different response time slopes of target detection among distractors, and observed attentional modulation of neuronal responses. We hypothesize that the organization of visual cortex in columns of neurons responding to the same feature at the same location may provide the copying architecture needed for translation invariance...|$|R
40|$|As Ethernet {{hardware}} bandwidth {{increased to}} Gigabit speeds it became evident {{that it was}} difficult for conventional messaging protocols to deliver this performance to the application layer. Kernel based protocols such as TCP/IP impose a significant load on the host processor in order to service incoming packets and pass them to the application layer. Under heavy loads this problem can also lead to the host processor being completely used up for processing incoming messages, thus starving host applications of CPU resources. Another problem suffered by inter-process communication using small messages is the latency imposed by memory-to-memory <b>copying</b> in <b>layered</b> protocols as well as the slow context switching times in kernel-level schedulers required for servicing incoming interrupts. All this has put pressure on messaging software which {{led to the development of}} several lower latency userlevel protocols specifically adapted to high-performance networks (see U-Net[18], EMP[16], VIA[3], QsNET[15], Active Messages[19], GM[13], FM[14]). The aim of this paper is to investigate the issues involved in building high performance cluster messaging systems. We will also review some of the more prominent work in the area as well as propose a low-overhead low-latency messaging system to be used by a cluster of commodity platforms running over Gigabit Ethernet. We propose to use the programmable Netgear GA 620 -T NICs and modify their firmware to design a lightweight reliable OS-bypass protocol for message passing. We propose the use of zero-copy and polling techniques in order to keep host CPU utilization to a minimum whilst obtaining the maximum bandwidth possible. peer-reviewe...|$|R
30|$|De Domenico et al. {{extended}} the well-known infomap method (Rosvall and Bergstrom 2008) to the multilayer case (De Domenico and Lancichinetti 2015). The infomap method solves the community detection problem by considering its duality with a coding problem. It {{assumes that the}} community is able to capture the flows on the network so that by utilizing the community structure, we can greatly compress the coding length needed to describe a random process on the network (Rosvall and Bergstrom 2008). The goal is to minimize the “map equation,” which describes the coding length based on a specific partition and the transition probability of the random process. De Domenico et al. defined the transition probability of a random walker in multilayer networks so that the map equation is able to describe the flow in multilayer scenarios. Such treatment is intuitively correct, albeit they assume the node can reach the neighbors of its <b>copies</b> in other <b>layers</b> in a single step. In fact this implicitly erases the difference between layers—it is equivalent to consider a collapsed network.|$|R
30|$|The hole depth (black squares) {{stays at}} quasi {{unchanged}} {{for the first}} 20  nm of AlGaAs deposition. Only for larger AlGaAs layer thickness, the depth reduces continuously and the hole gets shallower. This supports our statement that thin AlGaAs <b>layers</b> <b>copy</b> the underlying morphological structure—an effect observed before and ascribed to the low diffusion coefficient of AlGaAs on a GaAs surface [40]. As pointed out during {{the discussion of the}} AFM images in Fig.  1 a–d, the hole morphology (as well as the mound morphology) undergoes an asymmetric filling. This is reflected in the shape aspect ratio (black squares) plotted in Fig.  1 e. The hole aspect ratio is nearly 1 for the unfilled holes and stays close to 1 for a hole filling up to 5  nm. Then it continuously drops to lower values indicating that the hole gets smaller in the [1 – 10] direction due to the mound growth in this direction. We attribute this behavior to a preferred material diffusion and accumulation in this crystal direction.|$|R
40|$|This paper proposes an {{efficient}} error concealment method for SNR scalable coded video. The algorithm adaptively selects a proper concealment candidate {{from the base}} or the enhanced pictures to conceal the artifact of a lost enhancement block. To determine the best concealment candidate, we propose a trial {{process in which the}} concealment candidates are examined based on two criteria: 1) picture continuity at the border of concealed macroblocks, and 2) to satisfy the coding distortion bound of the base layer coefficients when they are available. For the latter, requantization of the concealed picture with the base layer quantizer step size and its dequantized pixels should result in zero distortion. We have implemented the method on a proposed SNR scalable H. 264 video codec and compared the decoded video quality against just <b>copying</b> the base <b>layer</b> pixels into the enhanced picture. Simulation results show that the proposed method can achieve a considerable improvement by up to 3 dB especially in situations where the enhancement layer contains {{a large portion of the}} picture information. This will make scalable video transmission more successful over unreliable channels. Key words: Error/Loss concealment, SNR scalability. ...|$|R
30|$|During {{the process}} of {{exploring}} the multilayer networks, different network models have been proposed (Mucha et al. 2010; Boccaletti et al. 2014; Kivelä et al. 2014). Mucha et al. (2010) linked multiple single-layer networks with couplings, which refer to the edges that connect the nodes with their <b>copies</b> in different <b>layers,</b> to represent a multilayer network. This model allows the layers to communicate through the couplings and is widely adopted especially by research involving dynamics defined on multilayer networks (De Domenico et al. 2013; Gomez et al. 2013). De Domenico et al. (2013) proposed a multilayer model based on tensor representation, which no longer restrains the between-layer connection to appear between node-copy pairs. In {{the rest of this}} paper, we will use between-layer edges to refer to this kind of connections that link a node with another node in different layers. On the one hand, the presence of between-layer edges makes the network more flexible. But on the other hand, a multilayer network with between-layer edges is very similar to a single-layer network in structure since they both have no limitations on the presence of edges (any node in any layer is allowed to link with another node in another layer). This will sometimes blur the boundary between single-layer and multilayer networks.|$|R
30|$|Although {{there is}} {{actually}} no consensus on its definition, a community usually refers {{to a group of}} nodes that are compactly connected with each other and sparsely connected with those nodes outside the group. By partitioning a network into communities, we obtain its community structure, which is a coarse-grained representation of the network that assists us analyzing the roles played by each node (Fortunato 2010). Despite numerous studies on multilayer networks in recent years, there is still a lack of evaluation metrics for measuring the community structure of a multilayer network, which in turn limits the number of available algorithms to find the optimal community structure in multilayer networks. Existing evaluation metrics in multilayer networks are mainly derived from “single-layer” cases, where the evaluation metrics are designed to detect modular structures in conventional networks that can be represented simply with nodes and edges, e.g., edge centrality, clustering coefficient, and metrics based on dynamic process (Battiston et al. 2013; Bródka et al. 2010; De Domenico et al. 2013; Lambiotte and Rosvall 2012; Kivelä et al. 2014; De Domenico and Lancichinetti 2015). In such methods, detections are applied independently on each layers before final assignment, or on a “collapsed network” which is a single-layer network generated by aggregating the layers (Peixoto 2015). Such treatment is intuitive to find an “average” role played by a node in different layers, but somehow fails to treat the multiple layers fundamentally as a whole. Mucha et al. 2010, proposed a modularity-based metric for multilayer network community structure derived from a Laplacian dynamic. To the best of our knowledge, they for the first time introduce couplings to the multilayer network models, which are links that appear between layers and connect a node with its <b>copy</b> in other <b>layers,</b> to combine the layers and form an interconnected-layer network model. Based on such an interconnected-layer structure, the generalized modularity is able to evaluate the community structure without any compression or loss of the information encoded in the multilayer networks.|$|R
40|$|The {{purpose of}} this thesis is to offer a new and {{coherent}} interpretation – a ‘reconstruction’ – of the cosmopolitical idea of humankind which is set out in Nemesius of Emesa's conspectus of ancient anthropology, De Natura Hominis (ca 390 CE). The Stoics held that "the world is governed by divine will, {{and that it is}} like a city and a polity of which both men and gods are citizens. " This Hellenistic cosmopolitical theory implied that "all other things were generated for the sake of humans and gods," and that "human nature" (natura hominis) subsists "like a code of civil law [...] . between human persons and the human species, so that the one who observes this code will be just, and the one who departs from it, unjust" (Cicero Fin. III 62 – 67). Now, Nemesius rejects numerous Stoic tenets in the Nat. Hom., and his 'world city' is not theirs. For instance, Nemesius holds that “those commit sin (ἁμαρτάνουσι) who mistreat irrational creatures”; whereas one of the Stoic tenets is a cold assertion that “no right” – which is to say, no form of obligation – “exists between humans and beasts” (homini nihil iuris esse cum bestiis). The intent of the present thesis is thus by no means to suggest that Nemesius’ idea of humankind is in a doctrinal sense Stoic. Nemesius twice calls the Platonists “the wisest of the Hellenes,” yet his world city is not purely Platonic (or Neoplatonic). The bishop of Emesa criticizes aspects of the Platonic world city – as set out in the Timaeus – in Nat. Hom. 2, and he returns to this critique in Nat. Hom. 38. Nevertheless, for Nemesius – as for Plato – the human person is a natural-born citizen of the world who is imputable, because free, and who is in communion with the whole of creation – and indeed with the Demiurge, since humankind is a “child of God” (θεοῦ τέκνον). It is argued in this thesis that Nemesius opens the Nat. Hom. with an elaborate description of divine creation as οἰκείωσις (in chapter 2), and that he closes his text with a highly structured defence of divine providence as διοίκησις (in chapter 5). Nemesius’ theory of body and soul turn upon the soul’s power to ‘conquer’ the body’s mixtures (in chapter 3), and the human body is itself devised like a city in which reason is to govern the organs of spirit and desire (in chapter 4). Nemesius writes in Nat. Hom. 1 that humankind is “by nature … a political animal,” and his description of humankind is thoroughly political. It is the idea of a ‘world city’, it is claimed here – a world that is made for the ‘political animal’ to inhabit – which gives structural and conceptual unity to the Nat. Hom. Wherever this idea may have originated, it is the world city idea which permits us to reconstruct Nemesius’ text as a formal unity. Without denying or diminishing Nemsius' habit of <b>copying</b> and paraphrasing, <b>layering</b> and interlacing others’ texts (and fragments), the fact that Nemesius offers a systematic account of human nature – its substance (Nat. Hom. 2 – 5), its powers (Nat. Hom. 6 – 28), and its acts (Nat. Hom. 29 – 43) – in light of the world city idea is what separates him decisively from the ‘servile copyist’ or ‘vulgar compiler’ that he tended to be in the eyes of 19 th and 20 th-century source-critical scholars. If the reconstruction offered here is correct, Nemesius’ horizons are broad and his basic intuitions deep. The status of the ‘person’ – which is to say, the ontological status of a legal and juridical ‘subject’ – is the decisive anthropological question in the Nat. Hom. The basic question of humanity therefore concerns the principle of imputability. Are we free? (“A city,” says Aristotle, “is a communion of the free. ”) And thus, can we be innocent and guilty? This is a question which orients some of the most recent contributions to philosophical anthropology, and which unsettles the discipline. It is not unthinkable that a renewed encounter with Nemesius’ text could help us to face it with greater honesty and acuity. status: publishe...|$|R

