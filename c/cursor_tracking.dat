13|18|Public
50|$|Version 1 of the {{extension}} included Save Set processing changes (to make embedding applications more reliable), selection notification events (add events sent when selection ownership is asserted) and <b>cursor</b> <b>tracking</b> (requests allowing {{the image to}} be tracked reliably).|$|E
50|$|Mouse {{tracking}} (also {{known as}} <b>cursor</b> <b>tracking)</b> {{is the use}} of software to collect users' mouse cursor positions on the computer. This goal is to automatically gather richer information about what people are doing, typically to improve the design of an interface. Often this is done on the Web and can supplement eye tracking in some situations.|$|E
40|$|<b>Cursor</b> <b>tracking</b> data {{contains}} {{information about}} website visitors which may provide {{new ways to}} understand visitors and their needs. This paper presents an Amazon Mechanical Turk study where participants were tracked as they used modified variants of the Wikipedia and BBC News websites. Participants {{were asked to complete}} reading and information-finding tasks. The results showed {{that it was possible to}} differentiate between users reading content and users looking for information based on cursor data. The effects of website aesthetics, user interest and cursor hardware were also analysed which showed it was possible to identify hardware from cursor data, but no relationship between cursor data and engagement was found. The implications of these results, from the impact on web analytics to the design of experiments to assess user engagement, are discussed. Comment: Mouse, <b>Cursor,</b> <b>Tracking,</b> Engagement, Involvement, Aesthetics, Self-report Measure, Experimental Desig...|$|E
50|$|Shock Wave Flash {{is useful}} to create {{multimedia}} presentation.Bhatkhande's notation, moving <b>cursor</b> and voice <b>track</b> can be synchronized to obtain swf file.|$|R
40|$|The {{effects of}} cursor configuration, size, and {{orientation}} {{on the performance}} of 11 commercial airline pilots were investigated in a difficult compensatory tracking task in a moving-base aircraft simulator. Three levels of congruent cab motion (0, 1, and 2 times the visual motion) were superimposed on the tracking task. Data analysis of the mean tracking error scores revealed no significant effects of cursor size, orientation, or configuration on pilots' tracking performance. Mean tracking error did not significantly differ between the three levels of motion for the conditions with a single dot as the cursor. However, for the dotted and solid line <b>cursors,</b> <b>tracking</b> error significantly decreased from the no motion condition to the motion conditions. The addition of simulator motion significantly reduced tracking error for large cursors, but not for small ones such as a single do...|$|R
50|$|A Stream {{access method}} is an {{instance}} of use of a stream file by a single client. A <b>cursor</b> keeps <b>track</b> {{of the position of}} the current byte of the sub-stream in use by the client. Using various SET commands, the cursor can be made to point to the beginning or end of the file, to any specific position in the file, or to any positive or negative offset from the current position.|$|R
30|$|When {{reporting}} statistical {{results in}} the next section, we present details of the F-ratio and the degrees of freedom from which it was calculated, the effect size η ^ 2, and the p value. Finally, since <b>cursor</b> <b>tracking</b> information was collected by MouseFlow, we inspected the heatmaps generated by this tool. This was done for every individual page to attain {{an understanding of the}} summarised cursor movements on these pages. Analysis and conclusions pertaining to this data were based on our visual interface.|$|E
40|$|Think Aloud is cost effective, {{promises}} {{access to}} the user’s mind and is the applied usability technique. But "keep talking" is difficult, besides, the multimodal interface is visual not verbal. Eye-tracking seems {{to get around the}} verbalisation problem. It captures the visual focus of attention. However, it is expensive, obtrusive and produces huge amount of data. Besides, eye-tracking do not give access to user’s mind. Capturing interface/cursor tracking may be cost effective. It is easy to install, data collection is automatic and unobtrusive and replaying the captured recording to the user and probing about her actions and thoughts open for participatory analysis. Keywords usability test, cost effective, unobtrusive, TA, eye and <b>cursor</b> <b>tracking,</b> user experience, participatory analysi...|$|E
40|$|Understanding how users examine result pages {{across a}} broad range of {{information}} needs is critical for search engine design. Cursor movements can be used to estimate visual attention on search engine results page (SERP) components, including traditional snippets, aggregated results, and advertisements. However, these signals can only be leveraged for SERPs where <b>cursor</b> <b>tracking</b> was enabled, limiting their utility for informing the design of new SERPs. In this work, we develop robust, log-based mouse movement models capable of estimating searcher attention on novel SERP arrangements. These models can help improve SERP design by anticipating searchers ’ engagement patterns given a proposed arrangement. We demonstrate the efficacy of our method using a large set of mouse-tracking data collected from two independent commercial search engines...|$|E
40|$|Abstract — We used visuomotor {{tracking}} as our motor {{task and}} studied how subjects learn {{to adjust for}} inversion {{of the relation between}} joystick movement and target movement. This task requires learning a novel sensorimotor transforma-tion. We have measured tracking performance and pupil dila-tion simultaneously. We have used pupil dilation as a measure of cognitive load, since the diameter of the human pupil in-creases with task difficulty across a wide range of cognitive tasks. Subjects observed a target moving at constant velocity along a clockwise circular trajectory on a computer screen. Subjects held a joystick in their hand, and moved it so that a <b>cursor</b> <b>tracked</b> the target as closely as possible. 60 normal subjects participated in the experiment. During 6 blocks of learning, inversion-evoked tracking error and inversion-evoked pupil dilation both decreased significantly. This finding suggests increasing automatization of the to-be-learned sen-sorimotor transformation. Pupil measures were not correlated with tracking error on individual trials, suggesting that the inversion-evoked cognitive load reflects changes in motor task, and is not merely a response to high errors. Our results thus suggest a relatively direct physiological measure of the proc-esses of motor-skill automatization...|$|R
40|$|Processing user {{interaction}} data is well-known to be cumbersome and mostly time-consuming, specially {{when it comes}} to web browsing behavior analysis. Current tools usually display {{user interaction}}s as mouse <b>cursor</b> <b>tracks,</b> a video-like visualization scheme that allows researchers to easily inspect what is going on behind the gathered data. However, to date, traditional online video inspection has not explored the full capabilities of hypermedia and interactive techniques. In response to this need, we have developed SMT 2 ǫ, a web-based tracking system to analyze browsing behavior using feature-rich hypervideo visualizations. We compare our system to related work in academia and industry, showing that ours features unprecedented visualization capabilities. We also show that SMT 2 ǫ efficiently captures browsing data, and is perceived to be helpful and easy to use. A series of prediction experiments illustrate that raw cursor data are both accessible and easily manipulable, providing evidence that the data can be used to construct and verify hypotheses. Considering its limitations, it is our hope that SMT 2 ǫ will assist researchers, usability practitioners, and other professionals interested in understanding how users browse the Web...|$|R
50|$|In {{order to}} provide a {{seamless}} and intuitive experience for the user, the extension technique <b>tracks</b> <b>cursor</b> movements and continuously extrapolates a second ahead based on its position and velocity, predicting where highlights might be made over an image. The Project Naptha software then scans and runs a processor-intensive character recognition algorithms, processing potential text that users might want to pick out from an image, ahead of time.|$|R
30|$|The {{study was}} {{launched}} on May 2015 {{and over a}} period of a month we gathered participants’ information. Our recruitment drive mainly involved advertising the study through social media and email, using research and industrial contacts. In the study itself, we collected the following data: participant demographics and user-related data; responses to the questions regarding the presented images; time spent on each page; the cursor movement on these pages; and optionally, email addresses if participants wished to receive the study’s results and further details about phishing prevention. As mentioned, the <b>cursor</b> <b>tracking</b> information was gathered and stored by a third party tool (MouseFlow) and allowed us to collect more quantitative information related to participants page actions. This study received ethical clearance from the University of Oxford Research Ethics Committee to be conducted.|$|E
40|$|Complex spikes {{generated}} in a cerebellar Purkinje cell via a climbing fiber have been assumed to encode {{errors in the}} performance of neuronal circuits involving Purkinje cells. To reexamine this notion, in this review I analyzed structures of motor control systems involving the cerebellum. A dichotomy was found between the two types of error: sensory and motor errors play roles in the feedforward and feedback control conditions, respectively. To substantiate this dichotomy, here in this article I reviewed recent data on neuronal connections and signal contents of climbing fibers in the vestibuloocular reflex, optokinetic eye movement response, saccade, hand reaching, <b>cursor</b> <b>tracking,</b> as well as some other cases of motor control. In our studies, various sources of sensory and motor errors were located in the neuronal pathways leading to the inferior olive. We noted that during the course of evolution, control system structures involving the cerebellum changed rather radically from the prototype seen in the flocculonodular lobe and vermis to that applicable to the cerebellar hemisphere. Nevertheless, the dichotomy between sensory and motor errors is maintained...|$|E
40|$|Understanding {{how people}} {{interact}} with search engines {{is important in}} improving search quality. Web search engines typically analyze queries and clicked results, but these actions provide limited signals regarding search interaction. Laboratory studies often use richer methods such as gaze tracking, but this is impractical at Web scale. In this paper, we examine mouse cursor behavior on search engine results pages (SERPs), including not only clicks but also cursor movements and hovers over different page regions. We: (i) report an eye-tracking study showing that cursor position {{is closely related to}} eye gaze, especially on SERPs; (ii) present a scalable approach to capture cursor movements, and an analysis of search result examination behavior evident in these large-scale cursor data; and (iii) describe two applications (estimating search result relevance and distinguishing good from bad abandonment) that demonstrate the value of capturing cursor data. Our findings help us better understand how searchers use cursors on SERPs and can help design more effective search systems. Our scalable <b>cursor</b> <b>tracking</b> method may also be useful in non-search settings...|$|E
40|$|A visuo-haptic {{augmented}} reality (VHAR) interface is presented enabling an operator to teleoperate an {{unmanned aerial vehicle}} (UAV) equipped with a custom CdZnTe-based spectroscopic gamma-ray detector in outdoor environments. The task is to localize nuclear radiation sources, whose location is unknown to the user, without the close exposure of the operator. The developed detector also enables identification of the localized nuclear sources. The aim of the VHAR interface {{is to increase the}} situation awareness of the operator. The user teleoperates the UAV using a 3 DOF haptic device that provides an attractive force feedback around the location of the most intense detected radiation source. Moreover, a fixed camera on the ground observes the environment where the UAV is flying. A 3 D {{augmented reality}} scene is displayed on a computer screen accessible to the operator. Multiple types of graphical overlays are shown, including sensor data acquired by the nuclear radiation detector, a virtual <b>cursor</b> that <b>tracks</b> the UAV and geographical information, such as buildings. Experiments performed in a real environment are reported using an intense nuclear source...|$|R
40|$|Visual {{feedback}} and non-visual information play different roles in tracking of an external target. This study explored the respective {{roles of the}} visual and non-visual information in eleven healthy volunteers who coupled the manual cursor to a rhythmically moving target of 0. 5 Hz under three sensorimotor conditions: eye-alone tracking (EA), eye-hand tracking with visual feedback of manual outputs (EH tracking), and the same tracking without such feedback (EHM tracking). Tracking error, kinematic variables, and movement intermittency (saccade and speed pulse) were contrasted among tracking conditions. The results showed that EHM tracking exhibited larger pursuit gain, less tracking error, and less movement intermittency for the ocular plant than EA tracking. With the vision of manual <b>cursor,</b> EH <b>tracking</b> achieved superior tracking congruency of the ocular and manual effectors with smaller movement intermittency than EHM tracking, except that the rate precision of manual action was similar for both types of tracking. The present study demonstrated that visibility of manual consequences altered mutual relationships between movement intermittency and tracking error. The speed pulse metrics of manual output were linked to ocular tracking error, and saccade events were time-locked to the positional error of manual tracking during EH tracking. In conclusion, peripheral non-visual information is critical to smooth pursuit characteristics and rate control of rhythmic manual tracking. Visual information adds to eye-hand synchrony, underlyin...|$|R
40|$|This paper {{details the}} design and {{evaluation}} of the Delphian Desktop, a mechanism for online spatial prediction of cursor movements in a Windows-Icons-Menus-Pointers (WIMP) environment. Interaction with WIMP-based interfaces often becomes a spatially challenging task when the physical interaction mediators are the common mouse and a high resolution, physically large display screen. These spatial challenges are especially evident in overly crowded Windows desktops. The Delphian Desktop integrates simple yet effective predictive spatial tracking and selection paradigms into ordinary WIMP environments {{in order to simplify}} and ease pointing tasks. Predictions are calculated by <b>tracking</b> <b>cursor</b> movements and estimating spatial intentions using a computationally inexpensive online algorithm based on estimating the movement direction and peak velocity. In testing the Delphian Desktop effectively shortened pointing time to faraway icons, and reduced the overall physical distance the mouse (and user hand) had to mechanically traverse. ACM Classification: H. 5. 2 [User Interfaces]: Graphica...|$|R
40|$|Abstract – We {{developed}} a real-time controller for a 2 degree-of-freedom robotic system using xPC Target. Th is system {{was used to}} investigate how different methods of performance error feedback can lead to faster and more complete motor learning in individuals asked to compensate for a novel visuo-motor transformation (a 30 degree rotation). Four groups of human {{subjects were asked to}} reach with their unseen arm to visual targets surrounding a central starting location. A <b>cursor</b> <b>tracking</b> hand motion was provided during each reach. For one group of subjects, deviations from the “ideal ” compensatory hand movement (i. e. trajectory errors) were amplified with a gain of 2 whereas another group was provided visual feedback with a gain of 3. 1. Yet another group was provided cursor feedback wherein the cursor was rotated by an additional (constant) offset angle. We compared the rates at which the hand paths converged to the steady-state trajectories. Our results demonstrate that error-augmentation can improve the rate and extent of motor learning of visuomotor rotations in healthy subjects. Furthermore, our results suggest that both error amplification and offset-augmentation may facilitate neuro-rehabilitation strategies that restore function in brain injuries such as stroke. Index Terms – neuro-robotics, error augmentation, xPC Target, motor learning, and visual distortion I...|$|E
40|$|Understanding human <b>cursor</b> <b>tracking</b> {{behavior}} {{is essential in}} understanding human motor control. Though tracking has been hypothesized as a sequence of discrete movements, better data is needed to support the theory. By analyzing moment-to-moment tracking data, this paper shows that discrete, nonballistic movements exist throughout a tracking task, and that these short submovements can be characterized by either Fitts ’ law or a linear model. A cognitive model was built to incorporate the characteristics of these discrete movements into a dual task. Using parameters estimated through linear regression of the movement data, the model achieves a good fit to the overall performance measures of the dual-task experiment. This research investigates the characteristics of human motor control in tracking tasks, improves modeling techniques by providing a new method for estimating tracking parameters, and advances the science of motor control with new evidence for the discrete movement tracking hypothesis. The discrete movement model presented here offers an excellent alternative to established control theory models {{that are used to}} simulate steering in cognitive models of driving. Tracking is a class of tasks in which people use their hands to guide the position of a pointer (such as a cursor) with respect to a target. Driving is a tracking task because a drive...|$|E
40|$|Abstract A {{number of}} nonhuman primate species have {{demonstrated}} {{the ability to use}} a joystick to control a cur-sor on a computer screen, yet the acquisition of this skill has not been the focus of systematic inquiry. Here, we ex-amined joystick acquisition in four tufted capuchins under two directional relationships of joystick movement and re-sultant cursor displacement, isomorphic and inverted. To document the natural history of the acquisition of this skill, we recorded the development of visual tracking of the cursor and body tilting. Rates of acquisition were compa-rable between the two conditions. After mastering the task in one condition, subjects remastered the task at an accel-erated rate in the opposing condition. All subjects signifi-cantly increased or maintained high proportions of <b>cursor</b> <b>tracking</b> throughout acquisition. All subjects demonstrated a postural tilt while moving the cursor from the mid-phase of acquisition through task mastery. In the isomorphic condition, all subjects tilted significantly more often in the direction of goal location than in the opposite direc-tion. In three of the four series of tilting that were scored for subjects in the inverted condition, tilting occurred sig-nificantly more often toward the direction of goal location than the direction of required hand movement. Together these findings suggest that body tilting participates in the organization of directional movement of the cursor rather than reflecting merely the motoric requirements of the task (to manipulate a joystick) ...|$|E
40|$|After {{surveying}} {{the concepts of}} audio windowing, this paper elaborates taxonomies of three sets of its dimensions: spatial audio (“throwing sound”), timbre (“pitching sound”), and gain (“catching sound”), establishing matrices of variability for each, drawing similes, and citing applications. Two audio windowing systems are examined across these three operations: repositioning, distortion/blending, and gain control (state transitions in virtual space, timbre space, and volume space). Handy Sound is a purely auditory system with gestural control, while Maw exploits exocentric graphical control. These two systems mo-tivated the development of special user interface features. (Sonic) piggyback-channels are introduced as filtear manifestations of changing <b>cursors,</b> used to <b>track</b> control state. A variable control/response ratio {{can be used to}} map a near-field work envelope into perceptual space. Clusters can be used to hierarchically collapse groups of spatial sound objects. Wimp idioms are reinterpreted for audio windowing functions. Reflexive operations are cast an instance of general manipulation when all the modified entities, including an iconification of the user, are projected into an egalitarian control/display system. Other taxonomies in-clude a spectrum of directness of manipulation, and sensitivity to current position crossed with dependency on some target position...|$|R
40|$|Conceptual {{and methodological}} {{problems}} related to Schmidt' (1975) motor schema theory are discussed. In particular, the motor schema is interpreted as representing {{the dynamics of the}} system being controlled, {{which may or may not}} be associated with a referent movement pattern. Furthermore, it is suggested that prior familiarity with a control system's dynamics is a critical but uncontrolled factor in tests of the theory, and largely accounts for their equivocal findings. These ideas are examined by two experiments in which subjects had to bimanually control the movement of a computer-displayed <b>cursor</b> along a <b>track</b> on a CRT screen. Different track orientations required different patterns of movement not entailing a single generalized motor program. Experiment 1 shows that variable track performance with a given control system, results in better transfer to novel tracks than does fixed practice. Experiment 2 demonstrates that altering the control system disrupts performance whether or not the required movements remain the same. These results indicate the need for a fundamental modification of schema theory, such that a schematic representation of effector-environment relations (effector function) is available independently of particular movement patterns used in its acquisition...|$|R
40|$|Sensorimotor error {{feedback}} {{plays an}} integral role in movement; it adapts the sensorimotor control system to rapid changes in environmental loads and allows smooth limb coordination. Studies {{have shown the}} cerebellum, parietal, and premotor cortices {{to be involved in}} error processing, but the specific neural function of those areas remain relatively unknown. The objective {{of this study was to}} characterize the neural sources that underlie the computation of visual and proprioceptive error during goal-directed movement. We tested the hypothesis that the cortical networks meditating the two sensory error systems are distinct. Subjects (n= 7) used a <b>cursor</b> to <b>track</b> a moving target presented on a computer display. Cursor position on the screen was yoked to a 1 -D wrist manipulandum that recorded wrist position, velocity, and torque and applied controlled torques to the wrist. External displacement errors were applied as either force perturbations to the wrist (Proprioceptive condition) or visual displacements to cursor position (Visual condition). Five levels of displacement were applied to identify neural responses that co-varied with the magnitude of displacement. EEG was collected from 64 electrodes. Distributed cortical source modeling (Brainstorm v. 3) identified cortical sources that contributed to the averaged EEG activity across error levels. In force perturbation trials, current source density across subjects showed early somatosensory, premotor, motor, and frontal activity ranging from 43 ± 5 ms to 48 ± 6 ms, followed by parietal activity at 70 ± 8 ms. In visual perturbation trials, parietal activation at 113 ± 8 ms was followed by sensory, motor, and premotor activation (123 ± 42 ms to 131 ± 22 ms). Spatial analyses suggest error representations for proprioception and vision may be computed in spatially distinct areas of frontal and parietal cortices. The temporal sequence of error-related activity suggests that sensorimotor error may not initially be computed in parietal regions before being processed in motor areas. The early premotor/motor activation in the Proprioceptive condition suggests that a course estimate of error is first computed in those areas before a more accurate representation of error is generated in the parietal regions. This may occur to initiate a course correction faster in the direction of the error while gathering more information about the error...|$|R
40|$|When {{designing}} {{for large}} screen displays, designers {{are forced to}} deal with <b>cursor</b> <b>tracking</b> issues, interacting over distances, and space management issues. Because of the large visual angle of the user that the screen can cover, {{it may be hard}} for users to begin and complete search tasks for basic items such as cursors or icons. In addition, maneuvering over long distances and acquiring small targets understandably takes more time than the same interactions on normally sized screen systems. To deal with these issues, large display researchers have developed more and more unconventional devices, methods and widgets for interaction, and systems for space and task management. For tracking cursors there are techniques that deal with {{the size and shape of}} the cursor, as well as the “density” of the cursor. There are other techniques that help direct the attention of the user to the cursor. For target acquisition on large screens, many researchers saw fit to try to augment existing 2 D GUI metaphors. They try to optimize Fitts’ law to accomplish this. Some techniques sought to enlarge targets while others sought to enlarge the cursor itself. Even other techniques developed ways of closing the distances on large screen displays. However, many researchers feel that existing 2 D metaphors do not and will not work for large screens. They feel that the community should move to more unconventional devices and metaphors. These unconventional means include use of eye-tracking, laser-pointing, hand-tracking, two-handed touchscreen techniques, and other high-DOF devices. In the end, many of these developed techniques do provide effective means for interaction on large displays. However, we need to quantify the benefits of these methods and understand them better. The more we understand the advantages and disadvantages of these techniques, the easier it will be to employ them in working large screen systems. We also need to put into place a kind of interaction standard for these large screen systems. This could mean simply supporting desktop events such as pointing and clicking. It may also mean that we need to identify the needs of each domain that large screens are used for and tailor the interaction techniques for the domain...|$|E
40|$|Rationale The cognition-enhancing {{effects of}} glucose {{administration}} to humans have been well-documented; however, {{it remains unclear}} whether this effect preferentially targets episodic memory or other cognitive domains. Objectives The effect of glucose on the allocation of attentional resources during memory encoding was assessed using a sensitive dual-attention paradigm. Materials and methods One hundred and twenty volunteers (mean age 21. 60, SD 4. 89, 77 females) took part in this randomised, double-blind, placebo-controlled, parallel groups study where each consumed a 25 -g glucose drink or a placebo. Half {{of the participants in}} each drink condition attempted to track a moving on-screen target during auditory word presentation. The distance between the <b>cursor</b> and the <b>tracking</b> target was used as an index of attentional cost during encoding. Effects of drink and tracking on recognition memory and drink on tracking performance were assessed. Self-rated appetite and mood were co-monitored. Results Co-performing the tracking task significantly impaired memory performance irrespective of drink condition. In the placebo–tracking condition, there was a cost to tracking manifest as greater deviation from target during and immediately following word presentation. Compared with placebo, the glucose drink significantly improved tracking performance during encoding. There were significant time-related changes in thirst and alertness ratings but these were not differentially affected by drink or tracking conditions. Conclusion Tracking but not memory was enhanced by glucose. This finding suggests that, under certain task conditions, glucose administrations does not preferentially enhance memory performance. One mechanism through which glucose acts as a cognition enhancer is through allowing greater allocation of attentional resources...|$|R
40|$|Myoelectric control can {{significantly}} improve human–robot interaction and intensive research {{has worked on}} the attempt of providing the user with intuitive control of multiple Degrees of Freedom (DOFs). However, no work has focused on patients with severe dyskinetic cerebral palsy (CP) {{who are unable to}} achieve effective voluntary movements. Research aimed at developing intuitive and flexible control interface strategies has the potential to provide these patients with significantly improved mobility. Indeed, in CP patients, there is no disconnect between the brain and the spinal cord, so that the electromyographic (EMG) signal provides a direct read-out of the movement-related activity in motor cortex. On the other hand, a major obstacle to the use of myoelectric control in patients with CP and arm dystonia is that the EMG signal is corrupted by co-contraction, variability, and noise. To address this problem, a synergy-based myoelectric approach should be tested. Indeed, when extracting synergies from multi-muscle EMG, a set of incoming EMG signals is converted into repeatable descriptors, while discarding irrelevant information, thus making muscle synergies more robust to possible noisy activity. In addition, previous studies showed that, although children with dystonia present aberrant EMG activity compared to control subjects, muscle synergies extracted from the two groups are very similar in terms of number and structure. In a previous work, we developed and successfully tested, on healthy subjects, a semi-supervised method to achieve online, simultaneous, continuous control of 2 DOFs of a robotic arm, using muscle synergies extracted from 8 upper limb muscles while performing reaching movements of the elbow and shoulder joints in the horizontal plane. Here, we tested this synergy-based myoelectric interface on 5 children with secondary dystonia due to CP. Our goal was to evaluate the feasibility and the efficacy of the synergy-based control method, compared to the muscle-pair method typically used in commercial applications, using EMG signals recorded during both unconstrained movements (Dynamic Condition) and isometric contractions (Isometric Condition). For the Dynamic Condition, the control performance was assessed by computing the Root-mean-square Error and the Pearson’s Correlation coefficient between the subject’s and the robot’s angles. For the Isometric Condition, we designed a graphical interface with a <b>cursor</b> that <b>tracked</b> the position of the robot’s end-effector and specific targets to be reached. The performance was evaluated using the time needed to accomplish the task and the number of targets reached. Results show that our method is able to provide online, simultaneous, and accurate control of 2 DOFs of a robotic arm in children with secondary dystonia due to CP. The current study is a first step toward application of synergy-based myocontrol for patients with dyskinetic CP and other disorders of the control of muscles...|$|R
40|$|Myoelectric control can {{significantly}} improve human–robot interaction {{due to the}} ability to non-invasively measure human motion intent. Intensive research has worked on the attempt of providing the user with simultaneous and intuitive control of multiple Degrees of Freedom (DOFs). Here, we propose a method based on the theory of muscle synergies, which assumes that movements are executed by translating low-dimensional task-level neural commands into high-dimensional muscle activations. Our approach models each DOF as driven by 2 activation signals and it estimates neural control information from 8 muscles of the upper-limb both during movement of the shoulder (DOF 1) and elbow (DOF 2) joints in the horizontal plane (Dynamic Condition), and during isometric contractions (Isometric Condition). The algorithm requires a calibration phase (Day 1), where the subject is asked to activate the 2 DOFs separately. A DOF-wise nonnegative matrix factorization (NMF) is then applied to extract a subject-specific synergy matrix (S). In the control phase, the subject directly uses the activation signals (extracted from the online EMG and the S matrix by solving a nonnegative least-squares constraints problem) for online torque-based control of 2 DOFs of a robotic arm. Low-latency is achieved by introducing a nonlinear filtering of the EMG based on Bayesian estimation. To test the robustness and repeatability of the algorithm over days, the control phase is tested also the following day (Day 2) using the same S extracted from the calibration phase on Day 1. To assess the effectiveness of our approach compared with the traditional single-muscle method, where 2 independent muscles are used for each DOF separately, we perform offline simulations where each DOF of the robotic arm is driven by 2 EMG signals that correspond to the muscles most involved in each of the 2 directions of articulation of the joint. For the Dynamic Condition, the performance of the control algorithm is assessed by computing the Root-mean-square Error (RMSE) and the Pearson’s Correlation coefficient (R) between the subject’s (electrogoniometers) and the robot’s (robot’s encoders) joint angles. For the Isometric Condition, we developed a graphical interface with a <b>cursor</b> that <b>tracks</b> the position of the robot’s end-effector, and specific targets that serve as cues to prompt the subject with the isometric contractions to perform. The performance of the algorithm is evaluated using the time needed to accomplish the task. The analysis compares these indexes across conditions (synergy vs muscle-pair methods; Day 1 vs Day 2). Results in 10 able-bodied subjects show that our method is able to provide online, simultaneous, and accurate control of 2 DOFs of a robotic arm. Our work shows the effectiveness of the synergy-based myoelectric control with respect to the traditional single-muscle approach. Results also report the robustness of the method over days without the need for a daily calibration...|$|R
40|$|Context: Digital {{pathology}} has {{the potential}} to dramatically alter the way pathologists work, yet little is known about pathologists′ viewing behavior while interpreting digital whole slide images. While tracking pathologist eye movements when viewing digital slides may be the most direct method of capturing pathologists′ viewing strategies, this technique is cumbersome and technically challenging to use in remote settings. <b>Tracking</b> pathologist mouse <b>cursor</b> movements may serve as a practical method of studying digital slide interpretation, and mouse cursor data may illuminate pathologists′ viewing strategies and time expenditures in their interpretive workflow. Aims: To evaluate the utility of mouse cursor movement data, in addition to eye-tracking data, in studying pathologists′ attention and viewing behavior. Settings and Design: Pathologists (N = 7) viewed 10 digital whole slide images of breast tissue that were selected using a random stratified sampling technique to include a range of breast pathology diagnoses (benign/atypia, carcinoma in situ, and invasive breast cancer). A panel of three expert breast pathologists established a consensus diagnosis for each case using a modified Delphi approach. Materials and Methods: Participants′ foveal vision was tracked using SensoMotoric Instruments RED 60 Hz eye-tracking system. Mouse <b>cursor</b> movement was <b>tracked</b> using a custom MATLAB script. Statistical Analysis Used: Data on eye-gaze and mouse cursor position were gathered at fixed intervals and analyzed using distance comparisons and regression analyses by slide diagnosis and pathologist expertise. Pathologists′ accuracy (defined as percent agreement with the expert consensus diagnoses) and efficiency (accuracy and speed) were also analyzed. Results: Mean viewing time per slide was 75. 2 seconds (SD = 38. 42). Accuracy (percent agreement with expert consensus) by diagnosis type was: 83 % (benign/atypia); 48 % (carcinoma in situ); and 93 % (invasive). Spatial coupling was close between eye-gaze and mouse cursor positions (highest frequency ∆x was 4. 00 px (SD = 16. 10), and ∆y was 37. 50 px (SD = 28. 08)). Mouse cursor position moderately predicted eye gaze patterns (Rx = 0. 33 and Ry = 0. 21). Conclusions: Data detailing mouse cursor movements may be a useful addition to future studies of pathologists′ accuracy and efficiency when using digital pathology...|$|R
40|$|Difficulties {{experienced}} in steering a vehicle {{can be expected}} to place a demand on onersquo;s mental resources (Orsquo;Donnell, Eggemeier 1986). While the extent of this mental workload (MWL) can be estimated by self-reports (e. g., NASA-TLX; Hart, Staveland 1988), it can also be physiologically evaluated in terms of how a primary task taxes a common and limited pool of mental resources, {{to the extent that it}} reduces the electroencephalographic (EEG) responses to a secondary task (e. g. an auditory oddball task). For example, the participant could be primarily required to control a <b>cursor</b> to <b>track</b> a target while attending to a series of auditory stimuli, which would infrequently present target tones that should be responded to with a button-press (e. g., Wickens, Kramer, Vanasse and Donchin 1983). Infrequently presented targets, termed oddballs, are known to elicit a large positive potential after approximately 300 ms of their presentation (i. e.,P 3). Indeed, increasing tracking difficulty either by decreasing the predictability of the tracked target or by changing the complexity of the controller dynamics has been shown to attenuate P 3 responses in the secondary auditory monitoring task (Wickens et al. 1983; Wickens, Kramer and Donchin 1984). In contrast, increasing tracking difficultymdash;by introducing more frequent direction changes of the tracked target (i. e. including higher frequencies in the function that describes the motion trajectory of the target) mdash;has been shown to bear little influence on the secondary taskrsquo;s P 3 response (Wickens, Israel and Donchin 1977; Isreal, Chesney, Wickens and Donchin 1980). Overall, the added requirement of a steering task consistently results in a lower P 3 amplitude, relative to performing auditory monitoring alone (Wickens et al. 1983; Wickens et al. 1977; Isreal et al. 1980). Using a dual-task paradigm for indexing workload is not ideal. First, it requires participants to perform a secondary task. This prevents it from being applied in real-world scenarios; users cannot be expected to perform an unnecessary task that could compromise their critical work performance. Second, it can only be expected to work if the performance of the secondary task relies on the same mental resources as those of the primary task (Wickens, Yeh 1983), requiring a deliberate choice of the secondary task. Thus, it is fortunate that more recent studies have demonstrated that P 3 amplitudes can be sensitive to MWL, even if the auditory oddball is ignored (Ullsperger, Freude and Erdmann 2001; Allison, Polich 2008). This effect is said to induce a momentary and involuntary shift in general attention, especially if recognizable sounds (e. g. a dog bark, opposed to a pure sound) are used (Miller, Rietschel, McDonald and Hatfield 2011). The current work, containing two experiments, investigates the conditions that would allow lsquo;novelty-P 3 rsquo;, the P 3 elicited by the ignored, recognizable oddball, to be an effective index for the MWL of compensatory tracking. Compensatory tracking is a basic steering task that can be generalized to most implementations of vehicular control. In both experiments participants were required to use a joystick to counteract disturbances of a horizontal plane. To evaluate the generalizability of this paradigm, we depicted this horizontal plane as either a line in a simplified visualization or as the horizon in a realworld environment. In the latter, participants experienced a large field-of-view perspective of the outside world from the cockpit of an aircraft that rotated erratically about its heading axis. The task was the same regardless of the visualization. In both experiments, we employed a full factorial design for the visualization (instrument, world) and 3 oddball paradigms (in experiment 1) or 4 levels of task difficulty (in experiment 2) respectively. Two sessions were conducted on separate days for the different visualizations, which were counter-balanced for order. Three trials were presented per oddball paradigm (experiment 1) or level of task difficulty (experiment 2) in blocks, which were randomized for order. Overall, we found that steering performance was worse when the visualization was provided by a realistic world environment in experiments 1 (F (1, 11) = 42. 8, p˘ 005 C 0. 01) and 2 (F (1, 13) = 35. 0, p˘ 005 C 0. 01). Nonetheless, this manipulation of visualization had no consequence on our participantsrsquo; MWL as evaluated by a post-experimental questionnaire (i. e., NASATLX) and EEG responses. This suggests that MWL was unaffected by our choice of visualization. The first experiment, with 12 participants, was designed to identify the optimal presentation paradigm of the auditory oddball. For the EEG analysis, two participants had to be excluded, due to noisy electrophysiological recordings (more than 50 % of rejected epochs). Whilst performing the tracking task, participants were presented with a sequence of auditory stimuli that they were instructed to ignore. This sequence would, in the 1 -stimulus paradigm, only contain the infrequent odd-ball stimulus (i. e., the familiar sound of a dogrsquo;s bark (Fabiani, Kazmerski, Cycowicz and Friedmann 1996)). In the 2 -stimulus paradigm this infrequently presented oddball (0. 1) is accompanied by a more frequently presented pure tone (0. 9) and in the 3 -stimulus paradigm the infrequently presented oddball (0. 1) is accompanied by a more frequently presented pure tone (0. 8) and an infrequently presented pure tone (0. 1). These three paradigms are widely used in P 3 research (Katayama, Polich 1996). It should be noted, however, that the target to target interval is 20 s regardless of the paradigm. To obtain the ERPs the epochs from 100 ms before to 900 ms after the onset of the recognizable oddball stimulus, were averaged. Mean amplitude measurements were obtained in a 60 ms window, centered at the group- mean peak latency for the largest positive maximum component between 250 and 400 ms for the oddball P 3, for each of the three mid-line electrode channels of interest (i. e., Fz, Cz, Pz). In agreement with previous work, the novelty-P 3 response is smaller when participants had to perform the tracking task compared to when they were only presented with the task-irrelevant auditory stimuli, without the tracking task (F (1, 9) = 10. 9, p˘ 005 C 0. 01). However, the amplitude of the novelty-P 3 differed significantly across the presentation paradigms (F (2, 18) = 5. 3, p˘ 005 C 0. 05), whereby the largest response to our task-irrelevant stimuli was elicited by the 1 - stimulus oddball paradigm. This suggests that the 1 -stimulus oddball paradigm is most likely to elicit novelty-P 3 s that are sensitive to changes in MWL. Finally, the attenuation of novelty-P 3 amplitudes by the tracking task varied across the three mid-line electrodes (F (2, 18) = 28. 0, p˘ 005 C 0. 001). Pairwise comparison, Bonferroni corrected for multiple comparisons, revealed P 3 amplitude to be largest at Cz, followed by Fz and smallest at Pz (all p˘ 005 C 0. 05). This stands in contrast with previous work that found control difficulty to attenuate P 3 responses in parietal electrodes (cf., Isreal et al. 1980; Wickens et al. 1983). Thus, the current paradigm that uses a recognizable, ignored sound is likely to reflect an underlying process that is different from previous studies, which could be more sensitive to the MWL demands of a tracking task. Given the result of experiment 1, the second experiment with 14 participants, investigated whether the 1 -stimulus oddball paradigm would be sufficiently sensitive in indexing tracking difficulty as defined by the bandwidth of frequencies that contributed to the disturbance of the horizontal plane (cf., Isreal et al. 1980). Three different bandwidth profiles (easy, medium, hard) defined the linear increase in the amount of disturbance that had to be compensated for. This manipulation was effective in increasing subjective MWL, according to the results of a post- experimental NASA-TLX questionnaire (F (2, 26) = 14. 9, p˘ 005 C 0. 001) and demonstrated the expected linear trend (F (1, 13) = 23. 2, p˘ 005 C 0. 001). This increase in control effort was also reflected in the amount of joystick activity, which grew linearly across the difficulty conditions (F (1, 13) = 42. 2, p˘ 005 C 0. 001). For the EEG analysis two participants had to be excluded due to noisy electrophysiological recordings (more than 50 % of rejected epochs). A planned contrast revealed that the novelty- P 3 was significantly lower in the most difficult condition compared to the baseline viewing condition, where no tracking was done (F (1, 11) = 5. 2, p˘ 005 C 0. 05; see Fig. 1 a). Nonetheless, novelty-P 3 did not differ significantly between the difficulty conditions (F (2, 22) = 0. 13, p = 0. 88), nor did it show the expected linear trend (F (1, 11) = 0. 02, p = 0. 91). Like (Isreal et al. 1980), we find that EEGresponses do not discriminate for MWL that is associated with controlling increased disturbances. It remains to be investigated, whether the novelty-P 3 is sensitive for the complexity of controller dynamics, like it has been shown for the P 3. The power spectral density of the EEG data around 10 Hz (i. e., alpha) has been suggested by (Smith, Gevins 2005) to index MWL. A post hoc analysis of our current data, at electrode Pz, revealed that alpha power was significantly lower for the medium and hard conditions, relative to the view-only condition (F (1, 11) = 6. 081, p˘ 005 C 0. 05; (F (1, 11) = 6. 282, p˘ 005 C 0. 05). Nonetheless, the expected linear trend across tracking difficulty was not significant (Fig. 1 b). To conclude, the current results suggest that a 1 -stimulus oddball task ought to be preferred when measuring general MWL with the novelty-P 3. Although changes in novelty-P 3 can identify the control effort required in our compensatory tracking task, it is not sufficiently sensitive to provide a graded response across different levels of disturbances. In this regard, it may not be as effective as self-reports and joystick activity in denoting control effort. Nonetheless, further research can improve upon the sensitivity of EEG metrics to MWL by investigating other aspects that better correlate to the specific demands of a steering task...|$|R

