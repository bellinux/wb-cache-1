16|957|Public
5000|$|PaRappa the Rapper Remastered {{received}} mixed or average reviews. It {{was praised}} {{for keeping the}} charm of the original game while improving on the graphical quality, but was criticised for only improving the graphics of the gameplay and not the cutscenes. Caitlin Cooke of Destructoid wrote that [...] "The remastered version does not include a <b>calibration</b> <b>setting.</b> This works very much against PaRappas favor as there’s an extremely noticeable lag throughout each of the levels, causing havoc when trying to hit the notes on time." ...|$|E
5000|$|Audio lag {{is also a}} {{significant}} detriment in rhythm games, where precise timing is required to succeed. Most of these games have a lag <b>calibration</b> <b>setting</b> where upon the game will adjust the timing windows by {{a certain number of}} milliseconds to compensate. In these cases, the notes of a song will be sent to the speakers before the game even receives the required input from the player {{in order to maintain the}} illusion of rhythm. Games that rely upon [...] "freestyling", such as Rock Band drums or DJ Hero, can still suffer tremendously, as the game cannot predict what the player will hit in these cases, and excessive lag will still create a noticeable delay between hitting notes and hearing them play.|$|E
40|$|Because {{of their}} {{chemical}} properties and multiday half lives, iodine- 124 and zirconium- 89 {{are being used}} in {{a growing number of}} PET imaging studies. Some aspects of their quantitation, however, still need attention. For (89) Zr the PET images should, in principle, be as quantitatively accurate as similarly reconstructed 18 F measurements. We found, however, that images of a 20 cm well calibration phantom containing (89) Zr underestimated the activity by approximately 10 % relative to a dose calibrator measurement (Capintec CRC- 15 R) using a published <b>calibration</b> <b>setting</b> number of 465. PET images of (124) I, in contrast, are complicated by the contribution of decays in cascade that add spurious coincident events to the PET data. When these cascade coincidences are properly accounted for, quantitatively accurate images should be possible. We found, however, that even with this correction we still encountered {{what appeared to be a}} large variability in the accuracy of the PET images when compared to dose calibrator measurements made using the <b>calibration</b> <b>setting</b> number, 570, recommended by Capintec. We derive new <b>calibration</b> <b>setting</b> numbers for (89) Zr and (124) I based on their 511 keV photon peaks as measured on an HPGe detector. The peaks were calibrated relative to an 18 F standard, the activity level of which was precisely measured in a dose calibrator under well-defined measurement conditions. When measuring (89) Zr on a Capintec CRC- 15 R we propose the use of <b>calibration</b> <b>setting</b> number 517. And for (124) I, we recommend the use of a copper filter surrounding the sample and the use of <b>calibration</b> <b>setting</b> number 494. The new dose calibrator measurement procedures we propose will result in more consistent and accurate radioactivity measurements of (89) Zr and (124) I. These and other positron emitting radionuclides can be accurately calibrated relative to 18 F based on measurements of their 511 keV peaks and knowledge of their relative positron abundances...|$|E
40|$|Multiple {{regional}} chironomid-climate calibration datasets {{are available}} to reconstruct quantitatively July air temperatures from fossil chironomid assemblages. We {{examined the relationship between}} July air temperature and the 40 most common chironomid taxa in three independent Eurasian <b>calibration</b> (training) <b>sets.</b> The estimated temperature optimum of each chironomid taxon is systematically lower (by ~ 1 - 2 °C) in a Norwegian <b>calibration</b> <b>set</b> compared to Finnish and Russian <b>calibration</b> <b>sets.</b> This result might partly be {{explained by the fact that}} the Norwegian <b>calibration</b> <b>set</b> extends further at the cold end of the temperature gradient. A difference in continentality between the Russian sites and the European sites might also contribute to this pattern. The number of taxa that show a statistically significant unimodal response to temperature is higher in the Norwegian <b>calibration</b> <b>set</b> (34 out of 40 taxa) compared to the modern Finnish (11 of 37 taxa; 3 common taxa absent) and the Russian <b>calibration</b> <b>set</b> (20 of 40 taxa), probably due to the longer temperature gradient incorporated in the Norwegian <b>calibration</b> <b>set.</b> We applied all three <b>calibration</b> <b>sets</b> to fossil chironomid assemblages from the high-latitude study site of Sokli (northeast Finland), a site with a unique series of lacustrine deposits covering (amongst others) the Holocene, part of early MIS 3 (at ~ 53 ka) and MIS 5 d-c (at ~ 110 - 95 ka) and with independent proxy-records for comparison. In the early Holocene and during MIS 5 c, the chironomid-based temperature inferences from all three inference models had similar values. Temperature reconstructions based on the Norwegian <b>calibration</b> <b>set</b> are 2 - 4 °C lower for the late Holocene, early MIS 3 and MIS 5 d than the inferred temperatures based on the other <b>calibration</b> <b>sets.</b> Although the lakes included in the Finnish <b>calibration</b> <b>set</b> are located closest to the site of Sokli, evaluation tests and a comparison with independent proxy data suggests that the Norwegian <b>calibration</b> <b>set</b> provides the most suitable analogues for reconstruction purposes for most of the fossil assemblages. Our results imply that when choosing a <b>calibration</b> <b>set</b> for quantitative climate reconstructions on glacial timescales, regional proximity of the fossil site may not be a sufficient basis, and the length of the temperature gradient of the calibration dataset and factors such as the continentality gradient covered by the <b>calibration</b> <b>set</b> must also be considered...|$|R
40|$|The {{visible and}} {{near-infrared}} (VNIR) spectroscopy prediction model {{is an effective}} tool for the prediction of soil organic matter (SOM) content. The predictive accuracy of the VNIR model is highly dependent on {{the selection of the}} <b>calibration</b> <b>set.</b> However, conventional methods for selecting the <b>calibration</b> <b>set</b> for constructing the VNIR prediction model merely consider either the gradients of SOM or the soil VNIR spectra and neglect the influence of environmental variables. However, soil samples generally present a strong spatial variability, and, thus, the relationship between the SOM content and VNIR spectra may vary with respect to locations and surrounding environments. Hence, VNIR prediction models based on conventional <b>calibration</b> <b>set</b> selection methods would be biased, especially for estimating highly spatially variable soil content (e. g., SOM). To equip the <b>calibration</b> <b>set</b> selection method with the ability to consider SOM spatial variation and environmental influence, this paper proposes an improved method for selecting the <b>calibration</b> <b>set.</b> The proposed method combines the improved multi-variable association relationship clustering mining (MVARC) method and the Rank–Kennard–Stone (Rank-KS) method in order to synthetically consider the SOM gradient, spectral information, and environmental variables. In the proposed MVARC-R-KS method, MVARC integrates the Apriori algorithm, a density-based clustering algorithm, and the Delaunay triangulation. The MVARC method is first utilized to adaptively mine clustering distribution zones in which environmental variables exert a similar influence on soil samples. The feasibility of the MVARC method is proven by conducting an experiment on a simulated dataset. The <b>calibration</b> <b>set</b> is evenly selected from the clustering zones and the remaining zone by using the Rank-KS algorithm in order to avoid a single property in the selected <b>calibration</b> <b>set.</b> The proposed MVARC-R-KS approach is applied to select a <b>calibration</b> <b>set</b> in order to construct a VNIR prediction model of SOM content in the riparian areas of the Jianghan Plain in China. Results indicate that the <b>calibration</b> <b>set</b> selected using the MVARC-R-KS method is representative of the component concentration, spectral information, and environmental variables. The MVARC-R-KS method can also select the <b>calibration</b> <b>set</b> for constructing a VNIR model of SOM content with a relatively higher-fitting degree and accuracy by comparing it to classical <b>calibration</b> <b>set</b> selection methods...|$|R
40|$|In {{this paper}} we report the {{application}} of NMR spectroscopy and Raman spectroscopy to determine the degree of maleate substitution in maleinated starches. Five kinds of maleinated starches were investigated and <b>calibration</b> <b>sets</b> were constructed to derive linear regression equations {{that may be used}} to predict the degree of maleate substitution for starch samples with unknown amounts of chemical modification. The <b>calibration</b> <b>sets</b> reported have very high linearity (r > 0. 99) for both the NMR and Raman methods. The NMR and Raman <b>calibration</b> <b>sets</b> allow fast and nondestructive measurement of the degree of maleate substitution for different starches with little need of sample preparation. link_to_subscribed_fulltex...|$|R
40|$|Over {{the past}} few years, the subject of movies getting louder has {{generated}} increasing concern within the film production community. In addition, it has become commonplace for movie-goers to claim that movies are too loud. Many theatres now project films at an audio fader setting below the <b>calibration</b> <b>setting</b> that would match that in the dubbing theatre, presumabl...|$|E
40|$|Abstract — We {{propose a}} new method for {{extrinsic}} calibration of a line-scan LIDAR with a perspective projection camera. Our method is a closed-form, minimal {{solution to the}} problem. The solution is a symbolic template found via variable elimination and the multi-polynomial Macaulay resultant. It does not require initialization, {{and can be used}} in an automatic <b>calibration</b> <b>setting</b> when paired with RANSAC and least-squares refinement. We show the efficacy of our approach through a set of simulations and a real calibration. I...|$|E
40|$|This paper {{focuses on}} {{geometry}} measuring of the shank cutting tools {{by the use}} of optical measuring devices. The scanning is realized in the system Atos Triplescan II and also in the system Zoller Genius 3. This paper provides a proposed methodology of shank cutting tools geometry measuring based on our scanning and measuring for the system Atos. The proposed methodology consists of the <b>calibration,</b> <b>setting</b> and tool clamping, preparation reference point and measuring in software. Part of the work also includes a comparison of measured results between the devices Atos and Zoller. This paper provides a contribution to the study of measurement geometry of the shank cutting tools...|$|E
40|$|Abstract. —Although recent methodological {{advances}} {{have allowed the}} incorporation of rate variation in molecular dating analyses, the calibration procedure, performed mainly through fossils, remains resistant to improvements. One source of uncertainty pertains to the assignment of fossils to specific nodes in a phylogeny, especially when alternative possibilities exist that can be equally justified on morphological grounds. Here we expand on a recently developed fossil cross-validation method to evaluate whether alternative nodal assignments of multiple fossils produce <b>calibration</b> <b>sets</b> that differ in their internal consistency. We use an enlarged Crypteroniaceae-centered phylogeny of Myrtales, six fossils, and 72 combinations of calibration points, termed <b>calibration</b> <b>sets,</b> to identify (i) the fossil assignments that produce the most internally consistent <b>calibration</b> <b>sets</b> and (ii) the mean ages, derived from these <b>calibration</b> <b>sets,</b> for the split of the Southeast Asian Crypteroni-aceae from their West Gondwanan sister clade (node X). We found that a correlation exists between s values, devised to measure the consistency among the calibration points of a <b>calibration</b> <b>set</b> (Near and Sanderson, 2004), and nodal distances among calibration points. By ranking all sets according to the percent deviation of s from the regression line with nodal distance, we identified the sets with {{the highest level of}} corrected calibration-set consistency. These sets generated lower standard deviations associated with the ages of node X than sets characterized by lower corrected consistency. The three <b>calibration</b> <b>sets</b> with the highest corrected consistencies produced mean age estimates for node X of 79. 70, 79. 14, and 78. 1...|$|R
40|$|We {{investigated}} {{the effect of}} both the <b>calibration</b> <b>set</b> size (number of samples) and the calibration sampling strategy {{on the performance of}} vis–NIR models to predict clay content and exchangeable Ca (Ca++). We evaluated the following calibration sampling algorithms: Kenard–Stone (KSS), conditioned Latin hypercube (cLHS) and fuzzy c-means (FCMS), which are commonly used in spectroscopy and digital soil mapping. These algorithmswere tested separately using a field-scale dataset and a regional scale dataset. For each datasetwe randomly selected a validation subset and the remaining samples were used as candidates for calibration sampling. The accuracy of vis–NIRmodels of clay content and Ca++were compared {{on the basis of the}} sampling algorithms used for selecting the calibration samples. We also tested 38 different <b>calibration</b> <b>set</b> sizes varying from 10 to 380 samples. The vis–NIR models were calibrated by using the support vector regression machine (SVM) algorithm. The training root mean square error (RMSE), the normalized RMSE and the prediction RMSE were used to evaluate the sensitivity of the models to both the sampling algorithmand the <b>calibration</b> <b>set</b> size. In addition, we {{investigated the}} sample representativeness of each algorithm and we suggest a novel and simple methodology to identify an adequate <b>calibration</b> <b>set</b> size based only on the vis–NIR data (i. e. without prior knowledge of the response variables). As expected, our results showthat the error of the soil vis–NIRmodels depends on the <b>calibration</b> <b>set</b> size. When the number of calibration samples is relatively small the sampling algorithm may play an important role on the accuracy of the vis–NIRmodels. On the other hand, if the <b>calibration</b> <b>set</b> size is large enough, the samplingmethod is not a critical issue. Concerning the sample representativeness, we found for all the algorithms that the original distribution of the vis–NIR data can be better replicated by increasing the <b>calibration</b> <b>set</b> size. The results indicate that the calibration samples selected by the cLHS and by the FCMSalgorithms better replicate the original vis–NIR distribution of all the samples, in comparison to those samples selected by the KSS algorithm...|$|R
40|$|Although recent methodological {{advances}} {{have allowed the}} incorporation of rate variation in molecular dating analyses, the calibration procedure, performed mainly through fossils, remains resistant to improvements. One source of uncertainty pertains to the assignment of fossils to specific nodes in a phylogeny, especially when alternative possibilities exist that can be equally justified on morphological grounds. Here we expand on a recently developed fossil cross-validation method to evaluate whether alternative nodal assignments of multiple fossils produce <b>calibration</b> <b>sets</b> that differ in their internal consistency. We use an enlarged Crypteroniaceae-centered phylogeny of Myrtales, six fossils, and 72 combinations of calibration points, termed <b>calibration</b> <b>sets,</b> to identify (i) the fossil assignments that produce the most internally consistent <b>calibration</b> <b>sets</b> and (ii) the mean ages, derived from these <b>calibration</b> <b>sets,</b> for the split of the Southeast Asian Crypteroniaceae from their West Gondwanan sister clade (node X). We found that a correlation exists between s values, devised to measure the consistency among the calibration points of a <b>calibration</b> <b>set</b> (Near and Sanderson, 2004), and nodal distances among calibration points. By ranking all sets according to the percent deviation of s from the regression line with nodal distance, we identified the sets with {{the highest level of}} corrected calibration-set consistency. These sets generated lower standard deviations associated with the ages of node X than sets characterized by lower corrected consistency. The three <b>calibration</b> <b>sets</b> with the highest corrected consistencies produced mean age estimates for node X of 79. 70, 79. 14, and 78. 15 My. These timeframes are most compatible with the hypothesis that the Crypteroniaceae stem lineage dispersed from Africa to the Deccan plate as it drifted northward during the Late Cretaceou...|$|R
40|$|The {{objective}} {{of this study was}} to verify how valid misclassification measurements obtained from a 'pre-survey' calibration exercise are by comparing them to validation scores obtained in 'field' conditions. Validation data were collected from the 'Smile for Life' project, an oral health intervention study in Flemish children. A calibration exercise was organized under 'pre-survey' conditions (32 age-matched children examined by eight examiners and the benchmark scorer). In addition, using a pre-determined sampling scheme blinded to the examiners, the benchmark scorer re-examined between six and 11 children screened by each of the dentists during the survey. Factors influencing sensitivity and specificity for scoring caries experience (CE) were investigated, including examiner, tooth type, surface type, tooth position (upper/lower jaw, right/left side) and validation setting (pre-survey versus field). In order to account for the clustering effect in the data, a generalized estimating equations approach was applied. Sensitivity scores were influenced not only by the <b>calibration</b> <b>setting</b> (lower sensitivity in field conditions, p[*]<[*] 0. 01), but also by examiner, tooth type (lower sensitivity in molar teeth, p[*]<[*] 0. 01) and tooth position (lower sensitivity in the lower jaw, p[*]<[*] 0. 01). Factors influencing specificity were examiner, tooth type (lower specificity in molar teeth, p[*]<[*] 0. 01) and surface type (the occlusal surface with a lower specificity than other surfaces) but not the validation setting. Misclassification measurements for scoring CE are influenced by several factors. In this study, the validation setting influenced sensitivity, with lower scores obtained when measuring data validity in 'field' conditions. Results obtained in a pre-survey <b>calibration</b> <b>setting</b> need to be interpreted with caution and do not (always) reflect the actual performance of examiners during the field work. status: publishe...|$|E
40|$|We {{recently}} {{proposed the}} use of consensus optimization as a viable and effective way {{to improve the quality}} of calibration of radio interferometric data. We showed that it is possible to obtain far more accurate calibration solutions and also to distribute the compute load across a network of computers by using this technique. A crucial aspect in any consensus optimization problem is the selection of the penalty parameter used in the alternating direction method of multipliers (ADMM) iterations. This affects the convergence speed as well as the accuracy. In this paper, we use the Hessian of the cost function used in calibration to appropriately select this penalty. We extend our results to a multi-directional <b>calibration</b> <b>setting,</b> where we propose to use a penalty scaled by the squared intensity of each direction. Comment: Draft, to be published in the Proceedings of the 24 th European Signal Processing Conference (EUSIPCO- 2016) in 2016, published by EURASI...|$|E
40|$|This study compares ERS {{scatterometer}} {{top soil}} moisture observations with simulations of a dual layer conceptual hydrologic model. The comparison is performed for 148 Austrian catchments {{in the period}} 1991 – 2000. On average, about 5 to 7 scatterometer images per month with a mean spatial coverage of about 37 % are available. The {{results indicate that the}} agreement between the two top soil moisture estimates changes with the season and the weight given to the scatterometer in hydrologic model calibration. The hydrologic model generally simulates larger top soil moisture values than are observed by the scatterometer. The differences tend to be smaller for lower altitudes and the winter season. The average correlation between the two estimates is more than 0. 5 in the period from July to October, and about 0. 2 in the winter months, depending on the period and <b>calibration</b> <b>setting.</b> Using both ERS scatterometer based soil moisture and runoff for model calibration provides more robust model parameters than using either of these two sources of information...|$|E
40|$|The {{reliability}} {{of a specific}} unit of commercial on-line NIR equipment for measuring the infernal quality of citrus was studied to verify its actual performance. Mandarins and oranges were measured at the packing house with the optical commercial equipment; following reference tested in the laboratory for soluble solids and acidity. The repeatability and the the reproducibiiity (position, temperature and <b>calibration</b> <b>set).</b> Proper <b>calibration</b> of the equipment's software using sample <b>calibration</b> <b>sets</b> with wide ranges was essential forobtaining reliable results...|$|R
40|$|International audienceThe hyperspectral imaging {{technology}} {{is used to}} detect early-maturing pear’s effective acidity nondestructively, and effective prediction model is established. 145 pears’ hyperspectral images are obtained in the wavelength range of 400 nm- 1000 nm. Total 145 pears are separated into the <b>calibration</b> <b>set</b> (77 samples) and prediction set (68 samples). Early-maturing pear’s effective acidity partial least squares (PLS) prediction model is built in different range of spectrum band. By comparison, the range 498 nm - 971 nm was selected in using partial least squares (PLS) to build early-maturing pear’s effective acidity prediction model. The experimental results show that, PLS prediction model of early-maturing pear’s effective acidity has the best effect in this range of wavelength. The correlation coefficient R between early-maturing pear’s actual effective acidity and predicted effective acidity is 0. 9944 and 0. 9233 for <b>calibration</b> <b>set</b> and prediction set respectively, the root mean squared error of prediction samples (RMSEP) is 0. 022 and 0. 072 for <b>calibration</b> <b>set</b> and prediction set respectively...|$|R
40|$|In {{high-performance}} liquid chromatography, quantitative structure-retention relationships (QSRRs) {{are applied}} to model the relation between chromatographic retention and quantities derived from molecular structure of analytes. Classically {{a substantial number of}} test analytes is used to build QSRR models. This makes their application laborious and time consuming. In this work a strategy is presented to build QSRR models based on selected reduced <b>calibration</b> <b>sets.</b> The analytes in the reduced <b>calibration</b> <b>sets</b> are selected from larger sets of analytes by applying the algorithm of Kennard and Stone on the molecular descriptors used in the QSRR concerned. The strategy was applied on three QSRR models of different complexity, relating log kw or log k with either: (i) log P, the n-octanol-water partition coefficient, (ii) calculated quantum chemical indices (QCI), or (iii) descriptors from the linear solvation energy relationship (LSER). Models were developed and validated for 76 reversed-phase high-performance liquid chromatography systems. From the results we can conclude {{that it is possible to}} develop log P models suitable for the future prediction of retentions with as few as seven analytes. For the QCI and LSER models we derived the rule that three selected analytes per descriptor are sufficient. Both the dependent variable space, formed by the retention values, and the independent variable space, formed by the descriptors, are covered well by the reduced <b>calibration</b> <b>sets.</b> Finally guidelines to construct small <b>calibration</b> <b>sets</b> are formulated. © 2009 Elsevier B. V. All rights reserved...|$|R
40|$|Objective The aim of {{the present}} work was to {{determine}} what dietary assessment method can provide a valid and accurate estimate of nutrient intake by comparison with the gold standard. Design A MEDLINE, EMBASE, ISI Web of Science, Cochrane and related references literature review was conducted on dietary assessment methods for adolescents reporting the validity and/or reproducibility values. A study quality assessment on the retrieved FFQ was carried out according to two different scoring systems, judging respectively the quality of FFQ nutrition information and of FFQ validation and <b>calibration.</b> <b>Setting</b> The present review considered adolescents attending high schools and recruited in hospitals or at home. Subjects The target of the review was the healthy adolescent population in the age range 13 - 17 years. Results Thirty-two eligible papers were included and analysed separately as 'original articles' (n 20) and 'reviews' (n 12). The majority (n 17) assessed the validation and reproducibility of FFQ. Almost all studies found the questionnaires to be valid and reproducible (r > 0 · 4), except for some food groups and nutrients. Different design and validation issues were highlighted, such as portion-size estimation, number of food items and statistics used. Conclusions The present review offers new insights {{in relation to the}} characteristics of assessment methods for dietary intake in adolescents. Further meta-analysis is required although the current review provides important indications on {{the development of a new}} FFQ, addressing the need for a valid, reproducible, user-friendly, cost-effective method of accurately assessing nutrient intakes in adolescents...|$|E
40|$|During an USEPA {{study in}} the Phoenix area from 1995 - 1998, {{measurements}} from a federal reference method (FRM) monitor, calibrated in accordance with National Ambient Air Quality Standards, were available less frequently with levels of accuracy and bias that di#ered from a colocated non-FRM or equivalent monitor. Using the soil constituent of PM 2. 5 (particles of aerodynamic particle diameter less than 2. 5 micrometers (m)) as an illustration, a Bayesian hierarchical calibration model is developed that combines information from reference and equivalent monitors to produce a temporally resolved posterior distribution of the complete concentration time series. Mean concentrations are modeled using a regression structure that reflects the influence of meteorology. To account for bias in monitors relative to each other, the mean at the equivalent monitor {{is represented by the}} product of an unknown bias parameter times the unknown mean concentration at the reference monitor. Estimation of the bias parameter involves inference about the ratio of normal means as in the well-known Fieller-Creasy problem. A new multi-parameter reference prior is developed for this comparative <b>calibration</b> <b>setting,</b> permitting simultaneous inference about the underlying mean concentrations and the bias parameter. By using a Bayesian hierarchical approach, the posterior distribution of unknown pollutant concentrations conditional on the measured data and model parameters can be estimated at all time points including those with missing data. The implications of using monitoring data from a biased monitor in models relating PM 2. 5 constituents and health are described in terms of the model...|$|E
30|$|The 18 F {{procedure}} {{involved the}} following steps. An 18 F sample was prepared in a 0.5 -mL volume within a 3 -mL plastic syringe. The activity {{was measured using}} a radionuclide calibrator (CRC 15 W, Capintec), and all subsequent measurements were decay-corrected back to this reference time. The <b>calibration</b> <b>setting</b> for 18 F (# 484) had been previously determined using an NIST-traceable 68 Ge/ 68 Ga mock syringe source that had been cross-calibrated for 18 F (X-Cal, RadQual, Weare, NH, USA). The radioactive sample was transferred from the syringe and mixed with approximately 30 mL of water in a closed container. Residual activity in the syringe was measured and subtracted from the original measurement to {{determine the amount of}} activity in the approximately 30 -mL solution. The exact volume of the radioactive solution was determined by weighing the container before and after filling using an accurate balance (XS 105, Mettler Toledo, Columbus, OH, USA) and an assumption of 1 g/mL for the density of water. In this way, the activity concentration (Bq/mL) in a stock solution was accurately measured. Five 0.3 -mL samples were pipetted from this solution and transferred to five glass test tubes with stoppers. The exact volumes of the radioactive samples in each test tube were determined by weighing each tube before and after filling. From the volume of each sample and the activity concentration of the stock solution, the activity in each test tube was determined (approximately 5 kBq). The samples were each counted for 1 min using the 409 - to 613 -keV energy window with background, deadtime, and decay corrections applied. The efficiency of the gamma counter for 18 F was determined by dividing the gamma counter data (CPM/ 60) by the activities in the samples (Bq). The entire measurement procedure was repeated on three separate occasions.|$|E
40|$|The {{inference}} of past temperatures from a sedimentary pollen record {{depends upon}} the sta-tionarity of the pollen-climate relationship. However, humans have altered vegetation inde-pendent of changes to climate, and consequently modern pollen deposition {{is a product of}} landscape disturbance and climate, which is different from the dominance of climate-derived processes in the past. This problem could cause serious signal distortion in pollen-based reconstructions. In the north-central United States, direct human impacts have strongly altered the modern vegetation and hence the pollen rain since Euro-American set-tlement in the mid- 19 th century. Using instrumental temperature data from the early 1800 s from Fort Snelling (Minnesota), we assessed the signal distortion and bias introduced by using the conventional method of inferring temperature from pollen assemblages in compar-ison to a <b>calibration</b> <b>set</b> from pre-settlement pollen assemblages and the earliest instrumen-tal climate data. The early post-settlement <b>calibration</b> <b>set</b> provides more accurate reconstructions of the 19 th century instrumental record, with less bias, than the modern set does. When both modern and pre-industrial <b>calibration</b> <b>sets</b> are used to reconstruct pas...|$|R
40|$|Calibration is {{the first}} step in the {{prediction}} of concentrations from spectral measurements of chemical reaction systems. It is a well-known fact that the species in the <b>calibration</b> <b>set</b> must include those in the new <b>set.</b> Typically, the <b>calibration</b> <b>set</b> is constructed from nonreacting mixtures of known concentrations. In this paper, it is proposed instead to use the calibration data from reacting mixtures, thereby avoiding the independent variation of possibly highly-reactive intermediates. However, for the prediction to be correct, restrictions on the initial and inlet concentrations of the new data set must be imposed. When these restrictions cannot be met, calibration of data in reaction-variant form is proposed. The methodology is illustrated experimentally using an esterification reaction...|$|R
3000|$|... 2) {{and root}} mean square error of {{prediction}} (RMSEP) served as the statistical measures of predictive power. RMSEP values were used to measure how well the calibration model predicts the parameter of interest for a set of unknown samples excluding the <b>calibration</b> <b>set.</b>|$|R
40|$|Calibration of car-following models against {{trajectory}} {{data has}} been widely applied {{as the basis for}} several type of studies ranging from the investigation and benchmarking of models, to the study of parameters correlation, or other theoretical issues like the inter/intra driver heterogeneity or the multi-anticipative driving behaviour. However, very few of these studies attempted also to analyze and quantify the uncertainty entailed in the calibration process and its impacts on the accuracy and reliability of results. A thorough understanding of the whole calibration problem (against trajectory data), {{as well as of the}} mutual effect of the specific problems raised in the field literature, indeed, does not yet exist. In this view, a general methodology to assess a calibration procedure was proposed and applied to the calibration of the Gipps’ car-following model. Compact indicators were proposed to evaluate the capability of a <b>calibration</b> <b>setting</b> to find the “known” global solution, in terms of both the accuracy and the robustness as to the variation of the starting conditions of the optimisation algorithm. Then, a graphical inspection method, based on the so called cobweb plots, was proposed to explore the existence and the nature of the local minima found by the algorithms, as well as to give insights into the measure of performances and the goodness of fit functions used in the calibration experiments. The methodology has been applied to all the calibration settings (i. e. combinations of algorithms, measure of performances and goodness of fit functions) utilized in the field literature so far. The study allowed us to highlight and motivate, for the model under investigation, the limits of some of these calibration settings. Research lines towards the definition of robust settings for the problem of car-following models calibration based on real trajectory data, are finally outlined...|$|E
40|$|The TSI DustTrak Aerosol Monitor is a {{portable}} real-time instrument widely used for particulate matter (PM) mass concentrations monitoring. The {{aim of this}} work is to report on issues that have arisen {{from the use of}} the latest generation models DustTrak DRX (8533 and 8534) in the BREATHE, UPTECH and IMPROVE projects that can compromise data quality. The main issue we encountered was the occurrence of sudden artefact jumps in PM concentration, which can involve an increase from a few to some hundreds of µg·m- 3. These artefact jumps can sometimes be easily recognised (“obvious jump”), while others can be difficult to identify because the difference in the concentrations before and after the jump might be just few µg·m- 3 (“possible jump”) or because the jump is sustained over the whole monitoring period and only detectable if PM concentrations are simultaneously measured by other instruments (“hidden jump”). Moreover, in areas of relatively low PM levels, the unit reported concentration of 0 µg·m- 3 for ambient PM concentration or even negative concentration values which may seriously compromise the dataset. These data suggest issues with the detection of low PM concentrations, which could be due to an incorrect instrument offset or the factory <b>calibration</b> <b>setting</b> being inadequate for these PM concentrations. The upward and downward artefact jumps were not related to especially dusty or clean conditions, since they have been observed in many kinds of environments: indoor and outdoor school environments, subway stations and in ambient urban background air. Therefore, PM concentration data obtained with the TSI DustTrak DRX models should be handled with care and meticulously revised before being considered valid. To prevent these issues the use of auto zero module is recommended, so the DustTrak monitor is automatic re-zeroed without requiring the presence of any use...|$|E
40|$|During {{a one-year}} {{supervision}} phase the function {{and operation of}} dynamic axle load weighing equipment was to be investigated at five measuring points on motorways in Hesse according to the bending plate principle {{in conjunction with a}} traffic computer centre, and during this period any longterm data and sporadic data collected on individual vehicles was to be analysed. An evaluation system was to be developed for the long-term data, and this was to be programmed {{in the form of a}} database. Furthermore, correlations between axle load distributions and the vehicle mix, depending on the traffic characteristics of a section, were to be investigated. During the test operation the accuracy of the dynamic axle load equipment was to be checked with the aid of static weighing equipment (wheel load measuring equipment), and the experience gained during the practical operation of the equipment systems was to be documented. The documentation of all breakdowns and malfunctions showed limited breakdown times of a total of one to three weeks for each of the five measuring points during a stipulated eight-month analysis period. In the initial phase there were a few breakdowns and malfunctions in the equipment due to hardware and software errors, which were immediately remedied through exchanging the respective defect electronic components and improving the software - in particular to adapt it to the TLS requirements. With regard to the accuracy of the axle load measurements compared to the static measuring results, relatively limited deviations were determined, and the long-term stability of the <b>calibration</b> <b>setting</b> was proved over a period of six months. After initial difficulties, the equipment system with bending plates which was used for these measurements was hence able to prove its suitability, above all with regard to the further expansion of the network. (orig.) Summary in FrenchAvailable from TIB Hannover: ZA 4681 (775) +a / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|A {{total of}} 139 batches of Chrysanthemum samples were {{randomly}} divided into <b>calibration</b> <b>set</b> (92 batches) and prediction set (47 batches). The near infrared diffuses reflectance spectra of Chrysanthemum varieties were preprocessed by a first order derivative (D 1) and autoscaling, and a modelwas built using partial least squares analysis. In this study, three Chrysanthemum varieties were identified, the accuracy rates in <b>calibration</b> <b>sets</b> of Dabaiju, Huju, and Xiaobaiju are 97. 60, 96. 65, and 94. 70 %, respectively; And 95. 16, 86. 11, and 93. 46 % accuracy rate in prediction sets was obtained. The research results {{demonstrate that the}} qualitative analysis can be conducted by machine learning combined with Near-Infrared Spectroscopy, which provides a new method for rapid and non-invasive identification of Chrysanthemum varieties...|$|R
40|$|We {{describe}} {{a method of}} fitting a model of germplasm distribution to climate data and illustrate it`s use in mapping the continental distribution of five Stylosanthes species. The climate data used are the monthly totals of rainfall and the monthly mean temperatures and diurnal temperature ranges. The data are rotated in time to standardize dates and then used in a principal components analysis to develop a function giving the probability density of a climate being {{similar to those of}} a <b>calibration</b> <b>set</b> of germplasm accessions. We present maps of the distributions of the <b>calibration</b> <b>sets</b> and probability densities and show how they can be used to guide further collection and to develop hypotheses of the genetic diversity within and between specie...|$|R
40|$|AbstractA {{total of}} 139 batches of Chrysanthemum samples were {{randomly}} divided into <b>calibration</b> <b>set</b> (92 batches) and prediction set (47 batches). The near infrared diffuses reflectance spectra of Chrysanthemum varieties were preprocessed by a first order derivative (D 1) and autoscaling, and a modelwas built using partial least squares analysis. In this study, three Chrysanthemum varieties were identified, the accuracy rates in <b>calibration</b> <b>sets</b> of Dabaiju, Huju, and Xiaobaiju are 97. 60, 96. 65, and 94. 70 %, respectively; And 95. 16, 86. 11, and 93. 46 % accuracy rate in prediction sets was obtained. The research results {{demonstrate that the}} qualitative analysis can be conducted by machine learning combined with Near-Infrared Spectroscopy, which provides a new method for rapid and non-invasive identification of Chrysanthemum varieties...|$|R
40|$|This thesis {{focuses on}} methodological aspects of oral health research, more {{specifically}} aspects {{related to the}} problem of misclassification of measurements by examiners. In the present work, the problem of misclassification was studied within the setting of caries experience surveys. In the introductory chapters, the general context of the performed research is depicted. In Chapter 1 the disease of interest, caries, is considered. Aspects of terminology used when screening caries experience are clarified. Specific attention is paid to the detection of the disease entity, more specifically in an epidemiological context, and the impact of detection thresholds. Finally, a critical reflection is made on the validity of the obtained information and its assessment. In Chapter 2 the motivating survey, the Smile for Life project, is presented. The general set-up of this oral health promotion study in Flemish young children and their parents, is described. Details are provided on the assessment of caries experience in these children and on standardization guidelines that were used. The training of the examiners is described and the organization of the (classical) calibration exercises is illustrated, including the methodology used for assessing examiner agreement. In Chapter 3, the field calibration technique that was developed and implemented as part of the thesis research work is introduced. This novel approach differs from the classical calibration exercise since it allows the evaluation of the scoring behaviour of the examiners in field circumstances, without the examiners being aware that their scoring ability is checked upon. The practical implementation of this type of validation is described in detail in this chapter. Chapter 4 covers the objectives of the present research work. The overall objective is to contribute to the handling of the problem of misclassification in caries experience surveys including multiple examiners. More specifically, four different objectives were defined. The results are described in the subsequent chapters. In Chapter 5, a review is presented of methodological aspects of caries experience assessment used in recent reports on caries experience surveys. From this review {{it became clear that the}} reporting of methodological aspects needs improvement. Journals with Impact Factor provided information on methodological aspects more often than journals without. In addition, it was noticed that papers reporting the use of standardized criteria often revealed deviations from the original description of the guideline. Of course, this hampers the (external) validity of the obtained results. In order to improve the quality of this aspect, a check-list of methodological aspects to be included in caries experience survey reports was developed. Chapter 6 explores methodological aspects used for assessing examiner reliability when scoring caries experience. Agreement can be measured using different techniques: kappa statistic, percentage agreement, dice coefficient, sensitivity and specificity. Each of these methods shows specific characteristics and has its own shortcomings. These are illustrated using data from the Smile for Life project. The impact of unit of analysis (subject, tooth, surface) and the disease level in the validation sample are illustrated and the need for multilevel modeling in case of dependency among observations (clustering) is shown. The impact of the validation setting on examiner performance in caries experience surveys was evaluated, considering other possible influencing factors. The results are shown in Chapter 7. It is clear that misclassification measurements for scoring caries experience are influenced by several factors. In the Smile for Life survey, the validation setting influenced sensitivity with lower scores obtained when measuring data validity in field conditions. Results obtained in a pre-survey <b>calibration</b> <b>setting</b> therefore need to be interpreted with caution and do not (always) reflect the actual performance of examiners during the field work. In Chapter 8 the nature of misclassification by examiners involved in caries experience scoring in young children was explored. Commonly used agreement measures fail to give a detailed insight into the misclassification process. However, this information is of great value for the individual examiners, allowing for correction of their scoring behavior. In addition, principal investigators of a survey can use this information for future training purposes. As part of this work, a graphical tool was developed to summarize the overscoring and underscoring of caries experience. This didactic tool can improve feedback after calibration. status: publishe...|$|E
40|$|Methane (CH 4) {{naturally}} {{produced by}} dairy cows during ruminal fermentation {{is an important}} greenhouse gas. An equation based on 446 reference data has been developed to predict easily individual CH 4 emissions from milk mid-infrared (MIR) spectra. This equation was based on CH 4 data measured exclusively with the SF 6 technique on 146 distinct Holstein, Jersey and Holstein×Jersey cows. As breeds, managements, diets, etc. are different from one geographical area to another, representative reference data have {{to be included in}} the <b>calibration</b> <b>set</b> before applying this equation in a location. However, the local CH 4 data needed are likely to be collected with different techniques (chambers, GreenFeed, etc.) depending on the research team and its equipment. A first study has therefore been conducted (1) to test the performance of the actual equation on data obtained in open-circuit chambers and (2) to analyse the impact of the inclusion of these data in the <b>calibration</b> <b>set.</b> A total of 60 chamber measurements of CH 4 and milk MIR spectra were obtained from 30 lactating Brown-Swiss cows. The correlation between actually measured and predicted CH 4 (C 1) was 0. 48. This result is in the range of expectations given the R 2 c of the equation (0. 75), the correlation known between SF 6 and chamber methods (~ 0. 80), and the breed and diet differing between <b>calibration</b> <b>sets.</b> The correlation was about 0. 70 after the inclusion of the chamber data (and so the inherent variability) in the <b>calibration</b> <b>set</b> (C 2). As chambers are known as the gold standard method, the C 1 observed confirms the relevance of using milk MIR technique. Moreover, C 2 is very encouraging regarding the possibility to include data coming from chambers into the existing CH 4 equation. Peer reviewe...|$|R
40|$|Genome-enabled {{prediction}} provides breeders {{with the}} means {{to increase the number}} of genotypes that can be evaluated for selection. One of the major challenges in genome-enabled prediction is how to construct a training set of genotypes from a <b>calibration</b> <b>set</b> that represents the target population of genotypes, where the <b>calibration</b> <b>set</b> is composed of a training and validation set. A random sampling protocol of genotypes from the <b>calibration</b> <b>set</b> will lead to low quality coverage of the total genetic space by the training <b>set</b> when the <b>calibration</b> <b>set</b> contains population structure. As a consequence, predictive ability will be affected negatively, because some parts of the genotypic diversity in the target population will be under-represented in the training set, whereas other parts will be over-represented. Therefore, we propose a training set construction method that uniformly samples the genetic space spanned by the target population of genotypes, thereby increasing predictive ability. To evaluate our method, we constructed training sets alongside with the identification of corresponding genomic prediction models for four genotype panels that differed in the amount of population structure they contained (maize Flint, maize Dent, wheat, and rice). Training sets were constructed using uniform sampling, stratified-uniform sampling, stratified sampling and random sampling. We compared these methods with a method that maximizes the generalized coefficient of determination (CD). Several training set sizes were considered. We investigated four genomic prediction models: multi-locus QTL models, GBLUP models, combinations of QTL and GBLUPs, and Reproducing Kernel Hilbert Space (RKHS) models. For the maize and wheat panels, construction of the training set under uniform sampling led to a larger predictive ability than under stratified and random sampling. The results of our methods were similar to those of the CD method. For the rice panel, all training set construction methods led to similar predictive ability, a reflection of the very strong population structure in this panel...|$|R
40|$|The {{ability of}} {{mid-infrared}} (MIR) spectroscopy {{as a quick}} technique for determining wood properties of Eucalyptus globulus plantations, specifically basic density and pulping yield, has been examined. Twenty-seven samples were used as a <b>calibration</b> <b>set</b> and other three, for prediction making based on <b>calibration</b> (validation <b>set).</b> <b>Calibrations</b> and predictions through principal components regression (PCR) were obtained through the Quant+ chemometrics. Spectral data for a PCR model based on diffuse reflectance infrared Fourier transform (DRIFT), gave standard prediction error values of 21. 44 kg m- 3 and 1. 73 % for basic density and pulping yield, respectively. The method allows to predict density (R² = 0. 84) and pulping yield (R²= 0. 40) from a single spectral MIR measuremen...|$|R
40|$|A {{statistical}} {{analysis was performed}} I on a large spectral data set to analyse the effect of orchard, season and cultivar. Season and cultivar were responsible for a major amount of the spectral variability, whereas the influence of the orchard was low and only appeared for certain cultivars during specific seasons. The robustness of the calibration models for soluble solids content with respect to the three factors was tested based on external validations. It was found that the accuracy of the models increased considerably when including more variability in the <b>calibration</b> <b>set.</b> Further, overfitting of the calibration model was avoided. On the other hand, adding more data to the <b>calibration</b> <b>set</b> increased the chance of adding atypical data, which resulted in reduced model accuracy. It is, therefore, important to construct the <b>calibration</b> data <b>set</b> {{in such a way that}} it is representative for future measurements. When the effect of a certain factor is known a priori, e. g. cultivar, it is recommended to use specific calibration models. (C) 2002 Elsevier Science B. V. All rights reserved. status: publishe...|$|R
3000|$|... 2) {{were used}} to assess the fitting performance. The {{standard}} error of prediction (SEP) was employed to evaluate the accuracy of the established model by predicting the parameter of interest for a set of unknown samples that are different from the <b>calibration</b> <b>set.</b> The predicting coefficient of determination (R [...]...|$|R
