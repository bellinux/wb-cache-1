228|482|Public
25|$|A SYN flood {{occurs when}} a host sends a flood of TCP/SYN packets, often with a forged sender address. Each of these packets are handled like a <b>connection</b> <b>request,</b> causing the server to spawn a half-open connection, by sending back a TCP/SYN-ACK packet (Acknowledge), and waiting for a packet in {{response}} from the sender address (response to the ACK Packet). However, because the sender address is forged, the response never comes. These half-open connections saturate the number of available connections the server can make, keeping it from responding to legitimate requests until after the attack ends.|$|E
50|$|SYN-SENT: (client) {{represents}} {{waiting for}} a matching <b>connection</b> <b>request</b> after having sent a <b>connection</b> <b>request.</b>|$|E
50|$|SYN-RECEIVED: (server) {{represents}} {{waiting for}} a confirming <b>connection</b> <b>request</b> acknowledgment after having both received and sent a <b>connection</b> <b>request.</b>|$|E
3000|$|... σ {{ranges from}} 0 to 62, while the arrival rates of new <b>connection</b> <b>requests</b> from {{services}} type 1 and 2 remain constant at 0.5 <b>connection</b> <b>requests</b> per minute and ψ = 50. Pb 1 and Pb 2 are the blocking probabilities of new <b>connection</b> <b>requests</b> of types 1 and 2 services, respectively. Pf 1, Pf 2, and Pf 3 are the forced termination probabilities of handover <b>connection</b> <b>requests</b> of types 1, 2, and 2 * services, respectively. The blocking probabilities of new <b>connection</b> <b>requests</b> and the dropping probabilities of handover <b>connection</b> <b>requests</b> of type 2 services {{are the highest}} because the connections require five {{times the amount of}} BBUs as type 1 services. In contrast, the dropping probabilities of handover <b>connection</b> <b>requests</b> of a type 2 * service are higher than a type 1 service. This is because the connection requirement of a type 2 * service requires three times as many BBUs as type 1 services.|$|R
3000|$|... min. The CMR will {{increase}} and both λ 1 and λ 2 increase while the inter-boundary time in each cell is fixed. Next, the blocking probabilities of new <b>connection</b> <b>requests</b> and the dropping probabilities of handover <b>connection</b> <b>requests</b> {{for the two}} services are increased because the occupancy of cell 1 is increased, as shown in Figure[*] 5.|$|R
40|$|The {{grooming}} factor C of a WDM {{optical network}} {{is the number}} of connections that can share the bandwidth of each wavelength and the process of grouping the requests that will share each wavelength is called traffic grooming. The goal of traffic grooming is either to reduce the transmission cost by reducing the number of wavelengths or to reduce the hardware cost by reducing the number of Add-Drop Multiplexors (ADM). In this paper, we investigate traffic grooming for directed path networks with online <b>connection</b> <b>requests</b> and distributed routing algorithms. When <b>connection</b> <b>requests</b> are online, the virtual topology that results from the assignment of ADMs to wavelengths cannot be changed with each request. The design of efficient virtual topologies that minimize either the number of ADMs needed to satisfy any set of <b>connection</b> <b>requests</b> or the blocking of <b>connection</b> <b>requests</b> depends strongly on the routing algorithm. We show how to design the best possible virtual topologies, independently of the routing algorithm, when each node is equipped with the same number of ADMs, and we analyze the performance of distributed greedy routing algorithms...|$|R
50|$|Client sends a <b>connection</b> <b>request</b> {{similar to}} SOCKS4.|$|E
50|$|LISTEN: (server) {{represents}} {{waiting for}} a <b>connection</b> <b>request</b> from any remote TCP and port.|$|E
50|$|Amendment 5 of the {{protocol}} introduces alternative method of executing <b>Connection</b> <b>Request</b> via NAT based on XMPP (see Annex K of TR-069 Amendment 5 for details).|$|E
3000|$|We {{evaluated}} {{the performance of}} the cellular systems using a policy based on the arrival rates of <b>connection</b> <b>requests.</b>|$|R
30|$|Previous studies[6] have {{demonstrated}} {{the effect of the}} level of guard capacity on blocking and forced termination probabilities. The blocking probabilities for new <b>connection</b> <b>requests</b> by two services increase whereas the dropping probabilities of handover <b>connection</b> <b>requests</b> by two services decrease when the guard capacity Cg changes from 0 to 48. Previous studies[6] have reduced the forced termination probability to a very low value by allowing the blocking probability to reach a higher level.|$|R
30|$|To {{create a}} server connection. In this case, {{this is the}} <b>connection</b> <b>requested</b> in step 3 {{executed}} by the above-mentioned GSCA application.|$|R
50|$|In {{this example}} MyVariable is of type INTEGER {{and is the}} only {{variable}} in the process. The first transition is the start transition that initializes the local variable. A <b>connection</b> <b>request</b> message conReq is sent, a 5 seconds timer conReqTimer is started, and the state machine goes to the connecting state. In the connecting state if the timer goes off -that is equivalent to a message receive- the <b>connection</b> <b>request</b> is sent again up to 10 times. If a connection confirmation is received the state machine goes to connected state. This is a typical telecommunication protocol scenario.|$|E
50|$|IP-Reputation Anti-spam It checks each email <b>connection</b> <b>request</b> with a {{database}} of IP addresses to establish whether a sender is legitimate or known spam sender and malware. If a sender is recognize us undesirable the messaging Security program drops the connection before de message is accepted.|$|E
50|$|The general {{objective}} of the RWA problem is to maximize the number of established connections. Each <b>connection</b> <b>request</b> must be given a route and wavelength. The wavelength must be consistent for the entire path, unless the usage of wavelength converters is assumed. Two connections requests can share the same optical link, provided a different wavelength is used.|$|E
3000|$|When {{one more}} video call request is added into the network, {{the number of}} <b>connection</b> <b>requests</b> {{increases}} to 16 and e [...]...|$|R
30|$|The saved {{bandwidth}} {{can be used}} {{to accept}} new <b>connection</b> <b>requests</b> if the saved bandwidth meets the QoS needs of the new connection.|$|R
3000|$|We {{developed}} {{a method for}} reducing blocking and dropping probabilities. The method used adaptive coding of handover <b>connection</b> service <b>requests</b> and the parameter adjustment of CAC policy functions in a multi-service cellular system. Mobility and handovers are important factors in cellular systems, so multiservices based on models with user mobility and a CAC policy were considered. Our study considered the mobility and arrival (departure) rate of user <b>connection</b> <b>requests,</b> the capacity of each cell, CAC policy, the adaptive coding probability of the “dual mode full-rate service type”, and blocking (dropping) probabilities of <b>connection</b> <b>requests</b> for each service. An efficient method is proposed to derive a better connection-level QoS, which was verified by performance simulations. The {{results indicate that the}} reservation policy for the new <b>connection</b> <b>requests</b> threshold ψ and the adaptive coding threshold σ were effective in providing a better connection-level QoS for new and handover calls. As an example in our study, we can see that in cell 1, the new call dropping probability for type 1 services falls from [...]...|$|R
5000|$|Asynchronous method {{dispatch}} (AMD) is a {{data communication}} method used {{when there is}} a need for the server side to handle a large number of long lasting client requests. Using synchronous method dispatch (SMD), this scenario may turn the server into an unavailable busy state resulting in a connection failure response caused by a network <b>connection</b> <b>request</b> timeout.|$|E
50|$|An {{application}} that wishes {{to use a}} connection-oriented network to transport traffic must first request a connection (through signalling, for example Q.2931), which involves informing the network about {{the characteristics of the}} traffic and the quality of service (QoS) required by the application. This information is matched against a traffic contract. If the <b>connection</b> <b>request</b> is accepted, the application is permitted to use the network to transport traffic.|$|E
5000|$|... #Caption: The diagram shows three entities. At {{start the}} phone is disconnected. A user tries to {{establish}} a connection. A <b>connection</b> <b>request</b> {{is sent to the}} switch and a timer is started. An alternative deals with two possibles responses: 1 - The timer goes off because the switch did not reply and the phone goes back to the disconnected state.2 - The switch grants the connection and the call is established.|$|E
50|$|FIN-WAIT-1: (both server and client) {{represents}} {{waiting for}} a <b>connection</b> termination <b>request</b> from the remote TCP, or an acknowledgment of the <b>connection</b> termination <b>request</b> previously sent.|$|R
50|$|Another of Mixer’s offerings is {{that users}} can refine their {{searches}} by location, industries, and industry-specific professions, and then either send <b>connection</b> <b>requests</b> or skip users through swiping.|$|R
50|$|LAST-ACK: (both server and client) {{represents}} {{waiting for}} an acknowledgment of the <b>connection</b> termination <b>request</b> previously sent to the remote TCP (which includes an acknowledgment of its <b>connection</b> termination <b>request).</b>|$|R
50|$|For example, {{suppose a}} user {{utilizes}} a remote access VPN software client connecting to a corporate network using a hotel wireless network. The user with split tunneling enabled {{is able to}} connect to file servers, database servers, mailservers and other servers on the corporate network through the VPN connection. When the user connects to Internet resources (Web sites, FTP sites, etc.), the <b>connection</b> <b>request</b> goes directly out the gateway provided by the hotel network.|$|E
50|$|Fixed {{alternate}} routing {{is an extension}} of fixed path routing. Instead of having just one fixed route for a given source and destination pair, several routes are stored. The probes can be sent in a serial or parallel fashion. For each <b>connection</b> <b>request,</b> the source node attempts to find a connection on each of the paths. If all of the paths fail, then the connection is blocked. If multiple paths are available, only one of them would be utilized.|$|E
50|$|The {{major issue}} with both fixed path routing and fixed {{alternate}} routing {{is that neither}} algorithm {{takes into account the}} current state of the network. If the predetermined paths are not available, the <b>connection</b> <b>request</b> will become blocked even though other paths may exist. Fixed Path Routing and Fixed Alternate Routing are both not quality aware. For these reasons, most of the research in RWA is currently taking place in Adaptive algorithms. Five examples of Adaptive Routing are LORA, PABR, IA-BF, IA-FF, and AQoS.|$|E
5000|$|Control thread Creates as many working threads as {{specified}} in the initialization parameter when Tibero is started, allocates new client <b>connection</b> <b>requests</b> to an idle working thread, and Checks signal processing.|$|R
30|$|The {{handover}} <b>connection</b> <b>requests</b> {{for type}} 2 services are easily changed into those of type 2 * service if the adaptation coding threshold is decreased. At this point, the average PSNR is lower {{while the average}} video quality of a type 2 service is poorer. From the other perspective, the adaptive coding probability of handover <b>connection</b> <b>requests</b> for type 2 services becomes gradually higher when σ is fixed and ψ is increased, as shown in Figure[*] 3. The average PSNR is lower, as shown in Figure[*] 4, while the average video quality of a type 2 service becomes very poor.|$|R
5000|$|Latency is {{the amount}} of delay {{associated}} with a <b>connection.</b> <b>Requesting</b> low latency in the quality of service (QoS) profile means that the cells need to travel quickly from one point in the network to another.|$|R
5000|$|Admission Control. This {{provides}} the principal mechanism used in Frame Relay {{to ensure the}} guarantee of resource requirement once accepted. It also serves generally to achieve high network performance. The network decides whether to accept a new <b>connection</b> <b>request,</b> based on {{the relation of the}} requested traffic descriptor and the network's residual capacity. The traffic descriptor consists of a set of parameters communicated to the switching nodes at call set-up time or at service-subscription time, and which characterizes the connection's statistical properties. The traffic descriptor consists of three elements: ...|$|E
50|$|A SYN flood {{occurs when}} a host sends a flood of TCP/SYN packets, often with a forged sender address. Each of these packets are handled like a <b>connection</b> <b>request,</b> causing the server to spawn a half-open connection, by sending back a TCP/SYN-ACK packet (Acknowledge), and waiting for a packet in {{response}} from the sender address (response to the ACK Packet). However, because the sender address is forged, the response never comes. These half-open connections saturate the number of available connections the server can make, keeping it from responding to legitimate requests until after the attack ends.|$|E
5000|$|A {{variation}} of HTTP tunneling when behind an HTTP proxy server {{is to use}} the [...] "CONNECT" [...] HTTP method. [...] In this mechanism, the client asks an HTTP proxy server to forward the TCP connection to the desired destination. The server then proceeds to make the connection on behalf of the client. Once the connection has been established by the server, the proxy server continues to proxy the TCP stream to and from the client. Note that only the initial <b>connection</b> <b>request</b> is HTTP - after that, the server simply proxies the established TCP connection.|$|E
5000|$|The {{lexicographical}} routing algorithm (LORA) algorithm {{was proposed}} in. The main idea behind LORA is to route <b>connection</b> <b>requests</b> away from congested areas of the network, increasing the probability that <b>connection</b> <b>requests</b> will be accepted. This is accomplished by setting the cost of each link to be [...] where [...] is parameter that can be dynamically adjusted according to the traffic load and [...] {{is the number of}} wavelengths in use on link [...] A standard shortest path algorithm can then be used to find the path. This requires each optical switch to broadcast recent usage information periodically. Note that LORA does not consider any physical impairments.|$|R
3000|$|... [...]. The arrival rate of new <b>connection</b> <b>requests</b> {{for type}} 1 (λ 1) and type 2 (λ 2) {{services}} are set from 0 to 1. Next, the interboundary time of each cell has {{a mean of}} [...]...|$|R
3000|$|Assuming {{that there}} is one request for each service type and service class shown in Table 3, we have in total 12 <b>connection</b> <b>requests</b> to {{consider}} in the WLAN. Based on Equations 2 to 7, e [...]...|$|R
