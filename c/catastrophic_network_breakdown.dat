0|113|Public
5000|$|... #Subtitle level 3: Kerner’s <b>network</b> <b>breakdown</b> {{minimization}} (BM) principle ...|$|R
40|$|In {{the present}} paper, we derive an upper bound {{of the average}} <b>network</b> <b>breakdown</b> {{probability}} of packet networks with unreliable relay nodes. We here assume that relay nodes get independently broken with a given node breakdown probability. A survivor graph is the induced subgraph obtained by removing the broken relay nodes and their connecting edges from the original graph. If the survivor network is disconnected, we consider a <b>network</b> <b>breakdown</b> happens. The primal contribution of the paper is to derive an upper bound of the average <b>network</b> <b>breakdown</b> probability, where the expectation is taken over a regular graph ensemble. The proof of the bound {{is based on a}} natural one-to-one correspondence between a regular graph and a regular bipartite graph, and also on enumeration of bipartite graphs satisfying certain conditions. This proof argument is inspired by the analysis of weight distribution for low-density parity-check codes. Compared with estimates of the average <b>network</b> <b>breakdown</b> probability obtained by computer experiments, it is observed that the upper bound provides the values which are not only upper bounds but also precise estimates of the <b>network</b> <b>breakdown</b> probability when the node breakdown probability is small. Comment: 5 pages, 4 figures, submitted to ISIT 201...|$|R
50|$|Every {{week they}} also deal with 650 <b>network</b> <b>breakdowns</b> due to damage, theft and weather, test 12,000 poles and replace 920, replace 85 cables and street cabinets, fix 100 low wires and connect another 3,000 newsite plots to its network.|$|R
25|$|Another {{application}} is to evaluate risks related to {{events such as}} communication <b>network</b> <b>breakdowns</b> or the inability of participants to send payments (e.g. in case of possible bank failure). This kind of analysis falls under the concepts of stress testing or scenario analysis.|$|R
40|$|IEEE 802. 11 {{wireless}} networks perform {{poorly in}} the presence of large traffic volumes. Measurements have shown that packet collisions and interference can lead to degraded performance to the extent that users experience unacceptably low throughput, which can ultimately lead to complete <b>network</b> <b>breakdown</b> [19]. An admission control framework that limits network flows can prevent <b>network</b> <b>breakdown</b> and improve the performance of throughput and delay-sensitive multimedia applications. In this paper, we present a measurement-driven admission control scheme that leverages wireless characteristics for intelligent flow control in a static wireless network. Experiments on the 25 node UCSB MeshNet show that the proposed admission control scheme can enhance network performance such that the QoS requirements of real time applications, such as VoIP, can be met. 1...|$|R
40|$|The {{increased}} {{usage of}} IEEE 802. 11 wireless backhaul networks {{and the growing}} popularity of real time applications, such as VoIP, presents a challenging resource management problem due to the limited capacity of wireless networks. At high traffic volumes, measurements have shown that packet collisions and interference in 802. 11 networks can lead to degraded performance to the extent that users experience unacceptably low throughput, which can ultimately lead to complete <b>network</b> <b>breakdown</b> [1]. A resource management framework that limits network flows can prevent <b>network</b> <b>breakdown</b> and improve the performance of throughput and delay-sensitive multimedia applications. To address this problem, we present a measurementdriven framework that leverages wireless characteristics for intelligent admission control in a static wireless network. Experiments on a 25 node wireless testbed show that the proposed scheme can enhance network performance such that the QoS requirements of real time applications, such as VoIP, can be met. 1...|$|R
40|$|Conventional {{thinking}} in emergency and crisis management {{focuses on the}} application of codified procedures to unforeseen contingencies. Modern society’s increased dependence on critical infrastructures and the emerging vulnerabilities of these large-scale networks create challenges {{that are hard to}} meet with conventional tools of crisis management. This article discusses the inherent vulnerabilities and explores the requirements of effective preparation for escalatory <b>network</b> <b>breakdowns...</b>|$|R
50|$|Kerner {{introduced}} {{an alternative approach}} to traffic assignment based on his <b>network</b> <b>breakdown</b> minimization (BM) principle. Rather than an explicit minimization of travel time that is the objective of System Optimum and User Equilibrium, the BM principle minimizes the probability of the occurrence of congestion in a traffic network. Under sufficient traffic demand, {{the application of the}} BM principle should lead to implicit minimization of travel time in the network.|$|R
40|$|Infrastructures like {{telecommunication}} systems, {{power transmission}} grids and the Internet are complex networks that {{are vulnerable to}} catastrophic failure. A common mechanism behind this kind of failure is avalanche-like <b>breakdown</b> of the <b>network's</b> components. If a component fails due to overload, its load will be redistributed, causing other components to overload and fail. This failure can propagate throughout the entire network. From studies of catastrophic failures in di erent technological networks, {{the consensus is that}} the occurrence of a catastrophe is due to the interaction between the connectivity and the dynamical behaviour of the networks' elements. The research in this thesis focuses particularly on packet-oriented networks. In these networks the tra c (dynamics) and the topology (connectivity) are coupled by the routing mechanisms. The interactions between the network's topology and its tra c are complex as they depend on many parameters, e. g. Quality of Service, congestion management (queuing), link bandwidth, link delay, and types of tra c. It is not straightforward to predict whether a network will fail catastrophically or not. Furthermore, even if considering a very simpli ed version of packet networks, there are still fundamental questions about catastrophic behaviour that have not been studied, such as: will a network become unstable and fail catastrophically as its size increases; do <b>catastrophic</b> <b>networks</b> have speci c connectivity properties? One of the main di culties when studying these questions is that, in general, we do not know in advance if a network is going to fail catastrophically. In this thesis we study how to build <b>catastrophic</b> 5 <b>networks.</b> The motivation behind the research is that once we have constructed networks that will fail catastrophically then we can study its behaviour before the catastrophe occurs, for example the dynamical behaviour of the nodes before an imminent catastrophe. Our theoretical and algorithmic approach is based on the observation that for many simple networks there is a topology-tra c invariant for the onset of congestion. We have extended this approach to consider cascading congestion. We have developed two methods to construct catastrophes. The main results in this thesis are that there is a family of <b>catastrophic</b> <b>networks</b> that have a scale invariant; hence at the break point it is possible to predict the behaviour of large networks by studying a much smaller network. The results also suggest that if the tra c on a network increases exponentially, then there is a maximum size that a network can have, after that the network will always fail catastrophically. To verify if <b>catastrophic</b> <b>networks</b> built using our algorithmic approach can re ect real situations, we evaluated the performance of a small <b>catastrophic</b> <b>network.</b> By building the scenario using open source network simulation software OMNet++, we were able to simulate a router network using the Open Shortest Path First routing protocol and carrying User Datagram Protocol tra c. Our results show that this kind of networks can collapse as a cascade of failures. Furthermore, recently the failure of Google Mail routers [1] con rms this kind of catastrophic failure does occur in real situations. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|PhDInfrastructures like {{telecommunication}} systems, {{power transmission}} grids and the Internet are complex networks that {{are vulnerable to}} catastrophic failure. A common mechanism behind this kind of failure is avalanche-like <b>breakdown</b> of the <b>network's</b> components. If a component fails due to overload, its load will be redistributed, causing other components to overload and fail. This failure can propagate throughout the entire network. From studies of catastrophic failures in di erent technological networks, {{the consensus is that}} the occurrence of a catastrophe is due to the interaction between the connectivity and the dynamical behaviour of the networks' elements. The research in this thesis focuses particularly on packet-oriented networks. In these networks the tra c (dynamics) and the topology (connectivity) are coupled by the routing mechanisms. The interactions between the network's topology and its tra c are complex as they depend on many parameters, e. g. Quality of Service, congestion management (queuing), link bandwidth, link delay, and types of tra c. It is not straightforward to predict whether a network will fail catastrophically or not. Furthermore, even if considering a very simpli ed version of packet networks, there are still fundamental questions about catastrophic behaviour that have not been studied, such as: will a network become unstable and fail catastrophically as its size increases; do <b>catastrophic</b> <b>networks</b> have speci c connectivity properties? One of the main di culties when studying these questions is that, in general, we do not know in advance if a network is going to fail catastrophically. In this thesis we study how to build <b>catastrophic</b> 5 <b>networks.</b> The motivation behind the research is that once we have constructed networks that will fail catastrophically then we can study its behaviour before the catastrophe occurs, for example the dynamical behaviour of the nodes before an imminent catastrophe. Our theoretical and algorithmic approach is based on the observation that for many simple networks there is a topology-tra c invariant for the onset of congestion. We have extended this approach to consider cascading congestion. We have developed two methods to construct catastrophes. The main results in this thesis are that there is a family of <b>catastrophic</b> <b>networks</b> that have a scale invariant; hence at the break point it is possible to predict the behaviour of large networks by studying a much smaller network. The results also suggest that if the tra c on a network increases exponentially, then there is a maximum size that a network can have, after that the network will always fail catastrophically. To verify if <b>catastrophic</b> <b>networks</b> built using our algorithmic approach can re ect real situations, we evaluated the performance of a small <b>catastrophic</b> <b>network.</b> By building the scenario using open source network simulation software OMNet++, we were able to simulate a router network using the Open Shortest Path First routing protocol and carrying User Datagram Protocol tra c. Our results show that this kind of networks can collapse as a cascade of failures. Furthermore, recently the failure of Google Mail routers [1] con rms this kind of catastrophic failure does occur in real situations...|$|R
40|$|Empirical {{estimation}} of critical points at which complex systems abruptly flip from one state to another {{is among the}} remaining challenges in network science. However, due to the stochastic nature of critical transitions {{it is widely believed}} that critical points are difficult to estimate, and it is even more difficult, if not impossible, to predict the time such transitions occur [1 - 4]. We analyze a class of decaying dynamical networks experiencing persistent attacks in which the magnitude of the attack is quantified by the probability of an internal failure, and there is some chance that an internal failure will be permanent. When the fraction of active neighbors declines to a critical threshold, cascading failures trigger a <b>network</b> <b>breakdown.</b> For this class of network we find both numerically and analytically that the time to the <b>network</b> <b>breakdown,</b> equivalent to the network lifetime, is inversely dependent upon the magnitude of the attack and logarithmically dependent on the threshold. We analyze how permanent attacks affect dynamical network robustness and use the network lifetime as a measure of dynamical network robustness offering new methodological insight into system dynamics. Comment: 8 pages, 10 figure...|$|R
40|$|A {{reliable}} server assignment (RSA) {{problem in}} networks {{is defined as}} determining a deployment of identical servers to maximize a measure of service availability. In networks, the communication between a client and a server might be interrupted since the server itself is offline or unreachable {{as a result of}} <b>catastrophic</b> <b>network</b> failures. In this paper, a novel simulation optimization approach is developed based on a Monte Carlo (MC) simulation and embedded into Particle Swarm Optimization (PSO) to solve the RSA problem. The experimental results show that the simulation optimization embedded PSO is an effective heuristic method. ...|$|R
40|$|In this study, the {{following}} statistical data {{are presented in}} detail: supply and use of resources at current prices, production, exports, consumption of petroleum products and gas products, land use patterns, crop yields, livestock, production of minerals, consumer price index, income of households, central government revenue, rehabilitation fund operations, housing supply, monetary survey, structure of interest rates, expansion of Bank’s <b>network,</b> <b>breakdown</b> of imports and exports, exports of hydrocarbon, trade indices, balance of payments, external debt, nominal and real effective exchange rates, and so on. ...|$|R
40|$|A {{method is}} {{presented}} to model server unreliability in closed queuing <b>networks.</b> <b>Breakdowns</b> and repairs of servers, assumed to be time-dependent, are modeled using virtual customers and virtual servers in the system. The problem is thus converted into a closed queue with all reliable servers and preemptive resume priority centers. Several recent preemptive priority approximations and an approximation of the one proposed {{are used in the}} analysis. This method has approximately the same computational requirements as that of mean-value analysis for a network of identical dimensions and is therefore very efficien...|$|R
40|$|We {{study the}} effects of concentration, surface area and surface {{chemistry}} of fractal fumed silica aggregates on a model fat-structured food system. We use oscillatory stress sweep rheology to determine the storage modulus, the length of the linear viscoelastic region and the rate of <b>network</b> <b>breakdown</b> after the linear region. Differential scanning calorimetry shows that silica is not acting as a seed for nucleation and that the melting profiles for samples with silica are not significantly different. We interpret these results in terms of hydrogen bonding between the silica aggregates and its role in strengthening the fat crystal networks...|$|R
40|$|This work {{presents}} a theoretical and numerical {{analysis of the}} conditions under which distributed sequential consensus is possible when the state of a portion of nodes in a network is perturbed. Specifically, it examines the consensus level of partially connected blockchains under failure/attack events. To this end, we developed stochastic models for both verification probability once an error is detected and <b>network</b> <b>breakdown</b> when consensus is not possible. Through a mean field approximation for network degree we derive analytical solutions for the average network consensus in the large graph size thermodynamic limit. The resulting expressions allow us to derive connectivity thresholds above which networks can tolerate an attack...|$|R
40|$|We {{introduce}} an optimum {{principle for}} a vehicular traffic network with road bottlenecks. This <b>network</b> <b>breakdown</b> minimization (BM) principle {{states that the}} network optimum is reached, when link flow rates are assigned in the network {{in such a way}} that the probability for spontaneous occurrence of traffic breakdown at one of the network bottlenecks during a given observation time reaches the minimum possible value. Based on numerical simulations with a stochastic three-phase traffic flow model, we show that in comparison to the well-known Wardrop's principles the application of the BM principle permits considerably greater network inflow rates at which no traffic breakdown occurs and, therefore, free flow remains in the whole network. Comment: 22 pages, 6 figure...|$|R
40|$|Abstract. This paper {{presents}} the security weaknesses {{and the possible}} attacks, which threaten the GPRS backbone network and the data that either reside at the network or are transferred through it. These attacks may be performed by malicious third parties, mobile users, network operators or network operator personnel, which exploit the weaknesses of the employed technology and the security measures applied to the GPRS backbone. The possible attacks against the GPRS backbone may result in the compromise of end-users security, the users over billing, the disclosure or alteration of critical information, the ser-vices unavailability, the <b>network</b> <b>breakdown,</b> etc. The analyzed attacks and their consequences increase {{the risks associated with}} the usage of GPRS, and, thus, influence its deployment that realizes the concept of the mobile Internet. ...|$|R
40|$|CCS is a {{resource}} management system for parallel high-performanc ecomputers. At the user level, CCS provides vendor-independent access to parallel systems. At the system administrator level, CCS offers tools for controlling (i. e. specifying, configuring and scheduling) the system components that are operated in a computing center. Hence the name "Computing Center Software". CCS provides: # hardware-independent scheduling of interactive and batch jobs, # partitioning of exclusive and non-exclusive resources, # open, extensible interfaces to other resource management systems, # a high degreeofreliability #e. g. automatic restart of crashed daemons#, # fault tolerance {{in the case}} of <b>network</b> <b>breakdowns.</b> In this paper, we describe CCS as one important component for the access, job distribution, and administration of networked HPC systems in a metacomputing environment...|$|R
40|$|A Hub Location Problem (HLP) {{deals with}} finding the {{locations}} of hub facilities and assignment of demand nodes to established facilities. Hubs {{play a central role}} in many networks such as telecommunication networks and their unavailability may lead to <b>network</b> <b>breakdown</b> or poor service levels. An objective in design of a hub-and-spoke network is maximization of reliability to transfer flows. This paper puts forward design of a reliable single-allocation hub-and-spoke network using an interactive fuzzy goal programming. To model and solve the problem, a fuzzy goal programming approach was developed for design of network in an interactive manner between decision maker and the model. To validate the model and the proposed solution approach, a test problem is presented and comparison of results is made using this problem...|$|R
40|$|It is {{difficult}} to propagate disaster management information rapidly among clients when some local <b>network</b> <b>breakdown</b> takes place. By applying percolation theory to propagate newly defined reverse-query messages over the unstructured P 2 P network, we propose novel information delivery network architecture built over existing unstructured P 2 P network. We analyzed our algorithm and examine the validity of our model, that will cover more than 80 % of all the clients,with relaying reverse-query messages under probability as low as 10 %, being effective drastically to reduce the total traffic generated by query propagation. This architecture can be a solution for presenting information to {{many people in the}} devastated area over the Internet in case of natural calamity. Key words...|$|R
40|$|The fault {{tolerance}} of random graphs with unbounded degrees {{with respect to}} connectivity is investigated. It {{is related to the}} reliability of wireless sensor networks with unreliable relay nodes. The model evaluates the <b>network</b> <b>breakdown</b> probability that a graph is disconnected after stochastic node removal. To establish a mean-field approximation for the model, the cavity method for finite systems is proposed. Then the asymptotic analysis is applied. As a result, the former enables us to obtain an approximation formula for any number of nodes and an arbitrary and degree distribution. In addition, the latter reveals that the phase transition occurs on random graphs with logarithmic average degrees. Those results, which are supported by numerical simulations, coincide with the mathematical results, indicating successful predictions by mean-field approximation for unbounded but not dense random graphs. Comment: 5 page...|$|R
40|$|This thesis {{considers}} {{the problem of}} traffic restoration of individual connections {{in the presence of}} failures in high-speed, virtual circuit based, packet switched wide-area networks. A major factor on network performance after a failure is the transient congestion resulting from both the attempt to restore disrupted connections and the subsequent retransmission of packets lost due to the failure. The transient congestion must be controlled or it can spread and lead to a <b>network</b> <b>breakdown</b> (zero throughput). However, standard congestion control schemes are not effective in preventing congestion after a failure, mainly since the overload is caused by the burst from connections simultaneously trying to send out their backlog of packets. In this dissertation it is first shown that routing can control the transient congestion, and that standard routing algorithms may not be appropriate for rerouting disrupted connections. This motivates the need for dedicated fault recovery routing algorithms [...] . ...|$|R
40|$|We {{consider}} two {{applications of}} neural networks in telecommunications: (1) dynamic routing using neural network controllers; (2) a hybrid expert system for classifying error messages {{generated from the}} telecom network. A model of non-uniform data is proposed to study the features of diagnostic problems. 1. INTRODUCTION The control and management of telecommunications networks involve the dynamic optimization of large complex systems, and the processing of large amount of stochastic data. This makes neural computation an attractive approach in this area. In this paper we consider two applications of neural networks: dynamic routing [1] and error message classification [2]. In dynamic routing of telecom traffic, a centralized algorithm can make a globally optimal decision, but may involve heavy computational load for the controller, and is susceptible to <b>network</b> <b>breakdown.</b> On the other hand, decentralized algorithms have the advantages of less computational load, and robustness agains [...] ...|$|R
40|$|The January 2010 {{earthquake}} devastated Haiti’s social, {{economic and}} health infrastructure, leaving 2 million persons—one-fifth of Haiti’s population—homeless. Internally displaced persons relocated to camps, where human rights remain compromised {{due to increased}} poverty, reduced security, and limited access to sanitation and clean water. This article draws on findings from 3 focus groups conducted with internally displaced young women and 3 focus groups with internally displaced young men (aged 18 – 24) in Leogane, Haiti to explore post-earthquake tent distribution practices. Focus group findings highlighted that community members were not engaged in developing tent distribution strategies. Practices that distributed tents to both children and parents, and linked food and tent distribution, inadvertently contributed to “chaos”, vulnerability to violence and family <b>network</b> <b>breakdown.</b> Moving forward we recommend tent distribution strategies in disaster contexts engage with community members, separate food and tent distribution, and support agency and strategies of self-protection among displaced persons...|$|R
40|$|Neuroimaging {{research}} has demonstrated the involvement of a well-defined brain network in the mediation of moral judgment in normal population, and has suggested the inappropriate network use in criminal psychopathy. We used {{functional magnetic resonance imaging}} (fMRI) to prove that alterations in the brain network subserving moral judgment in criminal psychopaths are not limited to the inadequate network use during moral judgment, but that a primary <b>network</b> <b>breakdown</b> would exist with dysfunctional alterations outside moral dilemma situations. A total of 22 criminal psychopathic men and 22 control subjects were assessed and fMRI maps were generated to identify (i) brain response to moral dilemmas, (ii) task-induced deactivation of the network during a conventional cognitive task and (iii) the strength of functional connectivity within the network during resting-state. The obtained functional brain maps indeed confirmed that the network subserving moral judgment is underactive in psychopathic individuals during moral dilemma situations, but the data also provided evidence of a baseline network alteratio...|$|R
40|$|Brokers {{are used}} in many multi-agent systems for {{locating}} agents, for routing and sharing information, for managing the system, and for legal purposes, as independent third parties. However, these multi-agent systems can be incapacitated and rendered non-functional when the brokers become inaccessible due to failures such as machine crashes, <b>network</b> <b>breakdowns,</b> and process failures that can occur in any distributed software system. We propose that the theory of teamwork {{can be used to}} create robust brokered architectures that can recover from broker failures, and we present the Adaptive Agent Architecture (AAA) to show the feasibility of this approach. The AAA brokers form a team with a joint commitment to serve any agent that registers with the broker team as long as the agent remains registered with the team. This commitment enables the brokers to substitute for each other when needed. A multiagent system based on the AAA can continue to work despite broker failures as long [...] ...|$|R
40|$|Computer {{communications}} data networks {{or simply}} networks {{have become part}} of our lives today. We can not imagine a day without using the network either for sending or receiving e-mail or for downloading a particular article via the Internet's World Wide Web (WWW). This story even extends to doing commerce via the networks (electronic commerce). All this assumes a well functioning communications network. A mulfunctioning network or a <b>network</b> <b>breakdown</b> due to whatever reason could bring severe different forms of loses to many. This paper peers into some adhoc tools {{that can be used to}} troubleshoot and monitor TCP/IP networks and thereby keep the networks in good productive forms that guarantee expected performance to the users. These tools mostly come with the UNIX operating system. 1 Introduction The tools that are discussed in this paper are the commands ping, ifconfig, arp, netstat, traceroute, nslookup and snoop. This paper does not attempt to give the syntax for using these command [...] ...|$|R
30|$|E_c, i.e. the {{smallest}} number of vertices or edges {{to be removed}} in order to disconnect the graph, respectively. For the case under examination such quantities take value V_c= 1 and E_c= 1, meaning that the removal of a single node or edge can be <b>catastrophic</b> for <b>network</b> connectivity. Identifying and monitoring such nodes/edges can be very important in case of low values of such parameters, {{in order to keep}} the network of relations tightly connected.|$|R
40|$|Interpersonal {{misunderstanding}} {{is often}} rooted in noise, or discrepancies between intended and actual outcomes for an interaction partner due to unintended errors (e. g., {{not being able}} to respond to an E-mail because of a local <b>network</b> <b>breakdown).</b> How can one effectively cope with noise in social dilemmas, situations in which self-interest and collective interests are conflicting? Consistent with hypotheses, the present research revealed that incidents of noise exert a detrimental effect on level of cooperation when a partner follows strict reciprocity (i. e., tit for tat) but that this effect can be overcome if a partner behaves somewhat more cooperatively than the actor did in the previous interaction (i. e., tit for tat plus 1). Also, when noise was present, tit for tat plus 1 elicited greater levels of cooperation than did tit for tat, thereby underscoring the benefits of adding generosity to reciprocity in coping with noise in social dilemmas. The Discussion outlines implications of the present work for theories focusing on self-presentation and attribution, communication, and trust and prorelationship behavior...|$|R
50|$|Motability Operations {{also set}} and {{monitors}} {{the standards of}} service provided by the dealer <b>network,</b> adaptations suppliers, <b>breakdown</b> company and the insurance company. Motability Operations also negotiates pricing with the vehicle manufacturers on a quarterly basis.|$|R
40|$|Abstract A {{condition}} is provided from which an error bound {{and rate of}} convergence can be concluded when comparing the performance of an open and closed analog of a possibly non-product form queueing network. The result is applied to a Jackson <b>network</b> with <b>breakdowns,</b> such as arising in performability analysis. An explicit simple error bound is obtained of order l/M with M the size of finite source input. Key-words Error bound * Open-closed queueing network * performability. - 1...|$|R
40|$|This paper {{presents}} the malicious actions (attacks), which threaten the GPRS network, the GPRS mobile users, {{and the data}} that either reside at the network or are transferred through it. These attacks may be performed by malicious third parties, mobile users, network operators or network operator personnel, which exploit the security weaknesses of the GPRS security architecture. Moreover, the attackers {{take advantage of the}} lack of adequate security measures that should protect certain parts of the GPRS architecture. The possible attacks against GPRS targets the equipment of mobile users, the radio access network, the GPRS backbone network, and the interfaces that connect the latter to other GPRS networks or the public Internet. The results of these attacks might be the com-promise of end-users security, the users over billing, the disclosure or alteration of critical information, the services unavailability, the <b>network</b> <b>breakdown,</b> etc. The analyzed attacks and their consequences increase the risks associated with the usage of GPRS, and, thus, in-fluence its deployment that realizes the concept mobile Internet. In order to defeat certain attacks and enhance the level of security provided by GPRS, specific security measures are proposed...|$|R
40|$|Findings {{derived from}} neuroimaging of the {{structural}} and functional organization {{of the human brain}} have led to the widely supported hypothesis that neuronal networks of temporally coordinated brain activity across different regional brain structures underpin cognitive function. Failure of integration within a network leads to cognitive dysfunction. The current discussion on Alzheimer 2 ̆ 7 s disease (AD) argues that it presents in part a disconnection syndrome. Studies using functional magnetic resonance imaging, positron emission tomography and electroencephalography demonstrate that synchronicity of brain activity is altered in AD and correlates with cognitive deficits. Moreover, recent advances in diffusion tensor imaging have made it possible to track axonal projections across the brain, revealing substantial regional impairment in fiber-tract integrity in AD. Accumulating evidence points towards a <b>network</b> <b>breakdown</b> reflecting disconnection at both the structural and functional system level. The exact relationship among these multiple mechanistic variables and their contribution to cognitive alterations and ultimately decline is yet unknown. Focused research efforts aimed at the integration of both function and structure hold great promise not only in improving our understanding of cognition but also of its characteristic progressive metamorphosis in complex chronic neurodegenerative disorders such as AD...|$|R
40|$|The {{viscoelastic}} {{properties of}} wheat flour dough {{are known to}} be very sensitive to small changes in water content and mixing time. In this study the simple scaling law originally proposed by Hibberd (1970) [Rheol. Acta 9, 497 - 500] to capture the water dependency of the dynamic moduli in small amplitude oscillatory shear, was also applied to creep-recovery shear tests and extensional tests. The scaling law turns out to be valid not only in the linear region, but to a certain extent also in the non-linear region. At sufficiently high water levels, a ‘free’ water phase exists in dough, which attenuates the starch-starch and gluten-starch interactions. Dough characterisation after different mixing times shows that overmixing may cause a disaggregation or even depolymerisation of the gluten <b>network.</b> The <b>network</b> <b>breakdown,</b> as well as the subsequent (partial) recovery, are clearly reflected {{in the value of the}} strain-hardening index, for which a maximum is reached at a mixing time close to the optimum as determined with the Mixograph. Finally, the gluten proteins turn out to be much less susceptible to overmixing in an oxygen-lean environment, which demonstrates the significant role of oxygen in the degradation process...|$|R
40|$|The {{organization}} in brain networks shows highly modular features with weak inter-modular interaction. The topology {{of the networks}} involves emergence of modules and sub-modules {{at different levels of}} constitution governed by fractal laws that are signatures of self-{{organization in}} complex networks. The modular organization, in terms of modular mass, inter-modular, and intra-modular interaction, also obeys fractal nature. The parameters which characterize topological properties of brain networks follow one parameter scaling theory in all levels of network structure, which reveals the self-similar rules governing the network structure. Further, the calculated fractal dimensions of brain networks of different species are found to decrease when one goes from lower to higher level species which implicates the more ordered and self-organized topography at higher level species. The sparsely distributed hubs in brain networks may be most influencing nodes but their absence may not cause <b>network</b> <b>breakdown,</b> and centrality parameters characterizing them also follow one parameter scaling law indicating self-similar roles of these hubs at different levels of organization in brain networks. The local-community-paradigm decomposition plot and calculated local-community-paradigm-correlation co-efficient of brain networks also shows the evidence for self-organization in these networks...|$|R
