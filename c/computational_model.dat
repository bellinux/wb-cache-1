10000|10000|Public
5|$|Furthermore, even single neurons {{appear to}} be complex and capable of {{performing}} computations. So, brain models that don't reflect this are too abstract to be representative of brain operation; models that do try to capture this are very computationally expensive and arguably intractable with present computational resources. However, the Human Brain Project is {{trying to build a}} realistic, detailed <b>computational</b> <b>model</b> of the entire human brain. The wisdom of this approach has been publicly contested, with high-profile scientists {{on both sides of the}} argument.|$|E
25|$|Simulations and experiments: {{iterations}} between large-scale {{simulations of}} neocortical microcircuits and experiments {{in order to}} verify the <b>computational</b> <b>model</b> and explore predictions.|$|E
25|$|Balakrishnan, K., Bousquet, O. and Honavar, V. (2000). Spatial Learning and Localization in Animals: A <b>Computational</b> <b>Model</b> and Its Implications for Mobile Robots, Adaptive Behavior. Vol. 7. no. 2. pp.173–216.|$|E
40|$|Scientific {{computing}} or Mathematical and <b>computational</b> <b>modeling</b> can be studied. All {{these names}} try to characterize a connection of applied mathematics, <b>computational</b> <b>modeling</b> and scientific, engineering and/or economic applications. Two years ago, {{a new study}} program Mathematical and <b>computational</b> <b>modeling</b> has been launched at th...|$|R
40|$|THESIS 9633 Theories of mechanoregulation {{have been}} {{integrated}} in <b>computational</b> <b>models</b> of mechanobiological experiments to test hypotheses of mechanobiology. It {{is believed that}} <b>computational</b> <b>models</b> need to be improved by considering the variability reported in animal experiments {{in order to enhance}} corroboration of hypotheses and to enable the use of <b>computational</b> <b>models</b> in practical bioengineering applications...|$|R
40|$|<b>Computational</b> <b>modeling</b> {{has long}} been {{advocated}} as an important tool in the scientist’s tool shed. They are common in physical and biological sciences, but are very rare in organizational psy-chology. This paper describes the role <b>computational</b> <b>models</b> might play in informing theory and science in organizational psychology. After describing the major advantages of <b>computational</b> <b>models,</b> architectures, examples, and resources are described. This {{is followed by a}} comprehensive review of where <b>computational</b> <b>models</b> have been applied and where they might be profitably applied in each of the major domains of organizational psychology...|$|R
25|$|In {{the field}} of {{computational}} chemistry, energy minimization (also called energy optimization, geometry minimization, or geometry optimization) {{is the process of}} finding an arrangement in space of a collection of atoms where, according to some <b>computational</b> <b>model</b> of chemical bonding, the net inter-atomic force on each atom is acceptably close to zero and the position on the potential energy surface (PES) is a stationary point (described later). The collection of atoms might be a single molecule, an ion, a condensed phase, a transition state or even a collection of any of these. The <b>computational</b> <b>model</b> of chemical bonding might, for example, be quantum mechanics.|$|E
25|$|SBML is not {{an attempt}} to define a {{universal}} language for quantitative models. SBML's purpose is {{to serve as a}} lingua franca—an exchange format used by different present-day software tools to communicate the essential aspects of a <b>computational</b> <b>model.</b>|$|E
25|$|A whole cell <b>computational</b> <b>model</b> for the {{bacterium}} Mycoplasma genitalium, including all its 525 genes, gene products, and their interactions, {{was built by}} scientists from Stanford University and the J. Craig Venter Institute and published on 20 July 2012 in Cell.|$|E
40|$|This paper {{discusses}} how <b>computational</b> <b>modeling</b> {{combines the}} autonomy of models with the automation of computational procedures. In particular, the case of ab initio methods in quantum chemistry will be investigated to draw two lessons from the analysis of <b>computational</b> <b>modeling.</b> The first belongs to general philosophy of science: <b>Computational</b> <b>modeling</b> faces a trade-off and enlarges predictive force {{at the cost of}} explanatory force. The other lesson is about the philosophy of chemistry: The methodology of <b>computational</b> <b>modeling</b> puts into doubt claims about the reduction of chemistry to physics...|$|R
40|$|To meet {{national}} workforce need, we integrated <b>computational</b> <b>modeling</b> training into undergraduate {{materials science}} and engineering (MSE) courses, including Thermodynamics, and Structure of Materials. We also flipped the courses, requiring students to self-study topics outside the class. In the class, the instructors focused on demonstrating real-world materials problems and guiding the students {{to solve the problems}} using different <b>computational</b> <b>modeling</b> techniques. Learning the <b>computational</b> <b>modeling</b> concepts within {{a short period of time}} was challenging to the students. Another challenge was that the students had various STEM backgrounds, such as MSE, mechanical engineering, and physics. In order to foster student learning, engage student interest and seamlessly couple <b>computational</b> <b>modeling</b> modules with the courses, real-world problems, examples and homework were all developed based on student background and interest. For each lecture, 90 % of the time was arranged for quiz, problem solving, and hands-on training. The students could improve their understanding of <b>computational</b> <b>modeling</b> concepts through practice. This paper presents the above teaching strategies and demonstrates one computational module used for teaching the students how to estimate point defect formation energy with a <b>computational</b> <b>modeling</b> tool. The student feedback suggests that integrating <b>computational</b> <b>modeling</b> training into undergraduate curriculum is feasible. However, it posts some challenges, such as teaching hours and teaching balance between <b>computational</b> <b>modeling</b> theory and practice, for the students and instructor. The paper also discusses the improvement plan...|$|R
50|$|COMBINE, the <b>COmputational</b> <b>Modeling</b> in BIology NEtwork is an {{initiative}} {{to coordinate the}} development of the various community standards and formats for <b>computational</b> <b>models,</b> initially in systems biology and related fields.|$|R
25|$|Upper {{and lower}} bounds are usually stated using the big O notation, which hides {{constant}} factors and smaller terms. This makes the bounds {{independent of the}} specific details of the <b>computational</b> <b>model</b> used. For instance, if T(n)=7n2+15n+40, in big O notation one would write T(n)=O(n2).|$|E
25|$|IoT {{modeling}} and simulation (and emulation) is typically carried out {{at the design stage}} before deployment of the network. Network simulators like OPNET, NetSim and NS2 can be used to simulate IoT networks. Digital Twins may also be implemented to produce updates on the status and health of an asset, based upon sensor readings integrated with a <b>computational</b> <b>model</b> of the asset.|$|E
25|$|Warren McCulloch and Walter Pitts (1943) {{created a}} <b>computational</b> <b>model</b> for neural {{networks}} based on mathematics and algorithms called threshold logic. This model {{paved the way}} for neural network research to split into two approaches. One approach focused on biological processes in the brain while the other focused on the application of neural networks to artificial intelligence. This work led to work on nerve networks and their link to finite automata.|$|E
40|$|<b>Computational</b> <b>modelling</b> of {{diseases}} is an emerging field, proven valuable for the diagnosis, prognosis {{and treatment of}} the disease. Cancer {{is one of the}} diseases where <b>computational</b> <b>modelling</b> provides enormous advancements, allowing the medical professionals to perform in silico experiments and gain insights prior to any in vivo procedure. In this paper, we review the most recent <b>computational</b> <b>models</b> that have been proposed for cancer. Well known databases used for <b>computational</b> <b>modelling</b> experiments, as well as, the various markup language representations are discussed. In addition, recent state of the art research studies related to tumour growth and angiogenesis modelling are presented...|$|R
40|$|<b>Computational</b> <b>models</b> for numerically {{simulating}} physical {{systems are}} increasingly being used to support decision-making processes in engineering. Processes such as design decisions, policy level analyses, and experimental design settings are often guided by information gained from <b>computational</b> <b>modeling</b> capabilities. To ensure effective application of results obtained through numerical simulation of <b>computational</b> <b>models,</b> uncertainty in model inputs must be propagated to uncertainty in model outputs. For expensive <b>computational</b> <b>models,</b> the many thousands of model evaluations required for traditional Monte Carlo based techniques for uncertainty propagation can be prohibitive. This paper presents a novel methodology for constructing surrogate representations of <b>computational</b> <b>models</b> via compressed sensing. Our approach exploits the approximate additivity inherent in many engineering <b>computational</b> <b>modeling</b> capabilities. We demonstrate our methodology on some analytical functions, with comparison to the Gaussian process regression, and a cooled gas turbine blade application. We also provide some possible methods to build uncertainty information for our approach. The results of these applications reveal substantial computational savings over traditional Monte Carlo simulation with negligible loss of accuracy...|$|R
40|$|The {{idea that}} human {{cognitive}} capacities are explainable by <b>computational</b> <b>models</b> is often conjoined {{with the idea}} that, while the states postulated by such models are in fact realized by brain states, there are no type-type correlations between the states postulated by <b>computational</b> <b>models</b> and brain states (a corollary of token physicalism). I argue that these ideas are not jointly tenable. I discuss the kinds of empirical evidence available to cognitive scientists for (dis) confirming <b>computational</b> <b>models</b> of cognition and argue {{that none of these}} kinds of evidence can be relevant to a choice among competing <b>computational</b> <b>models</b> unless there are in fact type-type correlations between the states postulated by <b>computational</b> <b>models</b> and brain states. Thus, I conclude, research into the computational procedures employed in human cognition must be conducted hand-in-hand with research into the brain processes which realize those procedures...|$|R
25|$|However, some {{computational}} {{problems are}} easier to analyze in terms of more unusual resources. For example, a non-deterministic Turing machine is a <b>computational</b> <b>model</b> that is allowed to branch out to check many different possibilities at once. The non-deterministic Turing machine has {{very little to do}} with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing computational problems.|$|E
25|$|Nonsynaptic {{activity}} in the cell is usually expressed as changes in neuronal excitability. This occurs through modulation of membrane components, such as resting and voltage-gated channels and ion pumps. Nonsynaptic processes {{are thought to be}} involved in memory storage. One possible mechanism of this action involves marking a neuron that has been recently active with changes in excitability. This would help to link temporally separated stimuli. Another potential mechanism comes from a <b>computational</b> <b>model</b> that indicates that nonsynaptic plasticity may prime circuits for modification in learning because excitability changes may regulate the threshold for synaptic plasticity.|$|E
25|$|Simon was {{interested}} in how humans learn and, with Edward Feigenbaum, he developed the EPAM (Elementary Perceiver and Memorizer) theory, {{one of the first}} theories of learning to be implemented as a computer program. EPAM was able to explain a large number of phenomena in the field of verbal learning. Later versions of the model were applied to concept formation and the acquisition of expertise. With Fernand Gobet, he has expanded the EPAM theory into the CHREST <b>computational</b> <b>model.</b> The theory explains how simple chunks of information form the building blocks of schemata, which are more complex structures. CHREST has been used predominantly, to simulate aspects of chess expertise.|$|E
5000|$|In this context, {{medical imaging}} and image {{computing}} play {{an increasingly important}} role as they provide systems and methods to image, quantify and fuse both structural and functional information about the human being in vivo. These two broad research areas include the transformation of generic <b>computational</b> <b>models</b> to represent specific subjects, thus {{paving the way for}} personalized <b>computational</b> <b>models.</b> [...] Individualization of generic <b>computational</b> <b>models</b> through imaging can be realized in three complementary directions: ...|$|R
40|$|<b>Computational</b> <b>modelling</b> {{has proven}} to be a {{valuable}} approach in developing theories of spoken-word processing. In this paper, we focus on a particular class of theories in which it is assumed that the spoken-word recognition process consists of two consecutive stages, with an 'abstract' discrete symbolic representation at the interface between the stages. In evaluating <b>computational</b> <b>models,</b> it is important to bring in independent arguments for the cognitive plausibility of the algorithms that are selected to compute the processes in a theory. This paper discusses the relation between behavioural studies, theories, and <b>computational</b> <b>models</b> of spoken-word recognition. We explain how <b>computational</b> <b>models</b> can be assessed in terms of the goodness of fit with the behavioural data and the cognitive plausibility of the algorithms. An in-depth analysis of several models provides insights into how <b>computational</b> <b>modelling</b> has led to improved theories and to a better understanding of the human spoken-word recognition process...|$|R
40|$|Students taking {{introductory}} physics {{are rarely}} exposed to <b>computational</b> <b>modeling.</b> In a one-semester large lecture introductory calculus-based mechanics course at Georgia Tech, students learned to solve physics problems using the VPython programming environment. During the term 1357 {{students in this}} course solved a suite of fourteen <b>computational</b> <b>modeling</b> homework questions delivered using an online commercial course management system. Their proficiency with <b>computational</b> <b>modeling</b> was evaluated in a proctored environment using a novel central force problem. The majority of students (60. 4 %) successfully completed the evaluation. Analysis of erroneous student-submitted programs indicated that a small set of student errors explained why most programs failed. We discuss the design {{and implementation of the}} <b>computational</b> <b>modeling</b> homework and evaluation, the results from the evaluation and the implications for instruction in <b>computational</b> <b>modeling</b> in introductory STEM courses. Comment: 14 pages, 1 figure, 6 tables, submitted to PRST-PE...|$|R
25|$|For limited applications, Computational fluid {{dynamics}} (CFD) can supplement or possibly replace {{the use of}} wind tunnels. For example, the experimental rocket plane SpaceShipOne was designed without any use of wind tunnels. However, on one test, flight threads were attached {{to the surface of}} the wings, performing a wind tunnel type of test during an actual flight in order to refine the <b>computational</b> <b>model.</b> Where external turbulent flow is present, CFD is not practical due to limitations in present-day computing resources. For example, an area that is still much too complex for the use of CFD is determining the effects of flow on and around structures, bridges, terrain, etc.|$|E
25|$|Defining {{structure}} and detecting {{the emergence of}} complexity in nature are inherently subjective, though essential, scientific activities. Despite the difficulties, these problems can be analysed {{in terms of how}} model-building observers infer from measurements the computational capabilities embedded in non-linear processes. An observer’s notion of what is ordered, what is random, and what is complex in its environment depends directly on its computational resources: the amount of raw measurement data, of memory, and of time available for estimation and inference. The discovery of structure in an environment depends more critically and subtly, though, on how those resources are organized. The descriptive power of the observer’s chosen (or implicit) <b>computational</b> <b>model</b> class, for example, can be an overwhelming determinant in finding regularity in data.|$|E
500|$|Although {{the subject}} matter and methodologies in social science differ from those in natural science or {{computer}} science, several of the approaches used in contemporary social simulation originated from fields such as physics and artificial intelligence. By the same token, some of the approaches that originated in computational sociology have been imported into the natural sciences, such as measures of network centrality from the fields of social network analysis and network science. In relevant literature, computational sociology is often related {{to the study of}} social complexity. Social complexity concepts such as complex systems, non-linear interconnection among macro and micro process, and emergence, have entered the vocabulary of computational sociology. A practical and well-known example is the construction of a <b>computational</b> <b>model</b> {{in the form of an}} [...] "artificial society", by which researchers can analyse the structure of a social system.|$|E
40|$|Therapeutic {{suggestions}} {{resulting from}} <b>computational</b> <b>models</b> of Alzheimer disease are made. Although several <b>computational</b> <b>models</b> {{of this disease}} {{have been published in}} the last decade few conclusions were drawn. Two such models are introduced here and directions for their further extensions are outlined. Assuming that <b>computational</b> <b>models</b> reflect real neural mechanisms leads to some therapeutic suggestions that should slow down the degeneration of synaptic connections and thus the development of the disease, at least in its early stages...|$|R
40|$|<b>Computational</b> <b>modeling</b> has the {{potential}} to add an entirely new approach to hypothesis testing in yeast cell biology. Here, we present a method for seamless integration of <b>computational</b> <b>modeling</b> with quantitative digital Xuorescence microscopy. This integration is accomplished by developing <b>computational</b> <b>models</b> based on hypotheses for underlying cellular processes that may give rise to experi-mentally observed Xuorescent protein localization patterns. Simulated Xuorescence images are generated from the <b>computational</b> <b>models</b> of underlying cellular processes via a “model-convolution ” process. These simulated images can then be directly compared to experimen-tal Xuorescence images in order to test the model. This method provides a framework for rigorous hypothesis testing in yeast cell biology via integrated mathematical modeling and digital Xuorescence microscopy...|$|R
40|$|This book first {{introduces}} classic as well {{as recent}} <b>computational</b> <b>models</b> for just-noticeable-difference (JND) applications. Since the discrete cosine transform (DCT) is applied in many image and video standards (JPEG, MPEG- 1 / 2 / 4, H. 261 / 3), the book also includes a comprehensive survey of <b>computational</b> <b>models</b> for JND {{that are based on}} DCT. The visual factors used in these <b>computational</b> <b>models</b> are reviewed in detail. Further, an extensive comparative analysis of these models using quantitative and qualitative performance criteria is presented, which compares the noise shaping performance of these models with subjective evaluation and the accuracy between the estimated JND thresholds and subjective evaluation. There are many surveys available on <b>computational</b> <b>models</b> for JND; however, these surveys seldom compare the performance of <b>computational</b> <b>models</b> that are based on DCT. The authors’ survey of the <b>computational</b> <b>models</b> and their in-depth review of the visual factors used in them will help readers understand perceptual image coding based on DCT. The book also provides a comparative analysis of several perceptual image coders that are based on DCT, which are compatible with the highly popular and widely adopted JPEG standard...|$|R
2500|$|The <b>computational</b> <b>model</b> that {{provides}} an approximate [...] could {{be based on}} quantum mechanics (using either density functional theory or semi-empirical methods), force fields, {{or a combination of}} those in case of QM/MM. Using this <b>computational</b> <b>model</b> and an initial guess (or ansatz) of the correct geometry, an iterative optimization procedure is followed, for example: ...|$|E
2500|$|Every computable {{function}} has {{a finite}} procedure giving explicit, unambiguous {{instructions on how}} to compute it. Furthermore, this procedure has to be encoded in the finite alphabet used by the <b>computational</b> <b>model,</b> so there are only countably many computable functions. For example, functions may be encoded using a string of bits (the alphabet [...] ).|$|E
2500|$|... {{which is}} stored in terms of {{synaptic}} weights (synapses per neuron). The standard <b>computational</b> <b>model</b> of a neuron {{is based on a}} dot product and a threshold. Another important feature of the visual cortex is that it consists of simple and complex cells. This idea was originally proposed by Hubel and Wiesel. M-theory employs this idea. Simple cells compute dot products of an image and transformations of templates [...] for [...] ( [...] is a number of simple cells). Complex cells are responsible for pooling and computing empirical histograms or statistical moments of it. The following formula for constructing histogram can be computed by neurons: ...|$|E
40|$|Abstract—This paper {{makes the}} case for perturbation-based <b>computational</b> <b>models</b> as a {{promising}} choice for implementing next generation ubiquitous information technology on unreliable nanotechnologies. We show the inherent robustness of such <b>computational</b> <b>models</b> to high defect densities and performance uncertainty which, when combined with low manufacturing precision requirements, makes them particularly suitable for emerging nanoelectronics. We propose a hybrid eNano-CMOS perturbation-based computing platform relying on a new style of configurability that exploits the <b>computational</b> <b>model’s</b> unique form of unstructured redundancy. We consider the practicality and scalability of perturbation-based <b>computational</b> <b>models</b> by developing and assessing initial foundations for engineering such systems. Specifically, new design and decomposition principles exploiting task specific contextual and temporal scales are proposed and shown to substantially reduce complexity for several benchmark tasks. Our results provide strong evidence for the relevance and potential of this class of <b>computational</b> <b>models</b> when targeted at emerging unreliable nanoelectronics. Index Terms—Nanotechnology, Real time systems, Signal processing I...|$|R
40|$|We {{describe}} <b>computational</b> <b>modeling</b> of flaring {{horns and}} piecewise conical bores using "Truncated Infinite Impulse Response" (TIIR) digital filtering techniques. The approach yields highly efficient and accurate <b>computational</b> <b>models</b> {{and is therefore}} appropriate for real-time simulations of woodwind and brass musical instruments...|$|R
50|$|<b>Computational</b> <b>modelling</b> of {{biological}} receptive fields.|$|R
