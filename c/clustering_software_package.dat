1|10000|Public
40|$|Clustering {{algorithms}} are exploratory {{data analysis}} tools that {{have proved to}} be essential for gaining valuable insights on various aspects and relationships of the underlying systems. In this paper we present gCLUTO, a stand-alone <b>clustering</b> <b>software</b> <b>package</b> which serves as an easy-to-use platform that combines clustering algorithms along with a number of analysis, reporting, and visualization tools to aid in interactive exploration and clustering-driven analysis of large datasets. gCLUTO provides a wide-range of algorithms that operate either directly on the original feature-based representation of the objects or on the object-to-object similarity graphs and are capable of analyzing different types of datasets and finding clusters with different characteristics. In addition, gCLUTO implements a project-oriented work-flow that eases the process of data analysis...|$|E
5000|$|A {{number of}} DX <b>cluster</b> <b>software</b> <b>packages</b> are available, among which are: ...|$|R
5000|$|DX Spider - {{the most}} widely used of the internet-based <b>cluster</b> <b>software</b> <b>packages</b> ...|$|R
5000|$|<b>Software</b> {{included}} a <b>cluster</b> resource manager <b>software</b> <b>package</b> called QuadricsRms, and Quadrics Linux Software, core {{components of the}} QsNet software release for Linux under the GNU LGPL License ...|$|R
40|$|In {{this paper}} we {{investigate}} {{the effectiveness of}} hierarchical matrix techniques when used as the linear solver in a certain domain decomposition algorithm. In particular, we provide a direct performance comparison between an algebraic multigrid solver and a hierarchical matrix solver {{which is based on}} nested dissection <b>clustering</b> within the <b>software</b> <b>package</b> PLTMG...|$|R
40|$|In {{recent years}} power {{consumption}} of high performance computing (HPC) clusters {{has become a}} growing problem due, e. g., to the economic cost of electricity, the emission of car- bon dioxide (with {{negative impact on the}} environment), and the generation of heat (which reduces hardware reliability). In past work, we developed EnergySaving <b>cluster,</b> a <b>software</b> <b>package</b> that regulates the number of active nodes in an HPC facility to match the users’ demands. In this paper, we extend this work by presenting a simulator for this tool that allows the evaluation and analysis of the benefits of applying different energy-saving strategies and policies, under realistic workloads, to different cluster configurations...|$|R
40|$|A protein family {{contains}} sequences {{that are}} evolutionarily related. Generally, this is reflected by sequence similarity. There {{have been many}} attempts to organize the set of protein families into evolutionarily homogenous clusters using certain clustering methods. How do we characterize these clusters? How can we cluster protein families using these characterizations? In this work, these questions were addressed by use of a concept called group-wide co-evolution, and was exemplified by some real and simulated protein family data. The results {{have shown that the}} trend of a group of monophyletic proteins might be characterized by a normal distribution, while the strength and variability of this trend can be described by the sample mean and variance of the observed correlation coefficients after a suitable transformation. To exploit this property, we have developed a monophyletic clustering method called monophyletic k−medoids <b>clustering.</b> A <b>software</b> <b>package</b> written in R has been made available a...|$|R
40|$|High-performance {{computing}} {{has created}} a new approach to science. Modeling is now a viable and respected alternative to the more traditional experiential and theoretical approaches. High performance is a key issue in data mining or in image rendering. Traditional high performance clusters have proved their worth in a variety of uses from predicting the weather to industrial design, from molecular dynamics to astronomical modeling. A multicomputer configuration, or cluster, is a group of computers that work together. A cluster has three basic elements a collection of individual computers, a network connecting those computers, and software that enables a computer to share work among the other computers via the network. Clusters are also playing a greater role in business. Advances in clustering technology have led to high-availability and load-balancing clusters. Clustering is now used for mission-critical applications such as web and FTP servers. For permanent clusters there are, {{for lack of a better}} name, <b>cluster</b> kits, <b>software</b> <b>packages</b> that automate the installation process. A cluster kit provides all the software you are likely to need in a single distribution. Cluster kits tend to be very complete. For example, the OSCAR distribution. Open Source Cluster Application Resources is a <b>software</b> <b>package</b> that is designed to simplify cluster installation. A collection of open source <b>cluster</b> <b>software,</b> OSCAR includes everything that you are likely to need for a dedicated, high-performance cluster. OSCAR takes you completely through the installation of your cluster. In this Paper with the help of Open Source Cluster Application Resource (OSCAR) cluster kit, attempt to setup a high performance computational cluster with special concern to applications like Integration and Sorting. The ease use of cluster is possible globally and transparently managing cluster resources. Cluster computing approach nowadays is an ordinary configuration found in many organizations to target requirements of high performance computing...|$|R
40|$|Databases of genomic {{documents}} contain substantial {{amounts of}} structured information {{in addition to the}} texts of titles and abstracts. Unstructured information retrieval techniques fail {{to take advantage of the}} structured information available. This paper describes a technique to improve upon traditional retrieval methods by clustering the retrieval result set into two distinct clusters using additional structural information. Our hypothesis is that the relevant documents are to be found in the tightest cluster of the two, as suggested by van Rijsbergen 2 ̆ 7 s cluster hypothesis. We present an experimental evaluation of these ideas based on the relevance judgments of the 2004 TREC workshop Genomics track, and the CLUTO <b>software</b> <b>clustering</b> <b>package...</b>|$|R
5000|$|A {{number of}} <b>software</b> <b>packages</b> use the SWMM5 engine, {{including}} many commercial <b>software</b> <b>packages.</b> Some of these <b>software</b> <b>packages</b> include: ...|$|R
50|$|There {{are many}} <b>software</b> <b>packages</b> {{available}} to merge text and images into VDP print files. Some are stand-alone <b>software</b> <b>packages,</b> however {{most of the}} advanced VDP <b>software</b> <b>packages</b> are actually plug-in modules for one or more publishing <b>software</b> <b>packages</b> such as Adobe Creative Suite.|$|R
5000|$|<b>Software</b> <b>packaging</b> formats {{are used}} to create <b>software</b> <b>packages</b> that may be self-installing files.|$|R
5000|$|With {{extraction}} lossy data conversion, <b>software</b> <b>packages</b> take content stored by {{a different}} <b>software</b> <b>package</b> and extract out the content to the desired format. This may allow data to be extracted in a format not recognized by the original <b>software</b> <b>package.</b>|$|R
40|$|Numerous <b>software</b> <b>packages</b> {{are being}} used and updated {{regularly}} on most computer systems. Installing all these <b>software</b> <b>packages</b> is a formidable task because each one has a different procedure for compiling or for placing the files required at run time. The LUDE (Logithèque Universitaire Distribuée et Extensible) software library is an organization for installing <b>software</b> <b>packages,</b> a set of tools to install and uninstall <b>software</b> <b>packages</b> and browse their documentation, {{and a number of}} FTP servers offering over 100 pre-installed freely redistributable <b>software</b> <b>packages.</b> It offers functionality and flexibility not available i...|$|R
40|$|This paper {{presents}} an integrated rule-based and case-based reasoning approach for evaluation and {{selection of the}} <b>software</b> <b>packages.</b> Rule-based reasoning is used to (i) store knowledge about the software evaluation criteria (ii) guide user to capture user needs of the <b>software</b> <b>package.</b> Case-based reasoning is used to (i) determine the fit between candidate <b>software</b> <b>packages</b> and user needs of the <b>software</b> <b>package</b> (ii) rank the candidate <b>software</b> <b>packages</b> according to their score. We have implemented this approach and performed usability test to verify functionality, efficiency and convenience of this approach...|$|R
40|$|Teachers using {{traditional}} lecture method {{find it difficult}} to communicate the concept of chemical bonding to students; and students {{find it difficult to}} learn the concept. The trend in the 21 st century learning is the use of computer and <b>software</b> <b>packages</b> to facilitate teaching-learning process. This study set out to develop and validate a <b>software</b> <b>package</b> for teaching chemical bonding in secondary schools. The study produced chemical bonding instructional <b>software</b> <b>package</b> (CBISP), adopting the procedure suggested in FTCESP-model for teacher-made computer educational <b>software</b> <b>package.</b> It also produced an instrument for validation of the <b>software</b> <b>package.</b> The internal consistency (α) of the Chemical Bonding Instructional <b>Software</b> <b>Package</b> (CBISP) has a value of 0. 781, obtained by Kendall's Coefficient of Concordance method used in determining it. The author asserts that the procedure adopted in the development and validation of the CBISP is a veritable way of ensuring sustainable supply of relevant <b>software</b> <b>packages</b> in the school system...|$|R
40|$|Publication of {{this article}} was funded by the Stellenbosch University Open Access Fund. The {{original}} publication is available at [URL] factors exist that may contribute to the unsuccessful completion of application <b>software</b> <b>package</b> implementation projects. The most significant contributor to application <b>software</b> <b>package</b> project failure lies in the misalignment of the organisation’s business processes with the functionality of the application <b>software</b> <b>package.</b> While various IT control frameworks that may assist in the implementation of application <b>software</b> <b>packages</b> are available, the question arises why industry still reports that the success rate of application <b>software</b> <b>package</b> implementation projects remains low. The {{purpose of this study was}} to examine the extent to which the Projects in Controlled Environment (PRINCE 2) framework assists in the alignment of the organisation’s business processes with the functionality provided by the application <b>software</b> <b>package</b> implemented. This study investigated whether PRINCE 2 addresses all the reasons for project failure. It identifies the shortcomings and weaknesses in PRINCE 2 which may contribute to the misalignment between the business processes of the organisation and the functionality of the application <b>software</b> <b>package</b> implemented. The study recommends how these weaknesses identified in PRINCE 2 can be addressed. By taking these recommendations into account when using PRINCE 2 to implement application <b>software</b> <b>packages,</b> proper alignment between the organisation’s business processes and the functionality of the application <b>software</b> <b>package</b> may be achieved. This results in a more successful application <b>software</b> <b>package</b> implementation. Stellenbosch UniversityPublishers' versio...|$|R
40|$|Software defect {{prediction}} {{is the process}} of locating defective modules in software. Software quality may be a field of study and apply that describes the fascinating attributes of <b>software</b> <b>package</b> product. The performance should be excellent with none defects. Software quality metrics are a set of <b>software</b> <b>package</b> metrics that target the standard aspects of the product, process, and project. The <b>software</b> <b>package</b> {{defect prediction}} model helps in early detection of defects and contributes to their economical removal and manufacturing a top quality <b>software</b> <b>package</b> supported many metrics. The most objective of paper is to assist developers determine defects supported existing <b>software</b> <b>package</b> metrics victimization data mining techniques and thereby improve the <b>software</b> <b>package</b> quality. In this paper, role of various classification techniques in software defect prediction process are analyzed...|$|R
40|$|An {{application}} <b>software</b> <b>package</b> implementation is {{a complex}} endeavour, and as such it requires the proper understanding, evaluation and redefining of the current business processes {{to ensure that the}} implementation delivers on the objectives set {{at the start of the}} project. Numerous factors exist that may contribute to the unsuccessful implementation of application <b>software</b> <b>packages.</b> However, the most significant contributor to the failure of an application <b>software</b> <b>package</b> implementation lies in the misalignment of the organisation’s business processes with the functionality of the application <b>software</b> <b>package.</b> Misalignment is attributed to a gap that exists between the business processes of an organisation and what functionality the application <b>software</b> <b>package</b> has to offer to translate the business processes of an organisation into digital form when implementing and configuring an application <b>software</b> <b>package.</b> This gap is commonly referred to as the information technology (IT) gap. This study proposes to define and discuss the IT gap. Furthermore this study will make recommendations for aligning the business processes with the functionality of the application <b>software</b> <b>package</b> (addressing the IT gap). The end result of adopting these recommendations will be more successful application <b>software</b> <b>package</b> implementations...|$|R
25|$|One of the {{elements}} of the package will be the <b>software</b> <b>package.</b> The <b>software</b> <b>package</b> is a package in itself, because it consists of the different software components that together form the product. In contrast with the overall <b>package,</b> the <b>software</b> <b>package</b> is always a technical package in which all the files needed are combined in order to run the software product. Another concept of the <b>software</b> <b>package</b> is the version. This keeps track of the modifications made to the software product. By relating it to the <b>software</b> <b>package</b> the vendor and the customer are able {{to keep track of the}} functionality and properties of the product the customer is using.|$|R
30|$|The {{following}} procedure {{requires a}} computer running Microsoft Windows and our symmetry-mismatch reconstruction <b>software</b> <b>package.</b> Unpacking the <b>software</b> <b>package</b> to a folder and setting {{a path to}} this folder in the Windows system are required before using the <b>software</b> <b>package.</b> This procedure assumes that users have experiences in cryo-EM image processing and single particle reconstruction.|$|R
40|$|A {{statistical}} {{user interface}} is an interface between a human user and a statistical <b>software</b> <b>package.</b> Whenever {{we use a}} statistical <b>software</b> <b>package</b> we want to solve a specific statistical problem. But very often at {{first it is necessary}} to learn specific things about the <b>software</b> <b>package.</b> Everyone of us knows about the ?religious wars? concerning the question which statistical software package/method is the best for a certain task; see Marron (1996) and Cleveland and Loader (1996) and related internet discussions. Experienced statisticians use a bunch of different statistical <b>software</b> <b>packages</b> rather than a single one; although all of the major companies (at least the marketing departments) tell us that we only need their <b>software</b> <b>package.</b> [...] ...|$|R
40|$|This work {{gives an}} {{overview}} of the overall equipment efficiency (OEE) and root cause analysis (RCA) methods. There are summarized parameters necessary to calculate and implement these methods. There has been {{an overview of}} plywood production line gluing process. This work describes overall equipment efficiency and root cause analysis implementation of “Latvijas Finieris” plywood production gluing line, data collection options using Wonderware System Platform, SQL <b>software</b> <b>packages.</b> Data analysis is implemented in several ways: graphs data analyzed with Wonderware Historian <b>software</b> <b>package,</b> logical data processing and calculation implemented through Wonderware System Platform and Wonderware MES <b>software</b> <b>packages,</b> graphical representation is realized with Wonderware Intouch <b>software</b> <b>package.</b> End-user data are available through Wonderware Information Studio <b>software</b> <b>package...</b>|$|R
40|$|Evaluating and {{selecting}} <b>software</b> <b>packages</b> {{that meet}} an organization's requirements {{is a difficult}} software engineering process. Selection of a wrong <b>software</b> <b>package</b> can {{turn out to be}} costly and adversely affect business processes. The aim {{of this paper is to}} provide a basis to improve the process of evaluation and selection of the <b>software</b> <b>packages.</b> This paper reports a systematic review of papers published in journals and conference proceedings. The review investigates methodologies for selecting <b>software</b> <b>packages,</b> <b>software</b> evaluation techniques, software evaluation criteria, and systems that support decision makers in evaluating <b>software</b> <b>packages.</b> The key findings of the review are: (1) analytic hierarchy process has been widely used for evaluation of the <b>software</b> <b>packages,</b> (2) there is lack of a common list of generic software evaluation criteria and its meaning, and (3) there is need to develop a framework comprising of software selection methodology, evaluation technique, evaluation criteria, and system to assist decision makers in software selection. (C) 200...|$|R
30|$|All {{numerical}} simulations and bifurcation diagrams (both one- and two-parameter) {{are constructed}} using the XPPAUT <b>software</b> <b>package</b> [26], using the Runge-Kutta integration method, and computer codes can be downloaded from the following website: [URL] The surface in Figure 9 was constructed using the AUTO <b>software</b> <b>package</b> [27]. All graphics were produced with the <b>software</b> <b>package</b> MATLAB.|$|R
30|$|This section {{presents}} the hardware design, software design, and choice technologies. The hardware {{is an open}} hardware and the <b>software</b> <b>packages</b> used are FLOSS (Free/Libre/Open Source <b>Software)</b> <b>packages.</b>|$|R
50|$|Dependency hell is a colloquial {{term for}} the {{frustration}} of some software users who have installed <b>software</b> <b>packages</b> which have dependencies on specific versions of other <b>software</b> <b>packages.</b>|$|R
40|$|In surveying, volume calculating is {{commonly}} used. Frequently we use cross-section method. Usually terestrical method {{is used to}} determine characteristic points of crosssections. Observations we make on field need to be processed in <b>software</b> <b>packages</b> in order to calculate volume of an object. The calculated volumes may {{vary depending on the}} density of measured cross-sections and selection of <b>software</b> <b>package.</b> In this thesis, we compared the course of processing in <b>software</b> <b>packages</b> and volume differences, which we obtained using different <b>software</b> <b>packages</b> and different density of measured cross-sections...|$|R
5000|$|A large {{proportion}} of free statistical <b>software</b> <b>packages,</b> however, are from individuals. Some of these <b>software</b> <b>packages</b> from individuals include Easyreg, MicrOsiris, [...] OpenStat, PSPP, SOFA, Zelig. and DataMelt ...|$|R
5000|$|Deltek Costpoint is {{a project}} {{accounting}} <b>software</b> <b>package</b> sold by Deltek. Costpoint is the [...] "high-end" [...] of the three main project accounting <b>software</b> <b>packages</b> sold by the company.|$|R
40|$|Abstract — MATLAB is {{at present}} {{among the best}} {{available}} technique for image processing. Medical images after digitalized processed can help {{reducing the number of}} false positives and they assist medical officers in deciding between follow-up and biopsy. This paper gives a survey of image processing algorithms that have been developed for detection of masses and segmentation techniques. 35 students from university campus participated in the Development of Biomedical Image Processing <b>Software</b> <b>Package</b> for New Learners Survey investigating the use of <b>software</b> <b>package</b> for processing and editing image. Composed of 19 questions, the survey built a comprehensive picture of the <b>software</b> <b>package,</b> programming language, workflow of the tool and captured the attitudes of the respondents. The result of this study shows that MATLAB is among the famous <b>software</b> <b>package</b> and this result is expected to be beneficial and able to assist users on effective image processing and analysis in a newly developed <b>software</b> <b>package.</b> Keywords- MATLAB; image processing; image editting; <b>software</b> <b>package.</b> 1...|$|R
40|$|The {{purpose of}} the study was to assess the {{reliability}} of (semi-) automatic left ventricular (LV) function measurements using three different <b>software</b> <b>packages</b> on the same dual-source computed tomography (DSCT) datasets and to compare agreement among the <b>software</b> <b>packages.</b> Forty consecutive patients, undergoing cardiac DSCT were included (31 men, mean age 58 +/- 14 years). LV function analysis was performed with all three <b>software</b> <b>packages.</b> ANOVA testing was used to determine the difference among the repeated measurements and the difference among the <b>software</b> <b>packages.</b> Bland-Altman plots were computed to describe the agreement among the <b>software</b> <b>packages.</b> No significant difference was found among the repeated measurements. In the comparison of the three <b>software</b> <b>packages,</b> a significant difference was observed when measurements were used with minimal user interaction. When end-diastolic and end-systolic phases were manually set, there was no overall significant difference, but in 12. 5 % of patients a large (> 10 %) difference in LVEF was found. All three <b>software</b> <b>packages</b> have good intraobserver variability, but the results of the three packages were significantly different. For clinical use, one should be aware of the clinical impact of possible segmentation flaws when (semi-) automatic LV function assessment is used...|$|R
5000|$|... eXpressDSP is a <b>software</b> <b>package</b> {{produced}} by Texas Instruments. This <b>software</b> <b>package</b> is {{a suite of}} tools used to develop applications on Texas Instruments Digital Signal Processing line of chips.|$|R
30|$|Statistically {{significant}} differences in SUV measurements, between the two <b>software</b> <b>packages,</b> ranging from 9 to 21.8 % were found depending on ROI location. In 79 % (n[*]=[*] 23) of the ROI locations, {{the differences between the}} SUV measurements from each <b>software</b> <b>package</b> were found to be statistically significant. The time taken to perform the analyses and export data from the <b>software</b> <b>packages</b> also varied considerably.|$|R
30|$|We {{used the}} normal {{databases}} {{provided in the}} <b>software</b> <b>packages.</b> Both Wolak et al. [6] and Guner et al. [7] found that the application of an institutional normal database did not significantly improve {{the performance of the}} software. Furthermore, to our knowledge, most clinical users of the <b>software</b> <b>packages</b> use a normal database provided by the vendor and not their own institutional normal database. We wanted the results to reflect the performance of the <b>software</b> <b>packages</b> in clinical routine and we therefore used the same normal databases that are available to other users of the <b>software</b> <b>packages.</b>|$|R
40|$|A {{major problem}} with the {{undergraduate}} mechanical course is the limited exposure of students to <b>software</b> <b>packages</b> coupled with the long learning curve on the existing <b>software</b> <b>packages.</b> This work proposes the use of appropriate <b>software</b> <b>packages</b> for the entire mechanical engineering curriculum to ensure students get sufficient exposure real life design problems. A variety of <b>software</b> <b>packages</b> are highlighted as being suitable for undergraduate work in mechanical engineering, e. g. simultaneous non-linear equations; uncertainty analysis; 3 -D modeling software with the FEA; analysis tools for the solution of problems in thermodynamics, fluid mechanics, mechanical system design, and solid mechanics...|$|R
