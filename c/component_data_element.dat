1|10000|Public
5000|$|The <b>component</b> <b>data</b> <b>element</b> {{separator}} {{and data}} element separator are the [...] "first level" [...] and [...] "second level" [...] separators of data elements within a message segment. Referring {{to them as}} + and : for brevity, the + separates top-level or composite data elements, and : separates second-level data elements nested within composite data elements. Trailing empty (or null) data elements and their leading separators are omitted to reduce message size.|$|E
50|$|Many {{standards}} {{require the}} use of Upper camel case to differentiate the <b>components</b> of a <b>data</b> <b>element</b> name. This is the standard used by ebXML, GJXDM and NIEM.|$|R
40|$|Abstract. The paper {{describes}} {{the architecture of}} a system supporting ad-hoc creation of short-term networked enterprises and business alliances, as it was designed within the SPIKE EU FP 7 project. The approach combines the business process modelling with Semantic Web services. Overview of the main system <b>components</b> and <b>data</b> <b>elements</b> is presented, together with a brief functional description...|$|R
5000|$|Segel co-founded Structured Data Intelligence with Xavier Kochhar {{and created}} The Video Genome Project which “...discovers, ingests, refines and understands the <b>component</b> <b>data</b> and {{metadata}} <b>elements</b> of film, television, and online video records." [...] In 2016 The Video Genome Project {{was acquired by}} Hulu.|$|R
40|$|This paper {{indicates}} {{the concept of}} metadata. Defined simply, it is “data about data”. There are three kinds of metadata associated with digital objects: Descriptive or content, Structural and Administrative metadata. It can generally be viewed as being of various types: Dublin Core, MARC, Global Information Locator service etc. The paper also discusses, how the metadata is structured. Finally, it indicates basic metadata <b>components</b> for <b>data,</b> creation, <b>elements,</b> protocal and a guide for Libraries. 1...|$|R
40|$|Abstract. The SPIKE project, {{described}} in this paper, is an EU FP 7 ICT project aimed at development of a software service platform for easy and fast start-up of virtual business alliances. Employing the business process modelling meth-ods and semantic technologies, the envisioned system will simplify collabora-tion between networked enterprises through both dynamically created and pre-defined business processes and workflows. Besides the basic facts and objec-tives of the project, the paper presents an initial architecture design, surveying main system <b>components</b> and <b>data</b> <b>elements</b> together with a brief functional de-scription. 1 Project Description The business networking based on interoperable services provided and consumed within a dynamic and cooperative environment was identified by the European Com-mission in the 7 th Framework Programme as a promising answer {{to the challenges of}} global market pressures [3]. The emerging technologies such as semantically en-hanced Web services in connection with business process modelling frameworks giv...|$|R
40|$|Software Product Line (SPL) {{engineering}} is one approach for addressing customization and variability for products. However, current approaches and research, while often addressing feature modeling and component variability, insufficiently address difficulties and additional complexity {{with respect to}} entity model variability, which negatively impacts various software qualities, such as correctness, reusability, maintainability, testability, and evolvability. This paper presents a solution approach with an integrated mechanism providing a consistent view to capture data variability in entity models, while hiding and decoupling <b>components</b> from superfluous <b>data</b> <b>elements</b> via adapter generation. An eHealth SPL case study is presented supporting adapter generation with differential entity conversion. The results show that with this approach, entity model variability can be effectively addressed and desirable software qualities preserved. 1...|$|R
40|$|Software Product Line (SPL) {{engineering}} is one approach for addressing customization and variability for software products. However, current state-of-the-art often focuses on feature modeling and component variability while insufficiently addressing data model variability difficulties and their associated complexity. Various software qualities, such as correctness, reusability, maintainability, testability, and evolvability, are negatively impacted. In this article the Approach for Data Model Variability (ADMV) is described {{which provides a}} unified and systematic methodology for providing a consistent view to capture data variability in data models. Adapter generation hides and decouples <b>components</b> from superfluous <b>data</b> <b>elements</b> and supports SPL data integration with the potentially multifarious external systems and devices that a SPL may need to consider. An eHealth SPL case study is presented supporting adapter generation with differential data conversion and data integration with medical devices. The results show that with this approach, data model variability and data integration can be effectively addressed and desirable software qualities preserved...|$|R
40|$|Keywords-Software architecture; Software quality; Software performance; Software {{maintenance}} Abstract—A multi-tenant {{software application}} {{is a special}} type of highly scalable, hosted software, in which the ap-plication and its infrastructure are shared among multiple tenants to save development and maintenance costs. The limited understanding of the underlying architectural concepts still prevents many software architects from designing such a system. Existing documentation on multi-tenant software architectures is either technology-specific or database-centric. A more technology-independent perspective is required to enable wide-spread adoption of multi-tenant architectures. We propose the SPOSAD architectural style, which describes the <b>components,</b> connectors, and <b>data</b> <b>elements</b> of a multi-tenant architecture as well as constraints imposed on these elements. This paper describes {{the benefits of a}} such an architecture and the trade-offs for the related design decisions. To evaluate our proposal, we illustrate how concepts of the style help to make current Platform-as-a-Service (PaaS) environments, such as Force. com, Windows Azure, and Google App Engine scalable and customizable...|$|R
50|$|<b>Data</b> <b>Components.</b> The {{fundamental}} {{building block}} of NIEM is the <b>data</b> <b>component.</b> <b>Data</b> <b>components</b> {{are the basic}} business <b>data</b> <b>elements</b> that represent real-world objects and concepts. Information exchanged between agencies {{can be broken down}} into individual components - for example, information about people, places, material things, and events. Components that are frequently and uniformly used in practice are specified in NIEM and can then be reused by practitioners for information exchanges, regardless of the nature of their business or the operational context of their exchanges, provided they are semantically consistent.|$|R
50|$|Part 7 {{provides}} RDF mappings of {{the different}} MLR entities introduced in the MLR framework: <b>Data</b> <b>element</b> specifications, resource classes, <b>data</b> <b>elements,</b> application profiles, MLR records and <b>data</b> <b>element</b> group specifications. It also provides an OWL 2 DL ontology for the resource classes and <b>data</b> <b>element</b> specifications.|$|R
50|$|DICOM uses three {{different}} <b>data</b> <b>element</b> encoding schemes. With explicit value representation (VR) <b>data</b> <b>elements,</b> for VRs {{that are not}} OB, OW, OF, SQ, UT, or UN, the format for each <b>data</b> <b>element</b> is: GROUP (2 bytes) ELEMENT (2 bytes) VR (2 bytes) LengthInByte (2 bytes) Data (variable length). For the other explicit <b>data</b> <b>elements</b> or implicit <b>data</b> <b>elements,</b> see section 7.1 of Part 5 of the DICOM Standard.|$|R
40|$|Abstract Background Synoptic reporting, {{either as}} part of the {{pathology}} report or replacing some free text <b>component</b> incorporates standardized <b>data</b> <b>elements</b> in the form of checklists for pathology reporting. This ensures the pathologists make note of these findings in their reports, thereby improving the quality and uniformity of information in the pathology reports. Methods The purpose of this project is to develop the entire set of elements in the synoptic templates or "worksheets" for hematologic and lymphoid neoplasms using the World Health Organization (WHO) Classification and the College of American Pathologists (CAP) Cancer Checklists. The CAP checklists' content was supplemented with the most updated classification scheme (WHO classification), specimen details, staging as well as information on various ancillary techniques such as cytochemical studies, immunophenotyping, cytogenetics including Fluorescent In-situ Hybridization (FISH) studies and genotyping. We have used a digital synoptic reporting system {{as part of}} an existing laboratory information system (LIS), CoPathPlus, from Cerner DHT, Inc. The synoptic elements are presented as discrete data points, so that a <b>data</b> <b>element</b> such as tumor type is assigned from the synoptic value dictionary under the value of tumor type, allowing the user to search for just those cases that have that value point populated. Results These synoptic worksheets are implemented for use in our LIS. The data is stored as discrete <b>data</b> <b>elements</b> appear as an accession summary within the final pathology report. In addition, the synoptic data can be exported to research databases for linking pathological details on banked tissues. Conclusion Synoptic reporting provides a structured method for entering the diagnostic as well as prognostic information for a particular pathology specimen or sample, thereby reducing transcription services and reducing specimen turnaround time. Furthermore, it provides accurate and consistent diagnostic information dictated by pathologists as a basis for appropriate therapeutic modalities. Using synoptic reports, consistent <b>data</b> <b>elements</b> with minimized typographical and transcription errors can be generated and placed in the LIS relational database, enabling quicker access to desired information and improved communication for appropriate cancer management. The templates will also eventually serve as a conduit for capturing and storing data in the virtual biorepository for translational research. Such uniformity of data lends itself to subsequent ease of data viewing and extraction, as demonstrated by rapid production of standardized, high-quality data from the hemopoietic and lymphoid neoplasm specimens. </p...|$|R
50|$|In metadata, a <b>data</b> <b>element</b> {{definition}} {{is a human}} readable phrase or sentence associated with a <b>data</b> <b>element</b> within a <b>data</b> dictionary that describes the meaning or semantics of a <b>data</b> <b>element.</b>|$|R
50|$|A {{semantic}} mapper processes {{on a list}} of <b>data</b> <b>elements</b> in {{the source}} namespace. The semantic mapper will successively translate the <b>data</b> <b>elements</b> from the source namespace to the destination namespace. The mapping does not necessarily need to be a one-to-one mapping. Some <b>data</b> <b>elements</b> may map to several <b>data</b> <b>elements</b> in the destination.|$|R
40|$|Figure 3 - A {{summary of}} the <b>data</b> <b>elements</b> {{mentioned}} by the different researcher types, showing which <b>data</b> <b>elements</b> researchers had in common and which were unique. This {{does not mean that}} any particular <b>data</b> <b>element</b> is not of interest to another group, only that it did not arise in the series of interviews. Details of these <b>data</b> <b>elements</b> {{can be found in the}} supplementary information. The full list of common <b>data</b> <b>elements</b> is listed in Table 2...|$|R
40|$|The {{main goal}} of this {{research}} is to determine mapping of Iran MARC <b>data</b> <b>elements</b> to Functional Requirement for Bibliographic Records (FRBR) model group one entities and attributes. FRBR group one entities are work, expression, manifestation and item and each one has special attributes. Therefore all fields and <b>data</b> <b>elements</b> of Iran MARC were examined via comparative method to the entities and attributes of the first group. In first segment a table was made and all of the <b>data</b> <b>elements</b> were mapped based on similar research conducted on MARC 21 by U. S Congress Library. Research findings showed that from the total of 1558 <b>data</b> <b>elements</b> that exist in Iran MARC, 531 <b>data</b> <b>elements</b> are manifestation, 73 <b>data</b> <b>elements</b> are Work y, 65 <b>data</b> <b>elements</b> are expression and 33 <b>data</b> <b>elements</b> are Item. Totally 702 <b>data</b> <b>elements</b> in Iran MARC(45. 05 %) have adaption capability. Among attributes of every entity, the Form of work for Work entity, language of Expression attribute for expression, Manifestation identifier attribute for Manifestation and Item identifier for item entity have the major frequency in Iran MARC structure and totally 692 <b>data</b> <b>elements</b> (44. 41 %) adopted this pattern...|$|R
40|$|An object {{tracking}} {{technique is}} provided which, given: (i) a potentially large data set; (ii) {{a set of}} dimensions along which the data has been ordered; and (iii) a set of functions for measuring the similarity between <b>data</b> <b>elements,</b> a set of objects are produced. Each of these objects is defined by a list of <b>data</b> <b>elements.</b> Each of the <b>data</b> <b>elements</b> on this list contains {{the probability that the}} <b>data</b> <b>element</b> is part of the object. The method produces these lists via an adaptive, knowledge-based search function which directs the search for high-probability <b>data</b> <b>elements.</b> This serves {{to reduce the number of}} <b>data</b> <b>element</b> combinations evaluated while preserving the most flexibility in defining the associations of <b>data</b> <b>elements</b> which comprise an object...|$|R
5000|$|... 3.3.51 <b>data</b> <b>element</b> {{representation}} classthe {{class of}} {{representation of a}} <b>data</b> <b>element</b> ...|$|R
50|$|A Representation Term may {{be thought}} of as an {{attribute}} of a <b>data</b> <b>element</b> in a metadata registry that classifies the <b>data</b> <b>element</b> according to the type of data stored in the <b>data</b> <b>element.</b>|$|R
50|$|While each <b>data</b> <b>element</b> has a {{specified}} meaning and format, the standard also includes some general purpose <b>data</b> <b>elements</b> and system- or country-specific <b>data</b> <b>elements</b> which vary enormously in use and form from implementation to implementation.|$|R
50|$|A <b>data</b> <b>element</b> {{definition}} is a required property when adding <b>data</b> <b>elements</b> to a metadata registry.|$|R
50|$|Metadata {{registries}} {{frequently have}} a formal <b>data</b> <b>element</b> submission, approval and publishing approval process. Each <b>data</b> <b>element</b> should {{be accepted by}} a data stewardship team and reviewed before <b>data</b> <b>elements</b> are published. After publication change control processes should be used.|$|R
50|$|Note that a {{registered}} <b>data</b> <b>element</b> is any <b>data</b> <b>element</b> that already exists within a metadata registry.|$|R
5000|$|Distinct - The {{definition}} should differentiate a <b>data</b> <b>element</b> {{from other}} <b>data</b> <b>elements.</b> This process is called disambiguation.|$|R
40|$|A method, {{system and}} {{computer}} program product for supporting concurrent updates to a shared <b>data</b> <b>element</b> group while preserving group integrity on behalf {{of one or more}} readers that are concurrently referencing group <b>data</b> <b>elements</b> without using locks or atomic instructions. Two or more updaters may be invoked to generate new group <b>data</b> <b>elements.</b> Each new <b>data</b> <b>element</b> created by the same up dater is assigned a new generation number that is different than a global generation number associated with the <b>data</b> <b>element</b> group and which allows a reader of the <b>data</b> <b>element</b> group to determine whether the new <b>data</b> <b>element</b> is a correct version for the reader. The new generation numbers are different for each up dater and assigned according to an order in which the updaters respectively begin update operations. The global generation number is updated so that when all of the up daters have completed <b>data</b> <b>element</b> update processing, the global generation number will correspond to the new generation number that is associated with the last of the up daters to begin update operations...|$|R
50|$|<b>Data</b> <b>element</b> to <b>data</b> <b>element</b> mapping is {{frequently}} complicated by complex transformations that require one-to-many and many-to-one transformation rules.|$|R
5000|$|... {{is greater}} than each <b>data</b> <b>element</b> in [...] and {{less than or equal}} to each <b>data</b> <b>element</b> in [...]|$|R
40|$|Controlled medical terminologies {{that have}} been {{developed}} to describe terms utilized in the field of Radiation Oncology, include SNOMED-CT and DICOM-RT. However, a literature review has failed to provide evidence that the coverage and the level of granularity of these nomenclatures have satisfied the needs of radiation oncologists. Indeed most investigations conclude that the coverage is generally unsatisfactory. Fur-thermore, {{there is no evidence that}} an objective specification of the specialist medical terms used in Radiation Oncology has been developed. We report the development of a Specialist Medical Vocabu-lary for Radiation Oncology using an objective and systematic method of discovery of <b>data</b> <b>elements</b> published in the Radia-tion Oncology literature. The importance of the <b>data</b> <b>elements</b> to radiation oncologists is judged according to the criterion that a submitted report has been deemed worthy of publica-tion. Within the time period of discovery, 97 articles were retrieved and, during the analysis of 80 articles, 622 individual <b>data</b> <b>elements</b> and 2392 instances of use were found. Infrequent <b>data</b> <b>elements</b> comprised the majority of individual <b>data</b> <b>elements</b> (54 %), and frequently used <b>data</b> <b>elements</b> were a minority (27 individual <b>data</b> <b>elements</b> with 10 or more in-stances of use). However these 10 <b>data</b> <b>elements</b> comprised 49. 5 % of the total <b>data</b> <b>elements</b> found...|$|R
5000|$|... #Subtitle level 3: Count the Input <b>Data</b> <b>Element</b> Types, the <b>Data</b> entity Types Referenced, and the Output <b>Data</b> <b>Element</b> Types ...|$|R
50|$|The {{result of}} this is a {{catalogue}} of sorts, in which related <b>data</b> <b>element</b> concepts are grouped by a high-level concept and an object class, and <b>data</b> <b>elements</b> grouped by a shared <b>data</b> <b>element</b> concept. Strictly speaking, this is not a hierarchy, even if it resembles one.|$|R
5000|$|Universal <b>Data</b> <b>Element</b> Framework Forum - {{merged with}} Open Platform 3.0 in 2015; {{now known as}} O-DEF (Open <b>Data</b> <b>Element</b> Framework) ...|$|R
50|$|<b>Data</b> <b>elements</b> are the {{individual}} fields carrying the transaction information. There {{are up to}} 128 <b>data</b> <b>elements</b> specified in the original ISO 8583:1987 standard, and up to 192 <b>data</b> <b>elements</b> in later releases. The 1993 revision added new definitions, deleted some, while leaving the message format itself unchanged.|$|R
40|$|A {{method for}} storing a vector of process <b>data</b> <b>elements</b> (D 1,..., D 8) {{that have a}} size of n bits from a {{register}} file (RF) into a memory (M) is described. The memory is arranged for storage of a vector of storage <b>data</b> <b>elements</b> in locations (M 1,..., M 5) having a size of m bits, wherein m 2 ̆ 6 gt;n. The method comprises the steps of: exchanging bits (S 2) between process <b>data</b> <b>elements</b> in the vector stored in mutually subsequent register elements, the exchanging resulting in a vector of modified <b>data</b> <b>elements</b> (DmI,..., Dm 8), shuffling (S 3) groups of k subsequent bits in the resulting vector, [...] storing (S 4) the resulting shuffled vector of modified <b>data</b> <b>elements</b> as a vector of storage <b>data</b> <b>elements</b> in the memory (M) ...|$|R
50|$|<b>Data</b> <b>elements</b> are {{frequently}} assigned to data stewards or data stewardship {{teams that are}} responsible for the maintenance of individual <b>data</b> <b>elements.</b>|$|R
50|$|If a <b>data</b> <b>element</b> {{is used to}} {{identify}} a record within a data set, the <b>data</b> <b>element</b> uses the Identifier representation term.|$|R
