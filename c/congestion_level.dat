387|408|Public
50|$|Most current {{congestion}} control algorithms detect congestion and slow down when they discover that packets are being dropped, {{so that the}} average sending rate depends on the loss probability. This has two drawbacks. First, low loss probabilities are required to sustain high data rates; {{in the case of}} TCP Reno, very low loss probabilities are required, but even new congestion avoidance algorithms such as H-TCP, BIC TCP and HSTCP require loss rates lower than those provided by most wireless wide area networks. Moreover, packet loss only provides a single bit of information about the <b>congestion</b> <b>level,</b> whereas delay is a continuous quantity and in principle provides more information about the network.|$|E
5000|$|However, {{the focus}} of the European Commission has rather been on lorries than on private cars, as lorries are {{concerned}} directly by the internal market. But {{it was only in the}} end of the last century, that the legal basis for road tolling was established in Directive 1999/62/EC ("Eurovignette") on European Community level. This Directive had the focus on the tolling of motorways, bridges, tunnels and mountain passes, but only for lorries over 12 tonnes maximum laden weight, and the charging was only possible for infrastructure costs. Eight years later in 2006, the Directive was amended by Directive 2006/38/EC, which has a new focus on road tolling of the trans-European road network, but leaves the EU Member States the right to apply tolls as well on roads not included in the trans-European road network. The amended Directive gives the EU Member States the possibility of varying tolls according to a number of factors such as distance travelled, place, infrastructure type and speed, vehicle characteristics, time of day and <b>congestion</b> <b>level.</b> In addition, the EU Member States are obliged to include all vehicles over 3.5 tonnes maximum laden weight after 2012, and after 2010, the tolls must be differentiated according to the environmental performance of the vehicle.Recently, the European Commission proposed a new, second amendment to the Directive 1999/62/EC, enableling EU Member States to integrate the cost of air and noise pollution caused by traffic in tolls levied on heavy goods vehicles and allowing tolls to be calculated on the basis of the cost of congestion imposed upon other vehicles during peak periods.Map: charging of heavy goods vehicles in the EU ...|$|E
30|$|The {{implementation}} of QCC {{is inspired by}} the protocols which monitor the local buffer occupancy of the sensor nodes in order to estimate congestion such as (ESRT) [10] and Fusion [11]. To determine the <b>congestion</b> <b>level</b> of the network, instead of using single threshold, QCC uses two thresholds between 0 % and 100 % to adapt the result of QCC congestion to SUIT’s rate adaptation. If the buffer occupancy rate {{is lower than the}} first threshold, the <b>congestion</b> <b>level</b> of the network is considered as Not Congested. If the buffer occupancy rate is between two thresholds, the <b>congestion</b> <b>level</b> of the network is considered as Slightly Congested. If the buffer occupancy rate is higher than the second threshold, the <b>congestion</b> <b>level</b> of the network is considered as Fairly Congested.|$|E
30|$|Good {{correlation}} values between infrastructure accessibility, socio-economic indicators, and <b>congestion</b> <b>levels</b> {{have been}} demonstrated with a reasonable goodness of fit. The analyses have shown that cities with higher GDP have built more infrastructure which in turn results in lower <b>congestion</b> <b>levels.</b> The relation between infrastructure accessibility and <b>congestion</b> <b>levels</b> has been quantified using regression models. For cities with low population density (above approximately 1500 Inh. per sq. km), more roads per inhabitant lead to lower <b>congestion</b> <b>levels.</b> Metropolises and mature cities with high population density have in general lower <b>congestion</b> <b>levels</b> where rail infrastructure per person is higher. There is significant evidence that, in case of high density cities, an increase in train infrastructure accessibility is more de-congestionating than an increase in road infrastructure accessibility.|$|R
30|$|Conversely, the {{agglomeration}} {{of economic}} activities usually entails higher <b>congestion</b> <b>levels</b> which negatively affect accessibility, through increasing transport costs. Nonetheless, {{most of the}} more accessible regions also have the highest <b>congestion</b> <b>levels.</b>|$|R
30|$|The {{main results}} reconfirm {{previous}} findings {{but with a}} larger sample size and more comparable data. Good correlation values between infrastructure accessibility, socio-economic indicators, and <b>congestion</b> <b>levels</b> are demonstrated. It is shown that cities with higher GDP have generally built more infrastructure which in turn reduces their <b>congestion</b> <b>levels.</b> In particular, for cities with low population density (above approximately 1500 inh. Per sq.km), more roads per inhabitant lead to lower congestion levels; cities with high population density have in general lower <b>congestion</b> <b>levels</b> if the rail infrastructure per person ratio is high. Furthermore, these cities increasing railways per person is more effective in reducing congestions than increasing road length per person.|$|R
30|$|The frame {{rates at}} source sensor nodes are {{calculated}} {{in a different}} manner for each protocol. SUIT and FCE use fuzzy logic-based approach whereas QCC uses local buffer occupancy for deciding on the <b>congestion</b> <b>level.</b> According to the <b>congestion</b> <b>level,</b> the frame rate is assigned dynamically while generating images. In Figure  10, the average calculated frame rate at the source sensor nodes is illustrated. All of the protocols decrease the frame rate as the network is getting congested. QCC estimates the <b>congestion</b> <b>level</b> optimistically and therefore calculates higher frame rates than the others. On the other hand, FCE estimates the congestion in a pessimistic manner and calculates lower frame rates than the others. SUIT provides a balanced <b>congestion</b> <b>level</b> via its efficient fuzzy logic-based congestion estimation technique. Therefore, SUIT provides better performance than its competitors in all QoS metrics, except of the average received frame quality.|$|E
30|$|For instance, when {{considering}} a fixed IR in EDCA, the <b>congestion</b> <b>level</b> of AC[2] should increase with n. Recall that the AC[2] in EDCA are FIFO based, not AQM based. There {{should be a}} similar increasing trend for the AQM-based mapping algorithms for AC[2], including the existing works and the proposed CQM algorithm, and the differences are that only the AQM-based algorithms will perform their own mechanism to downward map those less significant video packets to lower-priority ACs, which could again increase the <b>congestion</b> <b>level</b> of the destined lower-priority AC. On the other hand, for a fixed n, the <b>congestion</b> <b>level</b> of AC[2] could be dominated by IR, i.e., the larger the IR, the more congested the AC[2].|$|E
40|$|In 4 G-domain multi home mobile host (MH) {{will have}} access to {{different}} wireless networks. In this 4 G wireless networks real time applications are initiated to support services like VOIP, videoconference. These applications use RTP over UDP. These protocols are unresponsive to congestion events. Our proposed congestion management scheme minimizes <b>congestion</b> <b>level</b> in 4 G domains using coalition game. Its main objective is to decide target networks for handoff with minimum <b>congestion</b> <b>level.</b> Our mechanism is based on the coalition game formation. It aims at maximizing the utilization of the resources available and meeting QoS requirement of users as much as possible. This will reduce <b>congestion</b> <b>level</b> with vertical handoff initiation...|$|E
40|$|This report aims {{to provide}} the general public, {{industry}} and policy makers with unique and unbiased information about <b>congestion</b> <b>levels</b> in urban areas. The methodology that is used in this report compares travel times during non-congested periods (free flow) with travel times in peak hours. The difference is expressed as a percentage increase in travel time. It takes into account local roads, arterials and highways. All data is based on actual GPS based measurements and for each city the sample size is expressed in total number of measured kilometres for the period. As well as assigning and ranking the overall <b>congestion</b> <b>levels</b> of over 120 cities* on different continents, the report evaluates the <b>congestion</b> <b>levels</b> in cities {{at different times of}} the day and on different days of the week. The report includes detailed information such as the most congested day, time delay per year for commuters and <b>congestion</b> <b>levels</b> on highways and local roads...|$|R
5000|$|Road pricing, {{charging}} {{money for}} access onto a road/specific area at certain times, <b>congestion</b> <b>levels</b> or for certain road users ...|$|R
40|$|This {{analysis}} {{breaks down}} the <b>congestion</b> <b>levels</b> experienced during specific parts of a wilderness canoe trip. By explicitly addressing the heterogeneity in preferences for congestion during a trip, {{we are able to}} determine the relative value canoeists place on solitude at different points of a trip. Our econometric model utilizes a random effects probit framework to efficiently estimate the welfare impacts of congestion on each trip portion. The welfare effects of <b>congestion</b> <b>levels</b> vary across wilderness areas, parts of a trip and individuals...|$|R
40|$|Abstract: End-to-end TCP (transmission control protocol) {{congestion}} control can cause unfairness among multiple TCP connections with different RTT (Round Trip Time). The throughput of TCP connection is {{inversely proportional to}} its RTT. To resolve this problem, researchers have proposed many methods. The existing proposals for RTT-aware conditioner work well when <b>congestion</b> <b>level</b> is low. However, they over-protect long RTT flows and starve short RTT flows when <b>congestion</b> <b>level</b> is high. Due to this reason, an improved method based on adaptive thought is proposed. According to the <b>congestion</b> <b>level</b> of networks, the mechanism can adaptively adjust the degree of the protection to long RTT flows. Extensive simulation experiments showed that the proposed mechanism can guarantee the bandwidth fairness of TCP flows effectively and outperforms the existing methods...|$|E
3000|$|Queuing: {{refers to}} the time waiting at the output link for transmission; usually {{depending}} on the <b>congestion</b> <b>level</b> of router; [...]...|$|E
30|$|The {{application}} layer {{is responsible for}} generating and viewing images. Images can be both SJPEG and PJPEG with or without restart markers. The source sensor is capable of fragmenting the image and the sink is capable of defragmenting it. In conventional layered designs, the {{application layer}} does not request information from the lower layers but in SUIT, the application layer gets the <b>congestion</b> <b>level</b> from the transport layer. According to the <b>congestion</b> <b>level,</b> it adapts the video rate as explained in Section 3.6.|$|E
40|$|Abstract—This paper {{presents}} a machine learning {{approach to the}} efficient vehicle power management and an intelligent power controller (IPC) that applies the learnt knowledge about the optimal power control parameters specific to road types and traffic <b>congestion</b> <b>levels</b> to online vehicle power control. The IPC uses a neural network for online prediction of roadway types and traffic <b>congestion</b> <b>levels.</b> The IPC and the prediction model have been implemented in a conventional (non-hybrid) vehicle model for online vehicle power control in a simulation program. The benefits of the IPC combined with the predicted drive cycle are demonstrated through simulation. Experiment {{results show that the}} IPC gives close to optimal performances. I...|$|R
30|$|Travel time {{predictions}} {{are increasingly}} important both, for commercial traffic (in {{order to minimize}} costs due to suboptimal planning) and individual traffic (in order to reduce <b>congestion</b> <b>levels</b> and {{minimize the risk of}} incurring penalties due to being unpunctual).|$|R
30|$|The AC- 5 B case {{seems to}} be {{slightly}} preferred than the others in all the <b>congestion</b> <b>levels</b> of n when IR = 512 kbps (in particular, AC- 5 B wins over SC- 5 B and SC- 10 B by around 1.1 and 0.7 dB when n = 2, and AC- 10 B is not preferred {{since it is the}} worst one when n = 6 in both IR = 512 kbps and IR = 384 kbps), though it also {{seems to be}} slightly worse than the others in heavy <b>congestion</b> <b>levels</b> of n when IR = 256 kbps. Thus, it should be safe to take AC- 5 B as a typical case throughout the rest of this article.|$|R
40|$|Abstract: In general, nodes in Wireless Sensor Networks (WSNs) are {{equipped}} with limited battery and computation capabilities but the occurrence of congestion consumes more energy and computation power by retransmitting the data packets. Thus, congestion should be regulated to improve network performance. In this paper, we propose a congestion prediction and adaptive rate adjustment technique for Wireless Sensor Networks. This technique predicts <b>congestion</b> <b>level</b> using fuzzy logic system. Node degree, data arrival rate and queue length are taken as inputs to the fuzzy system and <b>congestion</b> <b>level</b> is obtained as an outcome. When the <b>congestion</b> <b>level</b> is amidst moderate and maximum ranges, adaptive rate adjustment technique is triggered. Our technique prevents congestion by controlling data sending rate and also avoids unsolicited packet losses. By simulation, we prove the proficiency our technique. It increases system throughput and network performance significantly...|$|E
40|$|In {{this paper}} we build an agent based {{evacuation}} model {{and use it}} to test a novel traffic control strategy called throttling. The evacuee agents travel from a source to a destination taking the dynamic shortest time path (total travel time depends on the distance to destination and the <b>congestion</b> <b>level).</b> Throttling involves closing a road segment temporarily when its <b>congestion</b> <b>level</b> reaches an upper threshold and opening it when <b>congestion</b> <b>level</b> falls below a lower threshold. Experimentation was performed by comparing the total evacuation time obtained with throttling to a base case (non-throttling) using a small test network and the more realistic Sioux Falls network. We found that throttling improves the total evacuation time significantly. To further test the effectiveness of our control strategy we compared it to contraflow on the test network and found the results to be comparable. ...|$|E
3000|$|... {{for all the}} {{congestion}} levels, {{meaning that}} it keeps the minimum value in average packet delay {{no matter how the}} <b>congestion</b> <b>level</b> changes, as aforementioned.|$|E
30|$|Based {{on these}} {{findings}} and conditioned by {{the availability of}} accessible data, this study will use the length of transport infrastructure per person to quantify the amount of available transport infrastructure. This term is known as infrastructure accessibility [21]. The transport performance is quantified by <b>congestion</b> <b>levels.</b>|$|R
40|$|Abstract—DVFS {{circuits}} {{are applied}} to network-controllers inorder to reduce power dissipation in networks. When receive and transmit buffers are relatively empty, energy is saved by lowering the packet processing rate. Simulations show an average energy savings of 29 % across various traffic loads and 19 % across various <b>congestion</b> <b>levels.</b> I...|$|R
30|$|We conduct {{numerical}} simulations {{to evaluate}} this framework and verify {{the influence of}} dynamic price for user association. Results show that when FHs adopt congestion pricing policy, the remarkable throughput gain can be achieved under different <b>congestion</b> <b>levels.</b> Due to dynamic cell load control, the effect of load balancing can also be substantially improved.|$|R
30|$|VQD can {{effectively}} alleviate the <b>congestion</b> <b>level</b> by early dropping video packets of less importance (i.e. those lower-priority ones) at congestion cases n[*]=[*] 2, 3 and 4.|$|E
3000|$|... {{except for}} n[*]=[*] 1 {{due to its}} {{effective}} packet dropping behaviour, particularly when the <b>congestion</b> <b>level</b> increases), it does always {{take the lead in}} both r [...]...|$|E
3000|$|... {{according}} to a single or multiple reward (respectively cost) metrics, such as queuing delay, available bandwidth, <b>congestion</b> <b>level,</b> packet loss rate, energy consumption level, link reliability, retransmission count, etc.|$|E
40|$|Lake County, Illinois {{is already}} {{experiencing}} a traffic congestion problem. By the year 2020, when its population {{is projected to}} increase by at least 250, 000, traffic congestion will likely be significantly worse. This report is the second installment in a study called "Crossroads: Smart Transportation Options for Lake County", which is commissioned by the Environmental Law and Policy Center and Citizens Organized for Sound Transportation. The study is carried out by Resource Systems Group, Inc. and the University of Illinois at Chicago. It uses advanced transportation modeling to {{examine the impact of}} various possible transportation improvements on traffic <b>congestion</b> <b>levels</b> in Lake County. The first installment of Crossroads, released in 1997, demonstrated that the State could relieve traffic <b>congestion</b> <b>levels</b> in the year 2020 14 % more by simply carrying out the existing plan to upgrade local roads in Lake County than by building the proposed new $ 1. 2 billion Route 53 tollroad. In other words, building a 25 -mile, six-lane extension to Route 53 would increase traffic congestion by 14 %. In this second installment, we now examine the impact of proposed transit improvements on Lake County traffic <b>congestion</b> <b>levels.</b> We tested a package of transit improvements that are, again, included in the State's official transportation plan. They include installing a second track on the Wisconsin North Central commuter rail line, building a portion of the Elgin Joliet and Eastern circumferential commuter rail line, and increasing bus service...|$|R
30|$|A study {{funded by}} the Intelligent Energy Europe Programme of the European Union [27] {{suggests}} that “ 51  % of all motorized trips in EU cities that involve the transportation of goods could be shifted to cargo bikes”. This sort of modal shift {{would have a significant}} impact in city centres, particularly in cities that suffer from high <b>congestion</b> <b>levels.</b>|$|R
40|$|Congestion {{information}} can greatly benefit network level decisions. For example, fast-reroute algorithms should leverage congestion information when computing backup paths. They could {{also use the}} information to monitor if the re-routing decision itself causes congestion in the network. Today, most solutions for inferring congestion work at the end-host level and relay end-to-end congestion information to transport protocols. Network level decisions, on the other hand, may need link <b>level</b> <b>congestion</b> information. Unfortunately, the mechanisms that routers can use to infer link <b>level</b> <b>congestion</b> information are insufficient. Such information could potentially be obtained by periodically sharing estimates between routers. However, this solution increases the traffic load on the network and has difficulty in reliably delivering the estimates during periods of congestion. In this thesis we show that routers inside an autonomous system can easily and accurately infer congestion information about each other. Routers first measure path <b>level</b> <b>congestion</b> information only from the congestion markings in the traffic that they forward. Next, we propose that routers combine routing information with the path <b>level</b> <b>congestion</b> information to obtain a more {{detailed description of the}} congestion in the network. Link <b>level</b> <b>congestion</b> {{information can}} be computed using this approach. Our techniques never add supplementary traffic into the network and use little router resources. They can be deployed incrementally or in heterogeneous environments. We show that the accuracy of the inference is good using experiments with multiple traffic patterns and various <b>congestion</b> <b>levels...</b>|$|R
30|$|The Minimum-Delay-Time {{selection}} rule {{embedded in}} CQM can generate more balanced congestions among AC[1] and AC[0] {{so that the}} <b>congestion</b> <b>level</b> of AC[1] in CQM {{seems to be the}} minimum among the AQM-based algorithms.|$|E
40|$|In this paper, {{we propose}} a new {{characteristic}} measure relative people density and motion dynamics {{for the purpose}} of long-term crowd monitoring. While many related works focus on direct people counting and absolute density estimation, we will show that relative densities provide reliable information on crowd behaviour. Furthermore, we will discuss the derivation of a so-called <b>Congestion</b> <b>Level</b> of local areas in the crowd, which takes the current dynamics and density within a certain image region into account. Our density estimation approach is based on a well-known KLT feature tracking algorithm, combined with a post-processing for motion vector association. The resulting feature tracks (tracklets) represent movements of detected objects in the scene. These trajectories are used as basic features for later estimation of track density and relative inertia (changes in motion dynamics), which together are combined to a joint <b>Congestion</b> <b>Level.</b> We show the results of our approach by comparing the characteristic measures of track density and <b>Congestion</b> <b>Level</b> with manually annotated Ground truth data of both artificial and real scenes...|$|E
40|$|Prior {{survey of}} RED {{algorithm}} deployment on multiqueue system with shared buffer was unfair and sensitive to <b>congestion</b> <b>level</b> by statically setting the parameters. In this paper, {{our goal is}} to deploy the Random Early Detection (RED) algorithm in routers on shared buffer and solve these problems. A novel buffer management scheme that dynamically adjusts the parameters of RED named RED-ODT is proposed. Simulations under uniform traffic load and nonuniform traffic load are given, the results of which ascertain and demonstrate the superiority of the proposed scheme in terms of low packet drop ratio, satisfying buffer utilization and fairness. Simulation also shows that RED-ODT is insensitive to <b>congestion</b> <b>level.</b> 1 1...|$|E
40|$|In this paper, an {{end-to-end}} real-time adaptive {{protocol for}} multimedia transmission is presented. The bandwidth is dynamically allocated {{according to the}} network status, and the client buffer occupancy and playback requirement. The transmission rate {{is determined by the}} quadratic probing algorithm that can obtain the maximal utilization of the client buffer and minimal occupation of the network bandwidth. It is also coupled with a congestion control mechanism that can effectively decrease the packet loss rate during network congestion. We investigate the performance of our quadratic probing algorithm in different <b>congestion</b> <b>levels</b> under both the Local Area Net (LAN) and Internet environments. Performance analysis reveals that our approach is more robust in avoiding overflows and underflows in different network <b>congestion</b> <b>levels,</b> and adapting to the changing network delays. Comparisons are made with the fixed rate approach and the rate by playback requirement approach. The experimental results show that our proposed real time protocol with the rate adjusting quadratic probing algorithm is efficient in utilizing the network resources and decreasing the packet loss ratios...|$|R
40|$|The {{simultaneous}} {{implementation of}} daily activity-travel schedules {{of individuals in}} a given spatial environment generally gives rise to time- and location-varying <b>congestion</b> <b>levels,</b> which affect the conditions for subsequent activity and travel choices. Although such dynamics are commonly recognized, current activity-based models typically ignore the adaptive behaviour of individuals. In this article, we propose an agent-based simulation system that allows one to simulate, in addition to activity-scheduling behaviour, also the execution of schedules in space and time. <b>Congestion</b> <b>levels</b> at specific times and places emerge {{in the system and}} may lead to discrepancies between scheduled and actual activity and travel times. Agents respond to such unforeseen events by reconsidering an existing schedule (within-day re-planning) and by adapting their expectations about traffic conditions for subsequent days (learning). The system is illustrated using the activity-travel diary data collected in the Eindhoven region, the Netherlands, to better understand the choice of urban parks in the study area. We discuss the merits of the system for transport and spatial planning and identify avenues for future research...|$|R
40|$|Congestion {{alleviation}} {{has long}} been a core planning objective in most transportation programs, but existing policy portfolios have been both costly and unsuccessful at alleviating congestion. Road gridlock is inconvenient, but it remains unclear under which conditions this indicator of active urban places also impedes other social objectives, among which this dissertation focuses on the economy. This dissertation contributes by estimating congestion 2 ̆ 7 s economic drag and identifying how policy can contribute to high-functioning regions despite congestion. First, I use panel data for 88 U. S. Metropolitan Statistical Areas (MSAs) to estimate congestion 2 ̆ 7 s drag on employment growth (1993 to 2008) and productivity growth (2001 to 2008). Next, to identify 2 ̆ 2 better 2 ̆ 2 regional adaptations to congestion, I explore congestion resilience using a metric of economic growth per unit 2 ̆ 2 cost 2 ̆ 2 of congestion growth. Using panel data for 88 MSAs, I estimate the relative contributions of policies in enabling congestion resilience. Finally, using case studies of high-congestion MSAs, I explore policies distinguishing congestion resilient Los Angeles and Washington, DC from congestion unresilient Chicago and Houston. ^ Results indicate that higher congestion is not associated with slower productivity growth, but is associated with slower employment growth rates above <b>congestion</b> <b>levels</b> of 39 (shorter-term) or 57 annual hours of delay per commuter (longer-term). When pooling MSAs across the range of <b>congestion</b> <b>levels</b> using panel data, sources of congestion resilience parallel 2 ̆ 2 good 2 ̆ 2 economic policy, more generally. But when focusing on four high-congestion MSAs, results suggest an important role for planners. Road transportation policy, public transit policy, and urban spatial structure distinguish congestion resilient Los Angeles and Washington, DC from congestion unresilient Chicago and Houston. ^ In conclusion, evidence suggests that regional economies are highly adaptive to congestion and that planning policy can contribute to congestion resilience, particularly for high-congestion MSAs, but that context matters. Lessons from case studies of high-congestion MSAs are critical for other large and congested MSAs, but are less applicable across the spectrum of lower regional <b>congestion</b> <b>levels.</b> In fact, lessons from panel models including MSAs with a large-range of regional <b>congestion</b> <b>levels</b> indicate that <b>congestion</b> resilience is largely a function of 2 ̆ 2 good 2 ̆ 2 economic policy generally for most regions. ...|$|R
