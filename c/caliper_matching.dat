12|13|Public
40|$|Matched {{sampling}} is {{a methodology}} {{used to estimate}} treatment effects. A caliper mechanism is used to achieve better similarity among matched pairs. We investigate finite sample properties of matching with caliper and propose a slight modification to the existing mechanism. The simulation study compare performance of both methods and show that standard caliper perform well only in case of constant treatment or uniform propensity score distribution. Secondly, {{in a case of}} non-uniform distribution and non-uniform treatment the dynamic caliper method outperform standard <b>caliper</b> <b>matching...</b>|$|E
40|$|Propensity-score {{matching}} {{is increasingly}} {{being used to}} estimate the effects of treatments using observational data. In many-to-one (M: 1) matching on the propensity score, M untreated subjects are matched to each treated subject using the propensity score. The authors used Monte Carlo simulations to {{examine the effect of}} the choice of M on the statistical performance of matched estimators. They considered matching 1 – 5 untreated subjects to each treated subject using both nearest-neighbor matching and <b>caliper</b> <b>matching</b> in 96 different scenarios. Increasing the number of untreated subjects matched to each treated subject tended to increase the bias in the estimated treatment effect; conversely, increasing the number of untreated subjects matched to each treated subject decreased the sampling variability of the estimated treatment effect. Using nearest-neighbor matching, the mean squared error of the estimated treatment effect was minimized in 67. 7 % of the scenarios when 1 : 1 matching was used. Using nearest-neighbor matching or <b>caliper</b> <b>matching,</b> the mean squared error was minimized in approximately 84 % of the scenarios when, at most, 2 untreated subjects were matched to each treated subject. The authors recommend that, in most settings, researchers match either 1 or 2 untreated subjects to each treated subject when using propensity-score matching...|$|E
40|$|BACKGROUND: Few {{studies have}} yielded {{information}} on comparative effectiveness of transcatheter aortic valve implantation (TAVI) versus surgical aortic valve replacement (SAVR) procedures in a real-world setting. The {{aim of this}} analysis is to describe procedural and post-procedural outcomes in a TAVI/SAVR intermediate risk propensity-matched population. METHODS: OBSERVANT is an observational prospective multicenter cohort study, enrolling AS patients undergoing SAVR or TAVI. Propensity score method was applied to analyze procedural and post-procedural outcomes. Pairs of patients with the same probability score were matched (<b>caliper</b> <b>matching).</b> RESULTS: The unadjusted enrolled population (N= 2108) comprises 1383 SAVR patients, 602 transarterial-TAVI patients and 123 transapical-TAVI patients. Matched population comprised a total of 266 patients (133 patients for each group). A relatively low risk population was selected (mean logistic EuroSCORE 9. 4 ± 10. 4...|$|E
30|$|The last zone, Z 9, is {{characterized}} by mud losses of 14  m 3 /h recorded {{at a depth of}} 1, 240  m. The <b>caliper</b> values <b>match</b> the depths of several peaks and a major anomaly of 16.80 inches at 1, 238 -m depth. Zone Z 9 is therefore classified as a complex permeable fracture zone.|$|R
5000|$|The Ducati Hypermotard is a supermotard Ducati {{motorcycle}} {{designed by}} Pierre Terblanche and was first {{seen at the}} November 2005 EICMA trade show in Milan. The Hypermotard was awarded [...] "Best of Show" [...] at EICMA and has since won other show awards.The Hypermotard has a [...] dual spark (see 2010 MY revisions) 'Desmo' or 'Desmodromic' aired-cooled two-valve 90° V-twin engine with fuel injection and weighs under 180 kg (396 lb). The Hypermotard is capable of speeds {{in the region of}} 125 mph, but many people choose this kind of bike for having fun at speeds of up to 100 mph and accept that there's limited protection from wind blast at higher speeds compared to some motorcycles, due to the upright riding position and lack of fairings/ screen.The rigidly triangulated trellis frame wears 50 mm Marzocchi R.A.C. inverted forks, and has a Sachs/ Öhlins remote reservoir shock attached to a strong, single-sided swing arm. The Marchesini racing wheels wear dual radially mounted Brembo four-piston, two-pad brake <b>calipers</b> <b>matched</b> with 305 mm discs up front, and a 245 mm disc with two-piston caliper at the rear.|$|R
40|$|We {{present a}} new {{algorithm}} which detects the maximal number of matched disjoint pairs satisfying a given <b>caliper</b> when the <b>matching</b> {{is done with}} respect to a scalar index (e. g., propensity score), and constructs a corresponding matching. If each of the groups is ordered with respect to the index then the number of operations needed is $O(N) $, where $N$ is the total number of objects to be matched. The case of 1 -to-$n$ matching is also considered. Keywords: propensity score matching, matching with calipe...|$|R
40|$|Subsidized {{research}} {{joint ventures}} (RJVs) between public research institutions and industry {{have become increasingly}} popular in Europe and the US. We study the long-run effects of such a support scheme that has been maintained by the Danish government since 1995. To cope with identification problems we apply nearest neighbor <b>caliper</b> <b>matching</b> and conditional difference-in-difference estimation methods. Our main findings are that (i) program participation effects are instant for annual patent applications and last for three years, (ii) employment effects materialize first after one year and (iii) there are no statistically significant effects on value added or labor productivity. We further show that these overall results are primarily driven by firms that were patent active prior to joining the RJV {{and that there are}} no statistically significant effect for large firms. Both types of firms are disproportionally represented in the support program we study. public-private partnership, research joint venture, research and development, research subsidies...|$|E
40|$|Objective As {{covariates}} are {{not always}} adequately balanced after propensity score matching and double-adjustment {{can be used to}} remove residual confounding, we compared the performance of several double-robust estimators in different scenarios. Methods We conducted a series of Monte Carlo simulations on virtual observational studies. After estimating the propensity scores by logistic regression, we performed 1 : 1 optimal, nearest-neighbor and <b>caliper</b> <b>matching.</b> We used four estimators on each matched sample: i) a crude estimator without double-adjustment, ii) double-adjustment for the propensity scores, iii) double-adjustment for the unweighted unbalanced covariates, and iv) double-adjustment for the unbalanced covariates, weighted by their strength of association with the outcome. Results The crude estimator led to highest bias in all tested scenarios. Double-adjustment for the propensity scores effectively removed confounding only when the propensity score models were correctly specified. Double-adjustment for the unbalanced covariates was more robust to misspecification. Double-adjustment for the weighted unbalanced covariates outperformed the other approaches in every scenario and using any matching algorithm, as measured by the mean squared error. Conclusion Double-adjustment can be used to remove residual confounding after propensity score matching. The unbalanced covariates with the strongest confounding effects should be adjusted. </p...|$|E
40|$|Three {{examples}} {{are used to}} demonstrate that the selection of controls from categories that overlap can lead to bias. Case-control studies that use friend controls and the practice of age-matching controls to cases within a specified number of years (<b>caliper</b> <b>matching)</b> are examples of the selection bias described in the paper. The bias resulting from the use of friend controls can be large and, since the use of friend controls is common, this source of bias is of considerable practical consequence. The use of friend controls or the selection of controls according to other variables with categories that overlap should be avoided. Selection bias is a serious challenge to the validity of observational studies. It is a particularly vexing problem because it is difficult to identify and adjustment for it in the analysis is usually impossible. The {{purpose of this paper is}} to demonstrate, through the use of examples, that selection of controls from categories that overlap can lead to bias. It will be shown that selection of controls from categories that are not mutually exclusive can lead to a situation in which th...|$|E
40|$|The {{present study}} {{deals with the}} problem of {{comparison}} between a two medical facilities 2 ̆ 7 with extremely skewed sample sizes from non-experimental study. The data came from a study of rehabilitation interventions with patients diagnosed with cardiac and pulmonary issues who received treatment either in inpatient rehabilitation facilities (IRFs) or in skilled nursing facilities (SNFs). Due to inclusion and exclusion criteria, however, the study had failed to recruit sufficient number of participants between two comparison groups: 319 from IRFs and 27 from SNFs. As a result, the main hypothesis of the study was not tested due to the disparity of the participants between the two comparison groups, which could not be analyzed as a study with an unbalanced design because of lack of power in the analysis (Beacham, 2008). In medical research, this kind of problem occurs often not only because of inclusion and exclusion criteria in recruiting patients for a study but also because of dropout patients due to many reasons, such as technical changes (certain insurance and/or Medicare policies eliminate possible participants), medical changes, or personal circumstances change {{in the middle of the}} study. By extracting matching methods from both Fisher 2 ̆ 7 s experimental design and Rubin 2 ̆ 7 s Causal Model (RCM) the present study attempts to offer ways to draw the causal inference in a non-experimental study with sample size disparity between two comparison groups, especially when collected data disable a researcher to analyze. The matched datasets were analyzed in two ways: multivariate of covariance (MANCOVA) first and two analysis of covariance (ANCOVA) models when there was a significant main effect in the previous MANCOVA model. No significant different effectiveness was found between IRFs and SNFs in the 1 : 1 Matched Data, but IRFs took better care than SNFs in the <b>Caliper</b> <b>Matched</b> Data, rehabilitating the patients diagnosed with cardiac and pulmonary diseases on the functional independent measure (FIM). In comparison methodology, the results suggested that datasets created by both matching methods provided similar results, but that Fisher 2 ̆ 7 s design fits better for small dataset while RCM, for larger dataset by using propensity scores to balance the matching sets...|$|R
25|$|Porsche's Composite Ceramic Brakes (PCCB) are siliconized carbon fiber, {{with very}} high {{temperature}} capability, a 50% weight reduction over iron discs (therefore reducing the unsprung {{weight of the}} vehicle), {{a significant reduction in}} dust generation, substantially increased maintenance intervals, and enhanced durability in corrosive environments over conventional iron discs. Found on some of their more expensive models, it is also an optional brake for all street Porsches at added expense. It is generally recognized by the bright yellow paintwork on the aluminum six-piston <b>calipers</b> that are <b>matched</b> with the discs. The discs are internally vented much like cast-iron ones, and cross-drilled.|$|R
40|$|Using {{survey data}} on Macedonian firms {{that participated in}} USAID {{programs}} providing technical and financial assistance for {{small and medium-sized enterprises}} (SMEs) and on firms that did not, we estimate the effectiveness of such assistance in increasing the growth of employment in the assisted firms. We control for selection bias in program participation and use both kernel and <b>caliper</b> propensity score <b>matching</b> to estimate the excess growth of employment in assisted firms. We find that assistance programs raised employment growth by 16 - 20 percentage points in the first year after assistance and by 26 - 30 points by the third year. © 2011 Association for Comparative Economic Studies...|$|R
40|$|BACKGROUND: EMR is the {{standard}} of care for the resection of large polyps. OBJECTIVE: To compare the efficacy and safety profile of submucosal polidocanol injection with epinephrine-saline solution injection for colon polypectomy with a diathermic snare. DESIGN: After 1 -to- 1 propensity score <b>caliper</b> <b>matching,</b> comparison of submucosal epinephrine injection was performed with polidocanol injection. SETTING: Endoscopic suite at the University of Foggia between 2005 and 2014. PATIENTS: Of 711 patients who underwent endoscopic resection of colon sessile polyps 20 mm or larger, 612 were analyzed after matching. INTERVENTIONS: Submucosal epinephrine injection in 306 patients and polidocanol injection in 306 patients. MAIN OUTCOME MEASUREMENTS: Univariate and multivariate logistic regression models aimed at identifying independent predictors of postpolypectomy bleeding (PPB). RESULTS: The 2 groups presented similar baseline clinical parameters and lesion characteristics. All patients had a single polyp 20 mm or larger; the median size was 32 mm (interquartile range [IQR], 25 - 38) in the polidocanol group and 32 (IQR, 24 - 38) in the epinephrine group (P=. 7). Polidocanol was more effective in preventing both immediate and delayed PPB (P<. 001 and P=. 003, respectively), and its efficacy was confirmed in {{almost all of the}} subgroups, regardless of polyp size and histology. Postprocedure perforation was observed in 2 patients (0. 3...|$|E
30|$|The most {{critical}} objection in this evaluation might {{refer to the}} point that individuals with unpromising business projects may expect greater returns form using additional support programs and are therefore more likely to take advantage of these promotions. Because this might go unobserved, matching may fail to estimate unbiased treatment effects. However, various checks were conducted to assess the robustness of the estimates. First, we performed different matching procedures, including single nearest neighbors, <b>caliper</b> <b>matching,</b> and propensity kernel matching, to check methodical issues. On the whole, the results of the procedures supported the reported findings. We also tested the potential effect of unobserved heterogeneity by explicitly excluding information and calculating post-estimation Rosenbaum bounds. 34 In particular, neither of the sensitivity tests supported the hypothesis that unobserved heterogeneity had affected the reported estimates. In addition, we re-ran the estimates and included only regions with high ratios of external expertise support programs to consider potential interference from ‘negative creaming’ (assuming that negative selection would be relatively higher in regions with {{only a small number of}} participants). Finally, we replicated estimations while focusing on regions with low levels of comparable self-employment promotion activities that were covered by state-specific ESF-funding to test for the effects of potential substitutes and to address the potential conflict with the SUTVA (see above). 35 Overall, none of the robustness checks revealed substantial differences from the findings reported above.|$|E
40|$|R&D {{activities}} {{of small and}} young firms get increasing attention from both scholars and policy makers due to the expectations {{on the creation of}} valuable new knowledge. As a consequence, small young firms are considered as important actors in the flagship initiative ’Innovative Union ’ of the ’Europe 2020 ’ targets and an important number of R&D subsidies are targeted towards these firms. However, it remains unclear whether all small young firms make efficient of this support. While governments already actively target young, small independent firms and increasingly acknowledge the importance of sectoral differentiation, there is no decisive evaluation yet on the importance of letting these factors have an influence on subsidy receipt of small young firms. Therefore, we compare the effect of innovation subsidies on independent high-tech small young firms (NTBFs), independent low-tech small young firms (LTBFs) and their group counterparts. Based on <b>caliper</b> <b>matching,</b> this study reveals that full crowding-out with regard to public funding can be rejected for all firm types studied. In addition, this study assesses the difference in treatment effects of the different firm types in a regression framework. The results reveal that a focus on independent firms is only efficient if the target group is restricted to high-tech firms. The only firms that convincingly make more efficient use of subsidies than the other small young firms, both in terms of R&D expenditures and in terms of R&D employment, are NTBFs...|$|E
40|$|Propensity score-matching {{methods are}} often used to control for bias in {{observational}} studies when randomization is not possible. This paper describes how to match samples using both local and global optimal matching algorithms. The paper includes macros to perform the nearest available neighbor, <b>caliper,</b> and radius <b>matching</b> methods with or without replacement and matching treated observations to one or many controls. The similarity between observations is evaluated using both the absolute value and the Mahalanobis distance that includes the propensity score along with other covariates. This paper also explains {{how to find a}} global optimal match with a variable number of controls using network flows. SAS ® 9. 1, SAS/STAT®, and SAS/OR ® are required...|$|R
30|$|We further {{compared}} the outcomes in the elemental formula {{group and the}} control group using a propensity score matching analysis [22] as the secondary analysis. The propensity score for predicting administration of elemental formula was calculated through a logistic regression analysis using the variables used {{for the establishment of}} the aforementioned prognosis model and the annual number of acute pancreatitis cases per hospital as a variable to account for the differences in treatment quality at each hospital. Propensity score matching extracted 1 : 1 matched pairs from the elemental formula group and the control group. A match balance between the two groups was assessed using the absolute standardized mean difference (ASMD) of all variables; values[*]<[*] 0.1 were regarded as acceptable. To achieve balanced <b>matching,</b> the <b>caliper</b> width for <b>matching</b> was set as the standard deviation (SD) of the logit-transformed propensity score multiplied by 0.3. Intergroup comparison of the outcomes with propensity score-matched subjects was performed using a Chi-square test.|$|R
40|$|Propensity score methods (PSM) {{that have}} been widely used to reduce {{selection}} bias in observational studies are restricted to a binary treatment. Imai and van Dyk extended PSM to estimate non-binary treatment effect using stratification with P-Function, and generalized inverse treatment probability weighting (GIPTW). However, propensity score (PS) matching methods on multiple treatments received little attention, and existing generalized PSMs merely focused on estimates of main treatment effects but omitted potential interaction effects that are of essential interest in many studies. In this dissertation, I extend Rubin’s PS matching theory to general treatment regimens under the P-Function framework. From theory to practice, I propose an innovative distance measure that can summarize similarities among subjects in multiple treatment groups. Based on this distance measure I propose four generalized propensity score matching methodologies. The first two methods are extensions of nearest neighbor matching. I implemented Monte Carlo simulation studies to compare them with GIPTW and stratification on P-Function methods. The next two methods are extensions of the nearest neighbor <b>caliper</b> width <b>matching</b> and variable matching. I define the caliper width as the product of a weighted standard deviation of all possible pairwise distances between two treatment groups. I conduct a series of simulation studies to determine an optimal caliper width by searching the lowest mean square error of average causal interaction effect. I further compare the ones with optimal caliper width with other methods using simulations. Finally, I apply these methods to the National Medical Expenditure Survey data to examine the average causal main effect of duration and frequency of smoking as well as their interaction effect on annual medical expenditures. Using proposed methods, researchers can apply regression models with specified interaction terms to the matched data and simultaneously obtain both main and interaction effects estimate with improved statistical properties...|$|R
40|$|AbstractObjectivesTo {{evaluate}} {{whether there are}} differences in propensity score (PS) and treatment effects estimated using conventional and calendar time-specific PS (CTS-PS) approaches. MethodsA retrospective database analysis at a university-affiliated hospital in Thailand was used. Diabetic patients receiving glucose-lowering medications from July 2008 to June 2011 were included. Patients were categorized into those exposed and not exposed to thiazolidinediones (TZDs). PSs were estimated by using conventional PS and CTS-PS. In the CTS-PS, PS was separately estimated for three specific calendar time periods. Patients were matched 1 : 1 using <b>caliper</b> <b>matching.</b> The outcomes were cardiovascular and all-cause hospitalizations. The TZD and non-TZD groups were compared with Cox proportional hazard models. ResultsA total of 2165 patients were included. The average conventional PS was 0. 198 (95 % confidence interval [CI] 0. 195 – 0. 202), while the average PS in the CTS-PS approach was 0. 212 (0. 206 – 0. 218), 0. 180 (0. 173 – 0. 188), and 0. 205 (0. 197 – 0. 213) for July 2008 to June 2009, July 2009 to June 2010, and July 2010 to June 2011, respectively. The average difference in PS was 0. 012 (P < 0. 001), − 0. 009 (P ≤ 0. 002), and 0. 000 (P = 0. 950) in the three calendar time periods. The adjusted hazard ratios of the conventional PS-matched cohort were 0. 97 (95 % CI 0. 39 – 2. 45) and 0. 97 (95 % CI 0. 78 – 1. 20) for CVD-related and all-cause hospitalizations, while the adjusted hazard ratios of the CTS-PS–matched cohort were 1. 11 (95 % CI 0. 43 – 2. 88) and 1. 12 (95 % CI 0. 91 – 1. 39), respectively. ConclusionCTS-PS is different from PS estimated by using the conventional approach. CTS-PS should be considered when a pattern of medication use has changed over the study period...|$|E
30|$|There are two {{different}} sets of strategies to adjust for the propensity score. The first approach is propensity score matching. The simplest form of matching is 1 : 1 nearest neighbor matching, which means to select for each treated unit the control unit with the most similar propensity score. There are several versions of matching including with or without replacement, increasing numbers of controls per treated unit (k: 1 matching), and the restriction that only pairs of treated and untreated units are formed if their propensity scores differ at most by a pre-specified amount (<b>caliper</b> <b>matching).</b> Nearest neighbor matching estimates the (sample or population) ATT because it matches control units to the treated units and discards controls which are not selected as matches. One drawback of matching {{is that it does}} not use all available data because control units are disregarded if other controls better match with the propensity scores of the treated units. The second set of strategies uses all data: Stratification (or subclassification) creates groups of individuals with a similar propensity score. For this purpose, the propensity score distribution is divided into, say, five subclasses. Within each subclass outcome differences between treated and control units are then compared separately. To estimate the (sample or population) ATT, we weigh each subclass by the number of treated units in this subclass before pooling them; weighting by the overall number of units in each subclass estimates the (sample or population) ATEs. Another strategy to adjust for the propensity score is weighting. Weighting uses the propensity score to compute weights for each individual. These weights can be computed in different ways to estimate the SATE or the SATT, and they can then be used like sampling weights. They can also be multiplied with the actual sampling weights to estimate PATE or PATT. Austin (2011) and Stuart (2010) elaborate on the different approaches of propensity score techniques and discuss trade-offs.|$|E
40|$|Doctor of PhilosophyDepartment of StatisticsMichael J. HigginsThis {{dissertation}} {{presents an}} approach to assess and validate causal inference tools to es- timate the causal effect of a treatment. Finding treatment effects in observational studies {{is complicated by the}} need to control for confounders. Common approaches for controlling include using prognostically important covariates to form groups of similar units containing both treatment and control units or modeling responses through interpolation. This disser- tation proposes a series of new, computationally efficient methods to improve the analysis of observational studies. Treatment effects are only reliably estimated for a subpopulation under which a common support assumption holds—one in which treatment and control covariate spaces overlap. Given a distance metric measuring dissimilarity between units, a graph theory is used to find common support. An adjacency graph is constructed where edges are drawn between similar treated and control units to determine regions of common support by finding the largest connected components (LCC) of this graph. The results show that LCC improves on existing methods by efficiently constructing regions that preserve clustering in the data while ensuring interpretability of the region through the distance metric. This approach is extended to propose a new matching method called largest <b>caliper</b> <b>matching</b> (LCM). LCM is a version of cardinality matching—a type of matching used to maximize the number of units in an observational study under a covariate balance constraint between treatment groups. While traditional cardinality matching is an NP-hard, LCM can be completed in polynomial time. The performance of LCM with other five popular matching methods are shown through a series of Monte Carlo simulations. The performance of the simulations is measured by the bias, empirical standard deviation and the mean square error of the estimates under different treatment prevalence and different distributions of covariates. The formed matched samples improve estimation of the population treatment effect {{in a wide range of}} settings, and suggest cases in which certain matching algorithms perform better than others. Finally, this dissertation presents an application of LCC and matching methods on a study of the effectiveness of right heart catheterization (RHC) and find that clinical outcomes are significantly worse for patients that undergo RHC...|$|E
40|$|Cataloged from PDF {{version of}} article. Bah, El-hadj, Brada, Josef C., and Yigit, Taner—With {{a little help}} from our friends: The effect of USAID {{assistance}} on SME growth in a transition economy Using survey data on Macedonian firms that participated in USAID programs providing technical and financial assistance for small and medium-sized enterprises (SMEs) and on firms that did not, we estimate the effectiveness of such assistance in increasing the growth of employment in the assisted firms. We control for selection bias in program participation and use both kernel and <b>caliper</b> propensity score <b>matching</b> to estimate the excess growth of employment in assisted firms. We find that assistance programs raised employment growth by 16 – 20 percentage points in the first year after assistance and by 26 – 30 points by the third year. Journal of Comparative Economics xxx (xx) (2011) xxx–xxx. The University of Auckland, Private Bag 92019, Auckland 1142, New Zealand; Arizona State University, PO Box 879801, Tempe, AZ 85287 - 9801, USA; Macedonian Academy of Sciences and Arts, Bul. Krste Misirkov, 2, 1000 Skopje, Republic of Macedonia; FEASS, Bilkent University, Ankara 06800, Turkey. 2011 Association for Comparative Economic Studies Published by Elsevier Inc. All rights reserved...|$|R
40|$|Background: Half {{of heart}} failure {{patients}} will die within five years of diagnosis, making them an ideal population for hospice to reach. Yet hospice originated in oncology, and problems have been noted with the enrollment {{of heart failure}} patients. Whether caregiver satisfaction, a key quality measure in hospice, differs between heart failure and cancer caregivers is unknown. Objective: We aimed to determine whether diagnosis makes a difference in satisfaction with hospice care in matched cohorts of heart failure caregivers and cancer caregivers. Methods: This was a national cohort study, using caregiver responses to the Family Evaluation of Hospice Care (FEHC) survey. Heart failure and cancer caregivers were matched via propensity scoring. The relationship between diagnosis and caregiver satisfaction was examined across the domains of symptom management, emotional support, caregiver teaching, coordination of care, and global satisfaction, {{both before and after}} matching via logistic regression. Results: One-to-one <b>matching</b> with <b>calipers</b> yielded 7730 <b>matched</b> pairs out of an original sample of 8175 heart failure caregivers and 24, 972 cancer caregivers. Significant differences were found in caregiver teaching, emotional support, coordination of care, and global satisfaction prior to matching, but the effect sizes were small. All differences disappeared after matching. High rates of dissatisfaction with caregiver teaching (42 %) and emotional support (30 %) were found in both cohorts. Conclusions: The diagnosis of heart failure, in and of itself, does not appear {{to make a difference in}} informal caregiver satisfaction with hospice care. Hospice provides high-quality care for patients, but improvements are needed in caring for the caregiver...|$|R
40|$|AbstractObjectiveA {{large number}} of {{possible}} techniques are available when conducting matching procedures, yet coherent guidelines for selecting the most appropriate application do not yet exist. In this article we evaluate several matching techniques and provide a suggested guideline for selecting the best technique. MethodsThe main purpose of a matching procedure is to reduce selection bias by increasing the balance between the treatment and control groups. The following approach, consisting of five quantifiable steps, is proposed to check for balance: 1) Using two sample t-statistics to compare {{the means of the}} treatment and control groups for each explanatory variable; 2) Comparing the mean difference {{as a percentage of the}} average standard deviations; 3) Comparing percent reduction of bias in the means of the explanatory variables before and after matching; 4) Comparing treatment and control density estimates for the explanatory variables; and 5) Comparing the density estimates of the propensity scores of the control units with those of the treated units. We investigated seven different matching techniques and how they performed with regard to proposed five steps. Moreover, we estimate the average treatment effect with multivariate analysis and compared the results with the estimates of propensity score matching techniques. The Medstat MarketScan Data Base provided data for use in empirical examples of the utility of several matching methods. We conducted nearest neighborhood matching (NNM) analyses in seven ways: replacement, 2 to 1 matching, Mahalanobis matching (MM), MM with <b>caliper,</b> kernel <b>matching,</b> radius matching, and the stratification method. ResultsComparing techniques according to the above criteria revealed that the choice of matching has significant effects on outcomes. Patients with asthma are compared with patients without asthma and cost of illness ranged from $ 2040 to $ 4463 depending on the type of matching. After matching, we looked at the insignificant differences or larger P-values in the mean values (criterion 1); low mean differences as a percentage of the average standard deviation (criterion 2); 100 % reduction bias in the means of explanatory variables (criterion 3); and insignificant differences when comparing the density estimates of the treatment and control groups (criterion 4 and criterion 5). Mahalanobis matching with caliber yielded the better results according all five criteria (Mean = $ 4463, SD = $ 3252). We also applied multivariate analysis over the matched sample. This decreased the deviation in cost of illness estimates more than threefold (Mean = $ 4456, SD = $ 996). ConclusionSensitivity analysis of the matching techniques is especially important because none of the proposed methods in the literature is a priori superior to the others. The suggested joint consideration of propensity score matching and multivariate analysis offers an approach to assessing the robustness of the estimates...|$|R

