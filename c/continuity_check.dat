12|10|Public
5000|$|<b>Continuity</b> <b>Check</b> Protocol (CCP): [...] "Heartbeating" [...] {{messages}} for CFM. The <b>Continuity</b> <b>Check</b> Message (CCM) {{provides a means}} to detect connectivity failures in an MA. CCMs are multicast messages. CCMs are confined to a domain (MD). These messages are unidirectional and do not solicit a response. Each MEP transmits a periodic multicast <b>Continuity</b> <b>Check</b> Message inward towards the other MEPs.|$|E
50|$|Fast link failure {{detection}} may {{be performed}} using IEEE 802.1ag <b>Continuity</b> <b>Check</b> Messages (CCMs) which test link status and report {{a failure to}} the IS-IS protocol. This allows much faster failure detection than is possible using the IS-IS hello message loss mechanisms.|$|E
50|$|Path {{protection}} {{is provided by}} configuring one work and one protect B-VID for each backbone service instance. In case of work path failure (as indicated by loss of 802.1ag <b>continuity</b> <b>check</b> messages, CCMs) the source bridge swaps the B-VID value to redirect the traffic onto the preconfigured protection path within 50 ms.|$|E
5000|$|Connectivity fault {{management}} (IEEE 802.1ag) - Defines standardized <b>continuity</b> <b>checks,</b> loopbacks and link trace for {{fault management}} capabilities in enterprise and carrier networks. This standard also partitions the network into 8 hierarchical administrative domains.|$|R
5000|$|Fault {{management}} and performance monitoring (ITU-T Y.1731) - Defines performance monitoring measurements such as frame loss ratio, frame delay and frame delay variation {{to assist with}} SLA assurance and capacity planning. For fault management the standard defines <b>continuity</b> <b>checks,</b> loopbacks, link trace and alarm suppression (AIS, RDI) for effective fault detection, verification, isolation and notification in carrier networks.|$|R
40|$|The third {{generation}} NetPRL CiNIC co-processor cards were fabricated and partially assembled during Summer 2005. Unfortunately the prototype network processing hardware was incomplete, untested, {{and could not}} yet be used by NetPRL project teams as a firmware and software development platform. This project endeavored to prepare the latest CiNIC for use in advancing iNIC related research at Cal Poly. The project began with the assembly and modifications necessary to complete the co-processor card. During assembly several manufacturability design issues were corrected or workarounds developed. Preliminary hardware verification testing was also conducted from <b>continuity</b> <b>checks,</b> power and smoke test, and hardware programming demonstration. The latest CiNIC prototype design is partially functional but many features are not yet proven and require additional testing...|$|R
50|$|A {{background}} timer {{is maintained}} for each link. When {{a certain amount}} of time is passed without regular incoming traffic, a message is sent over the link to indicate to the counterpart that the link is still up. This message also contains an acknowledge for the last received Link Level Sequence Number, in order to allow the receiver to release sent packet buffers, and a Last Sent Sequence Number, allowing the receiver to detect gaps in the packet sequence. The <b>continuity</b> <b>check</b> mechanism allows rapid detection of communication media failure, or node crashes. The Link Tolerance is a configurable parameter for each link endpoint, determining how long the other link endpoint may remain unresponsive before the link is declared faulty, and reset. For Ethernet the default value of this parameter is 1.5 s. After a reset, the remaining link endpoint will continue to probe the link until it is re-established.|$|E
40|$|<b>Continuity</b> <b>Check</b> {{monitors}} a Label Switched Path for any loss {{of continuity}} defect. Connectivity Verification augments <b>Continuity</b> <b>Check</b> {{in order to}} provide confirmation that the desired source is connected to the desired sink. Remote Defect Indication enables an end point to report, to its associated end point, a fault or defect condition that it detects on a pseudowire, Label Switched Path, or Section. This document specifies specific extensions to Bidirectional Forwarding Detection (BFD) and methods for proactive <b>Continuity</b> <b>Check,</b> Continuity Verification, and Remote Defect Indication for MPLS-TP pseudowires, Label Switched Paths, and Sections using BFD as extended by this memo. Status of This Memo This is an Internet Standards Track document. This document {{is a product of the}} Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|E
3000|$|... as Laplacian matrix), the {{continuity}} of the network is not ensured. For the <b>continuity</b> <b>check,</b> it has been exploited another important property of the Laplacian matrix, namely the multiplicity m [...]...|$|E
30|$|It is {{sufficient}} to verify the conditions of Theorem 2.4. According to Theorem 2.6, the norm-to-weak <b>continuity</b> is easily <b>checked.</b>|$|R
40|$|The {{utilization}} of Kevlar cord and thermal knives in a deployable release system produces {{a number of}} issues that must be addressed {{in the design of the}} system. This paper proposes design considerations that minimize the major issues, thermal knife failure, Kevlar cord relaxation, and the measurement of the cord tension. Design practices can minimize the potential for thermal knife laminate and element damage that result in failure of the knife. A process for in-situ inspection of the knife with resistance, rather than <b>continuity,</b> <b>checks</b> and 10 x zoom optical imaging can detect damaged knives. Tests allow the characterization of the behavior of the particular Kevlar cord in use and the development of specific prestretching techniques and initial tension values needed to meet requirements. A new method can accurately measure the tension of the Kevlar cord using a guitar tuner, because more conventional methods do not apply to arimid cords such as Kevlar...|$|R
40|$|Morphological skeletonization is {{an image}} {{processing}} technique that reduces complex, thick-lined images {{to a series of}} single pixel lines that accurately represent the original shapes. This procedure is especially useful to simplify automated applications requiring simple shape analysis and <b>continuity</b> <b>checking</b> by reducing the amount of redundant image data. In the semiconductor inspection field, skeletonization is a process {{that can be used to}} detect defects during plasma display panel (PDP) inspection. This paper will introduce a novel morphological skeletonization algorithm developed for electrode pattern inspection of PDPs. This algorithm has been successfully integrated within a commercial machine vision system. to provide a new technique that properly reduces circles to dots and more accurately maintains the shapes of objects during the skeletonization process. The new algorithm is designed to overcome the problems with the traditional method. This paper first explains the concept of skeletonization. It describes the design criteria for a new skeletonization algorithm, its development, and the outline of some application-specific modifications which can be made to deal with various input and output requirements. Also, the feature point classification and its direction code based matching method for defect inspection are introduced and demonstrated with PDP images...|$|R
40|$|With {{its three}} beams in {{different}} directions, the Transportable Atmospheric RAdar system (TARA) {{can provide a}} wind field estimation. These estimations are inaccurate when the Doppler velocities {{in one or more}} of the three beams are aliased. Amongst different approaches to solve aliasing are a <b>continuity</b> <b>check</b> up to four dimensions, staggering PRT (Pulse Repetition Time) technique and a method using polarimetric information. The staggering PRT technique is not applicable, because it requires altering the radar system itself. For the main beam of TARA the method using polarimetric information is used, but for the offset beams nopolarimetric information is available. The research presented in this thesis focuses on the dealiasing of the offset beams using a <b>continuity</b> <b>check</b> in one dimension. The assumed correctly dealiased main beam is used as a reference to compare the offset beams with. The first step towards correct Doppler velocities is unfolding every individual Doppler spectrum. Then, a reference spectrum is searched for in the main beam. The first spectrum in the offset beam that is placed in the right Doppler velocity interval, is the one that is at the same height as the reference spectrum. From there on a <b>continuity</b> <b>check</b> is performed. First away from the radar and then towards the radar. Comparison is done by using the mean Doppler velocities of every Doppler spectrum. The algorithm proposed in this thesis shows significant improvement in performance, compared with the old algorithm. In case of very wide Doppler spectra, a large difference between the reference and the current spectrum and clutter, the algorithm can fail. Geoscience & Remote SensingTelecommunicationsElectrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|This {{document}} specifies how signaling {{and selection}} processes for Pseudowire (PW) Virtual Circuit Connectivity Verification (VCCV) are modified to ensure backward compatibility and allow use of proactive Connectivity Verification (CV), <b>Continuity</b> <b>Check</b> (CC), and Remote Defect Indication (RDI) over MPLS Transport Profile (MPLS-TP) PWs. This document introduces four new CV types and, to accommodate them, a new VCCV Extended CV parameter for PW Interface Parameters Sub-TLV is defined...|$|E
40|$|The Doppler {{velocity}} dealiasing technique {{based on}} alias-robust VAD and variational (AR-Var) analyses {{developed at the}} National Severe Storms Laboratory for radar data quality control and assimilation is further improved in its two-step procedures: the reference check in the first step and the <b>continuity</b> <b>check</b> in the second step. In the first step, the alias-robust variational analysis is modified adaptively and used {{in place of the}} alias-robust velocity-azimuth display (VAD) analysis for all scan modes (rather than solely the WSR- 88 D volume coverage pattern 31 with the Nyquist velocity vN reduced below 12 [*]m[*]s− 1 and the TDWR Mod 80 with vN reduced below 15 [*]m[*]s− 1), so more raw data can pass the stringent threshold conditions used by the reference check in the first step. This improves the dealiased data coverage without false dealiasing to better satisfy the high data quality standard required by radar data assimilation. In the second step, new procedures are designed and added to the <b>continuity</b> <b>check</b> to increase the dealiased data coverage over storm-scale areas threatened by intense mesocyclones and their generated tornados. The performances of the improved dealiasing technique versus the existing techniques are exemplified by the results obtained for tornadic storms scanned by the operational KTLX radar in Oklahoma...|$|E
40|$|Abstract — In this study, a deep {{analysis}} of the reliability of lead-free (SnAgCu) solders in comparison with tin-lead solders have been done for a particular aerospace application. Creep properties of this solder composition have been investigated, and results have been validated with a thermal shock test. An 0805 resistor has been considered to simulate creep deformation, an electronic board {{has been used for}} a thermal shock test to <b>check</b> <b>continuity</b> of the circuit for the specified mission, and finally a detailed metallographic study has been performed. Main constitutive relations have been implemented in a commercial finite-element analysis software (ABAQUS 6. 5), to predict creep strain accumulation under thermal loads. Effects of implementing different constitutive relations in compare with life prediction models have been investigated. Overall, both solders are highly reliable with this number of thermal cycles; however, SnAgCu shows higher life time under this type of loading. Index Terms — lead-free solder, finite-element analysis, creep deformations, reliability analysis. I...|$|R
5000|$|There was a {{revolving}} door of staff members, with only editor-in-chief Tony Caputo and editor Katherine Llewellyn {{sticking with the}} book for its entire run from 1988-90. Llewellyn was credited and worked in numerous capacities, editing stories, coloring frames, <b>checking</b> <b>continuity</b> and writing scripts. Lenin Delsol penciled the adaptations of both films {{as well as some}} of the early issues, but presumably he got tied up with other works as three issues were credited as [...] "guest-penciled by Doug Murphy." [...] Neil Vokes agreed to come to work for NOW Comics with the proviso he be allowed to work on Fright Night, which he's cited as a favorite film, but he became disenchanted with the work environment and eventually quit. [...] Future regular Guardians of the Galaxy penciler Kevin West got his start picking up where Vokes left off and continued to work on Fright Night until the end - though issue #18 was inexplicably penciled by James Lyle. The writing was slightly more consistent. The adaptations of the films followed the source material fairly closely, and then James Van Hise took over writing duties for the first batch of original stories. Tony Caputo took the reins for issues #8-12, injecting a slightly more comedic tone, and then Mark Wheatley penned a single issue which was a complete and total departure from the ongoing plot. Beginning with issue #14, Katherine Llewellyn was credited as both writer and editor, and she closely followed the storyline that Caputo had established before handing off the writing to Diane M. Piron-Gelman (aka novelist D.M. Pirrone).|$|R
40|$|Cables {{are very}} {{important}} electrical devices that carry power and signals across multiple instruments. Any fault in a cable can easily result in a catastrophic outcome. Therefore, verifying that all cables are built to spec {{is a very important}} part of Electrical Integration Procedures. Currently, there are two methods used in lab for verifying cable connectivity. (1) Using a Break-Out Box and an ohmmeter this method is time-consuming but effective for custom cables and (2) Commercial Automated Cable Tester Boxes this method is fast, but to test custom cables often requires pre-programmed configuration files, and cables used on spacecraft are often uniquely designed for specific purposes. The idea is to develop a semi-automatic continuity tester that reduces human effort in cable testing, speeds up the electrical integration process, and ensures system safety. The JPL-Cable Tester Box is developed to check every single possible electrical connection in a cable in parallel. This system indicates connectivity through LED (light emitting diode) circuits. Users can choose to test any pin/shell (test node) with a single push of a button, and any other nodes that are shorted to the test node, even if they are in the same connector, will light up with the test node. The JPL-Cable Tester Boxes offers the following advantages: 1. Easy to use: The architecture is simple enough that it only takes 5 minutes for anyone to learn how operate the Cable Tester Box. No pre-programming and calibration are required, since this box only <b>checks</b> <b>continuity.</b> 2. Fast: The cable tester box checks all the possible electrical connections in parallel at a push of a button. If a cable normally takes half an hour to test, using the Cable Tester Box will improve the speed to as little as 60 seconds to complete. 3. Versatile: Multiple cable tester boxes can be used together. As long as all the boxes share the same electrical potential, any number of connectors can be tested together...|$|R
40|$|A {{series of}} {{detailed}} non-intrusive laser velocimeter flow field surveys {{were performed to}} validate computational fluid dynamic (CFD) codes for rotating pump components. Three component laser- 2 -focus (L 2 F) laser velocimetry was used to acquire data within a flow passage of a diffuser at design flow conditions. The thirteen vane-island type diffuser was designed to allow diffusion in the axial direction. Multiple laser velocimeter surveys were performed throughout several diffuser passages and at multiple diffuser depths (hub to shroud). The axial (3 D) component of the velocity at all locations was small. The radial and meridional velocity components nearest the diffuser hub increased in magnitude relative to the flow nearest the shroud as the flow progressed through the diffuser. A <b>continuity</b> <b>check</b> across the diffuser throat {{and based on the}} meridional velocity component yielded a match with a facility flow meter of 98. 0 %...|$|E
40|$|A {{recently}} {{proposed and}} successfully validated post-processing algorithm is extended to treat particle {{data obtained by}} a phase Doppler anemometer (PDA) in dense, fluctuating, low-speed, two-phase flow. In such a flow, Doppler signals may be noisy and split, since particles have long residence times in the measurement volume. A novel time average {{based on the measured}} burst lengths is proposed to estimate the cross-sectional area of the measurement volume. This time average accounts for the possible split of a noisy Doppler burst, and it provides a more general description of the measurement volume than the conventional ensemble average. The extended post-processing algorithm was tested on experimental time series obtained in a circulating fluidized bed and the algorithm was compared to conventional treatment of the particle data by a commercial PDA processor. The conventional processing strongly overestimates the vertical mass flux integrated over the cross-section. In contrast, time-mean and fluctuations of mass flux, particle volume concentration, and particle velocity are reliably estimated employing the proposed algorithm, with <b>continuity</b> <b>check</b> parameters in succeeding particle data, as well as with a particle velocity filter to estimate the size of the probe volume, applying a two-component PDA in a three-dimensional flow...|$|E
40|$|This {{research}} {{investigated the}} effects of data presentation formats on technician performance when maintenance procedures are presented on a monocular, head-mounted display (HMD). The maintenance task was a <b>continuity</b> <b>check</b> performed by identifying, selecting, and testing pairs of cannon plug connector pins. Two formats were used to present ask procedure information to the subject: a format hat mimicked the standard technical procedure manual, including the textual and graphical characteristics; a format which provided the same information as the first, while adding visual cues to the graphical portion of the technical information. Two types of cannon plugs were used: ‘few-pin ’ plugs (12 and 13 pins) and ‘many-pm ’ plugs (55 and 79 pins). United States Air Force (USAF) avionics maintenance t chnicians tationed atBarksdale Air Force Base, Louisiana served as subjects. Dependent measures were: task completion time, task error rate, and subjective reports on the usability of the information presentation structure and the HMD. Results indicate that in general, technicians perform tasks more quickly and commit fewer errors when using enhanced graphical data presentation methods. Technicians indicated via post test questionnaire that such data formats, and HMDs in general, could be a useful tool {{in the performance of}} their maintenance duties...|$|E
40|$|In {{this paper}} {{the results of}} an {{investigation}} are presented that are concerned with the feasibility of employing a weather radar to make precise measurements of the properties of a precipitating cloud. A schematic cloud is proposed as a model for interpreting the interaction of the radar energy with the cloud. Point values of the liquid-water concentration are estimated from measurements of the received power. The measurements were made under conditions which minimized errors arising from attenuation of the radar signal and a radar beam which is not completely filled with raindrops. A continuity equation for liquid-water concentration is developed. The vertical speeds at the core of convective clouds are related to the spatial and temporal variations of the liquid-water content by means of this equation. The version of the continuity equation developed in this study represents an improvement over forms used previously. The new version accounts for the downward development of a radar echo at speeds faster than the fall speed of raindrops. This echo development is caused by the coalescence mechanism. An error analysis is performed and it indicates that the percentage error of the measurements of the liquid-water concentration may be as much as 102. 4 %. The fractional error of the vertical speeds is + 1391. 4 % which results from the compounding of the experimental errors of the terms in the <b>continuity</b> equations. To <b>check</b> the estimated magnitudes of the experimental errors a case study was performed. The echoes of 23 convective clouds were studied and 695 observations of liquid-water concentration were obtained. The observed magnitudes indicate that these estimates are of the correct order. The values of vertical speeds also indicate that the estimated error of this quantityis indeed large. Possible methods for reducing the experimental errors are considered. This examination indicates that reasonably accurate measurements of liquid-water concentration can be made if high experimental standards are maintained. The use of calibrating instruments which are very accurate together with good experimental control may permit a reduction of the percentage error to less than 2 O%. However, this study indicates that attempts to measure vertical speeds accurately by use of the continuity equation may not be too successful...|$|R

