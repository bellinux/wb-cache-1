52|10000|Public
50|$|DirectBand, {{owned by}} Microsoft, uses the 67.65 kHz {{subcarrier}} leased from FM radio stations. This subcarrier delivers about 12 kbit/s (net after error <b>correction)</b> <b>of</b> <b>data</b> per station, for over 100 MB per day per city. Data includes traffic, sports, weather, stocks, news, movie times, calendar appointments, and local time.|$|E
5000|$|Brazil: The 1988 Brazilian Constitution {{stipulates}} that: “Habeas Data {{shall be}} granted: a) {{to ensure the}} knowledge of information related to {{the person of the}} petitioner, contained in records or databanks of government agencies or of agencies of a public character; b) for the <b>correction</b> <b>of</b> <b>data,</b> when the petitioner does not prefer to do so through a confidential process, either judicial or administrative”.|$|E
40|$|A simple {{isothermal}} calorimeter ideal {{to study}} hydration of cementitious systems is described {{together with an}} ampoule design to allow addition of water and mixing with the ampoule inside the calorimeter. An overview of dynamic corrections is given, and the utilisation of the different dynamic corrections on the calorimeter output is discussed. <b>Correction</b> <b>of</b> <b>data</b> on b-hemihydrate hydration to form gypsum has shown good kinetic agreement with data from synchrotron X-ray diffraction...|$|E
40|$|The aim of {{this work}} is the {{simulation}} of a moving cell on a noisy backgroud. Experience gained during this work was used for <b>correction</b> <b>of</b> artificially created <b>data.</b> Subsequently it {{was used for the}} <b>correction</b> <b>of</b> real experiment a data. Spyder, open source cross-platform IDE for scientific programming in the Python language, was used for it. The simulation was successful, as well as the <b>correction</b> <b>of</b> artificially created <b>data.</b> The <b>correction</b> <b>of</b> real experiment <b>data</b> was only partly suscessfull. It gives us enough room for further improvement...|$|R
50|$|This code is for {{a program}} in perl that allows for the {{determination}} of multiple moveout velocities for the <b>correction</b> <b>of</b> seismic <b>data.</b>|$|R
30|$|The {{collected}} {{temperature and}} distance data must be processed by the thermodetector {{to obtain the}} final furnace tube surface temperature. Data processing includes initialization, filtering, and filtering <b>correction</b> <b>of</b> the <b>data,</b> and finally, the temperature can be calculated.|$|R
40|$|This {{describes}} a remotely trackable drifter system enabling {{up to ten}} units to be monitored from a shore or vessel station. Detailed descriptions. Individual drifters are equipped with a Global Positioning System sensor, radio modems and they transmit their position to the station. Each component has been tested and proved under field conditions. If differential correction is not undertaken, accuracy of about 100 m can be expected. If differential <b>correction</b> <b>of</b> <b>data</b> is completed, accuracy of better than 10 m can be expected...|$|E
40|$|A user {{interface}} {{for the management}} of water quality data based on the database management system MS-ACCESS by Microsoft has been developed. It also incorporates a series of tools for data analysis and graphical interfaces for data import, export and visualization. For further work proposals for <b>correction</b> <b>of</b> <b>data</b> model, the integration of a multi-user environment and a client/server model are givenSIGLEAvailable from TIB Hannover: RN 8908 (93 - 067) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Umwelt, Naturschutz und Reaktorsicherheit, Bonn (Germany) DEGerman...|$|E
40|$|Technical {{information}} {{focused upon}} emerging wall interference assessment/correction (WIAC) techniques applicable to transonic wind tunnels with conventional and passively or partially adapted walls is given. The possibility {{of improving the}} assessment and <b>correction</b> <b>of</b> <b>data</b> taken in conventional transonic wind tunnels by utilizing simultaneously obtained flow field data (generally taken near the walls) appears to offer a larger, nearer-term payoff than the fully adaptive wall concept. Development of WIAC procedures continues, and aspects related to validating the concept need to be addressed. Thus, the scope of wall interference topics discussed was somewhat limited...|$|E
50|$|Some {{variants}} of schematics support only 2 drives. Phase <b>correction</b> <b>of</b> the drive <b>data</b> signal {{is made in}} different ways.|$|R
40|$|Abstract—We {{discuss the}} DISORT-based {{radiative}} transfer pipeline (“CRISM_LambertAlb”) for atmospheric and ther-mal <b>correction</b> <b>of</b> MRO/CRISM <b>data</b> acquired in multispectral Manuscript received October 4, 2007; revised March 25, 2008. Current ver-sion published November 26, 2008. This work {{was supported by}} the Nationa...|$|R
40|$|We {{previously}} {{developed an}} algorithm named Tafkaa for atmospheric <b>correction</b> <b>of</b> remote sensing ocean color data from aircraft and satellite platforms. The algorithm allows quick atmospheric <b>correction</b> <b>of</b> hyperspectral <b>data</b> using lookup tables generated with {{a modified version}} of Ahmad & Fraser s vector radiative transfer code. During the past few years we have extended the capabilities of the code. Current modifications include the ability to account for within scene variation in solar geometry (important for very long scenes) and view geometries (important for wide fields of view). Additionally, versions of Tafkaa have been made for a variety of multi-spectral sensors, including SeaWiFS and MODIS. In this proceeding we present some initial results <b>of</b> atmospheric <b>correction</b> <b>of</b> AVIRIS <b>data</b> from the 2001 July Hyperspectral Coastal Ocean Dynamics Experiment (HyCODE) at LEO- 15...|$|R
40|$|Prototypes of MICROMEGAS chambers, using bulk {{technology}} and analog readout, with 1 x 1 cm 2 readout segmentation {{have been built}} and tested. Measurements in Ar/iC 4 H 10 (95 / 5) and Ar/CO 2 (80 / 20) are reported. The dependency of the prototypes gas gain versus pressure, gas temperature and amplification gap thickness variations has been measured with an 55 Fe source and a method for temperature and pressure <b>correction</b> <b>of</b> <b>data</b> is presented. A stack of four chambers has been tested in 200 GeV/c and 7 GeV/c muon and pion beams respectively. Measurements of response uniformity, detection efficiency and hit multiplicity are reported. A bulk MICROMEGAS prototype with embedded digital readout electronics has been assembled and tested. The chamber layout and first results are presented. Prototypes of MICROMEGAS chambers, using bulk {{technology and}} analog readout, with 1 x 1 cm 2 readout segmentation have been built and tested. Measurements in Ar/iC 4 H 10 (95 / 5) and Ar/CO 2 (80 / 20) are reported. The dependency of the prototypes gas gain versus pressure, gas temperature and amplification gap thickness variations has been measured with an 55 Fe source and a method for temperature and pressure <b>correction</b> <b>of</b> <b>data</b> is presented. A stack of four chambers has been tested in 200 GeV/c and 7 GeV/c muon and pion beams respectively. Measurements of response uniformity, detection efficiency and hit multiplicity are reported. A bulk MICROMEGAS prototype with embedded digital readout electronics has been assembled and tested. The chamber layout and first results are presented...|$|E
30|$|Despite the {{relatively}} high frequency of tail vein extravasation, the low activity remaining in the tail vein following extravasation (never higher than 20  % of the injected dose) led to a negligible magnitude of error and did {{not interfere with the}} cancer therapy assessment in rats bearing subcutaneous tumors undergoing targeted therapy. Assessment of therapeutic response using data uncorrected for tail vein extravasation provided similar results to those following correction. Nevertheless, there was no inter-observer variability when quantifying tail vein activity suggesting that the <b>correction</b> <b>of</b> <b>data</b> for tail vein extravasation can be reproducibly performed and may be important when assessing therapies inducing more subtle SUV changes between groups or when important extravasations occur.|$|E
40|$|The {{paper is}} {{dedicated}} to the efficiency improving of double error <b>correction</b> <b>of</b> <b>data</b> transmission in channels with spectral modulation by simplifying and accelerating the computations associated with error correction. The paper presents a theoretically grounded and investigated approach of double errors correction in channel with spectral modulation based on positional correcting sums that allows to determine the positions of distorted symbols and their distortion vectors without enumeration through all the symbols of block. The method mathematical basis and procedure of errors detecting and correcting are presented in detail. The use of the procedure error correction is illustrated via the thorough presentation of an example of erroneous data transmission. The theoretical and experimental estimations of effectiveness of proposed method are given...|$|E
50|$|The DHS Traveler Redress Inquiry Program (TRIP) is a {{procedure}} for travelers who are delayed or denied boarding of an aircraft, consistently receive excess scrutiny at security checkpoints, or are denied {{entry to the}} U.S. because they {{are believed to be}} or are told that they are on a government watch list. The traveler must complete an online application at the Department of Homeland Security website, print and sign the application, and then submit it with copies of several identifying documents. After reviewing their records, DHS notifies the traveler that if any <b>corrections</b> <b>of</b> <b>data</b> about them were warranted, they will be made.|$|R
30|$|AC 1 —Each PET image {{corrected}} by its corresponding CT-derived attenuation map. Each CT-derived attenuation map was registered to the MR-derived attenuation map using a rigid registration through Niftyreg software [12] and subsequently uploaded to the PET-MR scanner for attenuation <b>correction</b> <b>of</b> PET <b>data.</b>|$|R
30|$|The results {{indicate}} that the proposed method is suitable for use in respiratory motion <b>correction</b> <b>of</b> PET <b>data.</b> In future work we will evaluate our approach on more datasets. Additionally, we will use motion estimates for each acquired 2 D image stack to correct motion frame-wise.|$|R
40|$|A {{commercial}} pressure logger {{has been}} adapted for long-term field use. Its flash memory affords the large data volume to allow months of pressure measurements {{to be acquired}} at the rapid cadence (> 1 Hz) required to detect dust devils, small dust-laden convective vortices observed in arid regions. The power consumption of the unit is studied and battery and solar/battery options evaluated for long-term observations. A two-month long field test is described, and several example dust devil encounters are examined. In addition, a periodic (~ 20 min) convective signature is observed, and some lessons in operations and <b>correction</b> <b>of</b> <b>data</b> for temperature drift are reported. The unit shows promise for obtaining good statistics on dust devil pressure drops, to permit comparison with Mars lander measurements, and for array measurements...|$|E
40|$|In {{the present}} {{scenario}} of information explosion nobody can demur that data is unquestionably the most indispensable {{thing in the}} modern world. Without this data, the whole technological development would come to a standstill. Data {{can be defined as}} string of meaningful and valuable information. This data should be assembled and stored properly in a media {{so that it can be}} accessed anytime, anywhere. The media first opted was paper. But paper has an unfortunate propensity to damage and updation and <b>correction</b> <b>of</b> <b>data</b> was too onerous. This exhorted the need for an alternative. Computer in this case has been a real bliss. Data is now stored digitally in an enormous amount at a less expense, efficiently and impeccably. The extraordinary ultra high density storage technologies that are emerging today have excessive and indubitable contribution to the future of distributed information networks...|$|E
40|$|The article {{reviews the}} {{existing}} methods of multicolor FISH on nuclear targets, first of all, interphase chromosomes. FISH proper and image acquisition are considered as two related {{components of a}} single process. We discuss (1) M-FISH (combinatorial labeling + deconvolution + widefield microscopy); (2) multicolor labeling + SIM (structured illumination microscopy); (3) the standard approach to multicolor FISH + CLSM (confocal laser scanning microscopy; one fluorochrome - one color channel); (4) combinatorial labeling + CLSM; (5) non-combinatorial labeling + CLSM + linear unmixing. Two related issues, deconvolution of images acquired with CLSM and <b>correction</b> <b>of</b> <b>data</b> for chromatic Z-shift, are also discussed. All methods are illustrated with practical examples. Finally, several rules of thumb helping to choose an optimal labeling + microscopy combination for the planned experiment are suggested. Copyright (c) 2006 S. Karger AG, Basel. ...|$|E
40|$|Report {{contains}} {{requirements for}} <b>correction</b> <b>of</b> instrumented <b>data</b> on the chemical composition of a specimen, obtained by electron microprobe analysis. A condensed review of electron microprobe techniques is presented, including background material for obtaining X ray intensity data corrections and absorption, atomic number, and fluorescence corrections...|$|R
40|$|<b>Correction</b> <b>of</b> crude {{thin layer}} chromatographic data usually enables a {{reliable}} comparison with reference data bases. However, when the correction standards are not spotted {{in the right}} positions, the calculation may produce false results if anomalous migration occurs. This was observed {{in the case of}} acidic and neutral drugs developed in the chloroform-methanol (9 : 1) system. In t roduct ion <b>Correction</b> <b>of</b> retention <b>data</b> in thin layer chromatography (TLC) is a basic requirement in systematic toxicological analysis. Existing methods <b>of</b> <b>correction</b> (1 - 5) enable an efficient use <b>of</b> reference <b>data</b> bases <b>of</b> compilations published by other toxicol-ogists. When the <b>correction</b> <b>of</b> raw retention <b>data</b> is made with standard substances, one condition must be fulfilled: the stand-ards must show comparable r tention behavior in relation to th...|$|R
40|$|The regularization of ill-posed {{systems of}} {{equations}} {{is carried out}} by <b>corrections</b> <b>of</b> the <b>data</b> or the operator. It is shown how the efficiency of regularizations can be calculated by statistical decision principles. The efficiency of nonlinear regularizations depends {{on the distribution of}} the admitted disturbances <b>of</b> the <b>data.</b> For the class of linear regularizations optimal corrections are given...|$|R
40|$|We present {{measurements}} of ab-plane resistivity ρ_ab(T) and superfluid density [∝λ^- 2, λ = magnetic penetration depth] in La_ 2 -xSr_xCuO_ 4 films. As Sr concentration x exceeds about 0. 22, the superconducting transition sharpens dramatically, becoming as narrow as 200 mK near the super-to-normal metal quantum critical point. At the same time, ρ_ab(T), λ^- 2 (T), and transition temperature T_c decrease, and upward curvature develops in λ^- 2 (T). Given the sharp transitions, we interpret these {{results in the}} context of a homogeneous d-wave superconducting state, with elastic scattering that is enhanced relative to underdoped LSCO due to weaker electron correlations. This interpretation conflicts with the viewpoint that the overdoped state is inhomogeneous due to phase separation into superconducting and normal metal regions. Comment: 21 pages including 3 figures and 56 references. This version includes responses to referees and slight <b>correction</b> <b>of</b> <b>data</b> on two films. Conclusions the same as befor...|$|E
40|$|It is {{possible}} to measure horizontal and vertical crustal motions with GPS. Regarding the horizontal movements, basis will be Sumatra where the continental movements will be analyzed before, {{during and after the}} earthquakes in 2004 / 2005. Concerning Helheim, the vertical displacements in form of uplift due to the melting of the ice sheet will be considered and the reason valued. To support the understanding of <b>correction</b> <b>of</b> <b>data</b> and GPS’ mode of operation an experiment has been carried out using a GPS receiver above a known point in Buddinge. For all points of interest, data from surrounding GPS sites will be analyzed to account for the actual deformations of the crust. Considering Sumatra there was no statistical proof of an upcoming earthquake, for which reason the analysis has led to no ambiguous conclusion. With GPS, it {{is possible}} to measure the uplift of Helheim and the cause may be found in either post glacial rebound or a direct melting of the ice...|$|E
40|$|In {{order to}} analyze the {{structural}} organization of complex axonal arbors reconstructed from histological serial sections, and to. investigate the functional implications of their geometrical properties, we developed software providing the following facilities: 1 direct importation of data files generated by a commercially available 3 -D light-microscopic reconstruction system, including routine procedures.. for identification and <b>correction</b> <b>of</b> <b>data</b> acquisition errors; 2 real-time 3 -D rotations of the arbors in the stack of serial sections; 3.. multiple interactive display modes; 4 possibility of modifying diameter andror connectivity of different branches; 5 simulation of {{the invasion of the}} arbor by a single action potential initiated at any chosen point, and visualization of spatio-temporal profiles of activation;. 6 extraction of quantitative data converted to standard file formats compatible with available mathematical software. All these tools can be applied to single or multiple axons, individually or simultaneously. The software, called Maxsim, is a highly flexible C-written program running on graphical workstations using the UNIX operating system and X-Window environment...|$|E
40|$|This paper {{presents}} the results of a study carried out for the ENVISAT Expert Support Laboratories group. The objectives of this study were the identification and investigation of relevant problems in the processing and radiometric <b>correction</b> <b>of</b> ScanSAR <b>data.</b> L-band <b>Data</b> <b>of</b> the SIR-C sensor in the ScanSAR mode of operations were used for the investigation...|$|R
40|$|LiDAR (Light Detection And Ranging) {{systems are}} capable of {{providing}} 3 D positional and spectral information (in the utilized spectrum range) of the mapped surface. Due to systematic errors in the system parameters and measurements, LiDAR systems require geometric calibration and radiometric <b>correction</b> <b>of</b> the intensity <b>data</b> {{in order to maximize}} the benefit from the collected positional and spectral information. This paper presents a practical approach for the geometric calibration of LiDAR systems and radiometric <b>correction</b> <b>of</b> collected intensity <b>data</b> while investigating their impact {{on the quality of the}} derived products. The proposed approach includes the use of a quasi-rigorous geometric calibration and the radar equation for the radiometric <b>correction</b> <b>of</b> intensity <b>data.</b> The proposed quasi-rigorous calibration procedure requires time-tagged point cloud and trajectory position data, which are available to most <b>of</b> the <b>data</b> users. The paper presents a methodology for evaluating the impact of the geometric calibration on the relative and absolute accuracy of the LiDAR point cloud. Furthermore, the impact of the geometric calibration and radiometric correction on land cover classification accuracy is investigated. The feasibility of the proposed methods and their impact on the derived products are demonstrated through experimental results using real data...|$|R
40|$|International audienceA {{comprehensive}} study {{of the limitations of}} vf-TLP setup for transient measurements is exposed. A new method, based on a numerical <b>correction</b> <b>of</b> measured <b>data</b> using a commercial Oryx vf-TLP system is presented. It allows the measurement of ESD pulses up to 1000 V with a time resolution down to 60 ps...|$|R
40|$|This {{paper is}} based on the notion of data quality. It {{includes}} correctness, completeness and minimality for which a notational framework is shown. In long living databases the maintenance of data quality is a first order issue. This paper shows that even well designed and implemented information systems cannot guarantee correct data in any circumstances. It is shown that in any such system data quality tends to decrease and therefore some data correction procedure should be applied from time to time. One aspect of increasing data quality is the <b>correction</b> <b>of</b> <b>data</b> values. Characteristics of a software tool which supports this data value correction process are presented and discussed. 1 Introduction For any information system (IS), data correctness is an important issue [5],[6],[19]. Data correctness is context dependent. The degree to which it is enforced depends on the purposes of the application(s) processing the data as well as on economical aspects [20]. Sometimes it is ch [...] ...|$|E
40|$|The {{program was}} {{designed}} to account the registry of patients with Gaucher disease. During the investigation of object domain a medical documentation and work regime of centre were analyzed including medical forms and questionnaires, medical cards, the order of filling appointment of treatment, report forms. The program provides the creation of automatized work place for interaction with patients with Gaucher disease on a personal computer of doctor. The purpose of development system is to perform a range of functions, which correspond to the full cycle of interaction doctor with patients. General function: introduction and <b>correction</b> <b>of</b> <b>data,</b> analysis and preservation {{of the history of}} this treatment, filtration patient records, construction of schedules {{based on the results of}} blood tests and examinations which reflect the dynamics of the patient. Special functions: calculation of required quantity of the medicine to the patient, tracing of human health standards depending on the age of the patient, the cost of the medicine...|$|E
40|$|Abstract-Data {{quality is}} major concern area in an Data Warehouse environment. ETL tools focus on {{detection}} and <b>correction</b> <b>of</b> <b>data</b> quality problems {{that affect the}} success of a data warehouse. Data imported from source into the data warehouse often has different quality, format, coding etc. In order to bring all the data together in a standard, homogeneous environment, Extraction–transformation– loading (ETL) tools are used. Proprietary tools used for data cleaning have a very limited functionality. Small and Medium Scale Enterprises(SME) and Small Scale Enterprises (SSE) cannot afford the licensing cost of these paid tools. The solution to data quality problems is provided by open source data quality tool- MaSSEETL is to deal with naming conflicts, structural conflicts, date conversions, missing values and changing dimensions. This tool solves the integrity issues faced by various available GPL tools. MaSSEETL solves the appropriate errors with appropriate level of warning. In this paper, we are presenting the implementation of MaSSEETL. The tool provides an increased ease of use in a data warehouse environment. General Terms-Data warehousing, data cleansing, quality data, dirty data, surrogate key...|$|E
40|$|The multi-filter rotated shadowband {{radiometer}} (MFRSR) provides spectral direct, diffuse, {{and total}} horizontal solar irradiance measurements. Because the MFRSR’s receiver has a non-Lambertian response, for a correct interpretation of measured radiation an angular correction is needed. Such a <b>correction</b> <b>of</b> MFRSR <b>data</b> is performed for direct solar radiation, whereas uncertainty exists concernin...|$|R
40|$|This {{paper is}} {{concerned}} with the problem of automatic detection and <b>correction</b> <b>of</b> inconsistent or out <b>of</b> range <b>data</b> in a general process <b>of</b> statistical <b>data</b> collecting. This problem is formulated as an Integer Linear Programming problem having a Set Covering predominance. This approach overcomes the computational limits of Fellegi-Holt methodology, while maintaining its positive statistical features. The procedure was implemented into a software system called DIESIS, that has been successfully used for the <b>correction</b> <b>of</b> demographical <b>data</b> <b>of</b> the 2001 Italian Population Census...|$|R
40|$|Precise <b>corrections</b> <b>of</b> Landsat <b>data</b> {{are useful}} for {{generating}} land-use maps, detecting various crops and determining their acreage, and detecting changes. The paper discusses computer processing and visualization techniques for Landsat data so that users can get more information from the imagery. The elementary unit <b>of</b> <b>data</b> in each band of each scene is the integrated value of intensity of reflected light detected {{in the field of}} view by each sensor. To develop the basic mathematical approach for precision <b>correction</b> <b>of</b> the <b>data,</b> differences between positions of ground control points on the reference map and the observed control points in the scene are used to evaluate the coefficients of cubic time functions of roll, pitch, and yaw, and a linear time function of altitude deviation from normal height above local earth's surface. The resultant equation, termed a mapping function, corrects the warped data image into one that approximates the reference map. Applications are discussed relative to shade prints, extraction of road features, and atlas of cities...|$|R
