192|250|Public
50|$|Given {{a sample}} , {{one can find}} the {{appropriated}} <b>context</b> <b>tree</b> using the following algorithms.|$|E
5000|$|The {{estimator}} of the <b>context</b> <b>tree</b> by BIC with {{a penalty}} constant [...] {{is defined as}} ...|$|E
50|$|Using a <b>context</b> <b>tree</b> it's {{possible}} {{to represent the}} past states of the sequence, showing which are relevant to identify the next state.|$|E
40|$|We {{establish}} sufficient {{conditions for}} perfect simulation of chains of infinite order on a countable alphabet. The new assumption, localized continuity, is formalized {{with the help}} of the notion of <b>context</b> <b>trees,</b> and includes the traditional continuous case, probabilistic <b>context</b> <b>trees</b> and discontinuous kernels. Since our assumptions are more refined than uniform continuity, our algorithms perfectly simulate continuous chains faster than the existing algorithms of the literature. We provide several illustrative examples. Comment: 38 pages, 1 figure, simplified proofs, improved results. We also removed the results concerning null chain...|$|R
40|$|In this work, we use <b>context</b> <b>trees</b> for privacypreserving {{modeling}} of genetic sequences. The resulting estimated models are applied for functional comparison of genetic sequences in a privacy preserving way. Here we define privacy as {{uncertainty about the}} genetic source sequence given its model and use equivocation to quantify it. We evaluate the performance of our approach on publicly available human genomic data. The simulation results confirm that the <b>context</b> <b>trees</b> can be effectively used to detect similar genetic sequences while guaranteeing high privacy levels. However, a trade-off between privacy and utility {{has to be taken}} into account in practical applications...|$|R
40|$|Indexing data {{structures}} are well-known to be {{crucial for the}} efficiency of the current state-of-the-art theorem provers. Examples are discrimination trees, which are like tries where terms are seen as strings and common prefixes are shared, and substitution trees, where terms keep their tree structure and all common contexts can be shared. Here we describe a new indexing data structure, <b>context</b> <b>trees,</b> where, by means of a limited kind of context variables, also common subterms can be shared, even if they occur below different function symbols. Apart from introducing the concept, we also provide evidence for its practical value. We describe an implementation of <b>context</b> <b>trees</b> based on Curry terms and on an extension of substitution trees with equality constraints and where one does not distinguish between internal and external variables. Experiments with matching show that our preliminary implementation is already competitive with tightly coded current state-of-the-art implementations of the other main techniques. In particular space consumption of <b>context</b> <b>trees</b> is substantially less than for other index structures...|$|R
5000|$|... where [...] is any {{positive}} constant. At last, by Rissanen, there's {{the following}} result. Given [...] of a finite probabilistic <b>context</b> <b>tree</b> , then ...|$|E
5000|$|The {{stochastic}} chain [...] is, then, a chain with {{memory of}} variable length, taking values in [...] and {{compatible with the}} probabilistic <b>context</b> <b>tree</b> , where ...|$|E
5000|$|A {{stochastic}} chain with {{memory of}} variable length is a stochastic chain , taking values in a finite alphabet , and {{characterized by a}} probabilistic <b>context</b> <b>tree</b> , so that ...|$|E
40|$|Abstract. The goal of {{this paper}} is to study the {{similarity}} between sequences using a distance between the <b>context</b> <b>trees</b> associated to the sequences. These trees are defined in the framework of Sparse Probabilistic Suffix Trees (SPST), and can be estimated using the SPST algorithm. We implement the Phyl-SPST package to compute the distance between the sparse <b>context</b> <b>trees</b> estimated with the SPST algorithm. The distance takes into account the structure of the trees, and indirectly the transition probabilities. We apply this approach to reconstruct a phylogenetic tree of protein sequences in the globin family of vertebrates. We compare this tree with the one obtained using the well-known PAM distance. 1...|$|R
50|$|This {{realization}} {{sequence is}} often called the context; therefore the VOM models are also called <b>context</b> <b>trees.</b> The flexibility {{in the number of}} conditioning random variables turns out to be of real advantage for many applications, such as statistical analysis, classification and prediction.|$|R
40|$|We {{address the}} problem of {{estimating}} pose in a static image of a human performing an action that may involve interaction with scene objects. In such scenarios, pose can be estimated more accurately using the knowledge of scene objects. Previous approaches do not make use of such contextual information. We propose Pose <b>Context</b> <b>trees</b> to jointly model human pose and object which allows both accurate and efficient inference when the nature of interaction is known. To estimate the pose in an image, we present a Bayesian framework that infers the optimal pose-object pair by maximizing the likelihood over multiple pose <b>context</b> <b>trees</b> for all interactions. We evaluate our approach on a dataset of 65 images, and show that the joint inference of pose and context gives higher pose accuracy. 1...|$|R
5000|$|In {{the article}} A Universal Data Compression System, Rissanen {{introduced}} a consistent algorithm {{to estimate the}} probabilistic <b>context</b> <b>tree</b> that generates the data. This algorithm’s function can be summarized in two steps: ...|$|E
5000|$|Note that [...] is {{the ratio}} of the log-likelihood to test the {{consistency}} of the sample with the probabilistic <b>context</b> <b>tree</b> [...] against the alternative that is consistent with , where [...] and [...] differ only by a set of sibling knots.|$|E
5000|$|The <b>context</b> <b>tree</b> {{weighting}} method (CTW) is a {{lossless compression}} and prediction algorithm by [...] The CTW algorithm {{is among the}} very few such algorithms that offer both theoretical guarantees and good practical performance (see, e.g. [...] ).The CTW algorithm is an “ensemble method,” mixing the predictions of many underlying variable order Markov models, where each such model is constructed using zero-order conditional probability estimators.|$|E
40|$|Abstract. Following {{a recent}} surge in using history-based methods for resolving perceptual {{aliasing}} in reinforcement learning, we introduce an algorithm {{based on the}} feature reinforcement learning framework called ΦMDP [12]. To create a practical algorithm we devise a stochastic search procedure for a class of <b>context</b> <b>trees</b> based on parallel tempering and a specialized proposal distribution. We provide the first empirical evaluation for ΦMDP. Our proposed algorithm achieves superior performance to the classical U-tree algorithm [18] and the recent active-LZ algorithm [6], and is competitive with MC-AIXI-CTW [26] that maintains a bayesian mixture over all <b>context</b> <b>trees</b> up to a chosen depth. We are encouraged by our ability to compete with this sophisticated method using an algorithm that simply picks one single model, and uses Q-learning on the corresponding MDP. Our ΦMDP algorithm is much simpler, yet consumes less time and memory. These results show promise for our future work on attacking more complex and larger problems. ...|$|R
40|$|Following {{a recent}} surge in using history-based methods for resolving perceptual {{aliasing}} in reinforcement learning, we introduce an algorithm {{based on the}} feature reinforcement learning framework called PhiMDP. To create a practical algorithm we devise a stochastic search procedure for a class of <b>context</b> <b>trees</b> based on parallel tempering and a specialized proposal distribution. We provide the first empirical evaluation for PhiMDP. Our proposed algorithm achieves superior performance to the classical U-tree algorithm and the recent active-LZ algorithm, and is competitive with MC-AIXI-CTW that maintains a bayesian mixture over all <b>context</b> <b>trees</b> up to a chosen depth. We are encouraged by our ability to compete with this sophisticated method using an algorithm that simply picks one single model, and uses Q-learning on the corresponding MDP. Our PhiMDP algorithm is much simpler, yet consumes less time and memory. These results show promise for our future work on attacking more complex and larger problems...|$|R
40|$|Dialog topic {{tracking}} aims at analyzing {{and maintaining}} topic transitions in on-going dialogs. This paper proposes a com-posite kernel approach for dialog topic tracking to utilize {{various types of}} do-main knowledge obtained fromWikipedia. Two kernels are defined based on history sequences and <b>context</b> <b>trees</b> constructed based on the extracted features. The ex-perimental results show that our compos-ite kernel approach can significantly im-prove the performances of topic tracking in mixed-initiative human-human dialogs. ...|$|R
50|$|Call graphs can {{be defined}} to {{represent}} varying degrees of precision. A more precise call graph more precisely approximates {{the behavior of the}} real program, at the cost of taking longer to compute and more memory to store. The most precise call graph is fully context-sensitive, which means that for each procedure, the graph contains a separate node for each call stack that procedure can be activated with. A fully context-sensitive call graph is called a calling <b>context</b> <b>tree.</b> This can be computed dynamically easily, although it may take up a large amount of memory. Calling context trees are usually not computed statically, because it would take too long for a large program. The least precise call graph is context-insensitive, which means {{that there is only one}} node for each procedure.|$|E
40|$|This paper {{describes}} the <b>Context</b> <b>Tree</b> Switching technique, {{a modification of}} <b>Context</b> <b>Tree</b> Weighting for the prediction of binary, stationary, n-Markov sources. By modifying <b>Context</b> <b>Tree</b> Weighting’s recursive weighting scheme, {{it is possible to}} mix over a strictly larger class of models without increasing the asymptotic time or space complexity of the original algorithm. We prove that this generalization preserves the desirable theoretical properties of <b>Context</b> <b>Tree</b> Weighting on stationary n-Markov sources, and show empirically that this new technique leads to consistent improvements over <b>Context</b> <b>Tree</b> Weighting as measured on the Calgary Corpus. ...|$|E
40|$|Bag {{context is}} a device for {{regulated}} rewriting in tree and string grammars. It represents context {{that is not}} part of the developing tree or string, but evolves on its own during a derivation. Motivation for investigating bag <b>context</b> <b>tree</b> languages is provided by showing that the class of bag <b>context</b> <b>tree</b> languages is the closure of the class of random <b>context</b> <b>tree</b> languages under linear top-down tree transductions. Furthermore, we establish an interchange theorem for subtrees of dense trees generated by bag <b>context</b> <b>tree</b> grammars. This result implies that the class of bag <b>context</b> <b>tree</b> languages is incomparable with the class of branching synchronization tree languages...|$|E
50|$|In a <b>context</b> where <b>trees</b> are {{supposed}} to have a root, a tree without any designated root is called a free tree.|$|R
40|$|Abstract. The {{prototype}} of a content based search engine for mathematical knowledge supporting a small set of queries requiring matching and/or typing operations is described. The prototype — called Whelp — exploits a metadata approach for indexing {{the information that}} looks far more flexible than traditional indexing techniques for structured expressions like substitution, discrimination, or <b>context</b> <b>trees.</b> The prototype has been instantiated to the standard library of the Coq proof assistant extended with many user contributions. ...|$|R
40|$|A {{method has}} been {{developed}} for constructing a tree source model for genetic text generation. Model visualization {{in the form of}} suffix (<b>context)</b> <b>trees</b> provides a new way of context analysis of symbol sequences. Estimation of the stochastic complexity of the data in the frame of the model serves as a criterion for the model's ascertainment. The software realization of this algorithm enables to reveal statistical properties of genetic sequences based on information measures. The program developed is available via Internet at [URL]...|$|R
40|$|We {{address the}} issue of <b>context</b> <b>tree</b> {{estimation}} in variable length hidden Markov models. We propose an estimator of the <b>context</b> <b>tree</b> of the hidden Markov process which needs no prior upper bound on the depth of the <b>context</b> <b>tree.</b> We prove that the estimator is strongly consistent. This uses information-theoretic mixture inequalities in the spirit of [1], [2]. We propose an algorithm to efficiently compute the estimator and provide simulation studies to support our result. Index Terms Variable length, hidden Markov models, <b>context</b> <b>tree,</b> consistent estimator, mixture inequalities...|$|E
40|$|International audienceWe {{address the}} issue of <b>context</b> <b>tree</b> {{estimation}} in variable length hidden Markov models. We propose an estimator of the <b>context</b> <b>tree</b> of the hidden Markov process which needs no prior upper bound on the depth of the <b>context</b> <b>tree.</b> We prove that the estimator is strongly consistent. This uses information-theoretic mixture inequalities in the spirit of [1], [2]. We propose an algorithm to efficiently compute the estimator and provide simulation studies to support our result...|$|E
40|$|Abstract. The Burrows-Wheeler {{transform}} (BWT) andblock sorting compression {{are closely}} related to the context trees of PPM. The usual approach of treating BWT as merely a permutation is not able to fully exploit this relation. We show that an explicit <b>context</b> <b>tree</b> for BWT can be efficiently generating by taking a subset of the corresponding suffix tree, identify the central problems in exploiting its structure, and trace the influence of the <b>context</b> <b>tree</b> on the common move-to-front schemes. We experimentally obtain limits for compression using the constructed trees, and, as an attempt at utilizing the full <b>context</b> <b>tree,</b> present a compression scheme that represents the <b>context</b> <b>tree</b> explicitly as part of the compressed data. We argue that a conscious treatment of the <b>context</b> <b>tree</b> should be able to achieve the full compression performance of PPM while maintaining the computational efficiency of BWT. Thus,BWT with explicit context trees is a strong candidate for powerful general compression, especially for large data files. 1...|$|E
40|$|Bytecode {{instrumentation}} is {{a valuable}} technique for trans-parently enhancing virtual execution environments for pur-poses such as monitoring or profiling. Current approaches to bytecode instrumentation either exclude some methods from instrumentation, severely restrict the ways certain methods may be instrumented, or {{require the use of}} native code. In this paper we compare different approaches to bytecode in-strumentation in Java {{and come up with a}} novel instrumen-tation framework that goes beyond the aforementioned lim-itations. We evaluate our approach with an instrumentation for profiling which generates calling <b>context</b> <b>trees</b> of various platform-independent dynamic metrics...|$|R
40|$|Efficient {{automatic}} protein classification is {{of central}} importance in genomic annotation. As an independent way {{to check the}} reliabil-ity of the classification we propose a statistical approach to test if two sets of protein domain sequences coming from two families of the Pfam database are significantly different. We model protein sequences as realizations of Variable Length Markov Chains (vlmc) and we use the <b>context</b> <b>trees</b> as a signature of each protein family. Our approach {{is based on a}} Kolmogorov-Smirnov-type goodness-of-fit test proposed by Balding et al. (2008) (bffs–test). The test statistic is a supremum over the space of trees of a function of the two samples; its computa-tion grows in principle exponentially fast with the maximal number of nodes of the potential trees. We show how to transform this prob-lem into a max-flow over a related graph which can be solved using a Ford-Fulkerson algorithm in polynomial time on that number. We apply the test to 10 randomly chosen protein domain families from the seed of Pfam-A database (high quality, manually curated fami-lies). The test shows that the distributions of <b>context</b> <b>trees</b> coming from different families are significantly different. We emphasize that this is a novel mathematical approach to validate the automatic clus-tering of sequences in any context. We also study the performance of the test via simulations on Galton-Watson related processes. 1. Introduction. Th...|$|R
40|$|In {{the finite}} {{alphabet}} context we propose four alternatives to fixed-order Markov models to estimate a conditional distribution. They consist {{in working with}} a large class of variable-length Markov models represented by <b>context</b> <b>trees,</b> and building an estimator of the conditional distribution with a risk of the same order as {{the risk of the}} best estimator for every model simultaneously, in a conditional Kullback-Leibler sense. Such estimators can be used to model complex objects like texts written in natural language and define a notion of similarity between them. This idea is illustrated by experimental results of unsupervised text clustering...|$|R
40|$|One {{can adapt}} the <b>context</b> <b>tree</b> {{weighting}} method {{in such a}} way, that it will find the minimum description length model (MDL-model) that corresponds to the data. In this paper this new algorithm, the <b>context</b> <b>tree</b> maximizing algorithm, and a few modifications of the algorithm will be studied, in particular, its performance if we apply it for data compression. ...|$|E
40|$|We {{consider}} {{the problem of}} estimating the <b>context</b> <b>tree</b> of a stationary ergodic process with finite alphabet without imposing additional conditions on the process. As a starting point we introduce a Hamming metric {{in the space of}} irreducible context trees and we use the properties of the weak topology in the space of ergodic stationary processes to prove that if the Hamming metric is unbounded, there exist no consistent estimators for the <b>context</b> <b>tree.</b> Even in the bounded case we show that there exist no two-sided confidence bounds. However we prove that one-sided inference is possible in this general setting and we construct a consistent estimator that is a lower bound for the <b>context</b> <b>tree</b> of the process with an explicit formula for the coverage probability. We develop an efficient algorithm to compute the lower bound and we apply the method to test a linguistic hypothesis about the <b>context</b> <b>tree</b> of codified written texts in European Portuguese...|$|E
40|$|Abstract. In {{order to}} meet the users'demand of {{knowledge}} and use knowledge efficiently,this paper adopts modeling methods of multilayer and multidimensional <b>context</b> <b>tree</b> to complete the establishment of the knowledge <b>context</b> <b>tree,</b> build the algorithm of the context entity similarity and realize the knowledge push, improve the similarity of the user with the necessary knowledge, so that a kind of very valuable method for pushing knowledge has also been put forward...|$|E
40|$|A new {{algorithm}} {{for context}} modeling of binary sources with application to video compression is presented. Our proposed method {{is based on}} a tree rearrangement and tree selection process for an optimized modeling of binary <b>context</b> <b>trees.</b> We demonstrate its use for adaptive context-based coding of selected syntax elements in a video coder. For that purpose we apply our proposed technique to the H. 264 /AVC standard and evaluate its performance for different sources and different quantization parameters. Experimental results show that by using our proposed algorithm coding gains similar or superior to those obtained with the H. 264 /AVC CABAC algorithm can be achieved...|$|R
40|$|Abstract. This {{paper is}} {{composed}} of two main results concerning chains of infi-nite order which are not necessarily continuous. The first one is a decomposition of the transition probability kernel as a countable mixture of unbounded proba-bilistic <b>context</b> <b>trees.</b> This decomposition is used to design a simulation algorithm which works as a combination of the algorithms given by Comets et al. (2002) and Gallo (2009). The second main result gives sufficient conditions on the kernel for this algorithm to stop after an almost surely finite number of steps. Direct consequences of this last result are existence and uniqueness of the stationary chain compatible with the kernel. 1...|$|R
40|$|The {{proliferation}} of online news creates {{a need for}} altering interesting articles. Compared to other products, however, recommending news has specific challenges: news preferences are subject to trends, users {{do not want to}} see multiple articles with similar content, and frequently we have insufficient information to prolfie the reader. In this paper, we introduce a class of news recommendation systems based on <b>context</b> <b>trees.</b> They can provide highquality news recommendations to anonymous visitors based on present browsing behaviour. Using an unbiased testing methodology, we show that they make accurate and novel recommendations, and that they are sufficiently exible for the challenges of news recommendation...|$|R
