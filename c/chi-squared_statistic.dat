145|485|Public
5|$|Another {{brute force}} {{approach}} is to match up the frequency distribution of the letters. By graphing the frequencies of letters in the ciphertext, and by knowing the expected distribution of those letters in the original language of the plaintext, a human can easily spot {{the value of the}} shift by looking at the displacement of particular features of the graph. This is known as frequency analysis. For example, in the English language the plaintext frequencies of the letters E, T, (usually most frequent), and Q, Z (typically least frequent) are particularly distinctive. Computers can also do this by measuring how well the actual frequency distribution matches up with the expected distribution; for example, the <b>chi-squared</b> <b>statistic</b> can be used.|$|E
25|$|Other notable {{measures}} of distance include the Hellinger distance, histogram intersection, <b>Chi-squared</b> <b>statistic,</b> quadratic form distance, match distance, Kolmogorov–Smirnov distance, and earth mover's distance.|$|E
500|$|... 55 Cancri f {{is located}} about 0.781 AU {{away from the}} star and takes 260 days to {{complete}} a full orbit. A limitation of the radial velocity method used to detect 55 Cancri f is that only a minimum mass can be obtained, in this case around 0.144 times that of Jupiter, or half the mass of Saturn. [...] A Keplerian fit to the radial velocity data of 55 Cancri A indicates that the orbit is consistent with being circular, however changing the value in a range between 0 and 0.4 does not significantly alter the <b>chi-squared</b> <b>statistic</b> of the fit, thus a representative eccentricity of 0.2±0.2 was assumed. [...] In a Newtonian model which takes interactions between the planets into account, the eccentricity comes out as 0.0002, almost perfectly circular.|$|E
40|$|Based on {{the concept}} of a {{logarithmic}} mean in two arguments, Pearson's <b>Chi-square</b> <b>statistic</b> is reformulated. Generalizations of the logarithmic mean are discussed, which immediately lead to new families of goodness-of-fit statistics. Thus it is possible {{to bridge the gap between}} Pearson's <b>Chi-square</b> <b>statistic</b> and the log-likelihood ratio statistic in a new way. Goodness-of-fit test log-likelihood ratio <b>statistic</b> Pearson's <b>Chi-square</b> power-divergence <b>statistic</b> logarithmic mean extended mean value functions...|$|R
30|$|The {{significance}} of the <b>chi-square</b> <b>statistic</b> supports these results.|$|R
40|$|Binary {{outcomes}} {{that depend on}} an ordinal predictor in a non-monotonic way are common in medical data analysis. Such patterns can be addressed in terms of cutpoints: for example, one looks for two cutpoints that define an interval {{in the range of}} the ordinal predictor for which the probability of a positive outcome is particularly high (or low). A chi-square test may then be performed to compare the pro-portions of positive outcomes in and outside this interval. However, if the two cutpoints are chosen to maximize the <b>chi-square</b> <b>statistic,</b> referring the obtained <b>chi-square</b> <b>statistic</b> to the standard chi-square 1 distribution is an inappropriate approach. It is then necessary to correct the p-value for multiple comparisons by considering the dis-tribution of the maximally selected <b>chi-square</b> <b>statistic</b> instead of the nominal chi-square distribution. Here, we derive the exact distribu-tion of the <b>chi-square</b> <b>statistic</b> obtained by the optimal two cutpoints. We suggest a combinatorial computation method and illustrate our approach by a simulation study and an application to varicella data...|$|R
5000|$|... {{which is}} known to be {{asymptotically}} normal and the conditional <b>chi-squared</b> <b>statistic</b> (Poisson dispersion test) ...|$|E
50|$|Phi can be {{computed}} {{by finding}} the square {{root of the}} <b>chi-squared</b> <b>statistic</b> divided by the sample size.|$|E
50|$|When {{the data}} {{consists}} of binary observations, the score statistic {{is the same}} as the <b>chi-squared</b> <b>statistic</b> in the Pearson's chi-squared test.|$|E
5000|$|The minimum {{chi-square}} {{estimate of}} the population mean λ is the number that minimizes the <b>chi-square</b> <b>statistic</b> ...|$|R
50|$|The model fits {{well when}} the {{residuals}} (i.e., observed-expected) {{are close to}} 0, that is the closer the observed frequencies are to the expected frequencies the better the model fit. If the likelihood ratio <b>chi-square</b> <b>statistic</b> is non-significant, then the model fits well (i.e., calculated expected frequencies are close to observed frequencies). If the likelihood ratio <b>chi-square</b> <b>statistic</b> is significant, then the model does not fit well (i.e., calculated expected frequencies are not close to observed frequencies).|$|R
40|$|Maximally {{selected}} {{chi-square statistics}} and non-monotonic associations: an exact approach {{based on two}} cutpoints Anne-Laure Boulesteix ∗, 1, Carolin Strobl 2 Binary outcomes that depend on an ordinal predictor in a non-monotonic way are common in medical data analysis. Such patterns can be addressed in terms of cutpoints: for example, one looks for two cutpoints that define an interval {{in the range of}} the ordinal predictor for which the probability of a positive outcome is particularly high (or low). A chi-square test may then be performed to compare the proportions of positive outcomes in and outside this interval. However, if the two cutpoints are chosen to maximize the <b>chi-square</b> <b>statistic,</b> referring the obtained <b>chi-square</b> <b>statistic</b> to the standard chi-square distribution is an inappropriate approach. It is then necessary to correct the p-value for multiple comparisons by considering the distribution of the maximally selected <b>chi-square</b> <b>statistic</b> instead of the nomi-nal chi-square distribution. Here, we derive the exact distribution of the <b>chi-square</b> <b>statistic</b> obtained by the optimal two cutpoints. We suggest a combinatorial compu-tation method and illustrate our approach by a simulation study and an application to varicella data...|$|R
50|$|Other notable {{measures}} of distance include the Hellinger distance, histogram intersection, <b>Chi-squared</b> <b>statistic,</b> quadratic form distance, match distance, Kolmogorov-Smirnov distance, and earth mover's distance.|$|E
5000|$|Cramér's V is {{computed}} {{by taking}} the square root of the <b>chi-squared</b> <b>statistic</b> divided by the sample size and the minimum dimension minus 1: ...|$|E
50|$|As the <b>chi-squared</b> <b>statistic</b> of 13.4 exceeds this {{critical}} value, we reject {{the null hypothesis}} and conclude that the die is biased at 95% significance level.|$|E
3000|$|Table  2 shows fit {{statistics}} for the unitary model (Model 2) of the TOEFL iBT test. Although the <b>chi-square</b> <b>statistic</b> was statistically significant (χ [...]...|$|R
40|$|Swain corrects the {{chi-square}} overidentification test (i. e., likelihood ratio test of fit) for structural equation models whethr {{with or without}} latent variables. The <b>chi-square</b> <b>statistic</b> is asymptotically correct; however, it does not behave as expected in small samples and/or when the model is complex (cf. Herzog, Boomsma, & Reinecke, 2007). Thus, particularly in situations where the ratio of sample size (n) {{to the number of}} parameters estimated (p) is relatively small (i. e., the p to n ratio is large), {{the chi-square}} test will tend to overreject correctly specified models. To obtain a closer approximation to the distribution of the <b>chi-square</b> <b>statistic,</b> Swain (1975) developed a correction; this scaling factor, which converges to 1 asymptotically, is multiplied with the <b>chi-square</b> <b>statistic.</b> The correction better approximates the chi-square distribution resulting in more appropriate Type 1 reject error rates (see Herzog & Boomsma, 2009; Herzog, et al., 2007) ...|$|R
3000|$|Table  6 shows fit {{statistics}} for the two unitary models (Model 5) of both tests combined and compared. Although the <b>chi-square</b> <b>statistic</b> was statistically significant (χ [...]...|$|R
50|$|The table shows that, {{for many}} dose levels, {{there are only}} {{one or a few}} observations. The Pearson <b>chi-squared</b> <b>statistic</b> would not give {{reliable}} estimates in this situation.|$|E
50|$|Correspondence {{analysis}} (CA)was {{developed by}} Jean-Paul Benzécriand is conceptually similar to PCA, but scales the data (which should be non-negative) so that rows and columns are treated equivalently. It is traditionally applied to contingency tables.CA decomposes the <b>chi-squared</b> <b>statistic</b> associated to this table into orthogonal factors.Because CA is a descriptive technique, {{it can be}} applied to tables for which the <b>chi-squared</b> <b>statistic</b> is appropriate or not.Several variants of CA are available including detrended correspondence analysis and canonical correspondence analysis. One special extension is multiple correspondence analysis, which may be seen as the counterpart of principal component analysis for categorical data.|$|E
50|$|The Pearson <b>chi-squared</b> <b>statistic</b> {{is the sum}} of (observed - expected)^2/expected. For the {{caffeine}} data, the Pearson <b>chi-squared</b> <b>statistic</b> is 17.46. The number of degrees of freedom is the number of doses (11) minus the number of parameters from the logistic regression (2), giving 11 - 2 = 9 degrees of freedom. The probability that a chi-square statistic with df=9 will be 17.46 or greater is p = 0.042. This result indicates that, for {{the caffeine}} example, the observed and expected proportions of A grades differ significantly. The model does not accurately predict the probability of an A grade, given the caffeine dose. This result is consistent with the graphs above.|$|E
50|$|Backward {{elimination}} is used {{to determine}} which of the model components are necessary to retain in order to best account for the data. Log-linear analysis starts with the saturated model and the highest order interactions are removed until the model no longer accurately fits the data. Specifically, at each stage, after {{the removal of the}} highest ordered interaction, the likelihood ratio <b>chi-square</b> <b>statistic</b> is computed to measure how well the model is fitting the data. The highest ordered interactions are no longer removed when the likelihood ratio <b>chi-square</b> <b>statistic</b> becomes significant.|$|R
5000|$|... where [...] is the {{proportion}} of the sample in cell [...] This is the empirical value of T. With [...] the Pearson <b>chi-square</b> <b>statistic,</b> this formula can also be written as ...|$|R
5000|$|Under {{the null}} {{hypothesis}} of no linkage the expected proportions of (i, h &minus; i &minus; j, j) are (0.25, 0.5, 0.25). One can derive a simple <b>chi-square</b> <b>statistic</b> with 2 degrees of freedom: ...|$|R
50|$|In this {{caffeine}} example, {{there are}} 30 observations for each dose, which makes {{calculation of the}} Pearson <b>chi-squared</b> <b>statistic</b> feasible. Unfortunately, it is common {{that there are not}} enough observations for each possible combinations of values of the x variables, so the Pearson <b>chi-squared</b> <b>statistic</b> cannot be readily calculated. A solution to this problem is the Hosmer-Lemeshow statistic. The key concept of the Hosmer-Lemeshow statistic is that, instead of observations being grouped by the values of the x variable(s), the observations are grouped by expected probability. That is, observations with similar expected probability are put into the same group, usually to create approximately 10 groups.|$|E
50|$|In statistics, {{the reduced}} <b>chi-squared</b> <b>statistic</b> is used {{extensively}} in {{goodness of fit}} testing. It {{is also known as}} mean square weighted deviation (MSWD) in isotopic dating and variance of unit weight in the context of weighted least squares.|$|E
50|$|Similarly, Cramér's V is {{computed}} {{by taking}} the square root of the <b>chi-squared</b> <b>statistic</b> divided by the sample size {{and the length of}} the minimum dimension (k is the smaller of the number of rows r or columns c).|$|E
40|$|We {{address the}} problem of maximally {{selected}} chi-square statistics {{in the case of a}} binary Y variable and a nominal X variable with several categories. The distribution of the maximally selected <b>chi-square</b> <b>statistic</b> has already been derived when the best cutpoint is chosen from a continuous or an ordinal X, but not when the best split is chosen from a nominal X. In this paper, we derive the exact distribution of the maximally selected <b>chi-square</b> <b>statistic</b> in this case using a combinatorial approach. Applications of the derived distribution to variable selection and hypothesis testing are discussed based on simulations. As an illustration, our method is applied to a pregnancy and birth data set. ...|$|R
40|$|The {{association}} between a binary variable Y and a variable X with an at least ordinal measurement scale might be examined by selecting a cutpoint {{in the range}} of X and then performing an association test for the obtained 2 x 2 contingency table using the <b>chi-square</b> <b>statistic.</b> The distribution of the maximally selected <b>chi-square</b> <b>statistic</b> (i. e. the maximal <b>chi-square</b> <b>statistic</b> over all possible cutpoints) under the null-hypothesis of no {{association between}} X and Y is different from the known chi-square distribution. In the last decades, this topic has been extensively studied for continuous X variables, but not for non-continuous variables with an at least ordinal measurement scale (which include e. g. classical ordinal or discretized continuous variables). In this paper, we suggest an exact method to determine the distribution of maximally selected chi-square statistics in this context. This novel approach {{can be seen as a}} method to measure the association between a binary variable and variables with an at least ordinal scale of different types (ordinal, discretized continuous, etc). As an illustration, this method is applied to a new data set describing pregnancy and birth for 811 babies. ...|$|R
40|$|Labor {{intensive}} {{experiments are}} typically required {{to identify the}} causal disease variants {{from a list of}} disease associated variants in the genome. For designing such experiments, candidate variants are ranked by their strength of genetic association with the disease. However, the two commonly used measures of genetic association, the odds-ratio (OR) and p-value, may rank variants in different order. To integrate these two measures into a single analysis, here we transfer the volcano plot methodology from gene expression analysis to genetic association studies. In its original setting, volcano plots are scatter plots of fold-change and t-test statistic (or -log of the p-value), with the latter being more sensitive to sample size. In genetic association studies, the OR and Pearson's <b>chi-square</b> <b>statistic</b> (or equivalently its square root, chi; or the standardized log(OR)) can be analogously used in a volcano plot, allowing for their visual inspection. Moreover, the geometric interpretation of these plots leads to an intuitive method for filtering results by a combination of both OR and <b>chi-square</b> <b>statistic,</b> which we term "regularized-chi". This method selects associated markers by a smooth curve in the volcano plot instead of the right-angled lines which corresponds to independent cutoffs for OR and <b>chi-square</b> <b>statistic.</b> The regularized-chi incorporates relatively more signals from variants with lower minor-allele-frequencies than <b>chi-square</b> test <b>statistic.</b> As rare variants tend to have stronger functional effects, regularized-chi is better suited to the task of prioritization of candidate genes. Comment: 5 figure...|$|R
50|$|At 99% {{significance}} level, {{the critical}} value is 15.086. As the <b>chi-squared</b> <b>statistic</b> does not exceed it, {{we fail to}} reject the null hypothesis and thus conclude that there is insufficient {{evidence to show that}} the die is biased at 99% significance level.|$|E
50|$|Using the chi-squared {{distribution}} to interpret Pearson's <b>chi-squared</b> <b>statistic</b> requires one {{to assume that}} the discrete probability of observed binomial frequencies in the table can be approximated by the continuous {{chi-squared distribution}}. This assumption is not quite correct, and introduces some error.|$|E
5000|$|The <b>chi-squared</b> <b>statistic</b> {{can then}} be used to {{calculate}} a p-value by comparing {{the value of the}} statistic to a chi-squared distribution. The number of degrees of freedom is equal to the number of cells , minus the reduction in degrees of freedom, [...]|$|E
40|$|A {{new family}} of goodness-of-fit {{statistics}} for discrete multivariate data is being introduced, {{which has the}} characteristic of linking Pearson's <b>Chi-square</b> <b>statistic</b> with the log-likelihood ratio statistic, thus leading to new compromises between these two classical test statistics. Preliminary simulation studies indicate that this family has further attractive elements, which are not "close" to standard statistics and which prove to have substantially higher power in specific situations. The new test procedure seems especially helpful with a null-hypothesis, where some cells have low probabilities of entry and an alternative hypothesis, which is "one-sided" with respect to those low-entry-cells: either postulating uniformly even lower or postulating uniformly higher probabilities of entry. Pearson's <b>Chi-square</b> <b>statistic</b> Log-likelihood ratio statistic Cressie-Read statistic Discrete multivariate models...|$|R
40|$|This program calculates the <b>chi-square</b> <b>statistic</b> {{for testing}} the {{assumptions}} of equality and symmetry of covariance matrices in a repeated measures design. THE univariate analysis of a repeated measures design is considered appropriate when the assumptions regarding the covariance matrices {{as well as the}} usual assumptions underlying the analysis of variance are met. The purpose of this brief paper was to describe a program COVAR that calculates the <b>chi-square</b> <b>statistic</b> (Kendall and Stuart, 1966) and number of degrees of freedom for testing the hypothesis of equal covariance matrices and the hypothesis of symmetry of covariance matrices for repeated measures designs involving an unequal number of subjects. Initial input parameters for this interactive APL program include the number of levels associated with the among subject factor(s), th...|$|R
3000|$|All items have {{significant}} contributions to their respective dimensions (≥[*]. 30), and all four aspects also significantly loaded on the learning perspective. The model enjoyed a good fit, although the <b>chi-square</b> <b>statistic</b> was significant (χ 2 (31)[*]=[*] 55.20, p[*]=[*]. 004) indicated that the model did not enjoy a good fit. Since the <b>chi-square</b> <b>statistic</b> is sensitive to large sample sizes, its ratio over the degree of freedom should be consulted. The ratios of the chi-square over the degree of freedom, i.e., 55.20 / 31 [*]=[*] 1.78, was lower than 3. These results also supported the fit of the model. The RMSEA statistic and its 90 % confidence intervals (RMSEA[*]=[*]. 060, 90 % CI [. 033, [...]. 086]) were between [...]. 05 and [...]. 08. This range is considered as “reasonable fit” by Byrne (2016).|$|R
