34|423|Public
5000|$|H.J. Kim et al. , A fast {{programmable}} {{trigger for}} isolated <b>cluster</b> <b>counting</b> in the BELLE experiment, Nucl. Instr. & Meth. A, 457, pp. 634-639, 2001 ...|$|E
40|$|An update is {{presented}} on the luminosity determination method based on pixel <b>cluster</b> <b>counting</b> developed in 2011. The cluster selection cuts have been updated {{and a full}} recalibration was performed for the 2012 LHC operating conditions. Preliminary luminosity results are presented for the pre-ICHEP 2012 data-taking era...|$|E
40|$|The {{measurement}} of the LHC luminosity delivered to CMS in the 2012 proton-proton physics run is presented. Results are based on <b>cluster</b> <b>counting</b> from the silicon pixel detector. The luminosity calibration is updated using the Van der Meer scans performed in November 2012. The overall uncertainty on the integrated luminosity {{is estimated to be}} 2. 5 % (syst.) + 0. 5 % (stat.) ...|$|E
40|$|It has {{recently}} been proposed that the large-scale bias of dark matter halos depends sensitively on primordial non-Gaussianity of the local form. In this paper we {{point out that the}} strong scale dependence of the non-Gaussian halo bias imprints a distinct signature on the covariance of <b>cluster</b> <b>counts.</b> We find that using the full covariance of <b>cluster</b> <b>counts</b> results in improvements on constraints on the non-Gaussian parameter f_(NL) of 3 (1) orders of magnitude relative to <b>cluster</b> <b>counts</b> (counts+clustering variance) constraints alone. We forecast f_(NL) constraints for the upcoming Dark Energy Survey in the presence of uncertainties in the mass-observable relation, halo bias, and photometric redshifts. We find that the Dark Energy Survey can yield constraints on non-Gaussianity of σ(f_(NL)) ~ 1 – 5 even for relatively conservative assumptions regarding systematics. Excess of correlations of <b>cluster</b> <b>counts</b> on scales of hundreds of megaparsecs would represent a smoking-gun signature of primordial non-Gaussianity of the local type...|$|R
30|$|Merge {{the pair}} of clusters, having a maximum {{characteristic}} similarity (DC) by reducing the <b>cluster</b> <b>count.</b>|$|R
40|$|The {{purpose of}} this {{research}} is to know consumer perception about simcard prepaid GSM product attribute which cover SIMPATI, AS, XL BEBAS, MENTARI, and, IM 3. The variable that used is brand, product fitur, quality, tidiness, and lable that steming from theory of Fandy Tjiptono (1997; 103 - 107) and Kotler & Amstrong (354 - 369). In this research, the method of data analyse is cluster. The result of research is shown that simcard AS 2 <b>cluster.</b> <b>Cluster</b> 1 <b>counted</b> 22 people take a fancy to excellence of simcard product attribute., <b>cluster</b> 2 <b>counted</b> 8 people frown upon excellence of product attribute. Simcard of XL BEBAS 2 <b>cluster.</b> <b>Cluster</b> 1 <b>counted</b> 28 people take a fancy to excellent of product attribute, <b>cluster</b> 2 <b>counted</b> 2 people frown upon product attribute. Simcard SIMPATI 2 <b>cluster.</b> <b>Cluster</b> 1 <b>counted</b> 27 people take a fancy to excellence of simcard product attribute., <b>cluster</b> 2 <b>counted</b> 3 people frown upon excellence of product attribute. Simcard MENTARI 2 <b>cluster.</b> <b>Cluster</b> 1 <b>counted</b> 26 people take a fancy to excellence of simcard product attribute, <b>cluster</b> 2 <b>counted</b> 4 people frown upon excellence of product attribute. Simcard IM 3 2 <b>cluster.</b> <b>Cluster</b> 1 <b>counted</b> 22 people take a fancy to excellence of simcard product attribute, <b>cluster</b> 2 <b>counted</b> 8 people frown upon excellence of product attribute...|$|R
40|$|The {{measurement}} of the integrated luminosity delivered to the CMS Experiment during the 2015 LHC proton-proton run at 13 TeV center-of-mass energy is presented. The Pixel <b>Cluster</b> <b>Counting</b> method is used and the absolute luminosity scale calibration is derived from an analysis of Van der Meer Scans performed in August 2015. The overall uncertainty on the luminosity measurement {{is estimated to be}} 2. 7 %...|$|E
40|$|Two basic {{approaches}} to the <b>cluster</b> <b>counting</b> task in the percolation and related models are discussed. The Hoshen-Kopelman multiple labeling technique for cluster statistics is redescribed. Modifications for random and aperiodic lattices are sketched {{as well as some}} parallelised versions of the algorithm are mentioned. The graph-theoretical basis for the spanning tree approaches is given by describing the breadth-first search and depth-first search procedures. Examples are given for extracting the elastic and geometric “backbone ” of a percolation cluster. An implementation of the “pebble game ” algorithm using a depth-first search method is also described. The algorithmic task of performing cluster statistics (i. e. <b>cluster</b> <b>counting)</b> is almost as old as the computer calculations: one of the pioneers of percolation theory, S. Broadbent, presented a percolation problem 1 at one of the first conferences on Monte Carlo simulations back in 1954. Since then for the physics community the cluster statistics problem has been tightly connected with the percolation theory. 2, 3 Another co-founder of this theory, J. M. Hammersley, argued in the 60 -s that the numerical study of percolation models is strongly hindered by the lack of fast enoug...|$|E
40|$|A brief {{introduction}} to the technique of Monte Carlo simulations in statistical physics is presented. The topics covered include statistical ensembles random and pseudo random numbers, random sampling techniques, importance sampling, Markov chain, Metropolis algorithm, continuous phase transition, statistical errors from correlated and uncorrelated data, finite size scaling, n-fold way, critical slowing down, blocking technique,percolation, cluster algorithms, <b>cluster</b> <b>counting,</b> histogram techniques, entropic/multicanonical Monte Carlo, Wang-Landau algorith and Jarzynski's identity. Comment: 66 pages; 11 figures; extensively revised; contains several new topic...|$|E
40|$|Min and Agresti (2005) {{proposed}} random effect hurdle {{models for}} zero-inflated <b>clustered</b> <b>count</b> data with two-part random effects for a binary component and a truncated count component. In this paper, we propose new marginalized models for zero-inflated <b>clustered</b> <b>count</b> data using random effects. The marginalized models {{are similar to}} Dobbie and Welsh’s (2001) model in which generalized estimating equations were exploited to find estimates. However, our proposed models are based on likelihood-based approach. Quasi-Newton algorithm is developed for estimation. We use these methods to carefully analyze two real datasets...|$|R
40|$|Abridged) Combining cosmic shear power spectra and <b>cluster</b> <b>counts</b> is {{powerful}} to improve cosmological parameter constraints and/or test inherent systematics. However they probe the same cosmic mass density field, {{if the two}} are drawn from the same survey region, and therefore the combination may be less powerful than first thought. We investigate the cross-covariance between the cosmic shear power spectra and the <b>cluster</b> <b>counts</b> based on the halo model approach, where the cross-covariance arises from the three-point correlations of the underlying mass density field. Fully {{taking into account the}} cross-covariance as well as non-Gaussian errors on the lensing power spectrum covariance, we find a significant cross-correlation between the lensing power spectrum signals at multipoles l~ 10 ^ 3 and the <b>cluster</b> <b>counts</b> containing halos with masses M> 10 ^{ 14 }Msun. Including the cross-covariance for the combined measurement degrades and in some cases improves the total signal-to-noise ratios up to plus or minus 20 % relative to when the two are independent. For cosmological parameter determination, the cross-covariance has a smaller effect as a result of working in a multi-dimensional parameter space, implying that the two observables can be considered independent to a good approximation. We also discuss that <b>cluster</b> <b>count</b> experiments using lensing-selected mass peaks could be more complementary to cosmic shear tomography than mass-selected <b>cluster</b> <b>counts</b> of the corresponding mass threshold. Using lensing selected clusters with a realistic usable detection threshold (S/N~ 6 for a ground-based survey), the uncertainty on each dark energy parameter may be roughly halved by the combined experiments, relative to using the power spectra alone. Comment: 32 pages, 15 figures. Revised version, invited original contribution to gravitational lensing focus issue, New Journal of Physic...|$|R
40|$|We {{present results}} of weak lensing <b>cluster</b> <b>counts</b> {{obtained}} from 11 degree 2 Subaru/SuprimeCam data. Although {{the area is}} much smaller than previous work dealing with weak lensing peak statistics, the number density of galaxies usable for weak lensing analysis is about {{twice as large as}} those. The higher galaxy number density reduces the noise in the weak lensing mass maps, and thus increases the signal-to-noise ratio (S=N) of peaks of the lensing signal due to massive clusters. This enables us to construct a weak lensing selected cluster sample by adopting a high threshold S=N, such that the contamination rate due to false signals is small. We nd 6 peaks with S=N> 5. For all the peaks, previously identied clusters of galaxies are matched within a separation of 1 arcmin, demonstrating good correspondence between the peaks and clusters of galaxies. We evaluate the statistical error in the weak lensing <b>cluster</b> <b>counts</b> using mock weak lensing data generated from full-sky ray-tracing simulations, and nd Npeak = 6 3 : 1 in an effective area of 9. 0 degree 2. We compare the measured weak lensing <b>cluster</b> <b>counts</b> with the theoretical model prediction based on halo models and place the constraint on m 8 plane which is found to be consistent with currently standard CDM models. It is demonstrated that the weak lensing <b>cluster</b> <b>counts</b> can place a unique constraint on 8 c 0 plane, where c 0 is the normalization of the dark matter halo mass{concentration relationship. Finally we discuss prospects for ongoing/future wide eld optical galaxy surveys...|$|R
40|$|A full {{simulation}} of a transition radiation detector (TRD) {{based on the}} GEANT, GARFIELD, MAGBOLTZ and HEED codes has been developed. This simulation {{can be used to}} study and develop TRD for high energy particle identification using either the <b>cluster</b> <b>counting</b> or the total charge measurement method. In this article it will be also shown an application of this simulation to the discrimination of electrons from hadrons in beams of momentum of few GeV/c or less, assuming typical TRD configuration, namely radiator-detector modules. Comment: 14 pages with 12 figure...|$|E
40|$|We {{develop a}} {{simplified}} {{implementation of the}} Hoshen-Kopelman <b>cluster</b> <b>counting</b> algorithm adapted for honeycomb networks. In our implementation of the algorithm we assume that all nodes in the network are occupied and links between nodes can be intact or broken. The algorithm counts how many clusters {{there are in the}} network and determines which nodes belong to each cluster. The network information is stored into two sets of data. The first one is related to the connectivity of the nodes and the second one to the state of links. The algorithm finds all clusters in only one scan across the network and thereafter cluster relabeling operates on a vector whose size is much smaller than the size of the network. Counting the number of clusters of each size, the algorithm determines the cluster size probability distribution from which the mean cluster size parameter can be estimated. Although our implementation of the Hoshen-Kopelman algorithm works only for networks with a honeycomb (hexagonal) structure, it can be easily changed to be applied for networks with arbitrary connectivity between the nodes (triangular, square, etc.). The proposed adaptation of the Hoshen-Kopelman <b>cluster</b> <b>counting</b> algorithm is applied to studying the thermal degradation of a graphene-like honeycomb membrane by means of Molecular Dynamics simulation with a Langevin thermostat. ACM Computing Classification System (1998) : F. 2. 2, I. 5. 3...|$|E
40|$|We {{present the}} main {{results of a}} {{numerical}} study of weak lensing <b>cluster</b> <b>counting.</b> We examine the scaling with cosmology of the projected-density-peak mass function. Our main conclusion is that the projected-peak and the three-dimensional mass functions scale with cosmology in an astonishingly close way. This means that, despite being derived from a two-dimensional field, the weak lensing cluster abundance {{can be used to}} constrain cosmology {{in the same way as}} the three-dimensional mass function probed by other types of surveys. Comment: 4 pages, 2 figures. Accepted for publication in ApJL. Figure 1 modified, unchanged conclusion...|$|E
40|$|We {{compare the}} {{efficiency}} of weak lensing-selected galaxy <b>clusters</b> <b>counts</b> and of the weak lensing bispectrum at capturing non-Gaussian features in the dark matter distribution. We use the halo model to compute the weak lensing power spectrum, the bispectrum and the expected number of detected clusters, and derive constraints on cosmological parameters for a large, low systematic weak lensing survey, {{by focusing on the}} Ω_m-σ_ 8 plane and on the dark energy equation of state. We separate the power spectrum into the resolved and the unresolved parts of the data, the resolved part being defined as detected clusters, and the unresolved part {{as the rest of the}} field. We consider four kinds of <b>clusters</b> <b>counts,</b> taking into account different amount of information : signal-to-noise ratio peak counts; counts as a function of clusters' mass; counts as a function of clusters' redshift; and counts as a function of clusters' mass and redshift. We show that when combined with the power spectrum, those four kinds of counts provide similar constraints, thus allowing one to perform the most direct counts, signal-to-noise peaks counts, and get percent level constraints on cosmological parameters. We show that the weak lensing bispectrum gives constraints comparable to those given by the power spectrum and captures non-Gaussian features as well as <b>clusters</b> <b>counts,</b> its combination with the power spectrum giving errors on cosmological parameters that are similar to, if not marginally smaller than, those obtained when combining the power spectrum with <b>cluster</b> <b>counts.</b> We finally note that in order to reach its potential, the weak lensing bispectrum must be computed using all triangle configurations, as equilateral triangles alone do not provide useful information. Comment: Matches ApJ-accepted versio...|$|R
40|$|In {{this paper}} we have {{presented}} a hand gesture recognition library. Various functions include detecting <b>cluster</b> <b>count,</b> <b>cluster</b> orientation, finger pointing direction, etc. To use these functions first the input image {{needs to be}} processed into a logical array for which a function has been developed. The library has been developed keeping flexibility in mind and thus provides application developers {{a wide range of}} options to develop custom gestures...|$|R
40|$|<b>Cluster</b> number <b>counts</b> {{can be used}} to test {{dark energy}} models. We {{investigate}} dark energy candidates which are coupled to dark matter. We analyze the <b>cluster</b> number <b>counts</b> dependence on the amount of dark matter coupled to dark energy. Further more, we study how dark energy inhomogeneities affect cluster abundances. It is shown that increasing the coupling reduces significantly the <b>cluster</b> number <b>counts,</b> and that dark energy inhomogeneities increases cluster abundances. Wiggles in <b>cluster</b> number <b>counts</b> are shown to be a specific signature of coupled dark energy models. Future observations will possibly detect such oscillations and discriminate among the different dark energy models. Comment: 9 pages, 8 figures. Further extensions on section on discriminating models with future surveys. Accepted for publication in Mon. Not. Roy. Astro. So...|$|R
40|$|For the Dark Energy Survey Collaboration Abstract. The Dark Energy Survey (DES) is a 5000 sq deg griz imaging {{survey to}} be {{conducted}} using a proposed 3 sq deg (2. 2 ◦-diameter) wide-field mosaic camera on the CTIO Blanco 4 m telescope. The primary scientific goal of the DES is to constrain dark energy cosmological parameters via four complementary methods: galaxy <b>cluster</b> <b>counting,</b> weak lensing, galaxy angular correlations, and Type Ia supernovae, supported by precision photometric redshifts. Here we present the photometric calibration plans for the DES, including a discussion of standard stars and field-to-field calibrations. 1...|$|E
40|$|The 4 th Concept {{detector}} presently being {{designed for}} the International Linear Collider introduces several innovations {{in order to achieve}} the necessary experimental goal of a detecter that is 2 -to- 10 times better than the already excellent SLC and LEP detectors. We introduce a dual-readout calorimeter system, a <b>cluster</b> <b>counting</b> drift chamber, and a second solenoid to return the magnetic flux without iron. We discuss particle identification, momentum and energy resolutions, and the machine-detector interface that together offer the possibility of a very high-performance detector for e + e − physics up to √ s = 1 TeV. ...|$|E
40|$|Single-cell {{prototype}} drift chambers {{were built}} at TRIUMF and tested with a ∼ 210 MeV/c beam of positrons, muons, and pions. A cluster-counting technique is implemented which improves {{the ability to}} distinguish muons and pions when combined with a traditional truncated-mean charge measurement. Sev-eral cluster-counting algorithms and equipment variations are tested, all showing significant improvement when combined with the traditional method. The results show that <b>cluster</b> <b>counting</b> is a feasible option for any particle physics experiment using drift chambers for particle identification. The technique does not require electronics with an overly high sampling rate. Optimal results are found with a signal smoothin...|$|E
40|$|<b>Clustered</b> <b>count</b> {{data are}} usually {{analysed}} using Poisson mixed models {{based on the}} assumptions of either gamma distributed or log-normal distributed random effects. As {{it is difficult to}} anticipate the true mixed model, the researchers tend to make an arbitrary choice between the assumption of gamma or log-normal distribution for the random effects. This arbitrary choice may not affect the estimation of the regression parameters of the model but the efficiency of the estimates of the variance component of the random effects may however be affected to a great extent. This paper addresses this issue by examining the misspecification effects of the distributional assumptions for the random effects in the <b>clustered</b> data. <b>Clustered</b> <b>count</b> data Mixed effects Quasi-likelihood Efficiency Regression effects Variance of the random effects...|$|R
40|$|We {{present a}} {{comparison}} of the SZ <b>cluster</b> <b>counts</b> predicted by the Press-Schechter (PS) mass function (MF) and the X-ray luminosity function (XLF) of clusters. The employment of the cluster XLF, together with the observationally determined X-ray luminosity(LX) -temperature(T) relation, may allow us to estimate the SZ <b>cluster</b> <b>counts</b> in a more realistic manner, although such an empirical approach depends sensitively on our current knowledge of the dynamical properties of intracluster gas and its cosmic evolution. Using both the non-evolving and evolving XLFs of clusters suggested by X-ray observations, we calculate the expectations for SZ surveys of clusters with X-ray luminosity LX ≥ 3 × 10 44 erg s − 1 and LX ≥ 1 × 10 43 erg s − 1 in the 0. 5 - 2. 0 band, respectively. The non-evolving XLF results in a significant excess of SZ <b>cluster</b> <b>counts</b> at high redshifts as compared with the evolving XLF, while a slightly steeper LX-T relation than the observed one is needed to reproduce the distributions of SZ clusters predicted by the standard PS formalism. It is pointed out that uncertainties in the cosmological application of future SZ cluster surveys via the standard PS formalism should be carefully studied...|$|R
40|$|We {{constrain}} {{radio source}} clustering towards $Planck$-selected galaxy clusters using the NVSS point source catalogue. The constraint can be utilised for generating realistic Sunyaev-Zeldovich effect (SZE) mocks, and for predicting detectable <b>clusters</b> <b>count</b> and quantifying source confusion in radio surveys. Comment: 2 pages, 1 figure, Talin 2014, 308 IAU Symposium contributio...|$|R
40|$|Two {{methods of}} {{constraining}} {{the properties of}} dark energy are weak lensing tomography and <b>cluster</b> <b>counting.</b> Uncertainties in mass calibration of clusters can be reduced by using the properties of halo clustering (the clustering of clusters). However, within a single survey, weak lensing and halo clustering probe the same density fluctuations. We explore {{the question of whether}} this information can be used twice [...] once in weak lensing and then again in halo clustering to calibrate cluster masses [...] or whether the combined dark energy constraints are weaker than the sum of the individual constraints. For a survey like the Dark Energy Survey (DES), we find that the cosmic shearing of source galaxies at high redshifts is indeed highly correlated with halo clustering at lower redshifts. Surprisingly, this correlation does not degrade cosmological constraints for a DES-like survey, and in fact, constraints are marginally improved since the correlations themselves act as additional observables. This considerably simplifies the analysis for a DES-like survey: when weak lensing and halo clustering are treated as independent experiments, the combined dark energy constraints (cluster counts included) are accurate if not slightly conservative. Our findings mirror those of Takada and Bridle, who investigated correlations between the cosmic shear and cluster counts. Comment: 4 pages, 2 color figures. Revised text for clarity and for resubmission to PhysRevD. Corrected error in our <b>cluster</b> <b>counting</b> Fisher matrix; combined dark energy constraints are now weaker, but our conclusions are the sam...|$|E
40|$|Two basic {{approaches}} to the <b>cluster</b> <b>counting</b> task in the percolation and related models are discussed. The Hoshen-Kopelman multiple labeling technique for cluster statistics is redescribed. Modifications for random and aperiodic lattices are sketched {{as well as some}} parallelised versions of the algorithm are mentioned. The graph-theoretical basis for the spanning tree approaches is given by describing the "breadth-first search" and "depth-first search" procedures. Examples are given for extracting the elastic and geometric "backbone" of a percolation cluster. An implementation of the "pebble game" algorithm using a depth-first search method is also described. Comment: LaTeX, uses ijmpc 1. sty(included), 18 pages, 3 figures, submitted to Intern. J. of Modern Physics...|$|E
40|$|The Dark Energy Survey (DES) is a 5000 sq deg griz imaging {{survey to}} be {{conducted}} using a proposed 3 sq deg (2. 2 deg-diameter) wide-field mosaic camera on the CTIO Blanco 4 m telescope. The primary scientific goal of the DES is to constrain dark energy cosmological parameters via four complementary methods: galaxy <b>cluster</b> <b>counting,</b> weak lensing, galaxy angular correlations, and Type Ia supernovae, supported by precision photometric redshifts. Here we present the photometric calibration plans for the DES, including a discussion of standard stars and field-to-field calibrations. Comment: 14 pages, 7 figures, {{to appear in the}} proceedings for the workshop, "The Future of Photometric, Spectrophotometric, and Polarimetric Standardization...|$|E
40|$|The {{evolution}} of galaxy <b>cluster</b> <b>counts</b> {{is a powerful}} probe of several fundamental cosmological parameters. A number of recent studies using this probe have claimed tension with the cosmology preferred by {{the analysis of the}} Planck primary CMB data, in the sense that there are fewer clusters observed than predicted based on the primary CMB cosmology. One possible resolution to this problem is systematic errors in the absolute halo mass calibration in cluster studies, which is required to convert the standard theoretical prediction (the halo mass function) into counts {{as a function of the}} observable (e. g., X-ray luminosity, Sunyaev-Zel'dovich flux, optical richness). Here we propose an alternative strategy, which is to directly compare predicted and observed <b>cluster</b> <b>counts</b> as a function of the one-dimensional velocity dispersion of the cluster galaxies. We argue that the velocity dispersion of groups/clusters can be theoretically predicted as robustly as mass but, unlike mass, it can also be directly observed, thus circumventing the main systematic bias in traditional <b>cluster</b> <b>counts</b> studies. With the aid of the BAHAMAS suite of cosmological hydrodynamical simulations, we demonstrate the potential of the velocity dispersion counts for discriminating even similar lambda CDM models. These predictions can be compared with the results from redshift surveys such as the highly complete Galaxy And Mass Assembly (GAMA) survey...|$|R
40|$|We {{show that}} the ability to probe {{primordial}} non-Gaussianity with <b>cluster</b> <b>counts</b> is drastically improved by adding the excess variance of counts which contains information on the clustering. The conflicting dependences of changing the mass threshold and including primordial non-Gaussianity on the mass function and biasing indicate that the self-calibrated <b>cluster</b> <b>counts</b> well break the degeneracy between primordial non-Gaussianity and the observable-mass relation. Based on the Fisher matrix analysis, we {{show that the}} count variance improves constraints on f_NL by more than an order of magnitude. It exhibits little degeneracy with dark energy equation of state. We forecast that upcoming Hyper Suprime-cam cluster surveys and Dark Energy Survey will constrain primordial non-Gaussianity at the level σ(f_NL) ∼ 8, which is competitive with forecasted constraints from next-generation cosmic microwave background experiments. Comment: 4 pages, 3 figures, accepted for publication in PR...|$|R
40|$|This work {{examines}} dynamic cluster {{assignment for}} a clustered trace cache processor (CTCP). Previously proposed cluster assignment techniques run into unique problems as issue width and <b>cluster</b> <b>count</b> increase. Realistic design conditions, such as variable data forwarding latencies between clusters and a heavily partitioned instruction window, increase {{the degree of}} difficulty for effective cluster assignment...|$|R
40|$|For cosmic {{particle}} spectroscopy on the International Space Station the AMS experiment will {{be equipped with}} a Transition Radiation Detector (TRD) to improve particle identification. The TRD has 20 layers of fleece radiator with Xe/CO 2 proportional mode straw tube chambers. They are supported in a conically shaped octagon structure made of CFC-Al-honeycomb. For low power consumption VA analog multiplexers are used as front-end readout. A 20 layer prototype built from final design components has achieved proton rejections from 100 to 2000 at 90 % electron efficiency for proton beam energies up to 250 GeV with <b>cluster</b> <b>counting,</b> likelihood and neural net selection algorithms. Comment: 11 pages, 25 figures, espcrc 2. sty (elsevier 2 -column...|$|E
40|$|In {{this review}} article {{we discuss the}} recent {{progress}} in PID techniques other than the RICH methods. In particular we mention the recent progress in the Transition Radiation Detector (TRD), dE/dx <b>cluster</b> <b>counting,</b> and Time Of Flight (TOF) techniques. The TRD technique is mature and has been tried in many hadron colliders. It needs space though, about 20 cm of detector radial space for every factor of 10 in the {pi}/e rejection power, and this tends to make such detectors large. Although the <b>cluster</b> <b>counting</b> technique is an old idea, it was never tried in a real physics experiment. Recently, there are efforts to revive it for the SuperB experiment using He-based gases and waveform digitizing electronics. A factor of almost 2 improvement, compared to the classical dE/dx performance, is possible in principle. However, {{the complexity of the}} data analysis will be substantial. The TOF technique is well established, but introduction of new fast MCP-PMT and G-APD detectors creates new possibilities. It seems that resolutions below 20 - 30 ps may be possible {{at some point in the}} future with relatively small systems, and perhaps this could be pushed down to 10 - 15 ps with very small systems, assuming that one can solve many systematic issues. However, the cost, rate limitation, aging and cross-talk in multi-anode devices at high BW are problems. There are several groups working on these issues, so progress is likely. Table 6 summarizes the author's opinion of pros and cons of various detectors presented in this paper based on their operational capabilities. We refer the reader to Ref. 40 for discussion of other more general limits from the PID point of view...|$|E
40|$|We {{show that}} an {{important}} and computationally challenging solution space feature of the graph coloring problem (COL), namely the number of clusters of solutions, can be accurately estimated by a technique very similar to one for {{counting the number of}} solutions. This <b>cluster</b> <b>counting</b> approach can be naturally written in terms of a new factor graph derived from the factor graph representing the COL instance. Using a variant of the Belief Propagation inference framework, we can efficiently approximate cluster counts in random COL problems over a large range of graph densities. We illustrate the algorithm on instances with up to 100, 000 vertices. Moreover, we supply a methodology for computing the number of clusters exactly using advanced techniques from the knowledge compilation literature. This methodology scales up to several hundred variables. ...|$|E
40|$|Possible {{explanations}} of the observed accelerated expansion of the Universe are {{the introduction of a}} dark energy component or the modifications of gravity at large distances. A particular difference between these scenarios is the dynamics of the growth of structures. The redshift distribution of galaxy clusters will probe this growth of structures with large precision. Here we will investigate how proposed galaxy cluster surveys will allow one to distinguish the modified gravity scenarios from dark energy models. We find that <b>cluster</b> <b>counts</b> can distinguish the Dvali-Gabadadze-Porrati model from a dark energy model, which has the same background evolution, as long as the amplitude of the primordial power spectrum is constrained by a CMB experiment like Planck. In order to achieve this, only a couple of hundred clusters in bins of width Delta-z = 0. 1 are required. This should be easily achievable with forthcoming Sunyaev-Zel'dovich <b>cluster</b> <b>counts,</b> such as the South Pole Telescope in conjunction with the Dark Energy Survey. Comment: 5 pages, 3 figure...|$|R
40|$|The {{predicted}} mass {{function of}} dark matter halos is essential in connecting observed galaxy <b>cluster</b> <b>counts</b> and models of galaxy clustering to {{the properties of the}} primordial density field. We determine the mass function in the concordance ΛCDM cosmology, as well as its uncertainty, using sixteen 1024 ^ 3 -particle nested-volume dark-matter simulations, spanning a mass range of over five orders of magnitude. Using the nested volumes and single-halo tests, we find and correct for a systematic error in the friends-of-friends halo-finding algorithm. We find a fitting form and full error covariance for the mass function that successfully describes the simulations' mass function and is well-behaved outside the simulations' resolutions. Estimated forecasts of uncertainty in cosmological parameters from future <b>cluster</b> <b>count</b> surveys have negligible contribution from remaining statistical uncertainties in the central cosmology multiplicity function. There exists a potentially non-negligible cosmological dependence (non-universality) of the halo multiplicity function. Comment: 4 pages, 3 figures, submitted to ApJ...|$|R
40|$|The latest Planck results reconfirm the {{existence}} of a slight but chronic tension between the best-fit Cosmic Microwave Background (CMB) and low-redshift observables: power seems to be consistently lacking in the late universe across a range of observables (e. g. weak lensing, <b>cluster</b> <b>counts).</b> We propose a two-parameter model for dark energy where the dark energy is sufficiently like dark matter at large scales to keep the CMB unchanged but where it does not cluster at small scales, preventing concordance collapse and erasing power. We thus exploit the generic scale-dependence of dark energy instead of the more usual time-dependence to address the tension in the data. The combination of CMB, distance and weak lensing data somewhat prefer our model to ΛCDM, at Δχ^ 2 = 2. 4. Moreover, this improved solution has σ_ 8 = 0. 79 ± 0. 02, consistent with the value implied by <b>cluster</b> <b>counts.</b> Comment: 13 pages, 7 figures, changes match published versio...|$|R
