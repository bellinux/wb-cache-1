957|1470|Public
5|$|The Saturn had {{technically}} impressive hardware at {{the time}} of its release, but its complexity made harnessing this power difficult for developers accustomed to conventional programming. The greatest disadvantage was that both CPUs shared the same bus and were unable to access system memory at the same time. Making full use of the 4kB of <b>cache</b> <b>memory</b> in each CPU was critical to maintaining performance. For example, Virtua Fighter used one CPU for each character, while Nights used one CPU for 3D environments and the other for 2D objects. The Saturn's Visual Display Processor 2 (VDP2), which can generate and manipulate backgrounds, has also been cited as one of the system's most important features.|$|E
25|$|The {{key idea}} of {{tabulation}} hashing is {{to view a}} key as a vector of t r-bit numbers, use a lookup table filled with random values to compute a hash value {{for each of the}} r-bit numbers representing a given key, and combine these values with the bitwise binary exclusive or operation. The choice of r should be made {{in such a way that}} this table is not too large; e.g., so that it fits into the computer's <b>cache</b> <b>memory.</b>|$|E
25|$|Although such {{techniques}} were not widely used by commercial interpreters, they exemplify the language's best survival mechanism: not specifying {{the order of}} scalar operations or the exact contents of memory. As standardized, in 1983 by ANSI working group X3J10, APL remains highly data-parallel. This gives language implementers immense freedom to schedule operations as efficiently as possible. As computer innovations such as <b>cache</b> <b>memory,</b> and SIMD execution became commercially available, APL programs are ported with almost no extra effort spent re-optimizing low-level details.|$|E
40|$|In multitask, {{preemptive}} real-time systems, {{the use of}} <b>cache</b> <b>memories</b> make difficult {{the estimation}} of the response time of tasks, due to the dynamic, adaptive and nonpredictable behaviour of <b>cache</b> <b>memories.</b> But many embedded and critical applications need the increase of performance provided by <b>cache</b> <b>memories...</b>|$|R
40|$|<b>Cache</b> <b>memories</b> {{are used}} in modern, medium and {{high-speed}} CPUs to hold temporarily those portions {{of the contents of}} main memory which are {believed to be) currently in use. Since instructions and data in <b>cache</b> <b>memories</b> can usually be referenced in 10 to 25 percent of the time required to access main <b>memory,</b> <b>cache</b> <b>memories</b> permit th...|$|R
40|$|Embedded {{microprocessor}} <b>cache</b> <b>memories</b> {{suffer from}} limited observability and controllability creating problems during in-system test. The application of test algorithms for SRAM <b>memories</b> to <b>cache</b> <b>memories</b> thus requires opportune transformations. In this paper {{we present a}} procedure to adapt traditional march tests to testing the data and the directory array of k-way set-associative <b>cache</b> <b>memories</b> with LRU replacement. The basic idea is to translate each march test operation into an equivalent sequence of cache operations able to reproduce the desired marching sequence into the data and the directory array of the cach...|$|R
25|$|The console {{contains}} 2GB of DDR3 {{system memory}} consisting of four 512MB DRAM chips {{with a maximum}} bandwidth of 12.8GB/s. This is 20 times the amount found in the Wii. Of this, 1GB is reserved for the operating system and is unavailable to games. The memory architecture allows the CPU and GPU to access both the main DDR3 memory pool and the eDRAM <b>cache</b> <b>memory</b> pool on the GPU, removing the need for separate, dedicated memory pools. The console includes either an 8GB (Basic) or 32GB (Deluxe (NA) / Premium (WW)) internal eMMC flash memory, expandable via SD memory cards up to 32GB and USB external hard disk drives up to 2TB.|$|E
25|$|In the 21st century, {{multi-core}} CPUs became commercially available. Content-addressable memory (CAM) {{has become}} inexpensive {{enough to be}} used in networking, and is frequently used for on-chip <b>cache</b> <b>memory</b> in modern microprocessors, although no computer system has yet implemented hardware CAMs for use in programming languages. Currently, CAMs (or associative arrays) in software are programming-language-specific. Semiconductor memory cell arrays are very regular structures, and manufacturers prove their processes on them; this allows price reductions on memory products. During the 1980s, CMOS logic gates developed into devices that could be made as fast as other circuit types; computer power consumption could therefore be decreased dramatically. Unlike the continuous current draw of a gate based on other logic types, a CMOS gate only draws significant current during the 'transition' between logic states, except for leakage.|$|E
25|$|One {{limitation}} (also afflicting the Intel Pentium III) is that SRAM cache designs at {{the time}} were incapable of keeping up with the Athlon's clock scalability, due both to manufacturing limitations of the cache chips and the difficulty of routing electrical connections to the cache chips themselves. It became increasingly difficult to reliably run an external processor cache to match the processor speeds being released—and in fact it became impossible. Thus initially the Level 2 cache ran at half of the CPU clock speed up to 700MHz (350MHz cache). Faster Slot-A processors had to compromise further and run at 2/5 (up to 850MHz, 340MHz cache) or 1/3 (up to 1GHz, 333MHz cache). This later race to 1GHz (1000MHz) by AMD and Intel further exacerbated this bottleneck as ever higher speed processors demonstrated decreasing gains in overall performance—stagnant SRAM <b>cache</b> <b>memory</b> speeds choked further improvements in overall speed. This directly lead to the development of integrating L2 cache onto the processor itself and remove the dependence on external cache chips. AMD's integration of the cache onto the Athlon processor itself would later result in the Athlon Thunderbird.|$|E
40|$|<b>Cache</b> <b>memories</b> {{bridge the}} growing access-time {{gap between the}} {{processor}} and the main <b>memory.</b> <b>Cache</b> <b>memories</b> use randomisation functions for two purposes: (i) to {{limit the amount of}} search when looking up an address in the cache and (ii) to interleave the access stream over multiple independent banks, allowing multiple simultaneous accesses...|$|R
40|$|Computer {{performance}} has increased rapidly {{for a number}} of years. In addition to the improvements in architecture and implementation techniques, <b>cache</b> <b>memories</b> have been utilized in memory hierarches to reduce memory latency and bus tra c. A large amount of research has been done to increase the performance of <b>cache</b> <b>memories.</b> This work is unique in that it optimizes the memor...|$|R
40|$|<b>Cache</b> <b>memories</b> {{are widely}} used to improve {{computer}} performance, but their inherent unpredictability presents new problems when cached systems must be analysed. In preemptive, multitask real-time systems, the <b>cache</b> <b>memories</b> have been analysed from two complementary points of view. First, calculating the Worst Case Execution Time #WCET# of each task considering no preemptions. Second, making the schedulability analysis considering the e#ect of cache when tasks are preempted...|$|R
500|$|An {{essential}} {{aspect of}} From Dust is the environment simulation, which underlies the player's {{interactions with the}} world. Developers intended that the world appear as a 'living thing', a dynamic and spontaneous entity, irrespective of the player's actions upon it. Chahi emphasised the difficulty of balancing this technical simulation with individual enjoyment, commenting that sometimes: [...] "it would take days {{to find the right}} value for gameplay that's also aesthetically pleasing". Montpellier accommodated this dynamism through a system of rules which govern the elements of the simulation: flowing water and moving soil result in the emergence of rivers; lakes {{at the base of a}} volcano accumulate sediment, which increases their viscosity; and similar rules govern volcanic eruptions, lava flow, and the spread of vegetation. With each rule, the layers accumulate to the point at which the developers are able to create an entire landscape. According to Chahi, simulation is the most challenging part of the game, as it requires developers to put lots of effort into optimisation because of its high computation demands. Chahi added that the game's programme is similar to that of VS Assembly, where the computation will be stored in the <b>cache</b> <b>memory,</b> allowing for fast computing. The team intentionally avoided developing any algorithms for objects like rivers and volcanoes, as they hoped that it would flow dynamically and naturally.|$|E
2500|$|Capacities of {{main memory}} and <b>cache</b> <b>memory</b> are usually {{expressed}} with customary binary prefixes ...|$|E
2500|$|The Wii U uses {{a custom}} multi-chip module (MCM) {{developed}} by AMD, IBM and Renesas in co-operation with Nintendo IRD and Nintendo Technology Development. The MCM combines an [...] "Espresso" [...] {{central processing unit}} (CPU) and a [...] "Latte" [...] graphics chip (GPU), {{as well as a}} SEEPROM memory chip. The Espresso CPU, designed by IBM, consists of a PowerPC 750-based tri-core processor with 3MB of shared L2 <b>cache</b> <b>memory</b> and clocked at approximately 1.24GHz. Despite belonging to the PowerPC family, the Espresso also shares some architectural concepts with the POWER7 architecture, {{such as the use of}} eDRAM cache and being manufactured at a 45nm node. The Latte graphics chip contains both a [...] "GX2" [...] GPGPU, which runs Wii U applications, and a [...] "GX" [...] GPU, which enables backward compatibility with Wii games. The GX2, designed by AMD, is based on the Radeon R600/R700 architecture and is clocked at approximately 550MHz. It is manufactured at a 40nm node and contains 32MB of eDRAM <b>cache</b> <b>memory,</b> which can also act as L3 cache for the CPU. The GX, originally designed by ArtX, contains a 1MB and a 2MB banks of eSRAM <b>cache</b> <b>memory.</b> The Latte chip also includes a secondary custom ARM9 processor with 96KB of SRAM memory that handles system tasks in the background during gameplay or while the system is in sleep mode, and dedicated hardware audio DSP module.|$|E
5000|$|Processor Nodes which {{consist of}} one or more {{processors}} along with their <b>caches,</b> <b>memories</b> and communication assist.|$|R
40|$|In multitask, {{preemptive}} real-time systems, {{the use of}} <b>cache</b> <b>memories</b> make difficult {{the estimation}} of the response time of tasks, due to the dynamic, adaptive and non predictable behavior of <b>cache</b> <b>memories.</b> But many embedded and critical applications need the increase of performance provided by <b>cache</b> <b>memories.</b> Recent studies indicate that for application-specific embedded systems, static cache-locking helps determining the worst case execution time (WCET) and cache-related pre-emption delay. The determination of upper bounds on execution times, commonly called Worst-Case Execution Times (WCETs), is a necessary step {{in the development and}} validation process for hard real-time systems. This problem is hard if the underlying processor architecture has components such as caches, pipelines, branch prediction, and other speculative components. This article describes different approaches to this problem and surveys several commercially available tools and research prototype...|$|R
40|$|In multitask, {{preemptive}} real-time systems, {{the use of}} <b>cache</b> <b>memories</b> makes {{estimating the}} response time of tasks difficult, due to the dynamic, adaptive and non-predictable behaviour of <b>cache</b> <b>memories.</b> This work presents a comprehensive method for attaining predictability {{on the use of}} caches in real-time systems through the use of locking caches, which ensure cache contents will remain unchanged during the execution of each task. Nowadays, locking caches are present in several commercial processors. In order to select the contents to be locked in cache, a genetic algorithm has been developed. Experimental results indicate that this scheme has a high level of predictability, and that the performance loss is negligible for around 70 % of the tasks. Copyright 2002 IFAC Keywords: <b>Cache</b> <b>Memories,</b> Response Times, Execution Times, Algorithms 1...|$|R
2500|$|Pentium MMX {{notebook}} CPUs used a [...] "mobile module" [...] {{that held}} the CPU. This module was a PCB with the CPU directly attached to it in a smaller form factor. The module snapped to the notebook motherboard and typically a heat spreader was installed and made contact with the module. However, with the 0.25µm Tillamook Mobile Pentium MMX (named after a city in Oregon), the module also held the 430TX chipset along with the system's 512 KB SRAM <b>cache</b> <b>memory.</b>|$|E
2500|$|The Athlon Classic is a {{cartridge}}-based processor, named Slot A {{and similar}} to Intel's cartridge Slot 1 used for Pentium II and Pentium III. It used the same, commonly available, physical 242 pin connector used by Intel Slot 1 processors but rotated by 180 degrees {{to connect the}} processor to the motherboard. The reversal served to make the slot keyed to prevent installation of the wrong CPU, as the Athlon and Intel processors used fundamentally different (and incompatible) signaling standards for their front-side bus. The cartridge assembly allowed the use of higher speed <b>cache</b> <b>memory</b> modules than could be put on (or reasonably bundled with) motherboards at the time. Similar to the Pentium II and the Katmai-based Pentium III, the Athlon Classic contained 512kB of L2 cache. This high-speed SRAM cache was run at a divisor of the processor clock and was accessed via its own 64-bit bus, known as a [...] "back-side bus" [...] allowing the processor to both service system front side bus requests (the rest of the system) and cache accesses simultaneously versus the traditional approach of pushing everything through the front-side bus.|$|E
5000|$|<b>Cache</b> <b>Memory</b> - Number of cache modules 1-32, Module {{capacity}} 8 or 16GB, Maximum <b>cache</b> <b>memory</b> 512GB ...|$|E
5000|$|... e500mc cores {{have private}} L2 caches but {{typically}} share other facilities like L3 <b>caches,</b> <b>memory</b> controllers, application specific acceleration cores, I/O and such.|$|R
40|$|Embedded {{microprocessor}} <b>cache</b> <b>memories</b> {{suffer from}} limited observability and controllability creating problems during in-system tests. This paper presents a procedure to transform traditional march tests into software-based self-test programs for set-associative <b>cache</b> <b>memories</b> with LRU replacement. Among {{all the different}} cache blocks in a microprocessor, testing instruction caches represents a major challenge due to limitations in two areas: 1) test patterns which must be composed of valid instruction opcodes and 2) test result observability: the results can only be observed through the results of executed instructions. For these reasons, the proposed methodology will concentrate on the implementation of test programs for instruction caches. The main contribution of this work lies {{in the possibility of}} applying state-of-the-art memory test algorithms to embedded <b>cache</b> <b>memories</b> without introducing any hardware or performance overheads and guaranteeing the detection of typical faults arising in nanometer CMOS technologie...|$|R
25|$|Most {{computer}} hardware uses SI prefixes to state capacity and define other performance parameters such as data rate. Main and <b>cache</b> <b>memories</b> are notable exceptions.|$|R
50|$|In {{addition}} to the macro-instruction <b>cache</b> <b>memory</b> {{also found in the}} ND-100, the ND-110 had a unique implementation of <b>cache</b> <b>memory</b> on the micro-instruction level. The step known as mapping in the ND-100 was then avoided because the first micro-instruction word of a macro-instruction was written into the control store cache.|$|E
50|$|These Seagate {{models were}} fitted with 2 MB of <b>cache</b> <b>memory.</b>|$|E
50|$|IBM and Hitachi {{models were}} fitted with 128 KB of <b>cache</b> <b>memory.</b>|$|E
3000|$|Reducing the {{supplied}} voltage. The renowned {{technique that}} {{has been applied to}} system components (e.g. CPUs, <b>cache</b> <b>memories)</b> is called Supply Voltage Reduction (SVR), [...]...|$|R
50|$|Most {{computer}} hardware uses SI prefixes to state capacity and define other performance parameters such as data rate. Main and <b>cache</b> <b>memories</b> are notable exceptions.|$|R
5000|$|... 2001: ACM Fellow for [...] "his highly cited {{paper on}} <b>cache</b> <b>memories,</b> for his {{contributions}} to performance measurement, and for his leadership in professional society activities" ...|$|R
5000|$|<b>Cache</b> <b>memory</b> error-correction {{of up to}} 4 errors per tag or 32-bit word ...|$|E
5000|$|DISKCACHE (OS/2 only, ignored under DR-DOS 7.02 and higher) : Configures <b>cache</b> <b>memory</b> sizes.|$|E
5000|$|<b>Cache</b> <b>memory</b> (often static RAM) - this {{operates}} at speeds comparable with the CPU.|$|E
40|$|Network continuous-media {{applications}} are emerging {{with a great}} pace. <b>Cache</b> <b>memories</b> have long been recognized as a key resource (along with network bandwidth) whose intelligent exploitation can ensure high performance for such applications. <b>Cache</b> <b>memories</b> exist at the continuous-media servers and their proxy servers in the network. Within a server, <b>cache</b> <b>memories</b> exist in a hierarchy (at the host, the storage-devices, and at intermediate multi-device controllers). Our research is concerned with how to best exploit these resources {{in the context of}} continuous media servers and in particular, how to best exploit the available <b>cache</b> <b>memories</b> at the drive, the disk array controller, and the host levels. Our results determine under which circumstances and system configurations it is preferable to devote the available memory to traditional caching (a. k. a. “data sharing”) techniques as opposed to prefetching techniques. In addition, we show how to configure the available memory for optimal performance and optimal cost. Our results show that prefetching techniques are preferable for small-size caches (such as those expected at the drive level). For very large caches (such as those employed at the host level) caching techniques are preferable. For intermediate cache sizes (such as those at multi-device controllers) a combination of both strategies should be employed...|$|R
40|$|This work takes a {{fresh look}} at the {{simulation}} of <b>cache</b> <b>memories.</b> It introduces the technique of static cache simulation that statically predicts a large portion of cache references. To efficiently utilize this technique, a method to perform efficient on-the-fly analysis of programs in general is developed and proved correct. This method is combined with static cache simulation for a number of applications. The application of fast instruction cache analysis provides a new framework to evaluate instruction <b>cache</b> <b>memories</b> that outperforms even the fastest techniques published. Static cache simulation is shown {{to address the issue of}} predicting cache behavior, contrary to the belief that <b>cache</b> <b>memories</b> introduce unpredictability to real-time systems that cannot be efficiently analyzed. Static cache simulation for instruction caches provides a large degree of predictability for real-time systems. In addition, an architectural modification through bit-encoding is introduced that provides fu [...] ...|$|R
40|$|Over {{the past}} couple of decades, trends in both {{microarchitecture}} and underlying semiconductor technology have significantly reduced microprocessor clock periods. Meanwhile, the technology trend in main memories has been a move toward higher densities rather than significantly reduced access times. Together, these trends have significantly increased relative main-memory latencies as measured in processor clock cycles. To avoid large performance losses caused by long memory access delays, microprocessors rely heavily on a hierarchy of <b>cache</b> <b>memories.</b> But <b>cache</b> <b>memories</b> are not always effective, either because they are not large enough to hold...|$|R
