11|186|Public
50|$|While the Counter-Terrorism Committee is not {{a direct}} <b>capacity</b> <b>provider</b> it does act as a broker between those states or groups that have the {{relevant}} capacities {{and those in the}} need of assistance.|$|E
50|$|Until 24 October 2013, ERT's {{employees}} {{were able to}} offer the television programmes of NET (also simulcast in HD as 'ERT-HD') and ET3, and the radio programmes of ERA Athens, ERA Thessaloniki and Third Programme through conventional means (analogue and digital TV, FM, medium and shortwave radio broadcasts) as well as over the Internet. At approximately 18:11 EEST, ERT lost their satellite capacity on the Astra 23.5°E Astra 3B satellite after successful lobbying by the Greek government to the <b>capacity</b> <b>provider</b> SES S.A.. That halted most conventional TV and radio broadcasts that received the feed from the satellite, but {{did not affect the}} regional ERA affiliates that produced their programming locally, nor a large part of Athens which is served by a DVB-T transmitter located within the ERT HQs in Ayia Paraskevi. Web streaming wasn't affected at all.|$|E
40|$|A {{callable}} {{product is}} {{a unit of}} capacity sold to self-selected low-fare customers who willingly grant the <b>capacity</b> <b>provider</b> the option to "call" the capacity at a prespecified recall price. We analyze callable products in a finite-capacity setting with two fare classes where low-fare customers book first, and show that callable products provide a riskless source of additional revenue to the <b>capacity</b> <b>provider.</b> An optimal recall price and an optimal discount-fare booking limit for the two-period problem are obtained. Numerical examples show the benefits from offering callable products can be significant, especially when high-fare demand uncertainty is large. Extensions to multifare structures, network models, overbooking, and to other industries are discussed. revenue management, product design, overbooking, capacity allocation...|$|E
40|$|We {{consider}} a game between two <b>capacity</b> <b>providers</b> that compete for customers through a broker {{who works on}} commissions and sells to both loyal and non-loyal customers. The <b>capacity</b> <b>providers</b> compete by selecting commission margins and sales thresholds at which commissions on all sales increase. We show that in equilibrium, contracts require positive sales thresholds. The threshold requirement can be best described as a mechanism for one provider to profit {{at the expense of}} the other. For exogenous commission margins, we show that it is the provider with the lower margin who benefits from thresholds {{at the expense of the}} broker. However, the gains for the lower margin provider can be a mirage in full equilibrium, where commission margins are endogenous...|$|R
5000|$|... {{to build}} the <b>capacity</b> of {{education}} <b>providers</b> and practitioners to improve their own performance ...|$|R
5000|$|... 2007 Socha-Gelbmann Survey: Top 5 service <b>provider</b> (<b>capacity).</b> CaseData Division of Océ Business Services.|$|R
40|$|We {{propose a}} method for {{determining}} how much to charge users of a communication network when they share bandwidth. Our approach can be employed either when a network owner wishes to sell bandwidth for a specified {{period of time to}} a number of different users, or when users cooperate to build a network to be shared among themselves. Our proposed contract and balancing mechanism can mediate between rapidly fluctuating prices and the longer time scales over which bandwidth contracts may be traded. An advantage of the process is that it avoids perverse incentives for a <b>capacity</b> <b>provider</b> to increase congestion. capacity contracts, congestion pricing, Nash equilibrium...|$|E
40|$|In power markets {{ancillary}} service is usually centrally handled. The system operator determines the required reserve capacity and purchases {{it from the}} reserve suppliers. The corresponding cost is allocated to consumers. This approach may lead to inefficiency and gaming in {{ancillary service}} markets. Is there any way that individual consumers can treat the reserve capacity through a decentralized decision-making approach? If so, how should each consumer make optimal ancillary service plan? With a decentralized approach, where each consumer tries to maximize his own benefit, could the maximal social welfare be obtained as its centralized counterpart? In this paper, conceptual study results on these issues are presented. Two cases are investigated. The first case aims at reducing electricity interruption risk of a specified consumer via asking a power supplier to improve generation reliability. The provider insurance theory is introduced to guarantee the improvement of generation reliability. In the second case, there are three participants in the market: a power supplier, a consumer (also the insured) and a reserve <b>capacity</b> <b>provider</b> (also the insurer). Reserve capacity is traded and the insurance policy used to enforce the liability of reserve <b>capacity</b> <b>provider.</b> It is shown that in both cases, once the consumer purchases a well-defined insurance policy, the latter will induce incentives for the insurer to provide the required level of reliability improvement or reserve capacity. With insurance policy, the consumer can reduce his expected outage loss and shift his risk to the risk-neutral insurer. It is proven that the suggested decentralized approach can yield maximal social welfare as well. link_to_subscribed_fulltex...|$|E
40|$|We {{consider}} a <b>capacity</b> <b>provider</b> who offers multiple {{versions of a}} single product, such as different seat locations for an event. We assume that the different versions share an unknown core value and command a known premium or discount relative to the core value. Customers arrive at an unknown arrival rate during a finite sales horizon. We assume that the provider has a prior knowledge on the arrival rate which is updated using Bayesian rule. Estimates of the core value are updated using maximum likelihood estimation. We show how to simultaneously estimate the unknown parameters as the sales evolve and how to price the products to maximize revenues under a rolling horizon framework...|$|E
50|$|USA Truck {{celebrated its}} 30th year in {{operation}} in 2013. In 2015, {{as part of}} a widespread brand enhancement initiative, the USA Truck marketing group unveiled a new collection of logos and launched a new corporate website (usa-truck.com) to reflect its growth as a <b>capacity</b> solutions <b>provider.</b>|$|R
50|$|Free {{cash flow}} to firm (FCFF) is the cash flow {{available}} to all the firm’s providers of capital once the firm pays all operating expenses (including taxes) and expenditures needed to support the firm’s productive <b>capacity.</b> The <b>providers</b> of capital include common stockholders, bondholders, preferred stockholders, and other claimholders.|$|R
50|$|The Clinician Consultation Center’s {{mission is}} to improve patient health {{outcomes}} by building the <b>capacity</b> of healthcare <b>providers</b> through expert clinical consultation and education.|$|R
40|$|Acallable {{product is}} {{a unit of}} {{capacity}} sold to self-selected low-fare customers who willingly grant thecapacity provider the option to “call ” the capacity at a prespecified recall price. We analyze callable products in a finite-capacity setting with two fare classes where low-fare customers book first, and show that callable products provide a riskless source of additional revenue to the <b>capacity</b> <b>provider.</b> An optimal recall price and an optimal discount-fare booking limit for the two-period problem are obtained. Numerical examples show the benefits from offering callable products can be significant, especially when high-fare demand uncertainty is large. Extensions to multifare structures, network models, overbooking, and to other industries are discussed. Key words: revenue management; product design; overbooking; capacity allocation History: Accepted by Paul H. Zipkin, operations and supply chain management; received November 15, 2004. This paper was with the authors 1 year and 2 months for 2 revisions. 1...|$|E
40|$|This paper {{presents}} the results of a research project, in which the situation of local software organizations operating with global industrial customers were examined. The prospects of locally operating software organizations have been lately dimmed by the processes of globalization, IT outsourcing, and offshore software development. The current situation of local software organizations is analyzed, and also trends and challenges that they face in the future are described. In the study, qualitative analysis with grounded theory was used as the research method. The analysis identified three types of local software organizations. Using business processes, technologies, and types of customer relationships and cooperation as the basis, these types can be labelled as Anticipator, Specializer and Collector. Local software organizations had recognized their inability to compete with globally operating software enterprises and they had difficulties in coping with changes in competition caused by outsourcing, mergers, and offshore development. The analysis of future trends produced three possible models of cooperation between asymmetrical partners, tailored solutions provider, software producer, and <b>capacity</b> <b>provider...</b>|$|E
40|$|Over {{the past}} decade network {{industries}} (such as gas, electricity, and telecommunications) have undergone a dramatic transformation. Competition has been introduced in industries that had long been viewed as textbook examples of natural monopolies. Production and transport have been unbundled to foster the introduction of competition: the <b>capacity</b> <b>provider</b> (the owner of the infrastructure) now often differs from the service provider. Chief among the challenges this raises for economists and policymakers: to design institutions that lead to"optimal"network expansion. Different arrangements have been suggested, ranging from indicative planning to decentralization of investment decisions through congestion pricing. Two questions lie {{at the core of}} the debate: Is the infrastructure network still a natural monopoly? And what role should congestion pricing play in ensuring optimal network expansion? The author shows that simple economic principles apply to the use of congestion pricing to induce network expansion: a) If network provision is competitive, congestion pricing leads to optimal investment. b) If network provision is monopolistic, congestion pricing leads to underinvestment. He shows the model applying to power networks as well as to the Internet. Policymakers must therefore assess whether network expansion is indeed competitive and design institutions that ease entry, or design an appropriate regulatory framework. Banks&Banking Reform,Economic Theory&Research,Common Carriers Industry,Transport and Trade Logistics,Markets and Market Access,Common Carriers Industry,Economic Theory&Research,Geographical Information Systems,Banks&Banking Reform,Transport and Trade Logistics...|$|E
40|$|This paper {{considers}} firms' {{incentives to}} invest in local and exible resources when demand is uncertain and correlated. Before demand is realized, two firms decide {{to invest in}} their local <b>capacity.</b> <b>Provider(s)</b> of exible resource observe these decisions and invest in their capacity. After demand is realized, firms buy exible resource if demand exceeds their local capacity. I find that market power of the monopolist providing exible resources distorts investment incentives, while competition mitigates them. The extent of improvement depends critically on demand correlation {{and the cost of}} capacity: under social optimum and monopoly, if the exible resource is cheap, the relationship between investment and correlation is positive, and if it is costly, the relationship becomes negative; under duopoly, the relationship is positive. The analysis also sheds light on some policy discussions in markets such as cloud computing...|$|R
5000|$|... Strengthen the {{implementation}} of laws, policies and action plans on burn and acid violence through data collection and analysis, building <b>capacities</b> of service <b>providers,</b> controlling the sale of acid, and strengthening institutions to become more effective, transparent and accountable in addressing burn and acid violence.- Expand survivors' of acid and burn violence to services including legal assistance, medical treatment, psychosocial counseling, health care, and building the <b>capacity</b> of service <b>providers</b> to respond effectively to the rehabilitation needs of survivors affected by acid and burn violence.|$|R
40|$|We {{consider}} a game between two <b>capacity</b> <b>providers</b> that compete for customers through a broker who earns commissions on sales and sells to both loyal and nonloyal customers. The providers compete by selecting commission margins and sales targets above which the margins on total sales increase. We study the contract form in equilibrium {{and the effect}} that sales targets have on the profit split between the providers and the broker. We show that in equilibrium, contracts require positive sales targets that can be best described as a mechanism for the larger provider to profit {{at the expense of}} the smaller provider. The effect of sales targets is different when commission margins are exogenous and the providers compete by setting targets. In this case, it is the low-margin provider who benefits from sales targets {{at the expense of the}} broker, who in this context resists the imposition of targets...|$|R
40|$|Adequate {{access to}} health {{services}} remains a fundamental challenge for the U. S. health care system. Ambulatory care sensitive hospitalizations (ACSH) are increasingly used as indicators of access in health services research. Importantly, most empirical research on ACSH has overlooked or narrowly defined the role of organizations in improving or impeding access. Using a coordination-and-control theoretical framework, this study examined whether the structural characteristics of markets such as provider <b>capacity,</b> <b>provider</b> composition, and inter-organizational relationships affect acute care, chronic care, and aggregate ACSH rates. The study used a longitudinal, pooled cross-sectional design that examined 58 California markets for the years 1998 through 2005. The unit of analysis was the market-year and the final analytic sample included 450 observations. The most robust findings pertained to provider composition, where the ratio of home health agencies, skilled nursing facilities, and physician organizations to hospitals were significantly and negatively associated with ACSH rates. Provider capacity and inter-organizational relationships generally failed to demonstrate significant relationships with ACSH rates. Contrasting results between provider capacity and provider composition suggest {{that the effects of}} provider supply may depend upon how supply is measured. Supplementary analysis examined these relationships on a condition-specific basis and suggested that the effects of inter-organizational relationships may be limited to specific clinical conditions. Specifically, the analysis found that the proportion of hospitals with a formal physician organization relationship was associated with higher hospitalization rates for pneumonia, angina, asthma, and congestive heart failure. In contrast, the proportion of hospitals in a market with a formal nursing home relationship was significantly associated with lower hospitalization rates for perforated appendix, angina, asthma, and hypertension. Likewise, the proportion of hospitals in a market that owned an insurance product was associated with lower hospitalization rates for congestive heart failure, chronic obstructive pulmonary disease, and uncontrolled diabetes. These results suggest that the relationship between market structure and ACSH rates may depend upon the medical condition and the type(s) of organizations under study. Overall, these findings raise questions about the appropriateness of combining clinical conditions into aggregated hospitalization rates and the conclusions of studies that use such approaches to study ACSH...|$|E
40|$|The {{need for}} {{mobility}} {{that emerged in}} the last decades led to an impressive {{increase in the number of}} vehicles as well as to a saturation of transportation infrastructures. Consequently, traffic congestion, accidents, transportation delays, and polluting emissions are some of the most recurrent concerns transportation and city managers have to deal with. However, just building new infrastructures might be not sustainable because of their cost, the land usage, which usually lacks in metropolitan regions, and their negative impact on the environment. Therefore, a different way of improving the performance of transportation systems while enhancing travel safety has to be found in order to make people and good transportation operations more efficient and support their key role in the economic development of either a city or a whole country. The concept of City Logistics (CL) is being developed to answer to this need. Indeed, CL focus on reducing the number of vehicles operating in the city, controlling their dimension and characteristics. CL solutions do not only improve the transportation system but the whole logistics system within an urban area, trying to integrate interests of the several. This global view challenges researchers to develop planning models, methods and decision support tools for the optimization of the structures and the activities of the transportation system. In particular, this leads researchers to the definition of strategic and tactical problems belonging to well-known problem classes, including network design problem, vehicle routing problem (VRP), traveling salesman problem (TSP), bin packing problem (BPP), which typically act as sub-problems of the overall CL system optimization. When long planning horizons are involved, these problems become stochastic and, thus, must explicitly take into account the different sources of uncertainty that can affect the transportation system. Due to these reasons and the large-scale of CL systems, the optimization problems arising in the urban context are very challenging. Their solution requires investigations in mathematical and combinatorial optimization methods as well as the implementation of efficient exact and heuristic algorithms. However, contributions answering these challenges are still limited number. This work contributes in filling this gap in the literature in terms of both modeling framework for new planning problems in CL context and developing new and effective heuristic solving methods for the two-stage formulation of these problems. Three stochastic problems are proposed in the context of CL: the stochastic variable cost and size bin packing problem (SVCSBPP), the multi-handler knapsack problem under uncertainty (MHKPu) and the multi-path traveling salesman problem with stochastic travel times (mpTSPs). The SVCSBPP arises in supply-chain management, in which companies outsource the logistics activities to a third-party logistic firm (3 PL). The procurement of sufficient capacity, expressed in terms of vehicles, containers or space in a warehouse for varying periods of time to satisfy the demand plays a crucial role. The SVCSBPP focuses on the relation between a company and its logistics <b>capacity</b> <b>provider</b> and the tactical-planning problem of determining the quantity of capacity units to secure for the next period of activity. The SVCSBPP is the first attempt to introduce a stochastic variant of the variable cost and size bin packing problem (VCSBPP) considering not only the uncertainty on the demand to deliver, but also on the renting cost of the different bins and their availability. A large number of real-life situations can be satisfactorily modeled as a MHKPu, in particular in the last mile delivery. Last mile delivery may involve different sequences of consolidation operations, each handled by different workers with different skill levels and reliability. The improper management of consolidation operations can cause delay in the operations reducing the overall profit of the deliveries. Thus, given a set of potential logistics handlers and a set of items to deliver, characterized by volume and random profit, the MHKPu consists in finding a subset of items which maximizes the expected total profit. The profit is given by the sum of a deterministic profit and a stochastic profit oscillation, with unknown probability distribution, due to the random handling costs of the handlers. The mpTSPs arises mainly in City Logistics applications. Cities offer several services, such as garbage collection, periodic delivery of goods in urban grocery distribution and bike sharing services. These services require the planning of fixed and periodic tours that will be used from one to several weeks. However, the enlarged time horizon as well as strong dynamic changes in travel times due to traffic congestion and other nuisances typical of the urban transportation induce the presence of multiple paths with stochastic travel times. Given a graph characterized by a set of nodes connected by arcs, mpTSPs considers that, for every pair of nodes, multiple paths between the two nodes are present. Each path is characterized by a random travel time. Similarly to the standard TSP, the aim of the problem is to define the Hamiltonian cycle minimizing the expected total cost. These planning problems have been formulated as two-stage integer stochastic programs with recourse. Discretization methods are usually applied to approximate the probability distribution of the random parameters. The resulting approximated program becomes a deterministic linear program with integer decision variables of generally very large dimensions, beyond the reach of exact methods. Therefore, heuristics are required. For the MHKPu, we apply the extreme value theory and derive a deterministic approximation, while for the SVCSBPP and the mpTSPs we introduce effective and accurate heuristics based on the progressive hedging (PH) ideas. The PH mitigates the computational difficulty associated with large problem instances by decomposing the stochastic program by scenario. When effective heuristic techniques exist for solving individual scenario, that is the case of the SVCSBPP and the mpTSPs, the PH further reduces the computational effort of solving scenario subproblems by means of a commercial solver. In particular, we propose a series of specific strategies to accelerate the search and efficiently address the symmetry of solutions, including an aggregated consensual solution, heuristic penalty adjustments, and a bundle fixing technique. Yet, although solution methods become more powerful, combinatorial problems in the CL context are very large and difficult to solve. Thus, in order to significantly enhance the computational efficiency, these heuristics implement parallel schemes. With the aim to make a complete analysis of the problems proposed, we perform extensive numerical experiments on a large set of instances of various dimensions, including realistic setting derived by real applications in the urban area, and combinations of different levels of variability and correlations in the stochastic parameters. The campaign includes the assessment of the efficiency of the meta-heuristic, the evaluation of the interest to explicitly consider uncertainty, an analysis of the impact of problem characteristics, the structure of solutions, as well as an evaluation of the robustness of the solutions when used as decision tool. The numerical analysis indicates that the stochastic programs have significant effects in terms of both the economic impact (e. g. cost reduction) and the operations management (e. g. prediction of the capacity needed by the firm). The proposed methodologies outperform the use of commercial solvers, also when small-size instances are considered. In fact, they find good solutions in manageable computing time. This makes these heuristics a strategic tool that can be incorporated in larger decision support systems for C...|$|E
5000|$|... 2009: Chosen by the Wallace Foundation {{as one of}} 14 {{organizations}} {{to participate in a}} four-year national pilot project to strengthen the financial management <b>capacities</b> of out-of-school-time <b>providers.</b>|$|R
40|$|International audienceWe {{conduct in}} this work a {{comparative}} study between a greedy versus limited proposals for resource aggregation in the backhaul of wireless local area networks. We consider a setting with several access points, some with excess backhaul <b>capacity</b> (<b>providers),</b> and others in shortage of it (beneficiaries) and investigate two approaches for the distribution of resources between them: a greedy one wherein each beneficiary seeks to maximize the resource it could obtain from the provider and a limited {{one in which the}} operator limits the amount of acquired resources to some limit, so as to ensure fairness between beneficiaries. We model the system using a one-to-one matching game, and compare the two approaches in three scenarios: a symmetric one with equal number of providers and beneficiaries, and asymmetric ones with higher number of either providers or beneficiaries. Our results show that the greedy scheme outperforms the limited one when the number of providers is larger than that of beneficiaries, the limited one performs best in the opposite case and ensures fairness between beneficiary access points. In all cases, both approaches outperform the random allocation schem...|$|R
40|$|Abstract—While early {{emphasis}} of Infrastructure as a Ser-vice (IaaS) clouds was on providing resource elasticity to end users, providers are increasingly interested in over-committing their resources {{to maximize the}} utilization and returns of their capital investments. In principle, over-committing resources hedges that users—on average—only need {{a small portion of}} their leased resources. When such hedge fails (i. e., resource de-mand far exceeds available physical <b>capacity),</b> <b>providers</b> must mitigate this provider-induced overload, typically by migrating virtual machines (VMs) to underutilized physical machines. Recent works on VM placement and migration assume the availability of target physical machines [1], [2]. However, in an over-committed cloud data center, this is not the case. VM migration can even trigger cascading overloads if performed haphazardly. In this paper, we design a new VM migration algorithm (called Scattered) that minimizes VM migrations in over-committed data centers. Compared to a traditional implementation, our algorithm can balance host utilization across all time epochs. Using real-world data traces from an enterprise cloud, we show that our migration algorithm reduces the risk of overload, minimizes the number of needed migrations, and has minimal impact on communication cost between VMs. I...|$|R
40|$|Diversification of {{exposure}} concentration means geographical balancing amongst <b>capacity</b> <b>providers</b> [...] insurers, reinsurers, or capital market participants. But how to diversify those exposures is still unsettled. Efforts {{to this point}} have focused on balancing the exposures which have already been written by insurers [...] via catastrophe reinsurance (regular or securitized), several proposed catastrophe indices, even direct exposure exchanges. This paper proposes an alternative approach: exposure balancing {{at the point of}} sale using an insurance pricing structure which reflects the insurer’s exposure level or “potiolio state ” [...] what can be called portfolio state dependent pricing. Instead of one set of filed loss costs and loss cost multipliers, insurers would quote a manual rate which included a surcharge which reflects their exposure level in the area where the potential insured is located. If all carriers were required to quote on a similar basis, had similar loss costs and multipliers, a potential insured’s desire to be charged the lowest premium would lead them to choose the carrier who was least exposed in their area. Biography Mr. Mango is with Zurich Centre Resource in New York City. Prior to that he was wit...|$|R
40|$|The {{unbundling}} of {{the formerly}} integrated activities of gas sales and transmission in Europe {{has created a}} distinct market for gas transmission capacity. In {{order to meet the}} capacity needs of all network users, non-discriminatory third party access arrangements to transmission capacity are being developed and implemented throughout Europe in accordance with the Second EU Gas Directive. The paper discusses the marketing of transmission capacity and the calculation of the available capacity that transmission system operators (TSOs) are able to bring to the market. TSOs throughout Europe have a different approach to these issues as there is yet no industry-wide standard for the provision of transmission services and neither for calculating available transmission capacity. In this context, the Council of European Energy Regulators (CEER) agreed that transmission <b>capacity</b> <b>providers</b> need to provide better documentation and greater transparency for their capacity calculation processes. This paper contains a number of recommendations to achieve more consistency among capacity calculations. The paper starts to set out capacity definitions and principles for a market-oriented provision of available capacities, so as to better meet the needs of network users and to enhance networ...|$|R
40|$|While early {{emphasis}} of Infrastructure as a Service (IaaS) clouds was on providing resource elasticity to end users, providers are increasingly interested in over-committing their resources {{to maximize the}} utilization and returns of their capital investments. In principle, over-committing resources hedges that users - on average - only need {{a small portion of}} their leased resources. When such hedge fails (i. e., resource demand far exceeds available physical <b>capacity),</b> <b>providers</b> must mitigate this provider-induced overload, typically by migrating virtual machines (VMs) to underutilized physical machines. Recent works on VM placement and migration assume the availability of target physical machines [1], [2]. However, in an over-committed cloud data center, this is not the case. VM migration can even trigger cascading overloads if performed haphazardly. In this paper, we design a new VM migration algorithm (called Scattered) that minimizes VM migrations in over-committed data centers. Compared to a traditional implementation, our algorithm can balance host utilization across all time epochs. Using real-world data traces from an enterprise cloud, we show that our migration algorithm reduces the risk of overload, minimizes the number of needed migrations, and has minimal impact on communication cost between VMs. © 2012 IEEE...|$|R
40|$|High quality {{child care}} is a {{population}} health investment that relies on the <b>capacity</b> of <b>providers.</b> The mental health and wellbeing of child care educators is fundamental to care quality and turnover, yet sector views {{on the relationship between}} working conditions and mental health and wellbeing are scarce. This paper examines child care educators 2 ̆ 7 and sector key informants 2 ̆ 7 perspectives on how working in family day care influences educator 2 ̆ 7 s mental health and wellbeing...|$|R
50|$|Cloud BUR {{enables a}} Service Provider to {{allocate}} storage capacity to a customer. If that customer later deletes their data or no longer needs that <b>capacity,</b> the Service <b>Provider</b> can then release and reallocate that same capacity {{to a different}} customer in an automated fashion.|$|R
40|$|Open access scheduling, {{introduced}} in recent years, is a revolutionary concept for improving healthcare access and reducing patient no-shows. In this paper, a Markov chain model {{is presented to}} capture appointment scheduling in open access clinics when considering patient choice of appointments. Due to the curse of dimensionality, {{it is impossible to}} solve the steady-state distribution of the Markov chain model for a typical-size open access primary care clinic. Therefore, an approximate approach is proposed to efficiently estimate the performance of a <b>provider</b> <b>capacity</b> policy based on the Markov chain model. This approach can accurately estimate the performance of a practical capacity policy in a significantly shorter time. Using this approach, the impact of patient choice on the performance of <b>provider</b> <b>capacity</b> policies is investigated. Appointment scheduling Patient choice model Healthcare Open access scheduling...|$|R
40|$|The {{search for}} {{enablers}} of continued growth of SMS traffic, {{as well as}} the take-off of the more diversified MMS message contents, open up for enterprises the potential of bulk use of mobile messaging, instead of essentially one-by-one use. In parallel, such enterprises or value added services needing mobile messaging in bulk - for spot use or for use over a prescribed period of time - want to minimize total acquisition costs, from a set of technically approved <b>providers</b> of messaging <b>capacity.</b> This leads naturally to the evaluation of auctioning for bulk SMS or MMS messaging capacity, with the intrinsic advantages therein such as reduction in acquisition costs, allocation efficiency, and optimality. The paper shows, with extensive results as evidence from simulations carried out in the Rotterdam School of Management e-Auction room, how multi-attribute reverse auctions perform for the enterprise-buyer, {{as well as for the}} messaging capacity-sellers. We compare 1 - and 5 -round auctions, to show the learning effect and the benefits thereof to the various parties. The sensitivity will be reported to changes in the enterprise's and the <b>capacity</b> <b>providers</b> utilities and priorities between message attributes (such as price, size, security, and delivery delay). At the organizational level, the paper also considers alternate organizational deployment schemes and properties for an off-line or spot bulk messaging capacity market, subject to technical and regulatory constraints...|$|R
40|$|As CDMA systems reach <b>capacity,</b> {{infrastructure}} <b>providers</b> are extending them {{by offering}} multicarrier capability. The capacity of an n-carrier CDMA {{system should be}} at least n times the capacity of a single-carrier system. We estimate the additional capacity that can be achieved by using carrier assignment disciplines. We produce the estimates from the CDMA System Static Simulator by preprocessing the simulator inputs and post-processing its outputs. The estimates are of capacities of multicarrier systems using simple carrier assignment disciplines, and of wideband CDMA systems. The latter estimates constitute an upper bound on the capacity of a multicarrier system with any carrier assignment discipline...|$|R
40|$|<b>Capacity</b> <b>providers</b> often {{experience}} a mismatch between {{supply and demand}} that can be partially alleviated while improving revenues by allowing for product upgrades. When prices are fixed and demands are independent, the problem is to decide which customer demands to upgrade to which products and when. We show that a fairness constraint can be imposed without loss of optimality under mild conditions. We also investigate a model that limits upgrades to the next higher quality product, and we provide necessary and sufficient conditions for its revenues to {{be as high as}} that of any less restricted upgrade model. Resellers of capacity also have an incentive to use upgrades as a mechanism to entice customers to higher quality products with higher commission margins. We show that this practice can be very profitable and that the profits can be much larger than direct commissions from sales would indicate. We then investigate the case where sellers have pricing flexibility and customer demand is driven by a choice model. We derive pricing formulas under the assumption that demand for products follows a multinomial logit model, and we develop an algorithm for finding a global optimal solution to the capacity constrained profit function. For this model we show that neither upgrades nor upsells improve profits when margins are homogenous and there is complete freedom in selecting prices. However, upgrades can improve revenues significantly when sensible business constraints on prices are imposed and when margins are heterogenous. ...|$|R
40|$|We are {{interested}} in whether preventing resale of tickets benefits the <b>capacity</b> <b>providers</b> for sporting and entertainment events. Common wisdom suggests that ticket resale is harmful to event organizers' revenues and event organizers have tried to prevent resale of tickets. For instance, Ticketmaster has recently proposed paperless (non-transferrable) ticketing which would severely limit the opportunity to resell tickets. We consider a model that allows resale from both consumers and speculators with different transaction costs for each party. Surprisingly, we find that this wisdom is incorrect when event organizers use fixed pricing policies, in fact event organizers benefit from reductions in consumers' (and speculators') transaction costs of resale. Even when multiperiod pricing policies are used, we find that an event organizer may still benefit from ticket resale if his capacity is small. While paperless ticketing is suggested {{as a way to}} reduce ticket resale and prevent speculators from buying tickets, our results suggest that it may reduce the capacity providers' revenues in many situations. Instead, we propose ticket options as a novel ticket pricing mechanism. We show that ticket options (where consumers would initially buy an option to buy a ticket and then exercise at a later date) naturally reduce ticket resale significantly and result in significant increases in event organizers' revenues. Furthermore, since a consumer only risks the option price (and not the whole ticket price) if she cannot attend the event, options may face less consumer resistance than paperless tickets...|$|R
50|$|Applications such as {{peer-to-peer}} (P2P) traffic present increasing {{problems for}} broadband service providers. Typically, P2P traffic {{is used by}} applications that do file sharing. These may be any kind of files (i.e. documents, music, videos, or applications). Due to the frequently large size of media files being transferred, P2P drives increasing traffic loads, requiring additional network <b>capacity.</b> Service <b>providers</b> say a minority of users generate large quantities of P2P traffic and degrade performance {{for the majority of}} broadband subscribers using applications such as e-mail or Web browsing which use less bandwidth. Poor network performance increases customer dissatisfaction and leads to a decline in service revenues.|$|R
25|$|Strengthening the <b>capacity</b> {{of service}} <b>providers.</b> This is essential, {{especially}} given the high turnover of senior staff in municipal utilities {{as a result of}} frequent changes in municipal governments. It is important to make municipal service providers more autonomous, to insulate them as much as possible from political influence, and to provide training and a career path for utility employees.|$|R
50|$|The Center for Bronx Nonprofits (CBNP) at Hostos Community College was {{launched}} in 2012 as a community focused resource to meet the capacity building needs of Bronx-serving nonprofit organizations, with collaborative support from the Jewish Community Relations Council (JCRC) and initial funding from the JPMorgan Chase Foundation and The New York Community Trust. CBNP functions as an important support organization to Bronx nonprofits, facilitating opportunities for leadership and organizational development, and technical skills training. Their mission is to positively impact {{the quality of life}} for the members of the Bronx community by strengthening the capacity of Bronx nonprofits.Since its inception, CBNP has positioned itself as the <b>capacity</b> building <b>provider</b> of choice for many Bronx nonprofit leaders and their organizations.|$|R
