2|188|Public
40|$|The {{reasons of}} the {{generation}} of defocus were discussed and the defocus change was analysed from the relative distance, atmospheric pressure and temperature change. The modulation transfer function model was proposed to study the image quality influenced by defocus. Then different defocus value leading image blurry was simulated. The simulation {{results indicate that the}} positive and negative defocus value induced by the relative distance, atmospheric pressure and temperature change can be counteracted. This paper provides an effective data to spatial camera design, <b>compensating</b> <b>measure</b> establishment and performance evaluation. © 2016, Science Press. All right reserved...|$|E
40|$|The Paris Agreement reached {{during the}} COP 21 in December 2015 {{represents}} a timid step towards burden sharing in emission mitigation involving all countries. However, given {{the heterogeneity of}} countries and their relative differences in vulnerability to climate change damage and in mitigation costs, compensating schemes are required to reach an effective agreement. This paper investigates {{the role of the}} Green Climate Fund (GCF) as a potential <b>compensating</b> <b>measure</b> for both adaptation and mitigation actions under a global climate regime. A dynamic climate-economy computable general equilibrium model (GDynEP) is developed by including both a monetary valuation of climate change damage costs and two alternative methods to determine the allocation of GCF resources among receiving countries and between adaptation and mitigation contributions. Results show that, despite the high costs associated with the implementation of mitigation actions, most developing countries would face even higher costs in case of inaction. Furthermore, the preference of a country for an allocation method is strongly influenced by its characteristics and needs. Consequently, a main policy conclusion is to design country-specific sharing rules for GCF in order to maximize country participation in a global agreement...|$|E
5000|$|Enforcing border {{security}} and national <b>compensating</b> <b>measures</b> under the schengen treaty.|$|R
30|$|It is {{important}} to visualize the distributional effects of different measures and also consider relevant <b>compensating</b> <b>measures</b> for groups or regions experiencing the disadvantages of airport structure changes.|$|R
40|$|The Nitrates Sensitive Areas (NSA) Scheme in England was a voluntary, <b>compensated</b> <b>measure</b> from 1990 to 2003 which {{aimed to}} reduce nitrate {{leaching}} from agricultural land to vulnerable groundwaters by modifying land use management. Measurements from 22 NSAs introduced in 1994 / 5 show an overall 34...|$|R
3000|$|Before {{giving the}} {{regularity}} of the mild solution of (2.1), we first need a stochastic Fubini theorem {{with respect to}} <b>compensated</b> Poisson <b>measure.</b> Set [...]...|$|R
40|$|The {{carbon tax}} {{is a major}} {{instrument}} for curbing greenhouse gas emissions that cause global warming. Yet its adoption has been limited because of concerns over its effects on economic growth, income distribution, and international competitiveness. The paper shows that policymakers can minimize {{the effects of the}} tax on economic growth through an efficient recycling of tax revenues and on equity through the adoption of appropriate mitigating or <b>compensating</b> <b>measures.</b> To eliminate the worry about the loss of competitiveness, the paper suggests an international agreement on a coordinated adoption of the tax. ...|$|R
40|$|In {{this paper}} we obtain {{existence}} and uniqueness of solutions of forward stochastic differential equations driven by <b>compensated</b> Poisson random <b>measures.</b> To this end, an Itô-Ventzell formula for jump processes is proved {{and the flow}} properties of solutions of stochastic differential equations driven by <b>compensated</b> Poisson random <b>measures</b> are studied...|$|R
40|$|We prove maximal inequalities for $L_q$-valued martingales {{obtained}} by stochastic integration {{with respect to}} <b>compensated</b> random <b>measures.</b> A version of these estimates for integrals with respect to <b>compensated</b> Poisson random <b>measures</b> were first {{obtained by}} Dirksen (arXiv: 1208 : 3885) using arguments based on inequalities for sums of independent Banach-space-valued random variables, geometric properties of Banach spaces, and decoupling inequalities. Our proofs are completely different and rely almost exclusively on classical stochastic analysis for real semimartingales. Comment: 14 page...|$|R
40|$|People's common {{propensity}} to value losses more than otherwise commensurate gains, {{gives rise to}} different values {{of positive and negative}} changes in entitlements depending on the measure used to assess them. A major implication of the differing valuations is a need to choose an appropriate measure for particular changes. The appropriate choice of measure appears to turn on the reference state that people use to weigh the values of gains and losses: the distinction between the compensating and equivalent variation measures of values. If people view the present state as expected and normal, then the <b>compensating</b> <b>measures</b> apply; the equivalent variation measures are appropriate if they view the changed state as the reference. Endowment effect, welfare measures, valuation...|$|R
40|$|The {{object of}} this paper is to analyse {{economic}} efficiency and equity aspects of the auto-gasoline mileage regulations for 1981 - 1984. The paper uses data available from the US Department of Transportation to estimate both the direct benefits of gasoline and maintenance cost savings and the cost of compliance by the manufacturers. The direct benefit/cost ratios exceed unity and it is concluded that the regulations are cost-effective. The equity aspects are analysed by grouping families according to income groups in the Consumer Expenditure Survey data of the US Bureau of Labor Statistics. The analysis shows that lower income groups owning fewer cars derive fewer benefits, relative to upper income groups, from fuel economy regulations. Income <b>compensating</b> <b>measures</b> such as [`]fuel stamps' are suggested as a way of mitigating this inequity. ...|$|R
40|$|Algorithm {{proposed}} {{for use in}} pulse-code phase-modulation transmitter in which non-return-to-zero (NRZ) or biphase data modulated directly onto radio-frequency residual carrier signal. Devised to compensate somewhat for effect, upon distant receiver, of unbalance in stream of transmitted data. Formulated to compute combinations of modulation index, data rate, and transmitter power <b>compensating</b> for <b>measured</b> unbalance in transmitted data stream...|$|R
50|$|In fluid measurement, the fluid's flow {{conditions}} (or flowing conditions) refer to quantities like temperature and static {{pressure of the}} metered substance. The flowing conditions are required data in order to calculate {{the density of the}} fluid at flowing conditions. The flowing density is in turn required in order to <b>compensate</b> the <b>measured</b> volume to quantity at base conditions.|$|R
40|$|Originally, the Internet {{delivered}} best-effort service quality {{with respect}} to end-to-end delay. Recently, extensions such as RSVP have been proposed to provide guaranteed real-time services as well. Unfortunately, network resources, such as routers, do not yet fully support RSVP reservation protocols so that guarantees cannot truly be given. In this paper, we suggest to follow the paradigm of open programmable networks for a more complete QoS provisioning. Reservation gaps or tunnels are dynamically closed {{by means of a}} software-agent approach that is flexibly deployed for an application oriented QoS support. Agents are dynamically located to such tunnels in order to monitor the tunnels, to provide feed-back information in case of QoS violations, and to decide on possible <b>compensating</b> <b>measures</b> to be taken. Keywords: QoS management, RSVP, Internet, intelligent and mobile agents, open programmable networks. 1 Introduction Quality of service is an increasingly important issue for dist [...] ...|$|R
40|$|Food {{policy and}} rural development. Economic growth does not {{necessarily}} come along with development; even less with food security. Trade expansion bound to economic growth politics isolates populations that {{have no access to}} the market and makes the farmers highly dependent to the variations of yields and prices of agricultural products. Equilibrium between supply and demand of agricultural products observed at the world level is generally not confirmed on the domestic market. Combined effects of population and GNP growth produce as a consequence important inequalities in the food distribution at the regional level. Politics of adjustment with as object increasing economic growth within the framework of free-trade strategy risk to further emphasize householdes disparities. A better welfare distribution can be obtained at regional level by carrying out <b>compensating</b> <b>measures</b> which can only be considered with government assistance. It would {{be the best way to}} reconcile economic growth and food security...|$|R
3000|$|... where a∈R, σ≥ 0, W is a Brownian {{motion and}} N (Ñ) is the (<b>compensated)</b> Poisson random <b>measure</b> {{corresponding}} to X, see Applebaum (2004) or Sato (1999).|$|R
40|$|We {{consider}} {{a family of}} stochastic processes on a metric space T, with a parameter [epsilon][downwards arrow] 0. We study {{the conditions under which}} when one has an a priori estimate on the modulus of continuity and the value at one point. We compare our problem to the celebrated Kolmogorov continuity criteria for stochastic processes, and finally give an application of our main result for stochastic integrals with respect to compound Poisson random measures with infinite intensity <b>measures.</b> <b>Compensated</b> Poisson random <b>measure</b> Generic chaining Kolmogorov continuity criterion Metric entropy Suprema of stochastic processes...|$|R
40|$|Existence and {{uniqueness}} of the mild solutions for stochastic differential equations for Hilbert valued stochastic processes are discussed, with the multiplicative noise term given by an integral {{with respect to a}} general <b>compensated</b> Poisson random <b>measure.</b> Parts of the results allow for coefficients which can depend on the entire past path of the solution process. In the Markov case Yosida approximations are also discussed, as well as continuous dependence on initial data, and coefficients. The case of coefficients that besides the dependence on the solution process have also an additional random dependence is also included in our treatment. All results are proven for processes with values in separable Hilbert spaces. Differentiable dependence on the initial condition is proven by adapting a method of S. Cerrai. Mild solutions of Stochastic Differential Equations Contraction semigroups Pseudo-differential operators Stochastic integrals on separable Hilbert spaces Martingale <b>measures</b> <b>Compensated</b> Poisson random <b>measures</b> Additive processes Random Hilbert valued functions...|$|R
40|$|During cutting, {{machine tools}} are {{influenced}} by different heat sources, which induces machine thermal deformation, deviation and thermal error. In different machine errors, thermal error accounts for 40 %~ 70 % of total machine errors, which is the main influence factor of machining accuracy. In order to reduce machine thermal error and improve machining precision, there are mainly 3 ways at present: 1) Improving machine thermal stiffness by optimal design of machine structure; 2) Separating heat sources from machine tools; 3) Thermal error compensation, which reduces the influence of thermal distortions by predicting and <b>compensating</b> <b>measures.</b> In order to compensate thermal errors, thermal error modeling is the premise and foundation. Therefore, thermal error modeling technology is introduced in this paper firstly, and its recent development {{both at home and}} abroad is analyzed. The main obstacles in thermal error modeling field at present are summerized, and the future of the technology are presented...|$|R
40|$|It is {{expected}} that an energy system faces increasing flexibility requirements in order to cope with increasing contributions from variable renewable energy sources (VRE). In general, the instant balance of temporal and spatial inequalities of the electricity system {{can be achieved by}} many <b>compensating</b> <b>measures.</b> However, a thorough and precise quantification of the flexibility demand of a VRE based energy system {{turns out to be a}} complex task. So far, literature on energy economics and engineering has provided analyses concerning various aspects of the system requirements for flexibility. Accordingly, this review paper primarily aims to categorize the scientific approaches that have been used in "flexibility demand" studies. In this context we classify exemplary study results from the German and European energy systems into technical, economic, and market potential categories to enhance their comparability. Moreover, we conduct a methodological evaluation of the literature findings to determine further research requirements. Against this background we also discuss a conceptual framework to quantify the market potential of flexible technologies...|$|R
40|$|Thermal effects {{impose the}} {{greatest}} {{limit on the}} precision of a ring laser gyro (RLG). Selections of temper-ature sensing points were comparatively discussed based on large numbers of experimental data to improve its precision, and the optimum combination was selected to establish a practical compensating model. The model is applied to new experimental data under the given and varied temperatures. Results show that the bias trend changing with the temperature is basically eliminated and the bias stability is enhanced significantly. OCIS codes: 140. 3370, 060. 2800, 120. 6810, 120. 6780, 070. 6020. Ring laser gyroscope (RLG) {{is a kind of}} optical gyroscope by means of the Sagnac effect, and {{it is one of the}} most ideal devices for the Strapdown Inertial Navigation Sys-tem (SINS). But the temperature characteristic of RLG brings lots of inverse influence and confines the further increase of its precision. Therefore, necessary temper-ature control or temperature <b>compensating</b> <b>measures</b> must be put into practice in order to improve gyroscop...|$|R
40|$|The Netherlands Railways NS {{intends to}} {{increase}} the maximum speed of trains on certain railway sections from 140 to 160 km/h. Higher speeds mean a greater chance on accidents, in particular of collisions with traffic on level crossings, but also a greater chance on derailments of trains. It is intended to avoid this risk by taking <b>compensating</b> <b>measures,</b> especially regarding the safety of level crossings. In this context, {{the policy of the}} NS is that unprotected level crossings or crossings with automatic flashing light installations (AKI's) will not occur on future 160 km/h railway sections anymore. They will be replaced by automatic half-sized barriers (AHOB's) or by multi-level intersections. AHOB's are considered to be safer than unprotected level crossings and AKI's. Compared with AHOB's, multi-level intersections are safer, but more expensive. The Dutch Council for Traffic Safety has ordered SWOV Institute for Road Safety Research to investigate how much these additional costs can be justified by higher savings on damage caused by accidents and favourable side-effects...|$|R
50|$|Jeremiah Bentley {{shows the}} effects of {{incentive}} compensation on surrogation are partially explained by a mechanism in which measure-based incentive compensation (in this case using a single measure) and wealth-maximizing behavior lead agents to distort their operational decisions (see Campbell's law). That operational distortion, in turn, leads them to change their beliefs about the <b>compensated</b> <b>measure's</b> causal relationship with the outcome—in other words, to surrogate—possibly {{as a means of}} reducing cognitive dissonance arising from inconsistency between beliefs and actions. He demonstrates that allowing people to provide narrative explanations for their decisions reduces the amount of operational distortion observed under an incentive compensation scheme, and also reduces surrogation. He also finds that the effect is larger for people who have a high preference for consistency, which supports the argument that surrogation is due to an attempt to reduce cognitive dissonance. Robert Bloomfield had proposed a link between cognitive dissonance and surrogation in an earlier paper.|$|R
40|$|This thesis {{consists}} of two parts. In the first part, we define stochastic integrals w. r. t. the <b>compensated</b> Poisson random <b>measures</b> in a martingale type p, 1 ≤ p ≤ 2 Banach space and establish a certain continuity, in substitution of the Ita isometry property, for the stochastic integrals [...] A version of Ita formula, as a generalization of the case studies in Ikecla and Watanabe [40], is derived. This Itô formula enables us to treat certain Levy processes without Gaussion components. Moreover, using ideas in [63] a version of stochastic Fubini theorem for stochastic integrals W. r. t. <b>compensated</b> Poisson random <b>measures</b> in martingale type spaces is established. In addition, {{if we assume that}} E is a martingale type p Banach space with the q-th, q ≥ p, power of the norm in C 2 -class, then we prove a maximal inequality for a cadlag modification u of the stochastic convolution w. r. t. the <b>compensated</b> Poisson random <b>measures</b> of a contraction Co-semigroups. The second part of this thesis is concerned with the existence and uniqueness of global mild solutions for stochastic beam equations w. r. t. the <b>compensated</b> Poisson random <b>measures.</b> In view of Khas'minskii's test for nonexplosions, the Lyapunov function technique is used via the Yosida approximation approach. Moreover, the asymptotic stability of the zero solution is proved and the Markov property of the solution is verified. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Abstract—On {{the basis}} of researching the fluid flow meter {{calibrating}} method and device, this paper has designed a set of flow meter calibrating system which based on LabVIEW software. It mainly introduces the hardware device, software control system and influence factors of precision test. The system use the software processing method for <b>compensating</b> the <b>measuring</b> error, improve the accuracy of system, and {{reduce the cost of}} system. Keywords-LabVIEW,flowmeter,calibrate,commutator I...|$|R
40|$|The paper {{contains}} analysis of, {{critical remarks}} on, and constructive suggestions to Towards Common Principles of Flexicurtity of the European Commission (2007). The latter promotes relaxing the employment protection legislation while providing advances in employment {{and social security}} for flexible workforces, like fixed-term, part-time and agency workers, or self-employed. The default assumption, that relaxing labour laws can be compensated by these advances, is criticised as the <b>compensating</b> <b>measures</b> are regarded as vague and insufficient. Therefore, some additional measures are proposed to counterbalance the actual flexibilisation of employment relations, including (1) flexinsurance, a kind of progressive flexibilisation tax, meaning that the employer's contribution to social security should be proportional to {{the flexibility of the}} contract/risk of becoming unemployed, (2) elements of the basic minimum income model, (3) workplace tax for worse working conditions of atypically employed which should protect 'the working environment' {{in the same way as}} the green tax protects the natural environment, and (4) constraining financial markets. It is argued that all of these meet interests of social partners and solve contradictions between several European policies. " (author's abstract...|$|R
40|$|An {{electronic}} dispersion compensating with tapped delay-line equalizers are investigated with numerical simulations. The {{focus is}} set on 10 Gbit/s signals that have been distorted by pure chromatic and polarization mode dispersion. The performance of the automatically adaptive equalizers, using the least mean square (LMS) algorithm to provide tap coefficients, are investigated. The equalizers examined are then used to <b>compensate</b> for <b>measured</b> 10 Gbit/s signal from laboratory measurements of 700 km transmission link...|$|R
40|$|The {{problem of}} {{completeness}} of the forward rate based bond market model {{driven by a}} Lévy process under the physical measure is examined. The incompleteness of market in the case when the Lévy measure has a density function is shown. The required elements {{of the theory of}} stochastic integration over the <b>compensated</b> jump <b>measure</b> under a martingale measure is presented and the corresponding integral representation of local martingales is proven. Comment: 25 page...|$|R
40|$|This paper {{evaluates the}} costs of {{inflation}} in Australia and New Zealand using a <b>compensated</b> <b>measure</b> calculated by calibrating a general equilibrium search model in the vein of Lagos and Wright (2005). We look at how inflation affects the intensive margin (the quantity traded in each match) by examining the impact of various pricing protocols. We also look at how inflation affects the extensive margin (the number of trades) by making the market composition between buyers and sellers endogenous. We obtain much larger costs of inflation than existing studies, but smaller costs than similar studies conducted on the US economy. Depending on the version of the model {{the costs of}} 10 % inflation for a $ 50, 000 worker ranges from $ 250 to $ 2200 per year in Australia, and from $ 200 to $ 1700 in New Zealand, that is between 0. 5 % and 4. 4 % of GDP and between 0. 4 % and 3. 4 % of GDP respectively. Finally it is calculated that Australia could gain up to 1. 6 % of GDP per annum [...] 1. 2 % for New Zealand [...] by implementing the Friedman rule. <br /...|$|R
40|$|AbstractThe bolting {{is easy to}} go out {{of force}} in soft coal roadway. Based on the field {{measured}} data, the reason of bolt pre-stressed hysteresis descending in soft coal roadway was analyzed in detail by theoretical analysis and field measurement. Closely encircling the changing law of anchorage force during the bolt bearing course, the reason of the low initial anchorage force in soft coal roadway, the effect of surrounding rock deformation on bolt anchorage force and the circulating hysteresis descending of anchorage force as well as the impact of the structure stability on bearing structure of the bolt-mesh support were analyzed. The analyzed results show there exists a great amount of bolt pre-stress hysteresis descending in soft coal roadway because of remarkable difference between bolt and soft coal deformable capability. Thus, many comprehensive measures should be taken to effectively control the initial loose deformation of non-anchorage rocks between two bolts, to achieve higher initial anchorage force and to prevent anchorage force losing during bolt bearing course. At the same time along with increasing the bolting strength, the structure <b>compensating</b> <b>measures</b> should be taken to ensure the structure stability of the bolt-mesh support and to realize the high-strength stable bolting...|$|R
40|$|In vivo {{analysis}} of the metabolic state of tissue by means of reduced nicotinamide adenine dinucleotide (NADH) fluorimetry is disturbed by tissue movements and by hemodynamic and oximetric effects. These factors cause changes in the absorption of ultraviolet (UV) excitation light by the tissue. Many different methods {{have been used in}} the literature to <b>compensate</b> <b>measured</b> NADH fluorescence intensities for these effects. In this paper we show on theoretical grounds that the ratio of NADH fluorescence intensity and UV diffuse reflectance intensity provides a (semi-) quantitative measure of tissue NADH concentrations. This result is corroborated by experiments with tissue phantoms in which absorption and back-scattering properties were varied. Furthermore, we have verified the validity of this compensation method in isolated Langendorff-perfused rat heart preparations. In this preparation oximetric effects (of blood and tissue) are the major determinants of the metabolism-dependent UV diffuse reflectance change. Hemodynamic effects accompanying compensatory vasodilation are negligible. Movement artifacts were eliminated by simultaneously recording fluorescence and reflectance images, using a CCD camera with a biprism configuration. The results show that the NADH fluorescence/UV reflectance ratio can be used to monitor the mitochondrial redox state of the surface of intact blood-perfused myocardium...|$|R
40|$|This paper {{examines}} {{the impact of}} the availability of fiscal revenues from nonrenewable resources on other revenues of Latin American and Caribbean resource-exporting countries. It compares the performance of nonresource revenues in these countries to that in other countries in the region. The effect of resource revenue on nonresource revenue is found to be negative and statistically significant, with structural breaks both over time and across countries. Nonresource revenues have risen considerably, but they are still lower on average than in comparator countries, and the wedge between both groups of countries has widened over time. They also tend to be more volatile. The paper also analyzes the composition of nonresource revenues. It finds that the performance of VAT and nonresource income taxes of resource exporters has been similar to that of other countries, but revenues from other taxes (including excises) have been lower. The paper's findings have important policy implications. Especially for resource exporters with fiscal vulnerabilities to shocks and sustainability issues, strengthening nonresource revenues would be important to create adequate fiscal space to meet expenditure needs. Oil exporters should also consider phasing out their costly, inefficient, and poorly targeted petroleum subsidies, with <b>compensating</b> <b>measures</b> to protect vulnerable groups. ...|$|R
40|$|Interpretation of 1000 Hz {{tympanometry}} is not standardized. Several <b>compensated</b> and uncompensated <b>measures</b> {{were analyzed}} and compared to otologic findings. Results of auditory brainstem testing and otoacoustic emissions {{were considered to}} better obtain middle ear status. Findings were inconclusive due to small sample size...|$|R
40|$|In Namibia {{historically}} {{high levels}} of support to the commercial farm sector have been reduced {{in recent years in}} line with general market liberalisation trends. However some support remains. At the same time more {{attention has been paid to}} supporting the previously neglected communal sector. The avowed aim of politicians is to ensure that grain producers in Namibia operate â€œon a level playing fieldâ€. This paper examines to what extent the policy support playing field has been levelled for all major types of grain producer in Namibia. A methodology is introduced for developing a common measure of the effects of price support across grain producers with subsistence and commercial objectives and across scales of operation ranging from 1 hectare to 300 hectares under grain crops. The finding show that the bulk of grain producers in Namibia, who farm most of the grain area, remain seriously disadvantaged compared to the fewer, larger farms. Ongoing discussions on outsourcing government support services to small farmers is likely to result in the playing field becoming more uneven and other <b>compensating</b> <b>measures</b> will need to be taken if politicians and decision makers are serious about â€œevening the playing field for allâ€. Agricultural and Food Policy, Crop Production/Industries,...|$|R
40|$|AbstractWe study a {{parabolic}} SPDE {{driven by}} a white noise and a <b>compensated</b> Poisson <b>measure.</b> We first define the solutions in a weak sense, and we prove the existence and the uniqueness of a weak solution. Then we use the Malliavin calculus {{in order to show}} that under some non-degeneracy assumptions, the law of the weak solution admits a density with respect to the Lebesgue measure. To this aim, we introduce two derivative operators associated with the white noise and the Poisson measure. The one associated with the Poisson measure is studied in detail...|$|R
40|$|Using Stein's {{method and}} the Malliavin {{calculus}} of variations, we derive explicit {{estimates for the}} Gamma approximation of functionals of a Poisson measure. In particular, conditions are presented under which the distribution of a sequence of multiple Wiener-Ito stochastic integrals {{with respect to a}} <b>compensated</b> Poisson <b>measure</b> converges to a Gamma distribution. As an illustration, we present a quantitative version and a non-central extension of a classical theorem by de Jong in the case of degenerate U-statistics of order two. Several multidimensional extensions, in particular allowing for mixed or hybrid limit theorems, are also provided...|$|R
