0|42|Public
50|$|Addition of gas to <b>compensate</b> for <b>compression</b> during descent {{is usually}} done by an {{automatic}} diluent valve.|$|R
40|$|An X-band 4 th {{harmonic}} RF {{section is}} used to linearize the bunch compression process in the Linac Coherent Light Source [1]. The optimum voltage is calculated to compensate both for the second-order RF time-curvature, and for the second-order momentum compaction terms. This <b>compensated</b> <b>compression</b> retains, to a much higher degree, the initial temporal distribution of the bunch, reducing the effects of coherent synchrotron radiation [2], and also reduces {{the sensitivity of the}} final compression to bunch arrival time variations...|$|R
40|$|International Telemetering Conference Proceedings / October 29 -November 02, 1990 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe {{ever-increasing}} {{demands of}} the modern telemetry system for the transmission of high resolution digital video data at primary and sub-primary bit rates necessitate the employment of efficient motion-compensated video coding algorithms. This paper reviews {{the current status of}} motion compensation techniques. The two major classes of motion estimation methods currently being used for predictive coding of time varying images: block matching and pel-recursive algorithms are treated in thorough detail. Examples of practical video coding systems using motion <b>compensated</b> <b>compression</b> are exhibited. Recent advances in the VLSI technology have made it possible to fit the entire circuitry required for a motion compensation algorithm onto a single chip...|$|R
50|$|Block {{boundary}} discontinuities {{can occur}} at edges of motion compensation prediction blocks. In motion <b>compensated</b> video <b>compression,</b> the current picture is predicted by shifting blocks (macroblocks, partitions, or prediction units) of pixels from previously decoded frames. If two neighboring blocks use different motion vectors, {{there will be}} a discontinuity at the edge between the blocks.|$|R
40|$|For the {{experimental}} SAR of DLR (E-SAR) a SAR-processor {{was developed to}} perform range and motion <b>compensated</b> azimuth <b>compression.</b> The E-SAR of DLR is described by (Horn, 1989, 1990). The motion compensation processor consists of a range compression module,a motion extraction module, a motion compensation module and an azimuth compression module. The motion extraction module is able to extract the displacement {{in line of sight}} (LOS) direction, the aircraft's drift angle and the forward velocity. In this paper, the motion compensation processor will be described, the off-line/on-line implementation possibilities will be given, followed by practical results...|$|R
30|$|Since {{all of the}} {{discarded}} pixels {{are classified}} into five categories: horizontal, 45 ° diagonal, vertical, 135 ° diagonal, and undefined direction, the directional interpolated frames V_i^l and V_i^r are generated based on this classification. The horizontal pixels are the average of corresponding four nearest corner pixels, and the undefined directional pixels are recovered by vertical interpolation, since the vertical neighbors are the closest to the discarded pixels. For the other three directions’ pixels, they are recovered by linearly interpolation along the pattern direction. In the fourth stage of the proposed upsampling algorithm, the discarded pixels are recovered by fusing the interpolated pixels with the virtual view pixels in order to exploit the advantages of both types of approach and to <b>compensate</b> the <b>compression</b> distortion.|$|R
50|$|A rebreather recirculates the exhaled gas for re-use {{and does}} not {{discharge}} it immediately to the surroundings. The inert gas and unused oxygen is kept for reuse, and the rebreather adds gas to replace the oxygen that was consumed, and removes the carbon dioxide. Thus, the gas in the rebreather's circuit remains breathable and supports life and the diver needs only carry {{a fraction of the}} gas that would be needed for an open-circuit system. The saving is proportional to the ambient pressure, so is greater for deeper dives, and is particularly significant when expensive mixtures containing helium are used as the inert gas diluent. The rebreather also adds gas to <b>compensate</b> for <b>compression</b> when depth increases, and vents gas to prevent overexpansion when depth decreases.|$|R
40|$|ABSTRACT: In this article, {{we address}} the problem of obtaining a {{high-resolution}} (HR) image from a compressed low-resolution (LR) video sequence. Motion information plays a critical role in solving this problem, and we determine which pixels in the sequence provide useful information for calculating the high-resolution image. The bit stream of hybrid motion <b>compensated</b> video <b>compression</b> methods includes low-resolution motion-compensated images; we therefore also study which pixels in these images should be used to increase the quality of the reconstructed image. Once the useful (observable) pixels in the low-resolution and motion-compensated sequences have been detected, we modify the acquisition model to only account for these observations. The proposed approach is tested on real compressed video sequences and the improved performance is re...|$|R
40|$|In this paper, {{we address}} the problem of obtaining a high {{resolution}} (HR) image from a compressed low resolution (LR) video sequence. Motion information plays a critical role in solving this problem and we determine which pixels in the sequence provide useful information for calculating the high resolution image. The bit-stream of hybrid motion <b>compensated</b> video <b>compression</b> methods includes low resolution motion compensated images; we therefore also study which pixels in these images should be used to increase the quality of the reconstructed image. Once the useful (observable) pixels in the low resolution and motion compensated sequences have been detected, we modify the acquisition model to only account for these observations. The proposed approach is tested on real compressed video sequences and the improved performance is reported...|$|R
40|$|Recent {{development}} in the Internet and Web based technologies require faster communication of multimedia data in a secure form. A number of encryption schemes for MPEG have been proposed. In this paper, we evaluate the compression performance of JPEG which has been encrypted with the zig-zag permutation algorithm, suggest a security enhancement to the scheme, and propose an alternative to entropy coding recommended by JPEG to <b>compensate</b> for the <b>compression</b> drop occurring due to permutation...|$|R
40|$|Block {{matching}} is {{a widely}} used method for fast motion estimation. Although using a very simple motion model, which does not fit most real world video material, many motion <b>compensating</b> video <b>compression</b> algorithms use block matching because of its speed. Applications based on true motion vector estimates often use an optical flow algorithm because of their higher need for accuracy {{at the expense of}} increased computing time. This paper presents a modified block matching algorithm suitable for true motion applications. A modified full search will be used on a cost function consisting of SAD and a vector field smoothing term. Several strategies as search center prediction, spiral search, early search termination and multilevel successive elimination are implemented to keep the computational demand low. This way, high-quality estimates can be computed in real-time...|$|R
40|$|In {{this talk}} we will {{describe}} embedded image and video compression techniques. We describe an embedded zero tree-like approach that exploits {{the interdependency between}} color components that is known as Color Embedded Zero Tree Wavelet (CEZW). We will also present a video compression technique, Scalable Adaptive Motion <b>Compensated</b> Wavelet (SAMCoW) <b>compression,</b> that uses the CEZW data structure described above. We show {{that in addition to}} providing a wide range of rate scalability, SAMCoW achieves comparable performance to the more traditional hybrid video coders...|$|R
40|$|Packet and {{compression}} {{losses are}} two sources of quality losses when streaming compressed video over unreliable IP networks, {{such as the}} Internet. In this paper, we propose two new approaches for concealing such losses. First, we present a joint sender-receiver approach for designing transforms in multi-description coding (MDC). In the receiver, we use a simple interpolation-based reconstruction algorithm, as sophisticated concealment techniques cannot be employed in real time. In the sender, we design an optimized reconstruction-based discrete cosine transform (ORB-DCT) with an objective of minimizing the mean squared error, assuming {{that some of the}} descriptions are lost and that the missing information is reconstructed by simple averaging at the destination. Second, we propose an artificial neural network to <b>compensate</b> for <b>compression</b> losses introduced in MDC. Experimental results show that our proposed algorithms perform well in real Internet tests. Keywords [...] - Artificial neural n [...] ...|$|R
40|$|Abstract—In this paper, {{we develop}} a range Doppler {{algorithm}} (RDA) for the tandem bistatic {{synthetic aperture radar}} (BiSAR) configuration. The key step is to use an analytical tandem bistatic spectrum. The proposed algorithm is able to handle reasonably high squint by <b>compensating</b> secondary range <b>compression</b> in the two-dimensional wavenumber domain, and is more robust to focus bistatic data compared with Neo’s RDA based on the spectrum of method of series reversion (MSR) in the tandem configuration particularly when the baseline-range ratio is large. The effectiveness of the proposed algorithm is verified by simu-lations. I...|$|R
40|$|Abstract—Packet and {{compression}} {{losses are}} two sources of quality losses when streaming compressed video over unreliable IP networks, {{such as the}} Internet. In this paper, we propose two new approaches for concealing such losses. First, we present a joint sender-receiver approach for designing transforms in multidescription coding (MDC). In the receiver, we use a simple interpolation-based reconstruction algorithm, as sophisticated concealment techniques cannot be employed in real time. In the sender, we design an optimized reconstruction-based discrete cosine transform (ORB-DCT) with an objective of minimizing the mean squared error, assuming {{that some of the}} descriptions are lost and that the missing information is reconstructed by simple averaging at the destination. Second, we propose an artificial neural network to <b>compensate</b> for <b>compression</b> losses introduced in MDC. Experimental results show that our proposed algorithms perform well in real Internet tests. Index Terms—Artificial neural networks, error concealment, Internet, interpolation-based reconstruction, multidescription coding, video streaming. I...|$|R
40|$|To my husband, Tao, and {{my parents}} Coding and {{transmission}} of images and videos have been a popular but very challenging topic. Traditional coding algorithms are usually designed to optimize compression ratio in an error-free environment {{but not for the}} current Internet that is only a best-effort, packet-switched and unreliable network. This conflict presents a number of challenges for high-quality image and video transmissions. Information loss and bandwidth limitation are two major factors that affect the quality of video streaming. In this thesis, we have developed various error concealment and reconstruction-based rate control schemes to address these two issues. First, we have proposed a sender-receiver based approach for designing a multiple-description video coder that facilitates recovery of packet losses. Second, we have studied artificial neural network-based reconstruction algorithms for <b>compensating</b> nonlinear <b>compression</b> losses due to multiple-description coding. Third, we have employed syntax-based packetization and decoder-side feedback for reducing propagation losses. Last, we have incorporated the reconstruction process in the design and evaluation of rate control schemes...|$|R
2500|$|The {{inflation}} valve is to <b>compensate</b> for air <b>compression</b> on descent. [...] The air {{inside the}} suit is compressed on descent squeezing the suit tightly and painfully onto the diver's body, especially where the suit folds. Suit squeeze also compresses insulating garments, reducing thermal protection, hinders the diver's freedom of movement and interferes with buoyancy control. [...] This is avoided by injecting compensating gas from the breathing gas cylinder, a small, dedicated inflation cylinder or the umbilical, via the inflation valve controlled by the diver. [...] Environmentally sealed suits which are sealed to the helmet automatically equalise from the breathing gas.|$|R
40|$|Abstract — An {{image sensor}} with focal plane based {{hardware}} acceleration of video compression is presented. The 90 × 90 pixel CMOS image sensor provides in-pixel processing of intensity changes, {{serving as an}} analog memory and processor for temporal image difference computation. Surveillance quality videos of up to a 48 : 1 compression ratio via a temporally <b>compensated</b> DCT based <b>compression</b> algorithm is attained with just an 18. 5 MHz micro-controller. Power consumption is 225 mW during full operation and 6 mW during a sleep mode that continuously monitors for change events to trigger encoding. I...|$|R
50|$|The {{inflation}} valve is to <b>compensate</b> for air <b>compression</b> on descent. The air {{inside the}} suit is compressed on descent squeezing the suit tightly and painfully onto the diver's body, especially where the suit folds. Suit squeeze also compresses insulating garments, reducing thermal protection, hinders the diver's freedom of movement and interferes with buoyancy control. This is avoided by injecting compensating gas from the breathing gas cylinder, a small, dedicated inflation cylinder or the umbilical, via the inflation valve controlled by the diver. Environmentally sealed suits which are sealed to the helmet automatically equalise from the breathing gas.|$|R
5000|$|When submerged, {{the water}} {{pressure}} on a submarine's hull can reach [...] for steel submarines {{and up to}} [...] for titanium submarines like , while interior pressure remains relatively unchanged. This difference results in hull compression, which decreases displacement. Water density also marginally increases with depth, as the salinity and pressure are higher. This change in density incompletely <b>compensates</b> for hull <b>compression,</b> so buoyancy decreases as depth increases. A submerged submarine is in an unstable equilibrium, having a tendency to either sink or float to the surface. Keeping a constant depth requires continual operation of either the depth control tanks or control surfaces.|$|R
40|$|The image {{processing}} pipeline of a traditional digital camera is often limited by processing power. A better image quality could be generated only if more complexity was allowed. In a raw data workflow most algorithms are executed off-camera. This allows the use of more sophisticated algorithms for increasing image quality while reducing camera complexity. However, this requires {{a major change in}} the processing pipeline: a lossy compression of raw camera images might be used early in the pipeline. Subsequent off-camera algorithms then need to work on modified data. We analyzed this problem for the interpolation of defect pixels. We found that a lossy raw compression spreads the error from uncompensated defects over many pixels. This leads to a problem as this larger error cannot be <b>compensated</b> after <b>compression.</b> The use of high quality, high complexity algorithms in the camera is also not an option. We propose a solution to this problem: Inside the camera only a simple and low complexity defect pixel interpolation is used. This significantly reduces the compression error for neighbors of defects. We then perform a lossy raw <b>compression</b> and <b>compensate</b> for defects afterwards. The high complexity defect pixel interpolation can be used off-camera. This leads to a high image quality while keeping the camera complexity low...|$|R
5000|$|In 2014, Theropoda Expeditions LLC was {{excavating}} {{a possible}} Gorgosaurus specimen near Havre, Montana. On 16 May, a skid-steer loader removing a twelve metre high overburden unexpectedly hit upon an ankylosaurian tail club. An almost complete ankylosaur skeleton {{proved to be}} present. As {{it had not been}} eroded on the surface, it was in pristine condition. It was found in a turned position, with the belly upwards. The skeleton was largely articulated but the skull and some neck vertebrae were separated from the main torso, while five ribs and the left ilium had shifted from their original position. The company secured the specimen in two main blocks, the largest of which weighed over fifteen tonnes. Its scientific importance was immediately recognised. It was initially identified as a new species of Euoplocephalus. After preparation of the skull and tail section, Theropoda Expeditions offered it for sale. The company nicknamed the specimen [...] "Sherman". In June 2016, it was acquired by the Canadian Royal Ontario Museum. The museum performed a laser scan of the skull, allowing to determine by a process of retro-deformation, <b>compensating</b> for <b>compression</b> of the fossil, its original form. In 2017, even before the torso had been prepared, a preliminary description was published of the skull and tail.|$|R
40|$|In {{the real}} world, most objects do not loose volume when they deform: they may for {{instance}} <b>compensate</b> a local <b>compression</b> by inflating in the orthogonal direction, or, {{in the case}} of a character, preservevolumethroughspecific bulges and folds. Thispaperpresentsanovelextensionto smooth skinning, whichnotonlyoffersanexactcontrol of the object volume, but also enables the user to specify the shape of volume-preserving deformations through intuitive 1 D profile curves. The method, a geometric post-processing to standard smooth skinning, perfectly fits into the usual production pipeline. It can be used whatever the desired locality of volume correction and does not bring any constraint on the original mesh. Severalbehaviorsmimickingthewayrubber-like materials and organic shapes respectively deform can be modeled. An improved algorithm for robustly computing skinning weights is also provided, making the method directly usable on complex characters, even for non-experts...|$|R
40|$|Image Compression reduces {{redundancy}} in {{data representation}} {{in order to}} achieve saving in the cost of storage and transmission. Image <b>compression</b> <b>compensates</b> for the limited on-board resources, in terms of mass memory and downlink bandwidth and thus it provides a solution to the “bandwidth vs. data volume ” dilemma of modern spacecraft. Thus compression is very important feature in payload image processing units of many satellites. A low complexity and high efficiency near-lossless image compression algorithm is suggested in this paper. The algorithm provides the average compression ratio of 1. 403 with high image quality for lossless compression. Compression ratio increases as ∆ parameter increases. Using proposed algorithm compression ratio of 4. 208 is achieved for near-lossless compression. The proposed algorithm has low memory cost suitable for hardware implementation...|$|R
40|$|A {{strategy}} of aeration {{based on the}} direction of continuity wave propagation has been developed to <b>compensate</b> for gas <b>compression</b> in standpipe flow. For the downflow of gas-solid mixture in a standpipe, continuity wave can move either up or down in the pipe. If the continuity wave is in the downward direction, i. e., Type I fluidized flow, tuning of aeration rate should be initiated sequentially from the top. With an upward continuity wave, i. e., Type II fluidized flow, sequential tuning should start from the lower end. For bubbly gas-solid flow in a standpipe, Type I fluidized flow is identified by high solid flowrate and bubbles travelling downwards; Type II fluidized flow is signified by low solid flowrate and bubbles moving upwards. The {{strategy of}} aeration developed here is particularly useful {{as a guide to}} plant operators in controlling operation of tall industrial standpipes...|$|R
40|$|This {{research}} {{deals with}} verification {{of the high}} dynamic range for a heterodyne radio frequency (RF) front end. A 2. 6 GHz RF front end is designed and implemented in a hybrid microwave integrated circuit (HMIC) for worldwide interoperability for microwave access (WiMAX) receivers. The heterodyne RF front end consists of a low-noise amplifier (LNA) with noise cancellation, an RF bandpass filter (BPF), a downconverter with linearization, and an intermediate frequency (IF) BPF. A noise canceling technique used in the low-noise amplifier eliminates a thermal noise and then reduces the noise figure (NF) of the RF front end by 0. 9 dB. Use of a downconverter with diode linearizer also <b>compensates</b> for gain <b>compression,</b> which increases the input-referred third-order intercept point (IIP 3) of the RF front end by 4. 3 dB. The proposed method substantially increases the spurious-free dynamic range (DRf) of the RF front end by 3. 5 dB...|$|R
40|$|International audienceIn {{the real}} world, most objects do not loose volume when they deform: they may for {{instance}} <b>compensate</b> a local <b>compression</b> by inflating in the orthogonal direction, or, {{in the case}} of a character, preserve volume through specific bulges and folds. This paper presents a novel extension to smooth skinning, which not only offers an exact control of the object volume, but also enables the user to specify the shape of volume-preserving deformations through intuitive 1 D profile curves. The method, a geometric post-processing to standard smooth skinning, perfectly fits into the usual production pipeline. It can be used whatever the desired locality of volume correction and does not bring any constraint on the original mesh. Several behaviors mimicking the way rubber-like materials and organic shapes respectively deform can be modeled. An improved algorithm for robustly computing skinning weights is also provided, making the method directly usable on complex characters, even for non-experts...|$|R
40|$|International audienceThe bond-valence {{model was}} {{commonly}} considered as inappropriate to metal cluster compounds, but recently {{it was shown}} that the model provides unique information on the lattice strains and stabilization mechanisms in (TM) (6) -chalcohalides, M-x(TM) (6) L-y (TM = transition metal, L = the chalcogen and/or halogen ligands; M = counter-cation). The previous study was mainly devoted to the non-uniform distribution of the anion valences (bond-valence sums) around clusters. This and the previous paper are focused on two additional phenomena: (i) a steric conflict between counter-cations and the cluster-ligand framework resulting in 'common' lattice strains [previous paper: Levi et al. (2013). Acta Cryst. B 69, 419 - 425], and (ii) steric conflict between the small (TM) (6) -cluster and the large coordination polyhedron around the cluster or so-called matrix effect (this paper). It was shown that both phenomena can be well described by changes in the bond-valence parameters. This paper demonstrates that the matrix effect results in high strains in the TM-L bonds {{in most of the}} (TM) (6) -chalcohalides (TM = Nb, Mo, W and Re). In spite of this, the violations for the total TM valence are minimal, because the cluster stretching is fully or partially <b>compensated</b> by <b>compression</b> of the TM-L bonds. As a result, the influence of the matrix effect on the material stability is rather positive: it decreases the volume of the structural units and in many cases ensures a more favorable distribution of the bond valences around TM atoms, stabilizing the cluster compound...|$|R
50|$|Meanwhile, baroreceptors in the {{aortic arch}} detect the {{increase}} in blood pressure and trigger a parasympathetic response via the Vagus nerve. This induces bradycardia, or slowed heart rate, and signifies {{the second stage of}} the reflex. Bradycardia may also be caused by increased ICP due to direct mechanical distortion of the vagus nerve. Mechanical distortion of the vagus nerve stimulates a parasympathetic response, which can in turn induce bradycardia. Furthermore, this reflexive increase in parasympathetic activity is thought to contribute to the formation of Cushing ulcers in the stomach, due to uncontrolled activation of the parietal cells. The blood pressure can be expected to stay higher than the pressure of the raised cerebral spinal fluid to continue to allow blood to flow to the brain. The pressure will rise {{to the point where it}} overcomes the resisting pressure of the compressed artery and blood is allowed through, providing oxygen to the hypoxic area of the brain. If {{the increase in}} blood pressure is not sufficient to <b>compensate</b> for the <b>compression</b> on the artery, infarction will occur.|$|R
40|$|Vertical drains and {{preloading}} {{are very}} effective and economical ground modification techniques for accelerating primary consolidation and <b>compensating</b> some secondary <b>compression</b> of soft compressible soils. If vertical sand drains are used, {{they can be}} installed at different diameters. The drain diameter required thus becomes a dependent variable in the design process and the drain spacing is determined a priori. The required parameters can be obtained after a few iterations. However, the number of iterations may increase significantly when prefabricated vertical drains or strip drains are used as the drain size is predetermined by manufacturers and available only in a very limited range. Design curves are developed for prefabricated vertical drains in this paper. The equivalent drain diameter is used as the independent variable and drain spacing becomes the dependent variable. Soil smear around the drain is considered but well resistance of the drain is neglected. The curves {{can be used to}} design a vertical drain system without unnecessary iterations and/or interpolations when the equivalent drain diameter, degree of consolidation required, time available, and pertinent geotechnical engineering properties of the soil to be consolidated are given. link_to_subscribed_fulltex...|$|R
40|$|Project (M. S., Electrical and Electronic Engineering) [...] California State University, Sacramento, 2011. As {{technology}} advances, multimedia applications increase exponentially in day-to-day life. Multimedia {{applications such}} as video telephony, video conferencing, TV, streaming video/audio online, and many other applications are in demand in video industry. These applications usually require high bandwidth, large storage, and high latency time to send on network. To conserve resources, it is required to compress the video data before sending them to the network by sender side. It is also required to decompress the video data at receiver end before broadcasting. Many different video codec standards such as H. 261, MPEG- 1, MPEG- 2, H. 263, and H. 264 are implemented. H. 264 is latest international video codec standard. This protocol was developed jointly by International Telecommunication Union ??? Telecommunication Standardization Sector (ITU-T) and International Organization for Standardization (ISO). 	 The objective of this project is to explore different blocks of H. 264 in MATLAB environment. This project first briefly describes about encoding and decoding process, and then it discusses more details about different modules of encoder and decoder, and the related algorithms. Finally, it compares the result of different algorithms based on compression ratio, peak signal to noise ratio, time required for encoding process, and storage. A video file is given as input to encoder, the video file is converted {{to a number of}} frames using video codec, and fixed size macro block is defined in each frame for encoding process. Motion search algorithm finds motion vector after macro block definition, then compensated image is generated based on reference frame and motion vector by video codec. Redundancy is removed from current frame by subtracting <b>compensated</b> image. <b>Compression</b> of residual information is performed using transformation, quantization, and entropy coder. Compressed data are given as inputs to decoder, and decoder process the image to reconstruct image. To enhance image quality and reduce blocking artifact, the image frame is passed through filter. The project is completed successfully by reconstructing video with reasonable quality. Electrical and Electronic Engineerin...|$|R
40|$|A key {{requirement}} {{for a sense}} of presence in Virtual Environments (VEs) is for a user to perceive space as naturally as possible. One critical aspect is distance perception. When judging distances, compression is a phenomenon where humans tend to underestimate the distance between themselves and target objects (termed egocentric or absolute compression), and between other objects (exocentric or relative compression). Results of studies in virtual worlds rendered through head mounted displays are striking, demonstrating significant distance compression error. Distance compression is a multisensory phenomenon, where both audio and visual stimuli are often compressed with respect to their distances from the observer. In this paper, we propose and test a method for reducing crossmodal distance compression in VEs. We report an empirical evaluation of our method via a study of 3 D spatial perception within a virtual reality (VR) head mounted display. Applying our method resulted in more accurate distance perception in a VE at longer range, and suggests a modification that could adaptively <b>compensate</b> for distance <b>compression</b> at both shorter and longer ranges. Our results have a significant and intriguing implication for designers of VEs: an incongruent audiovisual display, i. e. where the audio and visual information is intentionally misaligned, may lead to better spatial perception of a virtual scene...|$|R
40|$|Nonlinear {{frequency}} <b>compression</b> <b>compensates</b> for {{hearing loss}} in frequency ranges where traditional amplification {{on its own}} does not provide sufficient benefit. The effectiveness of Phonak’s proprietary nonlinear frequency compression algorithm, SoundRecover, has been documented for more significant degrees hearing loss (Simpson, Hersbach & McDermott, 2005, 2006; Nyffeler, 2008). The {{purpose of this study}} was to test whether SoundRecover provides sufficient benefit for people with mild to moderate hearing loss. Sufficient benefit is defined as whether the person can more easily recognize quiet, high frequency sounds. This study focused particularly on the /s/ sound. To measure consonant identification, a special test, the Adaptive Logatom Test, was designed that is sufficiently sensitive for cases of mild and moderate hearing loss (i. e. phonemes cannot be discerned on the basis of word or sentence context). The Adaptive Logatom Test was administered using adaptive control of the presentation level, and the respective identification thresholds of various consonants in nonsense syllables (logatoms) were recorded. The identification threshold of the /s/ sound clearly improved with SoundRecover. In addition, subjects reported that listening with SoundRecover was more pleasant than listening without it. A summary of this study was previously published in Phonak Field Study News (April 2009). This article provides the entire study, results and discussion...|$|R
40|$|AbstractThe {{state of}} photosystem II core complex (PS II CC) in {{monolayer}} at the gas-water interface was investigated using in situ polarization-modulated infrared reflection absorption spectroscopy and x-ray reflectivity techniques. Two approaches for preparing and manipulating the monolayers were examined and compared. In the first, PS II CC was compressed immediately after spreading at an initial surface pressure of 5. 7 mN/m, {{whereas in the}} second, the monolayer was incubated for 30 min at an initial surface pressure of 0. 6 mN/m before compression. In the first approach, the protein complex maintained its native α-helical conformation upon compression, and the secondary structure of PS II CC {{was found to be}} stable for 2 h. The second approach resulted in films showing stable surface pressure below 30 mN/m and the presence of large amounts of β-sheets, which indicated denaturation of PS II CC. Above 30 mN/m, those films suffered surface pressure instability, which had to be <b>compensated</b> by continuous <b>compression.</b> This instability was correlated with the formation of new α-helices in the film. Measurements at 4 °C strongly reduced denaturation of PS II CC. The x-ray reflectivity studies indicated that the spread film consists of a single protein layer at the gas-water interface. Altogether, this study provides direct structural and molecular information on membrane proteins when spread in monolayers at the gas-water interface...|$|R
5000|$|In most scuba sets, a {{buoyancy}} compensator (BC) or buoyancy {{control device}} (BCD), {{such as a}} back-mounted wing or stabilizer jacket (also known as a [...] "stab jacket"), {{is built into the}} harness. Although strictly speaking this is {{not a part of the}} breathing apparatus, it is usually connected to the diver's air supply, to provide easy inflation of the device. This can usually also be done manually via a mouthpiece, in order to save air while on the surface, or in case of a malfunction of the pressurized inflation system. The BCD inflates with air from the low pressure inflator hose to increase the volume of the scuba equipment and cause the diver gain buoyancy. Another button opens a valve to deflate the BCD and decrease the volume of the equipment and causes the diver to lose buoyancy. Some BCDs allow for integrated weight, meaning that the BCD has special pockets for the weights that can be dumped easily in case of an emergency. The function of the BCD, while underwater, is to keep the diver neutrally buoyant, i.e., neither floating up or sinking. The BCD is used to <b>compensate</b> for the <b>compression</b> of a wet suit, and to compensate for the decrease of the diver's mass as the air from the cylinder is breathed away.|$|R
40|$|An {{integral}} part of proper wood chip inventory management {{is the ability to}} accurately monitor wood chip quantities. This thesis examines the use of a new method of capturing the volume of mill yard wood chip piles through the utilization of aerial drones. The drones are used to capture images and the images are converted into digital 3 D models, which are then capable of measuring pile volume. This process allows for conversion of the volume into an accurate mass estimate by <b>compensating</b> for <b>compression</b> factors within the chip pile. These factors can change the volume by a maximum of 9. 46 %, but on average during simulations and real world applications, most piles exhibit a change in volume in the range of 1 % to 6 % difference. By performing the estimation procedure multiple times and averaging the results this method is able to generate a result that is more precise, timely and less labour intensive than the previous methods of using a ground survey to determine volume and applying a linear volume to mass conversion for the quantity of wood chips. The results suggest that this averaging technique can improve the standard deviation spread from over 5 % variation in the measurement to less than 2 %. This new method combines multiple techniques to improve both overall accuracy and precision. Each stage of the new method was examined to determine the accumulated degree of error. This included looking at operator error of about 2. 4 %, considering the precision of 3 D volume capture, which adds on average of 5 % to 10 % error, understanding the variation in bulk density due to pile shape, and size, which adds 1 % to 6 % error, using different 3 D software modeling for measuring pile volume, which adds about 4 % error. Combined together in extreme cases, these errors can skew the results by over 20 %. The results of this examination provides research-based recommendations as to how to collect the images, generate the models, and process the data for mass estimation and improve error reduction at all stages...|$|R
