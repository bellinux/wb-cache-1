24|31|Public
5000|$|MEDCIN {{terminology}} engine can {{be easily}} integrated into existing EHRs and legacy systems to enable mapping of existing terminologies and other coding systems such as ICD, DSM, CPT, LOINC, SNOMED CT and the Clinical Care Classification (CCC) System to generate seamless <b>codified</b> <b>data</b> at point of care. [...] MEDCIN’s interoperability features enable easy access and sharing of patient data between health care facilities.|$|E
40|$|Objective. Electronic {{medical records}} (EMRs) are a rich data source for {{discovery}} research but are underutilized {{due to the}} difficulty of extracting highly accurate clinical data. We assessed whether a classification algorithm incorporating narrative EMR data (typed physician notes) more accurately classifies subjects with rheumatoid arthritis (RA) compared with an algorithm using codified EMR data alone. Methods. Subjects with> 1 International Classification of Diseases, Ninth Revision RA code (714. xx) or who had anti–cyclic citrullinated peptide (anti-CCP) checked in the EMR of 2 large academic centers were included in an “RA Mart ” (n � 29, 432). For all 29, 432 subjects, we extracted narrative (using natural language processing) and codified RA clinical information. In a training set of 96 RA and 404 non-RA cases from the RA Mart classified by medical record review, we used narrative and <b>codified</b> <b>data</b> to develop classification algorithms using logistic regression. These algorithms were applied to the entire RA Mart. We calculated and compared the positive predictive value (PPV) of these algorithms by reviewing the records of an additional 400 subjects classified as having RA by the algorithms. Results. A complete algorithm (narrative and <b>codified</b> <b>data)</b> classified RA subjects with a significantly higher PPV of 94 % than an algorithm with <b>codified</b> <b>data</b> alone (PPV of 88 %). Characteristics of the RA cohort identified by the complete algorithm were comparable to existing RA cohorts (80 % women, 63 % anti-CCP positive, and 59 % positive for erosions). Conclusion. We demonstrate the ability to utilize complete EMR data to define an RA cohort with a PPV of 94 %, which was superior to an algorithm using <b>codified</b> <b>data</b> alone...|$|E
40|$|Objective: Electronic {{medical records}} (EMRs) are a rich data source for {{discovery}} research but are underutilized {{due to the}} difficulty of extracting highly accurate clinical data. We assessed whether a classification algorithm incorporating narrative EMR data (typed physician notes) more accurately classifies subjects with rheumatoid arthritis (RA) compared with an algorithm using codified EMR data alone. Methods: Subjects with ≥ 1 International Classification of Diseases, Ninth Revision RA code (714. xx) or who had anti–cyclic citrullinated peptide (anti-CCP) checked in the EMR of 2 large academic centers were included in an “RA Mart” (n = 29, 432). For all 29, 432 subjects, we extracted narrative (using natural language processing) and codified RA clinical information. In a training set of 96 RA and 404 non-RA cases from the RA Mart classified by medical record review, we used narrative and <b>codified</b> <b>data</b> to develop classification algorithms using logistic regression. These algorithms were applied to the entire RA Mart. We calculated and compared the positive predictive value (PPV) of these algorithms by reviewing the records of an additional 400 subjects classified as having RA by the algorithms. Results: A complete algorithm (narrative and <b>codified</b> <b>data)</b> classified RA subjects with a significantly higher PPV of 94 % than an algorithm with <b>codified</b> <b>data</b> alone (PPV of 88 %). Characteristics of the RA cohort identified by the complete algorithm were comparable to existing RA cohorts (80 % women, 63 % anti-CCP positive, and 59 % positive for erosions). Conclusion: We demonstrate the ability to utilize complete EMR data to define an RA cohort with a PPV of 94 %, which was superior to an algorithm using <b>codified</b> <b>data</b> alone. National Library of Medicine (U. S.) (Award U 54 LM 008748) National Institutes of Health (U. S.). i 2 b 2 (Informatics for Integrating Biology and the Bedside) (Grant U 54 -LM 008748...|$|E
50|$|ISO/IEC 19794 Information {{technology}} — Biometric data interchange formats — Part 5: Face image data, or ISO/IEC 19794-5 for short, is {{the fifth}} of 8 parts of the ISO standard ISO/IEC 19794, published in 2005, which describes interchange formats for several types of biometric data. ISO/IEC 19794-5 defines specifically a standard scheme for <b>codifying</b> <b>data</b> describing human faces within a CBEFF-compliant data structure, for use in facial recognition systems. Modern biometric passport photos should comply with this standard. Many organizations and have already started enforcing its directives, and several software applications have been created to automatically test compliance to the specifications.|$|R
40|$|A {{biometric}} system {{is essentially a}} pattern recognition system. It compares the feature set data against the set of templates. Initially the biometric data is acquired from the subject, and from the acquired data the feature sets are extracted, these feature sets are used for comparison. With the ever-growing use of biometrics, it is the utmost need to use standard {{biometric system}}s. The biometric standards simplifies otherwise complicated choices, enables large scale integration, promote longevity and enables interoperability of the biometric systems. ISO/IEC has developed the biometric standards for all modalities. The part- 5 of it contains the Face-Image Format for Data Interchange. It defines specifically a standard scheme for <b>codifying</b> <b>data,</b> describing human faces within a compliant data-structure. In order to enable applications that run {{on a variety of}} devices, including those with limited resources and to improve face recognition accuracy; the specification describes not only the data format, but also additional requirements, namely: scene constraints; photographic properties; digital image attributes...|$|R
40|$|The lack {{of use of}} {{a single}} {{terminology}} across all health systems has led to issues of patient data interoperability. This requires data models to be independent of the terminologies when formalising data representations. The paper discusses the principles to base a middleware system to enable semantic mapping of data in the models to formal biomedical terminologies. The principles have been tested against the MoST system, which maps Archetype data to SNOMED CT codes. At first, contextual and non-contextual methods were applied using lexical and semantic procedures to obtain matches. These automated matches were then presented as candidate mappings to clinical modelers to choose from. The {{aim of the research}} is to enable clinical modelers to quickly and efficiently <b>codify</b> <b>data</b> at the time of modeling the information through automated processes. The research intends to simplify the task of mapping thereby encouraging standardising data at source by alleviating tedious manual lookups performed traditionally by clinicians...|$|R
40|$|Introduction—Prior studies {{identifying}} {{patients with}} {{inflammatory bowel disease}} (IBD) utilizing administrative codes have yielded inconsistent results. Our objective {{was to develop a}} robust electronic medical record (EMR) based model for classification of IBD leveraging the combination of <b>codified</b> <b>data</b> and information from clinical text notes using natural language processing (NLP) ...|$|E
40|$|To access {{publisher}} {{full text}} {{version of this}} article. Please click on the hyperlink in Additional Links field. OBJECTIVES: To test whether data extracted from full text patient visit notes from an electronic medical record would improve the classification of psoriatic arthritis (PsA) compared with an algorithm based on <b>codified</b> <b>data.</b> METHODS: From the > 1, 350, 000 adults in a large academic electronic medical record, all 2318 patients with a billing code for PsA were extracted and 550 were randomly selected for chart review and algorithm training. Using <b>codified</b> <b>data</b> and phrases extracted from narrative data using natural language processing, 31 predictors were extracted and 3 random forest algorithms were trained using coded, narrative, and combined predictors. The receiver operator curve was used to identify the optimal algorithm and a cut-point was chosen to achieve the maximum sensitivity possible at a 90...|$|E
40|$|Background: Previous studies {{identifying}} {{patients with}} {{inflammatory bowel disease}} using administrative codes have yielded inconsistent results. Our objective {{was to develop a}} robust electronic medical record–based model for classification of inflammatory bowel disease leveraging the combination of <b>codified</b> <b>data</b> and information from clinical text notes using natural language processing. Methods: Using the electronic medical records of 2 large academic centers, we created data marts for Crohn’s disease (CD) and ulcerative colitis (UC) comprising patients with ≥ 1 International Classification of Diseases, 9 th edition, code for each disease. We used codified (i. e., International Classification of Diseases, 9 th edition codes, electronic prescriptions) and narrative data from clinical notes to develop our classification model. Model development and validation was performed in a training set of 600 randomly selected patients for each disease with medical record review as the gold standard. Logistic regression with the adaptive LASSO penalty was used to select informative variables. Results: We confirmed 399 CD cases (67 %) in the CD training set and 378 UC cases (63 %) in the UC training set. For both, a combined model including narrative and <b>codified</b> <b>data</b> had better accuracy (area under the curve for CD 0. 95; UC 0. 94) than models using only disease International Classification of Diseases, 9 th edition codes (area under the curve 0. 89 for CD; 0. 86 for UC). Addition of natural language processing narrative terms to our final model resulted in classification of 6 % to 12 % more subjects with the same accuracy. Conclusions: Inclusion of narrative concepts identified using natural language processing improves the accuracy of electronic medical records case definition for CD and UC while simultaneously identifying more subjects compared with models using <b>codified</b> <b>data</b> alone. available in PMC 2014 June 01 National Institutes of Health (U. S.) (NIH U 54 -LM 008748) American Gastroenterological AssociationNational Institutes of Health (U. S.) (NIH K 08 AR 060257) Beth Isreal Deaconess Medical Center (Katherine Swan Ginsburg Fund) National Institutes of Health (U. S.) (NIH R 01 -AR 056768) Burroughs Wellcome Fund (Career Award for Medical Scientists) National Institutes of Health (U. S.) (NIH U 01 -GM 092691) National Institutes of Health (U. S.) (NIH R 01 -AR 059648...|$|E
40|$|SEED Center PaperFinal Report of Task Group MSG- 088. Final Report of Task Group MSG- 088 Data Farming is {{a process}} that has been {{developed}} to support decision-makers by answering questions that are not currently addressed. Data farming uses an inter-disciplinary approach that includes modelling and simulation, high performance computing, and statistical analysis to examine questions of interest with large number of alternatives. Data farming allows for the examination of uncertain events with numerous possible outcomes and provides the capability of executing enough experiments so that both overall and unexpected results may be captured and examined for insights. In 2010, the NATO Research and Technology Organization started the three-year Modeling and Simulation Task Group “Data Farming in Support of NATO” to assess and document the data farming methodology to be used for decision support. This final report documents the completed work of this Task Group, designated MSG- 088. It includes a description of the six realms of data farming as well as the two case studies performed during the course of MSG- 088. This report leverages the knowledge of data farming experts to <b>codify</b> <b>data</b> farming, describing how best to perform data farming to gain insight into questions in support of decision makers...|$|R
40|$|The {{presence}} of enterotoxigenic Bacteroides fragilis and nontoxigenic B. fragilis (NTBF) among 109 strains isolated from 1980 - 2008 in Brazil were investigated by PCR. One strain, representing 0. 9 % {{of the total}} analyzed strains, harbored the bft gene which was identified as bft- 1 isoform based on PCR-RFLP and sequencing. Forty-nine strains (44. 9 %) exhibited the NTBF pattern III which possesses the flanking region required for pathogenicity island acquisition in which the bftgene is <b>codified.</b> These <b>data</b> reinforce the potential of B. fragilis as an emerging enteropathogen in our country...|$|R
40|$|This study {{transforms}} clinical {{narrative in}} three knowledge-rich modalities: case writeup, patient record and online desk reference {{to develop a}} casebase of clinical knowledge useful for medical and health education. We process a medical text corpus through MetaMap Transfer, which discovers UMLS Metathesaurus concepts in text. Our ultimate purpose is to aggregate concepts into knowledge elements for case-based teaching. We structure patient data using Health Level Seven (HL 7) classes. Our initial presentation of the case base is through a web portal comprised of electronic health records and references in Clinical Document Architecture (CDA) form. We introduce health informatics students to examples of <b>codified</b> patient <b>data</b> integrated with explicit knowledge...|$|R
40|$|Abstract: At present, the {{healthcare}} industry uses <b>codified</b> <b>data</b> mainly for billing purpose. <b>Codified</b> <b>data</b> {{could be used}} to improve patient care through decision support and analytical systems. However to reduce medical errors, these systems need access {{to a wide range of}} medical data. Unfortunately, a great deal of data is only available in a narrative or free text form, requiring natural language processing (NLP) techniques for their codification. Structuring narrative data and analyzing their underlying meaning from a medical domain requires extensive knowledge acquired through studying the domain empirically. Existing NLP system like MedLEE has a limited ability to analyze free text medical observations and codify data against Unified Medical Language System (UMLS) codes. MedLEE was successful in extracting meaning from relatively simple sentences from radiological reports, but could not analyze more complicated sentences which appear frequently in medical reports. An important problem in medical NLP is, understanding how many codes or symbols are necessary to codify a medical domain completely. Another problem is determining whether existing medical lexicons like SNOMED-CT and ICD- 9, etc. are suitable for representing the knowledge in medical reports unambiguously. This thesis investigates the problems behind current NLP systems and lexicons, and attempts to estimate the number of required symbols or codes to represent a large corpus of radiology reports. The knowledge will provide a greater understanding of how many symbols may be needed for the complete representation of concepts in other medical domains...|$|E
40|$|The College of Veterinary Medicine (CVM) at Mississippi State University (MSU) has {{implemented}} a Macintosh/HyperCard™ based workstation (HyperVeT) as an interface to its COSTAR™ based medical record system. The workstation supports storage and display of patient demographic and clinical encounter medical information. It's sophisticated, graphics-oriented user interface {{is designed to}} encourage clinician entry of <b>codified</b> <b>data</b> elements selected from logically organized directories of standard medical nomenclature. Communication with the DEC Vax™ resident COSTAR system is accomplished {{in the background and}} is transparent to the user. Methods and strategies for developing this workstation are discussed in light of the academic and clinical environment of the MSU CVM...|$|E
40|$|Metadata is {{structured}} and <b>codified</b> <b>data</b> that describe {{the characteristics of}} an entity that contains information to assist in efforts to identify, locate, assess, and manage entities that are described. There {{are a number of}} metadata standards used in the library. Metadata standards are required for information retrieval, data exchange and interoperability needs. One of the metadata is MODS (Metadata Description Schema Objects). Senayan Library Management System (SLiMS) is an library application well known in Indonesia, even abroad using MODS as metadata. This is due to several advantages of this metadata as to which are described in this article. MODS is expected to be disseminated to the wider community in efforts to develop digital libraries in Indonesia. May the spirit of the advancement of science and technology, especially in the library science improve...|$|E
40|$|Clinical {{auditing}} requires {{structured data}} for aggregation {{and analysis of}} patterns. Clinicians however, need to record clinical encounters in written or spoken language, {{not only for its}} work-flow naturalness but also for its expressivity, precision, and capacity to convey all required information, which <b>codified</b> structured <b>data</b> is incapable of. Therefore, structured data must be obtained from clinical text as a later step, a task known as information extraction. Specialised areas of medicine use their own clinical language and clinical coding systems, resulting in unique challenges for the extraction process. This research is devoted to creating a novel semi-automated method for generating <b>codified</b> auditing <b>data</b> from clinical notes recorded in a neurosurgical department in an Australian teaching hospital. The department has its own audit coding system, and language used in its clinical notes is highly specific to the neurological and neurosurgical domains, which necessitated a customised approach. The principles of Design Science Research were followed to design a method that combines Natural Language Information Extraction and Machine Learning techniques. The method was tested by developing a computer programme that incorporates text extraction algorithms trained and tested on data supplied by the neurosurgical department. The software implements rules initially provided by a domain expert and extended during the development of the software; combined with a custom built machine learning-based prediction system. The software architecture was informed by the requirement for it to be an instantiation of the method, therefore that it should be capable of evaluation within the department’s computer systems. To the author’s knowledge there has been no previous published research addressing the challenges of codifying neurosurgical-specific audit categories from free text. By combining highly specific rules-based information extraction with the weighted word counts of a machine learning component in a unique way, the method demonstrates a unique approach to creating applications that solve this codification problem...|$|R
40|$|Although {{researchers}} {{suggest that}} a systems approach is required to make meaningful advances in the U. S. psychological health care system for service members, limited research has considered such an approach. This research uses an enterprise architecting framework to identify the system's strengths and areas for opportunity {{as they relate to}} the Ecosystem, Stakeholders, Strategy, Process, Organization, Knowledge, Information, and Infrastructure. <b>Codifying</b> qualitative <b>data</b> from publicly available U. S. Defense Health Agency and U. S. Service Branch doctrine, policy guidance, and concepts of operations, our findings indicate that the psychological health care system is strongly process-oriented and mentions a variety of key stakeholders and their roles and responsibilities in the enterprise. Potential opportunities of improvement for the system include a stronger emphasis on the development and transfer of knowledge capabilities, and a stronger information-based infrastructure. Department of Defens...|$|R
40|$|Abstract: Clinicians need {{to record}} {{clinical}} encounters in written or spoken language, {{not only for}} its work-flow naturalness but also for its expressivity, precision, and capacity to convey all required information, which <b>codified</b> structured <b>data</b> is incapable of. Therefore, the structured data which is required for aggregation and analysis must be obtained from clinical text as a later step. Specialised areas of medicine use their own clinical language and clinical coding systems, resulting in unique challenges for the extraction process. Rule-based information extraction techniques have been used effectively in commercial systems and are favoured because they are easily understood and controlled. However, there is promising research into the use of machine learning techniques for extracting information, and this research explores the effectiveness of a hybrid rule-based and machine learning-based audit coding system developed for the neurosurgical department of a major trauma hospital...|$|R
30|$|In {{relational}} operations (R), {{according to}} Gadrey’s typology, {{the object of}} the service operation is the customer himself, in a direct contact service. In our case of freight transport services, this type of operations is difficult, if not impossible, to identify, especially in large, <b>codified</b> <b>data</b> sets such as the ECHO survey. In our case studies in the Nord-Pas-de-Calais Region, we could however identify some cases where this type of operation applies. The object of the relational service operation is, in these cases, the relation between the shipper’s and his customer, in which the transport firm plays a particular role. This is mainly the case for transport firms that operate frequent dedicated delivery tour type operations on a regular basis for a given shipper. The transport service provider has the only direct contact to the customer and can give important feedback on quality issues and customer satisfaction.|$|E
40|$|Clinical {{data that}} may be used in a {{secondary}} capacity to support research activities are regularly stored in three significantly different formats: (1) structured, <b>codified</b> <b>data</b> elements; (2) semi-structured or unstructured narrative text; and (3) multi-modal images. In this manuscript, we will describe the design of a computational system that is intended to support the ontology-anchored query and integration of such data types from multiple source systems. Additional features of the described system include (1) the use of Grid services-based electronic data interchange models to enable the use of our system in multi-site settings and (2) the use of a software framework intended to address both potential security and patient confidentiality concerns that arise when transmitting or otherwise manipulating potentially privileged personal health information. We will frame our discussion within the specific experimental context of the concept-oriented query and integration of correlated structured data, narrative text, and images for cancer research...|$|E
40|$|Clinical {{auditing}} requires <b>codified</b> <b>data</b> for aggregation {{and analysis}} of patterns. However in the medical domain obtaining structured data can be difficult as the most natural, expressive and comprehensive way to record a clinical encounter is through natural language. The task of creating structured data from naturally expressed information is known as information extraction. Specialised areas of medicine use their own language and data structures; the translation process has unique challenges, and often requires a fresh approach. This research is devoted to creating a novel semi-automated method for generating codified auditing data from clinical notes recorded in a neurosurgical department in an Australian teaching hospital. The method encapsulates specialist knowledge in rules that instantaneously make precise decisions {{for the majority of}} the matches, followed up by dictionary-based matching of the remaining text. Comment: ISBN# 978 - 0 - 646 - 95337 - 3 Presented at the Australasian Conference on Information Systems 2015 (arXiv: 1605. 01032...|$|E
40|$|In {{this paper}} we propose a model of {{encoding}} data into DNA strands so that this data can be used in the simulation of a genetic algorithm based on molecular operations. DNA computing is an impressive computational model that needs algorithms to work properly and efficiently. The first problem when trying to apply an algorithm in DNA computing must be how to <b>codify</b> the <b>data</b> that the algorithm will use. In a genetic algorithm the first objective must be to codify the genes, which are the main data. A concrete encoding of the genes in a single DNA strand is presented and we discuss what this codification is suitable for. Previous work on DNA coding defined bond-free languages which several properties assuring the stability of any DNA word of such a language. We prove that a bond-free language is necessary but not sufficient to codify a gene giving the correct codification...|$|R
40|$|This study {{investigates the}} {{relationship}} between the motion of the first ten costovertebral joints (CVJ) and lung volume over the inspiratory capacity (IC) using detailed kinematic analysis in a sample of 12 asymptomatic subjects. Retrospective <b>codified</b> spiral-CT <b>data</b> obtained at total lung capacity (TLC), middle of inspiratory capacity (MIC) and at functional residual capacity (FRC) were analysed. CVJ 3 D kinematics were processed using previously-published methods. We tested the influence of the side, CVJ level and lung volume on CVJ kinematics. In addition, the correlations between anthropologic/pulmonary variables and CVJ kinematics were analysed. No linear correlation was found between lung volumes and CVJ kinematics. Major findings concerning 3 D kinematics can be summarized as follows: 1) Ranges-of-motion decrease gradually with increasing CVJ level; 2) rib displacements are significantly reduced at lung volumes above the MIC and do not differ between CVJ levels; 3) the axes of rotation of the ribs are similarly oriented for all CVJ levels. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|The musical {{involvement}} {{of people over}} the centuries is fundamentally interwoven with spiritual experiences (Seifert 2011). This paper discusses the connection between music and spirituality in an inter-denominational group in the southeastern suburbs of Melbourne. With ethical clearance, through semi-structured interviews with two church leaders and the music worship team, subsequently employing Interpretative Phenomenological Analysis (IPA), I analysed and <b>codified</b> the <b>data</b> gathered. Two overarching themes are discussed: insights into music and spirituality; and connecting music to worship with self and others. The findings show that music in worship may provide a rich pathway for people to explore, experience, and express their spirituality, and to connect to the wider multicultural society. It also adds to the current debates on whether music has spiritual significance for some people apart from community expressions of spirituality through music. Limitations {{of the current study}} are knowledged and generalizations cannot be made regarding connections to music and spirituality. However, the findings do indicate that music in worship can enrich one’s spiritual experience and connection with God and others...|$|R
40|$|TaLTaC 2 (T 2) is a ‘metric’ {{software}} for the automatic analysis of texts of various types (collections of documents and fragments, short texts from surveys, websites etc.). T 2 allows for both a lexical and a textual treatment, and for the full integration of (unstructured) textual data with (structured) <b>codified</b> <b>data</b> - the latter associated with the units of context. The lexical unit of the analysis is mixed, both words and multiwords. The search and extraction of information exploits statistico-linguistic resources – both standard and tailor-made – as well as weighing criteria of a statistical and quantitative nature. Linguistic and semantic annotations are also employed. This allows the user to individuate keywords and elements of terminology {{at the level of}} the whole corpus, of parts of it and of single units of context. The results can be exported via matrices, and this makes multi-dimensional analyses possible that express associations between words and latent sense models...|$|E
40|$|The Quick Scan Audit Methodology (QSAM) is {{a supply}} chain {{business}} diagnostic. The QSAM has both an Action Learning and a Management Theory stream. The former is concerned with evaluating the operating characteristics and performance of specific value streams. The latter builds on <b>codified</b> <b>data</b> emanating from a sample of QSAM outputs to statistically evaluate any possible contributions to new management theory. During such research other powerful outputs including delineation of best practice and identification of preferred, successful, trajectories for change emerge. Originally developed to suit research needs when studying European Automotive First Tier Suppliers it was also tested on other European value streams. Recent opportunities have arisen to apply QSAM more widely. To date the major contribution from QSAM studies on other continents is restricted to the action learning mode by minimum sample size considerations. The latter will be satisfied in due course. This paper presents the background and modus operandi of the QSAM plus new action learning lessons arising from internationalising the supply chain diagnostic...|$|E
40|$|The Linked Data {{initiative}} {{offers a}} straight method to publish structured {{data in the}} World Wide Web and link it to other data, resulting in a world wide network of semantically <b>codified</b> <b>data</b> known as the Linked Open Data cloud. The size of the Linked Open Data cloud, i. e. the amount of data published using Linked Data principles, is growing exponentially, including life sciences data. However, key information for biological research is still missing in the Linked Open Data cloud. For example, the relation between orthologs genes and genetic diseases is absent, even though such information {{can be used for}} hypothesis generation regarding human diseases. The OGOLOD system, an extension of the OGO Knowledge Base, publishes orthologs/diseases information using Linked Data. This gives the scientists the ability to query the structured information in connection with other Linked Data and to discover new information related to orthologs and human diseases in the cloud...|$|E
40|$|The Australian Government {{recognizes that}} the Arts are a {{critical}} part of formal school education and it should not be viewed as subordinate or extra. This paper forms part of a wider research project titled “Pre-service teacher attitudes and understandings of Music Education” that started in 2013. The focus of this paper investigates music teaching and learning in a core unit within the Bachelor of Education (Primary) course at Deakin University (Australia). Using questionnaire and interview data gathered in 2014, I employ Interpretative Phenomenological Analysis to analyse and <b>codify</b> the <b>data.</b> Three themes are discussed in relation to: Why it is important to include music in the primary school? What was enjoyable and what aspects were challenging in the music workshops? What can students integrate as generalist teachers into their future classrooms? Though the findings focus on “we did the how to teach it”, it also highlights some challenges and opportunities for students and staff. Tertiary educators are challenged to raise the capacity and status of music when preparing students to translate the music curriculum into their future classrooms...|$|R
40|$|The {{conceptual}} {{foundation for}} my creative thesis work {{is based in}} research into the development of science, particularly the field of cosmology, and its related visual vocabulary. Three interrelated projects encompass my interests in unique artists 2 ̆ 7 books and variable editions, research based projects, <b>codified</b> presentation of <b>data,</b> and universal interconnectedness, or oneness in all things, {{that was at the}} heart of medieval cosmology and is embraced by some 21 st century subcultures. The thematic timeline of the artwork spans developments in the Early Middle Ages related to astronomy and cosmology and through 20 th century guidebooks and NASA 2 ̆ 7 s social media accounts. The resulting artwork includes an artist 2 ̆ 7 s book, sculptural bookwork, monoprints, and an edition of broadsides...|$|R
40|$|In {{this work}} {{the onset of}} the "Little Ice Age" period in Andalusia (southern Spain) is {{analysed}} from documentary data, focusing attention on the evolution of the climate during the 16 th and 17 th centuries. It is shown that changes in the rainfall regime have been more important than those in the temperature in studying the Andalusian climate change. Analysis of the total annual precipitation is carried out by <b>codifying</b> the documentary <b>data</b> and establishing an ordinal index. Several statistical methods are used to detect and characterize climate changes in the region. The results suggest a fluctuating evolution, without trends or abrupt changes, with a prevailing wet period from 1550 to 1650 AD. Cycles of ~ 17, 3. 5 and 2. 1 years are detected. Some possible causal mechanisms are suggested...|$|R
40|$|The {{domain of}} {{knowledge}} {{we have been}} able to examine by secondary analysis contained 250 discrete items of information requested in American national surveys between 1949 and 1971. Since the influence of education on each item (with a few exceptions) is examined separately for each of four age cohorts, our fundamental findings involve about a thousand sets of comparisons of knowledge among several educational levels. How to present such massive evidence creates a severe problem. Compression and condensation are essential if the reader is not to become submerged and finally drown in the ocean of data. In a letter to the New York Times, one poor soul who had waded through the Coleman report, survived then to read Jencks 2 ̆ 7 s work, only finally to confront the recent multi-volume report of the International Association for the Evaluation of Educational Achievement, put the problem poignantly: 2 ̆ 2 The voice of reason is overwhelmed by the vast array of <b>codified</b> <b>data</b> 2 ̆ 2 (9 June, 1973, p. 32) ...|$|E
40|$|Inspired by the {{researchers}} ' own experiences involving and teaching {{in junior high school}} English program in Iran, this study aims at evaluating the program. To fulfill the objectives, the study benefits from SWOT (Strengths, Weaknesses, Opportunities and Threats) analysis to present an overall picture of the program. Twenty experienced teachers and members of educational groups involved in the program were selected based on purposive sampling who were supposed to be representative of the accessible population. They were interviewed and their views about the program were meticulously recorded. Using Grounded Theory approach, the data were codified in three phases of open, axial and selective coding. The <b>codified</b> <b>data</b> were the SWOT of the program that was presented in a number of Tables. The interpreted results were presented in some Graphs and Tables, too. The researchers concluded that the program more suffers from weaknesses and is threatened by several threats than it enjoys the strengths or takes advantage of the opportunities. To improve the program, the stakeholders and users of the program should take advantage of the strengths, compensate for weaknesses, avoid threats and tap on the opportunities. For this to be fulfilled, several strategies and solutions are available, a sample of which is presented {{at the end of the}} study...|$|E
40|$|The {{purpose of}} this {{qualitative}} {{study was to identify}} the classroom management needs of graduate education students in one college, and develop a seminar that emerged from the research. Researchers have shown that professional development provided for graduate education students typically deals with curriculum and instructional methodologies rather than classroom management. However, graduate education students have expressed the need to learn more effective classroom management skills. The research questions asked what classroom management skills participants said they needed to teach in both collaborative, and special education classrooms. A grounded theory approach and the constructivist paradigm were used in the study. Interviews and focus groups employing a purposive sample of 12 graduate education students were used to determine core phenomena where participants were able to help shape and construct a seminar in classroom management. The results of the <b>codified</b> <b>data</b> concluded that participants lacked skills and wanted to be trained in the meaning of effective teacher engagement with students, collaboration with other professionals, effective use of class rules and procedures, helping students understand consequences for misbehavior, and managing classroom disruptions. The research generated a 3 -hour seminar for special education or general education graduate students. The results gathered during the development of the seminar suggest that the content and presentation will help graduate education students foster social change by developing skills to effectively manage their classes. Additionally, the study can contribute to social change by affording participants classroom management skills necessary to create safe and nurturing school environments that have the potential to positively impact student achievement...|$|E
40|$|Prisons remain one of {{the social}} service {{agencies}} of last resort for women. Female prisoners are often disproportionately women of color, who are survivors of physical and/or sexual abuse as children and adults, with significant substance abuse problems, mental health problems, and low attainment of educational, vocational, and employment success, and with fragmented family histories including intergenerational involvement with the criminal justice system. However, understanding how these gendered characteristics are associated with prison program participation remains unclear {{as there is a}} lack of emphasis on the factors that help explain prisoners’ patterns of participation in prison programs. Understanding factors that are associated with participation in prison programs is important as some programs have been associated with recidivism reduction. This dissertation examined the characteristics associated with prison program participation among female prisoners. It used <b>codified</b> interview <b>data</b> from state inmates in the 2004 Survey of Inmates in State and Federal Correctional Facilities. Hierarchical logistic regressions were used to evaluate the odds that a female prisoner had participated in a prison program given her pattern of response to questions about her demographics, static (unchanging) and dynamic (malleable) criminogenic characteristics, gender-responsive characteristics, and intergenerational characteristics. Hierarchical logistic regressions were performed on participation on seven types of prison programs (religious, visitation, vocational/educational, self-help, prerelease, drug and alcohol, mental health). This study found that for females’ participation in prison programs, 7...|$|R
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. The {{purpose of this study}} was to collect and <b>codify</b> <b>data</b> from a sample of the Warrington census enumerators' books for 1841, 1851, 1861, 1871 and 1881. Main Topics : 1841 Number of persons in household; first name; surname; sex; age; marital status; relationship to head of household; occupation, rank or profession; industry of employment; socio-economic status; place and county of birth; distance of birth place from Warrington; medical infirmities; employment status; enumeration district; address. 1851 Number of persons in household; first name; surname; sex; age; marital status; relationship to head of household; occupation, rank or profession; industry of employment; socio-economic status; place, county and region of birth; distance of birth place from Warrington; medical infirmities; employment status; age bands; social class; sector of economy; lodgers; industries; characteristics of birthplace; enumeration district; address; family size; household composition including servants and other employees; degree of risk to household and women. 1861 Number of persons in household; first name; surname; sex; age; marital status; relationship to head of household; occupation, rank or profession; industry of employment; socio-economic status; place and county of birth; distance of birth place from Warrington; medical infirmities; employment status; enumeration district; address. 1871 Number of persons in household; first name; surname; sex; age; marital status; relationship to head of household; occupation, rank or profession; industry of employment; socio-economic status; place, county and region of birth; distance of birth place from Warrington; medical infirmities; employment status; enumeration district; address; age bands; social class. 1881 Number of persons in household; first name; surname; number in family and nuclear family; relationship to head of household; marital status; sex; age; occupation, rank or profession; industry of employment; socio-economic status; place and county of birth; distance of birth place from Warrington; medical infirmities; employment status; address; owner occupiers; description of property; rate payers and rates; rents; comments about household; number of rooms; sex ratios; age bands; social class; sector of economy; family size; household composition including servants and other employees; degree of risk to Household and women. In addition to the Warrington census material, the dataset includes a parish listing for Stoke-upon-Trent in 1701. These data include: number of individuals and communicants in the household; first name, surname, sex, relation to head of household, and age of individuals listed. Occupational classifications: The occupations classifications are based on two schemes: Industrial Classification The industrial classification used is the Booth-Armstrong classification which was developed in the 1880 s by Charles Booth and modified by W. A. Armstrong. Social Class Classification The social class classification used is based on the Registrar General's Classification of Occupations: 1951 and uses the modifications suggested by W. A. Armstrong. Armstrong, W. A. (1972) 'The use of information about occupation' IN E. A. Wrigley (ed) Nineteenth century society: essays in the use of quantitative methods for the study of social data Cambridge: Cambridge University Press, pp. 191 - 310...|$|R
40|$|Biomedicine is {{a pillar}} of the collective, {{scientific}} effort of human self-discovery, {{as well as a}} major source of humanistic <b>data</b> <b>codified</b> primarily in biomedical documents. Despite their rigid structure, maintaining and updating a considerably-sized collection of such documents is a task of overwhelming complexity mandating efficient information retrieval for the purpose of the integration of clustering schemes. The latter should work natively with inherently multidimensional data and higher order interdependencies. Additionally, past experience indicates that clustering should be semantically enhanced. Tensor algebra is the key to extending the current term-document model to more dimensions. In this article, an alternative keyword-term-document strategy, based on scientometric observations that keywords typically possess more expressive power than ordinary text terms, whose algorithmic cornerstones are third order tensors and MeSH ontological functions, is proposed. This strategy has been compared against a baseline using two different biomedical datasets, the TREC (Text REtrieval Conference) genomics benchmark and a large custom set of cognitive science articles from PubMed...|$|R
