41|1|Public
5000|$|Several {{organizations}} {{exist to}} set standardizations for <b>connectability</b> between individual layout sections (commonly called [...] "modules"). This is so several (or hundreds, given enough space and power) people or groups can bring together their own modules, connect {{them together with}} as little trouble as possible, and operate their trains. Despite different design and operation philosophies, different organizations have similar goals; standardized ends to facilitate connection with other modules built to the same specifications, standardized electricals, equipment, curve radii.|$|E
50|$|The Red Jade was Ericsson's {{unreleased}} handheld console, {{intended to}} compete with the Game Boy Advance. Originally the developing team for the Red Jade approached Sony and Sega as potential partners but both declined. Ericsson decided to invest US$10 million in the Red Jade, which was supposed to have PDA functions, wireless <b>connectability,</b> DivX movies, cell phone capabilities, a GPS server, a digital camera, MP3 audio playback, a web browser, the ability to download games from the website, game sharing utilizing Bluetooth technology, and graphics equivalent to the PlayStation. It was to be released in late 2001 and would have retailed for $150. When overall sales plummeted, Ericsson cancelled the Red Jade before production in April 2001 and cut 22,000 employees to help minimize losses. The number of existing prototype units is unclear along with possibility of games made for them. Ericsson's mobile phone division later divested into joint venture with Sony and rebranded as Sony Ericsson, until Sony acquired Ericsson's share and became Sony Mobile Communications.|$|E
5000|$|When IBM {{initially}} {{moved into}} the Data Processing world, each computer was a stand-alone machine with limited stored program capability with little interaction with other devices or software. The only support documentation was a manual of operation outlining the basic capabilities of the computer. The technical specifications were restricted in their distribution and rarely available to users. With the advent of System/360 in 1964 with their <b>connectability</b> to various I/O components and their associated software, their installation and their very usage rapidly became a challenge. Hands-on training was no longer just for the installation and maintenance professionals (Customer Engineers) but a necessity for the IBM System Engineers who ran and coded the systems. While the system engineers in the US Company had some access to the technical skills available in the Poughkeepsie Plant where the systems were built, the World Trade Division (the 131 countries outside of the US where IBM did business) had no such fall-back capability.|$|E
40|$|Morphological {{analysis}} of Japanese {{is very different}} from that of English, because no spaces are placed between words. The analysis includes segmentation of words. However, ambiguities in segmentation is not always resolved only with morphological information. This paper proposes a method to integrate the morphological and syntactic analysis based on LR parsing algorithm. An LR table derived from grammar rules is modified on the basis of <b>connectabilities</b> between two adjacent words. The modified LR table reflects both the morphological and syntactic constraints. Using the LR table, efficient morphological and syntactic analysis is available. 1 Introduction Morphological {{analysis of}} Japanese {{is very different from}} that of English, because no spaces are placed between words. This is also the case in many Asian languages such as Korean, Chinese, Thai and so forth. In the Indo-European family, some languages such as German have the same phenomena in forming complex noun phrases. Processing [...] ...|$|R
5000|$|The harsh {{atmosphere}} {{of this region}} is clear, but its remoteness also creates a dreamlike nature that accentuates the metaphysical crisis the protagonist is experiencing. The plot follows the ascension of a man up a deep ravine where he plans to commit suicide, but is finally saved when he {{falls in love with}} Ascen (short for Ascension), an old religious and indigenous woman with whom he ultimately has sexual relations. The relation between these two characters has an clear allegorical significance that goes beyond its pure physicality and exposes the ultimate aim of an encounter, the true purpose of all human <b>connectability.</b> In this respect, although Japón focuses on the inner problems of a single individual, and the protagonist's relation both with the old woman and with the rustic surrounding where the story takes place, in its core it [...] "reveals the potential that cinema has to be truly cosmopolitan, {{to the extent that it}} gives us structures for developing empathy towards the foreign and the unfamiliar, and for understanding more deeply the divide between self and other.".|$|E
50|$|The V.Smile Pocket's direct {{competition}} is the handheld Leapster by LeapFrog. The Leapster TV Learning System is the less high-profile but available counterpart to the multiple V.Smile and V-Motion consoles that are direct connect to TV. The Leapster L-Max {{is comparable to}} the V.Smile Cyber Pocket and is stylus-enhanced. Vtech has the advantage in number and diversity of available accessories such as SmartBooks and Art Studio, whereas Leapfrog's Leapster accessories are generally focused on portability options such as batteries and cases. The V.Smile family in general is more focused on TV <b>connectability,</b> while the Leapster family is more focused on the handheld, portable systems, but both V.Tech and Leapster have moved to compete with one another on both fronts. Leapster systems and games tend to be slightly more expensive than V.Smile games. The Leapster does have an age range for some games that reaches up to age 11, which is territory more for the V-Flash than the V.Smile. Noteworthy is that both Leapfrog and V.Tech continue to sell previous generation handhelds at a reduced price compared to the Leapster 2 and New V.Smile Pocket.|$|E
40|$|Kogo and Wagemans {{provide an}} {{intriguing}} way of assigning a polarity value to closed edges in fragmented images (solving the border ownership problem), but their model lacks generality and disregards <b>connectability</b> as a relevant aspect of visual completion. The lack of generality depends on considering concave disk sectors (pacmen) {{as the main}} inducers of illusory contours. <b>Connectability</b> is crucial for defining the occurrence, the salience and the shape of completed contours. A complete theory of completion should integrate border ownership and <b>connectability,</b> rather than emphasizing one aspect over the other...|$|E
40|$|In {{this paper}} we define a general class of {{problems}} in computational geometry that we cal <b>connectability</b> problems. <b>Connectability</b> problems involve connecting objects by some kind of connections, avoiding obstacles. This includes {{many different types of}} problems like intersection problems, visibility problems, etc. Studying these problems in a general framework might led to general solutions. Some solutions axe presented. In paxticulax, an O(nlog nlogiog n) solution is given for determining al pairs of points in a set that can be connected with an axis-paxallel rectangle, avoiding a set of obstacle points...|$|E
40|$|Prépublication LIPNWe study {{conditions}} for a concurrent construction of proof-nets in the framework developed by Andreoli in recent papers. We define specific correctness criteria for that purpose. We first study closed modules (i. e. validity of the execution of a logic program), then extend the criterion to open modules (i. e. validity during the execution) distinguishing criteria for acyclicity and <b>connectability</b> {{in order to allow}} incremental verification...|$|E
40|$|Verbs expressing {{economic}} growth and decline {{are an important part}} of business language. The rules for their semantic <b>connectability</b> are hard to determine, even for native speakers. Partial rules for the use of some of them are formulated in this article. Alot of the metaphorically used verbs are not to be found in our dictionaries. They appear in the business language, especially for stylistic reasons. verbs of growth and decline, rules of their use, business language...|$|E
40|$|A robust {{approach}} for automatically extracting roads from overhead images is developed in this paper. The first step involves extracting a very dense set of edge pixels using a technique {{based on the}} magnitude and direction of pixel gradients. In step two, the edges are separated into successive channels of edge orientation that each contain edge pixels whose gradient directions lie within a different angular range. A de-cluttered map of edge curve segments is extracted from each channel, {{and the results are}} merged into a single composite map of broken edge curves. The final step divides broken curves into segments that are nearly linear and classifies each segment as connected at both ends or disconnected. A measure of <b>connectability</b> between two disconnected line segments based on proximity and relative alignment is defined mathematically. Each disconnected segment is paired with the disconnected segment that it is most connectable to. Pairs of segments are merged if their separation and misalignment are below thresholds (manually specified at present) and the <b>connectability</b> of the pair is two-way optimal. Extended curve and road extraction examples are provided using commercial overhead images...|$|E
40|$|The {{question}} whether distant simultaneity (relativized to an inertial frame) has a fac-tual or a conventional status in special relativity {{has long been}} disputed and remains in contention even today. At one point it appeared that Malament (1977) had settled the issue by proving that the only non-trivial equivalence relation definable from (tempo-rally symmetric) causal <b>connectability</b> is the standard simultaneity relation. Recently, however, Sarkar and Stachel (1999) claim to have identified a suspect assumption in the proof by defining a non-standard simultaneity relation from causal <b>connectability.</b> I contend that their critique {{is based on a}} misunderstanding of the criteria for the de-finability of a relation, a misunderstanding that Malement’s original treatment helped to foster. There are in fact a variety of notions of definability that can be brought to bear. They all, however, require a condition that suffices to secure Malament’s result. The non-standard relation Sarkar and Stachel claim to be definable is not so definable, and, I argue, their proposal to modify the notion of “causal definability ” is misguided. Finally, I address the relevance of Malament’s result to the thesis of conventionalism. 1. Introduction. I...|$|E
40|$|The ambitious aim of CONNECT is {{to achieve}} {{universal}} interoperability between heterogeneous Networked Systems by means of on-the-fly synthesis of the CONNECTors through which they communicate. The goal of WP 5 within CONNECT {{is to ensure that}} the non-functional properties required at each side of the connection going to be established are fulfilled, including dependability, performance, security and trust, or, in one overarching term, <b>CONNECTability.</b> To model such properties, we have introduced the CPMM meta-model which establishes the relevant concepts and their relations, and also includes a Complex Event language to express the behaviour associated with the specified properties. Along the four years of project duration, we have developed approaches for assuring <b>CONNECTability</b> both at synthesis time and at run-time. Within CONNECT architecture, these approaches are supported via the following enablers: the Dependability and Performance analysis Enabler, which is implemented in a modular architecture supporting stochastic verification and state-based analysis. Dependability and performance analysis also relies on approaches for incremental verification to adjust CONNECTor parameters at run-time; the Security Enabler, which implements a Security-by-Contract-with-Trust framework to guarantee the expected security policies and enforce them accordingly to the level of trust; the Trust Manager that implements a model-based approach to mediate between different trust models and ensure interoperable trust management. The enablers have been integrated within the CONNECT architecture, and in particular can interact with the CONNECT event-based monitoring enabler (GLIMPSE Enabler released within WP 4) for run-time analysis and verification. To support a Model-driven approach in the interaction with the monitor, we have developed a CPMM editor and a translator from CPMM to the GLIMPSE native language (Drools). In this document that is the final deliverable from WP 5 we first present the latest advances in the fourth year concerning CPMM, Dependability&Performance Analysis, Incremental Verification and Security. Then, we make an overall summary of main achievements for the whole project lifecycle. In appendix we also include some relevant articles specifically focussing on <b>CONNECTability</b> that have been prepared in the last period...|$|E
40|$|Abstract—In {{a typical}} BitTorrent swarm, a large {{proportion}} of the peers are behind firewalls or NATs. These peers are called unconnectable. When developing P 2 P applications, a main requirement is to handle unconnectable peers appropriately. One important aspect of this problem, which has not been emphasized so far, is understanding the difference between the attributes of unconnectable peers and peers in the open Internet. For example, if unconnectable peers spend much less time online, or if they download significantly more, exploiting these facts helps to optimize the implementation; and ignoring these facts can even lead to severe performance problems. Comparing open and unconnectable peers is not easy because most traces contain no information about <b>connectability.</b> Here we study two large traces collected in two private BitTorrent communities: FileList. org and BitSoup. org, both of which contain the <b>connectability</b> attribute. From these traces we extract several attributes of individual online sessions, swarms, and users. We compare the distributions of these attributes over unconnectable and open peers. We find that there are some potentially important differences, e. g., unconnectable users tend to have a lot more sessions, and they tend to spend slightly more time online. Some of our findings are in contradiction with previous results that were based on a different trace collection methodology. I...|$|E
40|$|Current {{phone calls}} using the Public Switched Telephone Network (PSTN) involve {{costs for the}} enduser, provide limited call data for network {{operators}} and currently impose limitations {{on the type of}} devices that have PSTN <b>connectability.</b> This thesis implements and evaluates a system in which a mobile web browser connects {{a phone call from a}} smartphone to the PSTN utilizing Web Real-Time Communication (WebRTC) technology whilst maintaining sufficient audio qualityand providing a non-obtrusive user interface. The methods for this thesis included, performing a literature study, the evaluation of existing solutions and software, and the implementation of a web application prototype. The web application was successfully connected to the PSTN using preexisting software, sipML 5 and Asterisk. WebSockets was used for signaling and the G. 711 audio codec was used for the audio path. The ability to utilize real-time communication in a web browser proved successful. The use of real-time communication also made it possible to extract more extensive call data. Additional benefits were also noted and included, potential cost reduction for end-users, expansion of the type of devices with PSTN <b>connectability,</b> and the ability togather greater call data such as browser history, environments and coordinates. The user experience was evaluated by performing interviews...|$|E
40|$|Could we {{consider}} urban morphologies as figures that emerge as ‘horizontal phenomena’? Could {{we consider}} urban morphologies as embedded within the complex {{systems of the}} city rather than assume they demarcate the city through an overlay of lines? Could the urban form then be considered as an affect which emerges from a dynamic thickened ground, creating a new landscape? If landscapes are {{understood in terms of}} their <b>connectability</b> to the order of things in the universe (as, for example, in physics), where landscape’s <b>connectability</b> is a reciprocation of forces between itself and its context at all scales, then each connection is a shared force, a received and distributed force. If the order of the landscape is inherent in its process of transformations, to what extent does this order produce the city? This research aims to contribute to the discourse on Landscape Urbanism which is often positioned and grounded within the philosophical and scientific fields. However, it is argued that the ability to open up new possibilities, new ways of thinking and acting, lies in the act of design. This research, therefore, aimed to reveal these possibilities through a structured design process which linked the disciplinary fields of Landscape Architecture and Architecture...|$|E
40|$|The aim of CONNECT is {{to achieve}} {{universal}} interoperability between heterogeneous Networked Systems. For this, the non-functional properties required at {{each side of the}} connection going to be established, which we refer to by the one inclusive term "CONNECTability", must be fulfilled. In Deliverable D 5. 1 we conceived the conceptual models at the foundation of <b>CONNECTability.</b> In D 5. 2 we then presented a first version of the approaches and of their respective enablers that we developed for assuring <b>CONNECTability</b> both at synthesis time and at run-time. In this deliverables, we present the advancements and contributions achieved in the third year, which include: - a refinement of the CONNECT Property Meta-Model, with a preliminary implementation of a Model-to-Code translator; - an enhanced implementation of the Dependability&Performance analysis Enabler, supporting stochastic verification and state-based analysis, that is enriched with mechanisms for providing feedback to the Synthesis enabler based on monitor's run-time observations; - a fully running version of the Security Enabler, following the Security-by-Contract-with-Trust methodology, for the monitoring and enforcement of CONNECT related security policies; - a complete (XML) definition of the Trust Model Description Language, an editor and the corresponding implementation of supporting tools to be integrated into the Trust Management Enabler...|$|E
40|$|Current data {{processing}} {{is limited by}} a container-reference dichotomy. Data once stored and connected is hard to rearrange and connect in new ways required by needs that have changed over time. This paper explains an approach to remove this fundamental limitation. It argues data should no longer be recorded and stored, but assimilated and represented/described. Instead of copying data into data structure for further processing, data should be described by a “system of pure relations ” in which the data itself {{is nowhere to be}} found anymore, but can be regenerated as needed. The benefits of such a “system of pure relations ” are infinite <b>connectability</b> of data at any level of abstraction...|$|E
40|$|Unlike {{the overall}} {{framework}} of Ernest Nagel's work on reduction, {{his theory of}} intertheoretic connection still has life in it. It handles aptly cases where reduction requires complex representation of a target domain. Abandoning his formulation as too liberal was a mistake. Arguments {{that it is too}} liberal at best touch only Nagel's deductivist theory of explanation, not his condition of <b>connectability.</b> Taking this condition seriously gives a powerful view of reduction, but one which requires us to index explanatory power to sciences as they are formulated at particular times. While we may thereby reduce more than philosophers have supposed, we must abandon hope (as Nagel did) of saying anything useful about reductionism. 15 page(s...|$|E
40|$|Abstract. This {{paper is}} a first step towards a study for a {{concurrent}} construction of proof-nets in the framework of linear logic after Andreoli’s works, by taking care of the properties of the structures. We limit here to multiplicative linear logic. We first give a criterion for closed modules (i. e. validity of polarized proof struc-tures), then extend it to open modules (i. e. validity of partial proof structures) distinguishing criteria for acyclicity and <b>connectability.</b> The keypoint is an exten-sive use of the fundamental structural properties of the logics. We consider proof structures as built from n-ary bipolar objects and we show that strongly conflu-ent (local) reductions on such objects are an elegant answer to the correctness problem. This has natural applications in (concurrent) logic programming. ...|$|E
40|$|Virtual Reality Environments for Psychoneurophysiological Assessment and Rehabilitation - is an European Community funded project (Telematics {{for health}} - HC 1053 [URL] whose aim is: - {{to develop a}} PC based virtual reality system (PC-VRS) for the medical market that can be marketed at a price which is {{accessible}} to its possible end-users (hospitals, universities and research centres) and which would have the modular, <b>connectability</b> and interoperability characteristics that the existing systems lack; - to develop three hardware/software modules {{for the application of}} the PC VRS in psychoneurophysiological assessment and rehabilitation. The chosen development areas are eating disorders (bulimia, anorexia and obesity), movement disorders (Parkinson's disease and torsion dystonia) and stroke disorders (unilateral neglect and hemiparesis). This paper presents the rationale of the different approaches and the methodology used. © 1997 The authors. </p...|$|E
40|$|A "Run Time Scheduler" (RunTS) is presented, {{a minimalist}} Discrete Event Simulator able to {{sequence}} {{the operation of}} multiple simulators, coordinating a simulation of several elements so to form a whole system. Dynamic cause-effect chains may emerge. In operation the net simulation possesses a known steady-state other than when changed. RunTS controls the application of state-changes, passing these to specific simulators to determine new steady-states. Messages can pass between simulations concerning configuration data, commands and results. Simulators must meet <b>connectability</b> criteria. The method allows variable periods between simulation stages rather than a fixed tempo, and can undertake specific simulation sequences unique to each event, through use of a novel per-event state-machine. RunTS is part of INSim, a Smart Grid simulator working {{with a mix of}} components including Electric Vehicles, Smart Agents and OpenDSS, a power network analysis tool...|$|E
40|$|Peer-to-Peer (P 2 P) {{networks}} work on {{the presumption}} that all nodes in the network are connectable. However, NAT boxes and firewalls prevent connections to many nodes on the Internet. For UDP based protocols, the UDP hole-punching technique has been proposed to mitigate this problem. This paper presents {{a study of the}} efficacy of UDP hole punching on the Internet {{in the context of an}} actual P 2 P network. To the best of our knowledge, no previous study has provided similar measurements. Our results show that UDP hole punching is an effective method to increase the <b>connectability</b> of peers on the Internet: approximately 64 % of all peers are behind a NAT box or firewall which should allow hole punching to work, and more than 80 % of hole punching attempts between these peers succeed. Wp...|$|E
40|$|AbstractIn {{this paper}} we present an {{extensive}} treatment of tile <b>connectability</b> problems, sometimes called domino snake problems. The interest in such problems stems from {{their relationship to}} classical tiling problems, which have been established as an important, simple and useful tool for obtaining basic lower bound results in complexity and computability theory. We concentrate on the following two contrasting results: The general snake problem is undecidable in a half-plane (due to Ebbinghaus), but is decidable in the whole plane. This surprising decidability result was announced without proof by Myers in 1979. We provide here the first full proof, and show {{that the problem is}} actually PSPACE-complete. We also prove many results concerning the difficulty of variants of these general snake problems and their extension to infinite snakes. In addition, we establish a resemblance between snake problems and classical tiling problems, considering the corresponding bounded, unbounded and recurring cases...|$|E
40|$|As design {{problems}} are inherently indeterminate or wicked, {{we have to}} rely on various strategies when practicing design. In this paper, we propose a material strategy that emphasizes the expressional potential of computers. We argue how computers, in principle, can be understood as a material for design and how they can be part of a formgiving practice. We embark on the beginning of establishing a practical understanding of the computer as a material by articulating a number of material properties of computers. Two of these properties, computed causality and <b>connectability,</b> are given shape through material samples of a computational composite. The composite {{is in the form of}} a copper tile of which the computer controls the thermodynamic behavior. The material strategy proposed here which produced dramatic results is still in its infancy, but by adopting a material understanding of computers and beginning to embody the space of opportunities it unfolds, we take the first steps towards a new way of designing computational objects and architectures...|$|E
40|$|Computer-assisted data {{collection}} in survey research offers potentially lower costs, quicker turnaround time, and improved data quality {{as compared to}} traditional paper-and-pencil methods. The proliferation of handheld computers in recent years nowmakes these benefits more accessible to field researchers. Handheld computers are inexpensive, portable, and energy efficient, making them ideal field instruments. In this article, I review a new software product designed for mobile computer-assisted personal interviewing (MCAPI) with Palm OS handheld computers. Based on my experience with MCAPI in the field, I conclude that version 3. 0 of Entryware software is a robust tool for face-to-face or self-administered structured interviews in field settings. I also consider some implications of this new technology for field research, including respondents ’ reactions and data quality. Handheld computers have become commonplace, and field researchers should take note: These small, affordable computers are not just personal organizers. They offer absolute portability, extended battery life, an intuitive interface, and surprising computing power. In addition, the <b>connectability</b> o...|$|E
40|$|The aim of CONNECT is {{to achieve}} {{universal}} interoperability between heterogeneous Networked Systems. For this, the non-functional properties required at {{each side of the}} connection going to be established must be fulfilled. By the one inclusive term "CONNECTability" we comprehend properties belonging to all four non-functional concerns of interest for CONNECT, namely dependability, performance, security and trust. We model such properties in conformance with a meta-model which establishes the relevant concepts and their relations. Then, building on the conceptual models proposed in the first year in Deliverable D 5. 1, in this document we present the approaches developed for assuring <b>CONNECTability</b> both at synthesis time and at runtime. The contributions include: the Dependability&Performance analysis Enabler, for which we release a modular architecture supporting stochastic verification and state-based analysis; incremental verification and event-based monitoring for runtime analysis; a model-based approach to interoperable trust management; the Security-by-Contract-with-Trust framework, which guarantees and enforces the expected trust levels and security policies...|$|E
40|$|Abstract—BitTorrent communities, {{both public}} and private, are immensely popular in the Internet, with tens of {{millions}} of users simultaneously active at any given moment. Public and private BitTorrent communities are managed in different ways – for instance, some private communities enforce sharing ratios, have strict rules for content management, have a certain level of community oversight, and maintain a strong sense of exclusiveness. In this paper, we present the results of extensive measurements of {{more than half a million}} peers in five communities, ranging from highly popular and well-known public communities to elite private communities that can only be joined by invitation. We observe that the performance experienced by downloaders in the private communities is by far superior to the performance in the public communities, and we observe significant differences in <b>connectability,</b> seeder/leecher ratio, and seeding duration. Based on our results, we conjecture that when effective ratio enforcement mechanisms are in place, BitTorrent’s tit-for-tat mechanism is hardly influential anymore. Our multi-community, multi-swarm measurements are significantly broader and more extensive than any earlier measurement study on BitTorrent. I...|$|E
40|$|Since their invention, TV's {{have become}} one of the most popular media devices and can be found in almost every livingroom in the world. For a long time, the {{functionality}} of the TV stayed the same: the ability to view television programs at certain fixed times of the day. Recently there has been development in the television market adding computing power and internet <b>connectability</b> to televisions. These new features open a whole new world of possibilities. The goal of this project was to create an application that runs on a Samsung SmartTV and uses the libswift peer-to-peer engine to download, upload and stream files. To create an application for a Samsung SmartTV a software development kit has been provided which allows programmers to create apps using JavaScript, HTML, CSS and Flash. This software development kit was used to create the front-end of our application. The front-end consists of an internal media player to handle streaming content and media playback found on an external USB device. Parallel and Distributed Systems GroupSoftware TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|E
30|$|By {{contrast}} electric-driven {{systems are}} able to compete economically with the hydropower-driven system of Bribin. Here, investment costs distinctly lower than the ones related to the “Bribin system” are associated with costs for electric energy, which sum up to approx. 90.000 € (exemplary calculations based on the electricity rate of October 2015 and on a mean annual supply rate of 42  l/s). The profitability of this alternative, however, firstly depends on the <b>connectability</b> of the plant to an existing power grid, which {{would not be the}} case for the Bribin site (so actually additional costs would occur). Secondly the profitability depends on the price trend for electricity, since this source of energy is currently significantly subsidized by the Indonesian government. Indeed, referring to today’s electricity rate the price per kilowatt hour is assumed to increase by approx. 25  % until 2019, since starting {{at this point in time}} the Indonesian Ministry of Energy and Mineral Resources (ESDM) will define the electricity rate solely market-based (IISD 2014; PLN 2014). The O&M-related costs of the hydropower-driven “Bribin system”, however, show hardly any sensitivity to the mean supply discharge, whereby the plant’s profitability can easily and sustainably be increased.|$|E
40|$|Highway 63 is {{the main}} north/south route through Fort McMurray, Alberta, one of Canada’s fastest growing cities. The highway was {{originally}} completed in the 1970 s, and was designed to service a population of roughly 25, 000. The intersection of Highway 63 and King Street was an at-grade unsignalized two-lane road that generated unacceptable traffic accident statistics. As early as 1991, designs had been put forward to improve the operation and safety of this intersection. By 1999, traffic through the intersection was approaching 20, 000 vehicles per day (1) and accident statistics were increasing. Although the Municipality had engaged an engineering firm to design a new interchange, they lacked the funds (even with provincial cost sharing) to proceed with construction. In 2000, Alberta Transportation took over all primary and secondary highways in the province to improve operations and maintenance, provide <b>connectability</b> and safety to the system, and directly alleviate costs for cash-strapped municipalities. The province {{recognized the need to}} improve the Highway 63 /King Street intersection, assigned a high priority to it, and proceeded with the functional planning, design, and construction of a new interchange...|$|E
40|$|This article {{looks at}} the unique role information {{technology}} plays in higher education, providing a responsive learning environment {{to facilitate the}} development and distribution of knowledge while also enhancing the operational effectiveness of academic institutions.    Already {{we have seen a}} shift from knowledge acquisition and retention to collaboration and development become a desired outcome: in the digitally networked community, knowledge unshared is knowledge unknown. It is no longer sufficient for learners to know what; they must also know why and how.  Knowledge is not an end but a means, and the need of professionals to keep abreast of new ideas has become de rigueur for an ever-expanding range of careers. To paraphrase an economics precept, “We are all professionals now. ” Information technology—through its speed, accuracy, scalability, traceability, comparability, measurability, <b>connectability,</b> and interoperability—provides an environment that is highly conducive to the formation, sharing, and recording of ideas. It allows us to collaborate in real time, in new ways, and in combination with resources that raise understanding to new levels. What are the drivers underlying this age of technological empowerment? Table 1 shows the current trends that are driving the change and creating the conditions for the adoption of technology...|$|E
40|$|Cognitive Radio Networks (CRNs) are {{considered}} as a promising solution to the spectrum shortage problem in wireless communication. In this paper, we initiate the first systematic study on the algorithmic complexity of the connectivity problem in CRNs through spectrum assignments. We model the network of secondary users (SUs) as a potential graph, where two nodes having an edge between them are connected {{as long as they}} choose a common available channel. In the general case, where the potential graph is arbitrary and the SUs may have different number of antennae, we prove that it is NP-complete to determine whether the network is connectable even if there are only two channels. For the special case where the number of channels is constant and all the SUs have the same number of antennae, which is more than one but less than the number of channels, the problem is also NP-complete. For the special cases in which the potential graph is complete, a tree, or a graph with bounded treewidth, we prove the problem is NP-complete and fixed-parameter tractable (FPT) when parameterized by the number of channels. Exact algorithms are also derived to determine the <b>connectability</b> of a given cognitive radio network. Comment: A preliminary version of this paper appeared in ALGOSENSORS 201...|$|E
40|$|In today's rapidly {{changing}} marketplace, product demand {{is one of}} the most powerful driving forces behind design, thus rendering product conceptualization full of challenges. As a port can be defined as the point of action between a component and its environment, it plays a crucial role in capturing component concepts and realizing conceptual design. This paper presents a convenient approach to representation of the intended exchange of signals, energy, and/or materials and the generation and management of port-based knowledge (PBK). A port-based ontology modeling (PBOM) process that supports product conceptualization is described. A port definition and port functional representation are provided first with their semantic synthesis then employed to describe a port ontology. Second, details of the construction of a port-based ontology (PBO) repository that contains the assorted primitive functions, similarity calculations, and primitive concepts needed to map component connections and interactions are provided. The hierarchical attributes and taxonomy of ports are established, and the compatibility rules are then used to determine the <b>connectability</b> of two components. Next, the PBOM process is presented and a port-based, multi-view model is articulated, with the definition of each view and the projected relationships among the views given. Furthermore, a port-based ontology language (PBOL) that represents the process of port ontology refinement is presented, and a port-based function–behavior–structure (FBS) modeling framework is constructed for primitive system configuration. Finally, the results of a correction tape dispenser case study carried out to validate the efficiency of the port ontology for product conceptualization are presented. Department of Mechanical Engineerin...|$|E
40|$|If each node of an {{idealized}} network has an equal capacity to efficiently exchange benefits, then the network's capacity to use energy is scaled {{by the average}} amount of energy required to connect any two of its nodes. The scaling factor equals e, and the network's entropy is (n). Networking emerges in consequence of nodes minimizing the ratio of their energy use to the benefits obtained for such use, and their <b>connectability.</b> Networking leads to nested hierarchical clustering, which multiplies a network's capacity to use its energy to benefit its nodes. Network entropy multiplies a node's capacity. For a real network in which the nodes {{have the capacity to}} exchange benefits, network entropy may be estimated as C _L(n), where the base of the log is the path length L, and C is the clustering coefficient. Since n, L and C can be calculated for real networks, network entropy for real networks can be calculated and can reveal aspects of emergence and also of economic, biological, conceptual and other networks, such as the relationship between rates of lexical growth and divergence, and the economic benefit of adding customers to a commercial communications network. Entropy dating can help estimate the age of network processes, such as the growth of hierarchical society and of language. Comment: About 27 pages, double spaced; v 3 changes remarks on zeroth generation in proposition 8, and makes some minor changes to wording and spelling; v 4 is intended to correct remarks relating to glottochronolog...|$|E
40|$|Abstract The {{academic}} {{debate on}} the interpretation of literary texts has always suf-fered from the semantic ambiguity of key concepts (literature, meaning, interpreta-tion, literary study, etc.). To {{get out of this}} dead end, literary scholars have to step back from their daily routine {{from time to time to}} consider what kind of activity they are actually engaged in, since nothing in academia is natural or self-evident; instead, all is contingent. That is, scholars are not talking about literary texts as givens or data; they are talking about problems they have with what they deem literary items. If lit-erary scholars aim at a scientific solution for their respective problems, they have to meet the usual standards of science; that is, they have to solve explicitly spelled-out problems via explicit problem-solving strategies or methods. This holds equally true for all problems subsumed under the title ‘‘interpretation. ’ ’ The point is not can in-terpretation be reasonable, possible, or neglectable; rather, can literary scholars per-form the operation called interpretation in terms of theory-guided operationalized productions of experiential knowledge which can be stabilized in respective scholarly discourses via communicative <b>connectability</b> and intersubjective inspection. Same Procedure as Last Year? Talking about a paradigm change in literary studies has lost its threatening but at the same time also its fascinating effect. The reflection on presuppositions of interpreting literary texts today is mostly based on heuristic or strictly pragmatic interests. The daily routine of interpretation has found its realm in a domain of normalized procedures in between scientific rationalization (which is no longer aimed at) and a subjective art of interpretation (which nobody really advocates) ...|$|E
