47|72|Public
5|$|However, {{contrary}} to {{the expectations of the}} Red Queen hypothesis, Hanley et al. found that the prevalence, abundance and mean intensity of mites was significantly higher in sexual geckos than in asexuals sharing the same habitat. Furthermore, Parker, after reviewing numerous genetic studies on plant disease resistance, failed to find a single example consistent with the concept that pathogens are the primary selective agent responsible for sexual reproduction in their host. At an even more fundamental level, Heng and Gorelick and Heng reviewed evidence that sex, rather than enhancing diversity, acts as a constraint on genetic diversity. They considered that sex acts as a <b>coarse</b> <b>filter,</b> weeding out major genetic changes, such as chromosomal rearrangements, but permitting minor variation, such as changes at the nucleotide or gene level (that are often neutral) to pass through the sexual sieve. The adaptive function of sex, today, remains a major unresolved issue in biology. The competing models to explain the adaptive function of sex were reviewed by Birdsell and Wills. A principal alternative view to the Red Queen hypothesis is that sex arose, and is maintained, as a process for repairing DNA damage, and that genetic variation is produced as a byproduct.|$|E
25|$|In {{contrast}} {{to the view that}} sex promotes genetic variation, Heng, and Gorelick and Heng reviewed evidence that sex actually acts as a constraint on genetic variation. They consider that sex acts as a <b>coarse</b> <b>filter,</b> weeding out major genetic changes, such as chromosomal rearrangements, but permitting minor variation, such as changes at the nucleotide or gene level (that are often neutral) to pass through the sexual sieve.|$|E
50|$|A better {{understanding}} of natural systems has resulted in new ideas about forest management, such as managed natural disturbances should be designed to achieve the landscape patterns and habitat conditions that are normally maintained in nature (DeLong 1998; Wong and Iverson 2004). This <b>coarse</b> <b>filter</b> approach to biodiversity conservation recognizes ecological processes and provides for a dynamic distribution of old growth across the landscape.And all seral stages - young, medium and old - support forest biodiversity. Plants and animals rely on different forest ecosystem stages to meet their habitat needs.|$|E
40|$|<b>Coarse</b> stage Nuclepore <b>filters</b> used in GENT aerosol {{sampling}} {{units were}} {{coated with a}} thin film of Apiezon L-type grease in order to minimise the loss of particles on the filters due to 'bounce off'. Originally Freon {{was used as the}} solvent to dissolve the Apiezon grease in the coating process. Because of the environmental impact, Freon was discontinued and replaced with Fluorinert. Apiezon grease did not dissolve freely in the Fluorinert and it was replaced by Fomblin grease in 1995. This increased production costs and coated Nuclepore <b>coarse</b> <b>filters</b> ceased production in 2004. Users were concerned that their stocks of coated Nuclepore filters were diminishing and as no alternative supply was available the feasibility of coating the <b>coarse</b> <b>filters</b> in house needed to be investigated. This report describes experiments conducted at ANSTO and the results obtained during the investigation of the coating process under laboratory conditions. Apiezon grease and Toluene were used in this process. Experiments were based on the procedure proposed by Prof P. Hopke and Dr A. Markwitz [1] with modification to this technique to increase the uniformity of the grease layer across the filter surface and to achieve approximately 100 µg of Apiezon grease per filter...|$|R
40|$|Ceramic foam {{filters are}} {{commonly}} used to clean liquid aluminum. It is well accepted that finer filters have greater filtration efficiency than <b>coarser</b> <b>filters.</b> It is also well known that operating difficulties with fine filters have prevented their potential from being fully utilized. This article outlines the improvements made by Pyrotek SA to measure and control filter pore size. It will also show how these techniques lead to greater consistency and improved efficiencies of casthouse filtration...|$|R
40|$|Peptide {{identification}} by tandem {{mass spectrometry}} (MS/MS) {{is one of}} the most important problems in proteomics. Recent advances in high throughput MS/MS experiments result in huge amount of spectra, and the peptide identification process should keep pace. In this paper, we strive to achieve high accuracy and efficiency for peptide identification with the presence of noise by a two-phase filtering strategy. Our algorithm transforms spectra to high dimensional vectors, and then uses self-organizing map (SOM) and multi-point range query (MPRQ) as very efficient <b>coarse</b> <b>filters</b> to select a number of candidate peptides from database. These candidate peptides are subsequently scored and ranked by an accurate tag-based scoring function S(λ). Experiments showed that our approach is both fast and accurate for peptide identification. Peptide identification by tandem mass spectrometry (MS/MS) {{is one of the}} most important problems in proteomics. Recent advances in high throughput MS/MS experiments result in huge amount of spectra, and the peptide identification process should keep pace. In this paper, we strive to achieve high accuracy and efficiency for peptide identification with the presence of noise by a two-phase filtering strategy. Our algorithm transforms spectra to high dimensional vectors, and then uses self-organizing map (SOM) and multi-point range query (MPRQ) as very efficient <b>coarse</b> <b>filters</b> to select a number of candidate peptides from database. These candidate peptides are subsequently scored and ranked by an accurate tag-based scoring function S(λ). Experiments showed that our approach is both fast and accurate for peptide identification...|$|R
50|$|However, {{contrary}} to {{the expectations of the}} Red Queen hypothesis, Hanley et al. found that the prevalence, abundance and mean intensity of mites was significantly higher in sexual geckos than in asexuals sharing the same habitat. Furthermore, Parker, after reviewing numerous genetic studies on plant disease resistance, failed to find a single example consistent with the concept that pathogens are the primary selective agent responsible for sexual reproduction in their host. At an even more fundamental level, Heng and Gorelick and Heng reviewed evidence that sex, rather than enhancing diversity, acts as a constraint on genetic diversity. They considered that sex acts as a <b>coarse</b> <b>filter,</b> weeding out major genetic changes, such as chromosomal rearrangements, but permitting minor variation, such as changes at the nucleotide or gene level (that are often neutral) to pass through the sexual sieve. The adaptive function of sex, today, remains a major unresolved issue in biology. The competing models to explain the adaptive function of sex were reviewed by Birdsell and Wills. A principal alternative view to the Red Queen hypothesis is that sex arose, and is maintained, as a process for repairing DNA damage, and that genetic variation is produced as a byproduct.|$|E
50|$|An {{oil bath}} air cleaner {{consists}} of a sump containing a pool of oil, and an insert which is filled with fibre, mesh, foam, or another <b>coarse</b> <b>filter</b> media. When the cleaner is assembled, the media-containing body of the insert sits a short distance above {{the surface of the}} oil pool. The rim of the insert overlaps the rim of the sump. This arrangement forms a labyrinthine path through which the air must travel in a series of U-turns: up through the gap between the rims of the insert and the sump, down through the gap between the outer wall of the insert and the inner wall of the sump, and up through the filter media {{in the body of the}} insert. This U-turn takes the air at high velocity across the surface of the oil pool. Larger and heavier dust and dirt particles in the air cannot make the turn due to their inertia, so they fall into the oil and settle to the bottom of the base bowl. Lighter and smaller particles are trapped by the filtration media in the insert, which is wetted by oil droplets aspirated there into by normal airflow. Oil bath air cleaners were very widely used in automotive and small engine applications until the widespread industry adoption of the paper filter in the early 1960s. Such cleaners are still used in off-road equipment where very high levels of dust are encountered, for oil bath air cleaners can sequester a great deal of dirt relative to their overall size without loss of filtration efficiency or airflow. However, the liquid oil makes cleaning and servicing such air cleaners messy and inconvenient, they must be relatively large to avoid excessive restriction at high airflow rates, and they tend to increase exhaust emissions of unburned hydrocarbons due to oil aspiration when used on spark-ignition engines.|$|E
40|$|A {{filtration}} medium {{includes a}} fine filter layer having {{a plurality of}} nanofibers and a <b>coarse</b> <b>filter</b> layer having a plurality of microfibers attached to the fine filter layer. The <b>coarse</b> <b>filter</b> layer is positioned proximal to a direction of fluid flow, and the fine filter layer is positioned distal to the direction of fluid flow. Department of Mechanical EngineeringUS 8303693; US 8303693 B 2; US 8303, 693 B 2; US 8, 303, 693; US 8, 303, 693 B 2; 8303693; Appl. No. 11 / 740, 513 Inventor name used in this publication: Wallace W. LeungU...|$|E
30|$|An {{approach}} {{that has been}} used in recent publications is the application of a Laplacian of Gaussian (LoG) bandpass filter to highlight and enhance different spatial scales between fine and <b>coarse</b> texture (<b>filter</b> value[*]=[*] 1.0 to 2.5) [1].|$|R
40|$|The agent {{transmitting}} leucosis readily passed {{all types}} of silicious filters. Filtration is particularly successful when the plasma is freed from particles and substances that would otherwise obstruct the pores of the filter. Filtration through fine filters seems to be facilitated by preceding filtration through <b>coarse</b> <b>filters.</b> A comparison of the periods of incubation of leucosis produced by unfiltered plasma and plasma passed through silicious filters shows {{that as a result}} of filtration, the incubation periods are somewhat prolonged. This suggests a slight or moderate decrease in the concentration of the transmitting agent in the plasma caused by filtration. Filtration tests through collodion membranes indicate that the agent transmitting leucosis is much smaller than the virus of bovine pleuropneumonia (250 mµ) and that it approximates the size of bacteriophage...|$|R
5000|$|Filtration is {{a partial}} removal of solid {{particles}} through filter medium. Oil filtration systems generally use a multistage filtration with <b>coarse</b> and fine <b>filters.</b>|$|R
3000|$|... 2 {{estimated}} with one-tissue compartment model [11]. For one exemplary patient, a parametric DVR map {{was generated}} from dynamic data reconstructed with a 10 -mm Gauss filter. Due to high statistical fluctuations, the <b>coarse</b> <b>filter</b> {{had to be}} applied for voxel-wise fitting with Logan reference tissue model.|$|E
30|$|Limited {{knowledge}} of fire regimes and their variations {{can lead to}} competing resource concerns that make fire and resource management problematic (Agee 1999, Stephens and Ruth 2005). An example {{is the presence of}} endangered or rare species in many forests. Their presence often leads to adoption of single-species, fine-filter approaches to management (Stephens and Ruth 2005); whereas fire operates more broadly as a <b>coarse</b> <b>filter</b> (Agee 1999).|$|E
40|$|An {{important}} element of resource management and conservation is {{an understanding of the}} tradeoffs between marketed products such as timber and measures of environmental quality such as biodiversity. In this paper, we develop an integrated economic – ecological spatial optimization model. The integrated model incorporates dynamic forest sector harvesting, oil and gas sector development, <b>coarse</b> <b>filter</b> or habitat based old-forest indicators, and a set of empirical forest bird models that predict bird abundance. Using our integrated model, economic tradeoff curves, or production possibility frontiers, are developed that illustrate the cost of achieving <b>coarse</b> <b>filter</b> targets by a set time (50 years) within a 100 year time horizon. We explore the production possibility frontier’s relationship to the natural range of variation of old growth habitat. Our analysis illustrates the use of ecological criteria like the natural range of variation in providing guidance for the choice of preferred location on the frontier. Keywords: Production possibility frontier, forest management, biodiversity, optimization, tradeoffs. Environmental Economics and Policy, Land Economics/Use, Resource /Energy Economics and Policy,...|$|E
25|$|A Cauchy filter {{is called}} minimal if it {{contains}} no smaller (i.e., <b>coarser)</b> Cauchy <b>filter</b> (other than itself). It {{can be shown}} that every Cauchy filter contains a unique minimal Cauchy filter. The neighbourhood filter of each point (the filter consisting of all neighbourhoods of the point) is a minimal Cauchy filter.|$|R
40|$|Abstract — {{one way of}} {{determining}} chemical and biological reactivity of a newly found compound is by searching database for structurally similar molecules. Graph theory concepts are being used for molecular matching. Molecular matching is of two kinds, like, complete matching and partial matching (like searching for functional groups). In this paper we propose an efficient way of pruning the large molecular databases in various stages {{in order to do}} <b>coarse</b> <b>filtering</b> which uses bit-string manipulation, histogram filtering and dimensionality reduction to prune some or most of the database molecules. Then exact matching with the query molecule is performed through fine filtering on the remaining molecules in order to find the exact match for the query molecule from the pruned database using more expensive graph isomorphism algorithm. In this way search time can be reduced significantly. I...|$|R
40|$|A Bloom Filter is an {{efficient}} randomized data structure for membership queries {{on a set}} with a certain known false positive probability. Bloom Filters (BFs) are very attractive for their limited memory requirements and their easy construction which make them a popular choice for many tasks in network devices. However, {{in a number of}} network applications, more than simple probabilistic membership queries is required, and BFs can be adopted as a <b>coarse</b> <b>filtering</b> stage, leaving the ultimate filtering and classification process to other techniques, such as hash tables or tree-like structures. In this paper we propose a scheme to extend BFs with ``indexing'' features so that when an element $x$ is queried, an univocal index of that element is returned, which in turn can be used as an address for a table, just as a perfect hashing scheme. This extension, called indexed Bloom Filter (iBF), comes at the cost of a small increment of false positive probability and simply fits in existing BF-based applications...|$|R
40|$|Many of the {{problems}} with modern patent-eligibility analysis {{can be traced back to}} a fundamental philosophical divide between judges who treat eligibility as the primary tool for effectuating patent policy and those who take patent-eligibility as nothing more than a <b>coarse</b> <b>filter</b> to be invoked in rare cases. After several years in which the <b>coarse</b> <b>filter</b> approach seemed to have the upper hand, the eligibility-as-king approach now is firmly in ascendancy. This Article, resists that trend, exploring more centrist approaches to patent-eligibility, particularly in the context of process inventions. This Article first examines the practice of undertaking an eligibility analysis with no antecedent claim construction; then concludes that this practice is problematic, drawing on the authors 2 ̆ 7 prior work concerning the design of patent law rules in view of the audience for those rules. This Article also assesses the unfortunate renaissance of the 2 ̆ 2 inventive concept 2 ̆ 2 inquiry, arguing that the Court 2 ̆ 7 s new embrace of that inquiry is a mistake that permits judges to privilege eligibility to the virtual exclusion of all other patentability doctrines...|$|E
40|$|Fire {{played an}} {{important}} role in maintaining and creating conditions suitable for native flora and fauna in the forests of western North America. Recent <b>coarse</b> <b>filter</b> conservation strategies have advocated creating future landscapes that incorporate historic or natural ranges of variability, including fire regimes. Historic fire regimes were variable across the West, and created quite unique coarse woody debris dynamics in low-, mixed-, and high-severity fire regimes. Moving towards more historic landscape structures will require variable standards for coarse woody debris retention...|$|E
30|$|Microspheres {{were formed}} by solvent {{evaporation}} technique. Resulting emulsion mixture was stirred at 250  rpm at an ambient temperature for 18 – 24  h to allow solvent evaporation leading to formation of microspheres. Centrifugation (9000  rpm) was performed for 20  min to collect hardened microspheres which were further washed three times with purified water for 5  min each. The obtained supernatant was filtered through a <b>coarse</b> <b>filter</b> to obtain microspheres retained in solution. Finally, the resulting microspheres were freeze-dried by adding 1 % w/v of mannitol for 24  h, collected and stored.|$|E
40|$|A {{filtration}} system consisting of <b>coarse</b> media <b>filters</b> {{in series with}} standard dual media filters was proposed and evaluated as an alternative for direct filtration of high turbidity waters. The <b>coarse</b> media <b>filters</b> utilized a 3. 08 mm uniform sand with a media depth of 1. 32 m;The study was divided into three phases. The first phase involved the use of jar tests to determine optimum coagulants and approximate dosages for direct filtration. The jar test results {{were used in the}} second phase of study which involved laboratory pilot filter studies. The optimum alum dosage in the pilot plant studies was less than that determined in the jar test. Successful filter runs were possible with influent solids concentrations of 100 mg/l of kaolin or less. Headloss development (3 m maximum) limited the filter run lengths at kaolin concentrations of 25 and 50 mg/l. With 100 mg/l of kaolin, filter runs were terminated due to turbidity breakthrough. The third phase of the study involved a pilot plant field investigation using Des Moines river water as the raw water source. The chemical coagulants used in the laboratory did not produce acceptable results during the field study. The difference in chemical requirements was attributed {{to the nature of the}} raw water turbidity. The turbidity in the Des Moines river water was attributed mainly to the presence of diatoms;Particle deposition in the <b>coarse</b> media <b>filters</b> was recorded photographically during the laboratory filter runs. The particles were deposited in the filters by first coating the media. Next, the particles filled the media void spaces. The filling of the void spaces resulted in the development of narrow channels through which the suspension was transferred deeper into the filter;Two mathematical models were applied to the laboratory pilot filter data. Both models agreed reasonably well with the experimental data and were subsequently used to develop design curves. Design considerations for both small and large system applications were evaluated;The results of the study indicated that <b>coarse</b> media <b>filters</b> in series with standard dual media filters can be used successfully in extending the process of direct filtration to waters of higher turbidity than presently acceptable...|$|R
30|$|Ganeshan et al. {{found that}} coarse texture entropy on CT in {{seemingly}} normal liver {{of patients with}} colorectal cancer correlated with patient survival and postulated {{that this may be}} related to micrometastasis formation [42]. The authors also investigated patients with colorectal metastases. They normalized finer texture values (filter 1.0 - 2.0) to the corresponding texture values obtained from the <b>coarsest</b> <b>filter</b> (filter 2.5) to account for the contribution to the overall texture by the different texture features obtained from different levels of image filtration. It was found that the uniformity of surrounding ‘normal’ liver at texture ratios of 1.5 / 2.5 and 2.0 / 2.5 predicted for survival, potentially related to differences in vascularization and shunting related to the presence of metastases [43]. The same group also assessed the texture of dynamic contrast-enhanced CT of the liver in node-negative and -positive non-metastatic colorectal cancer. Uniformity and entropy were significantly different between the node-positive and -negative patients and greatest for fine texture entropy between 26 and 30  s following injection of intravenous contrast in comparison with the hepatic perfusion index, which was not significantly different between the two groups [32]. In a study of 54 patients with non-small-cell lung cancer (NSCLC) undergoing PET-CT staging, a heterogeneous texture on the non-contrast-enhanced CT component of the PET-CT was a predictor of poorer survival; in particular, patients with coarse texture uniformity < 0.624 did not survive more than 2.5  years [44]. Similarly, in a study of 21 patients with primary esophageal cancer undergoing PET-CT staging, advanced stage tumors demonstrated greater heterogeneity at filter values 1.5 – 2.0. Survival was also poorer for more heterogeneous tumors, particularly for coarse texture uniformity < 0.8477 (odds ratio[*]=[*] 4.45, 95  % CI 1.08 – 18.37, p[*]=[*] 0.039) [33].|$|R
40|$|Abstract- Increasing {{knowledge}} {{about the risk of}} toxic effects caused by anthropogenic mercury accumulation in ecosystems has resulted in a growing pressure forreduction of the discharge of mercury waste. Consequently, the mercury waste problems of dental clinics have been given increased attention. and restrictions on handling and discharge of contaminated waste have been established in several countries. Major amalgam particles from trituration surplus of those produced during the carving and burnishing of new amalgam restorations are generally collected in <b>coarse</b> <b>filters</b> and sold for refinement. Minor amalgam particles released by production of new fillings or by removal of old restorations partly sediment in tubes and drains. The remaining particles are carried with the waste water stream to the local purifying plant. In Scandinaviathe industrial discharge of mercury-contaminated waste water has been reduced to a minimum. According to recent investigations, dental clinics appear to be responsible for the major amount of mercury collected in the sludge generated in purifying plants. If threshold values for heavy metal content, including mercury, are exceeded, the sludge is not allowed to be recycled as fertilizer. Installation of an approved amalgam-separating apparatus in dental clinics is now mandatory in several countries- for example, Switzerland...|$|R
30|$|While {{stratification}} by {{the median}} value on two key variables is admittedly a <b>coarse</b> <b>filter,</b> we {{were attempting to}} build on use of a similar framework by UNOCHA-PCI 2007 elaborated on by Catley et al. 2012 (and recently modified by Lind et al. 2015). Also, note that a similar 2 by 2 framework was proposed in the Theory of Change and Development Hypothesis for the USAID grant SOL- 623 - 12 - 000008 : Resilience and Economic Growth in the Arid Lands-Improving Resilience Project in Kenya {{that was used to}} guide development activities in parts of our study areas beginning in 2012.|$|E
30|$|The {{fermented}} broth was extracted with methanol (1 : 1, v/v) {{and it was}} stirred for 60 {{minutes and}} filtered through a <b>coarse</b> <b>filter</b> paper. The filtrate was concentrated using vacuum concentrator. The aqueous concentrate was passed through 10 % (v/v) bed volume of Diaion® HP 20 (SUPELCO) resin {{at the rate of}} 1 L/h. The adsorbent on the resin was eluted with 80 % methanol after water wash. The methanolic extract was dissolved in demineralized water to get concentration of 75 mg/ml. 100 ml of this aqueous solution was partitioned with 100 ml ethyl acetate (EA) five times. The EA extracts were pooled together and dried on vacuum concentrator.|$|E
40|$|A {{comprehensive}} and micro-scale land snail and isopoda data set from 16 dolines of the Aggtelek Karst Area, Hungary, {{as described in}} Kemecei et al. 2014 [1] and Vilisics et al. 2008 [2]. [1] Kemencei, Z., Farkas, R., Pall-Gergely, B., Vilisics, F., Nagy, A., Hornung, E. & Solymos, P. (2014) : Microhabitat associations of land snails in forested dolinas: implications for <b>coarse</b> <b>filter</b> conservation. Community Ecology 15 : 180 [...] 186. [2] Vilisics, F., Nagy, A., Sólymos, P., Farkas, R., Kemencei, Z. Páll-Gergely, B., Kisfali, M. & Hornung, E. (2008) : Data on the terrestrial Isopoda fauna of the Alsó-hegy, Aggtelek National Park, Hungary. Folia Faunistica Slovaca, 13 : 9 - 12...|$|E
40|$|In {{spite of}} decades of {{conservation}} efforts, biological diversity {{throughout the world}} continues to dwindle. Prevailing conservation models have had greater success in determining which species and ecosystems to conserve than in fully {{taking into account the}} social and cultural landscapes within which these conservation targets are embedded. International conservation organizations have tended to define conservation targets (and approaches) at large spatial scales in hopes that they may apply broadly. Thus, over the last few decades we have seen a succession of generalized, monolithic conservation models replacing one another or competing with one another for attention and resources (for a recent review see Redford et al. 2003. Conservation Biology 17 : 116 – 131). These models have been developed within large international conservation organizations and are thus partly driven by a need for general application. The models, based on conservation science, seek unifying principles reflecting science's quest for general and widely applicable concepts. They tend to view the world through relatively <b>coarse</b> <b>filters</b> and may fail to encourage the emergence and spread of fine-grained models adapted to local conditions. Moreover, most models are directed toward the achievement of particular outcomes, rather than the support of systemic resilience...|$|R
40|$|Combined sewer {{systems are}} {{designed}} to transport stormwater surface run off {{in addition to the}} dry weather flows up to defined limits. In most European countries, hydraulic loads greater than the design flow are discharged directly into receiving water bodies, with minimal treatment (screening, sedimentation), or with no treatment at all. One feasible solution to prevent receiving waters from strong negative impacts seems to be the application of vertical flow constructed wetlands. In Germany, first attempts to use this ecological technology were recognized in early 1990 s. Since then, further development continued until a high level of treatment performance was reached. During recent years the national &# 8220;state-of-the-art&# 8221; (defined in 2005) was adapted in other European countries, including France and Italy. Against the background of differing national requirements in combined sewer system design, substantial developmental steps were taken. The use of <b>coarser</b> <b>filter</b> media in combination with alternating loadings of separated filter beds allows direct feedings with untreated combined runoff. Permanent water storage in deep layers of the wetland improves the system&# 8217;s robustness against extended dry periods, but contains operational risks. Besides similar functions (but different designs and layouts), correct dimensioning of all approaches suffers from uncertainties in long-term rainfall predictions as well as inside sewer system simulation&# 160;tools...|$|R
40|$|In {{this paper}} the {{performance}} of single and dual media filters with in-line flocculation have been examined as pretreatment to seawater reverse osmosis (SWRO). A comparison of filter performance was made between single medium filter (80 cm) consisting of sand or anthracite, and dual media filter consisting of sand (40 cm at the bottom) and anthracite (40 cm on top). Short terms (6 hours) experiments were conducted with in-line coagulation followed by direct filtration. Filtration velocities of 5 m/h and 10 m/h were used. The performances of these filters were assessed in terms of turbidity removal, head loss build-up, and organic compound removal in terms of Molecular Weight Distribution (MWD). The efficiency of the filter as pretreatment was evaluated in terms of Silt Density Index (SDI) and Modified Fouling Index (MFI). It {{was found that the}} turbidity removal was high and all the filters produced more or less same quality water. There was a slower buildup of head loss for <b>coarser</b> <b>filter</b> medium. A post treatment of reverse osmosis after an inline-flocculation-dual media filtration showed lower normalized flux decline (J/J 0) (0. 35 to 0. 22 during the first 20 hours operation) while, seawater without any pretreatment showed steeper flux decline (0. 18 to 0. 11 at first 20 hours operation) in RO...|$|R
40|$|Peptide {{identification}} by tandem {{mass spectrometry}} {{is both an}} important and challenging problem in proteomics. At present, huge amount of spectrum data are generated by high throughput mass spectrometers at a very fast pace, but algorithms to analyze these spectra are either too slow, not accurate enough, or only gives partial sequences or sequence tags. In this paper, we emphasize on the balance between identification completeness and efficiency with reasonable accuracy for peptide identification by tandem mass spectrum. Our method works by converting spectra to vectors in high-dimensional space, and subsequently use self-organizing map (SOM) and multi-point range query (MPRQ) algorithm as a <b>coarse</b> <b>filter</b> {{reduce the number of}} candidates to achieve efficient and accurate database search. Experiments show that our algorithm is both fast and accurate in peptide identification...|$|E
40|$|AbstractIn {{biological}} applications, the tandem {{mass spectrometry}} {{is a widely}} used method for determining protein and peptide sequences from an “in vitro” sample. The sequences are not determined directly, but they must be interpreted from the mass spectra, which is {{the output of the}} mass spectrometer. This work is focused on a similarity-search approach to mass spectra interpretation, where the parameterized Hausdorff distance (dHP) is used as the similarity. In order to provide an efficient similarity search under dHP, the metric access methods and the TriGen algorithm (controlling the metricity of dHP) are employed. Moreover, the search model based on the dHP supports posttranslational modifications (PTMs) in the query mass spectra, what is typically a problem when an indexing approach is used. Our approach can be utilized as a <b>coarse</b> <b>filter</b> by any other database approach for mass spectra interpretation...|$|E
30|$|Managers {{wishing to}} {{maintain}} ecosystem integrity via naturally ignited fires {{can do so}} {{using a combination of}} coarse- and fine-filter conservation approaches (Noon et al. 2003, USDA Forest Service 2012). Coarse filters invariably include relatively few indicators associated with the larger ecosystem of interest (e.g., major vegetation types or, in this case, different categories of burn severity). Their presence is meant to indicate that essential components of the whole system are intact, and they operate at broad spatial scales such as those associated with large fires (hundreds of square kilometers). Coarse filters are typically used to guide reserve design based on fundamental principles of conservation biology, including spatially redundant reserve complexes representative of the major forest types and fire severities interconnected across large landscapes. To achieve a pyrodiverse landscape, perhaps the best <b>coarse</b> <b>filter</b> would include high-severity fire patches interspersed with fire refugia (unburned areas) and low- to moderate-severity patches.|$|E
40|$|David S Wilcove 1 and Lawrence L Master 2 Only about 15 % of {{the known}} species in the United States have been studied in {{sufficient}} detail {{to determine whether or}} not they are imperiled. Any estimate of the total number of imperiled species in this country must therefore rely on extrapolations from this small number of comparatively well-studied species to a much larger number of poorly studied ones. We review the best available data on the status of plants, animals, and fungi in the US and conclude that the actual number of known species threatened with extinction is at least ten times greater than the number protected under the Endangered Species Act (ESA). The key to developing a more accurate picture of the extent of species endangerment is to obtain more data on the following groups (in decreasing order of priority) : (1) invertebrate animals; (2) fungi; and (3) marine organisms. However, given the slow pace at which species are being protected under the ESA, and the rapid rate at which natural areas are being destroyed, a more urgent task is to develop and refine approaches to conservation that complement species-by-species protection, most notably the use of <b>coarse</b> <b>filters.</b> Front Ecol Environ 2005; 3 (8) : 414 – 420 How many endangered species are there in the United States? This seemingly straightforward question is, i...|$|R
40|$|Ecological regionalizations, such as {{ecoregions}} {{or environmental}} clusters, {{are often used}} as <b>coarse</b> <b>filters</b> for conservation. To be effective biodiversity surrogates, regionalizations should contain distinct species assemblages. This condition is not frequently evaluated and regionalizations are rarely assessed comparatively. We used a national dataset of Canadian butterfly collections to evaluate four regionalizations (ecoregions, land cover and productivity regime classifications, and a spatial grid) at two thematic resolutions using analysis of similarity (ANOSIM) and species indicator values. Overall, the spatially constrained schemes (ecoregions and grids) best captured patterns of butterfly community composition and species affinities, indicating that butterfly communities are strongly structured by space at the continent scale. In contrast, when comparing regions only within spatial or environmental neighbourhoods (i. e., comparing between regions that are adjacent along geographic or environmental gradients), all regionalizations performed similarly. Adjacency in environmental space is thus as important as physical adjacency at determining community dissimilarity. Productivity regimes and land cover will be useful biodiversity surrogates when considered in conjunction with space or within a spatially constrained area. This finding was confirmed with two ecoregional case studies (of the Algonquin-Lake Nipissing and Thompson-Okanagan Plateau ecoregions), which also revealed that the relative performance of regionalizations depends upon {{the context of the}} study area. We conclude that including species data can improve the efficiency of environmental surrogates for systematic conservation planning...|$|R
40|$|Abstract only availableMMP- 3, or Stromelysin 1, is an {{proteolytic}} enzyme of the extracellular matrix that {{is involved in}} the repair of wounds. It is implicated in inflammation and cartilage damage and inflammation in rheumatoid arthritis and damage to the blood-brain barrier immediately after stroke. While a natural inhibitor does exist, it stops all processes, good and bad. MMP- 3 must be selectively inhibited, and for this reason, we must understand how Tissue Inhibitor of Metalloproteinases (TIMP) inhibits MMP- 3. Using NMR spectroscopy, the chemical shift of the 15 N and 1 H atoms, as well as the 15 N NMR relaxation data (R 1;, R&sub 2;, and heteronuclear NOE) of the MMP- 3 protein was recorded. Using NMRpipe, this data was converted into a spectrum, showing the contoured peaks. Using the NMR program Sparky, the relaxation data were fitted, and converted into a relaxation rate constant for each residue. For more accurate results, the data was <b>filtered</b> twice: <b>coarse</b> and fine. After <b>coarse</b> <b>filtering,</b> it was realized that the R 2 data were collected at different a frequency than the R 1 data. This renders the data less compatible. Preparation of new samples to be done at the correct frequencies will be completed sometime in the near future. Once this is accomplished, the new relaxation data for R 2 can be calculated, and the dynamics of the MMP- 3 /TIMP complex can be calculated accurately. Missouri Academy at Northwest Missouri State Universit...|$|R
