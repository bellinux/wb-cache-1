7|111|Public
2500|$|It is {{possible}} to obtain an optimal solution to the dual when only an optimal solution to the primal is known using the <b>complementary</b> <b>slackness</b> <b>theorem.</b> The theorem states: ...|$|E
40|$|Here {{we present}} an {{implementation}} of Primal-Dual Affine scaling method to solve linear optimization problem on GPU based systems. Strategies {{to convert the}} system generated by <b>complementary</b> <b>slackness</b> <b>theorem</b> into a symmetric system are given. A new CUDA friendly technique to solve the resulting symmetric positive definite subsystem is also developed. Various strategies to reduce the memory transfer and storage requirements were also explored...|$|E
40|$|Abstract [...] The {{shortest}}-route problem determines shortest routes {{from one}} node to another. In this paper Dijkstra’s Algorithm and Floyd’s algorithm to determine shortest route between two nodes {{in the network}} are discussed. Some extensions in Floyd’s algorithm have done. We have formulated a shortest route problem as a linear programming problem and solved it as a 0 - 1 integer programming problem. The dual of the formulated linear programming problem {{is also used to}} determine the shortest routes. <b>Complementary</b> <b>Slackness</b> <b>Theorem</b> is used to solve the primal problem from the solution of the dual problem and to determine the shortest distance as well as the shortest routes...|$|E
5000|$|To {{satisfy the}} <b>complementary</b> <b>slackness</b> condition, let [...] It follows that ...|$|R
40|$|Balinski and Tucker {{introduced}} in 1969 a special form of optimal tableaus for LP, {{which can be}} used to construct primal and dual optimal solutions such that the <b>complementary</b> <b>slackness</b> relation holds strictly. In this paper, first we note that using a polynomial time algorithm for LP Balinski and Tucker’s tableaus are obtainable in polynomial time. Furthermore, we show that, given a pair of primal and dual optimal solutions satisfying the <b>complementary</b> <b>slackness</b> relation strictly, it is possible to find a Balinski and Tucker’s optimal tableau in strongly polynomial time. This establishes the equivalence between Balinski and Tucker’s format of optimal tableaus and a pair of primal and dual solutions to satisfy the <b>complementary</b> <b>slackness</b> relation strictly. The new algorithm is related to Megiddo’s strongly polynomial algorithm that finds an optimal tableau based on a pair of primal and dual optimal solutions. Key words: Linear programming, the simplex tableau, primal and dual solu-tions, <b>complementary</b> <b>slackness,</b> strongly polynomial-time...|$|R
3000|$|... to be {{feasible}} {{and that the}} choice of the projection subset depending on μ is in accordance with the <b>complementary</b> <b>slackness</b> constraint [...]...|$|R
40|$|In {{this paper}} we first derive a {{necessary}} and sufficient condition for a stationary strategy {{to be the}} Nash equilibrium of discounted constrained stochastic game under certain assumptions. In this process we also develop a nonlinear (non-convex) optimization problem for a discounted constrained stochastic game. We use the linear best response functions of every player and <b>complementary</b> <b>slackness</b> <b>theorem</b> for linear programs to derive both the optimization problem and the equivalent condition. We then extend this result to average reward constrained stochastic games. Finally, we present a heuristic algorithm motivated by our necessary and sufficient conditions for a discounted cost constrained stochastic game. We numerically observe the convergence of this algorithm to Nash equilibrium. (C) 2015 Elsevier B. V. All rights reserved...|$|E
40|$|The {{problem of}} finding the path in a network {{connecting}} two given nodes, source and sink, with minimum possible cost is known in the literature as the shortest path problem (SPP) {{and it is a}} core model that {{lies at the heart of}} network optimization. The reason is the wide range of its practical applications and the large amount of interesting generalizations that can be considered, among them, the analysis of the multiobjective shortest path problem. This last model allows us to find how to send a given product between two specified nodes of a network as quickly, as cheaply and as reliable as possible taking into account the so-called Pareto optimal paths. The text presented here consists of two chapters. The first one is devoted to the introduction of some notation and properties related to networks where each arc is associated to just one cost value. The formulation of the SPP as a Mathematical Programming model is considered as well as its corresponding dual problem. The <b>complementary</b> <b>slackness</b> <b>theorem</b> provides us with a characterization of any basic feasible solution as a spanning tree in the original network. A sufficient optimality condition is also derived from this relation. Finally, the Dijkstra algorithm is studied as well as other specific algorithms that use special properties on acyclic networks. The second chapter extends the hypotheses considered in the previous one to a multiobjective context. The continuous formulation of the problem {{of finding the}} Pareto optimal paths is compared with its discrete version and some properties are stated. A generalization of the Dijkstra algorithm is proposed in order to find the whole set of Pareto optimal solutions. This procedure allows us to determine that the optimal set of paths corresponds with a set of adjacent trees. This property is very important in order to generate the Pareto optimal set of solutions and is the basis of a new improved algorithm that, starting with a given optimal tree, explores its adjacent trees and finds those Pareto optimal ones by using the duality conditions of the <b>complementary</b> <b>slackness</b> <b>theorem</b> presented in the chapter one. Universidad de Sevilla. Grado en Matemática...|$|E
40|$|International {{audience}} Due to {{the constant}} development of society, increasing quantities of commodities have to be transported in large urban centers. Therefore, network design problems arise as tools to support decision-making, aiming to meet the need of finding efficient ways to perform the transportation of each commodity from its origin to its destination. The Fixed-Charge Uncapacited Network Design Problem with User-optimal Flows (FCNDP-UOF) {{is a way of}} treating the problem described above and can be modeled as a bi-level discrete linear programming problem. This type of problem involves two distinct agents acting simultaneously rather than sequentially when making decisions. On the upper level, the leader is in charge of choosing a subset of edges to be opened in order to minimize the sum of fixed and variable costs. In response, on the lower level, the follower must choose a set of shortest paths in the network, resulting in the paths through which it commodity will be sent. The effect of an agent on the other is indirect: the decision of the followers is affected by the network designed on the upper level, while the leader's decision is affected by variable costs imposed by the routes settled in the lower level. This work reviews three different mathematical formulations of the FCNDP-UOF, a bi-level formulation (Billheimer et al. [1973]) and two one-level formulations. The first one-level formulation is based on the model presented by Kara et al. [2004] for the hazmat transportation problem, which uses KKT's conditions in order to transform the bi-level formulation into a one-level formulation. The second one, proposed by Mauttone et al. [2008], is obtained by applying the <b>complementary</b> <b>slackness</b> <b>theorem,</b> Bellman's optimality conditions and a Big-M linearizing technique into the bi-level formulation. Not only we compare the different formulations, but also implement a heuristics to quickly find a initial solution. In order to verify its efficiency, we modify the GRASP presented by González et al. [2013], to use this new constructive algorithm. </p...|$|E
3000|$|Equation (10) holds with <b>complementary</b> <b>slackness</b> (Farzin [1995]). Equation (11) {{means that}} there are no {{additional}} costs associated with the cumulative discoveries [...]...|$|R
3000|$|... {{where the}} last {{inequation}} holds true {{due to the}} fact that rank ([...] (1 /√(β _k)d_k+√(β)ĥ_k)(1 /√(β _k)d_k+√(β)ĥ_k)^H)= 1. Recalling the <b>complementary</b> <b>slackness</b> conditions tr(X [...]...|$|R
5000|$|... where [...] and [...] are the Lagrange {{multipliers}} {{associated with}} the constraints [...] and , respectively. The last condition, which is equivalent to [...] for all , is called the <b>complementary</b> <b>slackness</b> condition.|$|R
3000|$|... > 0. So the <b>complementary</b> <b>slackness</b> {{condition}} (32) only holds when [...] (∑ _k= 1 ^ip_kj-∑ _k= 1 ^i- 1 E_kj) = 0, {{which means}} all stored energy {{should be used}} up before the current transmission. □ [...]...|$|R
50|$|Since each {{inequality}} can {{be replaced}} by an equality and a slack variable, this means each primal variable corresponds to a dual slack variable, and each dual variable corresponds to a primal slack variable. This relation allows us to speak about <b>complementary</b> <b>slackness.</b>|$|R
40|$|A new DEA {{model has}} been {{introduced}} recently combining the primal and the dual models in order to impose strong <b>complementary</b> <b>slackness</b> conditions. It was claimed that a reference set that contains {{the maximum number of}} efficient units can then be determined. The model is very interesting as a theoretical idea. However, not only does the computational burden increase significantly, but it seems also that the basic matrices may be inherently ill-conditioned, leading to wrong results. Numerical experiments have been carried out on two real datasets of medium size with 163 and 920 units. These experiments show pervasive existence of ill-conditioned matrices leading to obviously wrong estimates of efficiency scores, and units declared as efficient reference units while actually being inefficient. Data envelopment analysis; BCC model; DEA/SCSC model; strong <b>complementary</b> <b>slackness</b> conditions...|$|R
40|$|AbstractThe aim of {{this paper}} is to develop a duality theory for linear multiobjective {{programming}} verifying similar properties as in the scalar case. We use the so-called “strongly proper optima” and we characterize such optima and its associated dual solutions by means of some <b>complementary</b> <b>slackness</b> conditions. Moreover, the dual solutions can measure the sensitivity of the primal optima...|$|R
40|$|Abstract. We {{discuss some}} {{implications}} of linear programming for Mather theory [13 – 15] and its finite dimensional approximations. We {{find that the}} <b>complementary</b> <b>slackness</b> condition of duality theory formally implies that the Mather set lies in an n-dimensional graph and as well predicts the relevant nonlinear PDE for the “weak KAM ” theory of Fathi [5 – 8]...|$|R
40|$|Conjunctive {{hydrology}} {{gives rise}} to reciprocal externalities between hydraulically connected ground and surface water. A partial equilibrium model was formulated for an n-node groundwater surface water conjunctive use in which economic equilibrium was defined by a system of <b>complementary</b> <b>slackness</b> equations. Using Mixed Complementary Programming, a three node example was parameterized using site specific data and functional forms applied to the general model. This example was solved for equilibrium water prices and quantities in the respective surface and ground water markets. The model provided a functional framework for cost/benefit analysis of three policy scenarios {{in the presence of}} reciprocal conjunctive use externalities: (1) Pigouvian tax/subsidy, (2) elimination of the externality through conservation infrastructure, and (3) aquifer recharge. The Pigouvian policy yielded the highest social welfare followed by the payment for aquifer recharge. Conservation that eliminated the externality decreased social welfare. Key words: conjunctive use, reciprocal externalities, <b>complementary</b> <b>slackness</b> conditions, partial equilibrium, cost benefit analysis, water conservation, Pigouvian tax, Pigouvian subsidy, water policy, aquifer recharge...|$|R
40|$|In {{this paper}} {{we present a}} {{generalization}} of the predictor corrector method of linear programming problem to semidefinite linear programming problem. We consider a direction which, we show, belongs to a family of directions presented by Kojima, Shindoh and Hara, and, one of the directions analyzed by Monteiro. We show that starting with the initial <b>complementary</b> <b>slackness</b> violation of t 0, in O(jlog(ffl t 0) j p n) iterations of the predictor corrector method, the <b>complementary</b> <b>slackness</b> violation {{can be reduced to}} {{less than or equal to}} ffl ? 0. We also analyze a modified corrector direction in which the linear system to be solved differs from that of the predictor in only the right hand side, and obtain a similar bound. We then use this modified corrector step in an implementable method which is shown to take a total of O(jlog(ffl t 0) j p nlog(n)) predictor and corrector steps. Key words: Linear programming, Semidefinite programming, Interior point methods, Path following, [...] ...|$|R
30|$|Abbreviations used in {{this study}} are {{summarized}} as follows: CSCs: <b>Complementary</b> <b>Slackness</b> Conditions, CSR: Corporate Social Responsibility, DEA: Data Envelopment Analysis, DTS: Damages to Scale, DMU: Decision Making Unit, DC: Desirable Congestion, NR: Non-radial, RTS: Returns to Scale, UC: Undesirable Congestion, UEN: Unified Efficiency under Natural Disposability, UEM: Unified Efficiency under Managerial disposability, UEM(DC): Unfired Efficiency under Managerial Disposability and Desirable Congestion and URS: Unrestricted.|$|R
40|$|AbstractIn any graph {{there exist}} a {{fractional}} cover and a fractional matching satisfying the <b>complementary</b> <b>slackness</b> conditions of linear programming. The proof uses a Gallai-Edmonds decomposition result for infinite graphs. We consider also {{the same problem}} for infinite hypergraphs, in particular in {{the case that the}} edges of the hypergraph are intervals on the real line. We prove an extension of a theorem of Gallai to the infinite case...|$|R
40|$|The Lagrange dual to {{a control}} problem is studied. The {{principal}} result {{based on the}} Hahn-Banach theorem proves that the dual problem has an optimal solution if there exists an interior point for the constraint set. A <b>complementary</b> <b>slackness</b> condition holds, if the primal problem has an optimal solution. A necessary and sufficient condition for the optimality of solutions to the primal and the dual problem is also presented...|$|R
40|$|We {{consider}} the classical optimal dividends problem under the Cramér-Lundberg model with exponential claim sizes {{subject to a}} constraint {{on the time of}} ruin. We introduce the dual problem and show that the <b>complementary</b> <b>slackness</b> conditions are satisfied, thus there is no duality gap. Therefore the optimal value function can be obtained as the point-wise infimum of auxiliary value functions indexed by Lagrange multipliers. We also present a series of numerical examples...|$|R
40|$|This project {{concerns}} the convex algebraic {{geometry of the}} central path of a linear programming problem. This path is an algebraic curve, described by linear and quadratic constraints arising from <b>complementary</b> <b>slackness.</b> We {{are interested in the}} defining polynomial equations and geometric invariants of this curve, such as degree, genus and singularities. These parameters are related to the curvature and thus to the performance of interior point methods. We also explore the natural extension to semidefinite programming...|$|R
40|$|AbstractThe {{well known}} blossom-algorithm for solving minimum weight perfect {{matching}} problems {{makes use of}} the optimality criteria arising from LP-duality and <b>complementary</b> <b>slackness.</b> But these instruments seem to fail when such a matching problem is considered with a different objective function as for instance the bottleneck objective which is also relevant in practice. Such a dilemma occurs for all those combinatorial optimization problems with algorithms based on Linear Programming. Therefore we present a rarely combinatorially motivated approach in this paper...|$|R
40|$|In {{this paper}} we present an {{extension}} of Moreau's sweeping process for higher order systems. The dynamical framework is carefully introduced, and preliminary well-posedness results are given. The time-discretisation of these nonsmooth systems with a time-stepping algorithm is also presented. This differential inclusion {{can be seen as}} a mathematical formulation of complementarity dynamical systems with arbitrary dimension and arbitrary relative degree between the <b>complementary</b> <b>slackness</b> variables. Applications of such high-order sweeping processes can be found in dynamic optimisation under state constraints and electrical circuits with ideal diodes...|$|R
40|$|In {{this paper}} we present linear time {{approximation}} schemes for several generalized matching problems on nonbipartite graphs. Our results include O_ϵ(m) -time algorithms for (1 -ϵ) -maximum weight f-factor and (1 +ϵ) -approximate minimum weight f-edge cover. As a byproduct, we also obtain direct algorithms for the exact cardinality versions {{of these problems}} running in O(m√(f(V))) time. The technical contributions of this work include an efficient method for maintaining relaxed <b>complementary</b> <b>slackness</b> in generalized matching problems and approximation-preserving reductions between the f-factor and f-edge cover problems...|$|R
30|$|Iterative {{application}} of the subgradient algorithm will converge to an optimal dual solution (u^*, λ^*). It should be emphasized that Lagrangian relaxation does not guarantee the optimal solution to the underlying problem. Thus, the solution generated may not satisfy the <b>complementary</b> <b>slackness</b> conditions. In case the solution is not feasible, we must develop a heuristic algorithm to find a feasible solution. In our system, we implement a simple heuristic algorithm that removes the excessive flows from the arcs with capacity violation by setting the arc capacity to zero and reroutes the excessive flows to {{other part of the}} network based on MCF algorithm.|$|R
40|$|A {{relaxation}} {{method for}} separable convex network flow problems is developed that is well-suited for problems with large {{variation in the}} magnitude of the nonlinear cost terms. The arcs are partitioned into two sets, one of which contains only arcs corresponding to strictly convex dual pairs that satisfy <b>complementary</b> <b>slackness</b> on the strictly convex arc set and e-complementary slackness on the remaining arcs. An asynchronous parallel variant of the method is also developed. Computational results demonstrate that the method is significantly more efficient on ill-conditioned networks than existing methods, solving problems with several thousand nonlinear arcs in one second or less...|$|R
40|$|We {{illustrate}} {{the use of}} a large-scale computable general equilibrium model to investigate the economic and environmental effects of renewable energy promotion within the European Union. Our hybrid model incorporates the technological explicitness of bottom-up energy system models for the electricity sector while production possibilities in other sectors are described at an aggregate level through top-down constant-elasticities-of-substitution (transformation) functions. The discrete activity analysis of technology options within conventional top-down computable general equilibrium models is possible when adopting the so-called mixed complementarity problem approach Ð a flexible mathematical representation of market equilibrium conditions which accommodates weak inequalities and <b>complementary</b> <b>slackness.</b> ...|$|R
40|$|We {{propose a}} new global and quadratically {{convergent}} algorithm for the linear l_∞ problem. This method works on the piecewise l_∞ problem directly by generating descent directions - via a sequence of weighted least squares problems - and using piecewise linear linesearches to ensure {{a decrease in the}} l_∞ function at every step. We prove that ultimately full Newton-like steps are taken where the Newton step is based on the <b>complementary</b> <b>slackness</b> condition holding at the solution. Numerical results suggest a very promising method; the number of iterations required to achieve high accuracy is relatively insensitive to problem size...|$|R
40|$|AbstractThis study {{discusses}} {{a combined}} use of DEA (Data Environment Analysis) with SCSC (Strong <b>Complementary</b> <b>Slackness</b> Condition) and DEA–DA (Discriminant Analysis). Many studies use DEA {{to evaluate the}} performance of various organizations in private and public sectors. A conventional use of DEA is not perfect because it still contains zero in many multipliers. This implies that DEA does not fully utilize information on all inputs and outputs. As a result, DEA produces many efficient organizations. To overcome the methodological difficulty, this study proposes a new use of DEA/SCSC and DEA–DA {{to reduce the number}} of efficient organizations...|$|R
40|$|AbstractIn this paper, {{we study}} the {{fuzzification}} of Weingartner’s pure capital rationing model and its analysis. We develop a primal–dual pair based on t-norm/t-conorm relation for the constraints and objective function for a fully fuzzified pure capital rationing problem except project selection variables. We define the α-interval {{under which the}} weak duality is proved. We perform sensitivity analysis {{for a change in}} a budget level or in a cash flow level of a non-basic as well as a basic variable. We analyze the problem based on duality and <b>complementary</b> <b>slackness</b> results. We illustrate the proposed model by computational analysis, and interpret the results...|$|R
40|$|The aim of {{this paper}} is to {{establish}} sufficient local conditions for the uniqueness of solutions to Nonlinear Complementarity Problems (NCP) and Mixed Complementarity Problems (MCP). Our main theorems state that for NCP and MCP defined by continuously differentiable functions, the solution is unique if the Jacobian of the function is a partial P-matrix at each solution. These theorems generalize the previous uniqueness results in a number of directions, including relaxing the strict <b>complementary</b> <b>slackness</b> requirement necessary in some of these approaches. The method of proof uses and extends a recent result by Simsek-Ozdaglar-Acemoglu [14] regarding the uniqueness of generalized critical points. ...|$|R
5|$|Von Neumann's {{results have}} been viewed as a special case of linear programming, where von Neumann's model uses only nonnegative matrices. The study of von Neumann's model of an {{expanding}} economy continues to interest mathematical economists with interests in computational economics. This paper {{has been called the}} greatest paper in mathematical economics by several authors, who recognized its introduction of fixed-point <b>theorems,</b> linear inequalities, <b>complementary</b> <b>slackness,</b> and saddlepoint duality. In the proceedings of a conference on von Neumann's growth model, Paul Samuelson said that many mathematicians had developed methods useful to economists, but that von Neumann was unique in having made significant contributions to economic theory itself.|$|R
40|$|International audienceIn {{this chapter}} {{we present a}} {{mathematical}} formulation of complementar- ity dynamical systems with arbitrary dimension and arbitrary relative degree between the <b>complementary</b> <b>slackness</b> variables. The proposed model incorporates the state jumps via high-order distributions through the extension of Moreau's sweeping process, which is a special type of differential inclusion. The time-discretization of these nonsmooth sys- tems, which is non-trivial, is also presented. Applications of such high- order sweeping processes {{can be found in}} dynamic optimization under state constraints and electrical circuits with ideal diodes, where it may be helpful for {{a better understanding of the}} closed-loop dynamics in- duced by some feedback laws...|$|R
