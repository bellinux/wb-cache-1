75|14|Public
500|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Symphony Technology Group compiled data for the season based on people using software on their phones that measures television viewing by detecting a program's sound. According to Symphony, the second season of Daredevil had 5.94% of viewers age 18-49 watching in an average minute in the first 32 days following its release. Symphony also estimated that 3.201 million viewers age 18-49 were watching an episode of Daredevil second season over the average minute in its first weekend of release. The marketing analytics firm Jumpshot determined the season was the most viewed Netflix season in the first 30 days after it premiered. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
500|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Symphony Technology Group compiled data for the season based on a sample size of 15,000 people using software on their phones that measures television viewing by detecting a program's sound. According to Symphony, from September to December 2015, episodes of Jessica Jones averaged 4.8 million viewers during a 35-day viewing cycle. The data was presented by Alan Wurtzel, NBCUniversal president of research and media development, in a presentation aimed to provide [...] "perspective" [...] when stating [...] "digital platforms are hurting the traditional TV business". Netflix CCO Ted Sarandos responded to the data by saying that [...] "the whole methodology and the measurement and the data itself doesn’t reflect any sense of reality of anything that we keep track of." [...] A further study from Symphony, for the same time period, found Jessica Jones {{to be one of}} the four most watched series in the 18 to 24 demographic, ahead of any broadcast network series. The marketing analytics firm Jumpshot determined the season was the fifth-most viewed Netflix season in the first 30 days after it premiered, garnering 26% of the viewers that the second season of Daredevil received, which was the most viewed season according to Jumpshot. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
2500|$|In early 2008, it was {{announced}} that the ISP arm of Virgin Media had entered into a contract (along with BT and TalkTalk) with the former spyware company Phorm (responsible under their 121Media guise for the Apropos rootkit) to intercept and analyse their users' <b>click-stream</b> data, and sell the anonymised aggregate information as part of Phorm's OIX advertising service. The practice, which has become known as [...] "data pimping", came under intense fire from various internet communities and other interested parties who believe that the interception of data is illegal under UK law (RIPA). At a more fundamental level, many have argued that the ISPs and Phorm have no right to sell a commodity (a user's data) to which they have no claim of ownership.|$|E
40|$|The {{database}} {{community is}} exploring {{more and more}} multidisciplinary avenues: Data semantics overlaps with ontology management; reasoning tasks venture into the domain of artificial intelligence; and data stream management and information retrieval shake hands, e. g., when processing Web <b>click-streams.</b> These new research avenues become evident, for example, in the topics that doctoral students choose for their dissertations. This paper surveys the emerging multidisciplinary research by doctoral students in database systems and related areas. It {{is based on the}} PIKM 2010, which is the 3 r...|$|R
40|$|Abstract:- The {{process of}} {{collecting}} useful research and marketing {{information from the}} immense volume of log-data available through the web has been an interesting challenge during the past decade. This paper proposes {{the use of the}} Factor Analysis method as a tool for the understanding and interpretation of general web document access patterns (or <b>click-streams).</b> On the basis of the proposed approach, Web-wide navigation data can be utilized to discover interesting usage patterns, in order to understand and better serve the needs both of internet users and web-based applications...|$|R
40|$|Analytics of {{tremendous}} big data generated from natural systems (e. g. tectonic plates' movement, atmospheric data, [...] .), engineered systems (e. g. servers, electronic devices, [...] .), and human activities (e. g. trajectories, web <b>click-streams,</b> health records, customers' transactions, user interactions in social networks, [...] .) require highly scalable data management systems with new capabilities in both algorithms and architectures. The focus {{in most of}} data management systems is on (1) horizontal scalability and high performance, (2) continuous availability, (3) non-structured data processing, and (4) real-time processing. Alternative systems such as SQL-on-Hadoop technologies are becoming mainstream for big data analytics...|$|R
2500|$|In early 2008 it was {{announced}} that BT had entered into a contract (along with Virgin Media and TalkTalk) with the spyware company Phorm (responsible under their 121Media guise for the Apropos rootkit) to intercept and analyse their users' <b>click-stream</b> data and sell the anonymised aggregate information as part of Phorm's OIX advertising service. The practice, known as [...] "behavioural targeting" [...] and condemned by critics as [...] "data pimping", came under intense fire from various internet communities and other interested-parties who believe that the interception of data without the consent of users and web site owners is illegal under UK law (RIPA). At a more fundamental level, many have argued that the ISPs and Phorm have no right to sell a commodity (a user's data, and the copyright content of web sites) to which they have no claim of ownership. In response to questions about Phorm and the interception of data by the Webwise system Sir Tim Berners-Lee, credited as the creator of the World Wide Web protocol, indicated his disapproval of the concept and is quoted as saying of his data and web history: ...|$|E
2500|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Symphony Technology Group compiled data for the season based on people using software on their phones that measures television viewing by detecting a program's sound. According to Symphony, Luke Cage opened stronger initially than the Netflix original series Making a Murderer and Stranger Things, but its performance over its first month fell short of both, comparatively. Symphony estimated that 6.34% of viewers age 18-49 were watching Luke Cage in an average minute in the first 32 days following its release, with Making a Murderer and Stranger Things seeing 9.1% and 9.81% of viewers, respectively. Symphony also estimated that 3.388 million viewers age 18-49 were watching an episode of Luke Cage over the average minute in its first weekend of release. The marketing analytics firm Jumpshot determined the season was the fourth-most viewed Netflix season in the first 30 days after it premiered, garnering 27% of the viewers that the second season of Daredevil received, which was the most viewed season according to Jumpstart. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
2500|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Parrot Analytics determined the season was generating the second-highest demand among the Marvel Netflix series during their respective launch weeks. Parrot calculated that Iron Fist was generating over 63 million [...] "Demand Expressions" [...] at its peak, behind Luke Cages 69 million, with Parrot calculating expressions [...] "by evaluating streaming video, P2P-sharing, social chatter, and more." [...] 7Park Data, which measures the number of streams on subscription video services, determined Iron Fist {{to be the most}} binge-watched premiere for Netflix in 2017. It found that 54.7% of Iron Fist streams on March 17, 2017 were of three episodes or more, against the average hour-long show binge score of 46.9%. 7Park Data also determined that Iron Fist accounted for 14.6% of all Netflix streams on its premiere date, the highest percentage of any series premiere measured by the company, beating the second season of Daredevil (13.8%) and Luke Cage (12.8%) on their premiere dates. Parrot later revealed that demand for Iron Fist a week after it launched was cut in half. This was the largest drop in retention between the four Marvel Netflix series, potentially indicating [...] "that people started binge-watching the show in its first few days and then didn't come back to finish the season the next weekend." [...] The marketing analytics firm Jumpshot determined the season was the third-most viewed Netflix season in the first 30 days after it premiered, garnering slightly 28% of the viewers that the second season of Daredevil received, which was the most viewed season according to Jumpstart. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
40|$|In this paper, we {{describe}} how web personalization techniques {{can be applied}} in a typical e-learning system. The central notion is the production of recommendations for studying new topics which come both from the automated processing of recorded online student behavior, {{as well as the}} manual specification of contextually related topics. The automated processing is based on knowledge discovery techniques and is preceded by web usage mining applied on user <b>click-streams.</b> The produced recommendations guide individual learners through the available material suggesting “interesting ” link shortcuts, which wouldn’t otherwise be discovered (at least not as many and not as fast) ...|$|R
40|$|International audienceThe {{database}} {{community is}} exploring {{more and more}} multidisciplinary avenues: Data semantics overlaps with ontology management; reasoning tasks venture into the domain of artificial intelligence; and data stream management and information retrieval shake hands, e. g., when processing Web <b>click-streams.</b> These new research avenues become evident, for example, in the topics that doctoral students choose for their dissertations. This paper surveys the emerging multidisciplinary research by doctoral students in database systems and related areas. It {{is based on the}} PIKM 2010, which is the 3 rd Ph. D. workshop at the International Conference on Information and Knowledge Management (CIKM). The topics addressed include ontology development, data streams, natural language processing, medical databases, green energy, cloud computing, and exploratory search. In addition to core ideas from the workshop, we list some open research questions in these multidisciplinary areas...|$|R
40|$|How to {{accurately}} predict search engine switch behavior {{is a very}} important but challenging problem. This paper describes the solution of GraphLab team that achieves the 4 th place for WSCD 2013 Search Engine Switch Detect contest sponsored by Yandex. There are three core steps in our solution: Feature extraction, Prediction, and Model ensemble. First, we extract features related to the quality of result, user preference and search behavior sequence pattern from user actions, query logs, and sequence patterns of <b>click-streams.</b> Second, models like Online Bayesian Probit Regression (BPR), Online Bayesian Matrix Factorization(BMF), Support Vector Regression (SVR), Logistic Regression(LR) and Factorization Machine Model (FM) are exploited based on the previous features. Finally, we propose a two-step ensemble method to blend our individual models in order to fully exploit the dataset and get more accurate result based on the local and public test dataset. Our final solution achieves 0. 8439 AUC on the public leaderboard and 0. 8432 AUC on the private test set...|$|R
50|$|Another {{problem is}} cookie deletion. When web {{analytics}} depend on cookies to identify unique visitors, {{the statistics are}} dependent on a persistent cookie to hold a unique visitor ID. When users delete cookies, they usually delete both first- and third-party cookies. If this is done between interactions with the site, the user will appear as a first-time visitor at their next interaction point. Without a persistent and unique visitor id, conversions, <b>click-stream</b> analysis, and other metrics dependent on the activities of a unique visitor over time, cannot be accurate.|$|E
50|$|In early 2008 it was {{announced}} that TalkTalk had entered into an agreement (along with BT and Virgin Media) with the former spyware company Phorm to intercept and analyse their users' <b>click-stream</b> data, and sell the anonymised aggregate information as part of Phorm's OIX advertising service. At the time, TalkTalk confirmed that the new Phorm system, when implemented, would be a strictly opt-in service. In July 2009, Charles Dunstone, CEO of TalkTalk Group announced that TalkTalk had withdrawn plans to introduce Phorm, along with a similar announcement from BT in the same week.|$|E
50|$|An {{underlying}} {{assumption is}} that {{a high level of}} big data maturity correlates with an increase in revenue and reduction in operational expense. However, reaching the highest level of maturity involves major investments over many years. Only a few companies are considered to be at a “Mature” stage of big data and analytics. These include internet-based companies (such as LinkedIn, Facebook, and Amazon) and other non-internet-based companies, including financial institutions (fraud analysis, real-time customer messaging and behavioral modeling) and retail organizations (<b>click-stream</b> analytics together with self-service analytics for teams).|$|E
40|$|Recent {{years have}} {{witnessed}} {{a new class}} of monitoring applications that need to continuously collect information from remote data sources. Those data sources, such as web <b>click-streams,</b> stock quotes, and sensor data, are often characterized as fast-rate highvolume “streams”. Distributed stream-processing systems are thus designed to efficiently use system resources to serve the data-acquisition needs of the applications. Most of the state-of-the-art stream-processing systems assume an Ethernet-based network whose bandwidth is abundant, and focus on mechanisms to save computational power and memory. For applications involving wireless networks, particularly multi-hop mesh networks, we recognize that the most limiting factor in efficiently processing streams lies in the network’s highly constrained bandwidth. Hence, this dissertation proposes a group-aware stream filtering approach that saves bandwidth at the cost of increased CPU time, for low-bandwidth data-streaming systems. This approach, used together with multicasting, exploits two overlooked properties of monitoring applications: 1) many of them can tolerate some degree of “slack ” in their dat...|$|R
40|$|A {{complex system}} creates a “whole that {{is larger than}} the sum of its parts,” by {{coordinating}} many interacting simpler component processes. Yet, each of these processes is difficult to decipher as their visible signatures are only seen in a syntactic background, devoid of the context. Examples of such visible datasets are time-course description of gene-expression abundance levels, neural spike-trains, or <b>click-streams</b> for web pages. It has now become rather effortless to collect voluminous datasets of this nature; but how can we make sense of them and draw significant conclusions? For instance, in the case of time-course gene-expression datasets, rather than following small sets of known genes, can we develop a holistic approach that provides a view of the entire system as it evolves through time? We have developed GOALIE (Gene-Ontology for Algorithmic Logic and Invariant Extraction) - a systems biology application that presents global and dynamic perspectives (e. g., invariants) inferred collectively over a gene-expression dataset. Such perspectives are important in order to obtain a process-level understanding of the underlying cellular machinery; especially how cells react, respond, and recover fro...|$|R
30|$|Recently, {{businesses}} {{particularly the}} enterprises are turning into big data systems. The collection of large data streams from Web users’ personal data streams (<b>click-streams,</b> ambulation activities, geo-locations, and health records) {{and integration of}} those data streams with personalized services is a key challenge [34]. The collection of irrelevant data streams increases the computational burden that directly affects the operational cost of enterprises. Therefore, the collection of fine-grained, highly relevant, and reduced data streams from users is another challenge that requires serious attention while designing big data systems. Currently, user data collection by third parties without explicit consent and information about commercialization is raising the privacy issues. The participatory personal data where users collect and mine their own data and participate for further utilization and customization of services in ubiquitous environments can {{address the issue of}} fine-grained data availability for enterprises. Keeping in view the big data complexity, the need for big data reduction, and analyzing big data reduction problem in different perspective, we present a thorough literature review of the methods for big data reduction.|$|R
5000|$|For example, {{customer}} service centers are using CEP for <b>click-stream</b> analysis and customer experience management. CEP software can factor real-time information about millions of events (clicks or other interactions) per second into business intelligence and other decision-support applications. These [...] "recommendation applications" [...] help agents provide personalized service based on each customer's experience. The CEP application may collect data about what customers {{on the phone}} are currently doing, or how they have recently interacted with the company in other various channels, including in-branch, or on the Web via self-service features, instant messaging and email. The application then analyzes the total customer experience and recommends scripts or next steps that guide the agent on the phone, and hopefully keep the customer happy.|$|E
5000|$|In early 2008 it was {{announced}} that the ISP arm of Virgin Media had entered into a contract (along with BT and TalkTalk) with the former spyware company Phorm (responsible under their 121Media guise for the Apropos rootkit) to intercept and analyse their users' <b>click-stream</b> data, and sell the anonymised aggregate information as part of Phorm's OIX advertising service. The practice, which has become known as [...] "data pimping", came under intense fire from various internet communities and other interested parties who believe that the interception of data is illegal under UK law (RIPA). At a more fundamental level, many have argued that the ISPs and Phorm have no right to sell a commodity (a user's data) to which they have no claim of ownership.|$|E
5000|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Symphony Technology Group compiled data for the season based on people using software on their phones that measures television viewing by detecting a program's sound. According to Symphony, the second season of Daredevil had 5.94% of viewers age 18-49 watching in an average minute in the first 32 days following its release. Symphony also estimated that 3.201 million viewers age 18-49 were watching an episode of Daredevil second season over the average minute in its first weekend of release. The marketing analytics firm Jumpshot determined the season was the most viewed Netflix season in the first 30 days after it premiered. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
40|$|When {{more and}} more people use web-based {{information}}, information of how they use the information is also available in the form of log data. Analysing such data can help information provider to understand their clients’ interests over the information space being served, and adapt it according to users point of view. This paper describes a novel way of applying data mining techniques on Internet logging data in order to find correlated web sections from users’ point of view. We explain how data from the log file can be transformed into a set of transactional <b>click-streams</b> and how data mining techniques can be applied on these transactions. A test bed has been developed for transforming web log data and discovering association rules from it. Real log data from Microsoft web site is used in experiments and evaluation results show that the approach is effective in obtaining useful knowledge of users correlated interests at a particular web site. We also make some effort on mining other service log data obtained from IRAIA project, an information retrieval system serving economical data...|$|R
40|$|Users often {{access and}} re-access {{more than one}} site during an online session, {{effectively}} engaging in multitasking. In this paper, we study the effect of online multitasking on two widely used engagement metrics designed to capture users browsing behavior with a site. Our study is based on browsing data of 2. 5 M users across 760 sites encompassing diverse types of services such as social media, news and mail. To account for multitasking we need to redefine how user sessions are represented {{and we need to}} adapt the metrics under study. We introduce a new representation of user sessions: tree-streams – as opposed to the commonly used <b>click-streams</b> – present a more accurate picture of the browsing behavior of a user that includes how users switch between sites (e. g., hyperlinking, teleporting, backpaging). We then discuss a number of insights on multitasking patterns, and show how these help to better understand how users engage with sites. Finally, we define metrics that characterize multitasking during online sessions and show how they provide additional insights to standard engagement metrics...|$|R
40|$|Data Streams {{occur in}} a variety of modern {{applications}} such as network monitoring, traffic engineering, sensor networks, RFID tags applications, telecom call records, medical records, financial applications, Web logs, <b>click-streams.</b> Even on the Web, blogs, feeds, and microblogs are increasingly adopted to distribute and present information in real-time streams. While Specialized Stream Database Management Systems - for on the fly analysis of data streams - were developed by the database community; the knowledge representation and reasoning community appears to have neglected or forgotten the problem. It is now the right time to look at it: reasoners are year after year scaling up in the classical, time invariant domain of ontological knowledge; and many application areas perceive the need to perform complex reasoning tasks that require combining streaming data with evolving knowledge. We hereby propose stream reasoning - an unexplored, yet high impact, research area - as the new multi-disciplinary approach which will provide the abstractions, foundations, methods, and tools required to integrate data streams and reasoning systems. In particular the focus {{of this paper is to}} sketch the research agenda for those that would like to start looking at Stream Reasoning...|$|R
5000|$|In early 2008 it was {{announced}} that BT had entered into a contract (along with Virgin Media and TalkTalk) with the spyware company Phorm (responsible under their 121Media guise for the Apropos rootkit) to intercept and analyse their users' <b>click-stream</b> data and sell the anonymised aggregate information as part of Phorm's OIX advertising service. The practice, known as [...] "behavioural targeting" [...] and condemned by critics as [...] "data pimping", came under intense fire from various internet communities and other interested-parties who believe that the interception of data without the consent of users and web site owners is illegal under UK law (RIPA). At a more fundamental level, many have argued that the ISPs and Phorm have no right to sell a commodity (a user's data, and the copyright content of web sites) to which they have no claim of ownership. In response to questions about Phorm and the interception of data by the Webwise system Sir Tim Berners-Lee, credited as the creator of the World Wide Web protocol, indicated his disapproval of the concept and is quoted as saying of his data and web history: ...|$|E
5000|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Symphony Technology Group compiled data for the season based on people using software on their phones that measures television viewing by detecting a program's sound. According to Symphony, Luke Cage opened stronger initially than the Netflix original series Making a Murderer and Stranger Things, but its performance over its first month fell short of both, comparatively. Symphony estimated that 6.34% of viewers age 18-49 were watching Luke Cage in an average minute in the first 32 days following its release, with Making a Murderer and Stranger Things seeing 9.1% and 9.81% of viewers, respectively. Symphony also estimated that 3.388 million viewers age 18-49 were watching an episode of Luke Cage over the average minute in its first weekend of release. The marketing analytics firm Jumpshot determined the season was the fourth-most viewed Netflix season in the first 30 days after it premiered, garnering slightly more than 25% of the viewers that the second season of Daredevil received, which was the most viewed season according to Jumpstart. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
5000|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Symphony Technology Group compiled data for the season based on a sample size of 15,000 people using software on their phones that measures television viewing by detecting a program's sound. According to Symphony, from September to December 2015, episodes of Jessica Jones averaged 4.8 million viewers during a 35-day viewing cycle. The data was presented by Alan Wurtzel, NBCUniversal president of research and media development, in a presentation aimed to provide [...] "perspective" [...] when stating [...] "digital platforms are hurting the traditional TV business". Netflix CCO Ted Sarandos responded to the data by saying that [...] "the whole methodology and the measurement and the data itself doesn’t reflect any sense of reality of anything that we keep track of." [...] A further study from Symphony, for the same time period, found Jessica Jones {{to be one of}} the four most watched series in the 18 to 24 demographic, ahead of any broadcast network series. The marketing analytics firm Jumpshot determined the season was the fifth-most viewed Netflix season in the first 30 days after it premiered, garnering slightly more than 25% of the viewers that the second season of Daredevil received, which was the most viewed season according to Jumpstart. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
40|$|Thesis (M. A.) [...] Özyeğin University, Graduate School of Sciences and Engineering, Department of Computer Engineering, June 2013. The {{world has}} seen {{proliferation}} of data stream applications {{over the last}} years. These applications include computer network monitoring, Radio Frequency Identication (RFID) -based supply chain and traffic management systems, e-trading, online financial transactions, web <b>click-streams,</b> some mobile communication applications, and civilian or military applications using sensor networks. All of these applications are considered ?mission-critical? by related organizations and require real-time stream processing to detect simple or complex events, so that strategic decisions can be made quickly. An emerging system architecture called Data Stream Management System (DSMS) is well-suited to address the analysis needs of emerging data stream applications. DSMS forms the basis for our project and allows processing of high-speed data streams with different continuous queries. In this thesis, we present design and implementation details of a data stream management system with advanced Complex Event Processing (CEP) capabilities. Specifically, we add ?online? Association Rule Mining (ARM) and testing capabilities {{on top of an}} open-source DSMS system and demonstrate its capabilities over fast data streams. Our most important findings show that online ARM can generate (1) more unique rules, (2) with higher throughput, (3) much sooner (lower latency) than online rule mining. In addition, we have found many interesting and realistic musical preference rules such as ?If a person listens to George Harrison, then s/he also listens to The Beatles?. We demonstrate a sustained rate of 15 K rows/sec per core. We hope that our findings can shed light on the design and implementation of other fast data analytics systems in the future...|$|R
40|$|Data streams {{arise in}} a variety of applications, such as feeds from {{financial}} markets, event streams from sensors and medical devices, logs produced by long-running programs, <b>click-streams</b> from websites, and packet sequences passing through internet routers. In this thesis, we are concerned with computing quantitative statistics over these streams, and with expressing transformations in the related domain of strings. Many string transformations are instances of simple patterns, such as inserting, deleting and replacing substrings, or applying a function to each element in the stream. Over data streams, the task is usually to compute some simple quantitative statistic, such as counting the number of occurrences of a pattern or the mean time between occurrences of an event. ^ There has traditionally been limited programming language support for stream processing, and programmers are forced to write low-level code, by manually maintaining state and updating it on seeing each new input element. This sacrifices both ease of expression and amenability to static analysis. We propose a simple, expressive programming model for stream transformations, with strong theoretical foundations and fast evaluation algorithms. ^ We present two concrete systems: DReX, to express string-to-string transformations, and quantitative regular expressions (QREs) for numerical queries. Both formalisms start with a set of basic functions and a small collection of hierarchically composable combinators, analogous to the operations of regular expressions. The operators are simple to describe, and can be used to combine small, easy-to-understand expressions into more complicated expressions. ^ The functions expressible using DReX and QREs coincide with the class of regular string transformations, which is a robust class with multiple characterizations and appealing closure properties (under composition, input reversal, and regular look-ahead). We present a single-pass linear-time evaluation algorithm for function expressions, and study efficient approximate representations of numerical terms, so that some numerical QREs can also be evaluated with sub-linear memory requirements. ...|$|R
5000|$|As Netflix {{does not}} reveal {{subscriber}} viewership numbers {{for any of}} their original series, Parrot Analytics determined the season was generating the second-highest demand among the Marvel Netflix series during their respective launch weeks. Parrot calculated that Iron Fist was generating over 63 million [...] "Demand Expressions" [...] at its peak, behind Luke Cages 69 million, with Parrot calculating expressions [...] "by evaluating streaming video, P2P-sharing, social chatter, and more." [...] 7Park Data, which measures the number of streams on subscription video services, determined Iron Fist {{to be the most}} binge-watched premiere for Netflix in 2017. It found that 54.7% of Iron Fist streams on March 17, 2017 were of three episodes or more, against the average hour-long show binge score of 46.9%. 7Park Data also determined that Iron Fist accounted for 14.6% of all Netflix streams on its premiere date, the highest percentage of any series premiere measured by the company, beating the second season of Daredevil (13.8%) and Luke Cage (12.8%) on their premiere dates. Parrot later revealed that demand for Iron Fist a week after it launched was cut in half. This was the largest drop in retention between the four Marvel Netflix series, potentially indicating [...] "that people started binge-watching the show in its first few days and then didn't come back to finish the season the next weekend." [...] The marketing analytics firm Jumpshot determined the season was the third-most viewed Netflix season in the first 30 days after it premiered, garnering slightly more than 25% of the viewers that the second season of Daredevil received, which was the most viewed season according to Jumpstart. Jumpshot, which [...] "analyzes <b>click-stream</b> data from an online panel of more than 100 million consumers", looked at the viewing behavior and activity of the company’s U.S. members, factoring in the relative number of U.S. Netflix viewers who watched at least one episode of the season.|$|E
30|$|Kosarak dataset [37] was {{donated by}} Ferenc Bodon and {{contains}} the <b>click-stream</b> data of a hungarian on-line news portal.|$|E
40|$|The {{wealth of}} <b>click-stream</b> data {{gathered}} from your site can help {{provide insight into}} the behavior, buying habits and preferences of the prospective customers who visit your web site. To understand what type of information can be gathered, consider the behavior of a certain John Smith, who decides to buy a new pair o...|$|E
40|$|Abstract. We {{present an}} {{analysis}} of the <b>click-stream</b> data provided for the ECML/PKDD data mining challenge. We primarily focus on predicting the next page that will be visited by a user based on a history of visited pages. We compare results of one statistical and two rule-based methods, and discuss interesting patterns that appear in the data. ...|$|E
40|$|This paper {{looks at}} the demand for Internet news sites before and after September 11. Analyzing {{information}} obtained from actual <b>click-stream</b> activity, support is found for {{the view that the}} events of September 11 changed the way households used the Internet to obtain information and news. These changes are observed long after September 11. Internet Activity, Household Behavior, September 11,...|$|E
40|$|In {{the last}} few years {{the number of people that}} used Internet has {{enormously}} increased. Companies promote and sell their products on the Web, institutions provide information about their services and single individuals exploit personal Web pages to be introduced to the whole Internet community. Every time a user links up at a web site, the server keeps track of all the actions accomplished in the log file. What is captured is the “click flow”, <b>click-stream,</b> of the mouse and the keys used by the user during the navigation inside the site. Usually at every click of the mouse corresponds the visualization of a web page. Therefore, the <b>click-stream</b> is commonly defined as the sequence of the requested pages. The succession of the pages seen by a single user during his navigation inside the Web identifies an user session. The set of the pages seen, inside a user session, coming from a determinate site is known with the term server session. All this information can be profitably used to efficiently design a Web site. A Web page is well designed if it is able to attract users and addresse...|$|E
40|$|Predicting {{the next}} request of a user as she visits Web pages has gained {{importance}} as Web-based activity increases. Markov models and their variations, or models based on sequence mining {{have been found}} well suited for this problem. However, higher order Markov models are extremely complicated due to their large number of states whereas lower order Markov models do not capture the entire behavior of a user in a session. The models {{that are based on}} sequential pattern mining only consider the frequent sequences in the data set, making it di#cult to predict the next request following a page that is not in the sequential pattern. Furthermore, it is hard to find models for mining two di#erent kinds of information of a user session. We propose a new model that considers both the order information of pages in a session and the time spent on them. We cluster user sessions based on their pair-wise similarity and represent the resulting clusters by a <b>click-stream</b> tree. The new user session is then assigned to a cluster based on a similarity measure. The <b>click-stream</b> tree of that cluster is used to generate the recommendation set. The model can be used as part of a cache prefetching system as well as a recommendation model...|$|E
