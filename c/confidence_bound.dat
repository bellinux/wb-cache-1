297|864|Public
5000|$|LinUCB (Upper <b>Confidence</b> <b>Bound)</b> algorithm: {{the authors}} assume a linear {{dependency}} between the expected reward {{of an action}} and its context and model the representation space using a set of linear predictors.|$|E
5000|$|In a first-person {{account for}} Canadian {{magazine}} <b>Confidence</b> <b>Bound,</b> McCallion credited her faith with giving her energy, {{and said she}} still does her own household chores. [...] "Housework and gardening are great forms of exercise and keep one humble." ...|$|E
5000|$|This is how Gott {{produces}} a 97.5% confidence of extinction within N ≤ 8,000,000 years. The number he quoted was the likely time remaining, N − n = 7.8 million years. This was {{much higher than}} the temporal <b>confidence</b> <b>bound</b> produced by counting births, because it applied the principle of indifference to time. (Producing different estimates by sampling different parameters in the same hypothesis is Bertrand's paradox.) ...|$|E
50|$|More recently, {{researchers}} have generalized algorithms from traditional MAB to dueling bandits: Relative Upper <b>Confidence</b> <b>Bounds</b> (RUCB), Relative EXponential weighing (REX3), Copeland <b>Confidence</b> <b>Bounds</b> (CCB), Relative Minimum Empirical Divergence (RMED), and Double Thompson Sampling (DTS).|$|R
40|$|AbstractAsymptotic <b>confidence</b> <b>bounds</b> on the {{location}} parameters of the linear growth curve, asymptotic distribution of the canonical correlations and asymptotic <b>confidence</b> <b>bounds</b> on the discriminatory value for the linear discriminant function are established when a set of independent observations are taken from an elliptical distribution (or from a distribution possessing some properties on the moments) ...|$|R
40|$|Let[Sigma]be {{an unknown}} {{covariance}} matrix. Perturbation (in) equalities are derived for various scale-invariant functionals of[Sigma]such as correlations (including partial, multiple and canonical correlations) or angles between eigenspaces. These {{results show that}} a particular confidence set for[Sigma]is canonical if one is interested in simultaneous <b>confidence</b> <b>bounds</b> for these functionals. The confidence set {{is based on the}} ratio of the extreme eigenvalues of[Sigma]- 1 S, whereSis an estimator for[Sigma]. Asymptotic considerations for the classical Wishart model show that the resulting <b>confidence</b> <b>bounds</b> are substantially smaller than those obtained by inverting likelihood ratio tests. correlation (partial, multiple, canonical), eigenspace, eigenvalue, extreme roots, Fisher's Z-transformation, nonlinear, perturation inequality, prediction error, scatter matrix, simultaneous <b>confidence</b> <b>bounds.</b> ...|$|R
50|$|The {{spatially}} correlated multi-armed bandit (SCMAB) {{was introduced}} by Wu, Schulz, Speekenbrink, Nelson, and Meder (2017), to study how humans generalize from observed to unobserved outcomes in limited horizon search. An underlying reward function was used to map the spatial location of each playable arm of the bandit to a mean reward, where the correlation between rewards decreased as an exponential function of the distance between two arms (generated using a radial basis function kernel). So far, SCMABs {{have been used to}} study human behavior, with the finding that human choices are best predicted by combining Gaussian process regression as a function learning mechanism with Upper <b>confidence</b> <b>bound</b> sampling.|$|E
50|$|Multi-armed bandit {{problem with}} known trend is {{a variant of}} the multi-armed bandit model, where the gambler knows the shape of the reward {{function}} of each arm but not its distribution. This new problem is motivated by different on-line problems like active learning, music and interface recommendation applications, where when an arm is sampled by the model the received reward change according to a known trend. By adapting the standard multi-armed bandit algorithm UCB1 {{to take advantage of this}} setting, the authors in propose the new algorithm named Adjusted Upper <b>Confidence</b> <b>Bound</b> (A-UCB) that assumes a stochastic model and provide upper bounds of the regret which compare favorably with the ones of UCB1.|$|E
50|$|A popular {{method for}} {{developing}} GGP AI is the Monte Carlo tree search (MCTS) algorithm. Often used {{together with the}} UCT method (Upper <b>Confidence</b> <b>Bound</b> applied to Trees), variations of MCTS have been proposed to better play certain games, {{as well as to}} make it compatible with video game playing. Another variation of tree search algorithms used is the Directed Breadth First Search (DBS), in which a child node to the current state is created for each available action, and visits each child ordered by highest average reward, until either the game ends or runs out of time. In each tree search method, the AI simulates potential actions and ranks each based on the average highest reward of each path, in terms of points earned.|$|E
40|$|We present here {{by direct}} {{argument}} the classical Clopper-Pearson (1934) “exact ” <b>confidence</b> <b>bounds</b> and corresponding intervals for the parameter p of the binomial distribution. The same arguments {{can be applied}} to derive <b>confidence</b> <b>bounds</b> and intervals for the negative binomial parameter p, for the Poisson parameter λ, for the ratio of two Poisson parameters, ρ = λ 1 /λ 2, and for the paramete...|$|R
40|$|Asymptotic <b>confidence</b> <b>bounds</b> on the {{location}} parameters of the linear growth curve, asymptotic distribution of the canonical correlations and asymptotic <b>confidence</b> <b>bounds</b> on the discriminatory value for the linear discriminant function are established when a set of independent observations are taken from an elliptical distribution (or from a distribution possessing some properties on the moments). linear growth curve canonical correlations discriminatory value central limit theorems asymptotic confindence bounds asymptotically independent normals...|$|R
40|$|AbstractThe paper {{extends the}} results of Khatri to complex {{elliptical}} variates. Asymptotic <b>confidence</b> <b>bounds</b> on location parameters for the linear growth curve for the complex variates, the asymptotic distribution of the canonical correlations for {{the two sets of}} complex variates, and the asymptotic <b>confidence</b> <b>bounds</b> for the discriminatory values for the linear Fisher's discriminator for the future complex observation z are developed in this paper on the lines given by Khatri...|$|R
50|$|In {{response}} to these challenges, the authors in DRARS, A Dynamic Risk-Aware Recommender System have developed a dynamic risk sensitive recommendation system called DRARS (Dynamic Risk-Aware Recommender System), which models the context-aware recommendation as a bandit problem. This system combines a content-based technique and a contextual bandit algorithm. They have shown that DRARS improves the Upper <b>Confidence</b> <b>Bound</b> (UCB) policy, the currently available best algorithm, by calculating the most optimal exploration value to maintain a trade-off between exploration and exploitation based on the risk level of the current user's situation. The authors conducted experiments in an industrial context with real data and real users and have shown that {{taking into account the}} risk level of users' situations significantly increased the performance of the recommender systems.|$|E
5000|$|The main {{difficulty}} in selecting child nodes is maintaining some {{balance between the}} exploitation of deep variants after moves with high average win rate and the exploration of moves with few simulations. The first formula for balancing exploitation and exploration in games, called UCT (Upper <b>Confidence</b> <b>Bound</b> 1 applied to trees), was introduced by Levente Kocsis and Csaba Szepesvári. UCT {{is based on the}} UCB1 formula derived by Auer, Cesa-Bianchi, and Fischer and the provably convergent AMS (Adaptive Multi-stage Sampling) algorithm first applied to multi-stage decision making models (specifically, Markov Decision Processes) by Chang, Fu, Hu, and Marcus. Kocsis and Szepesvári recommend to choose in each node of the game tree the move for which the expression [...] has the highest value. In this formula: ...|$|E
5000|$|Another {{example is}} given by: The air lead levels were {{collected}} from [...] different areas within the facility. It was noted that the log-transformed lead levels fitted a normal distribution well (that is, the data are from a lognormal distribution. Let [...] and , respectively, denote the population mean and variance for the log-transformed data. If [...] denotes the corresponding random variable, we thus have [...] We note that exp(mu) is the median air lead level. A confidence interval for mu can be constructed the usual way, based on the t-distribution; this in turn will provide a confidence interval for the median air lead level. If [...] and S denote the sample {{mean and standard deviation}} of the log-transformed data for a sample of size n, a 95% confidence interval for mu is given by , where [...] denotes the 1-alpha quantile of a t-distribution with m degrees of freedom. It may also be of interest to derive a 95% upper <b>confidence</b> <b>bound</b> for the median air lead level. Such a bound for mu is given by [...] Consequently, a 95% upper <b>confidence</b> <b>bound</b> for the median air lead is given by [...] Now suppose we want to predict the air lead level at a particular area within the laboratory. A 95% upper prediction limit for the log-transformed lead level is given by [...] A two-sided prediction interval can be similarly computed. The meaning and interpretation of these intervals are well known. For example, if the confidence interval [...] is computed repeatedly from independent samples, 95% of the intervals so computed will include the true value of , in the long run. In other words, the interval is meant to provide information concerning the parameter [...] only. A prediction interval has a similar interpretation, and is meant to provide information concerning a single lead level only. Now suppose we want to use the sample to conclude whether or not at least 95% of the population lead levels are below a threshold. The confidence interval and prediction interval cannot answer this question, since the confidence interval is only for the median lead level, and the prediction interval is only for a single lead level. What is required is a tolerance interval; more specifically, an upper tolerance limit. The upper tolerance limit is to be computed subject to the condition that at least 95% of the population lead levels is below the limit, with a certain confidence level, say 99%.|$|E
5000|$|... lower 95% CI {{and upper}} 95% CI are the lower and upper 95% <b>confidence</b> <b>bounds</b> for the {{proportion}} surviving.|$|R
40|$|The {{problem of}} {{providing}} lower <b>confidence</b> <b>bounds</b> for the mean improvements of p ? 2 test treatments over a control treatment is considered. The expected average and expected maximum allowances are two criteria for comparing different systems of <b>confidence</b> intervals or <b>bounds.</b> In this paper, lower bounds are derived for the expected average allowance and the expected maximum allowance of Dunnett's simultaneous lower <b>confidence</b> <b>bounds</b> for the p mean improvements. These lower bounds hold for any p ? 2 and any allocation of sample sizes. For p = 2 test treatments, sample allocations are given {{for which the}} bounds are achievable. For p = 3 test treatments, a tighter set of bounds is derived which enables easy determination of the sample allocation required to achieve highly efficient designs. A table of the bounds for the expected average and expected maximum allowances and the sample allocation that achieves these bounds is given for p = 2, 3. The theoretical results can easily be adapted to cover upper <b>confidence</b> <b>bounds...</b>|$|R
40|$|Abstract: This paper {{explores the}} {{information}} FIA data can produce regarding forest types {{that were not}} sampled and develops the equations necessary to define the upper <b>confidence</b> <b>bounds</b> on not-sampled forest types. The problem is reduced to a Bernoulli variable. This simplification allows the upper <b>confidence</b> <b>bounds</b> to be calculated based on Cochran (1977). Examples are provided that demonstrate how the resultant equations are relevant to creating mid-level vegetation maps by assisting {{in the development of}} statistically defensible map units...|$|R
40|$|When {{artifical}} {{neural networks}} (ANN) {{are used in}} the prediction problems, it is usually desirable that some form of <b>confidence</b> <b>bound</b> is placed on the predicted value. Methods to estimate the <b>confidence</b> <b>bound</b> are available. However, these methods are valid under certain assumptions, which are rarely satisfied in practice. The behavior of the estimated <b>confidence</b> <b>bound</b> are not well understood when the assumptions are violated. We have designed some test functions to examine the behavior, and suggest how the estimated <b>confidence</b> <b>bound</b> can be corrected. The suggested method is used in the prediction of rock porosity values from seismic data for oil reservoir characterisation...|$|E
40|$|This paper {{considers}} {{the construction of}} an upper <b>confidence</b> <b>bound</b> on the range of a set of p (? 2) location parameters following a sequential range test. Although details are given only for the one-way analysis of variance model with known variance, generalisation to other situations is pointed out. This upper <b>confidence</b> <b>bound</b> is useful in assessing the equivalence of all the location parameters. An illustrative example is give...|$|E
30|$|A novel feedback-control-based {{adaptive}} defense algorithm {{extended from}} UCB (Upper <b>Confidence</b> <b>Bound)</b> algorithm (Auer et al. 2002) is proposed.|$|E
40|$|We {{extend the}} results of Gupta and Liang (1998), derived for {{location}} parameters, to obtain lower <b>confidence</b> <b>bounds</b> for the probability of correctly selecting the t best populations (PCSt) simultaneously for all t= 1,…,k− 1 for the general scale parameter models, where k {{is the number of}} populations involved in the selection problem. The application of the results to the exponential and normal probability models is discussed. The implementation of the simultaneous lower <b>confidence</b> <b>bounds</b> for PCSt is illustrated through real-life datasets...|$|R
40|$|The paper {{develops}} {{and studies}} simultaneous <b>confidence</b> <b>bounds</b> that {{are useful for}} making low dose inferences in quantitative risk analysis. Application is intended for risk assessment studies where human, animal or ecological data are used to set safe low dose levels of a toxic agent, but where study information is limited to high dose levels of the agent. Methods are derived for estimating simultaneous, one-sided, upper confidence limits on risk for end points measured on a continuous scale. From the simultaneous <b>confidence</b> <b>bounds,</b> lower <b>confidence</b> limits on the dose {{that is associated with}} a particular risk (often referred to as a "bench-mark dose") are calculated. An important feature of the simultaneous construction is that any inferences that are based on inverting the simultaneous <b>confidence</b> <b>bounds</b> apply automatically to inverse bounds on the bench-mark dose. Copyright 2005 Royal Statistical Society. ...|$|R
40|$|Summary. In {{this paper}} the {{implications}} of certain results obtained in earlier papers;- 1, 2, 3, 47 on <b>confidence</b> <b>bounds</b> on parametric functions connected with multivariate normal populations are fully worked out. This leads {{to a number of}} <b>confidence</b> <b>bounds,</b> expected to be useful, but hitherto unnoticed, (i) on the characteristic roots of one population dispersion matrix and on roots connected with (ii) two population dispersion matrices, (iii) the regression matrix of a p-set on a q-set and (iv) multivariate linear hyoothesis on means, including, in?articular,the problem of discriminant analysis. 1. <b>Confidence</b> <b>bounds</b> on roots connected with Z of N(~,Z). Let us Il. ~ start from the statement 0. 1, 2) of £ 2 J and note that the statement is exactly equivalent to (1. 1) for all nonnull a(p x l) 's, that is, t...|$|R
40|$|This article {{considers}} {{the construction of}} an upper <b>confidence</b> <b>bound</b> on the range of a set of k location parameters, such as the k treatment effects in a one-way layout. This <b>confidence</b> <b>bound</b> will be useful to the experimenter in assessing the “equivalence” of the location parameters. Some general theoretical results are presented and the case of normally distributed data is considered in detail, with accompanying tables of confidence bounds. Some examples of the application of this new inference method are given...|$|E
40|$|Contextual bandits {{are widely}} used in Internet {{services}} from news recommendation to advertising, and to Web search. Generalized linear models (logistical regression in particular) have demonstrated stronger performance than linear models in many applications where rewards are binary. However, most theoretical analyses on contextual bandits so far are on linear bandits. In this work, we propose an upper <b>confidence</b> <b>bound</b> based algorithm for generalized linear contextual bandits, which achieves an Õ(√(dT)) regret over T rounds with d dimensional feature vectors. This regret matches the minimax lower bound, up to logarithmic terms, and improves on the best previous result by a √(d) factor, assuming the number of arms is fixed. A key component in our analysis {{is to establish a}} new, sharp finite-sample <b>confidence</b> <b>bound</b> for maximum-likelihood estimates in generalized linear models, which may be of independent interest. We also analyze a simpler upper <b>confidence</b> <b>bound</b> algorithm, which is useful in practice, and prove it to have optimal regret for certain cases. Comment: Published at ICML 201...|$|E
40|$|For a {{wireless}} avionics communication system, a Multi-arm bandit game is mathematically formulated, which includes channel states, strategies, and rewards. The simple case includes only two agents sharing the spectrum which is fully studied {{in terms of}} maximizing the cumulative reward over a finite time horizon. An Upper <b>Confidence</b> <b>Bound</b> (UCB) algorithm is used to achieve the optimal solutions for the stochastic Multi-Arm Bandit (MAB) problem. Also, the MAB problem can also be solved from the Markov game framework perspective. Meanwhile, Thompson Sampling (TS) is also used as benchmark to evaluate the proposed approach performance. Numerical results are also provided regarding minimizing the expectation of the regret and choosing the best parameter for the upper <b>confidence</b> <b>bound...</b>|$|E
40|$|The paper {{extends the}} results of Khatri to complex {{elliptical}} variates. Asymptotic <b>confidence</b> <b>bounds</b> on location parameters for the linear growth curve for the complex variates, the asymptotic distribution of the canonical correlations for {{the two sets of}} complex variates, and the asymptotic <b>confidence</b> <b>bounds</b> for the discriminatory values for the linear Fisher's discriminator for the future complex observation z are developed in this paper on the lines given by Khatri. elliptical complex variates linear growth curve model canonical correlations discriminator value Fisher's linear discriminator...|$|R
40|$|The {{iterative}} advanced {{mean value}} algorithm (AMV+), introduced nearly ten years ago, is now widely {{used as a}} cost-effective probabilistic structural analysis tool when the use of sampling methods is cost prohibitive (Wu et al., 1990). The need to establish <b>confidence</b> <b>bounds</b> on calculated probabilities arises {{because of the presence}} of uncertainties in measured means and variances of input random variables. In this paper an algorithm is proposed that makes use of the AMV+ procedure and analytically derived probability sensitivities to determine <b>confidence</b> <b>bounds</b> on calculated probabilities...|$|R
40|$|Abstract—The {{application}} of multi-armed bandit (MAB) algo-rithms {{was a critical}} step {{in the development of}} Monte-Carlo tree search (MCTS). One example would be the UCT algorithm, which applies the UCB bandit algorithm. Various research has been conducted on applying other bandit algorithms to MCTS. Simple regret bandit algorithms, which aim to identify the optimal arm after a number of trials, have been of great interest in various fields in recent years. However, the simple regret bandit algorithm has the tendency to spend more time on sampling suboptimal arms, which may be a problem in the context of game tree search. In this research, we will propose combined <b>confidence</b> <b>bounds,</b> which utilize the characteristics of the <b>confidence</b> <b>bounds</b> of the improved UCB and UCB√ · algorithms to regulate exploration for simple regret minimization in MCTS. We will demonstrate the combined <b>confidence</b> <b>bounds</b> bandit algorithm has better empirical performance than that of the UCB algorithm on the MAB problem. We will show that the combined <b>confidence</b> <b>bounds</b> MCTS (CCB-MCTS) has better performance over plain UCT on the game of 9 × 9 Go, and has shown good scalability. We will also show that the performance of CCB-MCTS can be further enhanced with the {{application of}} all-moves-as-first (AMAF) heuristic. I...|$|R
40|$|In {{this study}} we {{consider}} the steady-state availability, denoted A, of a system with distribution-free failure and repair time. In particular, {{we are interested in}} constructing a lower <b>confidence</b> <b>bound</b> and a testing framework for A. We first show that the natural estimator Â of A, defined as the ratio of the failure time sample mean to the sum of the failure time sample mean and the repair time sample mean, is strongly consistent and asymptotically normal. Then using the asymptotic distribution of Â, we develop a lower <b>confidence</b> <b>bound</b> and a hypothesis test for A. Finally, a numerical simulation study is conducted in order to illustrate the performance of Â in applied inference about A...|$|E
40|$|International audienceIn {{this paper}} {{we present a}} {{framework}} for testing various algorithms that deal with transpositions in Monte-Carlo Tree Search (MCTS). We call this framework Upper <b>Confidence</b> <b>bound</b> for Direct acyclic graphs (UCD) as it constitutes an extension of Upper <b>Confidence</b> <b>bound</b> for Trees (UCT) for Direct acyclic graphs (DAG). When using transpositions in MCTS, a DAG is progressively developed instead of a tree. There are multiple ways to handle the exploration exploitation dilemma when dealing with transpositions. We propose parameterized ways to compute {{the mean of the}} child, the playouts of the parent and the playouts of the child. We test the resulting algorithms on several games. For all games, original configurations of our algorithms improve on state of the art algorithms...|$|E
40|$|Confidence {{limits for}} the {{reliability}} of series systems based on binomial component data are discussed. Several examples are given which show that Buehler optimal confidence bounds can increase in length with an increasing point estimate of reliability, a counter-intuitive result. Optimal lower <b>confidence</b> <b>bound</b> reliability series system...|$|E
30|$|The {{outline of}} {{the paper is the}} following. In Section 2 we give an {{overview}} of the recent relevant results. In Section 3 the model is described in detail, as well as the data that is used for the initialisation and calibration of the model. The focus is initially EV adoption only. In Section 4 the <b>confidence</b> <b>bounds</b> creation is explained with some simulation results shown. Then in Section 5 the adaptation of the model to include socio-demographic information is discussed. As well, <b>confidence</b> <b>bounds</b> are used {{to assess the impact of}} this new model feature. Next in Section 6 the model is further modified to investigate the combined uptake of EVs and PVs. Again, <b>confidence</b> <b>bounds</b> are computed to determine the effect of changing our model assumptions. Finally in Section 7 we discuss the implications of our results and their possible use in design, planning and policy.|$|R
50|$|ANOVA is (in part) a {{significance}} test. The American Psychological Association {{holds the}} view that simply reporting significance is insufficient and that reporting <b>confidence</b> <b>bounds</b> is preferred.|$|R
40|$|Characterizing neural spiking {{activity}} {{as a function}} of intrinsic and extrinsic factors is important in neuroscience. Point process models are valuable for capturing such information; however, the process of fully applying these models is not always obvious. A complete model application has four broad steps: specification of the model, estimation of model parameters given observed data, verification of the model using goodness of fit, and characterization of the model using <b>confidence</b> <b>bounds.</b> Of these steps, only the first three have been applied widely in the literature, suggesting the need to dedicate a discussion to how the time-rescaling theorem, in combination with parametric bootstrap sampling, can be generally used to compute <b>confidence</b> <b>bounds</b> of point process models. In our first example, we use a generalized linear model of spiking propensity to demonstrate that <b>confidence</b> <b>bounds</b> derived from bootstrap simulations are consistent with those computed from closed-form analytic solutions. In our second example, we consider an adaptive point process model of hippocampal place field plasticity for which no analytical <b>confidence</b> <b>bounds</b> can be derived. We demonstrate how to simulate bootstrap samples from adaptive point process models, how to use these samples to generate <b>confidence</b> <b>bounds,</b> and how to statistically test the hypothesis that neural representations at two time points are significantly different. These examples have been designed as useful guides for performing scientific inference based on point process models. Burroughs Wellcome FundL'Oréal-UNESCO For Women in ScienceUnited States. National Institutes of Health (MH 59733) National Institutes of Health (U. S.). Pioneer Award (DP 1 OD 003646 - 01) United States. National Institutes of Health (DA 015644) United States. National Institutes of Health (MH 58847) McKnight FoundationJohn Merck Scholars Progra...|$|R
