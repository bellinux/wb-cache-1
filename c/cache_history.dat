6|33|Public
2500|$|... "Delete Browsing History" [...] cleans the {{complete}} browsing {{history in a}} single step. Previously this was a multistage process requiring users to delete browser <b>cache,</b> <b>history,</b> cookies, saved form data and passwords {{in a series of}} different steps. This is useful for improving privacy and security in a multiuser environment, such as an Internet café.|$|E
40|$|With Internet Explorer 10, Microsoft {{changed the}} way of storing web related information. Instead of the old index. dat files, Internet Explorer 10 uses an ESE {{database}} called WebCacheV 01. dat to maintain its web <b>cache,</b> <b>history</b> and cookies. This database contains {{a wealth of information}} that can be of great interest to a forensic investigator. This thesis explores the structure of the new database, what information it contains, how it behaves in different situations, and also shows {{that it is possible to}} recover deleted database records – even when the InPrivate browsing mode has been used...|$|E
40|$|Based on {{the system}} request or {{application}} request a set of word is loaded on the cache memory. When the system is switched off the <b>cache</b> <b>history</b> gets abscond. The performance of CPU {{is based on the}} factors such as cache hit, write through cache, write back, cache memory mapping technique, CPU speed, bandwidth, cache memory size etc., Some of the standard cache addresses mapping techniques are set associative, associative and direct mapping technique. This paper proposes a novel idea of set associative cache address mapping using linear equation. The standard set associative mapping is remapped with linear set associative for to secure the data in a non sequential portion by having the standard mapping execution time. This is mainly focus on to design the cache enhancement and improvement...|$|E
2500|$|Simmonds, A.J.; In God's Lap: <b>Cache</b> Valley <b>History</b> as {{told in the}} {{newspaper}} columns of A.J. Simmonds; Logan, Utah; The Herald Journal; 2004; ...|$|R
5000|$|One {{critical}} {{feature of}} kiosk {{software is the}} ability to clear the <b>cache,</b> user <b>history</b> and data between uses and users.This prevents users from accessing private data and protects both the device & the user from unauthorized data access.|$|R
50|$|Most browsers support HTTP Secure {{and offer}} {{quick and easy}} ways to delete {{personally}} identifiable information such as the web <b>cache,</b> download <b>history,</b> form and search history, cookies, and browsing history. For {{a comparison of the}} current security vulnerabilities of browsers, see comparison of web browsers.|$|R
40|$|This project adds new cache-related {{features}} to Yioop, an Open Source, PHP-based search engine. Search engines often maintain caches of pages downloaded by their crawler. Commercial search engines like Google display {{a link to}} the cached version of a web page along with the search results for that particular web page. The first feature enables users to navigate through Yioop 2 ̆ 7 s entire cache. When a cached page is displayed along with its contents, links to cached pages saved in the past are also displayed. The feature also enables users to navigate <b>cache</b> <b>history</b> based on year and month. This feature is similar in function to the Internet Archive as it maintains snapshots of the web taken at different times. The contents of a web page can change over time. Thus, a search engine caching web pages has {{to make sure that the}} cached pages are fresh. The second feature of this project implements cache validation using information obtained from web page headers. The cache validation mechanism is implemented using Entity Tags and Expires header. The cache validation feature is then tested for effect on crawl speed and savings in bandwidth...|$|E
40|$|Caching {{is built}} up each {{time when the}} machine starts up {{according}} to user’s application usability. This built up procedure escalates the efficiency of application’s usage for the next coming access of same application. This <b>cache</b> <b>history</b> is vanished when power is switched off. Most of the time, a user uses the same common applications in his/her daily routine, particularly during the working hours. Moreover, against every new start up, the user bears the penalty of cache rebuilt to achieve better and efficient access because on first time access, the application is opened without caching which results more time to open rather than the second time after the cache has already built up. This paper proposes a novel idea of intelligent and permanent caching which can build up dynamically and can be stored permanently {{in one part of}} cache chip according to user’s application usability. This paper describes an algorithm that how CPU can build a dynamic and intelligent Electrically Editable Permanent Cache (EEPC) according to the probability of user’s application usage in a computer machine. For proposed EEPC, we implement a Probability Calculation Table (PCT) by reusing available compression techniques and through introducing some basic change in cache storage policy. On the other hand L 1 and L 2 implementation is also the part of this study; for example, History Table (HT) is maintained for L 1 and L 1 is physically addressed to the main memory. Whereas, L 2 is virtually addressed with the main memory and fully associative to handle misses. We mainly focus on Cache design enhancement, improvement in cache speed and implementation issues...|$|E
40|$|Reverse {{execution}} provides {{access to}} old states of an executing process. An application of reverse execution {{can be found in}} program debugging. When an error is detected, its cause is often hidden {{in the history of the}} process. In such situations, it is important to be able to recover and examine past states of the process. Numerous other applications of reverse execution are found in programming environments, in fault-tolerant computing and in speculative computation. Since processes are in general irreversible, the history must be saved in order to provide reverse execution. The main problem in dealing with the history is the amount of data generated. This paper describes a new approach to reverse execution based on a <b>history</b> <b>cache</b> which compacts the history. The performance of the <b>history</b> <b>cache</b> is measured on a simulator. The <b>history</b> <b>cache</b> can compact the history by more than an order of magnitude. Efficient support for reverse execution enables many new techniques such as a generi [...] ...|$|R
25|$|Features of Dillo include bookmarks, tabbed browsing, {{and support}} for JPEG, PNG (including alpha transparency), and GIF images. Partial support for CSS was {{introduced}} in release 2.1. Settings such as the default fonts, background color, downloads folder, and home page are customizable through configuration files. Cookies are supported but disabled by default due to privacy concerns. While most web browsers retain the web <b>cache</b> and <b>history</b> after the program is closed, Dillo automatically clears them to improve both privacy and performance.|$|R
5|$|Symantec {{announced}} a Professional Edition on November 19, 2002. Data recovery tools in this version allow users to recover deleted or malware-damaged files. The {{inclusion of a}} data erasure tool allows users to delete files while minimizing the chance of recovery. Web Cleanup removes browser <b>cache</b> files, <b>history,</b> and cookies. To maintain dial-up connections, Connection Keep Alive simulates online activity during periods of user inactivity. Norton Productivity Control enables users to filter Internet content and block newsgroups. When used with the User Access Manager, multiple filtering profiles can be created, assigned to different users.|$|R
50|$|Email is {{sometimes}} used to distribute passwords {{but this is}} generally an insecure method. Since most email is sent as plaintext, a message containing a password is readable without effort during transport by any eavesdropper. Further, the message will be stored as plaintext {{on at least two}} computers: the sender's and the recipient's. If it passes through intermediate systems during its travels, it will probably be stored on there as well, at least for some time, and may be copied to backup, <b>cache</b> or <b>history</b> files on any of these systems.|$|R
50|$|Symantec {{announced}} a Professional Edition on November 19, 2002. Data recovery tools in this version allow users to recover deleted or malware-damaged files. The {{inclusion of a}} data erasure tool allows users to delete files while minimizing the chance of recovery. Web Cleanup removes browser <b>cache</b> files, <b>history,</b> and cookies. To maintain dial-up connections, Connection Keep Alive simulates online activity during periods of user inactivity. Norton Productivity Control enables users to filter Internet content and block newsgroups. When used with the User Access Manager, multiple filtering profiles can be created, assigned to different users.|$|R
50|$|A {{customizable}} {{user interface}} was added as a {{feature in the}} 3.0 version launch in early 2000. Additional third party plug-ins were made available for download {{as well as the}} ability to wash the recent <b>history</b> <b>cache</b> of Windows Media Player. Increased compatibility was also added for Netscape 6, MSN, Explorer 6, and AOL 6.|$|R
50|$|The Alpha 21264 {{contained}} 15.2 million transistors. The logic {{consisted of}} approximately six million transistors, {{with the rest}} contained in the <b>caches</b> and branch <b>history</b> tables. The die measured 16.7 mm by 18.8 mm (313.96 mm²). It was fabricated in a 0.35 µm complementary metal - oxide - semiconductor (CMOS) process with six levels of interconnect.|$|R
50|$|Firefox Portable retains all of Mozilla Firefox's {{abilities}} such as extensions {{and automatic}} updating. Modifications {{to reduce the}} number of writes to the flash drive have also been added. The web <b>cache</b> and browser <b>history</b> were previously disabled under the release of 2.0. Firefox Portable's ability to delete cookies and the download history on exit is not enabled by default, as per a licensing agreement with Mozilla.|$|R
40|$|Abstract—Memristor, a long {{postulated}} yet missing circuit element, {{has recently}} {{emerged as a}} promising device in non-volatile memory technologies. However, beyond its use as memory cell, {{it is challenging to}} integrate memristor in modern architectures for general purpose computation. In this paper we propose a non-conventional use of memristor and demonstrate its applicability to enhancing cache replacement policy. We design a memristor-based saturation counter which can track <b>cache</b> access <b>history</b> at low cost. Based on our counter design, we develop a cache replacement framework that is both reconfigurable and adaptive (MRAC). Our evaluation demonstrates MRAC’s reconfigurability and adaptivity, which result in better performance (up to 57. 9 % more cache miss reduction) and more robust performance improvement. I...|$|R
50|$|An August 2009 {{study by}} the Social Science Research Network found that 50% of {{websites}} using Flash were also employing flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' <b>cache</b> and <b>history</b> delete functions do not affect Flash Player's writing Local Shared Objects to its own cache, and the user community is much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users having deleted HTTP cookies and purged browser <b>history</b> files and <b>caches</b> may {{believe that they have}} purged all tracking data from their computers when in fact Flash browsing history remains. As well as manual removal, the BetterPrivacy addon for Firefox can remove Flash cookies. Adblock Plus can be used to filter out specific threats and Flashblock can be used to give an option before allowing content on otherwise trusted sites.|$|R
50|$|The index.dat file is a {{database}} file. It is {{a repository of}} information such as web URLs, search queries and recently opened files. Its purpose is to enable quick access to data used by Internet Explorer. For example, every web address visited is stored in the index.dat file, allowing Internet Explorer to quickly find Autocomplete matches as the user types a web address. The index.dat file is user-specific and is open as long a user is logged on in Windows. Separate index.dat files exist for the Internet Explorer <b>history,</b> <b>cache,</b> and cookies.|$|R
40|$|When {{presenting}} forensic {{information to}} a court, it is cur-rently difficult to explain the data that is output from foren-sic software. In addition, the forensic investigator needs to create reports of the discovered outcomes of the investiga-tion, these reports would then {{be used by the}} lawyers and criminal investigators and integrated into their current work flows. In this paper we introduce the Fovea environment (FOrensic Visualization Exploration of Activities) that visu-alizes recovered web browsing <b>history,</b> <b>caches</b> and computer log information. We present some design decisions, present our initial development of the system and discuss challenges and some pertinent wider issues for forensic activity visual-ization. Author Keywords Visual Analytics, Forensic computing visualizatio...|$|R
5000|$|Both iOS and Android {{versions}} are free without advertising. [...] There is an advanced version called Dolphin Browser for Android 2.0 or later. Dolphin Browser Beta was also launched in May 2012 {{and at the}} time it was cited as the fastest HTML5 browser by scoring over 450 on HTML5test. The new own HTML5 engine Jetpack is used. In December 2013 Dolphin Zero was launched, a version aimed at user privacy. By deleting all traces like downloaded files, <b>caches</b> cookies and <b>history</b> after each session, Dolphin Zero strives to give the user the opportunity to hide browsed sites from the eyes of other people having access to the device.|$|R
50|$|Like the HTTP cookie, a flash cookie (also {{known as}} a “Local Shared Object”) {{can be used to}} save {{application}} data. Flash cookies are not shared across domains. An August 2009 study by the Ashkan Soltani and a team of researchers at UC Berkeley found that 50% of websites using Flash were also employing flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' <b>cache</b> and <b>history</b> suppress or delete functions did not affect Flash Player's writing Local Shared Objects to its own cache in version 10.2 and earlier, at which point the user community was much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users with those versions, having deleted HTTP cookies and purged browser <b>history</b> files and <b>caches,</b> may believe that they have purged all tracking data from their computers when in fact Flash browsing history remains. Adobe's own Flash Website Storage Settings panel, a submenu of Adobe's Flash Settings Manager web application, and other editors and toolkits can manage settings for and delete Flash Local Shared Objects.|$|R
40|$|Abstract. We propose new, tractably (in {{some cases}} provably) {{efficient}} algorithmic methods for exact (sound and complete) parameterized reasoning about cache coherence protocols. For reasoning about general snoopy <b>cache</b> protocols, <b>history</b> graph construction {{can be used}} to reason about safety properties for this framework. Although the worst case size of the abstract history graph can be exponential {{in the size of the}} transition diagram of the given protocol, the actual size is small for standard cache protocols as is evidenced by our experimental results. The framework can handle all 8 of the cache protocols in [19] as well as their split-transaction versions. We next identify a framework called initialized broadcast protocols suitable for reasoning about invalidation-based snoopy cache protocols and show how to reduce reasoning about such systems with an arbitrary number of caches to a system with at most 7 caches. This yields a provably polynomial time algorithm for the parameterized verification of invalidation based snoopy protocols. Our results apply to both safety and liveness properties. Finally, we present a methodology for reducing parameterized reasoning about directory based protocols to snoopy protocols, thus leveraging techniques developed for verifying snoopy protocols to directory based ones, which are typically are much harder to reason about. We demonstrate by reducing reasoning about a directory based protocol suggested by German [17] to the ESI snoopy protocol, a modification of the MSI snoopy protocol. ...|$|R
40|$|Microprocessor {{design is}} both complex and time consuming: Exploring a huge design space for {{identifying}} the optimal design under {{a number of}} constraints is infeasible using detailed architectural simulation of entire benchmark executions. Statistical simulation is a recently introduced approach for efficiently culling the microprocessor design space. The basic idea of statistical simulation is to collect {{a number of important}} program characteristics and to generate a synthetic trace from it. Simulating this synthetic trace is extremely fast as it contains only a million instructions. This paper improves the statistical simulation methodology by proposing accurate memory data flow models. We propose 1) cache miss correlation, or measuring cache statistics conditionally dependent on the global <b>cache</b> hit/miss <b>history,</b> for modeling <b>cache</b> miss patterns and memory-level parallelism, 2) cache line reuse distributions for modeling accesses to outstanding cache lines, and 3) through-memory read-after-write dependency distributions for modeling load forwarding and bypassing. Our experiments using the SPEC CPU 2000 benchmarks show substantial improvements compared to current state-of-the-art statistical simulation methods. For example, for our baseline configuration, we reduce the average instructions per cycle (IPC) prediction error from 10. 9 to 2. 1 percent; the maximum error observed equals 5. 8 percent. In addition, we show that performance trends are predicted very accurately, making statistical simulation enhanced with accurate data flow models a useful tool for efficient and accurate microprocessor design space explorations...|$|R
40|$|We have {{developed}} a fast handoff scheme, called AuthScan, to reduce the time-consuming channel scanning latency in IEEE 802. 11 wireless networks. AuthScan comprises two steps: First, a client <b>caches</b> its handoff <b>history</b> with beacon information. Second, when in need of handoff, a client transmits Authentication Request frames to the selected Access Points (APs) from the cache instead of broadcasting Probe Request frames in active scan to discover the next AP. Our proposed method does not require any support from the infrastructure network and contributes to finish the handoff procedure with the lowest latency when compared to approaches that improve the efficiency of channel scanning. Furthermore, AuthScan requires neither hardware upgrades to the client, nor any modification to currently deployed APs. In this paper, we present the theoretical handoff latency of AuthScan and compare it to other approaches. 1...|$|R
40|$|A {{technique}} is described for reducing miss latency in coherent-cache sharedmemory parallel computers. Miss latency {{is reduced by}} speculatively invalidating and downgrading (copying an exclusively held line back to memory) cache lines at one processor that might be needed at another processor. A line becomes a candidate for speculative invalidation when another line last accessed by the same instruction is invalidated. A line becomes a candidate for speculative downgrading under corresponding conditions. The technique can be implemented by constructing linked lists of lines for recent memory access instructions. The amount of memory needed by an implementation {{is little more than}} 11 % the size of the cache. No time need be added to cache hits. In execution-driven simulations of such systems running programs from the SPLASH 2 suite invalidations and downgrades are reduced by 50 % or more. Keywords: Multiprocessor, Coherent Caches, <b>Cache</b> Management, Instruction <b>History,</b> Speculative Inval [...] ...|$|R
40|$|Data {{prefetching}} is {{an effective}} way to bridge the increasing performance gap between processor and memory. As computing power is increasing much faster than memory performance, we suggest {{that it is time to}} have a dedicated cache to store data access histories and to serve prefetching to mask data access latency effectively. We thus propose a new cache structure, named Data Access <b>History</b> <b>Cache</b> (DAHC), and study its associated prefetching mechanisms. The DAHC behaves as a cache for recent reference information instead of as a traditional cache for instructions or data. Theoretically, it is capable of supporting many well known history-based prefetching algorithms, especially adaptive and aggressive approaches. We have carried out simulation experiments to validate DAHC design and DAHC-based data prefetching methodologies and to demonstrate performance gains. The DAHC provides a practical approach to reaping data prefetching benefits and its associated prefetching mechanisms are proven more effective than traditional approaches...|$|R
40|$|We {{address the}} problem of {{processing}} continuous historical queries over streams of XML data, returning continuous, exact answers. The stream data considered are tokenized XML data with embedded updates for inserting, removing, or replacing stream subsequences that correspond to complete XML tree nodes when they are fully materialized to trees. Our query language for expressing historical queries is XQuery extended with temporal annotations that specify sliding windows that focus on the stream results of query subexpressions, rather than on the query input streams. We have developed a novel architecture that can evaluate historical queries over large XML data streams using short history lists. Instead of buffering a fixed-size window, sliding through the input stream events, we focus on the temporal requirements of individual operations derived from the query and use <b>history</b> lists to <b>cache</b> the state <b>history</b> of the operation as long as necessary to answer the query. 1...|$|R
5000|$|In December 2016, {{the full}} {{version of the}} opera had its world premiere in Vienna, with {{conductor}} Zubin Mehta as patron. During 2016, Deutscher had edited and expanded the opera considerably, and fully orchestrated it. The premiere was received with a standing ovation and with jubilant reception in the Austrian and international press. [...] The Viennese newspaper Der Standard wrote of Alma Deutscher as [...] "this amazing girl, who has also written this amazingly good opera, which sparkles with original ideas. Stylistically, Cinderella moves between [...] "Vienna Classic" [...] and early Romanticism. From this <b>cache</b> of music <b>history,</b> however, emerge remarkable inspirations, which understand the psychological corset of the characters. Here, someone {{with a great deal}} of empathy delves into the characters. And she also understands how to build scenes, keep them in tension, and orchestrate dense atmospheres. Alma Deutscher proves talent for the humorous as well as the melancholy." ...|$|R
40|$|Processor {{cycle times}} are {{currently}} {{much faster than}} memory cycle times, and the trend has been for this gap to increase over time. The problem of increasing memory latency, relative to processor speed, has been dealt with by adding high speed cache memory. However, {{it is difficult to}} make a cache both large and fast, so that cache misses are expected to continue to have a significant performance impact. Prediction <b>caches</b> use a <b>history</b> of recent <b>cache</b> misses to predict future misses, and to reduce the overall cache miss rate. This paper describes several prediction caches, and introduces a new kind of prediction cache, which combines the features of prefetching and victim caching. This new cache is shown to be more effective at reducing miss rate and improving performance than existing prediction caches. Key Words and Phrases: Dynamic scheduling, Memory latency, Stream buffer, Victim cache, Prediction cache Copyright c fl 1996 by James E. Bennett Michael J. Flynn Contents 1 Int [...] ...|$|R
40|$|The {{confluence}} of the Fraser and Nechako Rivers is a complicated place. Prince George, a key centre for Aboriginal European interaction in the BC interior, drew various people to the opportunities on offer. For many indigenous peoples however, opportunities were hard to realize, and urban poverty persisted. Located just before the rivers meet is {{a place called the}} Island Cache, where a community of settlers took up residence in the 1920 s. The area was initially an island separated by a flood channel, and so for the <b>Cache’s</b> entire <b>history,</b> flooding was an issue. The Cache was a very different place than the city on its border, but in 1970, it was incorporated, and a period of escalating political turmoil began. Integration was swift and decisive, and accomplished through by-laws, condemnation orders, and bulldozers; the event triggering it was a flood. This is a brief history of the Island Cache. It is about rivers and the lands around them; it is about floods of water and of power; it is about dykes, and the ground they are built on; and it is about the communities that build dykes and why they fail. The Cache was lost because power, like water, can seep into people’s lives, around and under attempts to protect their communities, unseen until it is too late, and both house and home are swept away. Pushed to margins of society, the people of the Cache survived as best they could. They created a vibrant community, but because it was very different than that of those with power, “progress” meant the end of the Cache. But it is better to read this story from its beginning...|$|R
40|$|Abstract Handoff {{procedure}} in IEEE 802. 11 wireless networks must be accomplished {{with as little}} interruption as possible to maintain the required quality of service (QoS). We have developed a fast handoff scheme, called Auth-Scan, to reduce the time-consuming channel scanning latency. AuthScan comprises two steps: First, a client <b>caches</b> its handoff <b>history</b> with beacon information. Second, when in need of handoff, a client transmits Authentication Request frames to the selected Access Points (APs) from the cache instead of broadcasting Probe Request frames like in active scan to discover the next AP. Our proposed method does not require any support from the infrastructure network and contributes to finish the handoff procedure with the lowest latency when compared to approaches that improve the efficiency of channel scanning. Furthermore, AuthScan requires neither hardware upgrades to the client, nor any modification to currently deployed APs. In this paper, we present the theoretical handoff latency of AuthScan with comparison to other approaches, and show the effectiveness of our system through experiments. Key words IEEE 802. 11 Wireless LAN, Fast Link-Layer Handoff 1...|$|R
40|$|Network {{processors}} have exploited {{many aspects}} of architecture design, such as employing multi-core, multi-threading and hardware accelerator, to support both the ever-increasing line rates and the higher complexity of network applications. Micro-architectural techniques like superscalar, deep pipeline and speculative execution provide an excellent method of improving performance without limiting either the scalability or flexibility, provided that the branch penalty is well controlled. However, {{it is difficult for}} traditional branch predictor to keep increasing the accuracy by using larger tables, due to the fewer variations in branch patterns of packet processing. To improve the prediction efficiency, we propose a flow-based prediction mechanism which <b>caches</b> the branch <b>histories</b> of packets with similar header fields, since they normally undergo the same execution path. For packets that cannot find a matching entry in the history table, a fallback gshare predictor is used to provide branch direction. Simulation results show that the our scheme achieves an average hit rate in excess of 97. 5 % on a selected set of network applications and real-life packet traces, with a similar chip area to the existing branch prediction architectures used in modern microprocessors...|$|R
40|$|Abstract—Network Processors have {{exploited}} {{all aspects}} of architecture design, such as employing multi-core, multi-threading and hardware accelerator, to support both the ever-increasing line rates and the higher complexity of network applications. Micro-architectural techniques like superscalar, deep pipeline and speculative execution provide an excellent method of improving performance without limiting either the scalability or flexibility, provided that the branch penalty is well controlled. However, traditional branch predictors are not as efficient in network applications as in general purpose processing, due to the fewer variations in branch patterns of packet processing. To improve the prediction accuracy, we propose a flow-based prediction mechanism which <b>caches</b> the branch <b>histories</b> of packets with similar header fields, since they normally undergo the same execution path. For packets that cannot find a matching entry in the history table, a fallback gshare predictor is used to provide branch direction. Simulation {{results show that the}} our scheme achieves an average hit rate in excess of 97. 5 % on a selected set of network applications and real-life packet traces, with a similar footprint to the traditional branch predictors used in modern microprocessors. Keywords-branch prediction; network processor; network traffic; packet flow I...|$|R
40|$|International audienceWhile {{the field}} of {{computer}} architecture is always looking for novel research directions to bring improved performance and efficiency, it is often simple improvements to more mature topics that have the most substantial impact. Cache replacement policy is one such research area, where innovations are highly sought after because of their direct improvement on performance. Furthermore, as chip-multiprocessors have become the dominant chip design, new cache replacement schemes should seek to improve the performance of workloads for both singlethreaded and shared cache multithreaded systems. In this paper we propose MadCache, a cache insertion policy that uses memory access history based on the Program Counter (PC) to determine the appropriate policy for the L 3 <b>cache.</b> A PC-based <b>history</b> table stores information regarding cache accesses and determines whether the L 3 should default to the LRU replacement policy for workloads that exhibit good locality or bypass for streaming memory accesses. Furthermore, this PC-based history table allows individual PCs to override this default policy if its history indicates a behavior {{significantly different from the}} typical trend of the workload. We show that MadCache is able to improve IPC by 2. 5 % over LRU for a singlethreaded 1 MB 16 -way L 3 cache. Finally, we extend MadCache to a four thread, 4 MB shared L 3 cache and demonstrate a 6 % improvement in throughput and 4. 5 % speedup over LRU averaged across the mixed benchmarks we tested...|$|R
40|$|Over 60 {{years have}} passed since steam {{threshing}} engines went out of production, yet the legendary machines refuse to vanish from the American scene. At scores of threshing shows every summer, millions of people turn out to experience the drama and poetry that is steam power. Of themselves, the machines are fascinating, but this alone does not explain the continuing interest that perpetuates the anachronistic rituals of steam threshing. The rhythmic tuck-a-tuck of the exhaust, the drone of the separator, and the lingering aroma of coal smoke and valve oil provide a vital link to the age of our fathers and grandfathers. For many, observing a steam engine at work is a profound emotional experience. In the Cache Valley of Utah and Idaho, the steam threshing phenomenon is alive and well. When steam was retired {{in this part of the}} Wheatbelt, collectors scoured the area to preserve examples of the venerated machines. Their annual threshing bees delighted the rural community. Today, most of those original collectors have gone to their reward, but their engines continue to operate at a local agricultural museum, the Ronald V. Jensen Living Historical Farm. Out of many special events on the museum 2 ̆ 7 s calendar, steam threshing consistently draws more visitors than the others combined. The high level of sustained interest demonstrated by local residents indicates that steam threshing is perceived as a significant part of their history and culture. Surprisingly, little has been written on this topic by local or, indeed, national historians. Almost four decades have passed since Reynold Wik published Steam Power on the American Farm, the only comprehensive book to deal with agricultural steam engines in the United States. This remains a fine and informative monograph, but it ignores that part of the wheatbelt that fell within the Mormon sphere of influence. An in-depth exploration of local steam threshing would reveal a great deal about lifestyles and values in Cache Valley, especially during that critical period that Charles Peterson has dubbed 2 ̆ 2 the Americanization of Utah. 2 ̆ 2 But before such weighty issues can be tackled, a good deal of basic information must be assembled. That is the purpose of this work. The following pages endeavor to chart the rise and fall of the steam era in Cache Valley agriculture. Because the equipment and many of the customs evolved in other areas, it begins with a national overview. It then establishes the beginnings of steam power locally as a precedent for its eventual adoption in agriculture, and it describes the conditions which made that adoption a reality. going further, it addresses local sales practices, steam plowing, the training of enginemen, what harvesting methods, and the hazards of engine operation. The demise of the steam engine is discussed as a consequence of the internal combustion tractor. Finally, a brief retrospective examines the significance of agricultural steam power in <b>Cache</b> Valley <b>history</b> and culture...|$|R
