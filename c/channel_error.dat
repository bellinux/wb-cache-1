391|2775|Public
50|$|E_D_TOV {{stands for}} Error Detect TimeOut Value. This {{is the basic}} error timeout used for all Fibre <b>Channel</b> <b>error</b> detection. Its default value is 2 seconds.|$|E
50|$|Since ICER {{provides}} a facility for automated flexibility {{in choosing the}} number of segments, compression effectiveness can be traded against packet loss protection, thereby accommodating different <b>channel</b> <b>error</b> rates.|$|E
50|$|As {{with any}} low bitrate codec, {{reaching}} {{high levels of}} compression will involve a trade-off against distortion, delay, and <b>channel</b> <b>error</b> robustness, and also codec state recovery {{in the face of}} packet loss. Since the lower rates are superset of the 2400 bit/s rate, the algorithm complexity (MIPS) is about the same for all rates. The lower rates use increased frames and lookahead, as well as codebook size, therefore they require more memory.|$|E
40|$|The paper {{describes}} the SONG and modified ABATE {{adaptive delta modulation}} algorithms for voice encoding. Waveforms of {{the response of the}} delta modulators to <b>channel</b> <b>errors</b> are given, and performance data which show the relationship between <b>channel</b> <b>errors</b> and word intelligibility are provided. An analytic derivation yielding a comparison between PCM and adaptive delta modulation with respect to <b>channel</b> <b>errors</b> is given. The Space Shuttle is employing the modified-ABATE device because it can tolerate a high error rate and operates at a relatively low sampling rate...|$|R
40|$|Compressed video {{sequences}} {{are vulnerable}} to <b>channel</b> <b>errors,</b> {{to the extent that}} minor errors and/or small losses can result in substantial degradation. Thus, protecting compressed data against <b>channel</b> <b>errors</b> is imperative. The use of channel coding schemes can be effective in reducing the impact of <b>channel</b> <b>errors,</b> although this requires that extra parity bits to be transmitted, thus utilizing more bandwidth. However, this can be ameliorated if the transmitter can tailor the parity data rate based on its knowledge regarding current channel conditions. This can be achieved via feedback from the receiver to the transmitter. This paper describes a channel emulation system comprised of a server/proxy/client combination that utilizes feedback from the client to adapt the number of Reed-Solomon parity symbols used to protect compressed video sequences against <b>channel</b> <b>errors...</b>|$|R
50|$|Data in a {{frame is}} {{typically}} protected from <b>channel</b> <b>errors</b> by error-correcting codes.|$|R
50|$|Most {{telecommunication}} systems use a fixed channel code {{designed to}} tolerate the expected worst-case bit error rate, and then fail to work at all if the bit error rate is ever worse.However, some systems adapt to the given <b>channel</b> <b>error</b> conditions: some instances of hybrid automatic repeat-request use a fixed FEC method {{as long as the}} FEC can handle the error rate, then switch to ARQ when the error rate gets too high;adaptive modulation and coding uses a variety of FEC rates, adding more error-correction bits per packet when there are higher error rates in the channel, or taking them out when they are not needed.|$|E
5000|$|In this case, {{the length}} of an input {{variable}} [...] from source [...] is 7 bits, therefore it can be sent lossless with 7 bits independent of any other bits. Based on the knowledge that [...] and [...] have Hamming distance at most one, for input [...] from source , since the receiver already has , the only possible [...] are those with at most 1 distance from [...] If we model the correlation between two sources as a virtual channel, which has input [...] and output , {{as long as we}} get , all we need to successfully [...] "decode" [...] is [...] "parity bits" [...] with particular error correction ability, taking the difference between [...] and [...] as <b>channel</b> <b>error.</b> We can also model the problem with cosets partition. That is, we want to find a channel code, which is able to partition the space of input [...] into several cosets, where each coset has a unique syndrome associated with it. With a given coset and , there is only one [...] that is possible to be the input given the correlation between two sources.|$|E
40|$|We have {{considered}} the response of a variable step size delta modulator communication system, to errors caused by a noisy channel. For the particular adaptive delta modulation scheme proposed by Song, Garodnick, and Schilling (1971), we have a simple analytic formulation of the output error propagation due to a single <b>channel</b> <b>error.</b> It is shown that single channel errors cause {{a change in the}} amplitude and dc level of the output, but do not otherwise affect the shape of the output waveform. At low <b>channel</b> <b>error</b> rates, these effects do not cause any degradation in audio transmission. Higher <b>channel</b> <b>error</b> rates cause overflow or saturation of the step size register. We present relationships between <b>channel</b> <b>error</b> rate, register size, and the probability of register overflow...|$|E
40|$|We {{investigated}} {{the effects of}} <b>channel</b> <b>errors</b> on an adaptive delta modulator used to encode video signals. The investigation revealed that <b>channel</b> <b>errors</b> caused a permanent shift in the dc level of the delta modulator's estimate. Errors in the step size, on the other hand, were transitory and had no noticeable effect on the received pictures. We then presented three error correction schemes to minimize the visibility of the <b>channel</b> <b>errors</b> in the received picture. The first scheme required the transmitter to periodically send the correct dc level of the estimate to the receiver. The second method employed a leaky integrator, and the third method used line-to-line interpolatio...|$|R
30|$|In addition, a {{conventional}} scheme, such as FEC metric masking, {{does not take}} into account the <b>channel</b> estimation <b>error</b> for calculating LLRs. <b>Channel</b> estimation <b>error</b> is known to cause intersymbol interference (ISI) and degradation of BER performance [5, 6]. Therefore, it is required to compensate the effect of <b>channel</b> estimation <b>error.</b> In [7, 8], LLR that takes into account the <b>channel</b> estimation <b>error</b> is proposed under single carrier transmission. It is shown that considering <b>channel</b> estimation <b>error</b> for LLR results in better BER performance.|$|R
40|$|Abstract—This paper {{presents}} TCP-DCR, a set {{of simple}} modifications to the TCP protocol to improve its robustness to <b>channel</b> <b>errors</b> in wireless networks. TCP-DCR {{is based on the}} simple idea of allowing the link-level mechanism to recover the packets lost, due to <b>channel</b> <b>errors,</b> thereby limiting the response of the transport protocol to mostly congestion losses. This is done by delaying the triggering of congestion response algorithms for a small bounded period of time to allow the link-level retransmissions to recover the loss due to <b>channel</b> <b>errors.</b> If {{at the end of the}} delay the packet is not recovered, then it is treated as a packet lost due to congestion. We analyze TCP-DCR to show that the delay in congestion response does not impact the fairness towards the native implementations of TCP that respond to congestion immediately after receiving three dupacks. We evaluate TCP-DCR through simulations to show that it offers significantly better performance when <b>channel</b> <b>errors</b> contribute more towards packet losses in the network with no or minimal impact on the performance when congestion is the primary cause for packet loss. We also present an analysis to show that protocol evaluation in the wireless networks is significantly influenced by the number of flows in the network. Index Terms—Wireless network, <b>channel</b> <b>errors,</b> TCP, delayed congestion response, local recovery. ...|$|R
40|$|Abstract. This paper {{addresses}} the following robust scheduling problem: Given that only coarse-grained channel state information (i. e., bounds on channel errors, {{but not the}} fine-grained error pattern) is available, how to design a robust scheduler that ensures worst-case optimal performance? To solve this problem, we consider two coarse-grained <b>channel</b> <b>error</b> models and take a zero-sum game theoretic approach, in which the scheduler and the <b>channel</b> <b>error</b> act as non-cooperative adversaries in the scheduling process. Our results show that in the heavy <b>channel</b> <b>error</b> case, the optimal scheduler adopts a threshold form. It does not schedule a flow if the price (the flow is willing to pay) is too small, {{in order to maximize}} the system revenue. Among the scheduled flows, the scheduler schedules a flow with a probability inversely proportional to the flow price such that the risk of being caught by the <b>channel</b> <b>error</b> adversary is minimized. We also show that in the mild <b>channel</b> <b>error</b> model, the robust scheduling policy exhibits a balanced trade-off between a greedy decision and a conservative policy. The scheduler is likely to take a greedy decision if it evaluates the risk of encountering the <b>channel</b> <b>error</b> adversary now to be small. Therefore, robust scheduling does not always imply conservative decision. The scheduler is willing to take “risks ” to expect higher gain in some scenarios. Our solution also shows that probabilistic scheduling may lead to higher worst-case performance compared to traditional deterministic policies. Finally, the current efforts show the feasibility to explore a probabilistic approach to cope with dynamic <b>channel</b> <b>error</b> conditions...|$|E
40|$|In this paper, {{we design}} a robust {{scheduling}} algorithm to ensure worst-case optimal performance when only coarse-grained channel state information (i. e., bounds on channel errors, {{but not the}} fine-grained error pattern) is available To solve this problem, we consider two coarse-grained <b>channel</b> <b>error</b> models and take a zero-sum game theoretic approach, in which the scheduler and the <b>channel</b> <b>error</b> act as non-cooperative adversaries in the scheduling process. Our results show that in the heavy <b>channel</b> <b>error</b> case, the optimal scheduler adopts a threshold form. It does not schedule a flow if the price (the flow is willing to pay) is too small, {{in order to maximize}} the system revenue. Among the scheduled flows, the scheduler schedules a flow with a probability inversely proportional to the flow price such that the risk of being caught by the <b>channel</b> <b>error</b> adversary is minimized. We also show that in the mild <b>channel</b> <b>error</b> model, the robust scheduling policy exhibits a balanced trade-off between a greedy decision and a conservative policy. The scheduler is likely to take a greedy decision if it evaluates the risk of encountering the <b>channel</b> <b>error</b> adversary now to be small. Therefore, robust scheduling does not always imply conservative decision. The scheduler is willing to take "risks" to expect higher gain in some scenarios. Our solution also shows that probabilistic scheduling may lead to higher worst-case performance compared to traditional deterministic policies. Finally, the current efforts show the feasibility to explore a probabilistic approach to cope with dynamic <b>channel</b> <b>error</b> conditions...|$|E
40|$|Bluetooth {{is an open}} {{specification}} for {{a technology}} to enable short-range wireless communications that operate in an ad-hoc fashion. Bluetooth uses frequency hopping with a slot length of 625 μs. Each slot corresponds to a packet and multi-slot packets of 3 or 5 slots can be transmitted to enhance the transmission efficiency. However, the use of multi-slot packet may degrade the transmission performance under high <b>channel</b> <b>error</b> probability. Thus, the length of multi-slot should be adjusted according to the current channel condition. Segmentation and Reassembly (SAR) operation of Bluetooth enables the adjustment {{of the length of}} multi-slot. In this paper, we propose an efficient multi-slot transmission scheme that adaptively determines the optimal length of slots of a packet according to the <b>channel</b> <b>error</b> probability. We first discuss the throughput of a Bluetooth connection {{as a function of the}} length of a multi-slot and the <b>channel</b> <b>error</b> probability. A decision criteria which gives the optimal length of the multi-slot is presented under the assumption that the <b>channel</b> <b>error</b> probability is known. For the implementation in the real Bluetooth system the <b>channel</b> <b>error</b> probability is estimated with the maximum likelihood estimator (MLE). A simple decision rule for the optimal multi-slot length is developed to maximize the throughput. Simulation experiment shows that the proposed decision rule for the multi-slot transmission effectively provides the maximum throughput under any type of <b>channel</b> <b>error</b> correlation...|$|E
30|$|We {{have first}} {{considered}} the frame-by-frame PSNR fluctuations, {{in order to}} evaluate the temporal effects of <b>channel</b> <b>errors.</b>|$|R
40|$|This paper {{presents}} a new TCP protocol, TCP-DCR, designed to tolerate <b>channel</b> <b>errors</b> in wireless networks. TCP-DCR employs the simple solution of allowing a link level retransmission scheme {{to recover the}} packets lost due to <b>channel</b> <b>errors</b> thereby limiting {{the response of the}} transport protocol to mostly congestion losses. TCP-DCR delays responding to a packet loss indication for a small period of time (one RTT) to allow the <b>channel</b> <b>errors</b> to be recovered by link level retransmission. We analyze TCP-DCR to show that the congestion response delay does not impact its performance and its fairness. We evaluate TCP-DCR through simulations and compare its performance with TCP-Reno, TCP-SACK and TCP-Westwood under different network conditions. Our results show that TCP-DCR offers significantly better performance when <b>channel</b> <b>errors</b> make a large contribution to packet losses in the network and when the round trip delays are large. We also present an analysis to show that protocol evaluation in the wireless networks is significantly impacted by the number of flows in the network...|$|R
3000|$|... considered. In particular, {{simulations}} show that, {{when the}} condition of perfect synchronization in (2) is satisfied, the loss is only due to <b>channel</b> <b>errors.</b>|$|R
40|$|This paper {{addresses}} the following robust scheduling problem: Given that only coarse-grained channel state information (i. e., bounds on channel errors, {{but not the}} fine-grained error pattern) is available, how to design a robust scheduler that ensures worst-case optimal performance? To solve this problem, we consider two coarse-grained <b>channel</b> <b>error</b> models and take a zero-sum game theoretic approach, in which the scheduler and the <b>channel</b> <b>error</b> act as non-cooperative adversaries in the scheduling process. Our results show that in the heavy <b>channel</b> <b>error</b> case, the optimal scheduler adopts a threshold form. It does not schedule a flow if the price (the flow is willing to pay) is too small, {{in order to maximize}} the system revenue. Among the scheduled flows, the scheduler schedules a flow inversely proportional to the price (the flow is to pay) to minimize the risk of being caught by the <b>channel</b> <b>error</b> adversary. We also show that in the mild <b>channel</b> <b>error</b> model, the robust scheduling policy exhibits a balanced trade-off between a greedy decision and a conservative policy. The scheduler is likely to take a greedy decision if it evaluates the risk of encountering the <b>channel</b> <b>error</b> adversary now to be small. Therefore, robust scheduling does not always imply conservative decision. The scheduler is willing to take "risks" to expect higher gain in some scenarios. Our solution also shows that probabilistic scheduling may lead to higher worst-case performance compared to traditional deterministic policies...|$|E
40|$|We {{propose a}} new vector {{quantization}} approach, {{which consists of}} Hidden Markov Models(HMMs) and entropy coding scheme. The entropy coding system is determined depending on the speech status modeled by HMMs, so the proposing approach can adaptively allocate suitable numbers of bits to the codewords. This approach realizes about 0. 3 [dB] coding gain in cepstrum distance(8 states HMMs). In other words, 8 bit-codebook is represented by about 6. 5 bits for average code length. We also research for robustness to the <b>channel</b> <b>error.</b> HMMs and the entropy coding system, which seem to be weak to the <b>channel</b> <b>error,</b> are augmented to be robust, so that {{the influence of the}} <b>channel</b> <b>error</b> is decreased into one-third...|$|E
40|$|The paper proposes two {{schemes for}} {{contention}} resolution in 802. 11 MAC namely modified back off strategy and estimation based back off strategy. The back off strategies provided {{a way to}} resolve contention for access to wireless channel which is continuously changing and difficult to model {{in a set of}} parameters. Differentiation between packet loss due to <b>channel</b> <b>error</b> and collision in 802. 11 MAC is essential for the above two schemes to exist. Modified strategy tries to find the optimum back off period on loss due to <b>channel</b> <b>error</b> by taking the advantages of both the current strategy implemented in 802. 11 MAC and the Return to Zero on <b>channel</b> <b>error</b> (ROCE) strategy. The Estimation based approach shows how by analyzing the channel for a period of time, we can predict the best back off interval in case of <b>channel</b> <b>error.</b> The aim is to maximize the throughput while being fair to all contending users. Simulation of the above two scheme suggest their superiority to the currently implemented scheme. Estimation based approach is better than other schemes for static correlated WLAN channel...|$|E
30|$|The {{observation}} matrix in (30) {{is derived}} from the <b>channel</b> estimation <b>error</b> δ. We evaluate how the <b>channel</b> estimation <b>error</b> affects the average throughput.|$|R
30|$|On {{the other}} hand, WiSE [6] applies {{bottleneck}} bandwidth estimation techniques to infer whether losses {{are a result}} of congestion or radio <b>channel</b> <b>errors.</b> If the packet loss is due to <b>channel</b> <b>errors,</b> WiSE does not adjust the congestion window size. W-A SCTP [9] determines the reason for packet loss from the packet's label. When the network becomes congested, W-A SCTP labels followup packets with ECN (explicit congestion notification). The reason for packet loss is identified from whether packets have this label.|$|R
40|$|AbstractAnalysis of {{distributed}} communication {{networks in}} noisy collision channels is given. Both feedback and feedforward <b>channel</b> <b>errors</b> are considered. A finite number of buffered users is addressed. It is shown that <b>channel</b> <b>errors</b> lead to stabilization of unstable access protocols, i. e. to {{elimination of the}} saturation phenomena and to stabilization of a network in a unique, globally asymptotically stable steady state with relatively high-performance characteristics. Thus channel noise, possibly introduced intentionally, {{could be viewed as}} a decentralized stabilizing controller...|$|R
40|$|Bluetooth {{is an open}} {{specification}} for {{a technology}} to enable short-range wireless communications. Bluetooth uses a frequency hopping with a slot length of 625 μs. Each slot corresponds to a packet and multi-slot packets of 3 or 5 slots can be transmitted to enhance the transmission efficiency. However, the use of multi-slot packet may degrade the performance under the high <b>channel</b> <b>error</b> probability. Thus, the length of multi-slot should be adjusted according to the current channel condition. In this paper, we propose an efficient multi-slot transmission scheme which adaptively determines the optimal length of slots for a packet according to the <b>channel</b> <b>error</b> probability. We derive the throughput of a Bluetooth connection and develop the decision criteria and the decision rule which give the optimal length of the multi-slot. Maximum likelihood estimator (MLE) is used to estimate the <b>channel</b> <b>error</b> probability...|$|E
40|$|ICSLP 1996 : the 4 th International Conference on Spoken Language Processing, October 3 - 6, 1996, Philadelphia, PA, USA. The authors {{propose a}} new vector {{quantization}} approach, {{which consists of}} hidden Markov models (HMMs) and an entropy coding scheme. The entropy coding system is determined depending on the speech status modeled by HMMs, so the proposed approach can adaptively allocate suitable numbers of bits to the codewords. This approach realizes about 0. 3 [dB] coding gain in cepstrum distance (8 state HMMs). In other words, an 8 bit codebook is represented by about 6. 5 bits for average code length. They also research for robustness to the <b>channel</b> <b>error.</b> HMMs and the entropy coding system, which seem to be weak to the <b>channel</b> <b>error,</b> are augmented to be robust, so that {{the influence of the}} <b>channel</b> <b>error</b> is decreased into one-third...|$|E
40|$|Absrrucr-A {{method is}} {{presented}} to automatically inspect the block boundaries of a reconstructed two-dimensional ' transform coded image, to locate blocks which {{are most likely to}} contain errors, to approximate the size and type of error in the block, and-to eliminate this estimated error from thepicture. This method uses redundancy in the source data to provide <b>channel</b> <b>error</b> correction. No additional <b>channel</b> <b>error</b> protection bits or changes to the transmitter are required. It can be used when channel errors are unexpected prior to reception. T I...|$|E
40|$|In this paper, {{we present}} WWTP(Wireless Waiting -Time Priority) to provide {{relative}} delay differentiation in a wireless network where packets are classified {{into one of}} the ordered classes according to their relative delay requirements. WWTP ensures that a packet of higher class to enjoy better QoS(Quality of Service) than that of lower class unless it suffers from wireless <b>channel</b> <b>errors.</b> Packet having suffered <b>channel</b> <b>errors</b> is compensated such that the compensation for the higher class is stronger than the lower class...|$|R
40|$|Abstruct- In nonstationary <b>channels,</b> <b>error</b> rates vary considerably. This letter proposes an {{effective}} go-back-N ARQ scheme which estimates the channel {{state in a}} simple manner, and adaptively switches its operation mode in a <b>channel</b> where <b>error</b> rates vary slowly. It provides higher throughput than other comparable ARQ schemes under {{a wide variety of}} error rate conditions...|$|R
30|$|We {{evaluated}} {{the performance of}} our proposal through simulations using OPNET [32]. Ten simulations are run for every case, each with a different seed for the random numbers, and the results shown correspond to the average values and the associated 95 % confidence intervals. We assume an underlying IEEE 802.11 -compatible physical layer running at 1 Mbps. This assumption is based again {{on the fact that}} high bandwidth is required from nodes. In our models, no frames are lost due to <b>channel</b> <b>errors,</b> but all losses are due to collisions. If the system is to be analyzed with <b>channel</b> <b>errors,</b> then this fact has to be taken into consideration when the wireless channel's effective data rate R is estimated, as mentioned in Section 3.2. It is worth emphasizing that, even though <b>channel</b> <b>errors</b> were not considered in our simulations, provisions are made to recover from them in the protocol.|$|R
40|$|Abstract—In RFID systems, {{far field}} passive tags send {{information}} using back scattering. The signal level is typically very small, so <b>channel</b> <b>error</b> during transmission may occur frequently. Due to <b>channel</b> <b>error,</b> performance of RFID tag identification under error-prone channel is degraded {{compared to that}} under error-free channel. In this paper, we propose a novel error resilient estimation and adaptive binary selection to overcome the problem of channel errors. Our proposed error resilient estimation algorithm can estimate the number of tags and the channel state accurately regardless of frame errors. And our proposed adaptive binary selection reduces the idle slots caused by frame errors. Performance analysis and simulation {{results show that the}} proposed algorithm consumes up to 20 percent less time slots than the binary tree protocol and dynamic framed slotted ALOHA (DFSA) in various packet error rate (PER) conditions. Index Terms—Anticollision, <b>channel</b> <b>error,</b> collision resolution, RFID, tag estimation. Ç...|$|E
40|$|This paper {{addresses}} the following scheduling problem in wireless packet switched networks: Given that only coarse-grained channel state information is available, how {{to design a}} robust scheduler that ensures worst-case optimal performance? To solve this problem, we take a zero-sum game theoretic approach, in which the scheduler and the <b>channel</b> <b>error</b> act as non-cooperative adversaries in the scheduling process. The scheduler tries to maximize the system revenue from serving flows while the channel errors try to minimize it. We give the optimal scheduling strategy in the heavy <b>channel</b> <b>error</b> case and the mild <b>channel</b> <b>error</b> case separately. Such an optimal scheduling strategy is probabilistic, {{in the sense that}} the scheduler makes decision based on a probablistc distribution. Our results show that this probabilistic scheduling may lead to higher worst-case performance compared to traditional deterministic policies, especially when the channel errors are dynamic and difficult to predict...|$|E
3000|$|... where during_error is {{the period}} when flow i is in <b>channel</b> <b>error.</b> The {{scheduler}} chooses the smallest start time of packet and forwards the packet for flow.|$|E
40|$|Abstract — <b>Channel</b> {{estimation}} <b>error</b> {{problem is}} among the main causes of performance degradation in wireless networks. In this paper, we investigate the impact of cooperative communications on mitigating the effect of <b>channel</b> estimation <b>error.</b> Two main performance criteria, namely, the traditional outage probability and the proposed signal-to-noise ratio (SNR) gap ratio, are utilized to characterize such impact. The SNR gap ratio measures {{the reduction in the}} SNR due to <b>channel</b> estimation <b>error.</b> Taking into consideration the <b>channel</b> estimation <b>error,</b> we show that the outage probability is reduced by utilizing cooperative transmission. We also show that cooperative transmission results in lower SNR gap ratio compared to that of the direct transmission. Thus, cooperative transmission is less susceptible to the effect of <b>channel</b> estimation <b>error</b> compared to direct transmission. Finally, we illustrate that increasing the number of cooperating relays reduces the effect of the <b>channel</b> estimation <b>error</b> more. I...|$|R
3000|$|... b To {{include the}} <b>channel</b> {{estimation}} <b>error</b> {{in the proposed}} model, H can be replaced with H[*]+[*]N in Equation 9, where N denotes the <b>channel</b> estimation <b>error</b> matrix.|$|R
3000|$|... (see (10)). In Problem (11), the infimum in the {{objective}} function and supremum {{in the first}} constraint are taken over all possible <b>channel</b> <b>errors</b> contained in the given uncertainty region.|$|R
