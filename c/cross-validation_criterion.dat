68|77|Public
50|$|To compare {{different}} HPM models, one of ways is {{to calculate}} their AIC (Akaike information criterion) {{and consider the}} <b>Cross-validation</b> <b>criterion.</b>|$|E
40|$|In geostatistics, one of {{the crucial}} {{problems}} is {{the choice of the}} covariance function. In this paper we show how to improve the <b>cross-validation</b> <b>criterion,</b> traditionally used for evaluating the fit of a covariance function, in the case of unequally spaced data. Dirichlet tessellation Cross-validation Mean integrated squared error Spatial linear model...|$|E
40|$|In this paper, we {{consider}} additive stochastic nonparametric regression models. By approximating the nonparametric components by {{a class of}} orthogonal series and using a generalized <b>cross-validation</b> <b>criterion,</b> an adaptive and simultaneous estimation procedure for all the nonparametric components is constructed. We illustrate the adaptive and simultaneous estimation procedure {{by a number of}} simulated and real examples...|$|E
40|$|AbstractFuzzy {{regression}} without predefined functional form, or nonparametric fuzzy regression, is investigated. The {{two most}} basic nonparametric regression techniques in statistics, namely, k-nearest neighbor smoothing and kernel smoothing, are fuzzified and analyzed. Algorithms are proposed {{to obtain the}} best smoothing parameters based on the minimization of <b>cross-validation</b> <b>criteria...</b>|$|R
40|$|Kernel {{logistic}} regression models, like their linear counterparts, {{can be trained}} using the efficient iteratively reweighted least-squares (IRWLS) algorithm. This approach suggests an approximate leave-one-out cross-validation estimator based on an existing method for exact leave-one-out cross-validation of least-squares models. Results compiled over seven benchmark datasets are presented for kernel {{logistic regression}} with model selection procedures based on both conventional k-fold and approximate leave-one-out <b>cross-validation</b> <b>criteria,</b> demonstrating the proposed approach to be viable...|$|R
40|$|This paper {{addresses}} {{the problem of}} comparing the fit of latent class and latent trait models when the indicators are binary and the contingency table is sparse. This problem is common {{in the analysis of}} data from large surveys, where many items are associated with an unobservable variable. A study of human resource data illustrates: (1) how the usual goodness-of-fit tests, model selection and <b>cross-validation</b> <b>criteria</b> can be inconclusive; (2) how model selection and evaluation procedures from time series and economic forecasting can be applied to extend residual analysis in this context. Multivariate statistics, latent variable models, forecast encompassing, human resource management,...|$|R
40|$|In {{this paper}} we suggest an {{efficient}} method {{to estimate the}} distribution function using the Bezier curve, and compare it with existing methods by simulation studies. In addition, we suggest a robust version of <b>cross-validation</b> <b>criterion</b> to estimate the number of Bezier points, and showed that the proposed method {{is better than the}} existing methods based on simulation studies...|$|E
40|$|AbstractThis note {{concentrates}} on the nonparametric estimation of a probability mass function (p. m. f.) using discrete associated kernels. An expression of the optimal bandwidth minimizing the asymptotic part of the global squared error is given. Some asymptotic expressions of bias and variance of the <b>cross-validation</b> <b>criterion</b> are also presented. At last, the two bandwidth selection procedures are illustrated through some simulations and an application on a real count data set...|$|E
40|$|Abstract. This article gives {{ideas for}} {{developing}} statistics software which can work without user intervention. Some popular methods of bandwidth selection for kernel density estimation (the near-est neighbour, least squares cross-validation, “plug-in ” technique) are discussed. Modifications of the <b>cross-validation</b> <b>criterion</b> are proposed. Two-stage estimators combining these methods with multiplicative bias correction are investigated by simulation means. Key words: kernel density estimation, local bandwidth selection, cross-validation, multiplicative bias correction...|$|E
40|$|The low capital {{mobility}} among OECD countries, signalled {{by a high}} saving-investment (SI) relation and known as the Feldstein-Horioka puzzle, has triggered a lively discussion in the empirical literature. In this paper, we compare between, pooled, time and country dependent specifications of the SI relation via <b>cross-validation</b> <b>criteria.</b> It is found that the country dependent model is best performing among the four. Secondly, error correction models are uniformly outperformed by static panel models. Thirdly, via scatter diagrams of cross section specific estimates we observe a different time evolution of SI relations for developed and developing economies. [...] Saving-investment relation,Feldstein-Horioka puzzle,model comparison...|$|R
40|$|Motivated by {{the need}} of extracting local trends and low {{frequency}} components in non-stationary time series, this paper discusses methods of robust non-parametric smoothing. Basic approach is {{the combination of the}} parametric M-estimation with kernel and local polynomial regression methods. The result is an iterative estimator that retains a linear structure, but has kernel weights also {{in the direction of the}} prediction errors. The design of smoothing coefficients is carried out with robust <b>cross-validation</b> <b>criteria</b> and rules of thumb. The method works well both to remove the influence of patches of outliers and to detect the local breaks and persistent structural change in time series...|$|R
40|$|Suppose that {{we observe}} {{a sample of}} {{independent}} and identically distributed realizations of a random variable. Given {{a model for the}} data generating distribution, assume that the parameter of interest can be characterized as the parameter value which makes the population mean of a possibly infinite dimensional estimating function equal to zero. Given a collection of candidate estimators of this parameter, and specification of the vector estimating function, we propose <b>cross-validation</b> <b>criteria</b> for selecting among these estimators. This <b>cross-validation</b> <b>criteria</b> is defined as the Euclidean norm of the empirical mean over the validation sample of the estimating function at the candidate estimator based on the training sample. We establish a finite sample inequality of this method relative to an oracle selector, and illustrate it with some examples. This finite sample inequality provides us with asymptotic equivalence of the selector with the oracle selector under general conditions. We also study the performance of this method in the case that the parameter of interest itself is path-wise differentiable (and thus, in principle, root-$n$ estimable), and show that the cross-validated selected estimator is typically efficient, and, at certain data generating distributions, superefficient (and thus non-regular). Finally, we combine 1) the selection of sequence of subspaces of the parameter space (i. e., a sieve), 2) the estimating equation as empirical criteria to generate a candidate estimator for each subspace, and 3) estimating function based cross-validation selector to select among the candidate estimators, in order to provide a new unified estimating function based methodology. In particular, we formally establish a finite sample inequality for this general estimator in the case that one uses epsilon-nets as sieve, and point out that this finite sample inequality corresponds with minimax adaptive rates of convergence w. r. t. to the norm implied by the estimating function...|$|R
40|$|Kyushu University 21 st Century COE Program Development of Dynamic Mathematics with High Functionality九州大学 21 世紀COEプログラム「機能数理学の構築と展開」The wavelet {{estimator}} of {{regression function}} in a non-linear auto-regressive model for non-stationary time series data is proposed. A convergence theorem of the estimators, and also related theorems, is developed. <b>Cross-Validation</b> <b>criterion</b> is proposed for the optimum selection of parameters. The criterion is justified by the $ alpha $-mixing condition. Finally, the method {{is applied to the}} electroencephalograph (EEG) data...|$|E
40|$|AbstractIn {{this short}} paper, we mainly aim {{to study the}} {{generalized}} ridge estimator in a linear regression model. Through matrix techniques including Hadamard product and derivative of a vector, the globally optimal generalized ridge estimator is derived under the generalized <b>cross-validation</b> <b>criterion</b> from the theoretical point of view. It will be seen {{that the notion of}} linearized ridge estimator {{plays an important role in}} the process. A numerical example is applied to illustrate the main results of the paper...|$|E
30|$|Thus, the {{synthetic}} control method with cross-validation is a two-step procedure. First, {{in the so-called}} “training” step, V∗ is determined by minimizing the <b>cross-validation</b> <b>criterion,</b> thereby making use of “training” weights W^*_(train)(V) as defined by Eq. (1). Then, in the second, so-called “main” step, these predictor weights V∗ are {{used to determine the}} “main” donor weights W^*_(main)(V^*) by Eq. (3). These “main” donor weights W^*_(main)(V^*) are then employed for synthesizing the treated unit. Again, this is visualized in Fig.  1.|$|E
40|$|We propose <b>cross-validation</b> <b>criteria</b> for the {{selection}} of regularisation parameter(s) in the semiparametric instrumental variable transformation model proposed in Florens and Sokullu (2016). In {{the presence of an}} endogenous regressor, this model is characterized by the need to choose two regularisation parameters, one for the structural function and one for the transformation of the outcome. We consider two-step and simultaneous criteria, and analyze the finite-sample performance of the estimator using the corresponding regularisation parameters by means of several Monte-Carlo simulations. Our numerical experiments show that simultaneous selection of regularisation parameters provides significant improvements in the performance of the estimator. We also apply our methods to the choice of regularisation parameters in the estimation of two-sided network effects in the German magazine industry. Nonparametric IV Regression, Transformation models, Cross-Validation, Tikhonov Regularization, Ill-posed inverse problems...|$|R
40|$|This paper {{concerns}} {{a class of}} model selection <b>criteria</b> based on <b>cross-validation</b> techniques and estimative predictive densities. Both the simple or leave-one-out and the multifold or leave-m-out cross-validation procedures are considered. These <b>cross-validation</b> <b>criteria</b> define suitable estimators for the expected Kullback-Liebler risk, which measures the expected discrepancy between the fitted candidate model and the true one. In particular, we shall investigate the potential bias of these estimators, under alternative asymptotic regimes for m. The results are obtained within the general context of independent, but not necessarily identically distributed, observations and by assuming that the candidate model may not contain the true distribution. An application to the class of normal regression models is also presented, and simulation results are obtained {{in order to gain}} some further understanding on the behavior of the estimator...|$|R
40|$|This paper {{develops}} {{point and}} interval forecasts of cumulative Greek GDP {{growth for the}} period 2015 Q 2 - 2017 Q 1. The forecasts are based on combining 1701 separate regression forecasts based on a broad set of leading indicators. The forecast combination weights are selected by minimizing the multi-step leave-h-out <b>cross-validation</b> <b>criteria,</b> which is {{an estimate of the}} multi-step mean-squared forecast error. We forecast that Greek GDP will decline by 2 % over the next several quarters, and not achieving positive growth until late 2016. These estimates are calculated under the strong assumption of no regime shift, and thus assume that a finance deal is reached with the international creditors, that the banking system is re-opened without capital controls, and that Greece stays in the Euro zone. ∗Research supported by the National Science Foundation...|$|R
40|$|Abstract: In this paper, we {{consider}} additive stochastic nonparametric regression models. By approximating the nonparametric components by {{a class of}} orthogonal series and using a generalized <b>cross-validation</b> <b>criterion,</b> an adaptive and simul-taneous estimation procedure for the nonparametric components is constructed. We illustrate the adaptive and simultaneous estimation procedure {{by a number of}} simulated and real examples. Key words and phrases: Adaptive estimation, additive model, dependent process, mixing condition, nonlinear time series, nonparametric regression, orthogonal se-ries, strict stationarity, truncation parameter. 1...|$|E
40|$|This article {{presents}} a modified Newton method for minimizing the Generalized <b>Cross-Validation</b> <b>criterion,</b> a commonly used smoothing parameter selection method in nonparametric regression. The method is applicable to higher dimensional {{problems such as}} additive and generalized additive models, and provides a computationally efficient alternative to full grid search in such cases. The implementation of the proposed method requires the estimation {{of a number of}} auxiliary quantities, and simple estimators are suggested. This article describes the methodology for local polynomial regression smoothing. ...|$|E
40|$|This article {{presents}} a modified Newton method for minimizing multidimensional bandwidth selection for estimation in generalized additive models. The method {{is based on}} the Generalized <b>Cross-Validation</b> <b>criterion</b> applied to backfitting estimates. The approach in particular is applicable to higher dimensional problems and provides a computationally e#cient alternative to full grid search in such cases. The implementation of the proposed method requires the estimation of a number of auxiliary quantities, and simple estimators are suggested. Extensions to semiparamatric models and other bandwidth selections are discussed...|$|E
40|$|AbstractIn {{this paper}} we propose a <b>cross-validation</b> {{selection}} <b>criterion</b> to determine asymptotically the correct model among the family of all possible partially linear models when the underlying model is a partially linear model. We establish the asymptotic consistency of the criterion. In addition, the criterion is illustrated using two real sets of data...|$|R
40|$|Three <b>cross-validation</b> <b>criteria,</b> denoted C, C_c, and C_u are {{proposed}} for selecting {{the orders of}} a self-exciting threshold autoregressive SETAR) model when both the delay and the threshold value are unknown. The derivatioon of C is within a natural cross-validation framework. The crietion C_c is similar in spirit as AIC_c, a bias-corrected version of AIC for SETAR model selection introduced by Wong and LI (1998). The criterion C_u is a variant of C_c having similar property as AIC_u, a modl selection criterion proposed by McQuarrie et al. (1997) for linear models. In a Monte Carlo study, the performance {{of each of the}} criteria C, C_c, C_u, AIC, AIC_c, AIC_u, and BIC is invesigated in detail for various models and various sample sizes. It will be shown that C_u consistently outperforms all other criteria when the sample size is moderate to large...|$|R
40|$|This article {{gives an}} {{overview}} of cross-validation techniques in regression and covariance structure analysis. The method of cross-validation offers a means for checking the accuracy or reliability of results that were obtained by an exploratory analysis of the data. Cross-validation provides the possibility to select, from a set of alternative models, the model with the greatest predictive validity, that is, the model that cross-validates best. The disadvantage of cross-validation is that the data need to be split in two or more parts. This can be a serious problem when sample size is small. Various authors have therefore tried to find single sample criteria that provide {{the same kind of}} information as the <b>cross-validation</b> <b>criteria</b> but that do not require the use of a validation sample. Several of these criteria will be discussed, along with some results from studies comparing cross-validation and single sample criteria in covariance structure analysis...|$|R
40|$|This paper studies nonparametric {{regression}} {{with long}} memory (LRD) errors and predictors. First, we formulate general conditions which guarantee the standard {{rate of convergence}} for a nonparametric kernel estimator. Second, we calculate the Mean Integrated Squared Error (MISE). In particular, we show that LRD of errors may influence MISE. On the other hand, an estimator for a shape function is typically not influenced by LRD in errors. Finally, we investigate properties of a data-driven bandwidth choice. We show that Averaged Squared Error (ASE) is a good approximation of MISE, however, {{this is not the}} case for a <b>cross-validation</b> <b>criterion...</b>|$|E
40|$|We provide Markov chain Monte Carlo (MCMC) {{algorithms}} for computing the bandwidth matrix for multivariate kernel density estimation. Our {{approach is}} based on treating {{the elements of the}} bandwidth matrix as parameters to be estimated, which we do by optimizing the likelihood <b>cross-validation</b> <b>criterion.</b> Numerical results show that the resulting bandwidths are superior to all existing methods; for dimensions greater than two, our algorithm is the first practical method for estimating the optimal bandwidth matrix. Moreover, the MCMC algorithm for bandwidth selection for multivariate data has no increased difficulty as the dimension of data increases. Bandwidth selection, cross-validation, multivariate kernel density estimation, sampling algorithms. ...|$|E
40|$|We {{investigate}} the numerical {{reconstruction of the}} missing thermal and mechanical boundary conditions on an inaccessible part of the boundary {{in the case of}} three-dimensional linear isotropic thermoelastic materials from the knowledge of over-prescribed noisy data on the remaining accessible boundary. We employ the method of fundamental solutions (MFS) and several singular value decomposition (SVD) -based regularization methods, e. g. the Tikhonov regularization method (Tikhonov and Arsenin, 1986), the damped SVD and the truncated SVD (Hansen, 1998), whilst the regularization parameter is selected according to the discrepancy principle (Morozov, 1966), generalized <b>cross-validation</b> <b>criterion</b> (Golub et al., 1979) and Hansen's L-curve method (Hansen and O'Leary, 1993) ...|$|E
40|$|In {{this paper}} we propose a <b>cross-validation</b> {{selection}} <b>criterion</b> to determine asymptotically the correct model among the family of all possible partially linear models when the underlying model is a partially linear model. We establish the asymptotic consistency of the criterion. In addition, the criterion is illustrated using two real sets of data. Jiti Gao, Rodney Wolff and Vo Anh[URL]...|$|R
40|$|We {{develop a}} robust regularized {{singular}} value decomposition (RobRSVD) method for analyzing two-way functional data. The research {{is motivated by}} the application of modeling human mortality as a smooth two-way function of age group and year. The RobRSVD is formulated as a penalized loss minimization problem where a robust loss function is {{used to measure the}} reconstruction error of a low-rank matrix approximation of the data, and an appropriately defined two-way roughness penalty function is used to ensure smoothness along each of the two functional domains. By viewing the minimization problem as two conditional regularized robust regressions, we develop a fast iterative reweighted least squares algorithm to implement the method. Our implementation naturally incorporates missing values. Furthermore, our formulation allows rigorous derivation of leaveone- row/column-out cross-validation and generalized <b>cross-validation</b> <b>criteria,</b> which enable computationally efficient data-driven penalty parameter selection. The advantages of the new robust method over nonrobust ones are shown via extensive simulation studies and the mortality rate application. © Institute of Mathematical Statistics, 2013. Link_to_subscribed_fulltex...|$|R
40|$|Two {{existing}} {{approaches to}} functional {{principal components analysis}} (FPCA) are due to Rice and Silverman (1991) and Silverman (1996), both based on maximizing variance but introducing penalization in different ways. In this article we propose an alternative approach to FPCA using penalized rank one approximation to the data matrix. Our contributions are four-fold: (1) by considering invariance under scale transformation of the measurements, the new formulation sheds light on how regularization should be performed for FPCA and suggests an efficient power algorithm for computation; (2) it naturally incorporates spline smoothing of discretized functional data; (3) the connection with smoothing splines also facilitates construction of cross-validation or generalized <b>cross-validation</b> <b>criteria</b> for smoothing parameter selection that allows efficient computation; (4) different smoothing parameters are permitted for different FPCs. The methodology is illustrated with a real data example and a simulation. Comment: Published in at [URL] the Electronic Journal of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
40|$|Paper not available. Full text {{of working}} paper {{suppressed}} by author. We provide Markov chain Monte Carlo (MCMC) algorithms for computing the bandwidth matrix for multivariate kernel density estimation. Our approach {{is based on}} treating {{the elements of the}} bandwidth matrix as parameters to be estimated, which we do by optimizing the likelihood <b>cross-validation</b> <b>criterion.</b> Numerical results show that the resulting bandwidths are superior to all existing methods; for dimensions greater than two, our algorithm is the first practical method for estimating the optimal bandwidth matrix. Moreover, the MCMC algorithm for bandwidth selection for multivariate data has no increased difficulty as the dimension of data increases...|$|E
40|$|AbstractThis paper {{studies the}} risks and {{bandwidth}} choices of a kernel estimate of the underlying density when the data are obtained fromsindependent biased samples. The main results of this paper give the asymptotic representation of the integrated squared errors and the mean integrated squared errors of the estimate and establish a <b>cross-validation</b> <b>criterion</b> for bandwidth selection. This kernel density estimate is shown to be asymptotically superior to many other intuitive kernel density estimates. The data-driven cross-validation bandwidth is shown to be asymptotically optimal {{in the sense of}} Stone (1984,Ann. Statist. 12, 1285 – 1297). The finite sample properties of the cross-validation bandwidth are investigated through a Monte Carlo simulation...|$|E
30|$|Closer {{inspection}} {{shows that}} the failure to reproduce the results of Abadie et al. (2015) is not due to software problems, but stems from the newly introduced cross-validation technique. In fact, all the above mentioned predictor weights deliver identical values for the <b>cross-validation</b> <b>criterion,</b> thus they are all equivalent solutions of the cross-validation approach. Hence, the cross-validation technique is (in most applications) not well-defined, since the predictor weights are not uniquely defined. As the cross-validation technique allows many different equivalent predictor weights, the results obtained by Abadie et al. (2015) are arbitrary {{in the sense that}} the authors could have obtained different results if they had used other software or organized the data differently.|$|E
3000|$|... [...]). For our analysis, we {{are using}} local {{constant}} techniques, and for bandwidth selection, we apply the least squares <b>cross-validation</b> (LSCV) <b>criterion</b> as described in (Hall et al. 2004; Li & Racine 2007). An increasing regression line indicates {{a positive effect on}} countries’ technological change (shift on the frontier) and on the distribution of their efficiencies (technological catch-up). However, the opposite indicates an unfavorable effect.|$|R
40|$|This paper 1 {{advances}} {{results in}} model selection by relaxing {{the task of}} optimally tuning the regularization parameter {{in a number of}} algorithms with respect to the classical <b>cross-validation</b> performance <b>criterion</b> as a convex optimization problem. The proposed strategy differs from the scope of e. g. generalized cross-validation (GCV) as it concerns the efficient optimization, not the individual evaluation of the model selection criterion. ...|$|R
40|$|The thesis {{analyzes}} some techniques adopted for {{model order}} selection in system identification: both classical methods (<b>cross-validation,</b> information <b>criteria,</b> the F-test and the statistical {{tests on the}} residuals) and innovative ones are evaluated, such as PUMS criterion and kernel-based estimation. The theoretical description of these methods is accompanied by an experimental analysis. Two combinations of the methods are also introduced, proving that they allow a more robust order selectio...|$|R
