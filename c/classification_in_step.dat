2|10000|Public
3000|$|... (see Section 3.3) for ballroom dance style classification. The same 10 -fold {{procedure}} as {{was used}} for meter <b>classification</b> <b>in</b> <b>step</b> 1 is performed in order to assign a ballroom dance style to all instances in the [...]...|$|E
40|$|Objective: To set out {{the methodological}} process for using Rasch {{analysis}} alongside traditional psychometric methods {{in the development of}} a health state classification that is amenable to valuation. Methods: The overactive bladder questionnaire is used to illustrate a four step process for deriving a reduced health state classification from an existing nonpreference based health related quality of life instrument. Step I excludes items that do not meet the initial validation process and step II uses criteria based on Rasch analysis and psychometric testing to select the final items for the health state <b>classification.</b> <b>In</b> <b>step</b> III, item levels are examined and Rasch analysis is used to explore the possibility of reducing the number of item levels. Step IV repeats steps I to III on alternative data sets in order to validate the selection of items for the health state classification. Conclusions: The techniques described enable the construction of a health state classification amenable for valuation exercises that will allow the derivation of preference weights. Thus, the health related quality of life of patients with conditions, like overactive bladder, can be valued and quality adjustment weights such as quality adjusted life years derived. ...|$|E
30|$|Classify the left-out {{observation}} {{using the}} <b>classification</b> rule obtained <b>in</b> <b>step</b> 1 above.|$|R
30|$|Step 2, feature extraction, then {{extracts}} {{this information}} {{in order to}} assign it to one abnormality type using the <b>classification</b> method used <b>in</b> <b>Step</b> 3.|$|R
40|$|Field-observed BRDFs for {{different}} land cover types are employed to derive a global BRDF/albedo database from land cover <b>classifications.</b> <b>In</b> a second <b>step,</b> AVHRR reflectance observations {{are used to}} reintroduce within-class variations into this database by fitting the field-observed BRDFs to the observed bidirectional reflectances. These databases are useful precursors to future satellite-derived BRDF databases...|$|R
40|$|This study {{aimed at}} {{classifying}} nineteen veteran lime trees (Tilia cordata Mill., T. platyphyllos scop. and T. x europaea L.) in their development. Tilia spp. {{was chosen because}} it is long lived and widely present <b>in</b> Belgium. A <b>classification</b> <b>in</b> five <b>steps</b> (A to E) is proposed, based on crown and trunk status, quantity of decaying wood and mean annual girth increment (MAI) as an additionnal criterion. We tested the relationship between veteran tree development and MAI. Threshold values were determined to help distinguish steps A to E. The relationship between trunk growth dynamics, and crown and root development is also discussed...|$|R
50|$|The {{purpose of}} {{preprocessing}} is to discard irrelevant {{information in the}} input data, that can negatively affect the recognition. This concerns speed and accuracy. Preprocessing usually consists of binarization, normalization, sampling, smoothing and denoising. The second step is feature extraction. Out of the two- or more-dimensional vector field received from the preprocessing algorithms, higher-dimensional data is extracted. The purpose of this step is to highlight important information for the recognition model. This data may include information like pen pressure, velocity or the changes of writing direction. The last big <b>step</b> is <b>classification.</b> <b>In</b> this <b>step</b> various models are used to map the extracted features to different classes and thus identifying the characters or words the features represent.|$|R
30|$|The third {{step was}} the {{implementation}} of classification techniques for sex identification. Algorithms that were chosen for this purpose were Naïve Bayes, Random Forest, Random Tree, REP Tree, and J 48 algorithm (Cichosz, 2014; Kim et al., 2014; Rughani and Bhatt, 2017). The measurements obtained <b>in</b> the second <b>step</b> were the input parameters to the abovementioned algorithms. <b>In</b> the fourth <b>step,</b> a final decision {{was made by the}} <b>classification</b> algorithms used (<b>in</b> <b>step</b> 3) for sex identification. The algorithm will use the features of feet and perform its analysis for differentiating males from females in the available sample (Fig.  2).|$|R
40|$|We {{present a}} method and an {{interactive}} software {{to assist in}} the creation of hypertext links in a text, whatever the topic of the text and the application domain may be. The method follows three steps: 1) preprocessing of the text for its segmentation and its "vectorization", 2) classification of segments of texts using ART, an unsupervised learning neural net, 3) research by genetic algorithm of the best associations between segments of text by using the <b>classification</b> provided <b>in</b> <b>step</b> 2 and the subjective choices expressed interactively by the user. Steps 1 and 2, carried out thanks to CONTERM software, are presented briefly. <b>Step</b> 3, implemented <b>in</b> PROGEN software, is developed and the results of a first experiment are presented. A discussion on the interest and the limits of the method are given in conclusion. ...|$|R
40|$|In this study, the pixel-based and {{object-oriented}} image classification approaches {{were used for}} identifying different land use types in Karnal district. Imagery from Landsat- 7 ETM with 6 spectral bands was used to perform the image classification. Ground truth {{data were collected from}} the available maps, personal knowledge and communication with the local people. In order to prepare land use map different approaches: Artificial Neural Network (ANN) and Support Vector Machine (SVM) were used. For performing object oriented classification eCognition software was used. During the object oriented <b>classification,</b> <b>in</b> first <b>step</b> several different sets of parameters were used for image segmentation and <b>in</b> second <b>step</b> nearest neighbor classifier was used for classification. Outcome from the classification works show that the object-oriented approach gave more accurate results (including higher producer’s and user’s accuracy for most of the land cover classes) than those achieved by pixelbased classification algorithms. It is also observed that ANN performed better as compared to SVM classification approach...|$|R
30|$|FER {{consists}} {{mainly of}} three important steps [3]: (1) face detection, (2) facial feature extraction and finally (3) expression <b>classification.</b> <b>In</b> the first <b>step,</b> faces are identified and {{extracted from the}} background. Different regions of the face can then be extracted such as the eyebrows, eyes, nose and mouth. The Viola and Jones face detection algorithm [6, 7] is widely used due to its efficiency, robustness and accuracy at identifying faces in uncontrolled backgrounds. Other methods {{include the use of}} active shape models (ASM) [8 – 10] to identify facial points and edges.|$|R
40|$|This paper {{introduces}} {{our research}} platform for enabling a multimodal Human-Robot Interaction scenario {{as well as}} our research vision: approaching problems in a holistic way to realize this scenario. However, in this paper the main focus is laid on the image processing domain, where our vision has been realized by combining particle tracking and Dynamic Bayesian Network <b>classification</b> <b>in</b> a unified Graphical Model. This combination allows for enhancing the tracking process by an adaptive motion model realized via a Dynamic Bayesian Network modeling several motion classes. The Graphical Model provides a direct integration of the <b>classification</b> <b>step</b> <b>in</b> the tracking process. First promising results show the potential of the approach. 1...|$|R
40|$|Machine {{learning}} and data mining methods {{can be the}} future of the clinical decision process like pathological diagnosis. In this project we studied Breast Cancer Wisconsin dataset and applied different algorithms, concretely classifiers, in order to predict the diagnosis and the prognostic of the cancer. In order to classify the different types of cancer we divided the <b>classification</b> <b>in</b> two <b>steps</b> and we tested different algorithms for each step. The first step is the diagnosis classification. Diagnosis consistsin predict if the cancer is malignant and benign. And the second step is the prognostic <b>classification.</b> Prognostic consist <b>in</b> predict if cancer is recurrent or non-recurrent. After applying different models for each steps {{the result is that the}} best model to predict the diagnosis is the Decision Forest model. And the best model to predict the prognostic is the Boosted Decision Tree model. So, we conclude that the two step classifier with Decision Forest model and Boosted Decision Tree model is the best classifier...|$|R
30|$|To {{compensate}} for this limitation, we propose a more fine-grained two-stage classification that operates {{on the individual}} pixels of a segment. First, we classify each pixel by the classifier used <b>in</b> one-stage <b>classification.</b> <b>In</b> a second <b>step</b> we apply a voting to the individual predictions. If the percentage of positively classified pixels is above two thirds, we classify the segment as positively detected; otherwise, we reject the entire segment. Results show that the two-stage classification is more robust in false detections while it detects elephants equally well. See Figures  6 d,e and 7 d,e for an illustration.|$|R
30|$|The <b>classification</b> {{conducted}} <b>in</b> this <b>step</b> of {{the analysis}} is of a qualitative nature; it does not entail additional mathematical restrictions for {{the determination of the}} optimal adaptation strategies, but rather divides the whole process into four distinct categories, one for each type of area extent. This fact implies that {{in order to determine the}} optimal adaptation measures, the integrated methodology has to be implemented four separate times (stages). In the end, the outputs of each stage {{of the analysis}} will be overall evaluated for the assessment of the optimal adaptation plans.|$|R
40|$|Abstract — In this work, we {{presented}} {{a novel approach}} for automated 3 D face recognition using range data. The contributions of the paper can be summarized as: 1) data registration, 2) data comparison. <b>In</b> first <b>step,</b> the nose tip {{was used as the}} reference point and three dimensional face shape was normalized to standard image size. Then 2 DPCA was applied to the resultant normalized data and the output data were used as the feature vectors. The Support Vector Machine was used <b>in</b> <b>classification</b> <b>step.</b> Recognition rate of 98 % was achieved. Index Terms— 3 D face recognition, 2 DPCA, SV...|$|R
40|$|ABSTRACT: In this study, {{we propose}} the {{integration}} of airborne LiDAR and satellite SAR data for building extraction and <b>classification</b> <b>in</b> four <b>steps.</b> First, we generated a digital surface model (DSM) from airborne LiDAR data. Second, the DSM was registered with a normalized radar cross-section (NRCS) image calculated from the SAR data. Third, buildings were extracted from the DSM, and finally, the buildings were classified into several clusters using NRCS values in the DSM. In our experiment, we selected a dense urban area in Tokyo as our study area. Then, we prepared ALOS- 2 PALSAR- 2 data and a DSM generated from an airborne LiDAR data. In the building extraction step, we extracted 1778 building roof segments from the DSM. <b>In</b> the <b>classification</b> <b>step,</b> we classified NRCS values of ascending and descending orbit data into several clusters based on ISODATA clustering to estimate building attributes. We conducted an experiment to validate our approach and clarified {{that a combination of}} airborne LiDAR and satellite SAR data could extract and classify buildings in a dense urban area...|$|R
40|$|Chromosome image {{analysis}} {{is composed of}} image preparation, {{image analysis}}, and image diagnosis. General procedureof chromosome image analysis includes of image preprocessing <b>in</b> the first <b>step,</b> image segmentation, feature extraction, andimage <b>classification</b> <b>in</b> the last <b>step.</b> This paper presents the preliminary results that use probabilistic neural network toclassify chromosome image into 24 classes. Features of chromosome which were used in this paper are area, perimeter, band’sarea, singular value decomposition, and band profile. Chromosome images were grouped <b>in</b> two <b>steps</b> by probabilistic neuralnetwork. Six groups and twenty four groups are {{in the first and}} the second step, respectively. The result from the secondstep is twenty four chromosome classes. Density profile sampled at 10, 30, 50 and 80 were tested. The best classificationresult of female is 68. 19 % when density profile at 30 samples was used, and that of male is 61. 30 % when density profile at 50 samples was used...|$|R
30|$|The {{remainder}} of the paper is organized as follows. We present related works in Section 2 and describe the spectral characteristics of an overblown tone in Section 3. In Section 4, we present the overall structure of the proposed system, including the preprocessing, feature-learning, max-pooling, and <b>classification</b> <b>steps.</b> <b>In</b> the following section, we explain the evaluation procedure, including the process of dataset construction, in detail. In Section 6, we present {{the results of the}} experiments and discussions, followed by the conclusions and directions for future work in Section 7.|$|R
40|$|There {{are several}} types of intersections such as merge-roads, diverge-roads, plus-shape intersections and two types of T-shape {{junctions}} in urban roads. When an autonomous vehicle encounters new intersections, {{it is crucial to}} recognize the types of intersections for safe navigation. In this paper, a novel intersection type recognition method is proposed for an autonomous vehicle using a multi-layer laser scanner. The proposed method consists of two steps: (1) static local coordinate occupancy grid map (SLOGM) building and (2) intersection <b>classification.</b> <b>In</b> the first <b>step,</b> the SLOGM is built relative to the local coordinate using the dynamic binary Bayes filter. <b>In</b> the second <b>step,</b> the SLOGM is used as an attribute for the classification. The proposed method is applied to a real-world environment and its validity is demonstrated through experimentation...|$|R
30|$|The {{individual}} identification {{is the main}} part of the proposed system and consists of three steps: feature extraction, feature space transformation, and <b>classification.</b> <b>In</b> the first <b>step</b> we extract global as well as local visual features that are both well suited for discrimination. As those descriptors are too high dimensional to perform fast and robust face recognition in practice, we apply a feature space transformation technique called LPP [23] to achieve a lower dimensional subspace with only little loss of information that is important for identification. These lower dimensional feature vectors are then used for classification. After classifying the global and local feature vectors separately, we apply a decision fusion technique to get the final result.|$|R
40|$|A segmentation-based fully-polarimetric {{synthetic}} aperture radar (PolSAR) image classification method that incorporates texture features and color features is designed and implemented. This method {{is based on the}} framework that conjunctively uses statistical region merging (SRM) for segmentation and support vector machine (SVM) for <b>classification.</b> <b>In</b> the segmentation <b>step,</b> we propose an improved local binary pattern (LBP) operator named the regional homogeneity local binary pattern (RHLBP) to guarantee the regional homogeneity in PolSAR images. <b>In</b> the <b>classification</b> <b>step,</b> the color features extracted from false color images are applied to improve the classification accuracy. The RHLBP operator and color features can provide discriminative information to separate those pixels and regions with similar polarimetric features, which are from different classes. Extensive experimental comparison results with conventional methods on L-band PolSAR data demonstrate the effectiveness of our proposed method for PolSAR image classification...|$|R
40|$|We give a {{complete}} classification of all static, spherically symmetric solutions of the SU(2) Einstein-Yang-Mills theory {{with a positive}} cosmological constant. Our <b>classification</b> proceeds <b>in</b> two <b>steps.</b> We first extend solutions of the radial field equations to their maximal interval of existence. <b>In</b> a second <b>step</b> we determine the Carter-Penrose diagrams of all 4 -dimensional space-times constructible from such radial pieces. Based on numerical studies we sketch {{a complete}} phase space picture of all solutions In contrast to the coupling of Abelian gauge fields to gravity, the interaction of non-Abelian gauge fields with gravity yields a rich structure of interesting solutions even in the spherically symmetric sector. While the Reissner-Nordstrøm black holes are the only static, spherically symmetric, asymptotically flat solution...|$|R
40|$|Face {{recognition}} in today’s technological world, and face recognition applications attain much more importance. Most {{of the existing}} work used frontal face images to classify face image. However these techniques fail when applied on real world face images. The proposed technique effectively extracts the prominent facial features. Most of the features are redundant and do not contribute to representing face. In order to eliminate those redundant features, computationally efficient algorithm is used to select the more discriminative face features. Extracted features are then passed to <b>classification</b> <b>step.</b> <b>In</b> the <b>classification</b> <b>step,</b> different classifiers are ensemble to enhance the recognition accuracy rate as single classifier is unable to achieve the high accuracy. Experiments are performed on standard face database images and results are compared with existing techniques...|$|R
40|$|ABSTRACT—New {{smartphone}} {{technologies are}} emerging which combine head-mounted displays (HMD) with standard {{functions such as}} receiving phone calls, emails, and helping with navigation. This opens new opportunities to explore cyber robotics algorithms (robotics sensors and human motor plant). To make these devices more adaptive to the environmental conditions, user behavior, and user preferences, {{it is important to}} allow the sensor-equipped devices to efficiently adapt and respond to user activities (e. g., disable incoming phone calls in an elevator, activate video recording while car driving). This paper hence presents a situation awareness system (SAS) for head-mounted smartphones. After collecting data from inertial sensors (accelerometers, gyroscopes), and video data (camera), SAS performs activity <b>classification</b> <b>in</b> three <b>steps.</b> Step 1 transforms inertial sensor data into a head orientation-independent and stable normalized coordinate system. Step 2 extracts critical features (statistical, physical, GIST). Step 3 classifies activities (Naive Bayes classifier), distinguishes between environments (Support Vector Machine), and finally combines both results (Hidden Markov Model) for further improvement. SAS has been implemented on a sensor-equipped eyeglasses prototype and achieved high accuracy (81. 5 %) when distinguishing between 20 real-world activities. I...|$|R
25|$|Even though <b>in</b> most {{statistical}} <b>classification</b> methods, {{the neutral}} class is ignored {{under the assumption}} that neutral texts lie near the boundary of the binary classifier, several researchers suggest that, as in every polarity problem, three categories must be identified. Moreover, it can be proven that specific classifiers such as the Max Entropy and the SVMs can benefit from the introduction of a neutral class and improve the overall accuracy of the <b>classification.</b> There are <b>in</b> principle two ways for operating with a neutral class. Either, the algorithm proceeds by first identifying the neutral language, filtering it out and then assessing the rest in terms of positive and negative sentiments, or it builds a three-way <b>classification</b> <b>in</b> one <b>step.</b> This second approach often involves estimating a probability distribution over all categories (e.g. naive Bayes classifiers as implemented by the NLTK). Whether and how to use a neutral class depends {{on the nature of the}} data: if the data is clearly clustered into neutral, negative and positive language, it makes sense to filter the neutral language out and focus on the polarity between positive and negative sentiments. If, in contrast, the data are mostly neutral with small deviations towards positive and negative affect, this strategy would make it harder to clearly distinguish between the two poles.|$|R
40|$|Test data {{prediction}} is about assigning {{the most suitable}} class for each test case during <b>classification.</b> <b>In</b> Associative <b>Classification</b> (AC) data mining, this step is considered crucial since the overall performance of the classifier is heavily dependent on the class assigned to each test case. This paper investigates the <b>classification</b> (prediction) <b>step</b> <b>in</b> AC {{in an attempt to}} come up with a novel generic prediction method that assures the best class assignment for each test case. The outcome is a new prediction method that takes into account all applicable rules ranking position in the classifier beside the class number of rules. Experimental results using different data sets from the University of California Irvine (UCI) repository and two common AC prediction methods reveal that the proposed method is more accurate for the majority of the data sets. Further, the proposed method can be plugged and used successfully by any AC algorithm...|$|R
40|$|International audienceIn {{the context}} of mine warfare, {{detected}} mines can be classified from their cast shadow. A standard solution is to perform image segmentation first, and then to extract a set of features from the shape allowing <b>classification</b> <b>in</b> a final <b>step.</b> <b>In</b> this paper, we extend this procedure to a sequence of images obtained along {{a part of a}} circular trajectory of the sonar. For a given ground mine except mine with radial symmetry, cast shadow appearance generally depends on the point of view. Consequently, different features values can describe the same object. Whereas this often entails misclassification when a single view is used, we propose to use feature values computed over a sequence of images, especially its evolution, to characterise objects from multiple views. Our supervised classification scheme is based on the correlation, for each feature, between the sequence of values obtained from the unknown object and typical values related to each class...|$|R
40|$|In {{this paper}} we sketch an {{approach}} to the integration of file based systems in database federations. For that the main problem {{is the lack of}} meta-information for local file systems. Therefore, we have to derive an appropriate local conceptual schema. Our approach is based on a classification of local file systems. <b>In</b> the first <b>step</b> a local file system has to be assigned to one or more classes accordingly to the <b>classification.</b> <b>In</b> the next <b>step,</b> class-specific methods and tools support the derivation of a structure description and, furthermore, of a conceptual schema. Keywords: federated database design, file integration, legal systems, reengineering. 1 Introduction Considering the situation in many organizations and enterprises we discover a number of different information systems in use. However, in each part of the organizations (or even worse for each specific task) a specialized information system is used. Most of these information systems have to store their important data in [...] ...|$|R
40|$|A {{technique}} is presented for frontal face detection in color images based on facial feature extraction and appearance-based classification. Salient facial features {{are used to}} define a search space that is then used <b>in</b> a <b>classification</b> <b>step</b> <b>in</b> order {{to find the best}} position of the face in the image. Mouth feature points are identified using the redness property of image pixels whilst eye feature points are detected using a search strategy applied to a subset of regions in a fine region-based segmentation of the candidate face. Face class modeling based on a multivariate normal distribution and discriminating feature analysis is used as the face classification method. The utilization of facial features in this system avoids analyzing the image at every pixel location as well as at multiple scales when detecting faces of different sizes...|$|R
40|$|Aiming at the {{deficiency}} of Melfrequency cepstral coefficients (MFCCs) in discriminating acoustic signals, a twolevel classification strategy based on different feature extraction techniques was proposed to classify nine audio signals in a smart healthcare monitoring system. In the first level, the MFCCs and its variants (ΔMFCCs) {{are used as}} the inputs of the hidden Markov model (HMM) for classification. Then, the {{mean and standard deviation}} of the firstorder difference of power spectral density over different frequency bands are calculated as features for further <b>classification</b> <b>in</b> the second <b>step.</b> Experiment results <b>in</b> realtime health monitoring system reveal that the firstorder derivatives of power spectral density contain some important information which is not included in MFCCs. The approach in this paper shows better robustness and high classification accuracy whose average is as high as 97  37 %...|$|R
40|$|The {{fusion of}} {{inertial}} sensor data is heavily {{used for the}} clas-sification of daily life activities. The knowledge about the performed daily life activities is mandatory to give physi-cally inactive people feedback about their individual quality of life. In this paper, four inertial sensors were placed on wrist, chest, hip and ankle of 19 subjects, which had to perform seven daily life activities. Each sensor node separately per-formed preprocessing, feature extraction and <b>classification.</b> <b>In</b> the final <b>step,</b> the classifier decisions of the sensor nodes were fused and a single activity was predicted by majority voting. The proposed classification system obtained an overall mean classification rate of 93. 9 % and was robust against defect sensors. The system allows an easy integration of new sen-sors without retraining of the complete system, which is an advantage over commonly used feature level fusion ap-proaches...|$|R
40|$|This paper {{presents}} a new offline face recognition system. The proposed system {{is built on}} one dimensional left-to- right Hidden Markov Models (1 D-HMMs). Facial image features are extracted using Gabor wavelets. The dimensionality of these features is reduced using the Fisher’s Discriminant Analysis method to keep only the most relevant information. Unlike existing techniques using 1 D-HMMs, <b>in</b> <b>classification</b> <b>step,</b> the proposed system employs 1 D-HMMs to find the relationship between reduced features components directly without any additional segmentation step of interest regions in the face image. The performance evaluation of the proposed method was performed with AR database and the proposed method showed a high recognition rate for this database...|$|R
40|$|Classifying species into {{functional}} {{groups is}} a way to understand the functioning of species-rich ecosystems, or to model the dynamics of such ecosystems. Many statistical techniques have been defined to classify species into groups, and a question is whether different techniques bring consistent <b>classifications.</b> <b>In</b> a tropical rain forest in French Guiana, five species classifications have been defined by different authors for the purpose of forest growth modelling but using different data sets and different statistical techniques. The correspondence between the five classifications was measured using four indices that are generalizations of existing indices to compare two classifications. A multiple correspondence analysis was used to identify associations between groups of different <b>classifications.</b> <b>In</b> a second <b>step,</b> two-table multivariate analyses were used to characterize the relationships between species classifications and eight species traits (consisting of seven populational traits and one functional trait). We evidenced a consensus on the potential size of trees: species were similarly clustered by the five classifications along this trait that is correlated to turnover rate. More surprisingly, no consensus was found for growth rate, nor wood density, traits that are correlated with light requirement. (Résumé d'auteur...|$|R
40|$|ABSTRACT: A {{modified}} neocognitron {{neural network}} suitable for medical signal classification is presented. The network's functionality is demonstrated on an application involving {{the classification of}} breathing signals measured on patients recovering from surgery. The performance of the system {{was found to be}} equivalent, and in some cases, better than a standard technique used for comparison. The main advantage of this system is that it allows for a detailed analysis into the decisions made by the system. Additionally, its internal property enables the rejection of inputs which are found to be too different to the learned ones, the thresholds for rejection can be set by tuning the structure of the network and selectivity of the cells in the network. This makes it possible to detect artefacts or identify new classes that might exist, in addition to providing the appropriate <b>classification</b> <b>in</b> the final <b>step</b> of the processing chain...|$|R
40|$|Construct definition, Object classification, Attribute classification, Rater identification, Scale formation, and Enumeration and {{reporting}} (C-OAR-SE) is proposed {{as a new}} procedure {{for the development of}} scales to measure marketing constructs. COAR- SE is based on content validity, established by expert agreement after pre-interviews with target raters. In C-OAR-SE, constructs are defined in terms of Object, Attribute, and Rater Entity. The Object classification and Attribute <b>classification</b> <b>steps</b> <b>in</b> C-OAR-SE produce a framework (six types of scales) indicating when to use single-item vs. multiple-item scales and, for multiple-item scales, when to use an index of essential items rather than selecting unidimensional items with a high coefficient alpha. The Rater Entity type largely determines reliability, which is a precision-of-score estimate for a particular application of the scale...|$|R
