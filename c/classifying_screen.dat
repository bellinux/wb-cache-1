2|57|Public
50|$|A {{size range}} {{coefficient}} of approximately three is advisable. A {{minimum amount of}} undersized fine material must enter the machines to optimize availability.Moisture of the feed is not important, if the material is sufficiently dewatered and the undersize fraction is efficiently removed. For surface detection technologies sometimes spray water on the <b>classifying</b> <b>screen</b> is required to clean the surfaces. Surface detection technologies would otherwise measure the reflectance of the adhesions {{on the surface and}} a correlation to the particle's content is not given.|$|E
40|$|This {{research}} {{investigates the}} validity of the layout complexity metric to GUI screen design. This metric offers a simple method to gauge the complexity of the visual design of a computer screen by <b>classifying</b> <b>screen</b> objects into classes based on common dimensions and positions. However, though it has been used by other interface researchers, {{it is not clear that}} it is a valid metric for GUIs. Initial work suggests that users prefer more complex layouts rather than the simple ones suggested by guidelines. The pilot study showed that screens midway between complex and simple were the most usable. The next experiment is at the data collection stage. It uses four screens differing in complexity and a Latin-squares design to avoid experimental bias and nuisance variables. Twenty-four human participants are randomly assigned to blocks. The final experiment will attempt to gain a wider range of users with a more complex task...|$|E
40|$|We give a {{rigorous}} notion and study of screening operators and screening pairs for a vertex operator superalgebra associated to an abelian intertwining algebra. Screening pairs arising from weight one primary vectors associated to a lattice vertex operator algebra are classified into five general types, {{one type of}} which has been shown {{to play an important role}} in the construction study of certain interesting W-vertex algebras. These types of screening pairs we go on to study in detail through the notion of a system of screeners which are a kind of set of generalized roots. We <b>classify</b> <b>screening</b> systems for all positive definite integral lattices of rank two, and for all positive definite even lattices of arbitrary rank when these lattices are generated by a screening system. Comment: 41 page...|$|R
40|$|Abstract. In {{this paper}} we study weakly {{irreducible}} holonomy {{representations of the}} normal connection of a spacelike submanifold in a pseudo-Riemannian space from. We associate screen representations to weakly irreducible normal holonomy groups and <b>classify</b> the <b>screen</b> representations having the Borel-Lichnérowicz property. In particular, we derive a classification of Lorentzian normal holonomy representations. 1...|$|R
40|$|Navy Computer Adaptive Personality Scales (NCAPS) is an {{innovative}} instrument developed to assess personal attributes for <b>classifying</b> or <b>screening</b> individuals into U. S. Navy occupations. The Armed Services Vocational Aptitude Battery (ASVAB), {{a collection of}} verbal, mathematical, and technical tests, serve as the primary selection and classification instrument for all Navy enlisted jobs and is a substantia...|$|R
40|$|BACKGROUND: Colorectal cancer {{screening}} is underused, and primary care clinicians are challenged to provide patient education within {{the constraints of}} busy practices. OBJECTIVE: To test the effect of an educational video, mailed to patients 2 ̆ 7 homes before a physical examination, on performance of colorectal {{cancer screening}}, particularly sigmoidoscopy. DESIGN: Randomized, controlled trial. SETTING: 5 primary care practices in central Massachusetts. PARTICIPANTS: 938 patients age 50 to 74 years who were scheduled for an upcoming physical examination, had no personal history of colorectal cancer, and were eligible for lower-endoscopy screening according to current guidelines. INTERVENTION: Participants {{were randomly assigned to}} receive usual care (n = 488) or a video about colorectal cancer, the importance of early detection, and screening options (n = 450). MEASUREMENTS: Baseline and 6 -month follow-up telephone assessments were conducted. A dependent variable <b>classified</b> <b>screening</b> since baseline as 1) sigmoidoscopy with or without other tests, 2) another test or test combination, or 3) no tests. RESULTS: Overall screening rates were the same in the intervention and control groups (55...|$|R
40|$|STUDY OBJECTIVE [...] The {{aim was to}} {{find out}} if it is possible, by <b>classifying</b> <b>screening</b> mammograms {{according}} to the likelihood of malignancy, to divide the recalled women to a group in which there is high suspicion of malignancy, most having breast cancers, and a group with more obscure findings. DESIGN [...] Screening mammograms of recalled women were classified according to the likelihood of malignancy. 0 = technically insufficient, 1 = normal, 2 = benign tumour, 3 = malignancy cannot be excluded, 4 = strongly suspicious for malignancy, 5 = malignant. SETTING [...] This study was a population based survey of mammography screening in Helsinki and surroundings in Finland. PATIENTS [...] 21, 417 women (aged 50 - 59 years) were invited to be screened, 18, 012 (84. 10 %) participated. Of these 579 (3. 21 % of those screened) were recalled for further studies; 124 of these were referred for surgical biopsy and 82 had breast cancer. MEASUREMENTS AND MAIN RESULTS [...] All cases classified as 5, 60 % of the cases classified as 4, 6. 5 % of the cases classified as 3, 0 % of the cases classified as 2 or 1, and 1. 2 % of the cases classified as 0 proved to have breast cancers. However classification 5 represented 5. 9 % of all recalled women and 41. 5 % of all screening detected breast cancers; classification 4, 6. 0 % of all recalled women and 25. 6 % of all screening detected breast cancers; classification 3, 68. 9 % of all recalled women and 31. 7 % of all screening detected breast cancers; classification 2, 11. 7 % and classification 1, 2. 9 % of all recalled women. No breast cancers were detected with these classifications. Classification 0 represented 4. 5 % of all recalled women and 1. 2 % of all screening detected breast cancers. Classifications 5 and 4 represented only 11. 9 % of all recalled women but 67. 1 % of all screening detected breast cancers. CONCLUSIONS [...] By <b>classifying</b> <b>screening</b> mammograms according to the likelihood of malignancy, recalled women can be divided into two groups: (1) a quite small subgroup in which everyone or almost everyone will be shown to have breast cancer; and (2) a much larger subgroup in which only a few will be proven to have breast cancer. The invitation procedure for the further studies should be improved on this basis of minimising anxiety among recalled women...|$|R
40|$|Bacterial strains {{isolated}} from deep-sea amphipods were identified, <b>classified,</b> and <b>screened</b> for plasmid content. Plasmids were common, with 11 of 16 isolates carrying {{one or more}} plasmids; these ranged in size from 2. 9 to 63 megadaltons. Several of the strains demonstrated distinctly different phenotypic traits yet contained plasmids of the same molecular weight. Results of agarose gel electrophoresis, DNA hybridization, and restriction analysis indicate that the plasmids detected in these deep-sea isolates are identical, suggesting that transmission may occur in the deep-sea environment and that plasmids are common in some deep-sea habitats...|$|R
40|$|Design: Retrospective analysis. Setting: East London Hospital. Subjects: 724 {{women who}} had {{maternal}} serum alphafetoprotein levels measured between 15 to 19 weeks gestation. Main outcome measure: The main outcome measures were defined as any case of preeclampsia, small-for-gestational age (SGA) birth- weight th centile, placental abruption, stillbirth or early neonatal death. Methods: Women with MSAFP > 2. 0 Multiples of Median (MoM) were <b>classified</b> as <b>screen</b> positive. Results: 41 (5. 7 %) women developed preeclampsia. Women with MSAFP > 2. 0 Multiples of the Median (MoM) {{were significantly more likely}} to develop preeclampsia (p th centile (p </p...|$|R
40|$|Past {{studies have}} {{suggested}} that thermal dissociation analysis of nucleic acids hybridized to DNA microarrays would improve discrimination among duplex types by scanning through a broad range of stringency conditions. To more fully constrain the utility of this approach using a previously described gel-pad microarray format, artificial neural networks (NNs) were trained to recognize noisy or low-quality data, as might derive from nonspecific fluorescence, poor hybridization, or compromised data collection. The NNs were trained to classify dissociation profiles (melts) into groups based on selected characteristics (e. g., initial signal intensity, area under the curve) using a data set of 21, 044 profiles derived from 186 probes hybridized to a study set of RNA extracted from 32 microbes common to the human oral cavity. Three melt profile groups were identified: one group consisted mostly of ideal melt profiles; another group consisted mostly of poor melt profiles; and, the remainder were difficult to <b>classify.</b> <b>Screening</b> of melting profiles of perfect-match hybrids revealed inconsistencies in the form of melting profiles even for identical probes on the same microarray hybridized to same target rRNA. Approximately 18 % of perfect-match duplex types were correctly classified as poor. Experimental variability and deviation from ideal melt behavior were shown to be attributable primarily to a method of local background subtraction that was very sensitive to displacement of the grid frames used for image capture (both determined by the image analysis system) and duplexes with low binding constants. Additional results showed that long RNA fragments limit the discriminating power among duplex types...|$|R
40|$|AbstractDespite the {{positive}} {{outcome of the}} recent randomized trial of computed tomography (CT) screening for lung cancer, substantial implementation challenges remain, including the clear reporting of relative risk and suggested workup of screen-detected nodules. Based on current literature, we propose a 6 -level Lung-Reporting and Data System (LU-RADS) that <b>classifies</b> <b>screening</b> CTs by the nodule with the highest malignancy risk. As the LU-RADS level increases, the risk of malignancy increases. The LU-RADS level is linked directly to suggested follow-up pathways. Compared with current narrative reporting, this structure should improve communication with patients and clinicians, and provide a data collection framework to facilitate screening program evaluation and radiologist training. In overview, category 1 includes CTs with no nodules and returns the subject to routine screening. Category 2 scans harbor minimal risk, including < 5 mm, perifissural, or long-term stable nodules that require no further workup before the next routine screening CT. Category 3 scans contain indeterminate nodules and require CT follow up with the interval dependent on nodule size (small [5 - 9 mm] or large [≥ 10 mm] and possibly transient). Category 4 scans are suspicious and are subdivided into 4 A, low risk of malignancy; 4 B, likely low-grade adenocarcinoma; and 4 C, likely malignant. The 4 B and 4 C nodules have a high likelihood of neoplasm simply based on screening CT features, even if positron emission tomography, needle biopsy, and/or bronchoscopy are negative. Category 5 nodules demonstrate frankly malignant behavior on screening CT, and category 6 scans contain tissue-proven malignancies...|$|R
40|$|AbstractIn normal {{classification}} analysis, {{there may}} be cases where the population distributions are perturbed by a screening scheme. This paper considers a new classification method for screened {{data that is obtained}} from the perturbed normal distributions. Properties of each population distribution is considered and the best region for <b>classifying</b> the <b>screened</b> data is obtained. These developments yield yet another optimal rule for the classification. The rule is studied from several aspects such as a linear approximation, error rates, and estimation of the rule using the EM algorithm. Relationships among these aspects as well as investigation of the rule’s performance are also considered. The screened classification ideas are illustrated in detail using numerical examples...|$|R
40|$|This paper {{addresses}} {{that natural}} consort of love: sex. It particularly considers {{the absence of}} actual sex from mainstream popular culture and the marginalisation of 2 ̆ 7 fun 2 ̆ 7 sex as porn, requiring its illicit circulation as ‘illegitimate’ videos. The absence of sex from films <b>classified</b> and <b>screened</b> in public venues (even to over- 18 s) prevents a discourse about actual sex informing the discourse of love and romance perpetuated through Hollywood movies. The {{value of a variety}} of representations of sexual practice {{in the context of a}} discussion of love, sex and romance in Western cinema was briefly illuminated for the few days that Baise-moi was legitimately screened in Australia...|$|R
40|$|This paper proposes an {{efficient}} content adaptive screen image scaling scheme for the real-time screen applications like remote desktop and screen sharing. In the proposed screen scaling scheme, a screen content classification step is first introduced to <b>classify</b> the <b>screen</b> image into text and pictorial regions. Afterward, we propose an adaptive shift linear interpolation algorithm {{to predict the}} new pixel values with the shift offset adapted to the content type of each pixel. The shift offset for each screen content type is offline optimized by minimizing the theoretical interpolation error based on the training samples respectively. The proposed content adaptive screen image scaling scheme can achieve good visual quality and also keep the low complexity for real-time applications. Comment: ICIP 201...|$|R
40|$|In normal {{classification}} analysis, {{there may}} be cases where the population distributions are perturbed by a screening scheme. This paper considers a new classification method for screened {{data that is obtained}} from the perturbed normal distributions. Properties of each population distribution is considered and the best region for <b>classifying</b> the <b>screened</b> data is obtained. These developments yield yet another optimal rule for the classification. The rule is studied from several aspects such as a linear approximation, error rates, and estimation of the rule using the EM algorithm. Relationships among these aspects as well as investigation of the rule's performance are also considered. The screened classification ideas are illustrated in detail using numerical examples. EM algorithm Probability of misclassification Screened classification analysis Screened normal data Two-sided conditioning normal distribution...|$|R
40|$|AbstractThis study {{identifies}} the spatial characteristics and relationships of each used space {{according to the}} multiplex type. In this study, multiplexes are <b>classified</b> according to <b>screen</b> rooms and circulation systems, and each used space is quantitatively analyzed. The multiplex type based on screen rooms and moving line systems influences the relationship and characteristics of each used space in various ways. In particular, {{the structure of the}} used space of multiplexes has a significant effect on profit generation and audience convenience...|$|R
40|$|Background: Epidemiological {{research}} exploring {{risk factors}} for Alzheimer’s dementia resulted {{in the identification of}} the mild cognitive impairment (MCI) profile. Subsequently, distinct subtypes of MCI have been proposed; however, the validity of these as diagnostic entities remains uncertain. Design and participants: The aim {{of the present study was}} to examine the longitudinal neuropsychological profiles of MCI subtypes. A total of 118 adults aged 60 – 90 years were <b>classified</b> at <b>screening</b> as amnestic (a-MCI), nonamnestic (na-MCI), and multiple-domain amnestic (a-MCI+) and were assessed at two time points across 20 months on a comprehensive neuropsychological assessment battery. Results: The a-MCI+ group displayed the poorest performance of all groups in terms of episodic memory, working memory, attention, and executive functioning. Conclusions: These findings suggest that the a-MCI+ subtype is the only variant that is recognizable via neuropsychological testing. In contrast, the differentiation between single-domain subtypes and healthy controls is difficult and may not be achievable through current neuropsychological assessment practices...|$|R
40|$|This {{study shows}} which hard tick species (Ixodidae) {{were found on}} {{domestic}} horses in the Netherlands in 2008 – 2009, and what potential pathogens these ticks carried. In the period 2008 – 2009, 130 ticks were collected, <b>classified</b> and <b>screened</b> {{for the presence of}} DNA from specific tick-borne pathogens using PCR-RLB. The numbers of ticks of the various species found were: 68 Ixodes ricinus, 58 Ixodes spp. (57 nymphs and 1 larva), 2 Dermacentor reticulatus and 2 Hyalomma marginatum. DNA from Borrelia valaisiana was detected in 49 % of these ticks, B. afzelii in 22 %, B. burgdorferi sensu stricto and B. garinii in 3 % and 2 %, respectively. Rickettsia helvetica was detected in 9 % of examined ticks, Anaplasma phagocytophilum in 1. 5 %, Babesia venatorum in 4 %, and B. caballi and Theileria equi in 1. 5 and 3 %, respectively. There were considerable regional differences suggesting focal distribution of these potential pathogens...|$|R
40|$|EPA) {{recognized}} the importance of controlling solid and floatable materials under the “nine minimum controls ” described in the Combined Sewer Overflow (CSO) Control Policy. CSOs can contain high levels of floatable materials, suspended solids, biochemical oxygen demand (BOD), oils and grease, toxic pollutants, and pathogenic microorganisms. Floatables are often the most noticeable and problematic CSO pollutant. They create aesthetic problems and boating hazards, threaten wildlife, foul recreational areas, and cause beach closures. There are numerous methods available for floatables control, including baffles, catch basin modifications, netting systems, containment booms, skimming processes, and screening and trash rack devices. These technologies are summarized in EPA’s CSO Technology Fact Sheet entitled “Floatables Control” (EPA 832 -F- 99 - 008). This fact sheet focuses on screens and trash racks for CSO floatables control. Screens are considered an effective and economically efficient method of removing solids and floatables from CSOs. CSO screens are typically constructed of steel parallel bars or wires, wire mesh (wedgewire), grating, or perforated plate; some screens, however, are constructed of milled bronze or copper plates. In general, the openings are circular or rectangular slots, varying in size from 0. 25 to 15. 24 centimeter (0. 1 to 6 inch) spacings. The amount and size of the solids and floatables removed is dependent on the type of screen {{and the size of the}} screen openings. Solids are removed from the flow by two basic treatment mechanisms: C Direct straining of all particles larger than the screen openings. Filtering of smaller particles by straining flow through the mat of solids already deposited on the screen. Generally there are two types of bar screens- coarse and fine. Both are used at CSO control facilities, with each different type providing a different level of removal efficiency. While there is no industry standard for <b>classifying</b> <b>screens</b> based on aperture size coarse bar screens generally have 0. 04 to 0. 08 meter (1. 5 to 3. 0 inch) clear spacing between bars and fine screens generally have rounded or slotted openings of 0. 3 to 1. 3 centimeters (0. 1 to 0. 5 inch) clear space...|$|R
40|$|PS 304 is a plasma spray {{deposited}} {{solid lubricant}} coating with feedstock composed of NiCr, Cr 2 O 3, Ag, and BaF 2 -CaF 2 powders. The effects of rounded BaF 2 -CaF 2 particles on the gravity-fed flow characteristics of PS 304 feedstock have been investigated. The BaF 2 -CaF 2 powder was fabricated by water atomization using {{four sets of}} process parameters. Each of these powders was then characterized by microscopy and <b>classified</b> by <b>screening</b> to obtain 45 to 106 micron particles and added incrementally from 0 to 10 wt% to the other constituents of the PS 304 feedstock, namely nichrome, chromia, and silver powders. The relationship between feedstock flow rate, measured with the Hall flowmeter, and concentration of fluorides {{was found to be}} linear in each case. The slopes of the lines were between those of the linear relationships previously reported using angular and spherical fluorides and were closer to the relationship predicted using the rule of mixtures. The results offer a fluoride fabrication technique potentially more cost-effective than gas atomization processes or traditional comminution processes...|$|R
30|$|One of {{the first}} {{approaches}} focusing on MTT problem is the Multiple Hypothesis Tracking (MHT) algorithm [6], which maintains several correspondence hypotheses for each object at each frame. An iteration of MHT begins {{with a set of}} current track hypotheses. Each hypothesis is a collection of disjoint tracks. For each hypothesis, a prediction is made for each object state in the next frame. The predictions are then compared with the measurements on the current frame by evaluating a distance measure. MHT makes associations in a deterministic sense and exhaustively enumerates all possible associations. The final track of the object is the most likely hypothesis over the time period. The MHT algorithm is computationally exponential both in memory and time. Over more than 30 years, MHT approaches have evolved mostly on controlling this exponential growth of hypotheses [7, 9 – 12]. For controlling this combinatorial explosion of hypotheses, all the unlikely hypotheses have to be eliminated at each frame. Several methods have been proposed to perform this task (for details refer to [9, 13]). These methods can be <b>classified</b> in: <b>screening</b> [9], grouping methods for selectively generating hypotheses, and pruning, grouping methods for elimination of hypotheses after their generation.|$|R
40|$|The {{effects of}} BaF 2 -CaF 2 {{particle}} size and size distribution on PS 304 feedstock powder flowability have been investigated. Angular BaF 2 -CaF 2 eutectic powders were produced by comminution and <b>classified</b> by <b>screening</b> to obtain 38 to 45 microns 45 to 106 microns, 63 to 106 microns, 45 to 53 microns, 63 to 75 microns, and 90 to 106 microns particle size distributions. The fluorides were added incrementally from 0 to 10 wt% {{to the other}} powder constituents of the PS 304 feedstock: nichrome, chromia, and silver powders. The flow rate of the powder blends decreased linearly with increasing concentration of the fluorides. Flow was degraded with decreasing BaF 2 -CaF 2 particle size and with increasing BaF 2 -CaF 2 particle size distribution. A semiempirical relationship is offered to describe the PS 304 powder blend flow behavior. The Hausner Ratio confirmed the funnel flow test results, but was slightly less sensitive to differences in BaF 2 -CaF 2 particle size and size distribution. These findings may have applicability to other powders that do not flow easily, such as ceramic powders...|$|R
40|$|A {{total of}} 95 D {{children}} who applied to enter kindergarten in 1986 in 6 Virginia school districts were studied {{in an effort}} to determine the relation of social class, age, ethnicity, and gender to kindergarten placement decisions, i. e., to nonplacement, placement in a regular kindergarten class, or placement in junior kiAdergarten. All participating districts screened all children entering school. The three types of initial data collected on each child were <b>classified</b> as demographic, <b>screening,</b> and placement. Demographic data included: birth date, eligibility for subsidized lunch, gender, and ethnicity. Placement categories included: not enrolled in kindergarten, enrolled in junior kindergarten, and enrolled in kindergarten. Students were tested with the Brigance Kindergarten and First Grade Screen, the Daberon Screening for School Readiness, or the Missouri Kindergarte...|$|R
50|$|Document {{screening}} is {{the rapid}} but systematic evaluation of documents {{to determine which}} documents contain priority information. Selected priority documents will be exploited immediately to meet intelligence collection management priorities. For screening purposes, CEDs are considered unclassified unless originated in the U.S. and/or allied nation(s), and are marked <b>classified.</b> The document <b>screening</b> phase is an integral step in the DOCEX process as screening determines applicability {{of a variety of}} exploitation treatments and procedures. Interpreters and qualified intelligence analysts working alongside communications and information technology specialists decide the DOCEX course of action during the screening phase. Complete translation is not required at this phase of the DOCEX process, but sufficient translation of documents is required to determine significance and relevance to priority intelligence requirements.|$|R
5000|$|A Vibrating Conveyor is {{a machine}} {{with a solid}} {{conveying}} surface which is turned up on the side to form a trough. They are used extensively in food grade applications where sanitation, washdown, and low maintenance are essential. Vibrating conveyors are also suitable for harsh, very hot, dirty, or corrosive environments. They {{can be used to}} convey newly cast metal parts which may reach upwards of [...] Due to the fixed nature of the conveying pans vibrating conveyors can also perform tasks such as sorting, <b>screening,</b> <b>classifying</b> and orienting parts. Vibrating conveyors have been built to convey material at angles exceeding 45° from horizontal using special pan shapes. Flat pans will convey most materials at a 5° Incline from horizontal line.|$|R
40|$|A Total System Performance Assessment for Site Recommendation (TSPA-SR) has {{recently}} been completed (CRWMS M&O, 2000 b) for the potential high-level waste repository at the Yucca Mountain site. The TSPA-SR is an integrated model of scenarios and processes relevant to the postclosure performance of the potential repository. The TSPA-SR scenarios and model components in turn include representations of all features, events, and processes (FEPs) identified as being relevant (i. e., screened in) for analysis. The process of identifying, <b>classifying,</b> and <b>screening</b> potentially relevant FEPs thus provides a critical foundation for scenario development and TSPA analyses for the Yucca Mountain site (Swift et al., 1999). The objectives of this paper are to describe (a) the identification and classification of the comprehensive list of FEPs potentially relevant to the postclosure performance of the potential Yucca Mountain repository, and (b) the development, structure, and use of an electronic database for storing and retrieving screening information about the inclusion and/or exclusion of these Yucca Mountain FEPs in TSPA-SR. The FEPs approach to scenario development {{is not unique to}} the Yucca Mountain Project (YMP). General systematic approaches are summarized in NEA (1992). The application of the FEPs approach in several other international radioactive waste disposal programs is summarized in NEA (1999) ...|$|R
40|$|AbstractDetecting and characterizing of anti-drug {{antibodies}} (ADA) {{against a}} protein therapeutic are crucially important {{to monitor the}} unwanted immune response. Usually a multi-tiered approach that initially rapidly screens for positive samples that are subsequently confirmed in a separate assay is employed for testing of patient samples for ADA activity. In this manuscript we evaluate the ability of different methods used to <b>classify</b> subject with <b>screening</b> and competition based confirmatory assays. We find that for the overall performance of the multi-stage process the method used for confirmation is most important where a t-test is best when differences are moderate to large. Moreover we find that, when differences between positive and negative samples are not sufficiently large, using a competition based confirmation step does yield poor classification of positive samples...|$|R
25|$|In milling, the {{incoming}} graphite products and concentrates can be ground before being <b>classified</b> (sized or <b>screened),</b> with the coarser flake size fractions (below 8 mesh, 8–20 mesh, 20–50 mesh) carefully preserved, {{and then the}} carbon contents are determined. Some standard blends can be prepared from the different fractions, each with a certain flake size distribution and carbon content. Custom blends can also be made for individual customers who want a certain flake size distribution and carbon content. If flake size is unimportant, the concentrate can be ground more freely. Typical end products include a fine powder {{for use as a}} slurry in oil drilling and coatings for foundry molds, carbon raiser in the steel industry (Synthetic graphite powder and powdered petroleum coke can also be used as carbon raiser). Environmental impacts from graphite mills consist of air pollution including fine particulate exposure of workers and also soil contamination from powder spillages leading to heavy metal contamination of soil.|$|R
40|$|Centrosomes {{comprise}} {{a pair of}} centrioles surrounded by an amorphous pericentriolar material (PCM). Here, we have performed a microscopy-based genome-wide RNA interference (RNAi) screen in Drosophila cells to identify proteins required for centriole duplication and mitotic PCM recruitment. We analysed 92 % of the Drosophila genome (13, 059 genes) and identified 32 genes involved in centrosome function. An extensive series of secondary <b>screens</b> <b>classified</b> these genes into four categories: (1) nine are required for centriole duplication, (2) 11 are required for centrosome maturation, (3) nine are required for both functions, and (4) three genes regulate centrosome separation. These 32 hits include several new centrosomal components, {{some of which have}} human homologs. In addition, we find that the individual depletion of only two proteins, Polo and Centrosomin (Cnn) can completely block centrosome maturation. Cnn is phosphorylated during mitosis in a Polo-dependent manner, suggesting that the Polo-dependent phosphorylation of Cnn initiates centrosome maturation in flies...|$|R
40|$|Although {{monitoring}} tuberculosis (TB) infection during {{long-term treatment}} with TNF antagonists {{is of great}} importance, no monitoring strategy has yet proved successful. Indeed, even the newly proposed interferon-gamma release assays (IGRAs) are known to produce dynamic changes in IFN-γ plasma levels, making them unreliable indicators of patients' pathological/clinical status. We used intracellular cytokine flow cytometry (ICCFC) to investigate the performance of multifunctional CD 4 + T cells producing IFN-γ, IL- 2, and/or TNF in response to M. tuberculosis-specific antigens in subjects treated with TNF antagonists. Patients were classified into 3 groups based on their TB status before commencement of treatment and on IFN-γ level fluctuations evaluated by IGRA during a 36 -month follow-up period. The cytokine profile of M. tuberculosis-specific CD 4 + T cells showed that LTBI subjects had higher frequency of double-positive IFN-γ+ IL- 2 + CD 4 + T cells and triple-positive IFN-γ+ IL- 2 + TNF+ CD 4 + T cells compared to those without LTBI who showed IFN-γ level fluctuations over time. In contrast, this latter group of patients showed similar proportions of cells producing IFN-γ alone, IL- 2 alone, and IL- 2 in combination with TNF in response to M. tuberculosis-specific antigens. It therefore appears that patients with and without LTBI infection are characterized by different intracellular cytokine profiles. This is the first study evaluating ICCFC in patients treated with TNF antagonists, and suggests that multifunctional analysis of CD 4 + T cells could be useful for ruling-out TB infection in patients <b>classified</b> at <b>screening</b> as LTBI-negative but who show IGRA fluctuations under long-term TNF antagonist treatment...|$|R
40|$|Objective: This study {{examined}} the relationships between reported history of childhood sexual abuse (CSA), psychological distress, and medical utilization among women in a health maintenance organization (HMO) setting. Methods: Participants were 206 women aged 20 to 63 years who were recruited from an HMO primary care clinic waiting area. Participants were <b>classified,</b> using <b>screening</b> questionnaires and the revised Symptom Checklist 90, as 1) CSA-distressed, 2) distressed only, 3) CSA only, or 4) control participants. Medical utilization rates were generated from the computerized database of the HMO for 1) nonpsychiatric outpatient, 2) psychiatric outpatient, 3) emergency room (ER), and 4) inpatient admissions. Results: CSA-distressed and distressed only groups both used significantly more nonpsychiatric outpatient visits than CSA only and control participants but were not different from one another. CSA only and control participants did not differ on nonpsychiatric outpatient utilization. CSA-distressed participants used significantly more ER visits {{and were more likely}} to visit the ER for pain-related complaints than other participants. Among CSA-distressed participants, those who met criteria for physical abuse had significantly more ER visits than those who did not. There were no differences among the four groups in inpatient utilization rates. Conclusions: Psychological distress is associated with higher outpatient medical utili-zation, independent of CSA history. History of CSA with concomitant psychological distress is associated with significantly higher ER visits, particularly for those with a history of physical abuse. History of CSA without distress is not associated with elevated rates of medical utilization. Screening for psychological distress, CSA, and physical abuse may help to identify distinct subgroups with unique utilization patterns. Key words: sexual abuse, medical utilization, psychological distress, pain. CSA 5 child sexual abuse; ER 5 emergency room...|$|R
40|$|Background: Medicinal plants {{constitute}} a natural reservoir for medicines worldwide. They serve mainstream therapeutics and are central in folklore medicine. In case of Adenium obesum (Lav, Apocynaceae), indigenous people of Oman {{use it for}} the treatment of venereal diseases, wounds, skin diseases, headaches, muscle pain as well as joint pain; yet, the active ingredients have not been <b>classified.</b> To <b>screened</b> the antioxidant and antimicrobial activities of an identified compound that we isolated from the highest active chloroform extract. Methods: The antioxidant and antimicrobial activities of the extracts and the isolated compound were determined by diphenyl- 1 -picrylhydrazyl (DPPH) and disc diffusion methods. To characterize the compound, we used TLC, column, 1 H-NMR, 13 C-NMR, 2 D-NMR, IR and MS. Results: The highest antioxidant activity was found in chloroform extract with EC 50 value of 28. 32  μg/ml followed by water, methanol, butanol, ethyl acetate and hexane extracts, their IC 50 being 29. 95, 39. 17, 42. 40, 43. 20 and 57. 00  μg/ml respectively. All crude extracts and pure compound displayed moderate antimicrobial activity against one Gram positive Staphylococcus aureus and three Gram negative Escherichia coli, Pseudomonas aeruginosa and Proteus vulgaris within growth inhibition range of 0 – 13  mm. The active metabolite was identified as 3, 4 -dihydroxycinnamic acid (R) - 1 -carboxy- 2 -(3, 4 -dihydroxyphenyl) ethyl ester which is a common plant ingredient known as rosmarinic acid. Conclusion: The results indicate that walnut chloroform fraction may contain effective compounds with a broad spectrum of curative applications. This is the first report on isolation and characterization of a compound from chloroform crude extract of A. obesum...|$|R
40|$|Abstract Background Infections due to {{parasitic}} nematodes {{are common}} causes of morbidity and fatality {{around the world}} especially in developing nations. At present however, {{there are only three}} major classes of drugs for treating human nematode infections. Additionally the scientific knowledge on the mechanism of action and the reason for the resistance to these drugs is poorly understood. Commercial incentives to design drugs that are endemic to developing countries are limited therefore, virtual screening in academic settings can play a vital role is discovering novel drugs useful against neglected diseases. In this study we propose to build robust machine learning model to <b>classify</b> and <b>screen</b> compounds active against parasitic nematodes. Results A set of compounds active against parasitic nematodes were collated from various literature sources including PubChem while the inactive set was derived from DrugBank database. The support vector machine (SVM) algorithm was used for model development, and stratified ten-fold cross validation was used to evaluate the performance of each classifier. The best results were obtained using the radial basis function kernel. The SVM method achieved an accuracy of 81. 79 % on an independent test set. Using the model developed above, we were able to indentify novel compounds with potential anthelmintic activity. Conclusion In this study, we successfully present the SVM approach for predicting compounds active against parasitic nematodes which suggests the effectiveness of computational approaches for antiparasitic drug discovery. Although, the accuracy obtained is lower than the previously reported in a similar study but we believe that our model is more robust because we intentionally employed stringent criteria to select inactive dataset thus making it difficult for the model to classify compounds. The method presents an alternative approach to the existing traditional methods and may be useful for predicting hitherto novel anthelmintic compounds. </p...|$|R
40|$|Asia Mining Company {{produces}} feldspar {{and supplies}} to {{both domestic and}} overseas industries. Ore from the mine is crushed and ground and then <b>classified</b> by <b>screening.</b> That which is coarsely sized (+ 40 mesh) can be sold to the market, while that which is finely sized is left unsold due to the market requirement that size must be of - 40 + 140 mesh. This research designed and constructed a Vertical Air Classifier in which the fine mineral {{is fed to a}} vertical chamber while air is blown from the bottom. The main variables are air flow rates and the length of contact between the air and the mineral (at length of 10 and 15 cm). The air is blown in by air compressor and its rate is controlled by a thin plate orifice. Experiments show that the classifier can eliminate more of the size of - 140 mesh as the air flow rate increases. The % fractional recovery at the size of - 140 mesh is found to decrease as the air flow rate increases. The length of contact between the air and the mineral influences the elimination and the % fractional recovery as well. When the length is shorter (at 10 cm), the elimination of the size - 140 mesh is better and the % fractional recovery at the size - 140 mesh in the underflow is lower. At the air flow rate of 6. 42 L/S and the length of contact of 10 cm, the size of - 140 mesh can be reduced from 37. 11 % in the feed down to 17. 70 % in the underflow. The results demonstrate the potential of the Vertical Air Classifier to be further developed in eliminating the size - 140 mesh by connecting the classifiers in series...|$|R
40|$|AbstractBreast {{cancer is}} {{considered}} {{as the second}} leading cause of cancer deaths among women in the United States. Early detection of cancer is crucial {{in order to reduce}} its negative effects. Recently, magnetic resonance imaging (MRI) has become an important modality in the detection of breast cancer in daily practice. However, routine breast MRI has a moderate specificity that may increase its false positive rates. Therefore, automated detection techniques of malignancy can provide an important tool for clinicians. In this study, different data classification methods were examined to <b>classify</b> breast tumors <b>screened</b> using contrast enhanced MRI. The used data set included 20 subjects categorized clinically into two groups; benign and malignant tumors. MRI scans were first preprocessed to extract imaging features. Then two classification methods were exploited to differentiate between the two tumor's categories using the extracted features. The used classification methods were K-Nearest Neighbor (KNN), and Linear Discriminant Analysis (LDA). The results show a relatively significant classification accuracy compared with pathological analysis, and also the calculated resubstitution error. In summary, the proposed automatic classification techniques can be used as noninvasive diagnostic tools for breast cancer, with the capability of decreasing false positive errors associated with regular MRI diagnosis...|$|R
40|$|The {{impacts of}} {{emissions}} sources {{of carbon monoxide}} and particulate matter pollution levels for projected level conformity assessment and National Environmental Policy Act (NEPA) analyses are usually estimated through computer-aided models. Because of the involvement and interaction {{of a large number}} of variables that affect formation of CO and PM hot spots, exhaustive impact assessment studies can be time consuming. This is especially true for complex urban projects consisting of numerous roadways whose potential CO and PM impacts on surrounding neighborhoods must be disclosed. A highway project may consist of hundreds of roadway links, therefore undertaking project level conformity analysis without screening tools can be computationally resource intensive. CALINE 4, a line source emission modeling tool, is used to predict downwind CO and PM concentrations for various receptors to generate a learning dataset for development of screening rules. This research has developed statistical screening criteria based on Classification and Regression Tree modeling that can be used to eliminate those links from the CALINE 4 analysis whose contribution of pollutant concentration to a particular receptor site are insignificant. For the purpose of this study, any link that contributes a concentration of 0 ppm of CO or 0 µg/m 3 of PM to a particular receptor site is termed insignificant for the corresponding pollutant. The model uses seven predictor variables, namely wind speed, wind directional variability, linear emission flux, link length and receptor polar coordinates. Response vector has two classes of pollutant concentrations namely significant and insignificant which are obtained by conversion of numerical values of pollutant concentration according to above mentioned criterion, thereby converting a regression problem into categorical or classification problem. The developed rules based on constructed model were validated through test samples and can be applied to future dataset to <b>classify</b> and <b>screen</b> out the insignificant links in highway planning analyses. The screening tool also allows analysts to prepare gridded pollution concentration predictions for use in environmental justice analyses. M. S. Committee Chair: Guensler, Randall; Committee Member: Rodgers, Michael; Committee Member: Russell, Armistea...|$|R
