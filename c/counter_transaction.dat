1|34|Public
50|$|In February 2011 Putnam {{moved from}} the his {{position}} on the board to the acting CEO of Trumarx Data Partners in Chicago. TruMarx Data Partners developed and currently operates COMET. COMET is the community of energy transactors. Which is an ECN networking site connecting large bilateral non-standard over the <b>counter</b> <b>transaction</b> of natural gas and power transactors.|$|E
50|$|The {{interest}} earned in any bank account {{is subjected to}} a flat 10% retention as income tax. All debit transactions, including debit card transactions, credit card transactions, at the bank's teller <b>counter</b> <b>transactions</b> & online banking transactions are also subjected to a Government Duty of 0.2N$ per transaction.|$|R
50|$|OTC {{clearing}} {{refers to}} a process under which standardized derivative contracts which relate to over the <b>counter</b> <b>transactions</b> will be cleared through an agency established by a stock or commodities exchange. The idea is to avoid having the effect of financial shocks from being amplified through means not supervised by the agencies, to encourage transparency of the pricing of these standardized financial products, and to mitigate credit and default risks associated with over-the-counter trading.|$|R
50|$|This {{notational}} {{scheme is}} not strictly accurate, because the <b>transaction</b> <b>counter</b> is 21 bits, {{which is not}} an even multiple of 4 (the number of bits in a hex digit). Consequently, the <b>transaction</b> <b>counter</b> actually consumes one bit of the field that is the TRSM ID (in this example {{that means that the}} TRSM ID field can accommodate 2(5*4-1) devices, instead of 2(5*4), or about half a million).|$|R
50|$|The {{industry}} {{practice is}} to designate the partitioning {{as a series}} of three digits, indicating the number of hex digits used in each part: the Key Set ID, the TRSM ID, and the <b>transaction</b> <b>counter.</b> A common choice is '6-5-5', meaning that the first 6 hex digits of the KSN indicate the Key Set ID (i.e., which BDK is to be used), the next 5 are the TRSM ID (i.e. a device serial number within the range being initialized via a common BDK), and the last 5 are the <b>transaction</b> <b>counter.</b>|$|R
5000|$|An {{identifier}} {{known as}} the “Key Serial Number” (KSN) is returned from the encrypting device, along with the cryptogram. The KSN is formed from the device’s unique identifier, and an internal <b>transaction</b> <b>counter.</b>|$|R
50|$|Kent's {{department}} store was a fixture of downtown Bathurst and {{was well known}} for its use of a pneumatic tube cash system that was among the last {{to be used in}} Canada. Rather than having a cash register at every <b>counter,</b> all <b>transactions</b> were handled by a central cashier who took payments and returned change through a tube system that connected to all the departments on all three floors.|$|R
50|$|Honoré N. Razafindramiandra was {{a seminar}} on the Common Market in Brussels in 1962, in Milan in 1963 and in Naples in 1964. He was a {{full-time}} internship at the National Bank of Paris from October 1966 to June 1967 as bank <b>counter</b> cash <b>transaction</b> at Paris Nations, Extensions of credit in Aubervilliers, Foreign Trade in Ivry, Accounting in Melun. He was also {{a seminar on}} Management at the Embassy of the United States of America in 1972 in Antananarivo, Madagascar.|$|R
50|$|In {{practical}} applications, {{one would}} have several BDKs on record, possibly for different customers, or to contain the scope of key compromise. When processing transactions, {{it is important for}} the receiver to know which BDK was used to initialize the originating device. To achieve this, the 80-bit KSN is structured into three parts: as Key Set ID, a TRSM ID, and the <b>transaction</b> <b>counter.</b> The algorithm specifies that the <b>transaction</b> <b>counter</b> is 21-bits, but treats the remaining 59 bits opaquely (the algorithm only specifies that unused bits be 0-padded to a nibble boundary, and then 'f' padded to the 80-bit boundary). Because of this, the entity managing the creation of the DUKPT devices (typically a merchant acquirer) is free to subdivide the 59 bits according to their preference.|$|R
40|$|We {{propose a}} {{non-linear}} State Space representation to model ATM implied volatilities and {{to estimate the}} unobserved stochastic volatility for the underlying asset. We are able to estimate the average volatility risk premia and we can also address the presence of long memory in the unobserved volatility factor. We then applied our methodology to implied volatilities on currency options. These data arise from Over The <b>Counter</b> (OTC) <b>transactions</b> that account for high liquidity. We found that the likelihood function and all the iterative procedures associated with it converge uniformly in the parameter space at very little computational expense...|$|R
5000|$|An EMV {{smartcard}} {{contains a}} (typically 16-bit) <b>transaction</b> <b>counter</b> that is incremented with each payment or CAP transaction. The response displayed by a CAP reader essentially {{consists of the}} {{various parts of the}} card's response (Application <b>Transaction</b> <b>Counter,</b> MAC, etc.) which is then reduced to specific bits as determined by the Issuer Authentication Indicator (IAI) record stored in the card (this is set on a per-issuer basis, although should an issuer desire, it could be set randomly for each card providing a database of each card's IAI is kept), finally, after unwanted bits are discarded (essentially the absolute position of bits is irrelevant, a bit in the IAI that is 0 means the corresponding bit in the card response will be dropped rather than merely being set to 0). Finally the value is converted from binary into a decimal number and displayed to the user. A truncated example is provided below: ...|$|R
25|$|Causal Vector Engine (CVE) {{mechanics}} {{are implemented}} simply, with an expandable view of SQL constructs written in stored procedures. If A causes B, and causality must occur within N number of transactions, then SQL ORDER BY timestamp clause creates a result set that increments a <b>counter</b> of all <b>transactions</b> that occurred within a timeframe, N number of matching B to occurrence A transactions. The creation of additional stored procedures is accomplished through the CVE console application or by using any standard database developer's toolkit.|$|R
40|$|This paper overviews {{our study}} on various shared memory {{consistency}} models, Sequential Consistency (SC), Weak Consistency (WC), Release Consistency (RC), and Protected Release Consistency (PRC) models in Network-on-Chip (NoC) based Distributed Shared Memory (DSM) multi-core systems. These memory models are implemented {{by using a}} <b>transaction</b> <b>counter</b> (TC) based unified approach in the NoC based systems. The performance gain observed in the WC, RC and PRC relaxed memory models under various benchmarks is between 20 % and 50 % compared to the SC strict model. Q...|$|R
50|$|Causal Vector Engine (CVE) {{mechanics}} {{are implemented}} simply, with an expandable view of SQL constructs written in stored procedures. If A causes B, and causality must occur within N number of transactions, then SQL ORDER BY timestamp clause creates a result set that increments a <b>counter</b> of all <b>transactions</b> that occurred within a timeframe, N number of matching B to occurrence A transactions. The creation of additional stored procedures is accomplished through the CVE console application or by using any standard database developer's toolkit.|$|R
40|$|We {{propose a}} novel {{hardware}} support for three relaxed memory models, Release Consistency (RC), Partial Store Ordering (PSO) and Total Store Ordering (TSO) in Network-on-Chip (NoC) based distributed shared memory multicore systems. The RC model is realized {{by using a}} <b>Transaction</b> <b>Counter</b> and an Address Stack based approach while the PSO and TSO models are realized by using a Write <b>Transaction</b> <b>Counter</b> and a Write Address Stack based approach. In the experiments, we use a configurable platform based on a 2 D mesh NoC using deflection routing policy. The results show that under synthetic workloads, the average execution time for the RC, PSO and TSO models in 8 x 8 network (64 cores) is reduced by 35. 8 %, 22. 7 % and 16. 5 % respectively, over the Sequential Consistency (SC) model. The average speedup for the RC, PSO and TSO models in the 8 x 8 network under different application workloads is increased by 34. 3 %, 10. 6 % and 8. 9 %, respectively, over the SC model. The area cost for the TSO, PSO and RC models is increased by less than 2 % over the SC model at the interface to the processor. QC 20121016 </p...|$|R
40|$|Abstract—We {{propose a}} novel {{hardware}} support for three relaxed memory models, Release Consistency (RC), Partial Store Ordering (PSO) and Total Store Ordering (TSO) in Network-on-Chip (NoC) based distributed shared memory multicore systems. The RC model is realized {{by using a}} <b>Transaction</b> <b>Counter</b> and an Address Stack based approach while the PSO and TSO models are realized by using a Write <b>Transaction</b> <b>Counter</b> and a Write Address Stack based approach. In the experiments, we use a configurable platform based on a 2 D mesh NoC using deflection routing policy. The results show that under synthetic workloads, the average execution time for the RC, PSO and TSO models in 8 x 8 network (64 cores) is reduced by 35. 8 %, 22. 7 % and 16. 5 % respectively, over the Sequential Consistency (SC) model. The average speedup for the RC, PSO and TSO models in the 8 x 8 network under different application workloads is increased by 34. 3 %, 10. 6 % and 8. 9 %, respectively, over the SC model. The area cost for the TSO, PSO and RC models is increased by less than 2 % over the SC model at the interface to the processor. Keywords- Memory consistency; Release consistency; Scalability; Distributed shared memory; Network-on-Chip I...|$|R
40|$|The nonproliferation {{community}} is currently addressing {{concerns that the}} access to special nuclear materials may increase the illicit trafficking in weapons-usable materials from civil and/or weapons material stores and/or fuel cycles systems. Illicit nuclear traffic usually involves reduced quantities of nuclear materials perhaps as samplings of a potential protracted diversionary flow from sources to users. To <b>counter</b> illicit nuclear <b>transactions</b> requires the development of techniques and methods in nuclear material traceability as an important phase of a broad forensic analysis capability. This report discusses how isotopic signatures and correlation methods were applied to determine the origins of Highly Enriched Uranium (HEU) and Plutonium samples reported as illicit trafficking in nuclear materials...|$|R
50|$|The {{original}} CAP specification {{was designed}} to use normal EMV transactions, such that the CAP application could be deployed without updating the firmware of existing EMV cards if necessary. The preferred implementation uses a separate application for CAP transactions. The two applications may share certain data, such as PIN, while other data is not shared in instances where it {{is only applicable to}} one application (i.e., terminal risk management data for EMV) or advantages to have separate (i.e., <b>transaction</b> <b>counter,</b> so that EMV and CAP <b>transactions</b> increment separate <b>counters</b> which can be verified more accurately). The reader also carries implementation specific data, some of which may be overridden by values in the card. Therefore, CAP readers are generally not compatible with cards from differing issuing banks.|$|R
50|$|For systems {{based on}} {{contactless}} smartcards (e.g. public transportation), security against fraud relies on many components, {{of which the}} card is just one. Typically, to minimize costs, systems integrators will choose a relatively cheap card such as a MIFARE Classic and concentrate security efforts in the back office. Additional encryption on the card, <b>transaction</b> <b>counters,</b> and other methods known in cryptography are then employed to make cloned cards useless, {{or at least to}} enable the back office to detect a fraudulent card, and put it on a blacklist. Systems that work with online readers only (i.e., readers with a permanent link to the back office) are easier to protect than systems that have offline readers as well, for which real-time checks are not possible and blacklists cannot be updated as frequently.|$|R
50|$|The {{method for}} {{arriving}} at session keys is somewhat different on the originating side {{as it is}} on the receiving side. On the originating side, there is considerable state information retained between transactions, including a <b>transaction</b> <b>counter,</b> a serial number, and an array of up to 21 “Future Keys”. On the receiving side there is no state information retained; only the BDK is persistent across processing operations. This arrangement provides convenience to the receiver (a large number of devices may be serviced while only storing one key). It also provides some additional security with respect to the originator (PIN capture devices are often deployed in security-averse environments; the security parameters in the devices are ‘distant’ from the sensitive BDK, and if the device is compromised, other devices are not implicitly compromised).|$|R
40|$|Purpose – The {{purpose of}} this paper is to anlalyze the {{consequences}} of the “safe harbor” provisions of the US Bankruptcy Code that were enacted from 1984 through 2005 and that protect certain financial contracts from standard bankruptcy procedures. Design/methodology/approach – Qualitative methods are used to evaluate whether these provisions of the Bankruptcy Code were successful in their stated goal of reducing systemic risk in the financial system. A model of systemic risk is presented verbally in order to frame the discussion. Findings – Recent evidence indicates that the “safe harbor” provisions, in fact, destabilized the financial system by encouraging collateralized interbank lending, discouraging careful analysis of the credit risk of counterparties and increasing the risk that creditors will run on a financial firm. Practical implications – This paper indicates that the rewriting of the Bankruptcy Code to favor financial firms has had a profoundly destabilizing effect on the financial system. To put the financial system on more secure foundations, the author propose that large complex financial institutions be prohibited from posting collateral on over the <b>counter</b> derivative <b>transactions</b> and that the repo-related bankruptcy amendments passed in 2005 be repealed. Originality/value – This paper proposes an original framework for understanding systemic risk which drives the results in the paper. Bankruptcy, Bankruptcy law, Financial risk, United States of America...|$|R
40|$|Abstract—In Multicore Network-on-Chip, it is {{preferable}} to realize distributed but shared memory (DSM) in order to reuse the huge amount of legacy code. Within DSM systems, memory consistency is a critical issue since it affects not only performance but also the correctness of programs. In this paper, we investigate the scalability of the weak consistency model, which may be implemented using {{the concept of a}} <b>transaction</b> <b>counter.</b> Our experimental results compare synchronization latencies for various network sizes, topologies and lock positions in the network. Average synchronization latency rises exponentially for mesh and torus topologies as the network size grows. However, torus limits the synchronization latency in comparison to mesh. For mesh topology network average synchronization latency is also slightly affected by the lock position with respect to the network center. Keywords-Synchronization, Scalability, Memory consistency, Distributed shared memory...|$|R
5|$|Brick Bank (set number 10251) is the {{eleventh}} {{set in the}} Modular Building line and the fourth corner building. It was released on January 1, 2016. This set contains 2380 pieces. The Brick Bank features a bank, secretary’s office, bank manager’s office, laundromat and a detailed façade and sidewalk. The bank features an atrium foyer with wide, arched entrance, triangular-patterned floor tiling, ornate chandelier, oxidized-copper colored skylight, <b>transaction</b> <b>counter</b> with hidden alarm buttons and security glass, and a bank vault with safe deposit boxes and a large round door. The laundromat features a printed window, tiled floor and 4 laundry machines. The secretary’s office features a wall clock, desk, typewriter, cabinet with opening drawers, fireplace and an espresso machine. The bank manager’s office features a large desk with banker’s lamp and approval stamp, leather-look chair, printed portrait, statue and a cabinet. It includes 5 minifigures.|$|R
40|$|This paper studies {{realization}} of relaxed memory consistency {{models in the}} network-on-chip based distributed shared memory (DSM) multi-core systems. Within DSM systems, memory consistency is a critical issue since it affects not only the performance but also the correctness of programs. We investigate the scalability of the relaxed consistency models (weak, release consistency) implemented by using <b>transaction</b> <b>counters.</b> Our experimental results compare the average and maximum code, synchronization and data latencies of the two consistency models for various network sizes with regular mesh topologies. The observed latencies rise for both the consistency models as the network size grows. However, the scaling behaviors are different. With the release consistency model these latencies grow significantly slower than with the weak consistency due to better optimization potential by means of overlapping, reordering and program order relaxations. The release consistency improves the performance by 15. 6 % and 26. 5 % on average in the code and consistency latencies over the weak consistency model for the specific application, as the system grows from single core to 64 cores. The latency of data transactions grows 2. 2 times faster on the average with a weak consistency model than with a release consistency model when the system scales from single core to 64 cores...|$|R
40|$|Abstract—This paper {{studies the}} {{realization}} and scalability of release and protected release consistency models in Network-on-Chip (NoC) based Distributed Shared Memory (DSM) multi-core systems. The protected release consistency (PRC) model is proposed {{as an extension}} of the release consistency (RC) model and provides further relaxation in the shared memory operations. The realization schemes of RC and PRC models use a <b>transaction</b> <b>counter</b> in each node of the NoC based multi-core (McNoC) systems. Further, we study the scalability of these RC and PRC models and evaluate their performance in the McNoC platform. A configurable NoC based platform with 2 D mesh topology and deflection routing algorithm is used in the tests. We experiment both with synthetic and application workloads. The performance of the RC and PRC models are compared using sequential consistency (SC) as the baseline. The experiments show that the average code execution time for the PRC model in 8 x 8 network (64 cores) is reduced by 30. 5 % over SC, and by 6. 5 % over RC model. Average data execution time in the 8 x 8 network for the PRC model is reduced by almost 37 % over SC and by 8. 8 % over RC. The increase in area for the PRC of RC is about 880 gates in the network interface (1. 7 %). Keywords-Network-on-Chip; Distributed shared memory; Memory consistency; Protected release consistency; Scalability. I...|$|R
40|$|Abstract—We {{analyze the}} {{scalability}} of six memory consistency models in network-on-chip (NoC) -based distributed shared memory multicore systems: 1) protected release consistency (PRC); 2) release consistency (RC); 3) weak consistency (WC); 4) partial store ordering (PSO); 5) total store ordering (TSO); and 6) sequential consistency (SC). Their realizations {{are based on}} a <b>transaction</b> <b>counter</b> and an address-stack-based approach. The scalability analysis is based on different workloads mapped on various sizes of networks using different problem sizes. For the experiments, we use Nostrum NoC-based configurable multicore platform with a 2 -D mesh topology and a deflection routing algorithm. Under the synthetic workloads, the average execution time for the PRC, RC, WC, PSO, and TSO models in the 8 × 8 network (64 -cores) is reduced by 32. 3 %, 28. 3 %, 20. 1 %, 13. 8 %, and 9. 9 % over the SC model, respectively. For the application workloads, as the network size grows, the average execution time under these relaxed memory models decreases with respect to the SC model depending on the application and its match to the architecture. The performance improvement of the PRC and RC models over the SC model tends to be higher than 50 % as observed in the experiments, when the system is further scaled up. The area cost in the network interface for the relaxed memory models is increased by less than 4 % over the SC model. Index Terms—Distributed shared memory, memory consistency, network-on-chip, performance, scalability. I...|$|R
40|$|The present {{research}} concentrates on automation of retail process that involves customers. One can save on total {{man power required}} to manage a physical retail store and store tills if RFID at item level is implemented in a retail store. One can reduce number of persons at Security / Payment till required at store counter and exit. Although RFID can automate and reduce human errors at payment <b>counters.</b> A commercial <b>transaction</b> takes place the moment a customer (buyer) reaches the store exit gate. The proposed solution implemented will cut down operational cost for retail stores and a business can pass the benefit to customers. It will ease customer shopping by extending shopping hours in retail physical stores. The work that {{has been carried out}} to produce a conceptual system that implements and integrates a RFID based message system with existing transactional based E-commerce applications. The research conducts a comparative overview of the various technological frameworks, together with transaction and data transfer. The researched and the applied architecture for the proposed prototype system minimize changes on the existing applications and network design. The results of the experiment using a prototype are analyzed. The study concludes with the reviews and considers how the issues highlighted may be addressed in order to achieve an improved framework through discussing possible solutions. The prototype system has been successfully developed. With the prototype one can achieve objective of unattended store. The tests have demonstrated {{that it is possible to}} make such system with required security, reliability and scalability. ...|$|R
40|$|Degree of Bachelor of Science in Information Technology for Management StudiesPost Office Management System (POMS) is {{designed}} for automation of existing post office system in Kurunegala post office. Kurunegala Post Office has 12 counters such as parcel post <b>transaction</b> <b>counter,</b> registered letters counter, postage stamps selling counter, tele-mail counter etc. In existing system postal work is done through manual process which is a time taking process and data is not secure. Manual system {{we want to do}} lots of works and also want to most of users and manual things. So computerized system work is very easy and also effective than manual system. As the usage of technology is increasing in our daily life implementing Post Office Management System will be an easy task. Post Office Management System manages all the post office transaction details effectively. Users can easily retrieve, updated or saved the information whenever they want. Using Post Office Management System we can generate summery repots and log entry reports easily. System is developed according to the Waterfall Life Cycle Model and also addresses the Object Oriented Techniques. Unified Modeling Language was used to analyze and design the system properly. Visual Studio 2010 & ADO. net 4. 0 are used to implement the system in C# language with the help of Microsoft SQL Server 2008 R 2 Database server in the windows environment. Through achieving functional and nonfunctional requirements of the project, this system will give a smooth functioning procedure with user friendly environment. Hence I believe that the project work will engage a better and efficient working environment in post offic...|$|R
40|$|This Report assesses Observance of Standards and Codes on the Financial Action Task Force (FATF) Recommendations for Anti-Money Laundering and Combating the Financing of Terrorism (AML/CFT) for Serbia and Montenegro. The {{assessment}} {{reveals that}} the AML/CFT regime of Serbia still lacks some essential components. On the repressive side, {{there is not a}} specific provision on the financing of terrorism. It is possible to confiscate the proceeds of crime, but {{it is not possible to}} confiscate money intended to finance an act of terrorism. Serbia and Montenegro;Combating the financing of terrorism;Reports on the Observance of Standards and Codes;money laundering, terrorism, financing of terrorism, law enforcement, terrorist financing, terrorist, suspicious transactions, customer identification, suspicious transaction, enforcement powers, suspicious transaction report, integrity standards, law enforcement authorities, securities sectors, enforcement authorities, money laundering cases, act of terrorism, prudentially regulated sectors, supervisory authorities, financial intelligence unit, suspicious transaction reporting, money remitters, dual criminality, transaction reporting, narcotic drugs, business relations, suspicious transactions reporting, money laundering offence, customer identification requirements, legal assistance, competent authorities, terrorist assets, money laundering measures, financial investigations, illegal activity, money laundering activities, criminal justice, customer acceptance, predicate crime, enhanced diligence procedures, criminal justice measures, criminal offence, supervisory bodies, financial transactions, compliance officer, financial crime, terrorist activities, terrorist acts, due diligence, customer acceptance policies, internal procedures, international terrorism, exchange information, criminal investigations, customer identification information, anonymous accounts, acts of terrorism, criminal law enforcement, customer identity, customer accounts, alternative remittance, supervisory regimes, regulatory authorities, investigative techniques, foreign counterparts, precious metals, banking supervision, assessment methodology, suspicious transaction reports, professional secrecy, special procedures, complete originator information, transaction reports, risk customers, fictitious names, supervisory agencies, criminal law, international standards, insurance intermediaries, risk accounts, cyber crime, financial <b>transaction,</b> cash <b>transaction,</b> <b>countering</b> money laundering, counter terrorist financing, laundering activities, adequate screening procedures, share capital...|$|R
40|$|This paper {{studies the}} {{realization}} and scalability of release and protected release consistency models in Network-on-Chip (NoC) based Distributed Shared Memory (DSM) multi-core systems. The protected release consistency (PRC) model is proposed {{as an extension}} of the release consistency (RC) model and provides further relaxation in the shared memory operations. The realization schemes of RC and PRC models use a <b>transaction</b> <b>counter</b> in each node of the NoC based multi-core (McNoC) systems. Further, we study the scalability of these RC and PRC models and evaluate their performance in the McNoC platform. A configurable NoC based platform with 2 D mesh topology and deflection routing algorithm is used in the tests. We experiment both with synthetic and application workloads. The performance of the RC and PRC models are compared using sequential consistency (SC) as the baseline. The experiments show that the average code execution time for the PRC model in 8 x 8 network (64 cores) is reduced by 30. 5 % over SC, and by 6. 5 % over RC model. Average data execution time in the 8 x 8 network for the PRC model is reduced by almost 37 % over SC and by 8. 8 % over RC. The increase in area for the PRC of RC is about 880 gates in the network interface (1. 7 %). © 2011 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. QC 2012020...|$|R
40|$|The {{shared memory}} systems should support parallelization at the {{computation}} (multi-core), communication (Network-on-Chip, NoC) and memory architecture levels {{to exploit the}} potential performance benefits. These parallel systems supporting shared memory abstraction both in the general purpose and application specific domains are confronting the critical issue of memory consistency. The memory consistency issue arises due to the unconstrained memory operations {{which leads to the}} unexpected behavior of shared memory systems. The memory consistency models enforce ordering constraints on the memory operations for the expected behavior of the shared memory systems. The intuitive Sequential Consistency (SC) model enforces strict ordering constraints on the memory operations and does not take advantage of the system optimizations both in the hardware and software. Alternatively, the relaxed memory consistency models relax the ordering constraints on the memory operations and exploit these optimizations to enhance the system performance at the reasonable cost. The purpose of this thesis is twofold. First, the novel architecture supports are provided for the different memory consistency models like: SC, Total Store Ordering (TSO), Partial Store Ordering (PSO), Weak Consistency (WC), Release Consistency (RC) and Protected Release Consistency (PRC) in the NoC-based multi-core (McNoC) systems. The PRC model is proposed {{as an extension of the}} RC model which provides additional reordering and relaxation in the memory operations. Second, the scalability analysis of these memory consistency models is performed in the McNoC systems. The architecture supports for these different memory consistency models are provided in the McNoC platforms. Each configurable McNoC platform uses a packet-switched 2 -D mesh NoC with deflection routing policy, distributed shared memory (DSM), distributed locks and customized processor interface. The memory consistency models/protocols are implemented in the customized processor interfaces which are developed to integrate the processors with the rest of the system. The realization schemes for the memory consistency models are based on a <b>transaction</b> <b>counter</b> and an an an address ddress ddress ddress ddress ddress ddress stack tacktack-based based based based based based novel approaches. approaches. approaches. approaches. approaches. approaches. approaches. approaches. approaches. approaches. The <b>transaction</b> <b>counter</b> is used in each node of the network to keep track of the outstanding memory operations issued by a processor in the system. The address stack is used in each node of the network to keep track of the addresses of the outstanding memory operations issued by a processor in the system. These hardware structures are used in the processor interface to enforce the required global orders under these different memory consistency models. The realization scheme of the PRC model in addition also uses acquire counter for further classification of the data operations as unprotected and protected operations. The scalability analysis of these different memory consistency models is performed on the basis of different workloads which are developed and mapped on the various sized networks. The scalability study is conducted in the McNoC systems with 1 to 64 -cores with various applications using different problem sizes and traffic patterns. The performance metrics like execution time, performance, speedup, overhead and efficiency are evaluated as a function of the network size. The experiments are conducted both with the synthetic and application workloads. The experimental results under different application workloads show that the average execution time under the relaxed memory consistency models decreases relative to the SC model. The specific numbers are highly sensitive to the application and depend on how well it matches to the architectures. This study shows the performance improvement under the relaxed memory consistency models over the SC model that is dependent on the computation-to-communication ratio, traffic patterns, data-to-synchronization ratio and the problem size. The performance improvement of the PRC and RC models over the SC model tends to be higher than 50 % as observed in the experiments, when the system is further scaled up. QC 20130204 </p...|$|R
40|$|This paper {{describes}} a multiprocessor machine for realtime Digital Signal Processing that uses commercial programmable DSP chips. The architecture is a shared memory, single shared bus parallel processor designed to run signal processing tasks {{that can be}} statically scheduled. Compile time information inherent in such applications is used to constrain an order in which shared resources are accessed at run time. This leads to an efficient inter-processor communication mechanism and eliminates semaphore synchronization overhead. A proof-of-concept prototype of this architecture has been built. The implementation details and performance results are discussed in this paper. rate). Partitioned accross 4 processors, with 15 IPCs, we could fit in 28 voices. This example is not communication intensive; the low overhead IPC mechanism easily absorbs the extra cycles associated with IPC. 4. 3 QMF filter bank A filter bank was implemented to decompose audio from a CD player into 5 bands. The resynthesis bank was also implemented together with the decompostion part. This involved 16 multirate filters (18 taps each). There were 85 IPCs in the final schedule. 5 CONCLUSION We have presented the design and implementation of a multi-DSP architecture that acheives low overhead interprocessor communication with low hardware complexity. Program entry, scheduling and code generation for {{this can be done}} under the Ptolemy environment. Some applications have been run on the board. We plan to expand the existing I/O capability of the board by adding peripheral modules. This will enable us to evaluate the architecture under several other applications. Imposition of a single fixed order at run time means that no data dependency can be tolerated. To run non-SDF graphs on the OMA architecture, we use a presettable <b>counter</b> as the <b>transaction</b> controller. Any processor that has posession of the shared bus can make the transaction controller jump to another bus access schedule by presetting the schedule counter. Conditional branches can thus be handled by computing access schedules for each branch outcome and switching between them at run time. Compilation process for this scheme under the Ptolemy environment will be the subject of future research. We can the...|$|R
40|$|Objective – To {{investigate}} the current organizational models for reference work in Australian academic libraries, {{and how these}} reference services are staffed. Design – Mixed methods. Setting – Academic universities in Australia. Subjects – Forty Council of Australian University Librarians (CAUL) member libraries. Methods – A literature study was undertaken to (1) find a definition of reference services and (2) explore the development of reference service models over time. Statistics from the CAUL member libraries were studied for trends in student population and number of academic and library staff. A web‐based survey, with questions {{based on the findings}} in the literature study, was then distributed to the 40 Australian university libraries in 2006. Respondents were asked when the library commenced different reference services in five areas: formats in which the library received and responded to reference queries, information literacy, subject specialization, liaison activities, and collection development. Respondents also answered questions about the organization of the reference department, including: whether they had a separate or integrated model; the size of the reference collections; if they had a librarian dedicated to supporting students studying in remote or distant mode; if the interlibrary loans department was part of the suite of reference services; and if they had a mission or statement of purpose for their reference services department. Main Results – Based on the literature study, the working definition of reference services (1) for the project was “all activities which assist in providing relevant and appropriate information services to patrons” (270), including: •All interactions with patrons to assist them in their searches for information in all media types. •All training by librarians of patrons to be able to access information for themselves. •Activities to help the library stay informed of relevant developments, such as establishing and maintaining relationships with patrons. The literature study also revealed (2) a shift from the traditional reference service model, focused on the reference desk and the services delivered from that location, to new models involving “consolidation of reference service points, establishment of tiered reference, reference by appointment, reorganization of reference departments, and limiting services to primary users” (271). The core aspects of reference services have changed little over time, including face‐to‐face reference work, print collection development, bibliographic instruction, and attending meetings. In some aspects, however, there has been a shift in emphasis, e. g., in bibliographic instruction from the teaching of tools to the teaching of information literacy. In addition, reference work has come to include “going out to users,” or academic liaison work, as well as research consultation as a general way to assist undergraduate student in getting started on assignments and projects. The Web‐based survey (n= 40, response rate 87. 5 %) showed that 32. 4 % of libraries have an integrated inquiry point which incorporates information queries and other queries that are not necessarily related to traditional library reference services (272, Table 1). This survey result supports the findings of the literature study in showing a trend of library services moving away from the traditional reference desk. A majority of the responding libraries still retained a separate reference department, but a significant number of libraries have developed departments incorporating reference services with other library services. Those that retained the separate department varied in how they described services to patrons, the most common name being Information Services, a more user‐friendly and descriptive name. In staffing the reference service, the respondents were asked to indicate the classification level of their staff using the Higher Education Worker (HEW) scale (an Australian salary scale, based on competencies, minimum 1 / maximum 10). Staff spans a variety of levels (4 ‐ 10), the most common level being HEW 6, a level where all libraries had staff. This indicates that a large part of reference staff in Australian academic libraries are highly qualified. The shift in higher education, resulting in greater numbers of students and fewer staff (including librarians), has in many libraries resulted in a more flexible organization of reference services, and the utilization of staff from other sections of the library for manning the reference service point. There is also evidence of how the changing student population leads to changing demands for library facilities and services, e. g. a decrease in the traditional complex reference questions, as well as in over the <b>counter</b> loan <b>transactions,</b> and an increase in more general queries. Conclusion – Reference services in Australian academic libraries are becoming more flexible and integrated (although the definition for integrated is still unclear), in part as the result of client demand, and in part due to decreased funding. The author sees an emerging role for reference librarians in helping patrons to navigate the increasingly complex information environment, and to assist in developing the skills to critically evaluate the information they access for authoritativeness and appropriateness...|$|R
5000|$|Construction {{of the new}} {{bank was}} by {{contractor}} Mr Kelleher {{under the supervision of}} Eyre and Munro. It opened for business on Monday 13 May 1889, and was described as [...] "handsome and very pleasing, an imposing structure, superior to anything north of Brisbane" [...] and overshadowing the adjacent Bank of Australasia (no longer extant). While the Northern Miner newspaper reported the cost at £9,000, the bank's archives indicated £6,040. The new building was seen as the way forward in both structure and location. The inclusion of a commodious manager's private apartment was usual for regional banks.On the ground floor the building comprised banking chamber, fitted handsomely in polished cedar, {{the upper part of the}} various partitions being in ornamental ground glass...ample room for the public in front of the <b>counter</b> for the <b>transaction</b> of business, and a table... placed there for the accommodation of those who may desire to fill in deposit slips, requisitions for drafts, &c; a counter...14 ft long by 4ft 6 in x 1.4m wide, with the bill department on the right, and the exchange clerks' office on the left; ledger desks...placed at the back of the counter. To the left of the main entrance to the public hall is the manager's room, ...and opening out of that is the accountant's office... which has a raised floor, so that the official, by simply standing up, can get a good view of all that is going on. There is a passage leading from the manager's room to the dining-room, which, with the exception of the kitchen and servants' offices is the only one of the private apartments on the ground floor. At the rear of the ledger-desks are the strong room (fireproof), a lavatory and a stationery-room. Leaving the dining-room, we come to the private hall, which is approached from the passage to the left of the building. The upper floor is reached by a staircase from this hall...and contains a handsome drawing room...communicating by folding doors with another large room...which will be used by Mr Beattie for his own bedroom. There are three other bedrooms and a dressing room, all of large dimensions, with linen closet and a bathroom. The upper part of the building has a balcony running around three sides...and the internal passages are all proportionately spacious. The servants' quarters on the ground floor comprise kitchen, pantry, wash-house and sleeping apartment, and are furnished with the usual appurtenances for cooking and washing. Stabling has yet to be erected. Gas is laid on in every room and provision is made: for the Burdekin water supply when that scheme is complete. In the meantime there are three 1000 gallon litres tanks all full. The chimney-pieces and other fittings are in cedar, and are in excellent taste. All the rooms are ceiled, with mouldings, &c., of elegant design, and ventilation and drainage have been specially attended to.'An economic downturn occurred in 1888, during the construction of the bank, due to a decrease in overseas investment and a continuing drought which led to the closure of crushing machines due to lack of water. The slump was short-lived after the development of the Brilliant Reef, which when mined to a depth of 3000 feet (914 m), became the biggest producer in the field.|$|R

