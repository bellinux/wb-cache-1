23|1186|Public
5000|$|The angle(s) {{obtained}} {{during the}} inclining experiment {{are directly related}} to GM. By means of the inclining experiment, the 'as-built' centre of gravity can be found; obtaining GM and KM by experiment measurement (by means of pendulum swing measurements and draft readings), the centre of gravity KG can be found. So KM and GM become the known variables during inclining and KG is the wanted <b>calculated</b> <b>variable</b> (KG = KM-GM) ...|$|E
40|$|The delay {{fluctuations}} in earth stations {{have become the}} main source of instability that degrades the accuracy of two-way satellite time and frequency transfer. We had installed a satellite simulator system on an earth station for measuring the variations of signal path delays in the station. The {{purpose of this paper is}} to analyze delay variations associated with the environmental temperature. With the data collected over 2 months, we observed that the long-term and short-term temperature variations have contributed different influences to the measured delay value of the earth station. Hence, we propose a method to calculate the related variable by combining the temperature data, and its 1 st and 2 nd differential values with different weighting coefficients. The result shows a possibility of finding a high correlation between the <b>calculated</b> <b>variable</b> and the delay data. The <b>calculated</b> <b>variable</b> can be used to compensate the delay for their fluctuations...|$|E
40|$|Measured {{values of}} several {{variables}} {{are incorporated into}} the calculation of snow water equivalent as measured from an aircraft by snow attenuation of terrestrial gamma radiation. Bayesian decision theory provides a snow water equivalent measurement by {{taking into account the}} uncertainties in the individual measurement variables and filtering information about the measurement variables through prior notions of what the <b>calculated</b> <b>variable</b> (water equivalent) should be...|$|E
30|$|Microsoft Access 2010 {{was used}} to <b>calculate</b> <b>variables,</b> derived from NFI 2002 and NFI 2012, {{describing}} structural diversity of forests. For further analysis, the statistic software R (Version 3.1. 2) and its package beanplot was used for beanplots.|$|R
40|$|The {{problem in}} this {{research}} is less stud ents ekstrakulikuler soccer when doing heading. There are still many students {{who have not been}} able to control the ball in the air properly, it is seen when students do duel in the air, especially when heading a lot of non-directional ball that should be able to take advantage of heading to control the ball in the air to pocket the ball to a friend, and To score goals. This study aims to determine whether there is a correlation between back muscles and explosive muscle limb muscles with heading skill in the game of soccer on extracurricular soccer team SMAN 1 Sabak Auh. Sampling technique that is the total population (total sampling) extracurricular football team SMAN 1 auh berjumblah 17 people. This research uses correlation technique. Then, the test data using normality test, product test moment correlation, and test that L <b>calculate</b> <b>variable</b> X 1 = 0. 2011, L <b>calculate</b> <b>variable</b> X 2 = 02005 and L <b>calculate</b> <b>variable</b> Y = 0. 1330 where L table obtained 02060 (α = 0, 05), with So L calculate = 0. 2011 <L table 0. 2060 on variable X 1, L count 02005 <L table = 0. 2060 on the variable X 2 and L arithmetic = 0. 1330 <L table = 0. 2060 on variable Y, in other words it is concluded that X 1, X 2 and Y data are distributed normal...|$|R
30|$|<b>Calculating</b> machine <b>variable</b> {{and fixed}} costs in each periods and also {{workforce}} hiring cost.|$|R
40|$|Current {{recommended}} reference ranges for echocardiographic measurements may not {{be relevant}} to the diverse world population they are applied to. A new study, the echocardiographic normal reference ranges of the left heart (EchoNoRMAL) study, is an individual person data meta-analysis of standard echocardiographic measurements which aims to re-define normal reference ranges of left heart dimensions, areas, volumes, mitral inflow and tissue Doppler, and associated <b>calculated</b> <b>variable...</b>|$|E
40|$|This {{research}} {{studied the}} power generation trends from national grid and gas {{for a period}} of 4 years. Energy audit of critical systems like this is needful for optimal energy utilization. An energy audit was carried outon 6 industrial cooloing towers and their annual operating cost <b>calculated.</b> <b>Variable</b> speed drive suggested was installed and corresponding annual energy savings of 114, 900 kWh/year cost saving of RM 30, 000 was achieved at a case study plant located in Malaysia. Cooling towers with smart systems was recommended for higher energy savings...|$|E
40|$|We {{develop a}} new method for tagging jets {{produced}} by hadronically decaying top quarks. The method is an application of shower deconstruction, a maximum information approach that was previously applied to identifying jets produced by Higgs bosons that decay to bb¯. We tag an observed jet as a top jet based on a cut on a <b>calculated</b> <b>variable</b> χ that is an approximation to {{the ratio of the}} likelihood that a top jet would have the structure of the observed jet to the likelihood that a nontop QCD jet would have this structure. We find that the shower deconstruction based tagger can perform better in discriminating boosted top quark jets from QCD jets than other publicly available tagging algorithms...|$|E
40|$|A new {{updated version}} is {{available}} at [URL] This DAC cookbook is to include instructions for the DACs on how to <b>calculate</b> different <b>variables</b> for the Argo files. It is separate from other data manuals because users {{do not need to}} understand all these details, but that it is important that all DACs to be <b>calculating</b> the <b>variables</b> in the same manner...|$|R
40|$|Chapters include Six Levels of Greenhouse Cost Accounting; Using Spreadsheets as Cost Analysis Tools; Overhead or Fixed Costs; Square Foot Weeks: Applying Overhead Costs to the Greenhouse Production Area; Variable Costs: General Discussion; <b>Calculating</b> <b>Variable</b> Costs; Labor Costs; Calculating Costs of Propagation; Calculating Costs of Pest Management; Greenhouse Productivity; Comparing Crop Revenue; Square Foot Revenue Tables; Pricing and Square Foot Revenue Examples; Completing the Profitability Equation; Profitability in the Greenhouse Industry...|$|R
3000|$|<b>Calculate</b> other <b>variables</b> {{corresponding}} to constraints (31) and (32) and then calculate the objective function value by Eq. (30) [...]...|$|R
40|$|Aiming {{to obtain}} {{empirical}} {{models for the}} estimation of Syrah leaf area a set of 210 fruiting shoots was randomly collected during the 2013 growing season in an adult experimental vineyard, located in Lisbon, Portugal. Samples of 30 fruiting shoots were taken periodically from the stage of inflorescences visible to veraison (7 sampling dates). At the lab, from each shoot, primary and lateral leaves were separated and numbered according to node insertion. For each leaf, {{the length of the}} central and lateral veins was recorded and then the leaf area was measured by a leaf area meter. For single leaf area estimation the best statistical models uses as explanatory variable the sum of the lengths of the two lateral leaf veins. For the estimation of leaf area per shoot it was followed the approach of Lopes & Pinto (2005), based on 3 explanatory variables: number of primary leaves and area of the largest and smallest leaves. The best statistical model for estimation of primary leaf area per shoot uses a <b>calculated</b> <b>variable</b> obtained from the average of the largest and smallest primary leaf area multiplied by the number of primary leaves. For lateral leaf area estimation another model using the same type of <b>calculated</b> <b>variable</b> is also presented. All models explain a very high proportion of variability in leaf area. Our results confirm the already reported strong importance of the three measured variables (number of leaves and area of the largest and smallest leaf) as predictors of the shoot leaf area. The proposed models can be used to accurately predict Syrah primary and secondary leaf area per shoot in any phase of the growing cycle. They are inexpensive, practical, non-destructive methods which do not require specialized staff or expensive equipment...|$|E
40|$|The {{growth of}} wind and solar {{generation}} in the United States, and the expectation of continued growth of these technologies, dictates that the future power system will be operated in a somewhat different manner because of increased variability and uncertainty. A small number of balancing authorities have attempted to determine an 'integration cost' to account for these changes to their current operating practices. Some balancing authorities directly charge wind and solar generators for integration charges, whereas others add integration charges to projected costs {{of wind and}} solar in integrated resource plans or in competitive solicitations for generation. This report reviews the balancing authorities that have <b>calculated</b> <b>variable</b> generation integration charges and broadly compares and contrasts the methodologies they used to determine their specific integration charges. The report also profiles each balancing authority and how they derived wind and solar integration charges...|$|E
40|$|In {{this paper}} we explore a {{distributed}} application used to smooth traffic and reduce long term traffic incidents. To do this we use VGrid: an ad hoc networking and computing grid formed by leveraging inter-vehicle wireless communications. In addition to exchanging data between vehicles, VGrid actively uses pertinent data to perform computations for solving traffic-related problems. We examine the problem of smoothing vehicular traffic flow {{through the use of}} real-time position and velocity information exchanged over the network. This is accomplished through the application of 1) accident alert messages sent from the accident site or obstruction point and 2) dynamically <b>calculated</b> <b>variable</b> speed limit leveraging the available vehicular grid computing network. In order to evaluate these application we develop an extensive simulation tool which incorporates both a comprehensive network model and a realistic vehicle mobility model. Using this simulation tool we show that VGrid reduces vehicle speed variance, resulting in more homogeneous vehicle behavior in both freeflow and obstructed-lane scenarios. I...|$|E
30|$|Data {{preparation}} Data {{analysis is}} rarely performed {{directly on the}} whole dataset. Usually, datasets of interest are created for certain hypotheses, and erroneous or implausible data are removed from these sets. Furthermore, in medicine, very often changes or differences (functions on data values), rather than raw data, contain valuable information [4]. Consequently, {{it is necessary to}} define these desired functions on the data and make their results accessible to researchers/users as new <b>calculated</b> <b>variables.</b>|$|R
40|$|The {{abstract}} {{domain of}} polyhedra {{lies at the}} heart of many program analysis techniques. However, its operations can be expensive, precluding their application to polyhedra that involve many variables. This paper describes a new approach to computing polyhedral domain operations. The core of this approach is an algorithm to <b>calculate</b> <b>variable</b> elimination (projection) based on parametric linear programming. The algorithm enumerates only non-redundant inequalities of the projection space, hence permits anytime approximation of the output...|$|R
40|$|The caret package, {{short for}} {{classification}} and regression training, contains numerous tools for developing predictive models using the {{rich set of}} models available in R. The package focuses on simplifying model training and tuning across {{a wide variety of}} modeling techniques. It also includes methods for pre-processing training data, <b>calculating</b> <b>variable</b> importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models. ...|$|R
40|$|Urethral {{pressure}} profilometry (UPP) is used {{to investigate}} the pressure distribution in the urethra. Single UPP {{is dependent on the}} orientation of the catheter during the study. To circumvent this problem, we developed a system for multichannel profilometry (MCUPP) {{that can be used in}} daily clinical practice. In the study reported in this article, 29 healthy female volunteers (mean age 34. 6 years) underwent MCUPP. The mean time needed to make five pressure profiles ranged from 4 to 12 minutes (mean 7. 6). The system is patient- and user-friendly. The volunteers scored the discomfort on a 1 to 10 scale, with 10 meaning no discomfort at all, rendering a mean score of 7. 6. The Symmetry Index (SI) is a <b>calculated</b> <b>variable</b> expressing the asymmetry in the pressure profiles. An SI of 1 means a completely symmetrical pattern of pressure distribution. The mean SI for the whole group was 0. 7 (range 0. 407 - 0. 930). The standard deviation was 0. 109. Within-subject SI was highly reproducible (Greenhouse-Geisser epsilon = 0. 98292...|$|E
40|$|The {{interspecific}} {{competition between}} three container sharing mosquitoes was investigated to further understand the reasoning for ovipositing partitioning previously analyzed. Past {{studies have demonstrated}} distinct difference in larval use of containers between Aedes aegypti and Aedes polynesiensis, preferring artificial and natural containers, respectively. Additionally, Culex quinquefasciatus is present in both types of containers. It was hypothesized that this partitioning {{was the result of}} interspecific competition between the species. To analyze this, two treatments were conducted to induce competition; food limiting (between Ae. aegypti and Ae. polynesiensis) and space limiting (between all three species), with the emergence rates being the <b>calculated</b> <b>variable.</b> ANOVA tests revealed that when food is present, Ae. polynesiensis competes better interspecifically than intraspecifically, suggesting that competitive displacement occurs in natural containers. It was also found that a space limiting environment does not provide a statistical significant difference between the emergence times of Ae. aegypti, Ae. polynesiensis, and Cx. quinquefasciatus, providing that larval density does not induce competition between these three species and therefore cannot be used to analyze theories for ovipositing partitioning...|$|E
40|$|Sorption-induced {{strain and}} {{permeability}} were measured {{as a function}} of pore pressure using subbituminous coal from the Powder River basin of Wyoming, U. S. A. and high-volatile bituminous coal from the Uinta basin of Utah, U. S. A. We found that for these coal samples, cleat compressibility was not constant, but variable. <b>Calculated</b> <b>variable</b> cleat-compressibility constants were found to correlate well with previously published data for other coals. Sorption-induced matrix strain (shrinkage/swelling) was measured on uncon-strained samples for different gases: carbon dioxide, methane, and nitrogen. During permeability tests, sorption-induced matrix shrinkage was clearly demonstrated by higher perme-ability values at lower pore pressures while holding overbur-den pressure constant; this effect was more pronounced when gases with higher adsorption isotherms such as carbon dioxide were used. Measured permeability data were modeled using three different permeability models that take into account sorption-induced matrix strain. We found that when the measured strain data were applied, all three models poorly matched the measured permeability results. However, by ap-plying an experimentally derived expression to the strain data that accounts for the constraining stress of overburden pres-sure, pore pressure, coal type, and gas type; two of the models were greatly improved...|$|E
30|$|In this section, a {{comparison}} of selected principal traffic results in the Reference and Alternative scenarios is reported. Because all results depend on the random variables generated at the initial traffic and energy states, multiple replications of this experiment should be examined to observe, using statistical analysis, how the random effects influence the simulation results. However, to better show the traffic and energy performance of the implemented simulation model, through {{the reading of the}} <b>calculated</b> <b>variables</b> in identical conditions, the following results will focus on one selected replication that is close to the average value.|$|R
40|$|Abstract: The {{definition}} {{and implementation of}} control points for the Norma language is considered. The nonprocedural Norma language is a tool aimed for automated solution of the grid-oriented problems on parallel computer systems. This language eliminates the programming phase {{that is necessary to}} pass from computational formulas, derived by an application specialist, to a computer program. The control points may be used for writing the <b>calculated</b> <b>variables</b> during the calculation and then for the ability to start the calculations not from the begin of program, but from the last passed control point. Note: Publication language:russia...|$|R
40|$|This paper presentes a process-monitoring scheme utilising {{adaptive}} self-organising maps (SOM) {{to detect}} process conditions {{that lead to}} the fouling of a caliper sensor in a board machine. The scheme is based on mapping on a SOM the process measurements and the <b>calculated</b> <b>variables</b> which provide insight into the chemical phenomena involved in fouling to classify faulty process conditions. The time-variant nature of the board making process was taken into account by regularly re-training the SOM. The monitoring scheme is demonstrated with industrial data, and the results are presented and discussed. Peer reviewe...|$|R
40|$|Mestrado Vinifera Euromaster - Viticulture and Enology - Instituto Superior de Agronomia - UL / Institut National D'Etudes Superieures Agronomiques de MontpellierEstimating a Vineyard’s leaf area is {{of great}} {{importance}} when evaluating the productive and quality potential of a vineyard and for characterizing the light and thermal microenvironments of grapevine plants. The aim of the present work was to validate the Lopes and Pinto method for determining vineyard leaf area in the vineyards of Lisbon’s wine growing region in Portugal, with the typical local red grape cultivar Trincadeira, and to improve prediction quality by providing cultivar specific models. The presented models are based on independent datasets of two consecutive years 2015 and 2016. Fruiting shoots were collected and analyzed during all phenological stages. Primary leaf area of shoots is estimated by models using a <b>calculated</b> <b>variable</b> obtained from {{the average of the}} largest and smallest primary leaf area multiplied by the number of primary leaves, as presented by Lopes and Pinto (2005). Lateral Leaf area additionally uses the area of the biggest lateral leaf as predictor. Models based on Shoot length and shoot diameter and number of lateral leaves were tested as less laborious alternatives. Although very fast and easy to assess, models based on shoot length and diameter were not able to predict variability of lateral leaf area sufficiently and were susceptible to canopy management. The Lopes and Pinto method is able to explain a very high proportion of variability, both in primary and lateral leaf area, independently of the phenological stage, as well as before and after trimming. They are inexpensive, universal, practical, non-destructive methods which do not require specialized staff or expensive equipmentN/...|$|E
40|$|Strain {{caused by}} the {{adsorption}} of gases was measured in samples of subbituminous coal from the Powder River basin of Wyoming, U. S. A., and high-volatile bituminous coal from the Uinta-Piceance basin of Utah, U. S. A. using a newly developed strain measurement apparatus. The apparatus {{can be used to}} measure strain on multiple small coal samples based on the optical detection of the longitudinal strain. The swelling and shrinkage (strain) in the coal samples resulting from the adsorption of carbon dioxide, nitrogen, methane, helium, and a mixture of gases was measured. Sorption-induced strain processes were shown to be reversible and easily modeled with a Langmuir-type equation. Extended Langmuir theory was applied to satisfactorily model strain {{caused by the}} adsorption of gas mixtures using the pure gas Langmuir strain constants. The amount of time required to obtain accurate strain data was greatly reduced compared to other strain measurement methods. Sorption-induced changes in permeability were also measured as a function of pres-sure. Cleat compressibility was found to be variable, not constant. <b>Calculated</b> <b>variable</b> cleat-compressibility constants were found to correlate well with previously published data for other coals. During permeability tests, sorption-induced matrix shrinkage was clearly demonstrated by higher permeability values at lower pore pressures while holding overburden pressure constant. Measured permeability data were modeled using three dif-ferent permeability models from the open literature that take into account sorption-induced matrix strain. All three models poorly matched the measured permeability data because they overestimated the impact of measured sorption-induced strain on permeabil-ity. However, by applying an experimentally derived expression to the measured strain data that accounts for the confining overburden pressure, pore pressure, coal type, and gas type, the permeability models were significantly improved...|$|E
30|$|This paper aims {{to explore}} how {{differently}} corporate enterprises and social enterprises strategically position themselves through their mission statements. The most notable distinctions between the mission statements of both groups exist {{in the degree of}} action orientation, endorsements of people/groups, and the highlights of positive entailment. The new and renewable energy sector is playing {{a key role in the}} emergence of India as an environmentally conscious emerging economy. The enterprises instrumental in this change are both social and corporate enterprises. While technology is important, a key factor to success is strategic approach. The vision and mission statements are strategically crafted by organizations to position themselves in the industry. This motivated the authors to carry out a comparative analysis of the mission statements of social and corporate enterprises to learn about the existing differences. Efforts were employed to quantify the narrative style and tonality of mission statements by applying DICTION software. This process generated values for the ‘master variables’ and ‘calculated variables’ in mission statements. Content analysis revealed that while a significant number of enterprises scored zero for the <b>calculated</b> <b>variable</b> ‘insistence’, only a few had scores within range. Most enterprises scored considerably well in the master variable ‘activity’. In ‘optimism’ social and corporate enterprises show some noticeable differences in their purpose, which reflect how different these organizations are. This content analysis succeeds in reflecting where the social and corporate enterprises in India’s renewable energy sector differ in their strategic intent. While in renewable energy social enterprises there is a domination of reference to beneficiaries/communities in their mission statements, and the positive entailments in terms of social change; renewable energy corporate enterprises seem to have a stronger intent to focus on issues related to technology, innovation, efficiency, and cost-leadership. Thus, this paper not only adds to establishing the fact that mission statements do play an important role in reflecting the strategic purpose of the organization, but adds to the arguments on the difference between social and commercial entrepreneurship.|$|E
40|$|This paper {{tests the}} quality of {{calculated}} 2 D isovist variables as predictors of perceived landscape openness. An isovist is the calculated field of view from a given viewpoint in space. Three isovist variables were selected to estimate openness: the minimum radial, the maximum radial and the average radial. An experiment with 32 participants was conducted to compare values of these <b>calculated</b> <b>variables</b> with perceived openness. The comparison showed that two variables, the maximum radial and average radial, explained most of the variation of perceived openness for groups and individuals. The three <b>calculated</b> isovist <b>variables</b> were strongly correlated to their measured equivalents in the field, which were obtained with a binocular with a rangefinder. The isovist variables also showed strong correlations with their perceived equivalents obtained by {{the perception of the}} 32 participants, except at very long distances. This research shows that the selected isovist variables are good indicators for perceived landscape openness. (C) 2014 Elsevier B. V. All rights reserved...|$|R
30|$|Φ and U {{are both}} unknown {{variables}} in (24). Our strategy {{to solve this}} minimization problem is <b>calculating</b> one <b>variable</b> while the other is fixed and iterating this process until convergence appears.|$|R
40|$|Mansi and Reeb (2002) {{document}} that the coinsurance effect can fully explain the diversification discount. But their calculations of the excess value and diversification discount are problematic, making their conclusions unreliable. Using correctly <b>calculated</b> <b>variables,</b> a large diversification discount is found {{for both the}} full sample and the sub-sample of all-equity firms even after the coinsurance effect is controlled for. This paper also improves their model specification by using the interactive term of leverage and firm risk to capture the coinsurance effect. The {{results indicate that the}} coinsurance effect has limited power in explaining the diversification discount...|$|R
40|$|In {{order to}} {{determine}} the effects of seed burial and flooding depths on the emergence and seedling growth of watergrass (Echinochloa oryzoides) and barnyardgrass (E. crus-galli), this experiment was conducted in a covered free air condition, at the Rice Research Institute of Iran, Rasht in summer of 2009. The treatments included four seeding depths (0. 1 (seeds were mixed with the top soil), 2, 4 and 6 cm), and four flooding depths (0. 1 (saturated soil with no standing water), 3, 6, and 9 cm) arranged as a factorial arrangement in a randomized complete block design with three replications. After 28 days, number of emergent seedlings, weed seedlings height, root and shoot fresh weight, leaf and root area were measured, and emergence percentage and root/shoot ratio were calculated. Since no germination of seeds was observed at the 6 cm sowing depth, this treatment wasn’t presented in results. Measured or <b>calculated</b> <b>variable</b> per unit was significantly different between two species and between various levels of seed burial and flooding depths. These variables also influenced by the interactions of the mentioned factors with an exception of emergence percentage. Emergence percentage and growth characteristics except for plant height were higher in E. oryzoides than E. crus-galli when weed seeds were located in the depth of 0. 1 centimeter. In seeds located in the depth of 2 centimeters, all variables were higher in E. oryzoides than E. crus-galli. In both species, the higher values for mentioned variables was observed in the saturated condition of soil, when weed seeds were located at the depth of 0. 1 centimeter and reduced with increasing flooding and seed burial depth. Results indicated that flooding condition with adequate height caused major limiting effects on emergence, establishment and growth of two Echinochloa species, especially when the seeds were deeply buried; but at decreased height specially saturated soils, emergence and growth of E. oryzoides were significantly more than E. crus-galli...|$|E
40|$|We {{consider}} {{the problem of}} determining the cumulative distribution function and/or moments of the optimal solution value of a nonlinear program dependent upon a single random variable. This problem is difficult computationally because one must in effect determine the optimal solution to {{an infinite number of}} nonlinear programs. Bereanu [Bereanu, B., G. Peeters. 1970. A `Wait-and-See' problem in stochastic linear programming. An experimental computer code. Cashiers Centre Etudes Rech. Oper. 12 (3) 133 - 148. ] has provided an algorithm to solve the distribution problem in the linear case based on extensions of the methods of parametric linear programming. (See also [Bereanu, B. 1967. On stochastic linear programming, distribution problems: stochastic technology matrix. Z. f. Wahrscheinlichkeitstheorie u. oerw. Gerbieter 8 148 - 152; Bereanu, B. 1971. The distribution problem in stochastic linear programming: the Cartesian integration method. Center of Mathematical Statistics of the Academy of RSR, Bucharest, 71 - 103 (mimeographed); Bereanu, B. 1970. Renewal processes and some stochastic programming problems in economics. SIAM J. Appl. Math. 19 308 - 322; Bereanu, B. 1973. The Cartesian integration method in stochastic linear programming. L. Collatz, W. Wetterlink, eds. Numerische Methoden bei Optimierungsaufgaben. Springer-Verlag Publishing Co., Inc., Basel; Prekopa, A. 1966. On the probability distribution of the optimum of a random linear program. SIAM J. Control 4 211 - 222. ] for the analysis of more general linear programs.) This paper presents an extremely simple algorithm to solve the problem in the special case when all functions in the nonlinear program are homogeneous. In this instance the infinite class of optimal solutions are known linear homogeneous transformations of the optimal solution to a single nonlinear program. The distribution function may then be determined by substitution of an easily <b>calculated</b> <b>variable</b> into the distribution function of the random variable. The results are useful in the solution and analysis of a number of financial optimization problems. Problems from the analysis of optimal capital accumulation and portfolio separation are treated in some detail. ...|$|E
40|$|Chris M Kozma, 1 Michael Dickson, 2 Amy L Phillips, 3 Dennis M Meletiche 31 CK Consulting Associates, LLC St Helena Island, SC, 2 University of South Carolina College of Pharmacy, Columbia, SC, 3 EMD Serono Inc, Rockland, MA, USABackground: The {{purpose of}} this study was to compare two methods of {{adherence}} calculation using administrative data for patients with multiple sclerosis (MS) who are prescribed disease-modifying drugs. Methods: Pharmacy-billed disease-modifying drug prescription claims were selected from the 2007 – 2008 LifeLink™ Health Plan Claims Database. The index date was the first disease-modifying drug prescription claim. Two cohorts were created: all patients with a disease-modifying drug claim in 2007 and a subset with continuous eligibility for 12 months post-index. Adherence was calculated across all disease-modifying drugs for 12 months post-index. Medication possession ratios (MPRs) with variable (start to end of therapy) and fixed (365 days) duration denominators were <b>calculated.</b> <b>Variable</b> MPR was calculated by summing days supply from the first to the last prescription (inclusive) divided by time between the last prescription date plus days supply and the first prescription date. Variable MPR was evaluated for all patients and the continuously eligible cohort. Fixed MPR used the same numerator but divided by 365 days of follow-up and evaluated only for the continuously eligible cohort. Results: There were 3405 patients with MS and a disease-modifying drug claim in 2007 and 2145 in the continuously eligible cohort. Means for variable MPR ranged from 87. 5 % ± 16. 6 % for the continuously eligible cohort to 90. 5 % ± 16. 0 % for the 2007 cohort. The comparable value for fixed MPR was 78. 0 % ± 28. 2 % for the continuously eligible cohort. Fixed MPR gave a consistently lower rate of adherence than variable MPR at an 80 % adherence threshold. Conclusion: Different adherence measures can yield different outcomes, especially when using different eligibility criteria. These results demonstrate the importance of full disclosure of methods used for calculations and specification of the study population. Keywords: adherence, compliance, medication possession ratio, multiple sclerosis, disease-modifying dru...|$|E
40|$|The paper {{extends the}} {{contingent}} valuation framework of Black and Cox (1976) to value subordinated debt by explicitly incorporating bankruptcy {{costs in the}} model. I show that subordinated debt prices have “value added ” relative to equity. In fact, the joint use of equity and subordinated debt prices can provide information on magnitude of expected bankruptcy costs. Knowing the magnitude of expected bankruptcy costs is necessary for <b>calculating</b> <b>variables</b> underlying policy objectives. In particular, it is illustrated {{that the value of}} expected liability of a deposit insurer would be underestimates if the bankruptcy costs were not taken into account...|$|R
40|$|Studies in the microeconometric {{literature}} increasingly utilize {{distance to}} or {{time to reach}} markets or social services as determinants of economic issues. These studies typically use self-reported measures from survey data, often characterized by non-classical measurement error. This paper is the first validation study of access to markets data. New and unique data from Peru allow comparison of self-reported <b>variables</b> with scientifically <b>calculated</b> <b>variables.</b> We investigate the determinants of the deviation between imputed and self-reported data and show that it is non-classical and dependent on observable socio-economic variables. Our results suggest that studies using self-reported measures of access may be estimating biased effects. ...|$|R
50|$|The ESM is a {{microcomputer}} that {{records the}} absolute switching {{values of the}} primary controller and also measures the 'rate of change' of both {{the rise and fall}} of temperatures during the operating cycle of the compressors. With this data the ESM computes a reference heat load to match the cooling capacity and then <b>calculates</b> <b>variable</b> operating parameters. This calculation is used to minimise compressor operation within the absolute switching values, with a resultant reduction in refrigeration and air conditioning compressor run time, reduced electricity consumption (kWh) and maximum demand (kW/KVA). This is achieved while maintaining the original operating temperature.|$|R
