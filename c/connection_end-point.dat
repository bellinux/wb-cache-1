1|10|Public
40|$|The IEEE 802. 11 Wireless Local Area Network (WLAN) {{specifications}} {{have been}} the subject of increased attention due to their rapid commercial adaptation and the introduction of new security and privacy concerns. The IEEE 802. 1 x standard was introduced in order to overcome the initial security shortcomings of the Wired Equivalent Privacy (WEP) protocol. The IEEE 802. 1 x standard is an extensible standard that couples 802. 11 networks with various authentication services through the incorporation of an Extensible Authentication Protocol (EAP) authentication dialog. The existing implementations of EAP dialogs are based on standard cryptographic solutions for authentication and session key generation but do not, however, provide any form of user anonymity or privacy. Anonymity and privacy are currently of pressing interest, especially in the context of WLANs, which are simultaneously the best medium to provide privacy (there is no physical phone number or <b>connection</b> <b>end-point</b> with a predetermined owner) as well as the most threatening medium to user privacy, as they have the potential of disclosing not only the identity of the user, but also their physical location. At the same time, the potential "perfect hiding" capabilities of WLAN users also highlights the need to control anonymity by introducing more flexible authentication mechanisms. Moreover, payment for wireless services is completely decoupled from the above procedures, raising additional efficiency and privacy concerns. In this work we propose a new EAP authentication dialog based on anonymous electronic cash that provides for privacy, anonymity control, payment acceptance and billing, and authentication. Our solution is based on the notion of "public-key embedding e-cash," an e-cash variant we present and formalize [...] ...|$|E
5000|$|A TCP {{connection}} is managed by an operating system through a programming interface {{that represents the}} local end-point for communications, the Internet socket. During the lifetime of a TCP <b>connection</b> the local <b>end-point</b> undergoes a series of state changes: ...|$|R
40|$|We {{measured}} and analyzed {{the variability in}} round trip times (RTTs) within TCP connections using passive measurement techniques. We collected eight hours of bidirectional traces containing over ### million TCP <b>connections</b> between <b>end-points</b> at a large university campus and almost # million remote locations. Of these, we used over # million TCP connections that yield ### or more valid RTT samples, to examine RTT variability within a TCP connection. Our results indicate that contrary to observations in several previous studies, RTT values within a connection vary widely. Our results have implications for designing better simulation models, and understanding how round trip times affect the dynamic behavior and throughput of TCP connections...|$|R
40|$|We {{consider}} {{some aspects of}} quantum field theory of a conformally coupled scalar field on the singular background obtained in the massless limit of a class of toroidal black holes. The stress-tensor and its back-reaction on the metric are computed using the point-splitting regularization, {{in the cases of}} transparent, Neumann and Dirichlet boundary conditions. We find that the quantum fluctuations generate an event horizon which hides the singularity. The resulting object can be interpreted as a long lived remnant. We discuss the relevance of this result {{in the context of the}} cosmic censorship conjecture, and in <b>connection</b> to the <b>end-point</b> of the quantum evaporation process. Comment: 12 pages, RevTeX, no figures, corrected typo...|$|R
40|$|ABSTRACT. The {{principal}} {{results of}} this paper are the following theorems. If X is a homogeneous continuum which contains a local end-point, then X is hereditarily indecomposable or X admits a continuous decomposition whose every element is a proper nondegenerate homogeneous hereditarily indecomposable subcontinuum of X and the decomposition space is a homogeneous continuum with no local end-points. If a continuum X with property K belongs to classes F or C, then X contains a local end-point. Classes F and Cinclude all chainable, almost chainable, and circulady chainable continua (except solenoids) {{as well as some}} tree-like continua. A known classification of homogeneous circularly chainable continua is obtained as a corollary. Other <b>connections</b> between local <b>end-points,</b> property K, hereditarily indecomposable continua, and homogeneity or homogeneity with respect to open light mappings are established...|$|R
40|$|Emerging {{high speed}} Broadband Integrated Services Digital Networks (B-ISDN) will carry traffic for {{services}} such as video-on-demand and video teleconferencing, which require resource reservation along the path on which the traffic is sent. As a result, such networks will need effective admission control algorithms. The simplest approach is to use greedy admission control; in other words, accept every resource request that can be physically accommodated. However, non-greedy admission control can lead to better network performance in many situations. This thesis develops several non-greedy algorithms that out-perform greedy admission control algorithms. Some of the algorithms are evaluated using simulations while others are evaluated using the theory of competitive analysis. The thesis considers both unicast communication (<b>connections</b> with two <b>end-points)</b> and multicast communication (connection with more than two end-points). The results of the thesis have already had a direct influence on the algorithms used in several commercial networks...|$|R
40|$|Modern {{consumer}} devices, like smartphones and tablets, {{have multiple}} interfaces (e. g., WiFi and 3 G) that attach to new access points as users move. These mobile, multi-homed computers are a poor match with an Internet architecture that binds <b>connections</b> to fixed <b>end-points</b> with topology- dependent addresses. As a result, hosts typically cannot spread a connection over multiple interfaces or paths, or change locations without breaking existing connections. In this paper, we introduce ECCP, an end-host connection control protocol that allows hosts to communicate over mul- tiple interfaces with dynamically-changing IP addresses. Each ECCP connection consists {{of one or}} more flows, each associated with an interface or path. A host can move an existing flow from one interface to another or change the IP address using in-band signaling, without any support from the underlying network. We use formal models to verify that ECCP works correctly in the presence of packet loss, out-of-order delivery, and frequent mobility, and to identify bugs and design limitations in earlier mobility protocols...|$|R
40|$|Abstract—Modern {{consumer}} devices, like smartphones and tablets, {{have multiple}} interfaces (e. g., WiFi and 3 G) that attach to new access points as users move. These mobile, multi-homed computers are a poor match with an Internet architecture that binds <b>connections</b> to fixed <b>end-points</b> with topology-dependent addresses. As a result, hosts typically cannot spread a connection over multiple interfaces or paths, or change locations without breaking existing connections. In this paper, we introduce ECCP, an end-host connection control protocol that allows hosts to communicate over multiple interfaces with dynamically-changing IP addresses. Each ECCP connection consists {{of one or}} more flows, each associated with an interface or path. A host can move an existing flow from one interface to another or change the IP address using in-band signaling, without any support from the underlying network. We use formal models to verify that ECCP works correctly in the presence of packet loss, out-of-order delivery, and frequent mobility, and to identify bugs and design limitations in earlier mobility protocols. Index Terms—migration; mobile devices; network architec-ture; in-band signaling; formal methods; I...|$|R
40|$|In today’s lecture, we {{discussed}} multicast protocols. The desirable {{features of a}} multicast protocol were described, and two protocols were considered. 3. 1 Multicast vs. Unicast Multicast allows the server to only transmit a message (destined for multiple users) once, instead of establishing an independent <b>connection</b> with each <b>end-point.</b> It outperforms unicast because it saves server load and diminishes network traffic. However, there are serious problems/challenges with implementing multicast because the paradigm on which networks are built is that the end-points are “smart ” while the internal routing devices are “dumb. ” To reliably and efficiently deliver every packet to every destination is difficult, and {{requires a lot of}} feedback and coordination among the routers. Today there is no reliable IP multicast, but P 2 P approximations exist where the message is first delivered to a number of end-points, which resend it to their neighbors. 3. 2 An Ideal Solution As described in [1], an ideal solution should satisfy the following requirements: • scalability (solution works just as well when the number of receivers, size of network, size of file increase) • reliability (message is delivered in its entirety without errors) • reception-efficiency (the amount of redundant data for the receiver is minimized) • time-efficiency (the amount of time needed for the receiver to reconstruct the message is minimized) • time-independence (as far as the receiver is concerned, it does not matter when it wants the file) • server-independence (the state of the network is irrelevant to the server) • tolerance (of heterogeneity of network: different bandwidth, latency and loss-rate at different end-points...|$|R
40|$|Although {{the birth}} of Precedence Diagramming Method (PDM) is not as radiant as of CPM or PERT, but it is {{definitely}} the prevailing scheduling technique of our times. This popularity is due to its modeling flexibility over other techniques and the easy-to-understand mathematical model behind the technique. However, even this technique has its own limitations; modeling overlapping activities in a proper way {{seems to be a}} never-ending debate. The reason of this {{can be found in the}} fundamentals of PDM technique; the four precedence relationships that form <b>connections</b> between the <b>end-points</b> of the activities, with constant production speed. These fundamentals of PDM have their own consequences to scheduling practice; it is more and more apparent among professionals that activity overlapping in PDM cannot be modeled adequately. Different solutions were proposed for solving this problem from the application of negative lag, through the combination of SS and FF relations to the fragmentation of activities. All these solutions have their shortcomings. Probably the fragmentation technique has led to the development of point-to-point type of relation that can connect any arbitrary points of the dependent activities. The objective of this paper is to analyze the pros and cons of different solutions that are used for modeling overlapped activities, then to show how newly defined point-to-point relations can be used for this purpose. Algorithms that handles point-to-point relations with minimal and maximal lags are also presented. The main finding of the paper is that newly developed point-topoint relations are better from theoretical and practical point of view than the solutions based on traditional precedence relationships, but they still cannot provide theoretically perfect solution for overlapping. This paper is the fully extended version of a paper building on the results already presented on the Creative Construction Conference [1]...|$|R
40|$|In {{the last}} 15 years, the {{adoption}} of enterprise level data networks had increased dramatically. This is mainly due to reasons, such as better use of IT resources, and even better coordination between departments and business units. These great demands have fuelled the push for better and faster connectivity to and from these networks, and even within the networks. We have moved from the slow 10 Mbps to 1 Gbps connectivity for <b>end-point</b> <b>connections</b> and moved from copper-based ISDN to fibre-linked connections for enterprise connections to the Internet. We now even include wireless network technologies in the mix, because of the greater convenience it offers. Such rapid progress is accompanied by ramifications, especially if not all aspects of networking technologies are improved linearly. Since the 1960 s and 1970 s, the only form of security had been {{along the line of}} authentication and authorisation. This is because of the widely used mainframes in that era. When the Internet and, ultimately, the wide-spread use of the Internet influxed in the 1980 s, network security was born, and {{it was not until the}} late 1980 s that saw the first Internet Worm that caused damage to information and systems on the Internet. Fast forward to today, and we see that although we have come a long way in terms of connectivity (connect to anywhere, and anytime, from anywhere else), the proposed use of network security and network security methods have not improved very much. Microsoft Windows XP recently switched from using their own authentication method, to the use of Kerberos, which was last revised 10 years ago. This thesis describes the many problems we face in the world of network security today, and proposes several new methods for future implementation, and to a certain extend, modification to current standards to encompass future developments. Discussion will include a proposed overview of what a secure network architecture should include, and this will lead into several aspects that can be improved on. All problems identified in this thesis have proposed solutions, except for one. The critical flaw found in the standard IEEE 802. 11 wireless technology was discovered during the course of this research. This flaw is explained and covered in great detail, and also, an explanation is given as to why this critical flaw is not fixable...|$|R

