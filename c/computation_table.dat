1|118|Public
40|$|In the {{execution}} of signature on a smart card, side channel attacks such as simple power analysis (SPA) have become serious threat. There are the fixed procedure method and the indistinguishable method for SPA resistant methods. The indistinguishable method conceals all branch instructions by using indistinguishable addition formulae but may reveal the hamming-weight when an addition chain with the un-fixed-hamming-weight is used. In the case of hyper-elliptic curve, the indistinguishable method has not been proposed yet. In this paper, we give an indistinguishable addition formulae of hyper-elliptic curve. We also give algorithms which output the fixed-hamming-weight representation for indistinguishable addition formulae and works with or without <b>computation</b> <b>table,</b> which can dissolve the above mentioned problem on the indistinguishable method and are also applied to an elliptic curve scalar multiplication...|$|E
50|$|Mathematical {{tables are}} lists of numbers showing {{the results of}} {{calculation}} with varying arguments, before calculators were cheap and plentiful, people would use such tables to simplify and drastically speed up <b>computation.</b> <b>Tables</b> of logarithms and trigonometric functions were common {{in math and science}} textbooks. Specialized tables were published for applications such as astronomy, celestial navigation and statistics.|$|R
25|$|In {{the days}} before calculators, people would use {{mathematical}} tableslists of numbers showing the results of calculation with varying argumentsto simplify and speed up <b>computation.</b> <b>Tables</b> of logarithms and trigonometric functions were common {{in math and science}} textbooks. Specialized tables were published for applications such as astronomy, celestial navigation and statistics. Methods of numerical approximation existed, called prosthaphaeresis, that offered shortcuts around time-consuming operations such as multiplication and taking powers and roots. Astronomers, especially, were concerned with methods that could speed up the long series of computations involved in celestial mechanics calculations.|$|R
5000|$|<b>Computations</b> or <b>tables</b> of the Wilks' {{distribution}} for higher dimensions are {{not readily available}} and one usually resorts to approximations.One approximation is attributed to M. S. Bartlett and works for m allows Wilks's lambda to be approximated with a chi-squared distribution ...|$|R
30|$|The <b>computations</b> {{summarized}} in <b>Table</b> 2 {{suggest that the}} error (88) decreases to 0 as ρ increases to +∞.|$|R
5000|$|Magma has {{extensive}} {{tools for}} computing in representation theory, including the <b>computation</b> of character <b>tables</b> of finite {{groups and the}} Meataxe algorithm.|$|R
40|$|Abstract — This paper {{develops}} a general, theoretical computational model for discussing synchronization and specification scheme. We analyze {{the domains of}} relationships between agents in a coordination system. A set of algorithms is proposed to derive reasonable relations between agents. Possible conflicts in the agent specification are firstly detected and eliminated. The mechanism constructs partial order relations among actions. We also propose a temporal algebra to deal with qualitative and quantitative temporal relationships and to reason about definite and indefinite time. The algebra can also integrate instant points and even intervals. Several <b>computation</b> <b>tables</b> are proposed, and each table include a set of complete logics. The mechanism is efficiently to eliminate conflict specification and to generate synchronization scenarios. The contributions of this paper are using the generic relationship framework to handle synchronization specifications, and to eliminate conflicts {{in order to satisfy}} agent request...|$|R
40|$|Memoisation, or tabling, is a {{well-known}} technique that yields large improvements {{in the performance of}} some recursive <b>computations.</b> <b>Tabled</b> resolution in Prologs such as XSB and B-Prolog can transform so called left-recursive predicates from non-terminating computations into finite and well-behaved ones. In the functional programming literature, memoisation has usually been implemented {{in a way that does}} not handle left-recursion, requiring supplementary mechanisms to prevent non-termination. A notable exception is Johnson's (1995) continuation passing approach in Scheme. This, however, relies on mutation of a memo table data structure and coding in explicit continuation passing style. We show how Johnson's approach can be implemented purely functionally in a modern, strongly typed functional language (OCaml), presented via a monadic interface that hides the implementation details, yet providing a way to return a compact represention of the memo tables at the end of the computation...|$|R
5|$|More recent models {{attempt to}} model bubble dynamics, also usually by {{simplified}} models, {{to facilitate the}} <b>computation</b> of <b>tables,</b> and later to allow real time predictions during a dive. Models that approximate bubble dynamics are varied. They range from {{those that are not}} much more complex than the dissolved phase models, to those that require considerably greater computational power.|$|R
40|$|This paper investigates {{how people}} build interpretations of {{compound}} mathematical expressions {{in a novel}} formal system. In traditional arithmetic, interpretations are guided by an order of precedence convention (times and division precede addition and subtraction). This order {{is supported by a}} spatial convention that supports the order of precedence. In the experiment described here, participants learned <b>computation</b> <b>tables</b> of two simple novel operators, and then were asked to discover a precedence rule. The operators were presented with a physical spacing convention that either aligned with the precedence order, opposed it, or randomly opposed or aligned with the precedence order. Participants were more likely to reach a criterion of successful performance when the order of operations aligned with the precedence order, and did so more quickly than either other group. The results indicate that reasoners integrate salient perceptual cues with formal knowledge following familiar conventions, even on novel systems...|$|R
25|$|More recent models {{attempt to}} model bubble dynamics, also by {{simplified}} models, {{to facilitate the}} <b>computation</b> of <b>tables,</b> and later to allow real time predictions during a dive. The models used to approximate bubble dynamics are varied, and range from those which are not much more complex that the dissolved phase models, to those which require considerably greater computational power.|$|R
40|$|<b>Computation</b> Look-up <b>tables</b> and {{matrix of}} cross-tabulations Factors Classification schema or {{decision}} tree Parameters Thematic spatial data and regional statistics directly or as proxy The {{evaluation of the}} requirements of the IPCC Tier 1 method starts with the results to determine the information needs. When estimating C-stock changes the processing steps advance in the inverse direction. Factor type G r...|$|R
50|$|More recent models {{attempt to}} model bubble dynamics, also by {{simplified}} models, {{to facilitate the}} <b>computation</b> of <b>tables,</b> and later to allow real time predictions during a dive. The models used to approximate bubble dynamics are varied, and range from those which are not much more complex that the dissolved phase models, to those which require considerably greater computational power.|$|R
40|$|Emission {{generated}} by the bow shock formed around the ATV as it re-enters the Earth’s atmosphere is estimated using a two-step procedure. First, the flow field formed {{in front of the}} cylindrical face of the vehicle, that has a radius of 2. 25 m, is computed using one of two techniques: (1) the continuum Navier-Stokes equations are solved using computational fluid dynamics (CFD) [1] at lower altitudes of 50 and 75 km; and (2) the particle-based direct simulation Monte Carlo (DSMC) method [2] is used at the higher altitudes (100 and 125 km). All flow field computations include thermal and chemical nonequilibrium. The freestream flow conditions employed are shown in Table 1. The speeds at given altitudes were calculated by H. Klinkrad (ESA/ESOC) in early June of 2008, from the SCARAB fragmentation model as applied to ATV. The vehicle wall temperatures are calculated iteratively in the DSMC simulations using the assumption of radiative equilibrium, and a maximum wall temperature of 900 K (equal to the melting point of aluminum) is employed in both CFD <b>computations.</b> <b>Table</b> 1 : Freestream flow conditions for ATV re-entry...|$|R
40|$|Sieberg) along a 40 km {{stretch of}} the Adriatic coast between Pesaro and Ancona, cen-tered on the town of Senigallia. This area is {{characterized}} by relatively infrequent and moderate-sized earthquakes and by elusive active faults. In spite {{of the presence of}} well-known northwest–southeast-trending, northeast-verging fault-propagation folds forming the outer thrusts of the Apennines, the current level of activity, and the kinematics of these coastal structures are still controversial. We present a multidisciplinary analysis of the source of the 30 October 1930 Se-nigallia earthquake, combining instrumental and macroseismic data and elaborations with available evidence from geological and tectonic investigations. We determine the main seismic parameters of the source, including the earthquake location, its magni-tude, and, for the first time, its focal mechanism, providing the first instrumental evidence for thrust faulting along the northern Marche coastal belt. Our findings provide conclusive evidence for the current activity of the northern Marche coastal thrusts. As such they have significant implications for the seismic hazard of the area, a densely populated region that hosts historical heritage, tourism facilities, industrial districts, and key transportation infrastructures. Online Material: Description of method used for moment tensor <b>computation,</b> <b>tables</b> of focal mechanisms and recording stations, and figures of seismic flux and uncertainty maps for macroseismic epicenters...|$|R
5000|$|... 1966: Zdenek Sekera for his {{numerous}} {{contributions to}} {{the dynamics of the}} atmosphere, which comprise studies of waves at interfaces, of the dynamics of the atmospheric jet stream, and especially of the brightness and polarization of sky light in a scattering atmosphere which led to the extension and application of Chandrasekhar's general theory of radiative transfer to atmospheric problems. This work led to the <b>computation</b> of <b>tables</b> by Sekera and his coworkers. With the publication of these tables, in Chandrasekhar's words, 'The problem that was formulated by Rayleigh in 1871 has now at last found its complete solution.' ...|$|R
50|$|Classes of human-based <b>computation</b> {{from this}} <b>table</b> can be {{referred}} by two-letter abbreviations: HC, CH, HH. Here {{the first letter}} identifies the type of agents performing innovation, the second letter specifies the type of selection agents. In some implementations (wiki {{is the most common}} example), human-based selection functionality might be limited, it can be shown with small h.|$|R
40|$|The paper {{describes}} a conceptual model of ferromagnetic behaviour which, al tough {{not based on}} physical grounds, becomes a useful "thinking device" for developing a <b>computation</b> algorithm sui <b>table</b> for being coupled to a general electromagnetic trans ients simulati on programme such as EMTP. A simple example is presented to show how this algorithm works in practice...|$|R
40|$|Abstract: Waveform {{tables are}} an {{important}} tool for synthesizing sound, but they introduce error which results in noise. Error {{is affected by the}} spectrum of the signal stored in the table. Error is reduced by increasing the table size and/or by increasing the quality of interpolation. Both of these also affect the signal <b>computation</b> cost. <b>Table</b> sizes required for a given signal-to-noise ratio are computed for different interpolation methods and spectral rolloffs. Execution times are then evaluated. Non-interpolated oscillators perform the best, but only if the storage and computation costs of the tables are not an issue. This and other tradeoffs are discussed. 1...|$|R
40|$|We {{introduce}} {{just enough}} tabling (JET), {{a mechanism to}} suspend and resume the tabled execution of logic programs at an arbitrary point. In particular, JET allows pruning of tabled logic programs to be performed without resorting to any recomputation. We discuss issues {{that are involved in}} supporting pruning in tabled resolution, how re-execution of <b>tabled</b> <b>computations</b> which were previously prune...|$|R
5000|$|In 1928 L.J. Comrie was {{the first}} to turn IBM “punched-card {{equipment}} to scientific use: <b>computation</b> of astronomical <b>tables</b> by the method of finite differences, as envisioned by Babbage 100 years earlier for his Difference Engine”. Very soon after, IBM started to modify its tabulators to facilitate this kind of computation. One of these tabulators, built in 1931, was The Columbia Difference Tabulator ...|$|R
5000|$|The {{following}} example {{defines a}} syntax extension of OCaml. It provides a new keyword, , {{which can be}} used as a replacement for [...] and provides automatic memoization of functions with pattern matching. Memoization consists in storing the results of previous <b>computations</b> in a <b>table</b> so that the actual computation of the function for each possible argument occurs at most once.|$|R
40|$|The {{exponential}} growth of Internet traffic requires that routers be scalable. A generic scalable IP router is typically {{composed of a}} number of routing nodes (RNs) interconnected by a scalable switching fabric. A critical issue in the design of scalable IP routers is to provide a global and consistent routing table in such distributed-memory architectures. A parallel routing <b>table</b> <b>computation</b> approach is proposed in this paper. By dividing an OSPF area into a number of disjoint Within-Area-Routing-Regions (WARRs), the computation required to calculate the routing table can be divided into multiple independent portions and done by different RNs in parallel. Compared to conventional approaches, this approach can have a speedup between n and n 2 for within-area link state updates and n for outside-area link state updates, where n is the number of RNs in the router. This parallel routing <b>table</b> <b>computation</b> approach requires no modification of OSPF. 1. Introduction The Inte [...] ...|$|R
40|$|Prepared by the 'Project for the {{computation}} {{of mathematical}} tables' sponsored by Dr. Lyman J. Briggs, {{director of the}} National bureau of standards, Washington, D. C., and {{under the auspices of}} the U. S. Works progress administration of New York city. " [...] Pref. Mimeographed. Each section and introduction preceded by half-title not included in the paging. On cover: [...] . Project for the <b>Computation</b> of mathematical <b>tables.</b> Mode of access: Internet...|$|R
40|$|The {{character}} {{theory of}} finite quasigroups, introduced in [4] and [5], is developed further. The Quotient Theorem relates the character theory of a quasigroup {{to that of}} its homomorphic images. The Fusion Theorem relates the character theories of different quasigroup structures on the same set. Fusion geometry interprets certain character values as solutions of optimization problems. Magic rectangle conditions impose additional constraints that facilitate the <b>computation</b> of character <b>tables...</b>|$|R
40|$|Dixon's {{algorithm}} for the <b>computation</b> {{of character}} <b>tables</b> faces two problems—it requires the computation of complete class matrices, and many such class matrices will often {{turn out to}} yield no new information. This paper describes a method for overcoming these difficulties. In addition, an algorithm is presented that has a high probability of determining the two characters that span a two-dimensional character space {{without the need for}} computing an additional class matrix...|$|R
40|$|We {{describe}} the <b>computation</b> of extended <b>tables</b> of degree 8 fields with a quartic subfield, using class field theory. In particular {{we find the}} minimum discriminants for all signatures {{and for all the}} possible Galois groups. We also discuss some phenomena and statistics discovered while making the tables, such as the occurrence of 11 non-isomorphic number fields having the same discriminant, or several pairs of non-isomorphic number fields having the same Dedekind zeta function...|$|R
40|$|Tabling in logic {{programming}} {{has been used}} to eliminate redundant computation and also to stop infinite loop. In this paper we add the third usage of tabling, i. e. to make infinite computation possible for probabilistic logic programs. Using PRISM, a logic-based probabilistic modeling language with a tabling mechanism, we generalize prefix probability computation for PCFGs to probabilistic logic programs. Given a top-goal, we search for all SLD proofs by tabled search regardless of whether they contain loop or not. We then convert them to a set of linear probability equations and solve them by matrix operation. The solution gives us the probability of the topgoal, which, in nature, is an infinite sum of probabilities. Our generalized approach to prefix probability <b>computation</b> through <b>tabling</b> opens a way to logic-based probabilistic modeling of cyclic dependencies...|$|R
40|$|One in {{a series}} of {{mathematical}} tables prepared by the Project for the <b>Computation</b> of Mathematical <b>Tables.</b> " [...] Volume I., Pref. "Reproduced by photo offset process. "I. Logarithms of the integers from 1 to 50, 000. [...] II. Logarithms of the integers from 50, 000 to 100, 000. [...] III. Logarithms of the decimal numbers from 0. 0001 to 5. 0000. [...] IV. Logarithms of the decimal numbers from 5. 0000 to 10. 0000. Mode of access: Internet...|$|R
40|$|The {{subgroup}} {{pattern of}} a finite group C is {{the table of}} marks of G together {{with a list of}} representatives of the conjugacy classes of subgroups of G. In this article we present an algorithm for the computation of the subgroup pattern of a cyclic extension of G from the subgroup pattern of G. Repeated application of this algorithm yields an algorithm for the <b>computation</b> of the <b>table</b> of marks of a solvable group G, along a composition series of G...|$|R
40|$|Abstract. The {{literature}} on side-channel analysis describes numerous masking schemes {{designed to protect}} block ciphers at the implementation level. Such masking schemes typically require the <b>computation</b> of masked <b>tables</b> prior to the execution of an encryption function. In this paper we revisit an attack which directly exploits this computation {{in such a way}} as to recover all or some of the masks used. We show that securely implementing masking schemes is only possible where one has access to a significant amount of random numbers...|$|R
40|$|Abstract. Knowledge {{representation}} systems {{based on}} the well-founded semantics can offer the degree of scalability required for semantic web applications and make use of ex-pressive semantic features such as Hilog, frame-based rea-soning, and defeasibility theories. Such features can be com-piled into Prolog tabling engines that have good support for indexing and memory management. However, due both {{to the power of}} the semantic features and to the declarative style typical of knowledge representation rules, the resources needed for query evaluation can be unpredictable. In such a situation, users need to understand the overall structure of a computation and examine problematic portions of it. This problem, of profiling a computation, differs from debug-ging and justification which address why a given answer was or wasn’t derived, and so profiling requires different tech-niques. In this paper we present a trace-based analysis tech-nique called forest logging which has been used to profile large, heavily <b>tabled</b> <b>computations.</b> In forest logging, criti-cal aspects of a <b>tabled</b> <b>computation</b> are logged; afterwards the log is loaded and analyzed. As implemented in XSB, for-est logging slows down execution of practical programs by a constant factor that is often small; and logs containing tens or hundreds of millions of facts can be loaded and analyzed in minutes...|$|R
40|$|We {{present a}} CUDA {{implementation}} of dense multivariate polynomial arithmetic based on Fast Fourier Transforms (FFT) over finite fields. The motivation {{of our work}} is to support polynomial system solvers based {{on the notion of}} a regular chains [3] where the core algorithms [1] rely on the theory of polynomial subresultants. In [4], we have shown that the dominant cost of those algorithms can be essentially reduced to that of subresultant chain <b>computations.</b> The <b>table</b> below lists our experimental results for computing resultants for trivariate random dense polynomials in x, y,z. The first column shows the common partial degree d in x, y and z. The second one, labelled by t 0, is the timing for GPU supported code, which includes host-device data transfers The third column, labelled by t 1, shows our pure CPU serial C code in the modpn library [5]. d t 0 t 1 t 1 /t...|$|R
40|$|First-generation {{streaming}} systems did not {{pay much}} attention to state management via ACID transactions (e. g., [3, 4]). S-Store is a data management system that combines OLTP transactions with stream processing. To create S-Store, we begin with H-Store, a main-memory transaction processing engine, and add primitives to support streaming. This includes triggers and transaction workflows to implement push-based processing, windows to provide a way to bound the <b>computation,</b> and <b>tables</b> with hidden state to implement scoping for proper isolation. This demo explores the benefits of this approach by showing how a naïve implementation of our benchmarks using only H-Store can yield incorrect results. We also show that by exploiting push-based semantics and our implementation of triggers, we can achieve significant improvement in transaction throughput. We demo two modern applications: (i) leaderboard maintenance for a version of "American Idol", and (ii) a city-scale bicycle rental scenario...|$|R
40|$|In {{this paper}} we {{describe}} the XSB system, an in-memory deductive database engine. XSB began from a Prolog foundation, and traditional Prolog systems {{are known to have}} a number of serious deficiencies when they are used as database systems. Accordingly, XSB has a fundamental bottom-up extension, introduced through tabling (or memoing) [4], which makes it appropriate as an underlying query engine for deductive database systems. Because it eliminates redundant <b>computation,</b> the <b>tabling</b> extension makes XSB able to compute all modularly stratified datalog programs finitely and with polynomial data complexity. For non-stratified programs, a meta-interpreter is provided that has the same properties. In addition XSB includes indexing capabilities greatly improved over those of standard Prolog systems. Also, it supports HiLog, which makes it a very flexible data modeling system [2]. The implementation of XSB derives from the WAM [24], an efficient Prolog engine. XSB inherits the WAM's efficiency [...] ...|$|R
40|$|Waveform {{tables are}} an {{important}} tool for synthesizing sound, but they introduce error which results in noise. Error {{is affected by the}} spectrum of the signal stored in the table. Error is reduced by increasing the table size and/or by increasing the quality of interpolation. Both of these also affect the signal <b>computation</b> cost. <b>Table</b> sizes required for a given signal-to-noise ratio are computed for different interpolation methods and spectral rolloffs. Execution times are then evaluated. Non-interpolated oscillators perform the best, but only if the storage and computation costs of the tables are not an issue. This and other tradeoffs are discussed. 1. Introduction Software-based synthesizers are gaining in popularity because computers are becoming faster and cheaper at an exponential rate and because they offer tremendous flexibility. However, software {{is not the same as}} hardware. It is important to reconsider design choices rather than simply emulate existing hardware designs. [...] ...|$|R
