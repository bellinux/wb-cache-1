20|318|Public
5|$|A {{cluster is}} a group of loosely <b>coupled</b> <b>computers</b> that work {{together}} closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a cluster {{do not have to be}} symmetric, load balancing is more difficult if they are not. The most common type of cluster is the Beowulf cluster, which is a cluster implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. The vast majority of the TOP500 supercomputers are clusters.|$|E
25|$|Grids are {{a form of}} {{distributed}} computing whereby a “super virtual computer” is composed of many networked loosely <b>coupled</b> <b>computers</b> acting together to perform very large tasks. This technology {{has been applied to}} computationally intensive scientific, mathematical, and academic problems through volunteer computing, and it is used in commercial enterprises for such diverse applications as drug discovery, economic forecasting, seismic analysis, and back office data processing in support for e-commerce and Web services.|$|E
2500|$|Grids are {{a form of}} {{distributed}} computing whereby a [...] "super virtual computer" [...] is composed of many networked loosely <b>coupled</b> <b>computers</b> acting together to perform large tasks. For certain applications, distributed or grid computing {{can be seen as}} a special type of parallel computing that relies on complete computers (with onboard CPUs, storage, power supplies, network interfaces, etc.) connected to a computer network (private or public) by a conventional network interface, such as Ethernet. This is in contrast to the traditional notion of a supercomputer, which has many processors connected by a local high-speed computer bus.|$|E
40|$|Hygrothermal {{prediction}} of buildings using computer software is regarded important. Much accurate computer software {{has been developed}} as computer technology advances. However, there is no <b>coupled</b> <b>computer</b> software of heat, moisture and air transfer. In this paper, new computer software that can calculate temperature and humidity of buildings with <b>coupled</b> <b>computer</b> model of heat, moisture and air transfer is developed. In {{the last part of}} this paper, the accuracy of this new computer software is verified using measurement data. The importance of considering absorption and desorption moisture of walls is also explained...|$|R
5000|$|Computer {{clusters}} {{are used}} for computation-intensive purposes, rather than handling IO-oriented operations such as web service or databases. For instance, a computer cluster might support computational simulations of vehicle crashes or weather. Very tightly <b>coupled</b> <b>computer</b> clusters are designed for work that may approach [...] "supercomputing".|$|R
40|$|A <b>coupled</b> <b>computer</b> system {{providing}} a distributed {{access to an}} ECG database is presented. The database {{is that of the}} HP 5600 C ECG interpretation and management system. Details are given about the architecture of a simultaneous access by a parallel computer, which allows independent laboratory research without interfering with the on-line routine ECG interpretation...|$|R
5000|$|Grid computing—"A form of {{distributed}} {{and parallel}} computing, whereby a 'super and virtual computer' {{is composed of}} a cluster of networked, loosely <b>coupled</b> <b>computers</b> acting in concert to perform very large tasks." ...|$|E
50|$|Grids are {{a form of}} {{distributed}} computing whereby a “super virtual computer” is composed of many networked loosely <b>coupled</b> <b>computers</b> acting together to perform very large tasks. This technology {{has been applied to}} computationally intensive scientific, mathematical, and academic problems through volunteer computing, and it is used in commercial enterprises for such diverse applications as drug discovery, economic forecasting, seismic analysis, and back office data processing in support for e-commerce and Web services.|$|E
5000|$|Grids are {{a form of}} {{distributed}} computing whereby a [...] "super virtual computer" [...] is composed of many networked loosely <b>coupled</b> <b>computers</b> acting together to perform large tasks. For certain applications, distributed or grid computing {{can be seen as}} a special type of parallel computing that relies on complete computers (with onboard CPUs, storage, power supplies, network interfaces, etc.) connected to a computer network (private or public) by a conventional network interface, such as Ethernet. This is in contrast to the traditional notion of a supercomputer, which has many processors connected by a local high-speed computer bus.|$|E
40|$|Numerical {{simulation}} of the National Ignition Facility (NIF) laser performance and automated {{control of the}} laser setup process are crucial to the project's success. These functions will be performed by two closely <b>coupled</b> <b>computer</b> code: the virtual beamline (VBL) and the laser performance operations model (LPOM). Comment: 3 pages, submission to ICALEPCS 2001 conferenc...|$|R
5000|$|... #Caption: A <b>couple</b> of <b>computer</b> {{controlled}} {{street gangs}} are fighting on an urban street.|$|R
40|$|In this paper, an {{analysis}} of state-of-the-art and an attempt to generalize {{the basic principles of}} multiphysical (<b>coupled)</b> <b>computer</b> simulation of various electromagnetic devices (electrical machines, induction heaters, actuators, electrophysical devices, etc.) are presented. The analysis is based on the author’s wide experience in solving various practical problems regarding design and operation of a variety of innovative machines and devices as well as on studies carried out by other researcher...|$|R
50|$|A {{cluster is}} a group of loosely <b>coupled</b> <b>computers</b> that work {{together}} closely, so that in some respects they can be regarded as a single computer. Clusters are composed of multiple standalone machines connected by a network. While machines in a cluster {{do not have to be}} symmetric, load balancing is more difficult if they are not. The most common type of cluster is the Beowulf cluster, which is a cluster implemented on multiple identical commercial off-the-shelf computers connected with a TCP/IP Ethernet local area network. Beowulf technology was originally developed by Thomas Sterling and Donald Becker. The vast majority of the TOP500 supercomputers are clusters.|$|E
50|$|BESYS (Bell Operating System) was {{an early}} {{computing}} environment originally implemented as a batch processing operating system in 1957 at Bell Labs for the IBM 704 computer. The initial version of the system BESYS2 was created by George H. Mealy and Gwen Hansen with Wanda Lee Mammel {{under the guidance of}} Victor A. Vyssotsky and utilized IBM's FORTRAN and North American's symbolic assembly program (SAP) programming languages. It was designed to efficiently deal with a large number of jobs originating on punched cards and producing results suitable for printing on paper and punched cards. The system also provided processing capabilities for data stored on magnetic tapes and magnetic disk storage units. Typically punched card and print processing was handled off line by peripheral Electronic Accounting Machines, IBM 1401 computers, and eventually direct <b>coupled</b> <b>computers.</b>|$|E
5000|$|In 1962 at the University of California, Berkeley he {{developed}} an incremental compiling technology, with a flexibility close to interpreted code, while running at high speed. {{he also took}} course work at UC Berkeley. In 1965 {{he developed}} similar techniques for the Stanford University Medical School.The next year he worked on real-time data-acquisition control and data analysis using <b>coupled</b> <b>computers</b> for clinical research, and in 1970 on transposed storage (now termed a Column-oriented DBMS) for databases for very-high speed on-line analytical processing, also at the medical school.From 1973 through 1976 he did graduate work at the University of California, San Francisco, with his Ph.D. thesis titled [...] "A Methodology for the Design of Medical Database Systems".An extensive study of computerized ambulatory health care systems, appeared as an appendix to his dissertation.|$|E
40|$|The {{design and}} {{analysis}} of SEASAT simulation studies in which the error structure of conventional analyses and forecasts is modeled realistically are presented. The development and computer implementation of a global spectral ocean wave model is described. The design of algorithms for the assimilation of theoretical wind data into computers and for the utilization of real wind data and wave height data in a <b>coupled</b> <b>computer</b> system are presented...|$|R
25|$|Ziaul Ahsan, {{a detective}} with the RAB, said {{investigators}} believed the murder was pre-meditated and committed {{by someone who}} knew the victims. Police said {{at least two people}} murdered the couple. At first police reported that nothing was stolen, but later reports said Sarowar’s laptop computer and cell phones could be missing. Another report, however, claimed that police had retrieved three cell phones as evidence. But in the petition brought to the High Court, it was learned that the <b>couple's</b> <b>computers</b> and laptops had been stolen.|$|R
40|$|Pile {{foundations}} transfer loads from superstructures to stronger sub soil. Their {{strength and}} stability can hence affect structural safety. This paper treats {{the response of}} reinforced concrete pile in saturated sand to a buried explosion. Fully <b>coupled</b> <b>computer</b> simulation techniques are used together with five different material models. Influence of reinforcement on pile response is investigated and important safety parameters of horizontal deformations and tensile stresses in the pile are evaluated. Results indicate that adequate longitudinal reinforcement and proper detailing of transverse reinforcement can reduce pile damage. Present findings {{can serve as a}} benchmark reference for future analysis and design...|$|R
40|$|Despite {{considerable}} {{commercial exploitation}} of fault tolerance systems, significant and difficult research problems remain {{in such areas}} as fault detection and correction. A research project is described which constructs a distributed computing test bed for loosely <b>coupled</b> <b>computers.</b> The project is constructing a tool kit to support research into distributed control algorithms, including a distributed Ada compiler, distributed debugger, test harnesses, and environment monitors. The Ada compiler is being written in Ada and will implement distributed computing at the subsystem level. The design goal is to provide a variety of control mechanics for distributed programming while retaining total transparency at the code level...|$|E
40|$|Many times, routing {{of signal}} nets in the layout design of VLSI {{circuits}} {{turns out to}} be a bottleneck in designing complex chips, due to the inherent compute-intensive nature of this task. Parallel processing of the routing problem holds promise for mitigating this situation. In this context, we present a parallel channel routing algorithm that is targeted to run on loosely <b>coupled</b> <b>computers</b> like hypercubes. The proposed parallel algorithm employs simulated annealing technique for achieving near-optimum solutions. For efficient execution, attempts have been made to reduce the communication overheads by restricting broadcast of updates only to cases of interprocessor net transfers. Performance evaluation studies on the algorithm show promising results...|$|E
40|$|Commodity-based {{computer}} clusters offer {{a cost-effective}} alternative to traditional largescale, tightly <b>coupled</b> <b>computers</b> {{as a means}} to provide high-performance computational and visualization services. The Center for the Simulation of Accidental Fires and Explosions (C-SAFE) at the University of Utah employs such a cluster, and we have begun to experiment with cluster-based visualization services. In particular, we seek to develop an interactive volume rendering tool for navigating and visualizing large-scale scientific datasets. Using Simian, an OpenGL volume renderer, we examine two approaches to cluster-based interactive volume rendering: (1) a "cluster-aware" version of the application that makes explicit use of remote nodes through a message-passing interface, and (2) the unmodified application running atop the Chromium clustered rendering framework. This paper provide...|$|E
2500|$|PureData System (tightly <b>coupled</b> and {{specialized}} <b>computer</b> appliance / software appliance) ...|$|R
5000|$|In 1965, Earnest {{became a}} {{lecturer}} {{in computer science}} at Stanford University and the chief administrative officer of the Stanford Artificial Intelligence Laboratory. Under founding director John McCarthy, he soon became deeply involved with the Advanced Research Projects Agency Network (ARPAnet) startup committee. This association would lead him to the one innovation he has received the most acclaim for: {{the invention of the}} Finger protocol (RFC 742) in the early 1970s. In the late 1960s, Earnest continued to diversify the types of technologies he involved himself with. He made significant contributions in the fields of robotics through the creation of systems that <b>coupled</b> <b>computer</b> vision with prosthetic and vehicular applications.|$|R
50|$|For formal {{definition}} of {{behavior of the}} coupled DEVS, you can refer to Behavior of <b>Coupled</b> DEVS. <b>Computer</b> algorithms to implement {{the behavior of a}} given coupled DEVS mode are available at Simulation Algorithms for Coupled DEVS.|$|R
40|$|We {{describe}} {{the design of}} an efficient portable driver for shared memory interconnects. The driver provides a foundation for interfacing to commodity software like clustered database servers. We present performance figures for a driver implementation that uses SCI through the PCI bus on standard PCs running Windows NT. Keywords: Clustering, Shared memory, SCI. 1 Introduction With the rapid advances in microprocessor design, the cluster of workstations is emerging as a cost effective solution to high-end processing needs [1]. A cluster consists {{of a number of}} autonomous, loosely <b>coupled</b> <b>computers.</b> Proprietary interconnects like high-speed memory buses are not required for their operation. Clusters will instead use standard communication technologies like Ethernet, or (more recently) IO-bus based shared memory interconnects like the Dolphin SBUS-SCI [2] and PCI-SCI [3] [4] adapters, ServerNet [5] and the DEC Memory Channel [6]. A cluster has two highly desirable properties:. Scalabili [...] ...|$|E
40|$|With metacomputing, in {{the sense}} of {{heterogeneous}} supercomputing, large computational problems can be solved, utilizing main memory and computational power of several <b>coupled</b> <b>computers.</b> However, because of the comparatively low bandwidth and high latency of external networks, it is quite difficult to realize these theoretical advantages. Experience shows that extensive restructuring of applications is necessary to make reasonable use of a metacomputer, as factors like load balancing and optimization of the communication have to be considered. In this thesis a programming model is developed which automatically optimizes external communication by combining messages and by overlapping computation and communication. A static load balancing scheme allows for different computational powers of the used machines. Furthermore, a dynamic load balancing module redistributes the load during runtime, considering the different speeds of the machines. A prototypical implementation shows the advantages which result from using the model in typical practical applications. (orig.) Available from TIB Hannover: RA 831 (3676) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|E
40|$|High-throughput {{computing}} (HTC) is {{a powerful}} paradigm allowing vast quantities of independent work to be performed simultaneously across many loosely <b>coupled</b> <b>computers.</b> These systems often exploit the idle time available on computers provisioned for other purposes – volunteer computing. However, until recently, little evaluation has been performed on the energy impact of HTC. Many organisations now seek to minimise energy consumption across their IT infrastructure. However, {{it is unclear how}} this will affect the usability of HTC systems especially when exploiting volunteer computers. We present here HTC-Sim, a simulation system that allows the evaluation of different energy reduction policies across an HTC system. We model systems that comprised both collections of computational resources dedicated to HTC work and resources provided through volunteer computing – a desktop grid. We demonstrate that our simulation software scales linearly with increasing HTC workload. We go further to evaluate a number of resource selection policies in terms of the overheads/slowdown incurred and the energy impact on the HTC system...|$|E
50|$|DX 200 is a versatile, fault-tolerant, modular {{and highly}} {{scalable}} telephone exchange and general purpose server platform, designed for high performance, high availability applications. Its hardware is built from loosely <b>coupled</b> redundant <b>computer</b> units, backed by distributed software architecture.|$|R
50|$|Prior to Red Hat, Young built a <b>couple</b> of <b>computer</b> rental and leasing businesses, {{including}} founding Vernon Computer Rentals in 1984.2 Descendants of Vernon {{are still}} operating under that name. After leaving Vernon, Young founded the ACC Corp Inc. in 1993.|$|R
25|$|Computer {{programs}} may be categorized along functional lines. The main functional categories are application software and system software. System software includes {{the operating system}} which <b>couples</b> <b>computer</b> hardware with application software. The purpose of the operating system is to provide {{an environment in which}} application software executes in a convenient and efficient manner. In addition to the operating system, system software includes embedded programs, boot programs, and micro programs. Application software designed for end users have a user interface. Application software not designed for the end user includes middleware, which couples one application with another. Application software also includes utility programs. The distinction between system software and application software is under debate.|$|R
40|$|Analytic {{measurement}} of visual parameters {{relevant to the}} labial production of speech as well as real-time 3 D computer animated models of the lips and of the face have been implemented on two <b>coupled</b> <b>computers,</b> so that synthetic lips alone or a whole facial model can mimic on line (or play back) the actual gestures of a natural speaker. The geometric measurements performed on the speaker's lips and jaw are made through image processing of the front and profile view of the speaker's face. Data are transmitted to a display computer through a control interface which delivers the proper parameters to control the animation of the 3 D models. The lip model uses five control parameters and the facial model uses one extra one: jaw lowering. At present, the tongue is not controlled. We here present the realtime techniques used for analysis, animation of the 3 D models, and synchronization of the two processes. Finally, we evaluate the bimodal intelligibility of speech under five levels of acousti [...] ...|$|E
40|$|Grid computing—also {{known as}} Metacomputing—is an {{abstraction}} by which clusters of loosely <b>coupled</b> <b>computers</b> in a distributed {{system can be}} treated as a single virtual machine. With the aid of Grid middleware, clusters of loosely coupled machines (quite possibly heterogeneous) can {{be treated as a}} single virtual system or a virtual organization (VO). ^ The optimal exploitation of resources within the Grid figures largely in the scheduling world. However, Grid computational resources are distributed, heterogeneous, and dynamic which makes it difficult to schedule applications in a way that maximizes appropriate performance metrics. In addition, the scheduling problem in its most general form is known to be NP-complete. Therefore, many heuristics have been developed to generate adequate (but sub-optimal) schedulers. ^ This research work focuses on developing algorithms for adaptively scheduling applications in dynamic multi-user distributed Grid environment based on three primary factors: an adaptive hierarchical Grid Monitoring policy, an adaptive hierarchical Grid Resource Forecasting policy, and an Intelligent Hierarchical Grid Scheduling policy. ^ Our objective is to optimize the services requested by user/node in the federated clusters to meet some criteria of performance optimality, (such as Mean Flow Time). ...|$|E
40|$|The {{hardware}} and software for a computer controlled optical radar, or lidar, system are described. The system builds on a previously installed pulsed ruby backscatter lidar, capable of acquiring data at controlled azimuth and elevation angles through the atmosphere. The described system replaces hardwired logic with computer control. Two <b>coupled</b> <b>computers</b> are used to allow a degree of real time control while data are processed. One of these computers reads and controls mount elevation angle, reads the laser energy monitor, and senses firing of the laser. The other computer serves as a user interface, and receives the lidar return data from a digitizer and memory, and the angle and energy information from the other computer. The second computer also outputs data to a disc drive. The software provided with the system is described, and the feasibility of additional software for both control and data processing is explored. Particular attention is given to data integrity and instrument and computer operation {{in the presence of}} the high energy pulses used to drive the laser. A previously described laser energy monitor has been improved to isolate it from laser transients. Mount elevation angles are monitored with an absolute angle readout. As a troubleshooting aid, a simulator with an output that approximates the lidar receiver output was developed. Its output is digitally generated and provides a known repetitive signal. Operating procedures are described for standard data acquisition, and troubleshooting is outlined. The system can be used by a relatively inexperienced operator; English sentences are displayed on the system console CRT terminal to lead the operator through data acquisition once the system hardware is turned on. A brief synopsis of data acquired on the system is given. Those data are used as the basis of other referenced papers. It constitutes soundings for over one hundred days. One high point has been operation of the system in conjunction with a balloon borne atmospheric particulate sampling package. The system has also been used occasionally as the transmitter of a lidar system with physically separated receiver and transmitter...|$|E
40|$|Abstract. By <b>coupling</b> <b>computer</b> with {{measurement}} devices, information measurement {{systems are}} being made, whose basic tasks are automation measuring and quality control of manufacturing processes, mathematical processing of measured results in real time, storing of measured results, documenting of measured results, process management, etc. Statistical methods for quality evaluation provide analyses of production processes which {{can serve as}} the basis for undertaking adequate preventive and correction measures in order to increase the total production quality. In this paper importance is emphasized for applying statistical quality control methods to evaluation of process stability and capability. There is a preview of structure and functioning of the developed applicative software for statistical process control. At the end, corresponding conclusions are given...|$|R
5000|$|... (b) a {{computer}} server at the outsource provider, which <b>computer</b> server is <b>coupled</b> to the <b>computer</b> store and programmed to: ...|$|R
40|$|The {{possibilities}} of studying nonlinear physical systems by small feedback action are discussed. Analytical bounds of possible system energy change by feedback are established. The feedback resonance and synchronization phenomena are studied for 2 -DOF system {{consisting of two}} <b>coupled</b> pendulums. <b>Computer</b> simulation results are presented...|$|R
