400|10000|Public
25|$|As {{the names}} indicate, weak {{convergence}} is weaker than strong convergence. In fact, strong convergence implies <b>convergence</b> <b>in</b> <b>probability,</b> and <b>convergence</b> <b>in</b> <b>probability</b> implies weak convergence. The reverse statements {{are not always}} true.|$|E
25|$|The {{concept of}} <b>convergence</b> <b>in</b> <b>probability</b> is used very often in statistics. For example, an {{estimator}} is called consistent if it converges in probability to the quantity being estimated. <b>Convergence</b> <b>in</b> <b>probability</b> {{is also the}} type of convergence established by the weak law of large numbers.|$|E
25|$|<b>Convergence</b> <b>in</b> <b>probability</b> implies {{convergence}} in distribution.|$|E
5000|$|The theorem remains valid if we replace all <b>convergences</b> <b>in</b> {{distribution}} with <b>convergences</b> <b>in</b> <b>probability</b> (due to this property).|$|R
5000|$|Dominated convergence. Suppose that Hn → H and |Hn| ≤ J, where J is an X-integrable process. then Hn · X → H · X. <b>Convergence</b> is <b>in</b> <b>probability</b> at {{each time}} t. In fact, it converges uniformly on {{compacts}} <b>in</b> <b>probability.</b>|$|R
40|$|We {{study the}} {{asymptotic}} {{behavior of the}} ν-symmetric Riemman sums for functionals of a self-similar centered Gaussian process X with increment exponent 0 (2 ℓ+ 1) ^- 1, we prove that the <b>convergence</b> holds <b>in</b> <b>probability...</b>|$|R
25|$|<b>Convergence</b> <b>in</b> <b>probability</b> {{does not}} imply almost sure convergence.|$|E
25|$|In the {{opposite}} direction, {{convergence in distribution}} implies <b>convergence</b> <b>in</b> <b>probability</b> when the limiting random variable X is a constant.|$|E
25|$|Consistency {{as defined}} here is {{sometimes}} referred to as weak consistency. When we replace <b>convergence</b> <b>in</b> <b>probability</b> with almost sure convergence, then the estimator is said to be strongly consistent. Consistency is related to bias; see bias versus consistency.|$|E
40|$|We {{consider}} {{the problem of}} estimating the s-th derivative of a density function f by the tilted Kernel estimator introduced in Hall and Doosti (2012). Then we further show this estimator achieves the same <b>convergence</b> rate, <b>in</b> <b>probability,</b> the wavelet estimators achieved as shown in Hall and Patil (1995) ...|$|R
40|$|In this largely expository article, we {{highlight}} {{the significance of}} various types of `dimension' for obtaining uniform <b>convergence</b> results <b>in</b> <b>probability</b> theory and we demonstrate how these results lead to certain notions of generalization for classes of binary-valued and realvalued functions. We also present new results on the generalization ability of certain types of artificial neural networks with real output...|$|R
40|$|In this paper, we {{investigate}} the <b>convergence</b> order <b>in</b> <b>probability</b> {{of a novel}} ergodic numerical scheme for damped stochastic nonlinear Schrödinger equation with an additive noise. Theoretical analysis shows that our scheme is of order one <b>in</b> <b>probability</b> under appropriate assumptions for the initial value and noise. Meanwhile, we show that our scheme possesses the unique ergodicity and preserves the discrete conformal multi-symplectic conservation law. Numerical experiments are given to show the longtime behavior of the discrete charge and the time average of the numerical solution, and to test the convergence order, which verify our theoretical results...|$|R
2500|$|The {{notion of}} {{asymptotic}} consistency is very close, almost synonymous {{to the notion}} of <b>convergence</b> <b>in</b> <b>probability.</b> As such, any theorem, lemma, or property which establishes <b>convergence</b> <b>in</b> <b>probability</b> may be used to prove the consistency. Many such tools exist: ...|$|E
2500|$|<b>Convergence</b> <b>in</b> <b>probability</b> implies {{convergence}} in distribution: ...|$|E
2500|$|<b>Convergence</b> <b>in</b> <b>probability</b> implies {{there exists}} a sub-sequence [...] which almost surely converges: ...|$|E
40|$|We give equivalences for {{conditions}} like X(T(r)) /r→ 1 and X(T^*(r)) / r→ 1, where the <b>convergence</b> is <b>in</b> <b>probability</b> or almost sure, both as r→ 0 and r→∞, where X is a Lévy process and T(r) and T^*(r) {{are the first}} exit times of X out of the strip {(t,y) :t> 0,|y|≤ r} and half-plane {(t,y) :t> 0, y≤ r}, respectively. We also show, using a result of Kesten, that X(T^*(r)) /r→ 1 a. s. as r→ 0 is equivalent to X "creeping" across a level...|$|R
40|$|Limit theorems for the multitype {{branching}} {{random walk}} as n [...] > [infinity] are given (n is the generation number) {{in the case}} in which the branching process has a mean matrix which is not positive regular. In particular, the existence of steady state distributions is proven in the subcritical case with immigration, and in the critical case with initial Poisson random fields of particles. In the supercritical case, analogues of the limit theorems of Kesten and Stigum are given. Branching random walk point process <b>convergence</b> <b>in</b> distribution <b>probability</b> generating functional steady state distribution...|$|R
40|$|AbstractWe {{study the}} weak limit {{behavior}} of {{certain types of}} point processes obtained by replacing the original observations by the bootstrap sample. The usual bootstrap fails asymptotically in cases for which there exists a Poisson point process or a fixed point measure in the limit. In some cases, by subsampling at the rate m=m(n) =o(n) →∞ in the bootstrap (where n is the sample size), this problem will be resolved and <b>convergence</b> holds <b>in</b> <b>probability.</b> If mloglogn/n→ 0 then asymptotic results are valid almost surely. The method is applied to some statistical problems...|$|R
2500|$|For random {{elements}} {X'n} on a separable metric space , <b>convergence</b> <b>in</b> <b>probability</b> {{is defined}} similarly by ...|$|E
2500|$|<b>Convergence</b> <b>in</b> <b>probability</b> is {{denoted by}} adding the letter p over an arrow {{indicating}} convergence, or using the “plim” probability limit operator: ...|$|E
2500|$|<b>Convergence</b> <b>in</b> <b>probability</b> {{defines a}} {{topology}} {{on the space}} of random variables over a fixed probability space. This topology is metrizable by the Ky Fan metric: ...|$|E
40|$|We {{present a}} {{theoretical}} {{analysis of a}} recent whole body motion planning method, the Randomized Possibility Graph, which uses a high-level decomposition of the feasibility constraint manifold in order to rapidly find routes {{that may lead to}} a solution. These routes are then examined by lower-level planners to determine feasibility. In this paper, we show that this approach is probabilistically complete for bipedal robots performing quasi-static walking in "semi-unstructured" environments. Furthermore, we show that the decomposition into higher and lower level planners allows for a considerably higher rate of <b>convergence</b> <b>in</b> the <b>probability</b> of finding a solution when one exists. We illustrate this improved convergence with a series of simulated scenarios...|$|R
40|$|We {{study the}} weak limit {{behavior}} of {{certain types of}} point processes obtained by replacing the original observations by the bootstrap sample. The usual bootstrap fails asymptotically in cases for which there exists a Poisson point process or a fixed point measure in the limit. In some cases, by subsampling at the rate m=m(n) =o(n) [...] >[infinity] in the bootstrap (where n is the sample size), this problem will be resolved and <b>convergence</b> holds <b>in</b> <b>probability.</b> If m loglog n/n [...] > 0 then asymptotic results are valid almost surely. The method is applied to some statistical problems. Bootstrap Point process Extremes Heavy tail Asymptotic Linear regression...|$|R
40|$|For {{probability}} {{measures on}} a complete separable metric space, we present sufficient {{conditions for the}} existence of a solution to the Kantorovich transportation problem. We also obtain sufficient conditions (which sometimes also become necessary) for the <b>convergence,</b> <b>in</b> transportation, of <b>probability</b> measures when the cost function is continuous, non-decreasing and depends on the distance. As an application, the CLT in the transportation distance is proved for independent and some dependent stationary sequences...|$|R
2500|$|Almost sure {{convergence}} implies <b>convergence</b> <b>in</b> <b>probability</b> (by Fatou's lemma), {{and hence}} implies convergence in distribution. [...] It {{is the notion}} of convergence used in the strong law of large numbers.|$|E
2500|$|The {{dominance}} condition can {{be employed}} {{in the case of}} i.i.d. observations. In the non-i.i.d. case the uniform <b>convergence</b> <b>in</b> <b>probability</b> can be checked by showing that the sequence [...] is stochastically equicontinuous.|$|E
2500|$|Given X is an i.i.d. source, {{its time}} series X1, ..., X'n is i.i.d. with entropy H(X) in the discrete-valued case and {{differential}} entropy in the continuous-valued case. The weak law {{of large numbers}} gives the AEP with <b>convergence</b> <b>in</b> <b>probability,</b> ...|$|E
40|$|We {{show that}} the {{relative}} entropy between a posterior density formed from a smooth likelihood and prior and a limiting normal form tends to zero in the independent and identically distributed case. The mode of <b>convergence</b> is <b>in</b> <b>probability</b> and <b>in</b> mean. Applications to codelengths in stochastic complexity and to sample size selection are briey discussed. Index Terms: Posterior density, asymptotic normality, relative entropy. Revision submitted to Trans. Inform Theory, 22 May 1998. This research was partially supported by NSERC Operating Grant 5 - 54891. The author is with the Department of Statistics, University of British Columbia, Room 333, 6356 Agricultural Road, Vancouver, BC, Canada V 6 T 1 Z 2. 1 I...|$|R
40|$|AbstractA random {{optimization}} problem P 0 minx∈Г 0 (ω) ƒ 0 (x,ω), ω∈Ω, is approximated by {{a sequence of}} random surrogate problems (Pn) n∈N with Pn minx∈Гn(ω) ƒn(x,ω), ω∈Ω ([Ω, Σ, P] a given probability space). We investigate the convergence almost surely and <b>in</b> <b>probability</b> of the optimal values and the solution sets. The results {{can be regarded as}} random versions of well-known stability statements of parametric programming. Semicontinuous <b>convergence</b> (almost surely, <b>in</b> <b>probability)</b> of sequences of random functions is a crucial assumption in this framework and will be investigated in more detail...|$|R
40|$|Policy {{gradients}} methods often achieve {{better performance}} when {{the change in}} policy {{is limited to a}} small Kullback-Leibler divergence. We derive policy gradients where the change in policy is limited to a small Wasserstein distance (or trust region). This is done in the discrete and continuous multi-armed bandit settings with entropy regularisation. We show that in the small steps limit with respect to the Wasserstein distance $W_ 2 $, policy dynamics are governed by the Fokker-Planck (heat) equation, following the Jordan-Kinderlehrer-Otto result. This means that policies undergo diffusion and advection, concentrating near actions with high reward. This helps elucidate the nature of <b>convergence</b> <b>in</b> the <b>probability</b> matching setup, and provides justification for empirical practices such as Gaussian policy priors and additive gradient noise...|$|R
2500|$|Convergence in the r-th mean, for r ≥ 1, implies <b>{{convergence}}</b> <b>in</b> <b>probability</b> (by Markov's inequality). Furthermore, if r > s ≥ 1, convergence in r-th mean implies convergence in s-th mean. [...] Hence, convergence in {{mean square}} implies convergence in mean.|$|E
2500|$|The {{vector space}} of (equivalence classes of) {{measurable}} functions on [...] is denoted [...] By definition, it contains all the , and {{is equipped with}} the topology of convergence in measure. When [...] is a probability measure (i.e., [...] ), this mode of convergence is named <b>convergence</b> <b>in</b> <b>probability.</b>|$|E
2500|$|The {{space of}} {{measurable}} functions {{on the unit}} interval [...] (where we identify two functions that are equal almost everywhere) has a vector-space topology defined by the translation-invariant metric: (which induces the convergence in measure of measurable functions; for random variables, convergence in measure is <b>convergence</b> <b>in</b> <b>probability)</b> ...|$|E
40|$|For ergodic {{systems with}} {{generating}} partitions, the well known result of Ornstein and Weiss {{shows that the}} exponential growth rate of the recurrence time is almost surely equal to the metric entropy. Here {{we look at the}} exponential growth rate of entrance times, and show that it equals the entropy, where the <b>convergence</b> is <b>in</b> <b>probability</b> <b>in</b> the product measure. This is however under the assumptions that the limiting entrance times distribution exists almost surely. This condition looks natural in the light of an example by Shields in which the limsup in the exponential growth rate is infinite almost everywhere but where the limiting entrance times do not exist. We then also consider ϕ-mixing systems and prove a result connecting the Rényi entropy to sums over the entrance times orbit segments. Comment: 13 page...|$|R
40|$|We {{present a}} class of {{modified}} circumcenter algorithms that allow a group of agents to achieve “practical ” rendezvous when they are only able to take noisy measurements of neighbors. Assuming a uniform detection <b>probability</b> <b>in</b> a disk about each neighbor true position, we show how initially connected agents converge to a practical stability ball. More precisely, a deterministic analysis allows to guarantee convergence to such a ball under r-disk graph connectivity in 1 D and with a connectivity-to-noise ratio of r/σ> 7. A stochastic analysis leads to a similar <b>convergence</b> result <b>in</b> <b>probability,</b> but for any r/σ> 1, and under a sequence of switching graphs connecting agents in 2 D every T steps. We include several simulations to discuss {{the performance of the}} proposed algorithms. Key words: multiagent systems, robotic networks, motion coordination, rendezvous algorithm...|$|R
40|$|Probability {{space and}} measure; sigma algebras; Caratheodory’s {{extension}} theorem; Kolmogorov’s extension theorem; independence. • Random variables; expected value; joint distributions; moment generating functions; characteristic functions; Chebyshev’s inequality; large deviations. • Modes of <b>convergence</b> (weak, <b>in</b> <b>probability,</b> Lp, almost sure) and properties. • Weak laws {{of large numbers}} for sequences and triangular arrays; L 2 weak law; applications to analysis and combinatorics. • Borel-Cantelli lemmas; strong law of large numbers; convergence of random series. •Weak convergence; central limit theorem for sequences and triangular arrays; Poisson convergence; applications. • Stopping times; Wald’s equation; conditional probability/expectation; Martingales; Radon-Nikodym theorem; optional stopping theorems; applications. • Stochastic processes and their properties; discrete and continuous time Markov chains; birth-death process and Poisson process; renewal theory. • Brownian motion and related Gaussian/diffusion processes; Donsker’s theorem...|$|R
