58|58|Public
5000|$|... where [...] is {{the cutoff}} distance. Simply {{applying}} this <b>cutoff</b> <b>method</b> introduces a discontinuity in the force at [...] {{that results in}} particles experiencing sudden impulses when other particles cross the boundary of their respective interaction spheres. In the particular case of electrostatic forces, as the force magnitude is large at the boundary, this unphysical feature can compromise simulation accuracy. A way to correct this problem is to shift the force to zero at , thus removing the discontinuity. This can be accomplished {{with a variety of}} functions, but the most simple/computationally efficient approach is to simply subtract the value of the electrostatic force magnitude at the cutoff distance as such: ...|$|E
3000|$|... by {{spectral}} <b>cutoff</b> <b>method</b> (see [2]). This ordinary {{differential equation}} system {{can easily be}} solved by various numerical methods.|$|E
40|$|In {{the present}} study a system have {{developed}} that uses the Successor Variety Stemming Algorithm to findstems for Arabic words. A corpus of 242 abstracts have obtained from the Saudi Arabian National Computer Conference. All of these abstracts involve computer science and information systems. The study have set out to discoverwhether the Successor Variety Stemming Algorithm technique with the <b>Cutoff</b> <b>Method</b> {{can be used for}} the Arabic Language or not. In addition, the Successor Variety Algorithmhave compared with the Cutoff and the Successor Variety with Entropy Method. Stemming is typicallyused in the hope of improving the accuracy of the searchreducing the size of the index. The results ofpresent research show that the Successor Variety Algorithm with the <b>Cutoff</b> <b>Method</b> is better than Successor Variety Algorithm with the Entropy Method. We have achieved an 84 % level of correctness using the <b>Cutoff</b> <b>Method,</b> but a 64 % level of correctness using the Entropy Method. These experiments were carried out using Visual Basic 6. 0...|$|E
40|$|A {{reduction}} of the cost for long-range interaction calculation is essential for large-scale molecular systems that contain a lot of point charges. <b>Cutoff</b> <b>methods</b> are often used {{to reduce the cost}} of long-range interaction calculations. Molecular dynamics (MD) simulations can be accelerated by using cutoff methods; however, simple truncation or approximation of long-range interactions often offers serious defects for various systems. For example, thermodynamical properties of polar molecular systems are strongly affected by the treatment of the Coulombic interactions and may lead to unphysical results. To assess the truncation effect of some <b>cutoff</b> <b>methods</b> that are categorized as the shift function method, MD simulations for bulk water systems were performed. The results reflect two main factors, i. e., the treatment of cutoff boundary conditions and the presence/absence of the theoretical background for the long-range approximation...|$|R
40|$|The {{possibility}} of a small modification of spinor Quantum Electro-Dynamics is reconsidered, in which Lorentz and CPT non-covariant kinetic terms for photons and fermions are present. The corresponding free field theory is carefully discussed. The full one-loop induced Chern-Simons parity-odd effective action is calculated using dimensional regularization and physical <b>cutoff</b> <b>methods.</b> The result, which is coherently {{the same in the}} two methods, is different from those ones so far quoted in the Literature. A comparison with the previous calculations is thoroughly developed...|$|R
2500|$|During a {{classical}} MD simulation, the most CPU intensive task is {{the evaluation of}} the potential {{as a function of the}} particles' internal coordinates. Within that energy evaluation, the most expensive one is the non-bonded or non-covalent part. In Big O notation, common molecular dynamics simulations scale by [...] if all pair-wise electrostatic and van der Waals interactions must be accounted for explicitly. This computational cost can be reduced by employing electrostatics methods such as particle mesh Ewald summation ( [...] ), particle–particle-particle–mesh (P3M), or good spherical <b>cutoff</b> <b>methods</b> ( [...] ).|$|R
40|$|Abstract Background The Significance Analysis of Microarrays (SAM) is {{a popular}} method for {{detecting}} significantly expressed genes and controlling the false discovery rate (FDR). Recently, {{it has been reported}} in the literature that the FDR is not well controlled by SAM. Due to the vast application of SAM in microarray data analysis, it is of great importance to have an extensive evaluation of SAM and its associated R-package (sam 2. 20). Results Our study has identified several discrepancies between SAM and sam 2. 20. One major difference is that SAM and sam 2. 20 use different methods for estimating FDR. Such discrepancies may cause confusion among the researchers who are using SAM or are developing the SAM-like methods. We have also shown that SAM provides no meaningful estimates of FDR and this problem has been corrected in sam 2. 20 by using a different formula for estimating FDR. However, we have found that, even with the improvement sam 2. 20 has made over SAM, sam 2. 20 may still produce erroneous and even conflicting results under certain situations. Using an example, we show that the problem of sam 2. 20 is caused by its use of asymmetric cutoffs which are due to the large variability of null scores {{at both ends of the}} order statistics. An obvious approach without the complication of the order statistics is the conventional symmetric <b>cutoff</b> <b>method.</b> For this reason, we have carried out extensive simulations to compare the performance of sam 2. 20 and the symmetric <b>cutoff</b> <b>method.</b> Finally, a simple modification is proposed to improve the FDR estimation of sam 2. 20 and the symmetric <b>cutoff</b> <b>method.</b> Conclusion Our study shows that the most serious drawback of SAM is its poor estimation of FDR. Although this drawback has been corrected in sam 2. 20, the control of FDR by sam 2. 20 is still not satisfactory. The comparison between sam 2. 20 and the symmetric <b>cutoff</b> <b>method</b> reveals that the relative performance of sam 2. 20 to the symmetric cutff method depends on the ratio of induced to repressed genes in a microarray data, and is also affected by the ratio of DE to EE genes and the distributions of induced and repressed genes. Numerical simulations show that the symmetric <b>cutoff</b> <b>method</b> has the biggest advantage over sam 2. 20 when there are equal number of induced and repressed genes (i. e., the ratio of induced to repressed genes is 1). As the ratio of induced to repressed genes moves away from 1, the advantage of the symmetric <b>cutoff</b> <b>method</b> to sam 2. 20 is gradually diminishing until eventually sam 2. 20 becomes significantly better than the symmetric <b>cutoff</b> <b>method</b> when the differentially expressed (DE) genes are either all induced or all repressed genes. Simulation results also show that our proposed simple modification provides improved control of FDR for both sam 2. 20 and the symmetric <b>cutoff</b> <b>method.</b> </p...|$|E
40|$|We {{construct}} a priori error estimation for the force error of the twin-range <b>cutoff</b> <b>method,</b> which {{is widely used}} to treat the short-range non-bonded interactions in molecular simulations. Based on the error and cost estimation, we develop a work flow that can automatically determine the nearly most efficient twin-range cutoff parameters (i. e. the cutoff radii and the neighbor list updating frequency) prior to a simulation for a predetermined accuracy. Both the error estimate and the parameter tuning method are demonstrated to be effective by testing simulations of the standard Lennard-Jones 6 - 12 fluid in gas, liquid as well as supercritical state. We recommend the tuned twin-range <b>cutoff</b> <b>method</b> that can save precious user time and computational resources...|$|E
40|$|The {{origin of}} {{spurious}} solutions in the eight-band envelope function model is examined {{and it is}} shown that spurious solutions arise from the additional spurious degeneracies caused by the unphysical bowing of the conduction bands calculated within the eight-band k center dot p model. We propose two approaches to eliminate these spurious solutions. Using the first approach, the wave vector <b>cutoff</b> <b>method,</b> we demonstrate the origin and elimination of spurious solutions in a transparent way without modifying the original Hamiltonian. Through the second approach, we introduce some freedom in modifying the Hamiltonian. The comparison between {{the results from the}} various modified Hamiltonians suggests that the wave vector <b>cutoff</b> <b>method</b> can give accurate enough description to the final results...|$|E
40|$|A Bayesian network {{expansion}} algorithm called BN+ 1 {{was developed}} to identify undocumented gene interactions in a known pathway using microarray gene expression data. In our recent paper, the BN+ 1 algorithm has been successfully used to identify key regulators including uspE in the E. coli ROS pathway and biofilm formation. 18 In this report, a synthetic network was designed to further evaluate this algorithm. The BN+ 1 method was found to identify both linear and nonlinear relationships and correctly identify variables near the starting network. Using experimentally derived data, the BN+ 1 method identifies the gene fdhE as a potentially new ROS regulator. Finally, a range of possible score <b>cutoff</b> <b>methods</b> are explored to identify a set of criteria for selecting BN+ 1 calls...|$|R
40|$|Methodological {{issues in}} {{molecular}} dynamics (MD) simulations, {{such as the}} treatment of long-range electrostatic interactions or the type of pressure coupling, have important consequences for the equilibrium properties observed. We report a series of long (up to 150 ns) MD simulations of dipalmitoylphosphatidylcholine (DPPC) bilayers in which the methodology of simulation is systematically varied. Comparisons of simulations with truncation schemes, Ewald summations, and modified Coulomb interactions, either by shift functions or reaction field models, to describe long-range electrostatics point out the artifacts inherent {{in each of these}} methods and above all those of straight <b>cutoff</b> <b>methods.</b> We further show that bilayer properties are less sensitive to the details of the pressure-coupling algorithm and that an increased integration time step of 5 fs can be safely used in simulations of phosphatidylcholine lipid bilayers. ...|$|R
40|$|The first {{renormalization}} group map {{arising from}} the momentum space decomposition of a weakly coupled system of fermions at temperature zero differs from all subsequent maps. Namely, the component of momentum dual to temperature may be arbitrarily large — there is no ultraviolet <b>cutoff.</b> The <b>methods</b> of Part 1 are supplemented t...|$|R
40|$|The {{adequacy}} of diets {{can be assessed}} using several analytical approaches. This paper reviews two methods of assessment: a <b>cutoff</b> <b>method,</b> which estimates {{the percentage of the}} population having usual intakes below a given value; and a probability method, which assesses the percentage of the population whose usual intakes are below their individual requirements. First, the concept of usual nutrient intakes and the problems associated with estimating usual intake distributions are discussed. Next, the two methods of dietary assessment and their related assumptions are described and compared. The more specific inference of the probability method is shown to rely on its assumptions and data that are currently not available. While the <b>cutoff</b> <b>method</b> is simpler, its use may result in misclassification errors and its estimates are highly influenced by the cut-off standard selected. ...|$|E
40|$|A general {{method is}} {{presented}} to calculate absolute binding energies of core levels in metals and insulators, based on a penalty functional and an exact Coulomb <b>cutoff</b> <b>method</b> in a framework of the density functional theory. The spurious interaction of core holes between supercells is avoided by the exact Coulomb <b>cutoff</b> <b>method,</b> while the variational penalty functional enables us to treat multiplet splittings due to chemical shift, spin-orbit coupling, and exchange interaction on equal footing, {{both of which are}} not accessible by previous methods. It is demonstrated that the absolute binding energies of core levels for both metals and insulators are calculated by the proposed method in a mean absolute (percentage) error of 0. 4 eV (0. 16 %) for eight cases compared to experimental values measured with X-ray photoemission spectroscopy within a generalized gradient approximation to the exchange-correlation functional. Comment: 6 pages, 4 figures, a supplemental tabl...|$|E
40|$|Abstract — This paper {{examines}} {{the use of}} Voronoi tessellations of proteins for generating contact maps, and compares it to existing methods. A Voronoi tesselation is computed on the three dimensional protein data, with each amino acid as a site. If two reigions in the Voronoi tesselation share a face, then the amino acids that created the regions are considered in contact. Amino acids are represented by points at their geometric centers. A simple <b>cutoff</b> <b>method</b> {{will be used for}} comparison. The results show that the Voronoi tessellation method can produce accurate, unambiguous contact maps. The new maps have on average 30 % fewer contacts, yet retain the patterns found on the maps produced by the <b>cutoff</b> <b>method.</b> More importantly, the data allowed us to tune the cutoff distance used in the reference method, justifying the choice of this parameter. Index Terms — voronoi tesselation, contact map, protein Geometric Structure...|$|E
40|$|Abstract. The first {{renormalization}} group map {{arising from}} the momentum space decomposition of a weakly coupled system of fermions at temperature zero differs from all subsequent maps. Namely, the component of momentum dual to temperature may be arbitrarily large – there is no ultraviolet <b>cutoff.</b> The <b>methods</b> of Part 1 are supplemented to control this special case...|$|R
40|$|For linear inverse {{problems}} Y = Aµ + ξ, it is classical {{to recover}} the unknown signal µ by iterative regularisation methods (µ (m), m = 0, 1,...) so that the weak (or prediction) error A(µ (τ) − µ) 2 is controlled for some early stopping rule τ based on a discrepancy principle. In the context of statistical estimation with stochastic noise ξ, we study oracle adaptation in strong squared-error E µ (τ) − µ 2. We give precise lower bounds for estimation by early stopping. For a stopping rule based on the residual process oracle adaptation bounds are established for general linear iterative methods. The proofs use bias and variance transfer techniques from weak prediction error to strong L 2 -error as well as convexity arguments and concentration bounds for the stochastic part. For Sobolev balls the adaptation bounds are shown to match the lower bounds. Adaptive early stopping for the Landweber and spectral <b>cutoff</b> <b>methods</b> are studied in further detail...|$|R
40|$|This paper {{presents}} {{two techniques}} for language model (LM) adaptation. The first aims {{to build a}} more general LM. We propose a distribution-based pruning of n-gram LMs, where we prune n-grams {{that are likely to}} be infrequent in a new document. Experimental results show that the distribution-based pruning method performed up to 9 % (word perplexity reduction) better than conventional <b>cutoff</b> <b>methods.</b> Moreover, the pruning method results in a more general ngram backoff model, in spite of the domain, style, or temporal bias in the training data. The second aims to build a more task-specific LM. We propose an n-gram distribution adaptation method for LM training. Given a large set of out-of-task training data, called training set, andasmall set of task-specific training data, called seed set, we adapt the LM towards the task by adjusting the n-gram distribution in the training set to that in the seed set. Experimental results show non-trivial improvements over conventional methods. 1...|$|R
40|$|The <b>cutoff</b> <b>method,</b> which {{cuts off}} {{the values of}} a {{function}} less than a given number, is studied for the numerical computation of nonnegative solutions of parabolic partial differential equations. A convergence analysis is given for a broad class of finite difference methods combined with cutoff for linear parabolic equations. Two applications are investigated, linear anisotropic diffusion problems satisfying {{the setting of the}} convergence analysis and nonlinear lubrication-type equations for which it is unclear if the convergence analysis applies. The numerical results are shown to be consistent with the theory and in good agreement with existing results in the literature. The convergence analysis and applications demonstrate that the <b>cutoff</b> <b>method</b> is an effective tool for use in the computation of nonnegative solutions. Cutoff can also be used with other discretization methods such as collocation, finite volume, finite element, and spectral methods and for the computation of positive solutions. Comment: 19 pages, 41 figure...|$|E
40|$|We derive simple new expressions, {{in various}} dimensions, for the {{functional}} determinant of a radially separable partial differential operator, thereby generalizing the one-dimensional result of Gel'fand and Yaglom to higher dimensions. We use the zeta function formalism, {{and the results}} agree with what one would obtain using the angular momentum <b>cutoff</b> <b>method</b> based on radial WKB. The final expression is numerically equal to an alternative expression derived in a Feynman diagrammatic approach, but is considerably simpler. Comment: 21 pages, uses axodraw. st...|$|E
40|$|Our previously-developed calculational method (the partial wave <b>cutoff</b> <b>method)</b> is {{employed}} to evaluate explicitly scalar one-loop effective actions {{in a class}} of radially symmetric background gauge fields. Our method proves to be particularly effective when it is used in conjunction with a systematic WKB series for the large partial wave contribution to the effective action. By comparing these numerically exact calculations against the predictions based on the large mass expansion and derivative expansion, we discuss the validity ranges of the latter approximation methods. Comment: 30 pages, 9 figures, RevTe...|$|E
40|$|We {{present a}} method for {{estimating}} the significant wave height of ocean waves (SWH) in coastal zones from satellite SAR images and using {{the value of the}} width of the spectral azimuthal <b>cutoff.</b> The <b>method</b> deals with the case of an energetic swell propagating over a wind wave system. It requires the preliminary retrieval of swell parameters using the wave-SAR spectral quasi-linear relationship. The method is applied to two ERS- 1 SAR images in coastal zones...|$|R
40|$|The three-loop {{effective}} {{potential of}} the massless O(N) φ 4 theory is calculated analytically using techniques of dimensional regularization. We see a complete agreement between our result and Jackiw’s result obtained only up to two-loop order using a different regularization (<b>cutoff</b> regularization) <b>method,</b> but the same renormalization conditions. For an easy check of the mutual cancellation of all the dangerous pole terms in each loop order, we give the ǫ-expanded loop integrals in full detail. I...|$|R
40|$|Here, {{we present}} the program QContacts, which {{implements}} Voronoi polyhedra to determine atomic and residue contacts across the interface of a protein-protein interaction. While QContacts also describes hydrogen bonds, ionic pair and salt bridge interactions, {{we focus on}} QContacts?????? identification of atomic contacts in a protein interface compared against the current methods. Initially, we investigated in detail the differences between QContacts, radial cutoff and Change in Solvent Accessible Surface Area (delta-SASA) methods in identifying pair-wise contacts across the binding interface. The results were assessed based {{on a set of}} 71 double cycle mutants. QContacts excelled at identifying knob-in-hole contacts. QContacts, closest atom radial cutoff and the delta-SASA methods performed well at picking out direct contacts; however, QContacts was the most accurate in excluding false positives. The significance of the differences identified between QContacts and previous methods was assessed using pair-wise contact frequencies in a broader set of 592 protein interfaces. The inaccuracies introduced by commonly used radial <b>cutoff</b> <b>methods</b> were found to produce misleading bias in the residue frequencies. This bias could compromise pair-wise potentials that are based on such frequencies. Here we show that QContacts provides a more accurate description of protein interfaces at atomic resolution than other currently available methods. QContacts is available in a web-based form at [URL] (Fischer et al., 2006) ...|$|R
40|$|The Casimir {{energy for}} the {{transverse}} oscillations of a piecewise uniformclosed string is calculated. The great adaptibility of this string model withrespect to various regularization methods is pointed out. We survey severalregularization methods: the <b>cutoff</b> <b>method,</b> the complex contour integrationmethod, and the zeta-function method. The most powerful method in the presentcase is the contour integration method. The Casimir energy turns out to benegative, and more so the larger {{is the number of}} pieces in the string. Thethermodynamic free energy F is calculated for a two-piece string in the limitwhen the tension ratio x=T_{I}/T_{II} approaches zero...|$|E
40|$|Fibrates lower {{triglycerides}} {{and raise}} HDL cholesterol in dyslipidemic patients, but show heterogeneous treatment response. We used k-means clustering to identify three representative NMR lipoprotein profiles for 775 subjects from the GOLDN population, {{and study the}} response to fenofibrate in corresponding subgroups. The subjects in each subgroup showed differences in conventional lipid characteristics and in presence/absence of cardiovascular risk factors at baseline; there were subgroups with a low, medium and high degree of dyslipidemia. Modeling analysis suggests {{that the difference between}} the subgroups with low and medium dyslipidemia is influenced mainly by hepatic uptake dysfunction, while the difference between subgroups with medium and high dyslipidemia is influenced mainly by extrahepatic lipolysis disfunction. The medium and high dyslipidemia subgroups showed a positive, yet distinct lipid response to fenofibrate treatment. When comparing our subgroups to known subgrouping methods, we identified an additional 33 % of the population with favorable lipid response to fenofibrate compared to a standard baseline triglyceride <b>cutoff</b> <b>method.</b> Compared to a standard HDL cholesterol <b>cutoff</b> <b>method,</b> the addition was 18 %. In conclusion, by using constructing subgroups based on representative lipoprotein profiles, we have identified two subgroups of subjects with positive lipid response to fenofibrate therapy and with different underlying disturbances in lipoprotein metabolism. The total subgroup with positive lipid response to fenofibrate is larger than subgroups identified with baseline triglyceride and HDL cholestero...|$|E
40|$|Closely {{following}} recent {{innovations in}} the literature on the multidimensional measurement of poverty, this paper provides similar measures for the top of the distribution using a dual <b>cutoff</b> <b>method</b> to identify persons, who can be considered as rich in a multidimensional setting. Thereby, the derived measures do not only take into account the number of individuals' affluent dimensions, but are also sensitive to changes in achievements of the rich. We make use of this framework to analyze the role of wealth, in addition to income, as one dimension of multidimensional well-being. In addition we analyze the roles of health and education. We provide empirical evidence for Germany...|$|E
40|$|BioMark is an R package {{implementing}} two meta-strategies {{for finding}} biomarkers. For two-class discrimination problems, Higher Criticism is available, {{an approach to}} define optimal <b>cutoffs</b> for <b>methods</b> like t testing for high-dimensional data. In this work, HC has been extended to multivariate methods, allowing, e. g., selection of biomarkers based {{on the size of}} regression coefficients. A second approach is Stability Selection, considering the consistency of variable selection under perturbation of the data. Both methods have the advantage that they do not rely on error estimates, that in this setting tend to be highly variable...|$|R
40|$|We {{discuss the}} use of <b>cutoff</b> <b>methods</b> in chiral {{perturbation}} theory. We develop a cutoff scheme based on the operator structure of the effective field theory that allows to suppress high momentum contributions in Goldstone boson loop integrals and by construction is free of the problems traditional cutoff schemes have with gauge invariance or chiral symmetries. As an example, we discuss the chiral expansion of the nucleon mass. Contrary to other claims in the literature we show that the mass of a nucleon in heavy baryon chiral perturbation theory has a well behaved chiral expansion up to effective Goldstone boson masses of 400 MeV when one utilizes standard dimensional regularization techniques. With {{the help of the}} here developed cutoff scheme we can demonstrate a well-behaved chiral expansion for the nucleon mass up to 600 MeV of effective Goldstone Boson masses. We also discuss in detail the prize, in numbers of additional short distance operators involved, that has to be paid for this extended range of applicability of chiral perturbation theory with cutoff regularization, which is usually not paid attention to. We also compare the fourth order result for the chiral expansion of the nucleon mass with lattice results and draw some conclusions about chiral extrapolations based on such type of representation. Comment: 19 pp, 8 fig...|$|R
30|$|Usually the T 2 <b>cutoff</b> or SBVI <b>methods</b> are {{typically}} used to partition the BVI of the T 2 distribution. As {{demonstrated in the}} cumulative porosity distribution plot, the partitioning presents estimates for T 2 cutoff and bulk volume irreducible (BVI). As illustrated, this corresponds to the maximum cumulative porosity where irreducible water saturation from the core NMR measurement intercepts the NMR T 2 log.|$|R
40|$|ICSLP 1998 : the 5 th International Conference on Spoken Language Processing, November 30 - December 4, 1998, Sydney, Australia. In {{this paper}} we propose an {{algorithm}} for reducing the size of back-off N-gram models, with less affecting its performance than the traditional <b>cutoff</b> <b>method.</b> The algorithm {{is based on the}} Maximum Likelihood (ML) estimation and realizes an N-gram language model with a given number of N-gram probability parameters that minimize the training set perplexity. To confirm the effectiveness of our algorithm, we apply it to trigram and bigram models, and the experiments in terms of perplexity and word error rate in a dictation system are carried out...|$|E
40|$|This paper {{proposes a}} multi-objective dynamic {{scheduling}} approach that combines three attributes {{based on a}} hybrid multiple attribute decision making (MADM) technique. With consideration of two kinds of uncertainties, three advanced attributes are specifically designed to optimize four key performance measures. Each attribute is converted into a relative closeness to the ideal alternative, and collaborate with the others at each scheduling instant. Furthermore, a <b>cutoff</b> <b>method</b> is {{used to make the}} proposed approach adapt to full-scale semiconductor manufacturing systems (SMSs) better. Results in two SMS models show that the proposed approach is validated for the real-time multi-objective scheduling problem. Dynamic scheduling Multi-objective optimization Multiple attribute decision making (MADM) Semiconductor manufacturing system (SMS) ...|$|E
40|$|A new {{formulation}} of the stochastic potential switching algorithm is presented. This reformulation naturally leads us to a generalized Fourtuin-Kasteleyn representation of the partition function Z. A formula for internal energy E and that of heat capacity C are derived from derivatives of the partition function. We also derive a formula for the exchange probability in the replica exchange Monte Carlo method. By combining the formulae with the Stochastic <b>Cutoff</b> <b>method,</b> we can greatly reduce the computational time to perform internal energy and heat capacity measurements and the replica exchange Monte Carlo method in long-range interacting systems. Numerical simulations in three dimensional magnetic dipolar systems show the validity and efficiency of the method. Comment: 11 pages, 6 figures, to appear in PR...|$|E
40|$|Abstract: The cutoff {{sampling}} technique is sometimes used in establishment surveys in the U. S. Census Bureau. Recently, the Governments Division in the U. S. Census Bureau proposed a new <b>method</b> of <b>cutoff</b> sampling, which modified the traditional cutoff {{sampling technique}}s by constructing the cutoff points {{based on the}} size of units in the strata and then reducing the sample size in the strata with small-sized units. We also introduced a decision-based estimation method as a stratum-wise regression for strata defined first by <b>cutoff</b> sampling <b>methods,</b> and then through stratum-collapsing rules determined from the results of a hypothesis test for equality of regression slopes. Finally, we applied the modified cutoff sampling technique and decision-based estimation for two major surveys of governments: the Annual Survey of Public Employment & Payroll and the Annual Finance Survey...|$|R
40|$|We {{present a}} method to {{parallelize}} the stochastic <b>cutoff</b> (SCO) <b>method,</b> which is a Monte-Carlo method for long-range interacting systems. After interactions are eliminated by the SCO method, we subdivide the lattice into non-interacting interpenetrating sublattices. This subdivision enables us to parallelize Monte-Carlo calculation in the SCO method. Such subdivision is found by numerically solving the vertex coloring of a graph created by the SCO method. We use an algorithm proposed by Kuhn and Wattenhofer to solve the vertex coloring by parallel computation. The present method was applied to a two-dimensional magnetic dipolar system on an L× L square lattice to examine its parallelization efficiency. The result showed that, {{in the case of}} L= 2304, the speed of computation increased about 102 times by parallel computation with 288 processors. Comment: 8 pages, 10 figures; 2 figures are adde...|$|R
40|$|International audienceHigh-order {{harmonic}} emission can {{be confined to}} {{the leading edge of}} an 800 nm driver laser pulse under moderately intense focusing conditions (7 × 10 ^ 14 W/cm^ 2) (Pfeifer et al. in Opt. Express 15 : 17120, 2007). Here, the experimentally observed curtailment of harmonic production on {{the leading edge of the}} driver pulse is shown to be controlled by an ionization-induced phase-matching condition. The transient plasma density inherent to the process of high-harmonic generation terminates the {{harmonic emission}} by an ultrafast loss of phase matching on the leading edge of the laser pulse. The analysis is supported by a reconstruction of the in situ intensity envelope of the driver pulse with attosecond temporal resolution, performed by measurements of the carrier-envelope phase dependence of individual half-cycle harmonic <b>cutoffs.</b> The <b>method</b> opens the way to wavelength-tunable isolated attosecond pulse generation...|$|R
