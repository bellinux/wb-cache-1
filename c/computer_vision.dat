10000|250|Public
5|$|Graph duality {{can help}} explain the {{structure}} of mazes and of drainage basins. Dual graphs have also been applied in <b>computer</b> <b>vision,</b> computational geometry, mesh generation, and the design of integrated circuits.|$|E
5|$|In <b>computer</b> <b>vision,</b> {{the active}} contour model for edge {{detection}} and image segmentation {{is based on}} curve shortening, and evolves curves based {{on a combination of}} their curvature and the features of an image.|$|E
5|$|OmniEarth, Inc. uses Watson <b>computer</b> <b>vision</b> {{services}} to analyze satellite and aerial imagery, {{along with other}} municipal data, to infer water usage on a property-by-property basis, helping water districts in drought-stricken California improve water conservation efforts.|$|E
5000|$|During {{the nineties}} he became {{known for his}} computer-generated fantasy posters, which {{eventually}} resulted in {{a book about his}} 3D illustrations entitled [...] "NEW TERRITORIES - The <b>Computer</b> <b>Visions</b> of Jurgen Ziewe", 1997, by Suckling, N., ...|$|R
5000|$|Brian Barsky (class of 1971) University of California, Berkeley <b>computer</b> scientist, <b>vision</b> scientist, {{professor}} ...|$|R
40|$|Technologies such as {{augmented}} realities, {{mobile and}} locative devices and <b>computer</b> <b>visions</b> systems, when integrated into choreographic practice, can liberate traditional notions of time, space and movement. Panel members explored the specific aesthetic concerns {{and the impact}} on performance practice that results from the convergence of technology and choreography. How does {{the integration of the}} body and technology significantly shift the relationship between the performers and audience...|$|R
5|$|State-of-the-art deep {{neural network}} {{architectures}} can sometimes even rival human accuracy in fields like <b>computer</b> <b>vision,</b> specifically on things like the MNIST database, and traffic sign recognition.|$|E
5|$|In <b>computer</b> <b>vision,</b> {{digital images}} are {{partitioned}} into small square pixels, {{each of which}} has its own color. The dual graph of this subdivision into squares has a vertex per pixel and an edge between pairs of pixels that share an edge; it is useful for applications including clustering of pixels into connected regions of similar colors.|$|E
5|$|Limited {{computer}} power: There was {{not enough}} memory or processing speed to accomplish anything truly useful. For example, Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only twenty words, because {{that was all that}} would fit in memory. Hans Moravec argued in 1976 that computers were still millions of times too weak to exhibit intelligence. He suggested an analogy: artificial intelligence requires computer power {{in the same way that}} aircraft require horsepower. Below a certain threshold, it's impossible, but, as power increases, eventually it could become easy. With regard to <b>computer</b> <b>vision,</b> Moravec estimated that simply matching the edge and motion detection capabilities of human retina in real time would require a general-purpose computer capable of 109 operations/second (1000 MIPS). As of 2011, practical <b>computer</b> <b>vision</b> applications require 10,000 to 1,000,000 MIPS. By comparison, the fastest supercomputer in 1976, Cray-1 (retailing at $5 million to $8 million), was only capable of around 80 to 130 MIPS, and a typical desktop computer at the time achieved less than 1 MIPS.|$|E
40|$|The {{goal is to}} {{describe}} a <b>computer</b> stereo <b>vision</b> system based on the well-known edge detection principles. The system provides surface recovering well enough both for far and close objects using two photos ofthe surface. <b>Computer</b> stereo <b>vision</b> task we define as a task of obtaining a number ofspatial points starting from the pictures ofan object. More exactly, an input ofa program consists oftwo pictures ofa given object, optionally some known points and intrinsic parameters ofthe camera. An output {{is a set of}} spatial points lying on the surface ofthe object that was photographed. <b>Computer</b> stereo <b>vision</b> or photogrammetry task has been widely developing since last several decades. A lot ofpapers an...|$|R
50|$|It {{is used in}} <b>computer</b> stereo <b>vision</b> {{to simplify}} the problem of finding {{matching}} points between images (i.e. the correspondence problem).|$|R
50|$|Foundations and Trends in <b>Computer</b> Graphics and <b>Vision</b> is {{a journal}} {{published}} by Now Publishers. It publishes survey and tutorial articles on {{all aspects of}} <b>computer</b> graphics and <b>vision.</b> The editor-in-chiefs are Brian Curless (University of Washington), Luc Van Gool (KU Leuven) and Richard Szeliski (Microsoft Research).|$|R
25|$|Yet another field {{related to}} <b>computer</b> <b>vision</b> is signal {{processing}}. Many methods for processing of one-variable signals, typically temporal signals, {{can be extended}} in a natural way to processing of two-variable signals or multi-variable signals in <b>computer</b> <b>vision.</b> However, because of the specific nature of images there are many methods developed within <b>computer</b> <b>vision</b> which have no counterpart in processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing {{as a part of}} <b>computer</b> <b>vision.</b>|$|E
25|$|As a {{scientific}} discipline, <b>computer</b> <b>vision</b> {{is concerned with}} the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, <b>computer</b> <b>vision</b> seeks to apply its theories and models for the construction of <b>computer</b> <b>vision</b> systems.|$|E
25|$|Artificial {{intelligence}} and <b>computer</b> <b>vision</b> share other {{topics such as}} pattern recognition and learning techniques. Consequently, <b>computer</b> <b>vision</b> is sometimes seen {{as a part of}} the artificial intelligence field or the computer science field in general.|$|E
5000|$|... #Article: Foundations and Trends in <b>Computer</b> Graphics and <b>Vision</b> ...|$|R
5000|$|... #Caption: [...] Institute for <b>Computer</b> Graphics and <b>Vision</b> (Inffeldgasse 16) ...|$|R
5000|$|Vom Verschwinden des <b>Computers</b> - Die <b>Vision</b> des Ubiquitous Computing ...|$|R
25|$|Each of the {{application}} areas described above employ a range of <b>computer</b> <b>vision</b> tasks; more or less well-defined measurement problems or processing problems, which can be solved {{using a variety of}} methods. Some examples of typical <b>computer</b> <b>vision</b> tasks are presented below.|$|E
25|$|There is a {{subfield}} within <b>computer</b> <b>vision</b> where artificial {{systems are}} designed to mimic the processing and behavior of biological system, {{at different levels of}} complexity. Also, some of the learning-based methods developed within <b>computer</b> <b>vision</b> have their background in biology.|$|E
25|$|<b>Computer</b> <b>vision</b> is {{the science}} and {{technology}} of machines that see. As a scientific discipline, <b>computer</b> <b>vision</b> {{is concerned with the}} theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences and views from cameras.|$|E
5000|$|<b>Computer</b> stereo <b>vision</b> {{with many}} cameras under fixed {{lighting}} is called structure from motion. Techniques using a fixed camera and known lighting are called photometric stereo techniques, or [...] "shape from shading".|$|R
50|$|Clark {{received}} the ACM SIGGRAPH Computer Graphics Achievement Award in 1984. He was {{a recipient of}} the 1997 Kilby International Awards, which honored him for his <b>computer</b> graphics <b>vision</b> and for enabling networked information exchange.|$|R
40|$|Abstract: Humans {{restrict}} knowledge space through perception {{to maintain}} mutual understanding. This provides computational {{basis for the}} communication between humans and <b>computers</b> with <b>vision.</b> To complete the communication channel, machine vision is required to generate object code in noisy imagery. Stochastic – computational representation of self...|$|R
25|$|<b>Computer</b> <b>vision</b> {{includes}} 3D {{analysis from}} 2D images. This analyzes the 3D scene projected onto one or several images, e.g., how to reconstruct structure or other {{information about the}} 3D scene from one or several images. <b>Computer</b> <b>vision</b> often relies on more or less complex assumptions about the scene depicted in an image.|$|E
25|$|The {{organization}} of a <b>computer</b> <b>vision</b> system is highly application dependent. Some systems are stand-alone applications which solve a specific measurement or detection problem, while others constitute a sub-system {{of a larger}} design which, for example, also contains sub-systems for control of mechanical actuators, planning, information databases, man-machine interfaces, etc. The specific implementation of a <b>computer</b> <b>vision</b> system also depends on if its functionality is pre-specified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are, however, typical functions which are found in many <b>computer</b> <b>vision</b> systems.|$|E
25|$|Some {{strands of}} <b>computer</b> <b>vision</b> {{research}} {{are closely related}} to the study of biological vision – indeed, just as many strands of AI research are closely tied with research into human consciousness, and the use of stored knowledge to interpret, integrate and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. <b>Computer</b> <b>vision,</b> on the other hand, studies and describes the processes implemented in software and hardware behind artificial vision systems. Interdisciplinary exchange between biological and <b>computer</b> <b>vision</b> has proven fruitful for both fields.|$|E
5000|$|... 1997 - Cyberscape: A <b>Computer</b> Animation <b>Vision</b> 45 minutes entirely {{created and}} co-produced by award-winning {{computer}} animator Beny Tchaicovsky, a surrealistic, fantastical [...] "recreation" [...] of the milestones of human history, spanning from primordial proto-humans to the idiosyncrasies of modern living. Music score by Peter Bernstein.|$|R
50|$|<b>Computer</b> stereo <b>vision</b> is the {{extraction}} of 3D information from digital images, such as obtained by a CCD camera. By comparing information about a scene from two vantage points, 3D information can be extracted by examination of the relative positions of objects in the two panels. This {{is similar to the}} biological process Stereopsis.|$|R
40|$|Analysis {{of human}} {{activity}} and anomaly detection from video sequences {{is one of the}} hottest and difficult research areas in <b>computer</b> <b>visions.</b> This paper describes a method for pedestrian gait classification and deals with the classification of human gait types based on the notion that gait types can be analyzed into a series of consecutive postures types. First, Silhouettes are extracted using the Background Subtraction method which is combined with the time-stepping method. Then a method using recursion method for establishment of the standard gait state sequence is proposed. Meanwhile, wavelet moment method is used to extract features of the human body image, and the result matrix leads to Discrete Hidden Markov Models. Finally, Bayesian classifier is proposed to recognize the gait classification of human motion. The experiment tests show some encouraging results, also shows the capability of real-time performance, which indicate that the method could be a choice for solving the problem but more tests are required...|$|R
25|$|Solid-state {{physics is}} another field that {{is closely related}} to <b>computer</b> <b>vision.</b> Most <b>computer</b> <b>vision</b> systems rely on image sensors, which detect {{electromagnetic}} radiation, which is typically in the form of either visible or infra-red light. The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Also, various measurement problems in physics can be addressed using <b>computer</b> <b>vision,</b> for example motion in fluids.|$|E
25|$|Gesture {{recognition}} can {{be conducted}} with techniques from <b>computer</b> <b>vision</b> and image processing.|$|E
25|$|Photogrammetry also {{overlaps}} with <b>computer</b> <b>vision,</b> e.g., stereophotogrammetry vs. computer stereo vision.|$|E
40|$|Includes bibliographical {{references}} (pages 44 - 47) With {{the prevalence}} of smart phones in our daily lives, sharing images has become {{an important part of}} social networking and communication. Along with sharing a photo, users often include a tag, short text related to the subject of the image. When someone uploads a photo to an image sharing website, with a tag indicating the location where the photo was taken, are these user submitted location tags accurate? This thesis examines the accuracy of geotagging of social media content, specifically of photos. Geo-location metadata from photos along with reverse geocoding of latitude and longitude coordinates is used to analyze the geotagging phenomena and its accuracy. It then proposes an approach for auto geotagging images, leveraging <b>computer</b> <b>vision???s</b> object recognition techniques. Specifically, images with the presence of a city landmark are used to assign a geotag to the photos. The accuracy of the auto geotagging is determined using a large of set of photos taken from Flickr...|$|R
5000|$|G. T. Toussaint, “Computational {{geometry}} and <b>computer</b> vision,” in <b>Vision</b> Geometry, Contemporary Mathematics, Volume 119, R. A. Melter, A. Rozenfeld and P. Bhattacharya, Editors, American Mathematical Society, 1991, pp. 213-224.|$|R
40|$|In {{the last}} decade, Augmented Reality {{has become more}} mature and is widely adopted on mobile devices. Exploring the {{available}} information of a user's environment {{is one of the}} key applications. However, current mobile Augmented Reality interfaces are very limited compared to the recently emerging big data exploration tools for desktop <b>computers.</b> Our <b>vision</b> is to bring powerful Visual Analytic tools to mobile Augmented Reality...|$|R
