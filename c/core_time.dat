33|691|Public
2500|$|... /YEAR=yyyy [...] Instructs the Windows <b>core</b> <b>time</b> {{function}} {{to ignore the}} year that the computer's real-time clock reports and instead use the one indicated. Example: /YEAR=2001. (This switch was created to assist in Y2K testing.) ...|$|E
5000|$|The <b>core</b> <b>time</b> {{scale is}} derived from the {{measured}} depth scale by a model incorporating surface snow accumulation variations, ice thinning, basal heat fluxes etc., and is empirically [...] "tied" [...] at 4 times by matches to the marine isotopic record.|$|E
40|$|Recent {{extensions}} to the SMPS format have vastly {{increased the}} range of stochastic linear programs that can be expressed within the format. This paper illustrates some {{of the features of}} SMPS using sample problems from the literature. For each problem, we give the general mathematical formulation, a small illustrative instance and the SMPS <b>core,</b> <b>time</b> and stoch files...|$|E
60|$|Luck obeys the downright striker; {{from the}} hollow <b>core,</b> Fifty <b>times</b> the Brahmins' offer deluged all the floor.|$|R
40|$|This paper {{proposes a}} wrapper design for {{interconnects}} with guaranteed bandwidth and latency services and on-chip protocol. We demonstrate that these interconnects abstract the interconnect details and provide predictability {{in the data}} transfer, which are desirable {{not only for the}} functional domain but also for the test application. The proposed wrapper is implemented in VHDL and integrated to the Æthereal NoC. The results show the impact of of bandwidth in the <b>core</b> test <b>time.</b> The wrapper area and <b>core</b> test <b>time</b> are compared with a wrapper design for dedicated TAM. 1...|$|R
50|$|The ring is {{essentially}} identical {{in shape and}} performance to the toroid, except that inductors commonly pass only {{through the center of}} the core, without wrapping around the <b>core</b> multiple <b>times.</b>|$|R
40|$|It is not {{transparent}} from single <b>core</b> <b>time</b> to multi-core {{time for}} programmer {{not like the}} enhancement of clock frequency of processor, and if we don’t design the programs what we compile aiming at multi-core characters, we can not obtain the enhancement of performance from multi cores. In this alternative time {{of old and new}} concepts, we should fully use former development experiences for references...|$|E
3000|$|... i 7 - 3970 3.50 GHz × 12, Memory 32 GB, C++ implementation). The <b>core</b> <b>time</b> for {{computation}} {{spent for}} solving a convex optimization problem in Eq. (8). In this experiment, 5.3 GB memory {{was required for}} our implementation. When we set F= 89, {{it takes more than}} 1 week for 4 -D light field reconstruction. In order to reduce the cost, we should find more efficient bases for representing light field and efficient way for solving the problem.|$|E
40|$|Abstract-This paper {{proposes a}} new {{scheduler}} applying {{the concept of}} non-uniform laxity to Earliest Deadline First (EDF) approach for aperiodic tasks. This scheduler improves task utilisation (Execution time / deadline) and also increases the number of tasks that are being scheduled. Laxity {{is a measure of}} the spare time permitted for the task before it misses its deadline, and is computed using the expression (deadline-(current time + execution time)). Weight decides the priority of the task and is defined by the expression ((quantum slice time / allocated time) *total <b>core</b> <b>time</b> for the task). Quantum slice time is the time actually used, allocated time is the time allocated by the scheduler, and total <b>core</b> <b>time</b> is the time actually reserved by the core for execution of one quantum of the task. Nonuniform laxity enables scheduling of tasks that have higher priority before the normal execution of other tasks and is computed by multiplying the weight of the task with its laxity. The algorithm presented in the paper has been simulated on Cheddar, a real time scheduling tool and also on SESC, an architectural simulator for multicore platforms. The algorithm has been tested varying random task sets upto 5000 and number of cores upto 100. The algorithm improves task utilisation by 35 % and increases the number of tasks scheduled by 36 %, compared to conventional EDF...|$|E
40|$|We {{clarify the}} {{mechanism}} of accelerated core formation by large-scale nonlinear flows in subcritical magnetic clouds by finding a semi-analytical formula for the <b>core</b> formation <b>time</b> and describing the physical processes that lead to them. Recent numerical simulations show that nonlinear flows induce rapid ambipolar diffusion that leads to localized supercritical regions that can collapse. Here, we employ non-ideal magnetohydrodynamic simulations including ambipolar diffusion for gravitationally stratified sheets threaded by vertical magnetic fields. One of the horizontal dimensions is eliminated, resulting in a simpler two-dimensional simulation that can clarify the basic process of accelerated core formation. A parameter study of simulations shows that the <b>core</b> formation <b>time</b> is inversely proportional to {{the square of the}} flow speed when the flow speed is greater than the Alfvén speed. We find a semi-analytical formula that explains this numerical result. The formula also predicts that the <b>core</b> formation <b>time</b> is about three times shorter than that with no turbulence, when the turbulent speed is comparable to the Alfvén speed. Comment: 22 pages, 9 figures, accepted for publication in Ap...|$|R
50|$|Stalcup, old-school to the <b>core,</b> {{wasted no}} <b>time</b> cutting Phelps for the misdeed.|$|R
30|$|The {{operational}} ROMS runs on our HPC cluster using from 32 {{central processing}} unit (CPU) cores to 48 CPU <b>cores.</b> The <b>time</b> taken to complete a 7 -day forecast is approximately 3  h with this configuration on the HPC cluster.|$|R
40|$|This paper {{proposes a}} new {{scheduler}} applying {{the concept of}} non-uniform laxity to Earliest deadline first (EDF) approach for aperiodic tasks. This scheduler improves task utilisation (Execution time / deadline) and also increases the number of tasks that are being scheduled. Laxity {{is a measure of}} the spare time permitted for the task before it misses its deadline, and is computed using the expression (deadline - (current time + execution time)). Weight decides the priority of the task and is defined by the expression (quantum slice time / allocated time) *total <b>core</b> <b>time</b> for the task. Quantum slice time is the time actually used, allocated time is the time allocated by the scheduler, and total <b>core</b> <b>time</b> is the time actually reserved by the core for execution of one quantum of the task. Non-uniform laxity enables scheduling of tasks that have higher priority before the normal execution of other tasks and is computed by multiplying the weight of the task with its laxity. The algorithm presented in the paper has been simulated on Cheddar, a real time scheduling tool and also on SESC, an architectural simulator for multicore platforms, for upto 5000 random task sets, and upto 5000 cores. This scheduler improves task utilisation by 35 % and the number of tasks being scheduled by 36 %, compared to conventional EDF. Comment: 7 pages, Journal of Computer Science and Information Securit...|$|E
40|$|A {{method to}} {{describe}} unresolved processes in meteorological models by physically based stochastic processes (SP) is {{proposed by the}} example of an energy budget model (EBM). Contrary to the common approach using additive white noise, a suitable variable within the model is chosen to be represented by a SP. Spectral analysis of ice <b>core</b> <b>time</b> series shows a red noise character of the underlying fluctuations. Fitting Ornstein Uhlenbeck processes to the observed spectrum defines the parameters for the stochastic dynamic model (SDM). Numerical simulations for different sets of ice core data lead to three sets of strongly differing systems. Pathwise, statistical and spectral analysis of these models show the importance of carefully choosing suitable stochastic terms {{in order to get}} a physically meaningful SDM...|$|E
40|$|This paper {{considers}} a generalisation {{of the classical}} RCPSP problem: the resource consumption of each task is continuously varying over time and the duration {{and the start of}} each task may vary within real intervals. A first contribution is a general model for describing the resource consumption of a task over time. This model is justified when considering continuously divisible resources. The second contribution is the computation of the compulsory part or <b>core</b> <b>time</b> of such a task. The compulsory part gives the task's resource consumption common to all feasible schedules. Hence, it {{can be used in a}} global resolution process such as constraint programming or branch and bound approaches. The presented polynomial algorithms use only two particular schedules of that task. ...|$|E
50|$|Ultra-Awaken: A {{variation}} of Awaken where {{the spirit is}} refreshed each <b>time</b> <b>cores</b> are placed on it.|$|R
5000|$|... memory unit: 4096 12-bit {{words of}} <b>core</b> memory (access <b>time</b> 2.5 microseconds, memory cycle time 16 microseconds) ...|$|R
40|$|Program uses minimal <b>core</b> and <b>time</b> {{resources}} and performs following analysis functions: artwork verification, device identification, nodal analysis, capacitance calculation, and logic equation generation. For data base simplicity, program processing operates on mask data {{which has been}} coverted from its original form to orthogonal rectangles...|$|R
40|$|Antarctica) Dome C {{drilling}} in East Antarctica {{has now been}} completed {{to a depth of}} 3260 m, at only a few meters above bedrock. Here we present the new EDC 3 chronology, which is based on the use of 1) a snow accumulation and mechanical flow model, and 2) a set of independent age markers along the core. These are obtained by pattern matching of recorded parameters to either absolutely dated paleoclimatic records, or to insolation variations. We show that this new time scale is in excellent agreement with the Dome Fuji and Vostok ice <b>core</b> <b>time</b> scales back to 100 kyr within 1 kyr. Discrepancies larger than 3 kyr arise during MIS 5. 4, 5. 5 and 6, which points to anomalies in either snow accumulation o...|$|E
40|$|A mobile {{hand held}} battery powered sensor based on fringe {{projection}} technique for preservation of fossil traces and archaeological excavations was developed. It {{consists of a}} projector and two cameras and covers a measuring field of about 240 mm x 175 mm x 160 mm. The <b>core</b> <b>time</b> for data acquisition is 0. 34 s and the final result of a 3 D point cloud is obtained {{in less than five}} seconds. Errors due to movements of the sensor are detected and can be swept out. The sensor allows the capturing of 3 D data of the observed surface together with colour information. It was successfully applied at fossil find of traces of a dinosaur at rock layers from Triassic. 3 D reconstruction of a part of the excavation was realized including the determination of the depth of traces...|$|E
40|$|Normal 0 7. 8 ? 0 2 false false false MicrosoftInternetExplorer 4 &# 13; /* Style Definitions */&# 13; table. MsoNormalTable&# 13; {mso-style-name:????;&# 13; mso-tstyle-rowband-size: 0;&# 13; mso-tstyle-colband-size: 0;&# 13; mso-style-noshow:yes;&# 13; mso-style-parent:"";&# 13; mso-padding-alt: 0 cm 5. 4 pt 0 cm 5. 4 pt;&# 13; mso-para-margin: 0 cm;&# 13; mso-para-margin-bottom:. 0001 pt;&# 13; mso-pagination:widow-orphan;&# 13; font-size: 10. 0 pt;&# 13; font-family:"Times New Roman";&# 13; mso-fareast-font-family:"Times New Roman";&# 13; mso-ansi-language:# 0400;&# 13; mso-fareast-language:# 0400;&# 13; mso-bidi-language:# 0400;}&# 13; It is not {{transparent}} from single <b>core</b> <b>time</b> to multi-core {{time for}} programmer {{not like the}} enhancement of clock frequency of processor, and if we don’t design the programs what we compile aiming at multi-core characters, we can not obtain the enhancement of performance from multi cores. In this alternative time {{of old and new}} concepts, we should fully use former development experiences for references. </p...|$|E
40|$|International audienceThe goal of {{this study}} is to analyze the {{previously}} unexplored gender and age specific relationship of flextime with absenteeism. This work is based on a French national survey on work organization and working conditions carried out on 25 000 employees. The approach taken is a quantitative analysis with a multinomial logit model. Contrary to the previous results, as we control the confounding effect of work organization and working conditions, flexible schedule is not significantly associated with job satisfaction and health, except for juniors for whom flexible schedule without <b>core</b> <b>times</b> is positively related to job satisfaction. The main contribution of our study is to relativize the effectiveness of flextime in decreasing absenteeism of women. Our research suggests that actions on work organization and working conditions are more effective to reduce women's absenteeism...|$|R
40|$|We analyze {{spatially}} and temporally resolved {{spectra of}} the fundamental vibration-rotation transitions of carbon monoxide (CO) in the solar spectrum at 4. 67 micrometers. Our observations imply that, in the quiet Sun, spatial variations in CO intensity are largely dynamical in nature, reinforcing the suggestion that dynamical effects {{play a key role}} in the formation of the dark CO <b>cores.</b> <b>Time</b> sequences of resolved spectra exhibit mainly 3 minute power in line-core intensity but mainly a 5 minute period in Doppler shift. The weak 7 - 6 R 68 line shows normal Evershed flow in the penumbra of a sunspot; we find evidence for the onset of inverse Evershed flow in the strong 3 - 2 R 14 line. Spectra at the limb indicate that 3 - 2 R 14 emission extends approximately 360 km beyond the continuum limb...|$|R
5000|$|... #Caption: The ALEPH {{detector}} had at its <b>core</b> a <b>time</b> projection chamber {{for detecting}} {{the direction and}} momenta of charged particles with extreme accuracy. In the foreground from the left, Jacques Lefrancois, Jack Steinberger, Lorenzo Foa and Pierre Lazeyras. ALEPH was an experiment on the LEP accelerator, which studied high-energy collisions between electrons and positrons (1989-2000) ...|$|R
40|$|Background Omitted or missed doses {{are common}} to all {{patients}} within an acute setting and are {{the second most common}} medication related incident in paediatrics. 1 Literature reported rates varying from 2. 4 % to 13 %. 2 The National Patient Safety Agency (NPSA) published a report highlighting potential harm from omitted and delayed medicines. 3 Five recommendations were made to reduce harm. A missed dose was defined by the NPSA, as a dose given more than one hour later than the prescribed time; omissions as no documentation for not administering the dose. In response to this report the Paediatric Intensive Care Unit (PICU) at Birmingham Children’s Hospital produced a <b>core</b> <b>time</b> critical list of medicines. Aims To assess the compliance with the NPSA’s recommenda-tions and the local resultant core critical list. To determine which medicines were missed most frequently, and establis...|$|E
40|$|Abstract — Bioinformatics {{applications}} are computationally very expensive programs. They work with large data sets and also consume {{a lot of}} CPU cycles and often require high degrees of precision. An important application {{in this area is}} tertiary structure prediction of proteins. This paper reports a codesign methodology to build hardware accelerators to minimize the running time of a protein energy minimization algorithm. It has been shown that significant speedups can be obtained by moving <b>core</b> <b>time</b> consuming functions onto an FPGA. It has been shown that a 5 fold decrease in the run time of the application can be achieved by simply moving one core function into hardware. Upto an order of magnitude improvement in runtimes can be obtained by moving two functions (core functions in many other bioinformatics applications) which consume 99 % of the CPU cycles in the chosen application. A generalized speedup analysis using single and multiple FPGA cards has also been presented. I...|$|E
40|$|AbstractModern Cooperative Engineering {{approaches}} {{suggest a}} transparent tracking of production costs during development stages. The traditional concept of Engineered Hours per Product, originally {{developed for the}} automotive industry, focusses on specific production and assembly times. Necessary but auxiliary tasks are ignored since their reduction is within the domain of production departments. Thereby this approach promotes the decrease of production time but does not give an adequate measure to compare design alternatives. This paper presents a complementary approach {{based on the assumption}} that the production system has reached a stable status and remains relatively constant for new variants. Based on existing products <b>core</b> <b>time</b> drivers based on features are successively identified until an adequate approximation of the time for the current product is achieved. Those time drivers thereby include the total time to perform the task, including auxiliary task and can be used during the development stage. The paper concludes with an industrial case study to illustrate the benefits...|$|E
50|$|<b>Core</b> {{memory cycle}} <b>times</b> were 20 microseconds for the Model I, 10 microseconds for the Model II (about a {{thousand}} times slower than typical computer main memory in 2006).|$|R
40|$|HALO: Heterogeneity-Aware Load Balancing is a {{paper that}} proposes {{a class of}} heterogeneity-aware Load Balancers (LBs) for cluster systems. LBs that are heterogeneity-aware are able to detect when servers differ in speeds and in number of <b>cores.</b> Response <b>times</b> for {{heterogeneous}} systems are calculated and presented. Comment: 3 pages, 2 charts, Report on HALO: Heterogeneity-Aware Load Balancing for independent study at O. S. ...|$|R
30|$|We run the {{experiments}} {{on a personal}} computer with four 3.19 Hz processors, and 12 GB memory. Most of the time, the usage of CPU is around 30 %, that is, {{the power of a}} single <b>core.</b> The <b>time</b> cost for training one Gaussian process is 6.5 h, and predicting one dimension is 3.1 min. And the time cost for calculating the vocabulary is 0.2 s.|$|R
40|$|A hybrid QMC-VMC {{approach}} {{similar to}} a previously used "damped core" method for separating valence and <b>core</b> <b>time</b> scales is used here to perform nonadiabatic calculations. A number of simple trial wave functions are constructed. Variational and hybrid energies are calculated for the system HD +. An energy of - 0. 59784 (4) hartree is obtained with relatively little computational effort, to {{be compared to the}} exact result of - 0. 5978979 [...] . hartree. The Monte Carlo result is essentially exact, despite the hybrid approximation. Additional precision is obtainable by running longer simulations. Also of note is how much better the hybrid result is than the variational energy obtained from the same wave function. This variational energy is - 0. 59652 (2) hartree. 2. Introduction Systems with a large number of correlated degrees of freedom present formidable difficulties in simulations of physical problems. This is manifested by a power-law increase in relevant time scales such as decorrelatio [...] ...|$|E
40|$|We {{report on}} the results of a recent blind search survey for gamma-ray pulsars in Fermi Large Area Telescope (LAT) data being carried out on the {{distributed}} volunteer computing system, Einstein@Home. The survey has searched for pulsations in 118 unidentified pulsar-like sources, requiring about 10, 000 years of CPU <b>core</b> <b>time.</b> In total, this survey has resulted in the discovery of 17 new gamma-ray pulsars, of which 13 are newly reported in this work, and an accompanying paper. These pulsars are all young, isolated pulsars with characteristic ages between 12 kyr and 2 Myr, and spin-down powers between 10 ^ 34 and 4 × 10 ^ 36 erg/s. Two of these are the slowest spinning gamma-ray pulsars yet known. One pulsar experienced a very large glitch Δ f/f ≈ 3. 5 × 10 ^- 6 during the Fermi mission. In this, the first of two associated papers, we describe the search scheme used in this survey, and estimate the sensitivity of our search to pulsations in unidentified Fermi-LAT sources. One such estimate results in an upper limit of 57...|$|E
40|$|International audienceThe EPICA (European Project for Ice Coring in Antarctica) Dome C {{drilling}} in East Antarctica {{has now been}} completed {{to a depth of}} 3260 m, at only a few meters above bedrock. Here we present the new EDC 3 chronology, which is based on the use of 1) a snow accumulation and mechanical flow model, and 2) a set of independent age markers along the core. These are obtained by pattern matching of recorded parameters to either absolutely dated paleoclimatic records, or to insolation variations. We show that this new time scale is in excellent agreement with the Dome Fuji and Vostok ice <b>core</b> <b>time</b> scales back to 100 kyr within 1 kyr. Discrepancies larger than 3 kyr arise during MIS 5. 4, 5. 5 and 6, which points to anomalies in either snow accumulation or mechanical flow during these time periods. We estimate that EDC 3 gives accurate event durations within 20 % (2 s) back to MIS 11 and accurate absolute ages with a maximum uncertainty of 6 kyr back to 800 kyr...|$|E
50|$|Jupiter has a rock and/or ice <b>core</b> 10-30 <b>times</b> {{the mass}} of the Earth, and this core is likely soluble in the gas {{envelope}} above, and so primordial in composition. Since the core still exists, the outer envelope must have originally accreted onto a previously existing planetary core. Thermal contraction/evolution models support the presence of metallic hydrogen within the core in large abundances (greater than Saturn).|$|R
40|$|In a randomized, {{controlled}} study, {{we found}} that convective warming after hypothermic cardiopul-monary bypass did not accelerate the rate of warming of the body <b>core</b> or the <b>time</b> to tracheal extubation. The relationship between body core and shell temperature, however, was affected. In all patients inadequate time spent rewarming on cardiopulmonary bypass prolonged body <b>core</b> warming <b>time</b> and time to tracheal extubation. Rate of warming of body core was inversely related to body mass index. Convective warming was de-livered using BairHugger (Augustine Medical Inc., MN, USA) and WarmTouch (Mallinckrodt Medical UK Ltd, Northampton, UK) blankets. There {{was no difference between}} the performance of each blanket when powered by the BairHugger 500 power unit set at its medium setting of 38 °C, and when chest drain and radial artery cannulation sites were lef...|$|R
50|$|Dense {{instruction}} coding, {{and extensive}} use of the register sets, meant that relatively few store accesses were needed for common scientific codes, such as scalar product and polynomial inner loops. This did much to offset the relatively slow <b>core</b> cycle <b>time,</b> giving the KDF9 {{about a third of}} the speed of its much more famous, but 8 times more expensive and much less commercially successful contemporary, the Manchester/Ferranti Atlas Computer.|$|R
