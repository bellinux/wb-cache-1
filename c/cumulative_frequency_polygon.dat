0|682|Public
40|$|Normal {{values have}} been {{established}} for haemoglobin and plasma calcium, inorganic phosphate, magnesium, iron and copper {{in the blood of}} Angora goats maintained in the Cape Midlands of South Africa. With the exception of the values obtained for haemoglobin, the data collected for these determinations present slightly to considerably skewed distribution curves. Normal values {{have been established}} by using <b>cumulative</b> relative <b>frequency</b> <b>polygons</b> constructed from these data. The journals have been scanned in colour with a HP 5590 scanner; 600 dpi. Adobe Acrobat v. 11 was used to OCR the text and also for the merging and conversion to the final presentation PDF-format...|$|R
40|$|A {{piecewise}} linear competitor to the <b>frequency</b> <b>polygon,</b> the edge <b>frequency</b> <b>polygon,</b> is proposed: instead of joining histogram ordinates at midpoints of bins by straight lines, one connects values at bin edges by straight lines, those values being averages of contiguous histogram ordinates. The new proposal {{is as simple}} and interpretable as the ordinary <b>frequency</b> <b>polygon</b> while holding theoretical and practical advantages...|$|R
40|$|The {{purpose of}} this paper is to {{investigate}} the <b>frequency</b> <b>polygon</b> as a density estimator for stationary strong mixing processes. Optimal bin widths which asymptotically minimize integrated mean square errors (IMSE) are derived. Under weak conditions, <b>frequency</b> <b>polygons</b> achieve the same rate of convergence to zero of the IMSE as kernel estimators. They can also attain the optimal uniform rate of convergence ((n- 1 logn) 1 / 3 under general conditions. <b>Frequency</b> <b>polygons</b> thus appear to be very good density estimators with respect to both criteria of IMSE and uniform convergence. Density estimation Mixing process Bin width <b>Frequency</b> <b>polygons...</b>|$|R
5000|$|The <b>cumulative</b> <b>frequencies</b> are plotted, and PSM advocates claim interpretive qualities {{exist for}} any {{intersecting}} of the <b>cumulative</b> <b>frequencies</b> {{for each of}} the four price categories. Note that the standard method requires that two of the four <b>cumulative</b> <b>frequencies</b> must be inverted in order to have the possibility of four intersecting points. Conventional practice inverts the <b>cumulative</b> <b>frequencies</b> for [...] "too cheap" [...] and [...] "cheap".|$|R
40|$|Jones et al. (Biometrica 85, 235) {{proposed}} an edge <b>frequency</b> <b>polygon</b> estimator to estimate a probability density function. Their estimator has a smaller asymptotic mean integrated squared error {{than that of}} the <b>frequency</b> <b>polygon</b> estimator. In this paper we introduce a generalized edge <b>frequency</b> <b>polygon</b> estimator. Instead of averaging heights of two bins at each bin edge, we take weighted averages of the heights in the neighboring 2 k (k[greater-or-equal, slanted] 1) bins, which further reduces the asymptotic mean integrated squared error. Density estimation Histogram Integrated squared error...|$|R
30|$|As {{pointed out}} by Scott [5], the <b>frequency</b> <b>polygon</b> has {{convergence}} rates {{similar to those of}} kernel density estimators and greater than the rate for a histogram. As for computation, the computational effort of the <b>frequency</b> <b>polygon</b> is equivalent to the one of the histogram. For large bivariate data sets, the computational simplicity of the <b>frequency</b> <b>polygon</b> and the ease of determining exact equiprobable contours may outweigh the increased accuracy of a kernel density estimator. Bivariate contour plots based on millions of observations are increasingly required in applications including high-energy physics simulation experiments, cell sorters and geographical data representation. Moreover, such data are usually collected in a binned form. Therefore, the <b>frequency</b> <b>polygon</b> can be a useful tool for examination and presentation of data. Since the <b>frequency</b> <b>polygon</b> has the advantages mentioned above, it attracts the attention of some scholars, and they have derived some results. For the explicit results obtained, one can refer to the references listed in Yang and Liang [6] and Xing et al. [7], which gave the strong consistency of <b>frequency</b> <b>polygons.</b> Among the obtained results, the study on asymptotic normality can be found in Carbon et al. [8]. The relevant Berry-Esséen bound for ϕ-mixing samples has not been seen. This motivates us to investigate the Berry-Esséen bound of <b>frequency</b> <b>polygon</b> under ϕ-mixing samples. Under the given assumptions, we give the corresponding Berry-Esséen bound. Furthermore, by the obtained Berry-Esséen bound, the relevant convergence rate of uniformly asymptotic normality is also derived, which is nearly O(n^- 1 / 6) under the given conditions.|$|R
40|$|A {{new data}} structure, namely “cumulative {{frequency}} matrix (CFM) ”, is proposed here for maintaining <b>cumulative</b> <b>frequencies.</b> For an order- 0 model having 256 symbols, CFM is a 2 -D array of 16 rows and 16 columns. Two nibbles, say L for left and R for right, of a byte symbol represents {{row and column}} dimensions respectively. Matrix element (L, R) represents <b>cumulative</b> <b>frequency</b> of symbol with right nibble as R among symbols with left nibble as L. Within row, it stores <b>cumulative</b> <b>frequency</b> of symbols with right nibble varying from 0 to 15. Adaptive arithmetic coding is a lossless data compression method. It needs to update <b>cumulative</b> <b>frequencies</b> at runtime. Various algorithms for maintaining <b>cumulative</b> <b>frequencies,</b> computing <b>cumulative</b> <b>frequency</b> interval etc. are discussed here. Practical implementation shows that proposed data structure is simpler as well as efficient as compared to other data structures in use...|$|R
50|$|<b>Cumulative</b> <b>frequency</b> {{analysis}} is {{the analysis of}} the frequency of occurrence of values of a phenomenon less than a reference value. The phenomenon may be time- or space-dependent. <b>Cumulative</b> <b>frequency</b> is also called frequency of non-exceedance.|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> {{distribution}} with a discontinuity ...|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> {{figure for}} GFMT (short version).|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> {{distribution}} (lognormal) of {{hydraulic conductivity}} (X-data) ...|$|R
50|$|Find the <b>frequencies,</b> {{relative}} <b>frequency,</b> <b>cumulative</b> <b>frequency</b> etc. as required.|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> Histogram, <b>frequency</b> <b>polygon,</b> bin width, object oriented programming, interactive graphics, statistical computing...|$|R
50|$|To {{present the}} <b>cumulative</b> <b>frequency</b> {{distribution}} {{as a continuous}} mathematical equation instead of a discrete set of data, one may try to fit the <b>cumulative</b> <b>frequency</b> distribution to a known cumulative probability distribution,. If successful, the known equation is enough to report the frequency distribution and a table of data will not be required. Further, the equation helps interpolation and extrapolation.However, care should be taken with extrapolating a <b>cumulative</b> <b>frequency</b> distribution, because {{this may be a}} source of errors. One possible error is that the frequency distribution does not follow the selected probability distribution any more beyond the range of the observed data.|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> distribution, adapted <b>cumulative</b> {{probability}} distribution, {{and confidence}} intervals ...|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> of {{simplified}} Chinese {{characters in}} Modern Chinese text ...|$|R
30|$|The bias {{correction}} technique {{adopted in}} this work is the “quantile mapping” one: mean and variability of the simulated values are corrected using the anomaly of the modeled <b>cumulative</b> <b>frequency</b> distribution compared to the observed <b>cumulative</b> <b>frequency</b> distribution. The algorithm systematically removes the median differences to zero and adopts the model output variance characteristics equal to the observed one.|$|R
50|$|One {{way is to}} use the {{relative}} <b>cumulative</b> <b>frequency</b> Fc as an estimate.|$|R
50|$|Probability {{theory can}} help to {{estimate}} the range in which the random error may be.In the case of <b>cumulative</b> <b>frequency</b> {{there are only two}} possibilities: a certain reference value X is exceeded or it is not exceeded. The sum of frequency of exceedance and <b>cumulative</b> <b>frequency</b> is 1 or 100%. Therefore, the binomial distribution can be used in estimating the range of the random error.|$|R
50|$|Further {{it gives}} the option to see the Q-Q plot in terms of {{calculated}} and observed <b>cumulative</b> <b>frequencies.</b>|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> {{analysis}} of the variable annual discharge of a river. Data analyzed with the CumFreq program ...|$|R
40|$|Abstract Background Disparities {{in health}} {{outcomes}} across communities are a central concern {{in public health}} and epidemiology. Health disparities research often links differences in health outcomes to other social factors like income. Choropleth maps of health outcome rates show the geographical distribution of health outcomes. This paper illustrates the use of <b>cumulative</b> <b>frequency</b> map legends for visualizing how the health events are distributed in relation to social characteristics of community populations. The approach uses two graphs in the <b>cumulative</b> <b>frequency</b> legend to highlight {{the difference between the}} raw count of the health events and the raw count of the social characteristic like low income in the geographical areas of the map. The approach is applied to mapping publicly available data on low birth weight by town in Connecticut and Lyme disease incidence by town in Connecticut in relation to income. The steps involved in creating these legends are described in detail so that health analysts can adopt this approach. Results The different health problems, low birth weight and Lyme disease, have different <b>cumulative</b> <b>frequency</b> signatures. Graphing poverty population on the <b>cumulative</b> <b>frequency</b> legends revealed that the poverty population is distributed differently with respect to the two different health problems mapped here. Conclusion <b>Cumulative</b> <b>frequency</b> legends can be useful supplements for choropleth maps. These legends can be constructed using readily available software. They contain all of the information found in standard choropleth map legends, and they can be used with any choropleth map classification scheme. <b>Cumulative</b> <b>frequency</b> legends effectively communicate the proportion of areas, the proportion of health events, and/or the proportion of the denominator population in which the health events occurred that falls within each class interval. They illuminate the context of disease through graphing associations with other variables. </p...|$|R
30|$|Under some mild assumptions, the Berry-Esséen bound of <b>frequency</b> <b>polygons</b> for ϕ-mixing samples is presented. By the bound derived, we {{obtain the}} {{corresponding}} convergence rate of uniformly asymptotic normality, which is nearly O(n^- 1 / 6) under the given conditions.|$|R
5000|$|... #Caption: <b>Cumulative</b> <b>frequency</b> {{distribution}} of the annual average river discharge, showing a large variation. The figure was made with the CumFreq program ...|$|R
5000|$|CumFreq {{uses the}} {{plotting}} position approach {{to estimate the}} <b>cumulative</b> <b>frequency</b> {{of each of the}} observed magnitudes in a data series of the variable.|$|R
40|$|The {{question}} of whether age-of-acquisition(AoA), frequency, and repetition priming effects occur at a common stage or {{at different stages of}} processing is addressed. Two single-stage accounts (i. e., <b>cumulative</b> <b>frequency</b> and a neural-network simulation) are considered in regard to their predictions concerning the interactions between AoA and frequencywith aging and priming effects. A repetition-priming face-classification task was conducted on both older and younger participants to test these predictions. Consistent with the predictions of the neural-network simulation, AoA had an effect on reaction times that could not be explained by <b>cumulative</b> <b>frequency</b> alone. Also, as predicted by the simulation, the size of the priming effect was determined by the <b>cumulative</b> <b>frequency</b> of the item. It is discussed how this evidence is supportive of the notion that AoA, frequency, and priming all have effects at a common and single stage during face processing...|$|R
50|$|The <b>cumulative</b> <b>frequency</b> is {{the total}} of the {{absolute}} frequencies of all events at or below {{a certain point in}} an ordered list of events.|$|R
50|$|The {{confidence}} belt around an experimental <b>cumulative</b> <b>frequency</b> or return period curve gives {{an impression of}} the region in which the true distribution may be found.|$|R
5000|$|The <b>cumulative</b> <b>frequency</b> MXr [...] of a {{reference}} value Xr is the frequency {{by which the}} observed values X are {{less than or equal}} to Xr.|$|R
50|$|In {{statistics}} and data analysis the application software CumFreq {{is a free}} and user-friendly tool for <b>cumulative</b> <b>frequency</b> analysis of a single variable and for probability distribution fitting.|$|R
40|$|Texto completo. Acesso restrito. p. 349 – 359 The {{nature of}} geochemical {{anomalies}} is discussed on a speculative basis. Anomalies {{are classified as}} independent or as additive, depending on their spatial relation to the background population. The additive anomalies, which are more commonly encountered in geochemical exploration, cannot {{be separated from the}} background, in a composite population, by extracting straight lines from curved <b>cumulative</b> <b>frequency</b> graphs, because the <b>cumulative</b> <b>frequency</b> of the distribution of the additive component of an anomaly plots as a curved line on normal and lognormal probability paper...|$|R
5000|$|The {{cumulative}} probability Pc of X {{to be smaller}} {{than or equal to}} Xr can be estimated in several ways {{on the basis of the}} <b>cumulative</b> <b>frequency</b> M [...]|$|R
50|$|An {{alternative}} {{method is to}} plot the log of the particle size against the <b>cumulative</b> <b>frequency.</b> This graph will usually consist two reasonably straight lines with a connecting line corresponding to the antimode.|$|R
40|$|LiqueMap is a {{proposed}} map for real-time distribution {{over the internet}} that estimates the spatial distribution of liquefaction probability in the epicentral area immediately after an earthquake. As proposed here, {{it is based on}} the methodology for liquefaction hazard mapping that uses field-determined <b>cumulative</b> <b>frequency</b> distributions of the liquefaction potential index (LPI) of surficial geologic units to estimate the probability of surface manifestations of liquefaction at a given level of shaking and earthquake magnitude. The requirements for creating a LiqueMap after an earthquake are: (1) a map of PGA; (2) a map of the surficial geology; and (3) predetermined empirical LPI <b>cumulative</b> <b>frequency</b> distributions of the mapped surficial geologic units. LiqueMap as proposed here is generated by using a post-earthquake map of PGA and the LPI <b>cumulative</b> <b>frequency</b> distributions to map the probability of surface manifestations of liquefaction within the strongly shaken area. LiqueMap is potentially useful to utility and transportation agencies for assessing potential damage to lifelines from liquefaction-induced permanent ground deformation. When overlain on maps of vulnerable pipelines and other lifelines, LiqueMap can help set priorities for post-earthquake inspections...|$|R
40|$|This paper {{establishes}} the asymptotic normality of <b>frequency</b> <b>polygons</b> {{in the context}} of stationary strongly mixing random fields indexed by ^d. Our method allows us to consider only minimal conditions on the width bins and provides a simple criterion on the mixing coefficients. In particular, we improve in several directions a previous result by Carbon, Francq and Tran (2010) ...|$|R
3000|$|Data cleaning—remove missing data, <b>cumulative</b> <b>frequency</b> {{not between}} 99 and 101, blends where a single coal {{represented}} more than 90 % of the blend (i.e., only blends where {{used in this}} stage of the process) [...]...|$|R
