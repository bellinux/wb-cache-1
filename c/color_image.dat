3323|6713|Public
25|$|In 1978, {{the first}} {{transmissions}} of <b>color</b> <b>image</b> with the {{parties of the}} World-wide one of Soccer of Argentina take place.|$|E
25|$|The {{basic idea}} of using three {{monochrome}} images to produce a <b>color</b> <b>image</b> had been experimented with {{almost as soon as}} black-and-white televisions had first been built.|$|E
25|$|The Belgian {{government}} {{issued a}} commemorative coin in 92.5% sterling silver in 2010 {{coinciding with the}} 100th anniversary of his birth. It is a silver 10-Euro coin with a <b>color</b> <b>image</b> of Reinhardt on the reverse side.|$|E
40|$|We {{propose a}} novel noise removal {{algorithm}} in <b>color</b> <b>images.</b> First, gradient is extended for <b>color</b> <b>images.</b> On this extended gradient, an algorithm called gradient peer group {{is used to}} detect the noise in <b>color</b> <b>images</b> and the peer group averaging algorithm is applied to remove the noise detected. The experiment shows that the proposed algorithm can detect and remove noise in <b>color</b> <b>images</b> effectively. The quality of images after noise removal {{is better than the}} ones reconstructed by other algorithms...|$|R
40|$|This paper {{presents}} {{a new and}} fast multiphase image segmentation model for <b>color</b> <b>images.</b> We propose our model by incorporating the globally convex image segmentation method and the split Bregman method into the piecewise constant multiphase Vese-Chan model for <b>color</b> <b>images.</b> We have applied our model to many synthetic and real <b>color</b> <b>images.</b> Numerical results show that our model can segment <b>color</b> <b>images</b> with multiple regions and represent boundaries with complex topologies, including triple junctions. Comparison with the Vese-Chan model demonstrates the efficiency of our model. Besides, our model {{does not require a}} priori denoising step and is robust with respect to noise...|$|R
40|$|The {{paper is}} devoted to the signal-dependent (SD) design of {{adaptive}} LMS L-filters with marginal data ordering for <b>color</b> <b>images.</b> The same stem of SD processing of noised grayscale images was applied on noisy <b>color</b> <b>images.</b> Component-wise and multichannel modifications of SD LMS L-filter in R'G'B' (gamma corrected RGB signals) color space were developed. Both modifications for filtering two-dimensional static <b>color</b> <b>images</b> degraded by mixed noise consisting of additive Gaussian white noise and impulsive noise were used. Moreover, single-channel spatial impulse detectors as detectors of impulses and details were used, too. Considering experimental results, SD modifications of L-filters for noisy <b>color</b> <b>images</b> can be concluded to yield the best results...|$|R
25|$|Mechanically scanned color {{television}} was also demonstrated by Bell Laboratories in June 1929 using three complete systems of photoelectric cells, amplifiers, glow-tubes and color filters, {{with a series}} of mirrors to superimpose the red, green and blue images into one full <b>color</b> <b>image.</b>|$|E
25|$|When lit {{primarily}} from the rear with the white LED backlight, the display shows a <b>color</b> <b>image</b> composed of both RGB and grayscale information. When lit {{primarily from}} the front by ambient light, for example from the sun, the display shows a monochromatic (black and white) image composed of just the grayscale information.|$|E
25|$|Similarly, current high-efficiency digital <b>color</b> <b>image</b> data {{compression}} schemes such as JPEG and MPEG store RGB color internally in YCBCR format, a digital luminance-chrominance format based on YPBPR. The use of YCBCR also allows to perform lossy subsampling with the chroma channels (typically to 4:2:2 or 4:1:1 ratios), which it aids {{to reduce the}} resultant file size.|$|E
50|$|Potrace's {{input and}} output is black and white (<b>colored</b> <b>images</b> are greyscaled before processing). However, Inkscape is capable of {{producing}} <b>color</b> <b>images</b> by decomposing each channel into several black and white images and tracing them separately with Potrace. The commercial Total Vectorize program also uses Potrace as its core.|$|R
5000|$|... #Caption: Mercury in {{enhanced}} <b>color,</b> <b>imaged</b> by MESSENGER (2008) ...|$|R
40|$|Extending differential-based {{operations}} to <b>color</b> <b>images</b> is hindered by the multi-channel nature of <b>color</b> <b>images.</b> The derivatives in different channels can point in opposite directions, hence cancellation might occur by simple addition. The {{solution to this}} problem is given by the structure tensor for which opposing vectors reinforce each other...|$|R
25|$|CompuServe {{introduced}} GIF on June 15, 1987 {{to provide}} a <b>color</b> <b>image</b> format for their file downloading areas, replacing their earlier run-length encoding (RLE) format, which was black and white only. GIF became popular because it used LZW data compression, which was more efficient than the run-length encoding that formats such as PCX and MacPaint used, and fairly large images could therefore be downloaded in a reasonably short time, even with very slow modems.|$|E
25|$|Currently {{available}} scanners typically use {{charge-coupled device}} (CCD) or {{contact image sensor}} (CIS) as the image sensor, whereas older drum scanners use a photomultiplier tube as the image sensor. Early color film scanners used a halogen lamp and a three-color filter wheel, so three exposures were needed to scan a single <b>color</b> <b>image.</b> Due to heating problems, the worst of them being the potential destruction of the scanned film, this technology was later replaced by non-heating light sources such as color LEDs.|$|E
25|$|In some {{configurations}} {{information about}} several specimen properties is gathered per pixel, usually {{by the use}} of multiple detectors. In SEM, the attributes of topography and material contrast can be obtained by a pair of backscattered electron detectors and such attributes can be superimposed in a single <b>color</b> <b>image</b> by assigning a different primary color to each attribute. Similarly, a combination of backscattered and secondary electron signals can be assigned to different colors and superimposed on a single color micrograph displaying simultaneously the properties of the specimen.|$|E
30|$|To {{solve the}} issue of {{illumination}} variations between adjacent <b>color</b> <b>images,</b> we construct a composite vector field in the gradient domain of color space, with the points located in the boundary as constraints. Due to the pixels distributing discretely, we solve the resulting discrete Poisson equation (Perez et al. 2003), and blend the adjacent <b>color</b> <b>images</b> smoothly. Thus the <b>color</b> of different <b>images</b> becomes coherent.|$|R
40|$|This paper proposes an {{effective}} <b>color</b> halftone <b>image</b> visual cryptography method to embed a binary secret pattern into dot diffused <b>color</b> halftone <b>images,</b> Data Hiding by Dual Color Conjugate Dot Diffusion (DCCDD). DCCDD considers inter-channel correlation {{in order to}} restrict the embedding distortions between different channels within an acceptable range. Compared to the previous method, the proposed method can hide a secret pattern into two halftone <b>color</b> <b>images</b> which come from different original multitone images. The experimental results show that DCCDD can embed a binary secret pattern into two <b>color</b> halftone <b>images</b> which can be generated from identical or different original multitone <b>color</b> <b>images.</b> When the two halftone images are overlaid, the secret pattern will be revealed...|$|R
50|$|For <b>colored</b> <b>images,</b> WAP {{supports}} the Portable Network Graphics format.|$|R
25|$|One common {{application}} of the RGB color model is the display of colors on a cathode ray tube (CRT), liquid crystal display (LCD), plasma display, or {{organic light emitting diode}} (OLED) display such as a television, a computer’s monitor, or a large scale screen. Each pixel on the screen is built by driving three small and very close but still separated RGB light sources. At common viewing distance, the separate sources are indistinguishable, which tricks the eye to see a given solid color. All the pixels together arranged in the rectangular screen surface conforms the <b>color</b> <b>image.</b>|$|E
25|$|Porco is {{fascinated by}} the 1960s and The Beatles and has, at times, {{incorporated}} references to The Beatles and their music into her presentations, writings, and press releases. The first <b>color</b> <b>image</b> released by Cassini to the public was an image of Jupiter, taken during Cassinis approach to the giant planet and released on October 9, 2000 to honor John Lennon’s 60th birthday. In 2006, she produced and directed a brief 8-minute movie of 64 of Cassini’s most spectacular images, put {{to the music of}} the Beatles, in honor of Paul McCartney’s 64th birthday. And in 2007, she produced a poster showing 64 scenes from Saturn.|$|E
25|$|The first {{permanent}} color {{photograph was}} taken in 1861 using the three-color-separation principle first published by Scottish physicist James Clerk Maxwell in 1855. The foundation of virtually all practical color processes, Maxwell's idea was to take three separate black-and-white photographs through red, green and blue filters. This provides the photographer with the three basic channels required to recreate a <b>color</b> <b>image.</b> Transparent prints of the images could be projected through similar color filters and superimposed on the projection screen, an additive method of color reproduction. A color print on paper could be produced by superimposing carbon prints of the three images made in their complementary colors, a subtractive method of color reproduction pioneered by Louis Ducos du Hauron in the late 1860s.|$|E
5000|$|... #Caption: True {{and false}} <b>color</b> <b>images</b> of Jupiter's cloud layers ...|$|R
40|$|The {{use of the}} {{singular}} value decomposition for image compression is common; however, its study {{in the area of}} true <b>color</b> <b>images</b> is slightly less frequent. In this article, we will delve into the use, history, and definition of the SVD specifically focusing on its use for compression of <b>color</b> <b>images.</b> 1...|$|R
40|$|Image based {{rendering}} (IBR) is {{a promising}} way to produce arbitrary {{views of a}} scene using images instead of object models. The emergence of low-price, fast, and reliable cameras for measuring depth will have {{a great impact on}} IBR in that depth measurements provide the perfect complementary information to the traditional <b>color</b> <b>images.</b> The issue then is to understand, given a certain scene of interest, how many depth images and how many <b>color</b> <b>images</b> are necessary in order to obtain good rendering results. In this paper, we perform a spectral analysis of both multiview depth <b>images</b> and multi-view <b>color</b> <b>images</b> in order to work out the relationship between the number of depth and <b>color</b> <b>images</b> needed. Our analysis is then validated using both synthetic and real images. Index Terms — One, two, three, four, five 1...|$|R
25|$|One of {{the great}} {{technical}} challenges of introducing color broadcast television was the desire to conserve bandwidth, potentially three {{times that of the}} existing black-and-white standards, and not use an excessive amount of radio spectrum. In the United States, after considerable research, the National Television Systems Committee approved an all-electronic Compatible color system developed by RCA, which encoded the color information separately from the brightness information and greatly reduced the resolution of the color information in order to conserve bandwidth. The brightness image remained compatible with existing black-and-white television sets at slightly reduced resolution, while color televisions could decode the extra information in the signal and produce a limited-resolution color display. The higher resolution black-and-white and lower resolution color images combine in the brain to produce a seemingly high-resolution <b>color</b> <b>image.</b> The NTSC standard represented a major technical achievement.|$|E
25|$|RCA used Valensi's {{concept as}} the basis of all of its developments, believing it to be the only proper {{solution}} to the broadcast problem. However, RCA's early sets using mirrors and other projection systems all suffered from image and color quality problems, and were easily bested by CBS's hybrid system. But solutions to these problems were in the pipeline, and RCA in particular was investing massive sums (later estimated at $100 million) to develop a usable dot-sequential tube. RCA was beaten to the punch by the Geer tube, which used three B tubes aimed at different faces of colored pyramids to produce a <b>color</b> <b>image.</b> All-electronic systems included the Chromatron, Penetron and beam-index tube that were being developed by various companies. While investigating all of these, RCA's teams quickly started focusing on the shadow mask system.|$|E
25|$|The {{operation}} of the Foveon X3 sensor {{is quite different from}} that of the Bayer filter image sensor more commonly used in digital cameras. In the Bayer sensor, each photosite in the array consists of a single light sensor (either CMOS or CCD) that, as a result of filtration, is exposed to only one of the three primary colors, red, green, or blue. Constructing a full <b>color</b> <b>image</b> from a Bayer sensor requires demosaicing, an interpolative process in which the output pixel associated with each photosite is assigned an RGB value based in part on the level of red, green, and blue reported by those photosites adjacent to it. The Foveon X3 sensor creates its RGB color output for each photosite by combining the outputs of each of the stacked photodiodes at each of its photosites. This operational difference results in several significant consequences.|$|E
40|$|International audienceThis {{chapter is}} focused on {{spatially}} adaptive <b>image</b> processing for <b>color</b> <b>images</b> {{in the context of}} the General Adaptive Neighborhood Image Processing (GANIP) approach. The GANIP was first defined for gray-tone images and is here extended to <b>color</b> <b>images.</b> A set of local adaptive neighborhoods is defined for each image point, depending on the color intensity function of the image. These adaptive neighborhoods are then used as spatially adaptive operational windows for defining adaptive Choquet filters and adaptive morphological filters. The resulting adaptive operators are successfully applied and compared with the classical operators for image restoration, enhancement and segmentation of <b>color</b> <b>images...</b>|$|R
40|$|This paper {{deals with}} the use of the vector levelings for coding <b>color</b> <b>images,</b> a class of {{morphological}} connected filters which suppresses details but preserves the contours of the remaining objects. If the <b>color</b> <b>images</b> are filtered by independently leveling each color component, new colors may be introduced. In order to avoid this drawback, a total order must be imposed on the color vectors. A comparative study has been drawn for various lexicographical orders in the RGB and the HLS color systems. These filters can be especially useful as a preprocessing step for improving the compression of <b>color</b> <b>images.</b> 1...|$|R
40|$|Texture mapping on scanned objects, that is, {{the method}} to map current <b>color</b> <b>images</b> on a 3 D {{geometric}} model {{measured by a}} range sensor, is a key technique of photometric modeling for virtual reality. Usually range and <b>color</b> <b>images</b> are obtained from different viewing positions, through two independent range and color sensors. Thus, in order to map those <b>color</b> <b>images</b> on the geometric model, {{it is necessary to}} determine relative relations between these two viewpoints. In this paper, we propose a new calibration method for the texture mapping; the method utilizes reflectance images and iterative pose estimation based on a robust M-estimator. ...|$|R
25|$|A {{pioneering}} three-color additive {{system was}} patented in England by Edward Raymond Turner in 1899. It used a rotating set of red, {{green and blue}} filters to photograph the three color components {{one after the other}} on three successive frames of panchromatic black-and-white film. The finished film was projected through similar filters to reconstitute the color. In 1902, Turner shot test footage to demonstrate his system, but projecting it proved problematic because of the accurate registration (alignment) of the three separate color elements required for acceptable results. Turner died a year later without having satisfactorily projected the footage. In 2012, curators at the National Media Museum in Bradford, UK, had the original custom-format nitrate film copied to black-and-white 35mm film, which was then scanned into a digital video format by telecine. Finally, digital image processing was used to align and combine each group of three frames into one <b>color</b> <b>image.</b> The result is that the whole world can now view brief motion pictures from 1902 in full color.|$|E
25|$|The {{method of}} color {{photography}} used by Prokudin-Gorsky was first suggested by James Clerk Maxwell in 1855 and demonstrated in 1861, but good results were not {{possible with the}} photographic materials available at that time. In imitation of the way a normal human eye senses color, the visible spectrum of colors was divided into three channels of information by capturing it {{in the form of}} three black-and-white photographs, one taken through a red filter, one through a green filter, and one through a blue filter. The resulting three photographs could either be projected through filters of the same colors and exactly superimposed on a screen, synthesizing the original range of color additively; viewed as an additive <b>color</b> <b>image</b> by {{one person at a time}} through an optical device known generically as a chromoscope or photochromoscope, which contained colored filters and transparent reflectors that visually combined the three into one full-color image; or used to make photographic or mechanical prints in the complementary colors cyan, magenta and yellow, which, when superimposed, reconstituted the color subtractively.|$|E
25|$|In {{its most}} basic form, a color {{broadcast}} can be created by broadcasting three monochrome images, one each in the three colors of red, green, and blue (RGB). When displayed together or in rapid succession, these images will blend together to produce a full-color image as seen by the viewer. One of the great technical challenges of introducing color broadcast television was the desire to conserve bandwidth, potentially three {{times that of the}} existing black-and-white standards, and not use an excessive amount of radio spectrum. In the United States, after considerable research, the National Television Systems Committee approved an all-electronic system developed by RCA which encoded the color information separately from the brightness information and greatly reduced the resolution of the color information in order to conserve bandwidth. The brightness image remained compatible with existing black-and-white television sets at slightly reduced resolution, while color televisions could decode the extra information in the signal and produce a limited-resolution color display. The higher resolution black-and-white and lower resolution color images combine in the eye to produce a seemingly high-resolution <b>color</b> <b>image.</b> The NTSC standard represented a major technical achievement.|$|E
5000|$|<b>Colored</b> <b>images</b> {{by direct}} {{exposure}} from nature using a Lippmann plate ...|$|R
5000|$|... #Subtitle level 2: Grayscale {{as single}} {{channels}} of multichannel <b>color</b> <b>images</b> ...|$|R
40|$|International audienceIn {{this paper}} {{spatially}} adaptive Mathematical Morphology (MM) is studied for <b>color</b> <b>images.</b> More precisely, the General Adaptive Neighborhood Image Processing (GANIP) approach is generalized to <b>color</b> <b>images.</b> The basic principle is {{to define a}} set of locally Color Adaptive Neighborhoods (CAN), one for each point of the image, and to use them as adaptive structuring elements (ASE) for morphological operations. These operators have been applied to <b>images</b> in different <b>color</b> spaces and compared them with other kinds of ASEs extended to <b>color</b> <b>images.</b> Results show that the proposed method is more respectful with {{the borders of the}} objects, {{as well as with the}} color transitions within the image. Finally, the proposed adaptive morphological operators are applied to the classification of <b>color</b> texture <b>images...</b>|$|R
