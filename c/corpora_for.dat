792|3588|Public
5000|$|... "From central {{embedding}} to corpus linguistics" [...] in Using <b>Corpora</b> <b>for</b> Language Research (Longman, 1996) ...|$|E
5000|$|... § A {{few other}} forms {{can be found}} in large English-language <b>corpora</b> (<b>for</b> example, *quintavalent, *quintivalent, *decivalent), but they are not the {{conventionally}} established forms in English and thus are not entered in major dictionaries.|$|E
5000|$|Extraction of {{specific}} or general sub-corpora following particular criteria (subject, author, year / period of publication, source, etc.), {{which could be}} used as training <b>corpora</b> <b>for</b> a number of applications - grammatical and semantic tagging, among others, as well as for other research purposes.|$|E
5000|$|Restoring habeas <b>corpus</b> <b>for</b> {{suspected}} alien enemy combatants.|$|R
5000|$|... the {{suspension}} of habeas <b>corpus</b> <b>for</b> crimes of political motivation.|$|R
5000|$|To develop large {{standardized}} <b>corpus</b> <b>for</b> Bengali {{text and}} speech.|$|R
50|$|Early work on CLIR {{depended}} on manually constructed parallel <b>corpora</b> <b>for</b> {{each pair of}} languages. This method is labor-intensive compared to parallel corpora created automatically. A more efficient way of finding data to train a CLIR system is to use matching pages on the web which are written in different languages.|$|E
50|$|To {{facilitate}} the further researches between multilingual tasks, some researchers discussed the universal annotation scheme for cross-languages. In this way, {{people try to}} utilize or merge the advantages of different treebanks <b>corpora.</b> <b>For</b> instance, The universal annotation approach for dependency treebanks; and the universal annotation approach for phrase structure treebanks.|$|E
50|$|Current {{statistical}} {{machine translation}} (SMT) systems use parallel <b>corpora</b> <b>for</b> source (s) and target (t) languages to achieve their good results, but good parallel corpora are not available for all languages. A pivot language (p) enables the bridge between two languages, to which existing parallel corpora are entirely or partially not yet at hand.|$|E
50|$|Text-mining {{can be used}} {{to narrow}} a search or quickly {{evaluate}} a patent <b>corpus.</b> <b>For</b> instance, if a query produces irrelevant documents, a multi-level clustering hierarchy identifies them in order to delete them and refine the search. Text-mining {{can also be used to}} create internal taxonomies specific to a <b>corpus</b> <b>for</b> possible mapping.|$|R
50|$|Access to the Tatar <b>Corpus</b> <b>for</b> {{research}} purposes {{is free of}} charge.|$|R
30|$|We present Entropy Guided Transformation Learning {{models for}} three Portuguese Language Processing tasks: Part-of-Speech Tagging, Noun Phrase Chunking and Named Entity Recognition. For Part-of-Speech Tagging, we {{separately}} use the Mac-Morpho Corpus and the Tycho Brahe <b>Corpus.</b> <b>For</b> Noun Phrase Chunking, {{we use the}} SNR-CLIC <b>Corpus.</b> <b>For</b> Named Entity Recognition, we separately use three corpora: HAREM, MiniHAREM and LearnNEC 06.|$|R
50|$|It is clear, however, {{that most}} {{research}} opportunities remain largely unexplored. For instance, {{little is known}} about how to use lexical information extracted from the Web in knowledge-based WSD systems; and it is also hard to find systems that use Web-mined parallel <b>corpora</b> <b>for</b> WSD, even though there are already efficient algorithms that use parallel corpora in WSD.|$|E
50|$|The {{application}} of semantic spaces in {{natural language processing}} (NLP) aims at overcoming limitations of rule-based or model-based approaches operating on the keyword level. The main drawback with these approaches is their brittleness, and the large manual effort required to create either rule-based NLP systems or training <b>corpora</b> <b>for</b> model learning. Rule-based and machine learning based models are fixed on the keyword level and break down if the vocabulary differs from that defined in the rules or from the training material used for the statistical models.|$|E
5000|$|For {{the reason}} that the user does not {{understand}} the target language when speech translation is used, a method [...] "must be provided for the user to check whether the translation is correct, by such means as translating it again back into the user's language".In order to achieve the goal of erasing the language barrier world wide, multiple languages have to be supported. This requires speech corpora, bilingual corpora and text <b>corpora</b> <b>for</b> each of the estimated 6,000 languages said to exist on our planet today.|$|E
5000|$|A <b>corpus</b> <b>for</b> the {{evaluation}} of lossless compression algorithms Timothy C Bell. Data Compression Conference 1997 ...|$|R
40|$|CLaSSES (<b>Corpus</b> <b>for</b> Latin Sociolinguistic Studies on Epigraphic textS) is an {{annotated}} <b>corpus</b> <b>for</b> {{quantitative and}} qualitative sociolinguistic analyses on Latin inscriptions. It allows specific researches on phonological and morphophonological phenomena of non-standard Latin forms with crucial reference to the typology of the text, its origin and chronological collocation. This paper presents the first macrosection of CLaSSES, focused on the inscriptions from the archaicearly period...|$|R
50|$|Michael Ratner, 72, American lawyer, won {{right of}} habeas <b>corpus</b> <b>for</b> Guantanamo Bay detainees, {{complications}} from cancer.|$|R
50|$|During his {{undergraduate}} years, {{under the}} tutelage of G B Matthews, Berwick became interested in number theory. He submitted an essay entitled An illustration of the theory of relative <b>corpora</b> <b>for</b> the Smith's Prize in 1911; the essay was placed second in the prize competition. He then co-wrote, with Matthews, a paper On the reduction of arithmetical binary cubics which have a negative determinant: it was published after Berwick had left Cambridge to take up an assistant lectureship at the University of Bristol, and was the only paper Berwick co-authored in his career.|$|E
50|$|Supervised {{methods are}} based on the {{assumption}} that the context can provide enough evidence on its own to disambiguate words (hence, common sense and reasoning are deemed unnecessary). Probably every machine learning algorithm going has been applied to WSD, including associated techniques such as feature selection, parameter optimization, and ensemble learning. Support Vector Machines and memory-based learning have been shown to be the most successful approaches, to date, probably because they can cope with the high-dimensionality of the feature space. However, these supervised methods are subject to a new knowledge acquisition bottleneck since they rely on substantial amounts of manually sense-tagged <b>corpora</b> <b>for</b> training, which are laborious and expensive to create.|$|E
50|$|Wikipedia is {{a widely}} used {{reference}} work {{and one of the}} most visited social networking services by users from Slovenia, but official internet usage statistics don't distinguish between Wikipedia editions, analyzing only the base domain wikipedia.org. In most cases, the Slovene-language edition gets a passing note of its existence in media reports about Wikipedia in general. However, as a relatively large and freely accessible body of structured knowledge, Slovene Wikipedia has been used, as an example, for building text <b>corpora</b> <b>for</b> the purpose of training linguistic software and analyzing Slovene literary authors' web presence. There are several successful collaboration projects with professors at the University of Ljubljana, using content creation by students as a teaching method.|$|E
40|$|We {{performed}} corpus correction on a modality <b>corpus</b> <b>for</b> {{machine translation}} by using such machine-learning methods as the maximum-entropy method. We thus constructed a high-quality modality corpus based on corpus correction. We compared {{several kinds of}} methods <b>for</b> <b>corpus</b> correction in our experiments and developed a good method <b>for</b> <b>corpus</b> correction. ...|$|R
25|$|There is a {{controversy}} over whether this law affects {{the rights of}} habeas <b>corpus</b> <b>for</b> United States citizens.|$|R
40|$|This paper {{describes}} {{some recent}} activities on speech technology and corpus development in Thailand. Many speech corpus {{projects have been}} launched this year. The National Electronics and Computer Technology Center (NECTEC) recently provides a grant for two cooperative speech corpus projects to interested universities. The first project aims at developing a Thai speech <b>corpus</b> <b>for</b> the research on speaker-independent, large vocabulary, continuous speech recognition. The second project is to collect continuous speech of telephone number recorded through telephone line. Except for these projects, some NECTEC's internal corpus projects such as the <b>corpus</b> <b>for</b> speech synthesis development and the speech <b>corpus</b> <b>for</b> ATR Spoken Language Translation Research Laboratories are also under development. Besides the corpus development projects, many speech-technology researches are also discussed...|$|R
50|$|The {{electronic}} version provides fast search. The {{text processing}} including tokenization, part-of-speech tagging, word-sense disambiguation enriches corpus texts with detailed linguistic information. This enables {{to narrow the}} search on the particular part of speeches, word sequences or select a specific part of a corpus. The first text corpora were created during the 1960s of the 20th century, such as the 1-million-word Brown Corpus of American English. Over time many further corpora were prepared - the British National Corpus, the LOB Corpus - and had begun to create also larger corpora and <b>corpora</b> <b>for</b> other languages. For the purpose of preparing better corpora {{in the view of}} the size, wider-coverage, data cleanness, etc., there occurred initiatives pursuing development of tools for creating corpora.|$|E
5000|$|Unlike other {{auxiliary}} languages, Hogben’s Interglossa {{tends to}} adopt the international words from Greek, {{on account of the}} intense infiltration of Greek roots into everyday life, which come from modern science and technology. For instance: microbe, microphone, telephone, etc. (p. 30).Even so, a great part of the lexicon is of Latin origin. The term Inter-glossa itself is composed of the Latin inter and the Greek glossa. At times Hogben wavers between Greek and Latin, and suggests pairs of equivalent synonyms (e.g. hypo and infra, soma and <b>corpora),</b> <b>for</b> an eventual international committee to decide between them. Mass observation on the basis of questionnaires sent out to different groups of people of different nationalities would settle which words in each pigeon-hole are entitled to first-rank. Hogben (1943, p.15-16) ...|$|E
5000|$|Linguistic change {{detection}} {{refers to}} the ability to detect word-level changes across multiple presentations of the same sentence. Researchers have found that the amount of semantic overlap (i.e., relatedness) between the changed word and the new word influences the ease with which such a detection is made (Sturt, Sanford, Stewart, & Dawydiak, 2004). Additional research has found that focussing one's attention to the word that will be changed during the initial reading of the original sentence can improve detection. This was shown using italicized text to focus attention, whereby the word that will be changing is italicized in the original sentence (Sanford, Sanford, Molle, & Emmott, 2006), as well as using clefting constructions such as [...] "It was the tree that needed water." [...] (Kennette, Wurm, & Van Havermaet, 2010). These change-detection phenomena appear to be robust, even occurring cross-linguistically when bilinguals read the original sentence in their native language and the changed sentence in their second language (Kennette, Wurm & Van Havermaet, 2010). Recently, researchers have detected word-level changes in semantics across time by computationally analyzing temporal <b>corpora</b> (<b>for</b> example:the word [...] "gay" [...] has acquired a new meaning over time) using change point detection.|$|E
40|$|This article {{describes}} the collecting, processing and validation of a large balanced <b>corpus</b> <b>for</b> Romanian. The annotation types {{and structure of the}} corpus are briefly reviewed. It was constructed at the Research Institute for Artificial Intelligence of the Romanian Academy {{in the context of an}} international project (METANET 4 U). The processing covers tokenization, POS-tagging, lemmatization and chunking. The corpus is in XML format generated by our in-house annotation tools; the corpus encoding schema is XCES compliant and the metadata specification is conformant to the METANET recommendations. To the best of our knowledge, this is the first large and richly annotated <b>corpus</b> <b>for</b> Romanian. ROMBAC is intended to be the foundation of a linguistic environment containing a reference <b>corpus</b> <b>for</b> contemporary Romanian and a comprehensive collection of interoperable processing tools...|$|R
40|$|National audienceThis article {{details the}} {{creation}} of TCOF-POS, the first freely available corpus of spontaneous spoken French. We present here the methodology that was followed {{in order to obtain}} the best possible quality in the final resource. This corpus already is freely available and {{can be used as a}} training/validation <b>corpus</b> <b>for</b> NLP tools, as well as a study <b>corpus</b> <b>for</b> linguistic research. We also present the results obtained by two POS-taggers trained on the corpus...|$|R
40|$|In this work, a {{framework}} for efficient discriminative training and modeling is developed and implemented for both small and large vocabulary continuous speech recognition. Special attention will be directed to the comparison and formalization of varying discriminative training criteria and corresponding optimization methods, discriminative acoustic model evaluation and feature extraction. A formally unifying approach for a class of discriminative training criteria including Maximum Mutual Information (MMI) and Minimum Classification Error (MCE) criterion is presented, including the optimization methods gradient descent (GD) and extended Baum-Welch (EB) algorithm. Using discriminative criteria, novel approaches to splitting of mixture Gaussian densities and to linear feature transformation are derived. Furthermore, efficient algorithms {{for the application of}} discriminative training to speech recognition with both small and large vocabulary are developed. Finally, a novel evaluation method for the stochastic models used in speech recognition is derived using methods related to discriminative training. Experiments have been carried out on the TI digit string <b>corpus</b> <b>for</b> American English continuous digit strings, the SieTill <b>corpus</b> <b>for</b> telephone line recorded German continuous digit strings, the Verbmobil <b>corpus</b> <b>for</b> German spontaneous speech and the Wall Street Journal <b>corpus</b> <b>for</b> American English read speech...|$|R
5000|$|... 1985: [...] "Monolingual & bilingual learners’ dictionaries: a comparison". In: Dictionaries, Lexicography & Language Learning, (ed.) R. F. Ilson. Oxford: Pergamon. 15-24.1986: (with J. Kegl & B. Levin) [...] "Implicit and Explicit Information in Dictionaries". In: Advances in Lexicology: Proceedings of the Second Annual Conference of the UW Centre for the New OED, 45-63, Waterloo, Canada.1987: (with H. Lewis, D. Summers, J. Whitcut) [...] "A {{research}} project into {{the use of}} learners’ dictionaries" [...] in The Dictionary and the Language Learner, A. P. Cowie (ed.), Niemeyer, Tübingen. 29-431987: [...] "Semantic-ID tags: corpus evidence for dictionary senses", in The Uses of Large Text Databases, proceedings of the Third Annual Conference of the New OED Centre, University of Waterloo, Canada. 17-36.1988: (with J. Kegl & B. Levin) [...] "Anatomy of a verb entry: from linguistic theory to lexicographic practice". In: International Journal of Lexicography, 1:2 Oxford University Press, Oxford. pp. 84-126. Also in Current Issues in Computational Linguistics: In Honour of Don Walker, Linguistica Computazionale IX-X. (eds.) A. Zampolli, N. Calzolari & M. Palmer (1994) Pisa: Giardini Editori. 237-266.1988: (with B. Levin) [...] "Admitting impediments". In: Information in Text, Proceedings of the Fourth Annual Conference of the New OED Centre, University of Waterloo, Canada. pp. 97-114. Also in Lexical Acquisition: Using On-Line Resources to Build a Lexicon, U. Zernik (ed.), Lawrence Erlbaum Assoc. Inc. (1991). pp. 233-262.1990: (with F. E. Knowles) [...] "Interim report on the EURALEX / AILA Research Project into Dictionary Use", in T. Magay & J. Zigany (eds) Proceedings of BudaLex ’88, Akadémiai Kiadó, Budapest. pp. 381-392.1991: [...] "Corpus lexicography: the bilingual dimension", in A. Zampolli & N. Calzolari (eds.) Computational Lexicology and Lexicography I, Giardini, Pisa. pp. 43-64.1991: [...] "Building a Lexicon: the Contribution of Lexicography", in B. K. Boguraev (ed.) International Journal of Lexicography, 4:3, pp. 163-204. Also in Challenges in Natural Language Processing, M. Bates and R. Weischedel (eds.), Cambridge University Press, Cambridge (1993). pp. 37-71992: [...] "Putting lexicography on the professional map", Proceedings of EURALEX ’90, M. Alvar Ezquerra (ed.), Bibliograf SA, Barcelona. pp. 519-526.1992: (with J. H. Clear & N. Ostler) [...] "Corpus design criteria". In: Journal of Literary and Linguistic Computing, (ed.) Gordon Dixon. Oxford: Oxford University Press. 1 - 16.1992: [...] "Tools for computer-aided corpus lexicography: the Hector project", in Papers in Computational Lexicography: Complex’92, F. Kiefer, G. Kiss and J. Pajsz (eds.) Hungarian Academy of Sciences, Budapest. pp. 1-60. Also in Acta Linguistica Hungarica 41, F. Kiefer (ed.) (1991), Hungarian Academy of Sciences, Budapest: Akadémiai Kiadó.1992: (with Charles J. Fillmore) [...] "Towards a Frame-based Lexicon: the Semantics of RISK and its Neighbors", in Frames, Fields and Contrasts: New Essays in Semantic and Lexical Organization, A. Lehrer & E. F. Kittay (eds.) Lawrence Erlbaum Associates: Hillsdale, New Jersey. 75-102.1992: (with N. Ostler) [...] "Predictable meaning shift: some linguistic properties of lexical implication rules" [...] in Lexical Semantics and Commonsense Reasoning, (eds.) J. Pustejovsky & S. Bergler, Springer-Verlag, NY. pp. 87-98.1993: [...] "Theoretical Lexicography {{and its relation to}} Dictionary-making". In: Dictionaries: the Journal of the Dictionary Society of North America, (guest editor) W. Frawley, DSNA, Cleveland Ohio. pp. 4-43.1994: (with Charles J. Fillmore) [...] "Starting where the dictionaries stop: the challenge of corpus lexicography". In Atkins & Zampolli. 350-3931994: (with Beth Levin & A. Zampolli) [...] "Computational Approaches to the Lexicon: An Overview". In Atkins & Zampolli. 17-451994: [...] "A corpus-based dictionary". In: Oxford-Hachette French Dictionary (Introductory section). Oxford: Oxford University Press. xix - xxxii1994: (with Charles J. Fillmore, J. B. Lowe & N. Urban) [...] "The Dictionary of the Future: a Hypertext Database". Presentation and on-line demonstration at the Xerox-Acquilex Symposium on the Dictionary of the Future, Uriage, France.1995: [...] "Analysing the verbs of seeing: a frame semantics approach to corpus lexicography". In: Proceedings of the Twentieth Annual Meeting of the Berkeley Linguistics Society, 1994, (eds.) S. Gahl, C. Johnson & A. Dolbey, BLS, UC Berkeley, CA.1995: (with Beth Levin) [...] "Building on a Corpus: A linguistic and lexicographical look at some near-synonyms". In: International Journal of Lexicography, 8 : 2. 85-114.1995: [...] "The Dynamic Database". In: Machine Tractable Dictionaries, (ed.) Cheng-ming Guo, Ablex Publishing Corporation, Norwood, NJ. 131-143.1995: (with Charles J. Fillmore and Ulrich Heid) [...] "Lexicographical Relevance in Corpus Evidence", Deliverable D-IX-2 of DELIS Project (LRE 61.034).1995: [...] "The role of the example in a frame semantics dictionary". In: Essays in Semantics and Pragmatics, in honor of Charles J. Fillmore. (eds.) Shibatani, Masayoshi & Sandra Thompson. Amsterdam: John Benjamins. 25-42.1996: [...] "Bilingual Dictionaries: Past, Present and Future". In: Euralex’96 Proceedings, (eds.) Gellerstam, M. , J. Järborg, S.-G. Malmgren, K. Norén, L. Rogström and C. R. Papmehl. Gothenburg: Gothenburg University, Department of Swedish. 515-590.1996: (with Beth Levin and Grace Song) [...] "Making Sense of Corpus Data: A Case Study". In: Euralex’96 Proceedings, (eds.) Gellerstam, M. , J. Järborg, S.-G. Malmgren, K. Norén, L. Rogström and C. R. Papmehl. Gothenburg: Gothenburg University, Department of Swedish. 345-354.1997: (with K. Varantola) [...] "Monitoring Dictionary Use". In International Journal of Lexicography, 10:1, 1-45, and reprinted in Atkins (1998).1997: (with Beth Levin and Grace Song) [...] "Making Sense of Corpus Data: A Case Study of Verbs of Sound". In: International Journal of Corpus Linguistics, 2:1 23-64.1998: (with Charles J. Fillmore) [...] "FrameNet and Lexicographic Relevance". In: Proceedings of the First International Conference On Language Resources And Evaluation, Granada, Spain, 28-30 May 19981998: (with K. Varantola) [...] "Language Learners Using Dictionaries: The Final Report of the EURALEX- and AILA-sponsored Research Project into Dictionary Use". In Atkins (1998).1998: (with Jan H. Hulstijn [...] ) [...] "Empirical research on dictionary use in foreign-language learning: an overview". In Atkins (1998).2000: (with Charles J. Fillmore) [...] "Describing polysemy : the case of crawl". In Polysemy: Linguistic and Computational Approaches, (eds) Yael Ravin and Claudia Leacock. Oxford: Oxford University Press.2002: (with Nuria Bel, Francesca Bertagna, Pierrette Bouillon, Nicoletta Calzolari, Christiane Fellbaum, Ralph Grishman, Alessandro Lenci, Catherine MacLeod, Martha Palmer, Gregor Thurmair, Marta Villegas, Antonio Zampolli) [...] "From Resources to Applications. Designing the Multilingual ISLE Lexical Entry", LREC2002, Las Palmas.2002: [...] "Then and Now: Competence and Performance in 35 Years of Lexicography". In Proceedings of the Tenth EURALEX International Congress, EURALEX 2002, (eds.) Braasch, A. and C. Povlsen. Copenhagen: Center for Sprogteknologi. 1-28.2003: (with Michael Rundell & Hiroaki Sato) [...] "The contribution of FrameNet to practical lexicography", in International Journal of Lexicography, guest editor2003: (with Charles Fillmore & Christopher Johnson) [...] "Lexicographic relevance: selecting information from corpus evidence", in International Journal of Lexicography, guest editor Thierry Fontenelle, Oxford, OUP: 16:3 251-2802004: Pierrette Bouillon, [...] "Relevance in dictionary-making", in Proceedings of the First International Symposium on Lexicography, Universitat Pompeu Fabra, Barcelona, May 2002; also in Text-based Studies: Lexicography, Terminology, Translation. In Honour of Ingrid Meyer (Ed.) Lynne Bowker; Ottawa, University of Ottawa Press, 2006.2006: (with Valerie Grundy) [...] "Lexicographic profiling: An aid to consistency in dictionary entry design". In Proceedings of the Twelfth EURALEX International Congress, EURALEX 2006, Alessandria Italy: Edizioni dell’Orso, 1097-1107.2007: [...] "Me Lexicographer, You Translators: or Context-free (vs. context-sensitive) translation and what it involves", in Proceedings of 4th International Maastricht-Lodz Duo Colloquium on Translation and Meaning, Maastricht, Netherlands: May 2005.(with Michael Rundell) [...] "Lexicography Training: An Overview" [...] in Dictionaries: An International Encyclopedia of Lexicography: Supplementary Volume: Recent Developments (eds.) R. H. Gouws, U. Heid, W. Schweickard & H.E. Wiegand (forthcoming from Mouton De Gruyter, Berlin).(with Michael Rundell) [...] "Criteria for the design of <b>corpora</b> <b>for</b> lexicography 1: monolingual dictionaries" [...] in Dictionaries: An International Encyclopedia of Lexicography: Supplementary Volume: Recent Developments (eds.) R. H. Gouws, U. Heid, W. Schweickard & H.E. Wiegand (forthcoming from Mouton De Gruyter, Berlin).|$|E
40|$|<b>Corpora</b> <b>for</b> {{computational}} linguistics 2 Since the mid 90 s corpora {{has become very}} important for {{computational linguistics}}. This paper offers a survey of how they are currently used in different fields of the discipline, with particular emphasis on anaphora and coreference resolution, automatic summarisation and term extraction. Their influence on other fields is also briefly discussed. <b>Corpora</b> <b>for</b> computational linguistics 3 <b>Corpora</b> <b>for</b> computational linguistic...|$|E
40|$|<b>Corpora</b> <b>for</b> {{training}} plan recognizers are scarce and di#- cult to gather from humans. However, corpora {{could be a}} boon to plan recognition research, providing a platform to train and test individual recognizers, as well as allow di#erent recognizers to be compared. We present a novel method for generating artificial <b>corpora</b> <b>for</b> plan recognition...|$|E
5000|$|Make-test-files: To {{extract from}} the {{original}} <b>corpus</b> a <b>corpus</b> <b>for</b> training, files for tuning and files for testing {{the results of the}} training.|$|R
40|$|We {{present a}} method for {{designing}} a phonetically balanced speech corpus. In this method, we used a phonotactic approach to design the phonetic content of VOXMEX: a phonetically balanced <b>corpus</b> <b>for</b> Mexican Spanish. The transcriptions of VOXMEX contain a complete coverage of phonemes and allophones of Mexican Spanish in every possible context. This <b>corpus</b> is designed <b>for</b> doing phonetic research and acoustic modeling in the speech recognition area. We are recording the readings of the designed text corpus to obtain the speech data of VOXMEX. Our main goal in this project is to construct a phonologically representative speech <b>corpus</b> <b>for</b> Mexican Spanish. 1...|$|R
40|$|Abstract. The {{paper is}} focused on the formants F 1 and F 2 values for the French and Romanian {{language}} in order to notice the similarities between the languages. We are studying the formants position in both languages. The analysis was made on the PFC <b>corpus</b> <b>for</b> French by M. Goudbeek, J. Ph. Goldman, K. R. Scherer and on SRoL <b>corpus</b> <b>for</b> Romanian language by the author in the team at the initiative and the guidance of the professor H. N. Teodorescu...|$|R
