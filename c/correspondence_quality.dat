12|49|Public
40|$|In this paper, an {{automatic}} scheme for {{the identification of}} fingerprint images is presented. The scheme consists of two main processes: the extraction of distinctive points only from the template fingerprint image and the detection of their corresponding ones (if they exist) on the input fingerprint image using an implementation of the Self Organizing Maps. The <b>correspondence</b> <b>quality</b> is evaluated using a proper metric, which determines the matching between the two images. The proposed scheme was tested on fingerprint image pairs subject to known and unknown transformations using the VeriFinger-Sample-Data-Base of NeuroTechnology. The overall performance for fingerprints originated from the same and different fingers was 94. 12 % {{in terms of the}} Equal Error Rate. © 2010 International Federation for Medical and Biological Engineering...|$|E
40|$|We {{present a}} method for {{computing}} dense stereo correspondences in calibrated monocular video by iteratively and stochastically sampling match quality values in the disparity search space. Most existing methods exhaustively compute local <b>correspondence</b> <b>quality</b> before searching for a globally optimal solution. Instead, we iteratively refine a correspondence estimate by perturbing it with random noise and formulating an influence at each sample based on the perturbation {{and its effect on}} correspondence match quality. Local influence is aggregated to recover consistent trends in match quality caused by the piecewise-continuous structure of the scene. Correspondence estimates for a given frame pair are seeded with the estimates from the previous frame pair, allowing convergence to occur across multiple frame pairs. Index Terms—Stereo vision, computational geometry, stochastic approximation, recursive estimation, simulated annealing 1...|$|E
40|$|The paper {{introduces}} {{an accurate}} solution to dense orthographic Non-Rigid Structure from Motion (NRSfM) in scenarios with severe occlusions or, likewise, inaccurate correspondences. We integrate a shape prior term into variational optimisation framework. It allows to penalize irregularities of the time-varying structure on the per-pixel level if <b>correspondence</b> <b>quality</b> indicator {{such as an}} occlusion tensor is available. We make a realistic assumption that several non-occluded views of the scene are sufficient to estimate an initial shape prior, though the entire observed scene may exhibit non-rigid deformations. Experiments on synthetic and real image data show that the proposed framework significantly outperforms {{state of the art}} methods for correspondence establishment in combination with {{the state of the art}} NRSfM methods. Together with the profound insights into optimisation methods, implementation details for heterogeneous platforms are provided...|$|E
5000|$|The {{evidence}} for [...] comes from prefixes; [...] {{has not been}} found in stem-initial position and thus is in parentheses above. Hale reconstructs the nasalization feature for nasal vowels. Vowel quality and prosodic features like vowel length, tone, and stress {{have not yet been}} reconstructed for the Tanoan family. Hale (1967) gives certain sets of vowel <b>quality</b> <b>correspondences.</b>|$|R
50|$|Her {{writings}} {{brought her}} little money, yet they secured her fame and many friends, first {{among them the}} Abbé Grégoire, with whom she carried on an extensive <b>correspondence.</b> The <b>quality</b> of her scholarship also earned her the respect and friendship of several prominent Boston intellectuals, most notably William Shaw and Joseph Stevens Buckminster. These men would soon establish the Anthology Society, precursor to the Boston Athenæum, and become Adams’s lifelong allies and patrons, establishing in 1809 a modest annuity that would keep her out of poverty. It was through the sponsorship of these gentlemen that aided her in preparing her History of the Jews (1812).|$|R
40|$|Most {{studies of}} quality {{improvement}} deal with ordered categorical data from industrial experiments. Accounting for the ordering of such data {{plays an important}} role in effectively determining the optimal factor level of combination. This paper utilizes the correspondence analysis to develop a procedure to improve the ordered categorical response in a multifactor state system based on Taguchi's statistic. Users may find the proposed procedure in this paper to be attractive because we suggest a simple and also popular statistical tool for graphically identifying the really important factors and determining the levels to improve process quality. A case study for optimizing the polysilicon deposition process in a very large-scale integrated circuit is provided to demonstrate the effectiveness of the proposed procedure. ordered categories, <b>correspondence</b> analysis, <b>quality</b> engineering, experimental design, Taguchi's statistic,...|$|R
40|$|A robust, {{flexible}} {{system for}} tracking {{the point to}} point nonrigid motion of the left ventricular (LV) endocardial wall in image sequences has been developed. This system is unique {{in its ability to}} model motion trajectories across multiple frames. The foundation of this system is an adaptive transversal filter based on the recursive least-squares algorithm. This filter facilitates the integration of models for periodicity and proximal smoothness as appropriate using a contour-based description of the object's boundaries. A set of correspondences between contours and an associated set of <b>correspondence</b> <b>quality</b> measures comprise the input to the system. Frame-to-frame relationships from two different frames of reference are derived and analyzed using synthetic and actual images. Two multiframe temporal models, both based on a sum of sinusoids, are derived. Illustrative examples of the system's output are presented for quantitative analysis. Validation of the system is performed by compa [...] ...|$|E
40|$|Abstract. This paper {{presents}} a novel method of optimizing pointbased correspondence among populations of human cortical surfaces by combining structural cues with probabilistic connectivity maps. The proposed method establishes a tradeoff between an even {{sampling of the}} cortical surfaces (a low surface entropy) and the similarity of corresponding points across the population (a low ensemble entropy). The similarity metric, however, isn’t constrained to be just spatial proximity, but uses local sulcal depth measurements as well as probabilistic connectivity maps, computed from DWI scans via a stochastic tractography algorithm, to enhance the correspondence definition. We propose a novel method for projecting this fiber connectivity information on the cortical surface, using a surface evolution technique. Our cortical correspondence method {{does not require a}} spherical parameterization. Experimental results are presented, showing improved <b>correspondence</b> <b>quality</b> demonstrated by a cortical thickness analysis, as compared to correspondence methods using spatial metrics as the sole correspondence criterion. ...|$|E
40|$|Establishing optimal {{correspondence}} across object populations {{is essential}} to statistical shape analysis. Minimizing the description length (MDL) is a popular method for finding correspondence. In this work, we extend the MDL method by incorporating various local curvature metrics. Using local curvature can improve performance by ensuring that corresponding points exhibit similar local geometric characteristics that can’t always be captured by mere point locations. We illustrate results {{on a variety of}} anatomical structures. The MDL method with a combination of point locations and curvature outperforms all the other methods we analyzed, including traditional MDL and spherical harmonics (SPHARM) correspondence, when the analyzed object population exhibits complex structure. When the objects are of simple nature, however, there’s no added benefit to using the local curvature. In our experiments, we did not observe {{a significant difference in the}} <b>correspondence</b> <b>quality</b> when different curvature metrics (e. g. principal curvatures, mean curvature, Gaussian curvature) were used...|$|E
40|$|To {{assure that}} records used by [Name] {{employees}} are properly managed. Records include reports, <b>correspondence,</b> diaries, <b>quality</b> records and technical records. Quality records include the following: internal audit reports, management reviews, corrective and preventive actions. Technical records include forms, worksheets, control graphs, inspection reports, and test reports. This procedure {{applies to the}} management of records within the [Name]. Records may be either in hard copy or electronic form. A. [Third Level Manager]: verifies adequacy and accuracy of forms and worksheets used in their area, reviews report packets for completeness, and ensures employees are trained in record keeping. B. [Second Level Manager]: implements record management system in respective branch, ensures proper forms and worksheets are used in respective branches, and follows established record storage and disposal schedule. C. [First Level Manager]...|$|R
40|$|Measured room {{acoustical}} parameter {{values are}} often investigated for <b>correspondence</b> with perceptual <b>quality.</b> However, these experiments usually deal with larger auditoriums rather then with smaller studio and listening spaces. The paper examines {{a set of}} selected objective measures on the changes of geometrical and acoustical properties of typical listening and recording spaces. The theoretical experiment {{is based on a}} conventional beam tracing room acoustical model. Results of this experiment show some clear trends in the relationship of architectural and room acoustical parameters...|$|R
40|$|Accurate {{fundamental}} matrix estimation from computed correspondences is hard {{to achieve}} depending on the constraints on computational time and available data (i. e. <b>correspondences</b> and <b>quality</b> scores). Several algorithms exist for this task, like the 8 -points, the 7 -points algorithm [1] or robust methods such as RANSAC [2], MSAC [3] or LMedS [4]. Robust methods are capable of discriminating correspondence outliers, thus, obtaining better results. Additionally, some variations of the previous methods have been proposed. For instance PROSAC [5] is an improvement of RANSAC which takes into account additional information {{of the quality of}} the matches to largely reduce the computational cost of the fundamental matrix estimation process. This work proposes a new robust method for fundamental matrix estimation that combines the benefits of PROSAC and LMedS algorithms, namely improved quality, reduced computational time and less parameters to adjustPostprint (published version...|$|R
40|$|Abstract. The {{identification}} of corresponding landmarks across {{a set of}} training shapes {{is a prerequisite for}} statistical shape model (SSM) construction. We automatically establish 3 D correspondence using one new and several known alternative approaches for consistent, shape-preserving, spherical parameterization. The initial correspondence determined by all employed methods is refined by optimizing a groupwise objective function. The quality of all models before and after optimization is thoroughly evaluated using several data sets of clinically relevant, anatomical objects of varying complexity. <b>Correspondence</b> <b>quality</b> is benchmarked in terms of the SSMs ’ specificity and generalization ability, which are measured using different surface based distance functions. We find that our new approach performs best for complex objects. Furthermore, all new and previously published methods of our own allow for (i) building SSMs that are significantly better than the well-known SPHARM method, (ii) establishing quasi-optimal correspondence for low and moderately complex objects without additional optimization, and (iii) considerably speeding up convergence, thus, providing means for practical, fast, and accurate SSM construction...|$|E
40|$|Abstract We pose robust {{matching}} with parametric and non-parametric constraints as {{the problem}} of finding a stable independent set (SIS) in an oriented graph whose vertices are all possible correspondences, whose edges capture {{the structure of the}} constraints and whose edge orientation represents pairwise comparison ‘is better ’ based on <b>correspondence</b> <b>quality,</b> including the uncertainty of this comparison. We show SIS possess properties of both robustness and weak optimality. The main contribution of this paper is algorithmic speedup that results from exploiting the dependence between the standard uniqueness constraint and the parametric constraint. The general theory is demonstrated on the example of image stitching using homography model. The algorithm needs at most k N 2 calls of a procedure testing if two ellipse correspondences are consistent with a general homography. The previous known SIS algorithm needed O(N 4) tests. Experiments show the method gives good results and is fast in practice with k ≈ 0. 3. 1...|$|E
40|$|The {{identification}} of corresponding landmarks across {{a set of}} training shapes {{is a prerequisite for}} statistical shape model (SSM) construction. We automatically establish 3 D correspondence using one new and several known alternative approaches for consistent, shape-preserving, spherical parameterization. The initial correspondence determined by all employed methods is refined by optimizing a groupwise objective function. The quality of all models before and after optimization is thoroughly evaluated using several data sets of clinically relevant, anatomical objects of varying complexity. <b>Correspondence</b> <b>quality</b> is benchmarked in terms of the SSMs' specificity and generalization ability, which are measured using different surface based distance functions. We find that our new approach performs best for complex objects. Furthermore, all new and previously published methods of our own allow for (i) building SSMs that are significantly better than the well-known SPHARM method, (ii) establishing quasi-optimal correspondence for low and moderately complex objects without additional optimization, and (iii) considerably speeding up convergence, thus, providing means for practical, fast, and accurate SSM construction...|$|E
40|$|This paper {{describes}} {{experiments on}} learning Dutch phonotactic rules using Inductive Logic Programming, a machine learning discipline based on inductive logical operators. Two {{different ways of}} approaching the problem are experimented with, and compared against each other {{as well as with}} related work on the task. The results show a direct <b>correspondence</b> between the <b>quality</b> and informedness of the background knowledge and the constructed theory, demonstrating the ability of ILP to take good advantage of the prior domain knowledge available. Further research is outlined. ...|$|R
40|$|International audienceWe are {{concerned}} {{by the use of}} Factorial Correspondence Analysis (FCA) for image retrieval. FCA is designed for analyzing contingency tables. For adapting FCA on images, we first define "visual words" computed from Scalable Invariant Feature Transform (SIFT) descriptors in images and use them for image quantization. At this step, we can build a contingency table crossing "visual words" as terms/words and images as documents. The method was tested on the Caltech 4 and Stewénius and Nistér datasets on which it provides better results (quality of results and execution time) than classical methods as tf*idf or Probabilistic Latent Semantic Analysis (PLSA). To scale up and improve the retrieval quality, we propose a new retrieval schema using inverted files based on the relevant indicators of <b>Correspondence</b> Analysis (<b>quality</b> of representation and contribution to inertia). The numerical experiments show that our algorithm performs faster than the exhaustive method without losing precision...|$|R
40|$|Automatic {{construction}} of Shape and Appearance Models from examples via establishing correspondences across the training set {{has been successful}} in the last decades. One successful measure for establishing <b>correspondences</b> of high <b>quality</b> is minimum description length (MDL). In other approaches {{it has been shown that}} parts+geometry models which model the appearance of parts of the object and the geometric relation between the parts have been successful for automatic model building. In this paper it is shown how to fuse the above approaches and use MDL to fully automatically build optimal parts+geometry models from unlabeled images. ...|$|R
40|$|We {{consider}} {{the problem of}} establishing dense correspondences within a set of related shapes of strongly varying geometry. For such input, traditional shape matching approaches often produce unsatisfactory results. We propose an ensemble optimization method that improves given coarse correspondences to obtain dense correspondences. Following ideas from minimum description length approaches, it maximizes the compactness of the induced shape space to obtain high-quality correspondences. We make a number of improvements that are important for computer graphics applications: Our approach handles meshes of general topology and handles partial matching between input of varying topology. To this end we introduce a novel part-based generative statistical shape model. We develop a novel analysis algorithm that learns such models from training shapes of varying topology. We also provide a novel synthesis method that can generate new instances with varying part layouts and subject to generic variational constraints. In practical experiments, we obtain a substantial improvement in <b>correspondence</b> <b>quality</b> over state-of-the-art methods. As example application, we demonstrate a system that learns shape families as assemblies of deformable parts and permits real-time editing with continuous and discrete variability...|$|E
40|$|Abstract. We {{consider}} {{the problem of}} establishing dense correspondences within a set of related shapes of strongly varying geometry. For such input, traditional shape matching approaches often produce unsatisfactory results. We propose an ensemble optimization method that improves given coarse cor-respondences to obtain dense correspondences. Following ideas from minimum description length approaches, it maximizes the compactness of the induced shape space to obtain high-quality correspondences. We make a number of improvements that are important for computer graphics applications: Our ap-proach handles meshes of general topology and handles partial matching be-tween input of varying topology. To this end we introduce a novel part-based generative statistical shape model. We develop a novel analysis algorithm that learns such models from training shapes of varying topology. We also provide a novel synthesis method that can generate new instances with varying part lay-outs and subject to generic variational constraints. In practical experiments, we obtain a substantial improvement in <b>correspondence</b> <b>quality</b> over state-of-the-art methods. As example application, we demonstrate a system that learns shape families as assemblies of deformable parts and permits real-time editing with continuous and discrete variability. (a) shape collection (b) coarse segmentation (c) dense correspondences 1...|$|E
40|$|The actual {{geographic}} information systems today {{provide access to}} {{a large number of}} heterogeneous and distributed sources. The multiplication of resources and increased data requires the use of Web services that appear as a solution to ensure interoperability between different resources. They are able to collaborate and share control of process data and information between applications on different platforms. The use of geographic data through Web services shows the geospatial Web Services (GWS). A growing number of GWS designed to interoperate spatial information over the network have emerged. GWS are changing the way in which spatial information systems and applications are designed, developed, and deployed. When GWS is increasing, the difficulty of the service discovery increases too. The service discovery represents one of the interactions between Web service components (supplier, customer and UDDI). It is unfortunately that it is based only on the syntax. The semantic aspect necessary to satisfy the user is absent. The use of semantic Web technology in the Web service discovery phase gives rise to the Web service semantic discovery. The latter is based on semantic reasoning. It enhances the accuracy of search results compared to traditional techniques of Web service discovery, the additional matching accuracy in terms of computing power. In this paper we are interested to the distributed GWS semantic discovery based on geographical metadata held in geo-catalogs. The metadata used in our case is designed according to the ISO 19119 standard reinforced by the quality criteria. The suggested approach is Geospatial Web services semantic discovery using metadata and multi-agents system. It is based on the co-operation of a set of agents using the semantic capacities of the geospatial Web service through the catalogues based on the metadata according to standard ISO 19119. The agents of our architecture take in account the principal properties of the agent technology (Portability, Autonomy, Stability, Persistence, Flexibility, and Sociability). The based idea of our approach is to classify to geospatial Web services by functionalities by using metadata of ISO 19119 standards. Optimization of the recent approach is done by using quality and personalization. Quality management plays a vital role to satisfy the user needs (explicit or implicit). Personalization aims to facilitate the expression of user needs and make information intelligible to the selected user and exploitable. Our discovery approach based on semantic metadata organized in catalogs, proposed in the publication phase of GWS two levels of description. The first level concerns the GWS classes catalog based on the ISO 19119 standards and quality criteria; the second level concerns the UDDI registry through the WSDL. In the discovery phase, this solution allows to restrict the search space and increase the number of relevant services through the application of the algorithm of "matching". In the metadata level, the matching algorithm “LARKS” is adjusted by applying the first three filters (context, profile, similarity) on the quality criteria contained in the request and description of classes available in GWS metadata catalog. This solution enables us to have a result like "relaxed match”. In the UDDI registry level, the application of “Matching” algorithm is based on the interrogation mechanism of the UDDI registry using the different pages (White pages, yellow pages, green pages). A list of GWS classified by order of <b>correspondence</b> (<b>quality</b> aspect, functional aspect) {{is the result of the}} discovery. For the implementation of our approach, we propose the tourism field as application domain; we use a prototype ontology which includes only the part of the terminology field of tourism. We develop a Web application, an adaptation of a traditional Web architecture. Our implementation is based on the use of metadata and the algorithm of "matching". To make these persistent metadata, we chose the pair XML / XML Schema, based on the principle of markup languages SGML family. A set of interface is available to the user (Provider /Customer / User), the interface is made using PHP that provides ease of interfacing with databases. These interfaces are: 1. Interfaces for acquiring knowledge of the user profile; 2. GWS publication interfaces; 3. GWS discovery interfaces...|$|E
40|$|Exhibition of {{monochrome}} works, Annie Whiles drawings {{are made}} painstakingly neatly with pencil crayon, Alison Jones’ watercolours are informal and splashy. The work shares {{a relationship with}} objects and spaces and the <b>correspondence</b> between <b>qualities</b> of drawing, texture, composition and line of very particular places and things. Annie Whiles has placed objects and things together to form portraits of polarised powers, objects are selected on their origin and status to form difficult relationships, often unstable and comical combinations, rendered with a steady hand. Alison Jones depicts plush interiors and the parade of wealth and glamour published in W magazine online. An exacting process of elimination has been undertaken by the artist, for this apparently convivial mood and event to take place. Whilst the work of both artists invite recognition and pleasure, this welcome has conditions: it asks the viewer to check their politics and art world, along with their coat at reception...|$|R
40|$|Figure 1. Visual abstract. Ricardo Marín-Viadel {{looking at}} the expert’s eyes, by J. Roldán, 2011. Digital photogra-phy with an {{indirect}} visual quotation from Daumier (1855). A research photo essay in visual a/r/tography is a coherent, systematic, and original group of visual images about education (or any other social science). This relatively recent research methodology essentially produces new visual images about educational questions. Like any other research methodology, visual a/r/tography assumes (a) certain basic epistemological positions, (b) distinctive methodological strategies, and (c) spe-cific quality criteria. We suggest five different paths to identify assessment criteria, {{the most important of}} these residing in the development of a framework of <b>correspondences</b> between <b>quality</b> criteria usually applied to research reports based on words (sentences, paragraphs, verbal thinking) and those based on visual images (photos, photo essays, visual thinking). 14 Visual Arts Research Winter 2012 The use of visual arts-based research methodologies and specifically visual a/r/togra-phy raises several epistemological, methodological, and evaluative problems. Perhap...|$|R
5000|$|Nonetheless, this {{extraordinarily}} large ensemble is {{used with}} great moderation by the composer. In particular, Penderecki exploits {{the use of}} chamber ensembles coupled by their <b>correspondence</b> of timbre <b>quality</b> and specific coloristic effect. [...] With the resulting pallet of orchestral colors at his command, Penderecki is able to provide a musical commentary and thus determine the expressive quality of a given scene. [...] While the smaller ensembles predominate through the work, Penderecki resources to the full ensemble resonance for dramatic effect, emphasizing this way the most emotionally charged scenes, such as the exorcisms of the Ursuline nuns {{and the death of}} Grandier.|$|R
2500|$|Her {{writings}} {{brought her}} little money, yet they secured her fame and many friends, first {{among them the}} Abbé Grégoire, with whom she carried on an extensive <b>correspondence.</b> [...] The <b>quality</b> of her scholarship also earned her the respect and friendship of several prominent Boston intellectuals, most notably William Smith Shaw and Joseph Stevens Buckminster. [...] These men would soon establish the Anthology Society, precursor to the Boston Athenæum, and become Adams’s lifelong allies and patrons, establishing in 1809 a modest annuity that would keep her out of poverty. It was through the sponsorship of these gentlemen that aided her in preparing her History of the Jews (1812).|$|R
40|$|Active {{triangulation}} {{systems are}} widely used for precise and fast measurements. Many different coding strategies have been invented to solve the <b>correspondence</b> problem. The <b>quality</b> of the measurement results depends on {{the accuracy of the}} pixel assignments. The most established method uses phase shifted-patterns projected on the scene. This is compared to a method using statistical patterns. In both coding strategies, the number and the spatial frequency of the projected patterns is varied. The measurements and calculations for all presented results were done with exactly the same measurement setup in a narrow time window to avoid any changes and to guarantee identical technical preconditions as well as comparability...|$|R
40|$|Abstract. We {{present a}} fully {{automatic}} model based system for segmenting bone and cartilage in magnetic resonance (MR) {{images of the}} knee. The segmentation method is based on Active Appearance Models (AAM) built from manually segmented examples from the Osteoarthritis Initiative database. High <b>quality</b> <b>correspondences</b> for the model are generated using a Minimum Description Length (MDL) Groupwise Image Registration method. A multi start and hierarchical modelling scheme is used to robustly match the model to new images. The model {{has been applied to}} the MICCAI 2010 Grand Challenge test data with no tuning from the supplied training data, and successfully segmented all the test data automatically to a good degree of accuracy. ...|$|R
40|$|To the Editor: Most {{next-generation}} sequencing (NGS) quality scores are space intensive, redundant and often misleading. In this <b>Correspondence,</b> we recover <b>quality</b> information directly from sequence data using a compression tool named Quartz, rendering such scores redundant and yielding substantially better {{space and time}} efficiencies for storage and analysis. Quartz is designed to operate on NGS reads in FASTQ format, {{but it can be}} trivially modified to discard quality scores in other formats for which scores are paired with sequence information. Discarding 95 % of quality scores resulted, counterintuitively, in improved SNP calling, implying that compression need not {{come at the expense of}} accuracy. Hertz FoundationNational Institutes of Health (U. S.) (NIH grant GM 108348...|$|R
40|$|High <b>quality</b> dense image <b>correspondence</b> {{estimation}} {{between two}} images {{is an essential}} pre-requisite for view interpola-tion in visual media production. Due to the ill-posed nature of the problem, automated estimation approaches are prone to erroneous <b>correspondences</b> and subsequent <b>quality</b> degra-dation, e. g. {{in the presence of}} ambiguous movements that require human scene understanding to resolve. Where visu-ally convincing results are essential, artifacts resulting from estimation errors must be repaired by hand with image edit-ing tools. In this paper, we propose a new workflow alter-native by fixing the correspondences instead of fixing the interpolated images. We combine realtime interactive corre-spondence display, multi-level user guidance and algorithmic subpixel precision to counteract failure cases of automated estimation algorithms. Our results show that already few interactions improve the visual quality considerably...|$|R
40|$|Highqualitydenseimagecorrespondenceestimationbetween {{two images}} is an {{essential}} pre-requisite for view interpolation in visual media production. Due to the ill-posed nature of the problem, automated estimation approaches are prone to erroneous <b>correspondences</b> and subsequent <b>quality</b> degradation, e. g. {{in the presence of}} ambiguous movements that require human scene understanding to resolve. Where visually convincing results are essential, artifacts resulting from estimation errors must be repaired by hand with image editing tools. In this paper, we propose a new workflow alternative by fixing the correspondences instead of fixing the interpolated images. We combine realtime interactive correspondencedisplay, multi-level user guidanceand algorithmic subpixel precision to counteract failure cases of automated estimation algorithms. Our results show that already few interactions improve the visual quality considerably. Categories andSubject Descriptor...|$|R
40|$|Recently, {{national}} Universities in Japan were {{pointed out}} many problems, for example superannuation of the buildings, delay of <b>correspondence</b> to quantitative <b>quality</b> change of educational research. To solve the problems, The Ministry of Education, Culture, Sports, Science and Technology announce the correspondence policy "Five year plan of national Universities facilities urgent maintenance (2001. 3) " "Base of wisdom (2002. 5) ". Since National Universities in Japan were incorporated in April 2004, managerial aspect for facilities maintenance {{and construction of}} campus has been required. For the first step, idea and goal of campus facility management should be established reflecting all students' and teaching/administrative staffs' demand. This research aims to make classification Method Of Campus Facilities Characteristics for Facilities Management本研究は以下の 2 つを目的としている。　 1 ）大学施設整備の目標策定のために、専門家とユーザという異なる視点を持つ参加主体にて整備対象を項目として明確化し、その重要度を求める手法を構築すること。　 2 ）大学施設整備の計画策定のために、重要度と併せてユーザ視点から現整備状況に対する満足度と品質認識を総合化し、整備項目の満足度特 1 生を明確化する方法を構築すること...|$|R
40|$|In {{addition}} to visual {{information from the}} face of the speaker, a less natural, but nowadays extremely important visual component of speech is its representation in script. In this review, neuro-imaging studies are examined which were aimed to understand how speech and script are associated in the adult "literate" brain. The reviewed studies focused on the role of different stimulus and task factors and effective connectivity between different brain regions. The studies will be summarized in a neural mechanism for the integration of speech and script that can serve as a basis for future studies addressing (the failure of) literacy acquisition. In this proposed mechanism, speech sound processing in auditory cortex is modulated by co-presented visual letters, depending on the congruency of the letter-sound pairs. Other factors of influence are temporal <b>correspondence,</b> input <b>quality</b> and task instruction. We present results showing that the modulation of auditory cortex is most likely mediated by feedback from heteromodal areas in the superior temporal cortex, but direct influences from visual cortex are not excluded. The influence of script on speech sound processing occurs automatically and shows extended development during reading acquisition. This review concludes with suggestions to answer currently still open questions to get closer to understanding the neural basis of normal and impaired literacy...|$|R
40|$|Abstract- This paper {{addresses}} concrete {{questions concerning}} the delivery of streaming video and multimedia application services over emerging WiMAX (Worldwide Interoperability for Microwave Access) networks, making a special emphasis on {{the features of the}} mobile implementation. The authors examined a selected number of current challenging WiMAX system designs and architectures in regards with their ability to provide flexible QoS parameters for dynamic real-time traffic such as video-gaming, streaming video and conferencing services, highlighting cross-layer interaction to achieve effective system performance and support resource allocation between multiple users. Deriving from the simulation results and conclusions advanced by the researchers, an experimental approach has been put forward to explore cross-layer optimization method providing direct <b>correspondence</b> between QoS (<b>quality</b> of services) parameters for up-layer user applications and MAC service flows i...|$|R
40|$|A key {{challenge}} in feature correspondence is {{the difficulty in}} differentiating true and false matches at a local descriptor level. This forces adoption of strict similarity thresholds that discard many true matches. However, if analyzed at a global level, false matches are usually randomly scattered while true matches tend to be coherent (clustered around a few dominant motions), thus creating a coherence based separability constraint. This paper proposes a non-linear regression technique that can discover such a coherence based separability constraint from highly noisy matches and embed it into a correspondence likelihood model. Once computed, the model can filter the entire set of nearest neighbor matches (which typically contains over 90 percent false matches) for true matches. We integrate our technique into a full feature correspondence system which reliably generates large numbers of good <b>quality</b> <b>correspondences</b> over wide baselines where previous techniques provide few or no matches...|$|R
40|$|IT system architectures, as well {{as other}} systems, are often {{described}} by formal models or informal diagrams. In practice, there are often a number of versions of a model, e. g. for different views of a system, divergent variants, or a series of revisions. Understanding how versions of a model correspond or differ is crucial, yet little work has been done on automated assistance for matching models and diagrams. We have designed a framework based on Bayesian methods for finding these correspondences automatically. We represent models and diagrams as graphs whose nodes have attributes such as name, type, connections, and containment relations, and we have developed probabilistic models for rating the <b>quality</b> of candidate <b>correspondences</b> based on various features of the nodes in the graphs. Given the probabilistic models, we can find high <b>quality</b> <b>correspondences</b> using search algorithms. Preliminary experiments focusing on architectural models suggest that the technique is promising...|$|R
40|$|Affine {{covariant}} local {{image features}} are {{a powerful tool}} for many applications, including matching and calibrating wide baseline images. Local feature extractors that use a saliency map to locate features require adaptation processes in order to extract affine covariant features. The most effective extractors make use of the second moment matrix (SMM) to iteratively estimate the affine shape of local image regions. This paper shows that the Hessian matrix can be used to estimate local affine shape in a similar fashion to the SMM. The Hessian matrix requires significantly less computation effort than the SMM, allowing more efficient affine adaptation. Experimental results indicate that using the Hessian matrix in conjunction with a feature extractor that selects features in regions with high second order gradients delivers equivalent <b>quality</b> <b>correspondences</b> in less than 17 % of the processing time, compared to the same extractor using the SMM...|$|R
