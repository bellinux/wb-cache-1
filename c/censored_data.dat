1310|567|Public
2500|$|The {{two common}} {{approaches}} to exclude outliers are truncation (or trimming) and Winsorising. Trimming discards the outliers whereas Winsorising replaces the outliers with the nearest [...] "nonsuspect" [...] data. Exclusion {{can also be}} a consequence of the measurement process, such as when an experiment is not entirely capable of measuring such extreme values, resulting in <b>censored</b> <b>data.</b>|$|E
50|$|Special {{techniques}} {{may be used}} {{to handle}} <b>censored</b> <b>data.</b> Tests with specific failure times are coded as actual failures; <b>censored</b> <b>data</b> are coded for the type of censoring and the known interval or limit. Special software programs (often reliability oriented) can conduct a maximum likelihood estimation for summary statistics, confidence intervals, etc.|$|E
5000|$|Support for <b>censored</b> <b>data,</b> {{temporal}} data, time series, and unit based data ...|$|E
30|$|In {{the next}} sub-section, our {{proposed}} control charts are developed when the <b>censoring</b> <b>data</b> exist.|$|R
50|$|Note that winsorizing is not {{equivalent}} to simply excluding data, {{which is a}} simpler procedure, called trimming or truncation, but is a method of <b>censoring</b> <b>data.</b>|$|R
40|$|Analysis of {{life time}} {{is one of}} {{statistical}} analysis which many utilized in industry and healt. Life time data having a form complete or <b>censor</b> <b>data,</b> that is a nonnegative random variable. Determination of point estimation is utilized MLE (maximum likelihood estimator), goodness of fit distribution is utilized Andersson Darling methods. Point estimation of life time test report on {{mean time to failure}} (MMTF), hazard fuction h(t), survival function S(t). Interval estimation is utilized pivotal quantity methods. Key words : <b>censor</b> <b>data,</b> MLE, mean time to failure, hazard function, survival function. ...|$|R
5000|$|Then the ordered probit {{technique}} {{will use}} the observations on , which are a form of <b>censored</b> <b>data</b> on , to fit the parameter vector [...]|$|E
50|$|A model {{commonly}} used to deal with <b>censored</b> <b>data</b> is the Tobit model, including variations such as theTobit Type II, Type III, and Type IV models.|$|E
50|$|One of the {{earliest}} attempts to analyze a statistical problem involving <b>censored</b> <b>data</b> was Bernoulli's 1766 analysis of smallpox morbidity and mortality data to demonstrate the efficacy of vaccination.|$|E
30|$|With {{decreasing}} n, {{the estimation}} results for both methods improve for zero-failure data, although, for some cases, the bias values provided by BE and MLE {{do not follow}} this rule. This differs {{from the effects of}} complete <b>data</b> or other <b>censoring</b> <b>data.</b>|$|R
40|$|Random {{survival}} forest can {{be extremely}} time consuming for large data set. In this paper we propose few computationally efficient algorithms in prediction of survival function. We explore {{the behavior of the}} algorithms for different cancer data sets. Our construction includes right <b>censoring</b> <b>data</b> too. We have also applied the same for competing risk survival function. Comment: 11 pages; 5 figure...|$|R
40|$|In {{this paper}} {{we will give}} the {{relationships}} of several Score tests and Weighted tests for right <b>censoring</b> <b>data</b> with other classical tests. Special care will be taken with the case of ties and {{with the kind of}} estimation of the variance used. After the description of ten tests, a comparative study will be made among them. Finally, an application with a real example will be included...|$|R
50|$|The {{problem of}} <b>censored</b> <b>data,</b> {{in which the}} {{observed}} value of some variable is partially known, {{is related to the}} problem of missing data, where the observed value of some variable is unknown.|$|E
50|$|These {{forms of}} missingness take {{different}} types, with different {{impacts on the}} validity of conclusions from research: Missing completely at random, missing at random, and missing not at random. Missing data can be handled similarly as <b>censored</b> <b>data.</b>|$|E
5000|$|Sometimes {{engineers}} plan a {{test program}} so that, {{after a certain}} time limit or number of failures, all other tests will be terminated. These suspended times are treated as right-censored data. The use of <b>censored</b> <b>data</b> is intentional.|$|E
40|$|AbstractThe {{purpose of}} this paper is to {{classify}} UIS data in order to identify their risk, reduce drug abuse, and to prevent high-risk in HIV behavior. A method for fitting proportional hazards models to <b>censored</b> survival <b>data</b> is described. Stratification is performed recursively. A tree-based method for <b>censored</b> survival <b>data</b> is developed, based on maximizing the difference in survival between groups of patients represented by nodes in a binary tree...|$|R
5000|$|Ying, Z. (1993), A {{large sample}} study of rank {{estimation}} for <b>censored</b> regression <b>data.</b> The Annals of Statistics, 76-99.|$|R
40|$|We {{previously}} {{proposed a}} class of ordered weighted logrank tests for analyzing <b>censored</b> survival <b>data</b> under order restrictions. However the power of these tests is asymmetrical with respect to possible alternative configurations and could be inferior to the non-ordered logrank test in extreme cases. A modified ordered logrank test is proposed to remedy this situation. The test is shown to be asymptotically locally equivalent to the generalized Jonckheere's test but computationally simpler. <b>Censored</b> survival <b>data</b> Logrank test Ordered alternatives...|$|R
50|$|Gentleman {{was awarded}} a Bachelor of Science degree in {{mathematics}} from the University of British Columbia. He {{was awarded a}} Ph.D. degree in Statistics from University of Washington in 1988; his thesis title was Exploratory methods for <b>censored</b> <b>data.</b>|$|E
5000|$|... {{where the}} {{parameters}} [...] are the externally imposed endpoints of the observable categories. Then the ordered logit technique {{will use the}} observations on y, which are a form of <b>censored</b> <b>data</b> on y*, to fit the parameter vector [...]|$|E
5000|$|Sometimes {{a failure}} is planned and {{expected}} {{but does not}} occur: operator error, equipment malfunction, test anomaly, etc. The test result was not the desired time-to-failure but can be (and should be) used as a time-to-termination. The use of <b>censored</b> <b>data</b> is unintentional but necessary.|$|E
40|$|We {{consider}} {{methods of}} categorical data analysis applicable {{for the survival}} experimental design. Categorical tests for right <b>censored</b> survival <b>data</b> with applications to epidemiology and AIDS research are discussed. We introduce Wald’s type homogeneity tests based on Kaplan–Meier and Nelson–Aalen estimators for categorical null hypothesis in right <b>censored</b> survival <b>data</b> case. Classical tests for contingency tables and the survival Wald’s type tests are examined to assess their validity to use them for different kinds of statistical conclusions...|$|R
2500|$|Heagerty, Patrick J.; Lumley, Thomas; and Pepe, Margaret S. (2000); Time-dependent ROC Curves for <b>Censored</b> Survival <b>Data</b> and a Diagnostic Marker, Biometrics, 56:337–344 ...|$|R
40|$|In {{this paper}} we {{introduce}} and study cause specific reversed hazard {{rates in the}} context of left <b>censored</b> lifetime <b>data</b> with multiple causes. Nonparametric inference procedure for left <b>censored</b> lifetime <b>data</b> with multiple causes using cause specific reversed hazard rate is discussed. Asymptotic properties of the estimators are studied. Simulation studies are conducted to assess the efficiency of the estimators. Further, the proposed method is applied to mice mortality data (Hoel 1972) and Australian twin data (Duffy et al. 1990) ...|$|R
5000|$|The {{two common}} {{approaches}} to exclude outliers are truncation (or trimming) and Winsorising. Trimming discards the outliers whereas Winsorising replaces the outliers with the nearest [...] "nonsuspect" [...] data. Exclusion {{can also be}} a consequence of the measurement process, such as when an experiment is not entirely capable of measuring such extreme values, resulting in <b>censored</b> <b>data.</b>|$|E
5000|$|He {{was among}} the first to apply the {{bootstrap}} in his 1975 analyses of 2&times;2 designs with a missing cell. [...] His chief contributions to statistics are in the area of small sample statistics, including a uniformly most powerful unbiased (UMPU) permutation test for Type I <b>censored</b> <b>data,</b> an exact test for comparing variances, and an exact test for cross-over designs.|$|E
50|$|An {{important}} {{advantage of}} the Kaplan-Meier curve is that the method can take into account some types of <b>censored</b> <b>data,</b> particularly right-censoring, which occurs if a patient withdraws from a study, is lost to follow-up, or is alive without event occurrence at last follow-up. On the plot, small vertical tick-marks indicate individual patients whose survival times have been right-censored. When no truncation or censoring occurs, the Kaplan-Meier curve is the complement of the empirical distribution function.|$|E
40|$|We {{show that}} {{two forms of}} linear rank {{statistics}} for right <b>censored</b> and grouped <b>data</b> are equivalent. In the case of no tied value among uncensored observations, we provide some intuition about the equivalence. Some key words: Likelihood ratio principle; Linear rank statistic; Right <b>censored</b> and grouped <b>data.</b> 1...|$|R
40|$|Abstract — Massive {{datasets}} arise naturally as {{a result}} of automated monitoring and transaction archival. Military intelligence data, stock trades, retail purchases, medical and scientific observations, weather monitoring, spacecraft sensor <b>data</b> and <b>censors</b> <b>data</b> are all examples of data streams continuously logged and stored in extremely large volumes, which create the need for innovative data visualization solutions. Although, there are many on-going researches and developments on this field recently, there are only few solutions to visualize information for general public. In this paper, I explore different methods to use ManoStick chart to visualize information. Index Terms—data visualization, chart, graph, manostic...|$|R
40|$|This article {{introduces}} a new measure of explained variation {{for use with}} <b>censored</b> survival <b>data.</b> It is {{a modified version of}} a measure previously described by John O'Quigley and colleagues, itself a modification of Nagelkerke’s earlier proposal for a general index of determination. I describe Stata programs str 2 ph, which implements the new measure, and str 2 d, which implements a measure proposed in 2004 by Royston and Sauerbrei. I provide examples with real data. Copyright 2006 by StataCorp LP. <b>censored</b> survival <b>data,</b> regression models, index of determina- tion, explained variation, explained randomness, information gain...|$|R
50|$|One of the {{earliest}} attempts to analyse a statistical problem involving <b>censored</b> <b>data</b> was Daniel Bernoulli's 1766 analysis of smallpox morbidity and mortality data to demonstrate the efficacy of vaccination. An early paper to use the Kaplan-Meier estimator for estimating censored costs was Quesenberry et al. (1989), however this approach was later found in 1997 by Lin et al. to be invalid unless all patients accumulated costs with a common deterministic rate function over time, they proposed an alternative estimation technique known as the Lin estimator.|$|E
5000|$|The Nelson-Aalen {{estimator}} is a non-parametric estimator of {{the cumulative}} hazard rate function {{in case of}} <b>censored</b> <b>data</b> or incomplete data. It is used in survival theory, reliability engineering and life insurance to estimate the cumulative number of expected events. An [...] "event" [...] can be {{the failure of a}} non-repairable component, the death of a human being, or any occurrence for which the experimental unit remains in the [...] "failed" [...] state (e.g., death) from the point at which it changed on. The estimator is given by ...|$|E
5000|$|This {{textbook}} takes {{a learning}} by doing approach, and [...] "covers basic econometric methods (statistics, simple and multiple regression, nonlinear regression, maximum likelihood, and generalized method of moments), and addresses the creative process of model building with due attention to diagnostic testing and model improvement. Its last part is devoted to two major application areas: the econometrics of choice data (logit and probit, multinomial and ordered choice, truncated and <b>censored</b> <b>data,</b> and duration data) and the econometrics of time series data (univariate time series, trends, volatility, vector autoregressions, and a brief discussion of SUR models, panel data, and simultaneous equations)." ...|$|E
40|$|Let T be a nonnegative random {{variable}} representing the lifetimes {{of individuals in}} some population. Let f(t) denote the probability density function of T and F(t) denote the distribution function of T, the hazard function of T defined as   F(t) - 1   S(t)    where S(t) f(t) h(t)   If equation (1) integrated we have cumulative hazard function H (t).   This paper describes application of kernel method for estimation of hazard function h (.) based <b>censoring</b> <b>data.</b> And then we will show that the hazard estimator is unbiased asymptotically, consistent, and normal asymptotically.   Key word: kernel methods, estimation hazard function...|$|R
40|$|As a {{flexible}} {{alternative to the}} Cox model, the additive risk model assumes that the hazard function {{is the sum of}} the baseline hazard and a regression function of covariates. For right <b>censored</b> survival <b>data</b> when variable selection is needed along with model estimation, we propose a path consistent model selector using a modified Lasso approach, under the additive risk model assumption. We show that the proposed estimator possesses the oracle variable selection and estimation property. Applications of the proposed approach to three right <b>censored</b> survival <b>data</b> sets show that the proposed modified Lasso yields parsimonious models with satisfactory estimation and prediction results. Copyright q 2007 John Wiley & Sons, Ltd...|$|R
40|$|Traditional {{inferential}} procedures {{often fail}} with <b>censored</b> and truncated <b>data,</b> especially when sample sizes are small. In this paper we evaluate {{the performances of}} the double and single bootstrap interval estimates by comparing the double percentile (DB-p), double percentile-t (DB-t), single percentile (B-p), and percentile-t (B-t) bootstrap interval estimation methods via a coverage probability study when the <b>data</b> is <b>censored</b> using the log logistic model. We then apply the double bootstrap intervals to real right <b>censored</b> lifetime <b>data</b> on 32 women with breast cancer and failure data on 98 brake pads where al...|$|R
