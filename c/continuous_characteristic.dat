22|201|Public
50|$|The inadequacies of this conclusion, however, were {{pointed out}} by Frenkel in his {{revision}} of the kinetic theory of solids and the theory of elasticity in liquids. This revision follows directly from the <b>continuous</b> <b>characteristic</b> of the structural transition from the liquid state into the solid one when this transition is not accompanied by crystallization—ergo the supercooled viscous liquid. Thus we see the intimate correlation between transverse acoustic phonons (or shear waves) and the onset of rigidity upon vitrification, as described by Bartenev in his mechanical description of the vitrification process.|$|E
30|$|Therefore, this nanowall network {{structure}} is promising in fields where a large surface/volume ratio is needed, for instance, gas sensors based on surface change after exposing {{to a particular}} gas. Compared with separated nanostructures, such as nanowires and nanoparticles, its <b>continuous</b> <b>characteristic</b> along the lateral direction makes {{it much easier to}} fabricate to various electronic devices. Moreover, Si substrate is helpful for integrated sensors through the combination with silicon micromachining as well as conventional Si electronics.|$|E
40|$|We {{consider}} {{the problem of}} depth estimation from a sin-gle molecular image in this work. It is a challenging task as no reliable depth cues are available, e. g., stereo correspon-dences, motions etc. Previous efforts have been focusing on exploiting geometric priors or additional sources of in-formation, with all using hand-crafted features. Recently, there is mounting evidence that features from deep convo-lutional neural networks (CNN) are setting new records for various vision applications. On the other hand, considering the <b>continuous</b> <b>characteristic</b> of the depth values, depth esti-mations can be naturally formulated into a continuous con-ditional random field (CRF) learning problem. Therefore, we in this paper present a deep convolutional neural field model for estimating depths from a single image, aiming t...|$|E
3000|$|Due to the <b>continuous</b> <b>characteristics</b> of {{the daily}} cost {{function}} F_n([...] x_n,x_ - n,y_n), it is continuously differentiable in x_n. After calculation, the Hessian of F_n([...] x_n,x_ - n,y_n) is a positive semi-definite, therefore, F_n([...] x_n,x_ - n,y_n) is convex in x_n [35].|$|R
40|$|The {{influence}} of wear-resistant PVD - coating TiAlN and magnetic abrasive machining (MAM) on mechanical behavior of cutting edges of carbide cutting tool under local loading is studied. To obtain <b>continuous</b> <b>characteristics</b> of mechanical behavior such as damageability and fracture resistance under local loading the testing method of next to edge {{surface of the}} cutting tip scanning is used...|$|R
40|$|The paper {{presents}} the results of the population structure research on the inhabitants of the Island of Rab by the analysis of anthropometric, <b>continuous</b> <b>characteristics</b> (morphological variables of head and body) on the representative sample of 601 adult persons (aged 18 – 75 years) from the settlements Banjol, Barbat, Lopar, Rab and Supetarska Draga (Figure 1). The aim was to investigate the possibility to confirm the existence of population groupings or divisions in one geographically limited area based on the analysis of continuous anthropometric variables. In other words, the purpose is to investigate the structure of the inhabitants in order to contribute to the explanation of its microevolution. The performed analysis shows partial anthropometric variability of the present day population that is confirmed by a series of biostatistics analyses. The analysis includes <b>continuous</b> (quantitative) <b>characteristics,</b> 36 anthropometric body variables and 14 anthropometric head variables. Heterogeneity among the groups of examinees is evaluated for separate phenotypic characteristics in order to obtain the data on the inhabitants’ microevolution. The estimation performed on the total of 36 analyzed body variables showed the existence of statistically significant heterogeneities for 13 variables in men and for women in 8. By descriptive statistic procedures and by the estimation of heterogeneity, in space of the head related phenotypic characteristics, heterogeneity was found for 7 characteristics in men and for 5 in women. Discrimination analyses show that certain heterogeneity exists in some investigated <b>continuous</b> <b>characteristics</b> among individual populations. The results of the biological distances evaluation among the populations of the Island of Rab point to the separation of some populations, primarily of the inhabitants of Lopar...|$|R
3000|$|... 27 One {{other reason}} to use origin school type (‘bad’ or ’good’ school) is for practicality. Because {{of the need}} to split searchers in {{discrete}} markets, using any other typical school characteristic (% traditionally disadvantaged group for example) would require an arbitrary cut off value to define markets. School category has the distinction of being a form of segmentation that the state decided was important. In addition, while it is possible to add in more teacher or school characteristics, each new variable geometrically increases the number of markets to search over, greatly complicating the estimation. For example, if a simple teacher minority status was added, this would increase the number of teacher types to twelve. It is impossible to add a <b>continuous</b> <b>characteristic,</b> as that would imply an infinite number of markets with no mass.|$|E
40|$|Abstract—A {{data stream}} {{is a massive}} {{unbounded}} sequence of data elements continuously generated at a rapid rate. The <b>continuous</b> <b>characteristic</b> of streaming data necessitates the use of algorithms that require only one scan over the stream for knowledge discovery. Data mining over data streams should support the flexible trade-off between processing time and mining accuracy. In many application areas, mining frequent itemsets has been suggested to find important frequent itemsets by considering the weight of itemsets. In this paper, we present an efficient algorithm WSFI (Weighted Support Frequent Itemsets) -Mine with normalized weight over data streams. Moreover, we propose a novel tree structure, called the Weighted Support FP-Tree (WSFP-Tree), that stores compressed crucial information about frequent itemsets. Empirical results show that our algorithm outperforms comparative algorithms under the windowed streaming model...|$|E
40|$|Duchenne muscular {{dystrophy}} (DMD), clinically featured as progressive skeletal muscle atrophy with gradual loss of muscle strength and activity abilities, {{is the most}} common genetic muscular disease in children throughout the world. The core and <b>continuous</b> <b>characteristic</b> of DMD is motor dysfunction. Motor function assessments of DMD are now focusing on muscle strength, walking ability, range of motion and ability of activities, still without unified standards. Confirming the comprehensive, scientific, reasonable and accurate evaluation tools for DMD assessment is the premise of research in motor developmental rules of DMD, which will help to better understand the motor progress of DMD and to supply evidences for choosing treatment methods, confirming timing of intervention, assessing effect of treatments and designing rehabilitation plans.   DOI: 10. 3969 /j. issn. 1672 - 6731. 2015. 06. 002 </p...|$|E
5000|$|Blau space {{consists}} of the multidimensional coordinate system, created by considering the set of socio-demographic variables as dimensions. All socio-demographic characteristics are potential elements of Blau space, including <b>continuous</b> <b>characteristics</b> such as age, years of education, income, occupational prestige, geographic location, and so forth. In addition, categorical measures of socio-demographic characteristics such as race, sex, religion, birthplace, and others are Blau dimensions. [...] "Blau space" [...] is a theoretical construct which was developed by Miller McPherson and named after Peter Blau. It was later elaborated by McPherson and Ranger-Moore.|$|R
40|$|Many quality {{programs}} prescribe {{a measurement}} system analysis (MSA) {{to be performed}} on the key quality characteristics. This guarantees {{the reliability of the}} acquired data, which {{serve as the basis for}} drawing conclusions with respect to the behavior of the key quality characteristics. When dealing with <b>continuous</b> <b>characteristics,</b> the Gauge R 2 ̆ 6 amp;R is regarded as the statistical technique in MSA. For binary characteristics, no such universally accepted equivalent is available. We discuss methods that could serve as an MSA for binary data. We argue that a latent class model is the most promising candidate...|$|R
40|$|We {{deal with}} {{stochastic}} epidemic models having {{a set of}} absorbing states. The aim of the paper is to study some <b>continuous</b> <b>characteristics</b> of the epidemic. In this sense, we first extend the classical study {{of the length of}} an outbreak by investigating the whole probability distribution of the extinction time via Laplace transforms. Moreover, we also study two almost new epidemic descriptors, namely, the time until a non-infected individual becomes infected and the time until the individual is removed from the infective group. The obtained results are illustrated by numerical examples including an application to a stochastic SIS model for head lice infections...|$|R
40|$|A simple {{symmetric}} 2 „e 2 strategic coordination game is {{analyzed in}} an evolutionary environment {{under the assumption}} that agents are able to condition their actions on observations made of the opponent. Agents are assumed to be associated with a profile of characteristics, of which all agents can make a noisy observation. Actions can be conditioned on how the observed characteristics relates to that of their own. It is shown that there exist feasible states under which evolutionary pressure will transform any population conditioning its actions through a genetically induced <b>continuous</b> <b>characteristic,</b> such as body length, into a population conditioning its actions through Status, or how well agents have done in previous games. It is also shown that there does not exist feasible states by which a population conditioning its actions through Status could be invaded by any other strategies. Coordination; Hawk-Dove Games; Status; Positional Concerns; Conditioned Strategies; Evolutionary Equilibrium...|$|E
40|$|We present {{models of}} labor-market {{discrimination}} in which identical employers choose among job applicants {{according to a}} <b>continuous</b> <b>characteristic</b> such as skin color or worker height. The characteristic in question {{is assumed to be}} unrelated to worker productivity. Firms are required to announce wage offers that are not conditioned on the characteristic. Workers apply to firms on the basis of those announcements. Firms rank all applicants with respect to the characteristic and select the most desirable one. We show that in equilibrium all firms will offer the same wage, and workers will apply to each firm with equal probability. All employed workers will receive the same wage, but lower ranked workers will have a higher rate of unemployment than higher ranked workers and will thus have a lower expected income. These results differ from those of directed-search models characterized by a finite number of worker types. ...|$|E
40|$|David Goss {{developed}} a very general Fourier transform in additive harmonic {{analysis in the}} function field setting. In order to introduce the Fourier transform for <b>continuous</b> <b>characteristic</b> p valued functions on Z_p, Goss introduced and studied an analogue of flows in finite characteristic. In this paper, we use another approach to study flows in finite characteristic. We recast {{the notion of a}} flow {{in the language of the}} classical umbral calculus, which allows to generalize the formula for flows first proved by Goss to a more general setting. We study duality between flows using the classical umbral calculus, and show that the duality notion introduced by Goss seems a natural one. We also formulate a question of Goss about the exact relationship between two flows of a Drinfeld module in the language of the classical umbral calculus, and give a partial answer to it. Comment: Final versio...|$|E
40|$|Statistics and {{probability}} {{theory in the}} work otTine Tammes (1871 - 1947) Tine Tammes (1871 - 1947) was the first professor in genetics in The Netherlands. She was a Mendelian who used descriptive as well as inferential statistics. Dutch botanists admired her feeling for the statistical aspects in botanical and genetical research. The astronomer J. C. Kapteyn (1851 - 1922) stimulated and helped her applying statistics. Especially in her most important genetical publication of 1911 on the validity of Mendel's laws for <b>continuous</b> <b>characteristics</b> she could draw convincing conclusions as she used inferential statistical methods more than others who published on the same subject. ...|$|R
50|$|Traits {{controlled}} by the both environment and genetic factors.Usually, multifactorial traits outside of illness result in what we see as <b>continuous</b> <b>characteristics</b> in organisms, especially human organisms such as: height, skin color, and body mass. All of these phenotypes are complicated by {{a great deal of}} give-and-take between genes and environmental effects. The continuous distribution of traits such as height and skin color described above, reflects the action of genes that do not manifest typical patterns of dominance and recessiveness. Instead the contributions of each involved locus are thought to be additive. Writers have distinguished this kind of inheritance as polygenic, or quantitative inheritance.|$|R
50|$|Coalescence: {{in case of}} a liquid, the {{multiple}} droplets may merge to form a uniform <b>continuous</b> layer. <b>Characteristics</b> of the ingredient in relation to the product, such as viscosity and surface tension associated to a mechanical effect (friction) are critical.|$|R
40|$|The k-core {{percolation}} is {{a fundamental}} structural transition in complex networks. Through {{the analysis of the}} size jump behaviors of k-core in the evolution process of networks, we confirm that k-core percolation is continuous phase transition when k= 1, 2 while it is a hybrid first-order-second-order phase transition when k> 3. 2 -core percolation belongs to different universality class from that of 1 -core (giant component) percolation. The discontinuity of k-core percolation with k> 3 can be concluded from largest size jump of k-core which will not disappear in the thermodynamic limit while its <b>continuous</b> <b>characteristic</b> is reflected by second largest size jump which converges to zero in power law as N→∞. Furthermore, along with the previously known exponent β= 0. 5, we obtain a set of exponents which are independent of k when k> 3 and also different from those critical exponents of 1 -core and 2 -core percolation...|$|E
40|$|For noninformative nonparametric {{estimation}} of finite population quantiles under simple random sampling, estimation {{based on the}} Polya posterior is similar to estimation based on the Bayesian approach developed by Ericson (1969, JRSSB, 31, 195 - 233) in that the Polya posterior distribution is the limit of Ericson’s posterior distributions as the weight placed on the prior distribution diminishes. Furthermore, Polya posterior quantile estimates can {{be shown to be}} admissible under certain conditions. We demonstrate the admissibility of the sample median as an estimate of the population median under such a set of conditions. As with Ericson’s Bayesian approach, Polya posterior based interval estimates for population quantiles are asymptotically equivalent to the interval estimates obtained from standard frequentist approaches. In addition, for small to moderate populations, Polya posterior based interval estimates for quantiles of a <b>continuous</b> <b>characteristic</b> of interest tend to agree with the standard frequentist interval estimates. Key words: finite population sampling, admissibility, quantile estimation, noninformative inference, nonparametric inferenc...|$|E
40|$|ABSTRACT. – We present {{models of}} labor-market {{discrimination}} in which identical employers choose among job applicants {{according to a}} <b>continuous</b> <b>characteristic</b> such as skin color or worker height. The characteristic in question {{is assumed to be}} unrelated to worker productivity. Firms are required to announce wage offers that are not conditioned on the characteristic. Workers apply to firms on the basis of those announcements. Firms rank all applicants with respect to the characteristic and select the most desirable one. We show that in equilibrium all firms will offer the same wage, and workers will apply to each firm with equal probability. All employed workers will receive the same wage, but lower ranked workers will have a higher rate of unemployment than higher ranked workers and will thus have a lower expected income. These results differ from those of directed-search models characterized by a finite number of worker types. L’affichage d’offres salariales avec continuum de types de travailleurs RÉSUMÉ. – Nous développons un modèle de la discrimination dans lequel les employeurs identiques choisissent parmi des demandeurs du travail selon une caractéristiqu...|$|E
40|$|Stability {{data are}} often {{collected}} {{to determine the}} shelf-life of certain characteristics of a pharmaceutical product, for example, a drug 2 ̆ 7 s potency over time. Statistical approaches such as the linear regression models are considered as appropriate to analyze the stability data. However, most of these regression models in both theory and practice rely heavily on their underlying parametric assumptions, such as normality of the <b>continuous</b> <b>characteristics</b> or their transformations. In this article, we propose and study some rank-based regression procedures for the stability data when the linear regression models are semiparametric with unspecified error structure. Numerical studies including Monte Carlo simulations and practical examples are demonstrated with the proposed procedures as well...|$|R
40|$|Discrete and {{continues}} time-frequency algorithms {{of the power}} intensity of non-stationary signals are proposed. Results show that the power intensity waveform analysis performed well in both discrete and <b>continuous</b> time-frequency <b>characteristics.</b> Two methods for the digital implementation of the proposed algorithms are described and assessed...|$|R
30|$|<b>Continuous</b> <b>characteristics</b> {{that met}} the {{assumptions}} of normality were summarized by {{mean and standard deviation}} and compared across groups using Student’s t test. For <b>continuous</b> <b>characteristics</b> that deviated from normality, data were summarized by median and interquartile range (25 th– 75 th percentile) and compared across groups using the Mann–Whitney U test. Binary characteristics were summarized by frequency and percent and compared across groups using chi-squared test. Univariate and multivariable binary logistic regression were used to identify potential risk factors of contralateral SCFE in subjects presenting with unilateral SCFE. Factors analyzed included age at presentation, gender, BMI, incidence of endocrine disorder, clinical SCFE stability, alpha angle, PSA, and modified Oxford score. Model fit was assessed using Akaike’s information criteria and the likelihood ratio test. Odds ratios along with 95  % CIs were estimated for significant factors. Based on significant risk factors, receiver operating characteristic (ROC) analysis was implemented to assess the ability of factors to detect contralateral SCFE in patients presenting with unilateral SCFE. The area under the ROC curve was estimated along with a 95  % CI. For continuous risk factors an optimal cut-off value was calculated based on Youden’s index (identifies the point on the ROC curve that simultaneously maximizes sensitivity and specificity). The Pearson product-moment correlation coefficient was employed as a measure of linear correlation between alpha angle and PSA results, with a correlation coefficient from 0 − 0.25 defined as an absence of correlation, 0.25 – 0.5 indicating poor correlation, 0.5 – 0.75 indicating good correlation, and 0.75 – 1 indicating excellent correlation between variables, as defined by Dawson and Trapp [26]. All tests were two-sided and p-values < 0.05 were considered significant. Analyses were conducted using SAS version 9.3 (SAS Institute Inc., Cary, NC, USA).|$|R
40|$|Teaching styles often affect {{students}} differently {{based on}} their predispositions towards becoming socially anxious. Previous research suggests that individuals {{with higher levels of}} trait social anxiety are more likely to experience stress in classroom engagement situations. This study sought to determine whether classroom engagement activities moderate the association between symptoms of general social anxiety and classroom stress in a sample of undergraduate students (N= 408). University students who had taken English 100 within five academic years completed measures of social anxiety, classroom stress, {{and the extent to which}} their instructor utilized classroom engagement activities in their English 100 course. Results indicate that individuals’ levels of social anxiety – a personal, <b>continuous</b> <b>characteristic</b> – and experiences with classroom stress differed by the extent of classroom engagement. However, this result only became apparent when the data set was limited to students who were currently taking English 100 (n= 90). This finding suggests that college students who report higher levels of social anxiety experience significantly higher levels of classroom stress when taking courses with high student engagement compared to classrooms with lower student engagement. The results suggest that while classroom engagement activities might be beneficial to the majority of students, they may also lead to greater levels of stress and negative outcomes in individuals with predispositions for social anxiety...|$|E
30|$|Though the GaN nanocolumns exhibit {{superior}} {{performance than}} the film, the fabrication of electrical device is of high difficulty because the separated nanocolumn needs alignment {{prior to the}} electrical contact fabrication. An in-plane electrically conductive nanostructure, therefore, is favored. For the growth of sample S 2, metallic Al pre-deposition {{was carried out in}} the MBE growth chamber for 40  s. Then, the N 2 plasma and the Ga source were simultaneously opened. The Ga flux for the S 2 growth is summarized in Table  1, the same with that of S 1. Figure  1 c shows the top-view FESEM image of the sample S 2. It is quite interesting that the GaN grows {{in the form of the}} nanowall network on the Al/Si (111). The nanowalls with diameter of 50 ~ 100  nm overlap and interlace with one another, forming an in-plane continuous network, namely nanowall network. Two classes of holes are observable, named class A and class B. The diameters of the class A and the class B holes are typically, 50 ~ 100 and 10 ~[*] 49  nm, respectively. The in-plane <b>continuous</b> <b>characteristic</b> makes the nanowall network in-pane electrically conductive [18], removing the obstacles of nano-device fabrication to some extent. The top surface of the nanowalls is relatively flat, different from the faceted GaN matrix reported in Ref. [13]. It is observable that the holes shown in the top-view image extend to near the substrate, as indicated by the rectangle in Fig.  1 d.|$|E
40|$|In this article, we {{tackle the}} problem of depth {{estimation}} from single monocular images. Compared with depth estimation using multiple images such as stereo depth perception, depth from monocular images is much more challenging. Prior work typically focuses on exploiting geometric priors or additional sources of information, most using hand-crafted features. Recently, there is mounting evidence that features from deep convolutional neural networks (CNN) set new records for various vision applications. On the other hand, considering the <b>continuous</b> <b>characteristic</b> of the depth values, depth estimations can be naturally formulated as a continuous conditional random field (CRF) learning problem. Therefore, here we present a deep convolutional neural field model for estimating depths from single monocular images, aiming to jointly explore the capacity of deep CNN and continuous CRF. In particular, we propose a deep structured learning scheme which learns the unary and pairwise potentials of continuous CRF in a unified deep CNN framework. We then further propose an equally effective model based on fully convolutional networks and a novel superpixel pooling method, which is ∼ 10 times faster, to speedup the patch-wise convolutions in the deep model. With this more efficient model, {{we are able to}} design deeper networks to pursue better performance. Experiments on both indoor and outdoor scene datasets demonstrate that the proposed method outperforms state-of-the-art depth estimation approaches. Comment: Appearing in IEEE T. Pattern Analysis and Machine Intelligence. Journal version of arXiv: 1411. 6387. Test code is available at [URL]...|$|E
40|$|A {{data stream}} is a massive, {{open-ended}} sequence of data elements continuously generated {{at a rapid}} rate. Mining data streams is more difficult than mining static databases because the huge, high-speed and <b>continuous</b> <b>characteristics</b> of streaming data. In this paper, we propose a new one-pass algorithm called DSM-MFI (stands for Data Stream Mining for Maximal Frequent Itemsets), which mines the set of all maximal frequent itemsets in landmark windows over data streams. A new summary data structure called summary frequent itemset forest (abbreviated as SFI-forest) is developed for incremental maintaining the essential information about maximal frequent itemsets embedded in the stream so far. Theoretical analysis and experimental {{studies show that the}} proposed algorithm is efficient and scalable for mining the set of all maximal frequent itemsets over the entire history of the data streams. 1...|$|R
30|$|Clinical and {{radiographic}} data {{between the}} two groups [deformity progression versus no progression after instrumented fusion (“stable”)] were analyzed to determine the variables associated with deformity progression. Patient and curve characteristics were summarized pre-operatively, at first erect, at 1 -year follow-up, and at 2 -year follow-up for all subjects and between deformity progression and control subjects. <b>Continuous</b> <b>characteristics</b> were compared using univariate logistic regression and ordinal characteristics were compared using the Cochran–Armitage test for trend or a Mann–Whitney U-test. Change in measurement over time was analyzed between deformity groups using mixed model analysis with a compound symmetry correlation structure. Univariable and multivariable logistic regression was used to assess pre-operative and post-operative risk factors of deformity progression. All tests were two-sided and p-values less than 0.05 were considered significant.|$|R
40|$|In {{this paper}} we propose a test to {{determine}} whether jumps are present in a discretely sampled process or not. We use the concept of truncated power variation to construct our test statistics for (i) semimartingale models and (ii) semimartingale models with noise. The test statistics converge to innity if jumps are present and have a normal distribution otherwise. Our method is valid (under very weak assumptions) for all semimartingales with absolute <b>continuous</b> <b>characteristics</b> and rather general model for the noise process. We nally implement the test and present the simulation results. Our simulations suggest that for semimartingale models the new test is much more powerful then tests proposed by Barndorff-Nielsen and Shephard (2006) and At-Sahalia and Jacod (2008). Central Limit Theorem, High-Frequency Data, Microstructure Noise, Semimartingale Theory, Tests for Jumps, Truncated Power Variation...|$|R
40|$|We {{consider}} {{the problem of}} depth estimation from a sin-gle monocular image in this work. It is a challenging task as no reliable depth cues are available, e. g., stereo corre-spondences, motions etc. Previous efforts have been focus-ing on exploiting geometric priors or additional sources of information, with all using hand-crafted features. Recently, there is mounting evidence that features from deep convo-lutional neural networks (CNN) are setting new records for various vision applications. On the other hand, considering the <b>continuous</b> <b>characteristic</b> of the depth values, depth esti-mations can be naturally formulated into a continuous con-ditional random field (CRF) learning problem. Therefore, we in this paper present a deep convolutional neural field model for estimating depths from a single image, aiming to jointly explore the capacity of deep CNN and continuous CRF. Specifically, we propose a deep structured learning scheme which learns the unary and pairwise potentials of continuous CRF in a unified deep CNN framework. The proposed method {{can be used for}} depth estimations of general scenes with no geometric priors nor any extra in-formation injected. In our case, the integral of the partition function can be analytically calculated, thus we can exactly solve the log-likelihood optimization. Moreover, solving the MAP problem for predicting depths of a new image is highly efficient as closed-form solutions exist. We experimentally demonstrate that the proposed method outperforms state-of-the-art depth estimation methods on both indoor and out-door scene datasets. 1...|$|E
40|$|We {{consider}} {{the problem of}} depth estimation from a sin- gle monocular image in this work. It is a challenging task as no reliable depth cues are available, e. g., stereo corre- spondences, motions etc. Previous efforts have been focus- ing on exploiting geometric priors or additional sources of information, with all using hand-crafted features. Recently, there is mounting evidence that features from deep convo- lutional neural networks (CNN) are setting new records for various vision applications. On the other hand, considering the <b>continuous</b> <b>characteristic</b> of the depth values, depth esti- mations can be naturally formulated into a continuous con- ditional random field (CRF) learning problem. Therefore, we in this paper present a deep convolutional neural field model for estimating depths from a single image, aiming to jointly explore the capacity of deep CNN and continuous CRF. Specifically, we propose a deep structured learning scheme which learns the unary and pairwise potentials of continuous CRF in a unified deep CNN framework. The proposed method {{can be used for}} depth estimations of general scenes with no geometric priors nor any extra in- formation injected. In our case, the integral of the partition function can be analytically calculated, thus we can exactly solve the log-likelihood optimization. Moreover, solving the MAP problem for predicting depths of a new image is highly efficient as closed-form solutions exist. We experimentally demonstrate that the proposed method outperforms state-of- the-art depth estimation methods on both indoor and out- door scene datasets. Fayao Liu, Chunhua Shen, Guosheng Li...|$|E
40|$|Abstract:- The aim of {{this work}} was the {{development}} of the IrrigRotation software which is a soil water balance simulation model, based on the dual Kc methodology, that performs the soil water balance continuously in time using a daily time step. This continuous simulation allows to overcoming one of the greatest sources of uncertainty in the use of water balance models, which is the amount of available water in the soil profile {{at the beginning of the}} simulation. Thus, the initial error is diluted over the data time series, loosing is relevance. This model was built to be more flexible as possible, regarding the time series intervals, simulating time intervals from one day up to several years. The IrrigRotation can be applied either at a field level or at a regional level allowing the assessment of regional water irrigation requirements, trough its integration into the GIS software Geomedia 6. 0. This model was implemented following an information system (IS) approach, and is composed by a graphic user interface, by several mathematical modules and a database. The methodology developed in this model, due to its <b>continuous</b> <b>characteristic</b> allows to consider the water needs of a sequence of crops and taking into account the water stored in the soil profile during the off-season time period, using a soil reservoir calculated according to the deepest root of the crop sequence/rotation. This way is possible to take into account the water requirements of a sequence of crops, including crop rotations, in opposition to traditional water balance models such as CROPWAT, ISAREG, PILOTE or more recently the SIMDualKc which typically perform th...|$|E
40|$|In {{this paper}} we study the {{exponential}} functionals {{of the processes}} X with independent increments, namelyI_t= ∫ _ 0 ^t(-X_s) ds, _, t≥ 0, and alsoI_∞= ∫ _ 0 ^∞(-X_s) ds. When X is a semi-martingale with absolutely <b>continuous</b> <b>characteristics,</b> we derive necessary and sufficient conditions {{for the existence of}} the Laplace exponent of I_t, and also the sufficient conditions of finiteness of the Mellin transform E(I_t^α) with α∈R. We give a recurrent integral equations for this Mellin transform. Then we apply these recurrent formulas to calculate the moments. We present also the corresponding results for the exponentials of Levy processes, which hold under less restrictive conditions then in BY. In particular, we obtain an explicit formula for the moments of I_t and I_∞, and we precise the exact number of finite moments of I_∞...|$|R
5000|$|Mendelian {{genetics}} were rediscovered in 1900. However, {{it remained}} somewhat controversial {{for several years}} as it was not then known how it could cause <b>continuous</b> <b>characteristics.</b> Udny Yule (1902) argued against Mendelism because he thought that dominant alleles would increase in the population. The American William E. Castle (1903) showed that without selection, the genotype frequencies would remain stable. Karl Pearson (1903) found one equilibrium position with values of p = q = 0.5. Reginald Punnett, unable to counter Yule's point, introduced the problem to G. H. Hardy, a British mathematician, with whom he played cricket. Hardy was a pure mathematician and held applied mathematics in some contempt; his view of biologists' use of mathematics comes across in his 1908 paper where he describes this as [...] "very simple": ...|$|R
40|$|An {{observation}} capsule, {{which measures}} water depths, velocities, turbidity andtemperature, being transported by river currents and radio-controlled for withdrawal,has {{been developed in}} order to make clear for spatially <b>continuous</b> <b>characteristics</b> offlood flows. The significance and importance of field observations of river floodingare discussed for the comprehensive river improvement and disaster prevention. Abrief review of previous flood observations implies specific and excellent features ofthe system with the observation capsule. Design and outlines of the capsule arementioned on its structure, radio control systems and equipment for measurementand data collection. The capsule is made from two fishing leisure boats, and thecontrol system is intelligent by the use of handy micro computers. The observationcapsule has been tested several times in the Yasu, the Uji and the Maruyama rivers. Difficulties and some aspects to be improved are pointed out from such fieldexaminations...|$|R
