10000|0|Public
5|$|Multiple {{sequence}} alignment also {{refers to}} the process of aligning such a sequence set. Because three or more sequences of biologically relevant length can be difficult and are almost always time-consuming to align by hand, computational algorithms are used to produce and analyze the alignments. MSAs require more sophisticated methodologies than pairwise alignment because they are more <b>computationally</b> complex. Most multiple sequence alignment programs use heuristic methods rather than global optimization because identifying the optimal alignment between more than a few sequences of moderate length is prohibitively <b>computationally</b> expensive.|$|E
5|$|An {{enumeration}} technique {{based on}} band generation was developed that is significantly less <b>computationally</b> intensive. The strategy begins {{by analyzing the}} permutations of the top band used in valid solutions. Once the Band1 symmetries and equivalence class for the partial solutions are identified, the completions of the lower two bands are constructed and counted for each equivalence class.|$|E
5|$|In {{the third}} step, {{these data are}} {{combined}} <b>computationally</b> with complementary chemical information to produce and refine {{a model of the}} arrangement of atoms within the crystal. The final, refined model of the atomic arrangement—now called a crystal structure—is usually stored in a public database.|$|E
5|$|Lipid bilayers are {{complicated}} molecular systems with many degrees of freedom. Thus atomistic simulation of membrane {{and in particular}} ab initio calculations of its properties is difficult and <b>computationally</b> expensive. Quantum chemical calculations has recently been successfully performed to estimate dipole and quadrupole moments of lipid membranes.|$|E
5|$|Sociologists {{increasingly}} {{draw upon}} <b>computationally</b> intensive methods to analyse and model social phenomena. Using computer simulations, artificial intelligence, text mining, complex statistical methods, and new analytic approaches like {{social network analysis}} and social sequence analysis, computational sociology develops and tests theories of complex social processes through bottom-up modelling of social interactions.|$|E
5|$|There is, however, {{one notable}} exception. In most implementations, COALESCE evaluates its {{parameters}} {{until it reaches}} the first non-NULL one, while NVL evaluates all of its parameters. This is important for several reasons. A parameter after the first non-NULL parameter could be a function, which could either be <b>computationally</b> expensive, invalid, or could create unexpected side effects.|$|E
5|$|Because of the {{resampled}} {{convolution method}} that they describe for computing a numerical approximation of the curve-shortening flow, they call their method the resampled curvature scale space. They observe that this scale space is invariant under Euclidean transformations of the given shape, and assert that it uniquely determines {{the shape and}} is robust against small variations in the shape. They compare it experimentally against several related alternative definitions of a scale space for shapes, and find that the resampled curvature scale space is less <b>computationally</b> intensive, more robust against nonuniform noise, and less strongly influenced by small-scale shape differences.|$|E
5|$|Chemical {{activity}} occurs along a protein's active site. Traditional drug design methods involve tightly binding to {{this site}} and blocking its activity, {{under the assumption}} that the target protein exists in one rigid structure. However, this approach works for approximately only 15% of all proteins. Proteins contain allosteric sites which, when bound to by small molecules, can alter a protein's conformation and ultimately affect the protein's activity. These sites are attractive drug targets, but locating them is very <b>computationally</b> costly. In 2012, Folding@home and MSMs were used to identify allosteric sites in three medically relevant proteins: beta-lactamase, interleukin-2, and RNase H.|$|E
5|$|Examples of extortionate {{ransomware}} became {{prominent in}} May 2005. By mid-2006, Trojans such as Gpcode, TROJ.RANSOM.A, Archiveus, Krotten, Cryzip, and MayArchive began utilizing more sophisticated RSA encryption schemes, with ever-increasing key-sizes. Gpcode.AG, which was detected in June 2006, was encrypted with a 660-bit RSA public key. In June 2008, a variant known as Gpcode.AK was detected. Using a 1024-bit RSA key, {{it was believed}} {{large enough to be}} <b>computationally</b> infeasible to break without a concerted distributed effort.|$|E
5|$|Folding@home {{is one of}} the world's fastest {{computing}} systems, with a {{speed of}} approximately 70 petaFLOPS. This performance from its large-scale computing network has allowed researchers to run <b>computationally</b> costly atomic-level simulations of protein folding thousands of times longer than formerly achieved. Since its launch on October1, 2000, the Pande Lab has produced 139 scientific research papers {{as a direct result of}} Folding@home. Results from the project's simulations agree well with experiments.|$|E
5|$|Furthermore, even single neurons {{appear to}} be complex and capable of {{performing}} computations. So, brain models that don't reflect this are too abstract to be representative of brain operation; models that do try to capture this are very <b>computationally</b> expensive and arguably intractable with present computational resources. However, the Human Brain Project is {{trying to build a}} realistic, detailed computational model of the entire human brain. The wisdom of this approach has been publicly contested, with high-profile scientists {{on both sides of the}} argument.|$|E
5|$|In a 2005 study, Felgenhauer and Jarvis {{analyzed}} the permutations {{of the top}} band used in valid solutions. Once the Band1 symmetries and equivalence classes for the partial grid solutions were identified, the completions of the lower two bands were constructed and counted for each equivalence class. Summing completions over the equivalence classes, weighted by class size, gives {{the total number of}} solutions as 6,670,903,752,021,072,936,960, confirming the value obtained by QSCGZ. The value was subsequently confirmed numerous times independently. A second enumeration technique based on band generation was later developed that is significantly less <b>computationally</b> intensive.|$|E
5|$|In early 2008, Rosetta {{was used}} to <b>computationally</b> design a protein with a {{function}} never before observed in nature. This was inspired {{in part by the}} retraction of a high-profile paper from 2004 which originally described the computational design of a protein with improved enzymatic activity relative to its natural form. The 2008 research paper from David Baker's group describing how the protein was made, which cited Rosetta@home for the computing resources it made available, represented an important proof of concept for this protein design method. This type of protein design could have future applications in drug discovery, green chemistry, and bioremediation.|$|E
5|$|In {{research}} {{involved with}} the Grand Challenges in Global Health initiative, Rosetta {{has been used to}} <b>computationally</b> design novel homing endonuclease proteins, which could eradicate Anopheles gambiae or otherwise render the mosquito unable to transmit malaria. Being able to model and alter protein–DNA interactions specifically, like those of homing endonucleases, gives computational protein design methods like Rosetta an important role in gene therapy (which includes possible cancer treatments).|$|E
5|$|The {{range of}} social {{scientific}} methods has also expanded. Social researchers draw upon a variety of qualitative and quantitative techniques. The linguistic and cultural turns of the mid-twentieth century led to increasingly interpretative, hermeneutic, and philosophic approaches towards the analysis of society. Conversely, {{the end of the}} 1990s and the beginning of 2000s have seen the rise of new analytically, mathematically and <b>computationally</b> rigorous techniques, such as agent-based modelling and social network analysis.|$|E
25|$|Concatenating {{rotations}} is <b>computationally</b> {{faster and}} numerically more stable.|$|E
25|$|Since {{identification}} of epistatic pairs is challenging both <b>computationally</b> and statistically, some studies try to prioritize epistatic pairs.|$|E
25|$|Cognitive {{musicology}} is {{a branch}} of cognitive science concerned with <b>computationally</b> modeling musical knowledge {{with the goal of}} understanding both music and cognition.|$|E
25|$|No {{neural network}} has solved such <b>computationally</b> {{difficult}} {{problems such as}} the n-Queens problem, the travelling salesman problem, or the problem of factoring large integers.|$|E
25|$|Clearly, {{simulation}} is <b>computationally</b> expensive, {{having to}} explore a large energy landscape. Grid-based techniques, optimization methods, and increased computer speed have made docking simulation more realistic.|$|E
25|$|Each axis can be <b>computationally</b> {{determined}} {{to result in}} a number representing degrees of deviation from zero, or it can be categorized into a few types.|$|E
25|$|In some cases, {{the details}} of {{electronic}} structure are {{less important than the}} long-time phase space behavior of molecules. This is the case in conformational studies of proteins and protein-ligand binding thermodynamics. Classical approximations to the potential energy surface are used, as they are <b>computationally</b> less intensive than electronic calculations, to enable longer simulations of molecular dynamics. Furthermore, cheminformatics uses even more empirical (and <b>computationally</b> cheaper) methods like machine learning based on physicochemical properties. One typical problem in cheminformatics is to predict the binding affinity of drug molecules to a given target.|$|E
25|$|While uranium {{trioxide}} is encountered as a polymeric solid under ambient conditions, {{some work}} has been done on the molecular form in the gas phase, in matrix isolations studies, and <b>computationally.</b>|$|E
25|$|In {{practical}} use in robust statistics, L-estimators {{have been replaced}} by M-estimators, which provide robust statistics that also have high relative efficiency, at the cost of being much more <b>computationally</b> complex and opaque.|$|E
25|$|Gauss's lemma {{in number}} theory gives a {{condition}} for an integer to be a quadratic residue. Although it is not useful <b>computationally,</b> it has theoretical significance, being involved in some proofs of quadratic reciprocity.|$|E
25|$|Until release 12, Rfam used {{an initial}} BLAST {{filtering}} step because profile SCFGs were too <b>computationally</b> expensive. However, the latest versions of INFERNAL are fast {{enough so that}} the BLAST step is no longer necessary.|$|E
25|$|<b>Computationally,</b> for a n×n matrix, {{this method}} needs only O(n3) {{arithmetic}} operations, while solving by elementary methods requires O(2n) or O(n!) operations. Even on the fastest computers, the elementary methods are impractical for n above 20.|$|E
25|$|However, {{polynomial}} interpolation {{also has}} some disadvantages. Calculating the interpolating polynomial is <b>computationally</b> expensive (see computational complexity) compared to linear interpolation. Furthermore, polynomial interpolation may exhibit oscillatory artifacts, especially at the end points (see Runge's phenomenon).|$|E
25|$|One way {{to reduce}} the number of false positives is to {{recalculate}} the energy of the top scoring poses using (potentially) more accurate but <b>computationally</b> more intensive techniques such as Generalized Born or Poisson-Boltzmann methods.|$|E
25|$|The {{search for}} {{efficient}} OLED materials {{has been extensively}} supported by simulation methods. By now {{it is possible to}} calculate important properties completely <b>computationally,</b> independent of experimental input. This allows cost-efficient pre-screening of materials, prior to expensive synthesis and experimental characterisation.|$|E
25|$|Subsequently, in 1936 Church {{isolated}} and published just the portion relevant to computation, {{what is now}} called the untyped lambda calculus. In 1940, he also introduced a <b>computationally</b> weaker, but logically consistent system, known as the simply typed lambda calculus.|$|E
25|$|The Box–Muller {{transform}} {{was developed}} as a more <b>computationally</b> efficient alternative to the inverse transform sampling method. The Ziggurat algorithm gives an even more efficient method. Furthermore, the Box–Muller transform can be employed for drawing from truncated bivariate Gaussian densities.|$|E
25|$|The Randomized Dependence Coefficient is a <b>computationally</b> efficient, copula-based {{measure of}} {{dependence}} between multivariate random variables. RDC is invariant {{with respect to}} non-linear scalings of random variables, is capable of discovering {{a wide range of}} functional association patterns and takes value zero at independence.|$|E
25|$|A {{problem in}} the field is that {{detailed}} neuron descriptions are <b>computationally</b> expensive and this can handicap the pursuit of realistic network investigations, where many neurons need to be simulated. So, researchers that study large neural circuits typically represent each neuron and synapse simply, ignoring much of the biological detail. This is unfortunate as there is evidence that the richness of biophysical properties on the single neuron scale can supply mechanisms that serve as the building blocks for network dynamics. Hence there is a drive to produce simplified neuron models that can retain significant biological fidelity at a low computational overhead. Algorithms have been developed to produce faithful, faster running, simplified surrogate neuron models from <b>computationally</b> expensive, detailed neuron models.|$|E
25|$|Molecular docking {{research}} focusses on <b>computationally</b> simulating {{the molecular}} recognition process. It aims {{to achieve an}} optimized conformation for both the protein and ligand and relative orientation between protein and ligand such that the free energy of the overall system is minimized.|$|E
25|$|The second method allows {{at least}} one {{mismatch}} between the two k-mer words. This decreases the amount of false positives, allowing larger k-mer sizes which are less <b>computationally</b> expensive to handle than those produced from the previous method. This method is very effective in identifying small homologous regions.|$|E
