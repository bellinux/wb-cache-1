0|87|Public
40|$|Some {{computer}} {{anomaly detection}} systems {{inspired by the}} immune system rely on the r-contiguous bits matching rule, whereby two strings of length l are said to match if they have at least r <b>contiguous</b> <b>bits</b> in common. In this paper, we derive a recurrence relation and its closed form solution for computing the number of strings matched by a single such string called a detector. ...|$|R
50|$|Addresses were {{encoded in}} orders in two bytes. For twelve bit {{addresses}} the high order two bits of each byte were normally set to form valid EBCDIC (or ASCII) characters. For example, address 0 was coded as X'4040', or space-space, address 1919 was coded as X'5D7F', or ''. Programmers hand coding panels usually kept {{the table of}} addresses from the 3270 Component Description or the 3270 Reference Card handy. For fourteen and sixteen bit address the address used <b>contiguous</b> <b>bits</b> in two bytes.|$|R
40|$|Abstract. Let n = pq> q 3 be an rsa modulus. This note {{describes}} a lll-based method allowing to factor n given 2 log 2 q <b>contiguous</b> <b>bits</b> of p, irrespective to their position. A second method is presented, which needs fewer bits but whose length {{depends on the}} position of the known bit pattern. Finally, we introduce a somewhat surprising ad hoc method where two different known bit chunks, totalling 3 2 log 2 q bits suffice to factor n. ...|$|R
5000|$|A {{polynomial}} [...] that admits other factorizations may {{be chosen}} then {{so as to}} balance the maximal total blocklength with a desired error detection power. The BCH codes are a powerful class of such polynomials. They subsume the two examples above. Regardless of the reducibility properties of a generator polynomial of degree r, if it includes the [...] "+1" [...] term, the code {{will be able to}} detect error patterns that are confined to a window of r <b>contiguous</b> <b>bits.</b> These patterns are called [...] "error bursts".|$|R
40|$|When {{transmitting}} a {{sampled signal}} digitally, data and error correction bits must be transmitted {{at least as}} fast as the sampling rate. Typically, each bit is allocated the same transmission time interval, which means the optimal detector yields the same error probability for each bit. An alternative is to vary the <b>bit</b> <b>interval</b> duration according to the bit's contribution to the reconstructed sample. The optimal solution yields significant gains in mean-squared error (several dB) over that provided by equal-duration <b>bit</b> <b>intervals.</b> These gains occurred over a wide range of signal-to-noise ratios. When block error correction is performed, we derive the optimal decoder from a Bayesian viewpoint and show that gains obtain here as well...|$|R
50|$|Another wrinkle occurs {{depending}} on whether surface bit densities are constant. Usually, with a CAV spin rate, the densities are not constant so that the long outside tracks have {{the same number of}} bits as the shorter inside tracks. When the bit density is constant, outside tracks have more bits than inside tracks and is generally combined with a CLV spin rate. In both these schemes <b>contiguous</b> <b>bit</b> transfer rates are constant. This is not the case with other schemes such as using constant bit density with a CAV spin rate.|$|R
40|$|Abstract. The {{operations}} addition modulo 2 n and exclusive-or {{have recently}} been combined to obtain an efficient mechanism for nonlinearity in block cipher design. In this paper, we show that ciphers using this approach may be approximated by pseudo-linear expressions relating groups of <b>contiguous</b> <b>bits</b> of the round key, round input, and round output. The bias of an approximation can be large enough for known plaintext attacks. We demonstrate an application of this concept to a reduced-round version of the Threefish block cipher, {{a component of the}} Skein entry in the secure hash function competition...|$|R
40|$|When {{transmitting}} a {{sampled signal}} digitally, {{an alternative to}} fixed power/bit is vary the power allocated to each bit to minimize signal distortion. We adjust the power here by allowing each <b>bit</b> <b>interval's</b> duration, whether a data bit or an error-correction bit, to vary and seek the set of bit durations that minimize the mean-squared reconstruction error. For smaller signal-to-noise ratios (SNR), the optimal solution amounted to only sending the most significant bits, with bit duration decreasing as the bit's significance to the sample decreases. As SNR increases, the optimal solution has more bits being transmitted, with durations becoming equal at high SNRs. The optimal solution yields significant gains in mean-squared error (several dB) {{over a wide range}} of channel signal-to-noise ratios when compared that provided by equal-duration <b>bit</b> <b>intervals...</b>|$|R
40|$|Linear {{least squares}} {{estimation}} techniques {{can be used}} to enhance suppression of narrowband interference in direct sequence spread spectrum systems. Nonlinear techniques for this purpose have also been investigated recently. In this paper, we derive maximum likelihood receivers for direct sequence signal in Gaussian interference with known second order characteristics. It is shown that if the receiver uses samples from outside the <b>bit</b> <b>interval,</b> then the receiver structure is nonlinear. The bit error rate performances of these receivers are compared to those of linear receivers employing one-sided and two-sided least squares estimation filters, for the case of Gaussian autoregressive interference. The results in this paper show that intersymbol interference due to filter taps extending beyond the <b>bit</b> <b>interval</b> cannot be ignored for small processing gains. In some cases, not accounting for intersymbol interference yields too optimistic error estimates, very much away from the true error rates...|$|R
40|$|Consider {{the forward}} link of a mobile {{communications}} system with a single transmitter and rather arbitrary randomly time varying channels connecting the base to the mobiles. Data arrives at the base in some ran-dom way (and might have a bursty character) and is queued according to the destination until transmitted. The main issues are the allocation of transmitter power and time to the various queues in a queue- and channel-state dependent way to assure stability and good operation. The control decisions are made {{at the beginning of}} the (small) scheduling intervals. Stability methods are used to allocate time and power. Many schemes of current interest can be handled: For example, CDMA with control over the <b>bit</b> <b>interval</b> and power per bit, TDMA with control over the time allo-cated, power per <b>bit,</b> and <b>bit</b> <b>interval,</b> as well as arbitrary combinations. There might be random errors in transmission which require retransmis-sion. The channel-state process might be known or only partially known...|$|R
40|$|The {{modulator}} structure {{consisting of}} a single-input two-output sequential transducer whose output sequences control the modulated signal in the manner s(t) = x(i) p(t) + y(i) q(t) is considered. Here, iT is {{less than or equal}} to t, which is less than iT + T, where T is the modulation bit duration and where x(i) and y(i) take values in /+ 1, - 1, 0 /. The behavior of a sequential transducer is characterized by means of a 'trellis'. It is shown that, provided only that the 'carriers' p(t) and q(t) have the same energy in every <b>bit</b> <b>interval,</b> the optimum demodulator for the additive white Gaussian noise channel need process the received signal over only two <b>bit</b> <b>intervals</b> in making each data bit decision. It is demonstrated that particular choices of the sequential transducer yield differential minimum shift keying and differential staggered quadriphase shift keying. Possible generalizations of this approach are discussed...|$|R
40|$|An {{asynchronous}} {{transfer mode}} (ATM) wireless network has bursty and high error rates. To combat the <b>contiguous</b> <b>bit</b> loss due to damaged or dropped packets, this paper presents a code packetization and image reconstruction scheme. The packetization method distributes the loss in both frequency and spatial domains to reduce the chance that adjacent DCT blocks lose the same frequency components. The image reconstruction takes into considera-tion the spatial characteristics represented by the frequency components. Combining these two approaches is able to reconstruct the damaged images more accurately, even under very high loss rates. In addition, since the reconstruction technique is computational e-cient, it conserves system resources and power consumption, which are restrictive in mobile computers...|$|R
5000|$|Harvest's most {{important}} {{mode of operation}} was called [...] "setup" [...] mode, in which the processor was configured with several hundred bits of information and the processor then operated by streaming data from memory — possibly taking two streams from memory — and writing a separate stream back to memory. The two byte streams could be combined, used to find data in tables, or counted to determine the frequency of various values. A value could be anything from 1 to 16 <b>contiguous</b> <b>bits,</b> without regard to alignment, and the streams could {{be as simple as}} data laid out in memory, or data read repeatedly, under the control of multiply-nested [...] "do"-loop descriptors, which were interpreted by the hardware.|$|R
30|$|In the {{unlikely}} event, {{where more than}} one relay transmit bits in the same rate slot and same <b>bit</b> <b>interval</b> location, then the source cannot separate the relays. Although rare (due to fewer relay nodes in the same rate slot and relay transmission at random <b>bit</b> <b>interval</b> location), this will result {{in more than one}} relay node relaying data packet to the destination node. However, since the conflicting relays transmit same data at the same rate (i.e., relays approximately experience same fade) to the destination node, it does not result in any collision at the destination node. Moreover, for the worst case, distance differences of about 50 m (see range limit in [4, 5]) between the relay nodes transmitting {{at the same time and}} the same rate, the relative packet delay remains within 0.15 μ s at the destination node. This is much smaller than the packet duration (which leads to insignificant fade and can be easily handled by the existing equalizer technology at physical layer [11]) and, hence, leads to error-free reception at the destination node.|$|R
5000|$|... 2. A {{process for}} {{converting}} {{a code of}} some predetermined bit structure, such as 5, 7, or 14 <b>bits</b> per character <b>interval,</b> to another code with the same or a different number of <b>bits</b> per character <b>interval.</b>|$|R
40|$|The {{advent of}} iteratively decodable codes has allowed a {{decrease}} in tolerable signal-to-noise ratios (SNRs) in magnetic recording systems, which typically translates into {{an increase in the}} recording densities. However, at such low SNRs, conventional timing recovery loops suffer from frequent cycle slips. Typical timing recovery loops in magnetic recording applications perform data detection, timing error detection, and loop filtering in a sequential manner. This sequence of operations in the timing recovery loop performs well if the timing error is {{a small fraction of the}} <b>bit</b> <b>interval.</b> However, in the cycle-slip regions, the timing error is comparable to the <b>bit</b> <b>interval,</b> and the loop fails. In this paper, we represent the timing error in magnetic recording systems by using a Markov model that does not confine the timing error to only small fractions of the <b>bit</b> <b>interval.</b> By utilizing such a model, we give a trellis representation of the timing error process. The trellis representation permits the formulations of two optimal baud-rate timing recovery loops, according to two optimality criteria. We prove that both optimality criteria lead to solutions similar to the classical first-order phase-locked loop. The new loops do not perform data detection, timing error detection, and loop filtering in a sequential manner. Instead, the loops perform data detection and timing error detection jointly on a trellis, without the need for a loop filter. Simulation results show that the new timing recovery loops outperform the standard second-order baud-rate Mueller and Müller phase-locked loop with fine-tuned loop parameters. This performance gain is substantial if the timing error process is extremely noisy or if there is residual frequency offset resulting from inaccurate acquisition from the sector preamble on a disk drive. Index Terms—Intersymbol interference, phase-locked loop, timing recovery, trellis. I...|$|R
40|$|An {{asynchronous}} {{transfer mode}} #ATM# wireless network has bursty and high error rates. To combat the <b>contiguous</b> <b>bit</b> loss due to damaged or dropped packets, this paper presents a code packetization and image reconstruction scheme. The packetization method distributes the loss in both frequency and spatial domains to reduce the chance that adjacent DCT blocks lose the same frequency components. The image reconstruction takes into consideration the spatial characteristics represented by the frequency components. Combining these two approaches one can reconstruct the damaged images more accurately,even under very high loss rates. In addition, since the reconstruction technique is computational e#cient, it conserves system resources and power consumption, which are restrictive in mobile computers. Keywords:multimedia, compression, mobile computing. 1 Introduction Many studies have proposed image and video data delivery schemes over wired channels. Since mobile computing has g [...] ...|$|R
5000|$|The [...] and [...] {{instructions}} are new generalized bit-level compress and expand instructions. They take two inputs; {{one is a}} source, {{and the other is}} a selector. The selector is a bitmap selecting the bits that are to be packed or unpacked. [...] copies selected bits from the source to <b>contiguous</b> low-order <b>bits</b> of the destination; higher-order destination bits are cleared. [...] does the opposite for the selected bits: <b>contiguous</b> low-order <b>bits</b> are copied to selected bits of the destination; other destination bits are cleared. This can be used to extract any bitfield of the input, and even do a lot of bit-level shuffling that previously would have been expensive. While what these instructions do is similar to a bit level gather-scatter SIMD instructions, [...] and [...] instructions (like the rest of the BMI instruction sets) operate on general-purpose registers.|$|R
40|$|Abstract. For {{elliptic}} curve based cryptosystems, the discrete logarithm problem must {{be hard to}} solve. But even when this is true from a mathematical point of view, side-channel attacks {{could be used to}} reveal information about the key if proper countermeasures are not used. In this paper, we study the difficulty of the discrete logarithm problem when partial information about the key is revealed by side channel attacks. We provide algorithms to solve the discrete logarithm problem for generic groups with partial knowledge of the key which are considerably better than using a square-root attack on the whole key or doing an exhaustive search using the extra information, under two different scenarios. In the first scenario, we assume that a sequence of <b>contiguous</b> <b>bits</b> of the key is revealed. In the second scenario, we assume that partial information on the “Square and Multiply Chain ” is revealed...|$|R
40|$|The {{representation}} of data aggregates is fundamentally made of concatenation and/or repetition of smaller representations. These structurations may be arbitrarily composed to form complex aggregates of primitive representations such as characters, integers or pointers. Knowing its structuration allows {{the interpretation of}} a sequence of <b>contiguous</b> <b>bits</b> as an instance of a type represented by the given structuration. This paper presents a formalization of data representations, it identifies and analyses the features which describe primitive representations as well as representation structurers which allow to compose data representations. These features can be very naturally {{expressed in terms of}} objects, classes and methods. Our model makes structurations fully explicit: some computations can be performed on them. We will show how to derive a general data inspector and a garbage collector from them. We also present an extension of the subclass concept based on concatenation of represent [...] ...|$|R
50|$|In most ALGOL-like languages, such as Pascal, Modula-2, Ada (programming language) and Delphi, {{conversion}} and casting are distinctly different concepts. In these languages, conversion refers to either implicitly or explicitly changing a value from one data type storage format to another, e.g. a 16-bit integer to a 32-bit integer. The storage needs may {{change as a}} result of the conversion, including a possible loss of precision or truncation. The word cast, on the other hand, refers to explicitly changing the interpretation of the bit pattern representing a value from one type to another. For example, 32 <b>contiguous</b> <b>bits</b> may be treated as an array of 32 booleans, a 4-byte string, an unsigned 32-bit integer or an IEEE single precision floating point value. Because the stored bits are never changed, the programmer must know low level details such as representation format, byte order, and alignment needs, to meaningfully cast.|$|R
40|$|Using the maximum-likelihood {{detector}} (MLD) of a soliton with {{timing jitter}} and noise, other than walk-out of the <b>bit</b> <b>interval,</b> timing jitter does not degrade {{the performance of}} MLD. When the MLD is simulated with important sampling method, even with a timing jitter standard deviation {{the same as the}} full-width-half-maximum (FWHM) of the soliton, the signal-to-noise (SNR) penalty is just about 0. 2 dB. The MLD performs better than conventional scheme to lengthen the decision window with additive noise proportional to the window wide. Comment: 3 pages, 2 figures, submitted to Optics Letter...|$|R
40|$|This paper {{describes}} the relative bandwidth {{requirements of the}} common digital baseband signaling techniques used for data transmission. Bandwidth considerations include the percentage of total power in a properly encoded PN sequence passed at bandwidths of 0. 5, 1, 2 and 3 times the reciprocal of the <b>bit</b> <b>interval.</b> The signals considered {{in this study are}} limited to the binary class. The study compares such signaling techniques as delay modulation, bipolar, biternary, duobinary, pair selected ternary and time polarity control in addition to the conventional NRZ, RZ and BI-phi schemes...|$|R
40|$|The {{intensity}} transients of {{the longitudinal}} modes in a modulated 1. 3 -μm Fabry-Perot laser diode are analyzed theoretically and experimentally. A simulation of the transient spectra, {{based on a}} 21 -mode rate-equation model, shows that nonlinear gain strongly affects the intensities of longitudinal modes during transients. The simulation results are confirmed by time-resolved spectrum measurements. From a comparison of measurements and the simulations, the self- and cross-saturation coefficients are estimated. Our simulations also show that the transient spectrum strongly depends on the <b>bit</b> <b>interval</b> during digital modulation...|$|R
50|$|Permutations that generalize the bit-reversal {{permutation}} by reversing <b>contiguous</b> {{blocks of}} <b>bits</b> within the binary representations of their indices {{can be used}} to interleave two equal-length sequences of data in-place.|$|R
40|$|Abstract. An {{asynchronous}} {{transfer mode}} (ATM) wireless network has bursty and high error rates. To combat the <b>contiguous</b> <b>bit</b> loss due to damaged or dropped packets, this paper presents a code packetization and image reconstruction scheme. The packetization method distributes the loss in both frequency and spatial domains to reduce the chance that adjacent DCT blocks lose the same frequency components. The image reconstruction takes into consideration the spatial characteristics represented by the frequency components. Combining these two approaches one can reconstruct the damaged images more accurately, even under very high loss rates. In addition, since the reconstruction technique is computational efficient, it conserves system resources and power consumption, which are restrictive in mobile computers. Keywords: multimedia, compression, mobile computing. 1 Introduction Many studies have proposed image and video data delivery schemes over wired channels. Since mobile computing has gained popularity in recent years, it is important also to devise robust techniques that work in a mobile environment. This paper presents image coding and reconstruction techniques that are suitable in a mobile (wireless) environment...|$|R
40|$|Computer memory chips store bits of information. A bit {{has only}} two {{possible}} values, either 0 or 1; however, multiple <b>contiguous</b> <b>bits</b> {{can be used to}} differentiate more possibilities. For example, 8 bits (called a byte) can differentiate 2 8 = 256 cases, enough to describe any character on a standard computer keyboard. Multiple bytes, contiguous in the memory, can be used to describe numbers, in either integer or floating point format. In C and C++, every set of bytes in memory that are used in the program must be declared as being of some data type. The data type determines how the bits are interpreted to form a number or character or other object. Each byte of memory has both a numerical location in the computer memory chip (its address) and the information it stores (its value). C and C++ allow us to access either the address or the value of a byte or contiguous set of bytes in the memory. Ex: ; double x; float y; int i...|$|R
40|$|Linear {{least squares}} {{estimation}} techniques {{can be used}} to enhance suppression of narrowband interference in direct-sequence spread-spectrum systems. Nonlinear techniques for this purpose have also been investigated recently. Here, we derive maximum-likelihood receivers for direct-sequence signal in Gaussian interference with known second order characteristics. It is shown that if the receiver uses samples from outside the <b>bit</b> <b>interval,</b> then the receiver structure (called ML II) is nonlinear. The bit error rate performances of these ML receivers are compared to those of linear receivers employing one-sided and two-sided least squares estimation filters, for the case of Gaussian autoregressive interference, It is shown that the ML II receiver outperforms the matched filter, the one sided and the two sided transversal filters...|$|R
50|$|Most clock {{recovery}} circuits designed for SONET OC-192 and 64b/66b are specified to tolerate an 80-bit run length. Such a run cannot occur in 64b/66b because transitions are guaranteed at 66 <b>bit</b> <b>intervals,</b> {{and in fact}} long runs are very unlikely. Although it is theoretically possible for a random data pattern to align with the scrambler state and produce a long run of 65 zeroes or 65 ones, the probability of such an event is equal to flipping a fair coin and having it {{come up in the}} same state 64 times in a row. At 10 Gigabits per second, the expected event rate of a 66-bit block with a 65 bit run-length, assuming random data, is 66x264/(2x1010) seconds, or about once every 1900 years.|$|R
40|$|Consider {{the forward}} link of a mobile {{communications}} system with a single transmitter and rather arbitrary randomly time varying channels connecting the base to the mobiles. Data arrives at the base in some random way (and might have a bursty character) and is queued according to the destination until transmitted. The main issues are the allocation of transmitter power and time to the various queues in a queue- and channel-state dependent way to assure stability and good operation. The control decisions are made {{at the beginning of}} the (small) scheduling intervals. Stability methods are used to allocate time and power. Many schemes of current interest can be handled: For example, CDMA with control over the <b>bit</b> <b>interval</b> and power per bit, TDMA with control over the time allocated, power per <b>bit,</b> and <b>bit</b> <b>interval,</b> as well as arbitrary combinations. There might be random errors in transmission which require retransmission. The channel-state process might be known or only partially known. The details of the scheme are not directly involved; all essential factors are incorporated into a "rate" and "error" function. The system and channel process are scaled by speed. Under a stability assumption on a model obtained from the "mean drift," and some other natural conditions, it is shown that the scaled physical system can be controlled to be stable, uniformly in the speed, for fast enough speeds. Owing to the non-Markov nature of the problem, we use the perturbed Liapunov function method, which is very useful for the analysis of non-Markovian systems. Finally, the stability method is used to actually choose the power and time allocations. The allocation will depend on the Liapunov function. But each such function corresponds loosely to an optimization problem for some performance [...] ...|$|R
30|$|In contrast, IrcMAC {{protocol}} fully exploits available relays {{and further}} resolves contention between relays under fading conditions as follows: (1) all the nodes passively monitor and estimate channel coherence time; (2) RTS and CTS messages are exchanged before relays can respond. By this way, only relays that can decode both RTS and CTS packets respond in the RR frame; (3) each relay with total transmission time {{less than the}} channel coherence time can only respond in RR frame; (4) each relay responds with a single bit at random <b>bit</b> <b>interval</b> location in an appropriate slot; and (5) source invokes relay with logical addressing by using Address 4 field in IEEE 802.11 MAC header. In short, IrcMAC resolves possible relay contentions and further guarantees instantaneous rates' information retrieval under fast fading conditions.|$|R
40|$|Abstract—This paper {{considers}} a minimum mean-squared error (MMSE) single user adaptive receiver for the asynchronous direct-sequence code-division multiple-access (DS-CDMA) system, {{based on the}} least-mean-square (LMS) algorithm. It is known that in this context the adaptive algorithm can be iterated {{several times during the}} same <b>bit</b> <b>interval</b> in order to achieve a faster convergence rate, which further reduces the length of the training sequence. The objective of this paper is twofold. First, instead of using such multiple iterations, we propose a single equivalent formula for updating the receiver coefficients, saving significant time processing. Secondly, in order to further increase the convergence rate, a division-free version of the gradient adaptive lattice (GAL) algorithm is proposed. Since the lattice predictor orthogonalizes the input signals, this algorithm achieves a faster convergence rate than the transversal LMS algorithm...|$|R
40|$|In cryptography, a {{block cipher}} is a {{deterministic}} algorithm operating on fixed-length groups of bits, called blocks, with an unvarying transformation that is specified by a symmetric key. Block ciphers are important elementary {{components in the}} design of many cryptographic protocols, and are widely used to implement encryption of bulk data. A block cipher is a method of encrypting text (to produce cipher text) in which a cryptographic key and algorithm are applied to a block of data (for example, 64 <b>contiguous</b> <b>bits)</b> at once as a group rather than applying it to one bit at a time. The primary purpose of encryption is to protect the confidentiality of digital data stored on computer systems or transmitted via the Internet or other computer networks. A recent promising low-cost alternative of advanced encryption standard (AES) on reconfigurable platforms called the SIMON. It has been implemented as the construction of the round function and the key generation of SIMON, that enables bit-serial hardware architectures which can significantly reduce the cost. Encryption and decryption can be done using the same hardware and also propose the hardware architecture of the smallest block cipher ever published on field-programmable gate arrays (FPGAs) at 128 -bit level of security...|$|R
40|$|This thesis {{proposes a}} novel method for {{implementing}} test pattern generators for Built-In Self Test (BIST) that eliminates {{the area and}} performance penalties associated with existing schemes. The method utilizes adders which are widely available in data-path architectures used in digital signal processing circuits and general purpose processors. Arithmetic test pattern generators produce test patterns by continuously accumulating a constant value. The generated patterns provide complete state coverage on subspaces of <b>contiguous</b> <b>bits</b> and are thus, excellent sources of pseudo-exhaustive tests. In this thesis, several metrics are developed to evaluate the testing properties of different arithmetic generators. Synthesis techniques for a class of generators that exhaustively cover single size subspaces in an optimal manner are formulated. Other generators that best target various ranges of subspace sizes are identified using an efficient search algorithm. Generators with interleaved output spaces are also evaluated. Detailed tables listing the best generators are provided. The proposed test pattern generation scheme, {{in conjunction with a}} previously introduced compaction scheme that uses similar existing hardware, now facilitates a non-intrusive, high quality BIST strategy for high performance data-path architectures. This strategy uses the functionality of existing hardware, is entirely integrated with the circuit under test, and permits at-speed testing, using simple BIST control, with no performance degradation or area overhead...|$|R
40|$|We {{consider}} a downlink DS-CDMA {{system in which}} multirate user signals are transmitted via synchronous orthogonal short codes overlaid with a common scram-bling sequence. The transmitted signal is subjected to significant time- and frequency-selective multipath fading, e. g., a channel with delay spread potentially longer than the <b>bit</b> <b>interval</b> of high-rate users. In response to this scenario, a novel two-step receiver is proposed that com-bines chip-rate adaptive equalization with error filtering. In the first step, a code-multiplexed pilot is used to adapt the equalizer. Single-pole averaging of the chip-rate error signal used in adaptation reduces MAI and implies third-order LMS, which has advantages over standard LMS in tracking the time-varying channel. In the second step, decision-direction is used to improve the error signal, resulting in improved tracking performance. The performance of the adaptive receiver is studied through analysis and simulation. i...|$|R
5000|$|In {{the absence}} of noise {{enhancement}} or noise correlation, the PRML sequence detector performs maximum-likelihood sequence estimation. As the operating point moves to higher linear recording densities, optimality declines with linear partial-response (PR) equalization, which enhances noise and renders it correlated. A close match between the desired target polynomial and the physical channel can minimize losses. An effective way to achieve near optimal performance independently of the operating point—in terms of linear recording density—and the noise conditions is via noise prediction. In particular, {{the power of a}} stationary noise sequence , where the [...] operator corresponds to a delay of one <b>bit</b> <b>interval,</b> at the output of a PR equalizer can be minimized by using an infinitely long predictor. A linear predictor with coefficients ,…, operating on the noise sequence [...] produces the estimated noise sequence [...] Then, the prediction-error sequence given by ...|$|R
