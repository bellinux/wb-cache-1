19|120|Public
25|$|FM is {{also used}} at {{intermediate}} frequencies by analog VCR systems (including VHS) to record the luminance (black and white) portions of the video signal. Commonly, the <b>chrominance</b> <b>component</b> is recorded as a conventional AM signal, using the higher-frequency FM signal as bias. FM is the only feasible method of recording the luminance ("black and white") component of video to (and retrieving video from) magnetic tape without distortion; video signals have a large range of frequency components – from a few hertz to several megahertz, too wide for equalizers to work with due to electronic noise below −60dB. FM also keeps the tape at saturation level, acting {{as a form of}} noise reduction; a limiter can mask variations in playback output, and the FM capture effect removes print-through and pre-echo. A continuous pilot-tone, if added to the signal – as was done on V2000 and many Hi-band formats – can keep mechanical jitter under control and assist timebase correction.|$|E
50|$|Analogue color video signals {{comprise}} two components: chrominance and luminance. The {{luminance component}} describes {{the brightness of}} {{each part of the}} picture, while the <b>chrominance</b> <b>component</b> describes the color tone. When displayed on a black-and-white monitor, the luminance signal produces a normal black-and-white image, while the chrominance signal manifests as a fine pattern of dots of varying size and intensity overlaid over the black-and-white picture. A related phenomenon is dot crawl, which can produce visual artifacts in color pictures.|$|E
50|$|FM is {{also used}} at {{intermediate}} frequencies by analog VCR systems (including VHS) to record the luminance (black and white) portions of the video signal. Commonly, the <b>chrominance</b> <b>component</b> is recorded as a conventional AM signal, using the higher-frequency FM signal as bias. FM is the only feasible method of recording the luminance ("black and white") component of video to (and retrieving video from) magnetic tape without distortion; video signals have a large range of frequency components - from a few hertz to several megahertz, too wide for equalizers to work with due to electronic noise below −60 dB. FM also keeps the tape at saturation level, acting {{as a form of}} noise reduction; a limiter can mask variations in playback output, and the FM capture effect removes print-through and pre-echo. A continuous pilot-tone, if added to the signal - as was done on V2000 and many Hi-band formats - can keep mechanical jitter under control and assist timebase correction.|$|E
40|$|This paper {{concerns}} {{color image}} restoration aiming at objective quality improvement of compressed color images in general {{rather than merely}} artifact reduction. In compressed color images, colors are usually represented by luminance and <b>chrominance</b> <b>components.</b> Considering characteristics of human vision system, <b>chrominance</b> <b>components</b> are generally represented more coarsely than luminance component. To recover such <b>chrominance</b> <b>components,</b> we previously proposed a model-based chrominance restoration algorithm where color images are modeled by a Markov random field. This paper presents a color image restoration algorithm derived by the MAP estimation where all components are totally estimated. Experimental {{results show that the}} proposed restoration algorithm is more effective than the previous one...|$|R
50|$|The <b>chrominance</b> <b>components</b> can be, {{but do not}} {{necessarily}} have to be, down-scaled in resolution.|$|R
5000|$|Finally the {{luminance}} and <b>chrominance</b> <b>components</b> are scaled to 8-bit {{values by}} the following equations: ...|$|R
50|$|A {{vectorscope}} uses an overlaid circular reference display, or graticule, for visualizing chrominance signals, {{which is}} the best method of referring to the QAM scheme used to encode color into a video signal. The actual visual pattern that the incoming chrominance signal draws on the vectorscope is called the trace. Chrominance is measured using two methods—color saturation, encoded as the amplitude, or gain, of the subcarrier signal, and hue, encoded as the subcarrier's phase. The vectorscope's graticule roughly represents saturation as distance {{from the center of the}} circle, and hue as the angle, in standard position, around it. The graticule is also embellished with several elements corresponding to the various components of the standard color bars video test signal, including boxes around the circles for the colors in the main bars, and perpendicular lines corresponding to the U and V components of the chrominance signal (and additionally on an NTSC vectorscope, the I and Q components). NTSC vectorscopes have one set of boxes for the color bars, while their PAL counterparts have two sets of boxes, because the R-Y <b>chrominance</b> <b>component</b> in PAL reverses in phase on alternating lines. Another element in the graticule is a fine grid at the nine-o'clock, or -U position, used for measuring differential gain and phase.|$|E
40|$|This paper {{presents}} a digital watermarking {{scheme based on}} a new application of DWT and SVD for color artworks protection. This scheme uses the major features of the two chrominance components where the watermark bits are embedded only into one <b>chrominance</b> <b>component</b> according to the color prevalence rate. In watermark embedding process, more modifications can be done upon the selected <b>chrominance</b> <b>component,</b> while more readable information is needed during the watermark extraction process. Simulation results demonstrate that the proposed scheme yields {{a high level of}} robustness against various image processing operations without sacrificing the visual quality of watermarked artwork image...|$|E
40|$|System greatly {{improves}} {{signal-to-noise ratio}} {{with little or}} no loss in picture resolution. By storage of luminance component, which is summed with <b>chrominance</b> <b>component,</b> system performs mathematical integration of basically-repetitive television signals. Integration of signals over interval of their repetition causes little change in original signals and eliminates random noise...|$|E
40|$|Abstract—Colorization is {{a method}} which adds color com-ponents to {{grayscale}} images using color assigned {{information provided by the}} user. Recently, a novel approach to image compression called colorization based coding has been proposed. It automatically extracts color assignations from original color images at an encoder and restores color components by coloriza-tion method at a decoder. In this paper, we propose the method which improves the conventional color image coding methods by regarding colorization as interpolation. At the encoder, the proposed method subsamples <b>chrominance</b> <b>components</b> consid-ering colorization and subsampled <b>chrominance</b> <b>components</b> are compressed by conventional methods. At the decoder, subsam-pled <b>chrominance</b> <b>components</b> are interpolated by colorization. Simulations reveal that the proposed method improves quality of reconstructed images, objectively. I...|$|R
5000|$|The preshaped RGB {{values are}} then {{converted}} to a luminance and two <b>chrominance</b> <b>components</b> via a CCIR 601-1 conformant transform matrix: ...|$|R
30|$|Herein, {{the model}} {{designed}} for gray image is also applied to <b>chrominance</b> <b>components</b> since the human visual perception is {{more sensitive to}} luminance <b>component</b> than to <b>chrominance</b> compo-nents.|$|R
40|$|Most {{watermarking}} algorithms {{are either}} robust watermarking for copyright protection or fragile watermarking for tamper detection. This paper proposes a fragile video watermarking algorithm {{that has the}} ability to detect tamper in spatial domains. The original video frame is converted from RGB color space into YCbCr color space, then the <b>chrominance</b> <b>component</b> Cb is partitioned into non-overlapping blocks of pixels according to the number of bits of the original watermark. The watermark bits are embedded using a mathematical rule for each block separately. A detailed study for the applicability of this algorithm to content authentication is conducted. Experimental results reveal that the proposed algorithm achieves a low computation cost and high detection rate against a wide range of tampering attacks such a...|$|E
40|$|In {{this paper}} we {{address the problem of}} the {{compression}} of a video sequence acquired by most inexpensive single sensor video cameras. For each pixel in a frame only one <b>chrominance</b> <b>component</b> is available and an interpolation is used to obtain the full color frame. Our goal is to compress the video directly from the Bayer color filter array (CFA) data. We propose a new method for the reduction of temporal redundancy in video sequences. Our approach consists of a pre- and post-processing phases in combination with a standard motion prediction scheme. Simulation results confirm the effectiveness of the proposed method. Compared to standard methods, the improvement in quality is achieved at low and high compression rates. The proposed method offers bandwidth reduction where videos are transmitted over a communications link at low bit-rates while maintaining the same quality produced in the conventional method. 1...|$|E
40|$|Color image sensors use {{color filter}} arrays (CFA) to capture {{information}} at each sensor pixel position and require color demosaicing to reconstruct full color images. The {{quality of the}} demosaicked image is hindered by the sensor characteristics during the acquisition process. In this work, we propose a bandelet-based demosaicing method for color images. To this end, {{we have used a}} spatial multiplexing model of color in order to obtain the luminance and the chrominance components of the acquired image. Then, a luminance filter is used to reconstruct the luminance component. Thereafter, based on the concept of maximal gradient of multivalued images, we propose an extension of the bandelet representation for the case of multivalued images. Finally, demosaicing is performed by merging the luminance and each of the <b>chrominance</b> <b>component</b> in the multivalued bandelet transform domain. The experimental evaluation of the proposed scheme shows beneficial performance over existing demosaicing approaches. Index Terms — Demosaicing, bandelet transform, CF...|$|E
5000|$|The idea of {{transmitting}} a {{color television}} signal with distinct luma and <b>chrominance</b> <b>components</b> originated with Georges Valensi, who patented {{the idea in}} 1938. Valensi's patent application described: ...|$|R
5000|$|YDbDr is {{composed}} of three components - , [...] and [...] [...] is the luminance, [...] and [...] are the <b>chrominance</b> <b>components,</b> representing the red and blue colour differences.|$|R
40|$|This paper {{presents}} a complete coding system for compression of natural color still images represented with 24 bits per pixel. The original 8 -bit red, green, and blue (RGB) image components are first transformed to a luminance (Y) and two <b>chrominance</b> <b>components</b> (Cb, Cr) {{according to the}} ITU-R Recommendation 601 [1]. Each of the Y, Cb, and Cr tristimulus values are then decomposed separately in a subband filter bank with different filters for the luminance and the <b>chrominance</b> <b>components.</b> The Y-component requires a significantly higher bit rate than the Cb- and Cr-components, which can be downsampled {{by a factor of}} 10 to 20. For high quality image compression the downsampling factor must not be too large to avoid color artifacts. The luminance and <b>chrominance</b> <b>components</b> are quantized in uniform threshold quantizers with step size adapted to the signal statistics and the human visual system. A bank of entropy coders adapted to the components' subband signal statistics is used for bit ef [...] ...|$|R
40|$|A {{two-stage}} {{coding system}} {{for reducing the}} high data rate of a digital HDTV signal (approximately= 1 Gbit/s) is described. Spatio-temporal subsampling of the interlaced source signal is {{used in conjunction with}} an intrafield DPCM of the remaining samples. For the luminance signal two well-known sampling patterns, fieldquincunx and linequincunx, are proposed; both provide a 2 : 1 subsampling. Prior to subsampling, a digital filter which adapts itself to the movement in the scene, adjusts the three-dimensional spectrum of the television signal to some reduced region supported by the sampling pattern and the properties of the human visual system. Different filter structures are suggested for prefiltering and for interpolation of the missing samples in the receiver. The chrominance signals are horizontally bandlimited before digitization. A modified linequincunx sampling structure is used for subsampling the chrominance signals. Two-dimensional digital prefilters and interpolators are required. Then predictive coding with a fixed quantizer and predictor is applied to the picture elements which remain in the luminance and chrominance paths after subsampling. Sixteen quantization levels are used for the luminance and for each <b>chrominance</b> <b>component</b> to reduce the whole data rate to less than 280 Mbit/s...|$|E
40|$|Abstract—In this paper, {{a fragile}} {{watermarking}} scheme is proposed for color image specified object’s authentication. The color image is first transformed from RGB to YST color space, suitable for watermarking the color media. The T channel {{corresponds to the}} <b>chrominance</b> <b>component</b> of a color image andYS ⊥ T, therefore selected for embedding the watermark. The T channel is first divided into 2 × 2 non-overlapping blocks and the two LSBs are set to zero. The object {{that is to be}} authenticated is also divided into 2 × 2 nonoverlapping blocks and each block’s intensity mean is computed followed by eight bit encoding. The generated watermark is then embedded into T channel randomly selected 2 × 2 block’s LSBs using 2 D-Torus Automorphism. Selection of block size is paramount for exact localization and recovery of work. The proposed scheme is blind, efficient and secure with ability to detect and locate even minor tampering applied to the image with full recovery of original work. The quality of watermarked media is quite high both subjectively and objectively. The technique is suitable for class of images with format such as gif, tif or bitmap...|$|E
40|$|Indiana University-Purdue University Indianapolis (IUPUI) In this thesis, we {{describe}} a different implementation for in loop filtering method for 3 D-HEVC. First we propose {{the use of}} adaptive loop filtering (ALF) technique for 3 D-HEVC standard in-loop filtering. This filter uses Wiener–based method to minimize the Mean Squared Error between filtered pixel and original pixels. The performance of adaptive loop filter in picture based level is evaluated. Results show up to of 0. 2 dB PSNR improvement in Luminance component for the texture and 2. 1 dB for the depth. In addition, we obtain up to 0. 1 dB improvement in <b>Chrominance</b> <b>component</b> for the texture view after applying this filter in picture based filtering. Moreover, a design of an in-loop filtering with Fast Bilateral Filter for 3 D-HEVC standard is proposed. Bilateral filter is a filter that smoothes an image while preserving strong edges and it can remove the artifacts in an image. Performance of the bilateral filter in picture based level for 3 D-HEVC is evaluated. Test model HTM- 6. 2 is used to demonstrate the results. Results show up to of 20 percent of reduction in processing time of 3 D-HEVC with less than affecting PSNR of the encoded 3 D video using Fast Bilateral Filter...|$|E
40|$|By keeping more <b>chrominance</b> <b>components,</b> YUV 422 format {{provides}} {{much better}} fidelity and visual quality than YUV 420 format {{and is used}} extensively in high end video applications such as studio and video archiving. A new video coding framework for YUV 422 video sources is proposed in this paper. The proposed framework features color space compatibility to the more popular YUV 420 syntax. Specifically, the <b>chrominance</b> <b>components</b> are separately into two parts and coded differently. The first part, together with luminance component, conforms to the YUV 420 layout and is coded {{the same way as}} a normal YUV 420 video to produce a YUV 420 -compatible base bit stream. The second part, i. e., the remaining <b>chrominance</b> <b>components,</b> is coded to generate an enhancement chrominance bitstream for improving the chrominance quality. This is {{in sharp contrast to the}} YUV 422 coding method of MPEG- 2 / 4 standards where all the chrominance are coded together and in the same way. Consequently, the resulting YUV 422 bitstream can be easily converted to a YUV 420 bitstream by simple truncation instead of undergoing an expensive transcoding process. New coding modes are also introduced for more efficient coding of the enhancing <b>chrominance</b> <b>components.</b> Performance-wise, the new framework also outperforms existing methods thanks to the new coding modes introduced. 1...|$|R
3000|$|... are {{the blue}} and red <b>chrominance</b> <b>components,</b> respectively. According {{to the fact that}} human eyes are only {{sensitive}} to the luminance but not sensitive to the chrominance, the sensitive privacy information is only included in [...]...|$|R
30|$|It {{is worth}} {{stressing}} that sepia images are {{the input of}} the proposed algorithm. For this reason, only their luminance component has been processed and is shown; the two <b>chrominance</b> <b>components</b> can be kept unchanged if desired.|$|R
40|$|Abstract—This paper {{addresses}} our proposed {{method to}} au-tomatically segment out a person’s face from a given image {{that consists of}} a head-and-shoulders view of the person and a complex background scene. The method involves a fast, reliable, and effective algorithm that exploits the spatial distribution characteristics of human skin color. A universal skin-color map is derived and used on the <b>chrominance</b> <b>component</b> of the input image to detect pixels with skin-color appearance. Then, based on the spatial distribution of the detected skin-color pixels and their corresponding luminance values, the algorithm employs a set of novel regularization processes to reinforce regions of skin-color pixels that {{are more likely to}} belong to the facial regions and eliminate those that are not. The performance of the face-segmentation algorithm is illustrated by some simulation results carried out on various head-and-shoulders test images. The use of face segmentation for video coding in applications such as videotelephony is then presented. We explain how the face-segmentation results can be used to improve the perceptual quality of a videophone sequence encoded by the H. 261 -compliant coder. Index Terms — Color image processing, face location, facial image analysis, H. 261, image segmentation, quantization, video coding, videophone communication. I...|$|E
40|$|Abstract—In this paper, a novel {{scheme is}} {{proposed}} for ownership identification and authentication using color images by deploying Cryptography and Digital Watermarking as underlaying technologies. The former {{is used to}} compute the contents based hash and the latter to embed the watermark. The host image that will {{claim to be the}} rightful owner is first transformed from RGB to YST color space exclusively designed for watermarking based applications. Geometrically YS ⊥ T and T channel corresponds to the <b>chrominance</b> <b>component</b> of color image, therefore suitable for embedding the watermark. The T channel is divided into 4 × 4 nonoverlapping blocks. The size of block is important for enhanced localization, security and low computation. Each block along with ownership information is then deployed by SHA 160, a one way hash function to compute the content based hash, which is always unique and resistant against birthday attack instead of using MD 5 that may raise the condition i. e. H (m) = H (m ′). The watermark payload varies from block to block and computed by the variance factorα. The quality of watermarked images is quite high both subjectively and objectively. Our scheme is blind, computationally fast and exactly locates the tampered region. Keywords—Hash Collision, LSB, MD 5, PSNR, SHA 160. I...|$|E
40|$|In this thesis, we {{describe}} a different implementation for in loop filtering method for 3 D-HEVC. First we propose {{the use of}} adaptive loop filtering (ALF) technique for 3 D-HEVC standard in-loop filtering. This filter uses Wiener-based method to minimize the Mean Squared Error between filtered pixel and original pixels. The performance of adaptive loop filter in picture based level is evaluated. Results show up to of 0. 2 dB PSNR improvement in Luminance component for the texture and 2. 1 dB for the depth. In addition, we obtain up to 0. 1 dB improvement in <b>Chrominance</b> <b>component</b> for the texture view after applying this filter in picture based filtering. Moreover, a design of an in-loop filtering with Fast Bilateral Filter for 3 D-HEVC standard is proposed. Bilateral filter is a filter that smoothes an image while preserving strong edges and it can remove the artifacts in an image. Performance of the bilateral filter in picture based level for 3 D-HEVC is evaluated. Test model HTM- 6. 2 is used to demonstrate the results. Results show up to of 20 percent of reduction in processing time of 3 D-HEVC with less than affecting PSNR of the encoded 3 D video using Fast Bilateral Filter. ...|$|E
30|$|The {{proposed}} algorithm, named DCT-CNR (Discrete Cosine Transform-Chroma Noise Reduction), {{consists of}} performing a soft-threshold to the <b>chrominance</b> <b>components</b> {{of the image}} preserving the luminance and the DC coefficients of each DCT 8 × 8 chrominance block of the image to be coded.|$|R
40|$|This article {{presents}} {{a method of}} semi-blind watermarking based on the discrete wavelet transform, that uses the <b>chrominance</b> <b>components</b> of the image for watermark embedding. The watermark is resistant to usual image processing operations such as compression, noise addition, cropping, histogram adjustment and filtering...|$|R
40|$|This paper {{presents}} an efficient two-stage filtering method that provides highly reliable 4 : 2 : 0 YCbCr signals, which {{are widely used}} in the image- and video-processing community. In the first phase, we use an index mapping, center-weighted median filter (IMCWMF) to detect and remove noise from luminance (Y) components while inheriting the <b>chrominance</b> <b>components</b> (Cb and Cr) for the selected median luminance. In the second phase, we use a downsampling sigma filter (DSF) to detect and remove noise from the <b>chrominance</b> <b>components</b> while performing the downsampling process. Simulation {{results indicate that the}} proposed method outperforms other nonlinear filters in terms of both noise attenuation and signal-detail preservation while providing accurate color channel information for the JPEG compression process and overall image quality. 1...|$|R
40|$|In {{the last}} two decades, two related {{categories}} of problems have been studied independently in the image restoration literature: super-resolution and demosaicing. A closer look at these problems reveals the relation between them, and as conventional color digital cameras su#er from both low-spatial resolution and color filtering, {{it is reasonable to}} address them in a unified context. In this paper, we propose a fast and robust hybrid method of super-resolution and demosaicing, based on a maximum a posteriori (MAP) estimation technique by minimizing a multi-term cost function. The L 1 norm is used for measuring the di#erence between the projected estimate of the high-resolution image and each low-resolution image, removing outliers in the data and errors due to possibly inaccurate motion estimation. Bilateral regularization is used for regularizing the luminance component, resulting in sharp edges and forcing interpolation along the edges and not across them. Simultaneously, Tikhonov regularization is used to smooth the <b>chrominance</b> <b>component.</b> Finally, an additional regularization term is used to force similar edge orientation in di#erent color channels. We show that the minimization of the total cost function is relatively easy and fast. Experimental results on synthetic and real data sets confirm the e#ectiveness of our method...|$|E
40|$|Steganography {{is defined}} as the process of hiding {{information}} in a multimedia carrier. Ultimate objectives of steganography are undetectability and robustness of the secret data. It is known as adaptive steganography as the data is embed in to the specific Region of Interest (ROI) of the cover image for the purpose of safety of the inserted data. The assurance of both imperceptibility and robustness requirements are the main objectives of developing an image-hiding technique. The main focus is on embedding the data in the skin region of a video frame. Thus we concentrate on the skin detection algorithm to extract the skin region. This acts as the region of interest for embedding the secret message. To perform embedding the video frames are converted to YCbCr colour space. The frame having least MSE is selected to embed secret data. The secret data is then inserted into the <b>chrominance</b> <b>component</b> (Cr or Cb) of YCbCr of a frame which has least MSE. After embedding secret data, steganoflage video is created by transforming the data into RGB colour space. Secure transmission of secret message can be achieveed through steganoflage video. Steganoflage video satisfies the main objective of steganography that is undetectability and robustness of hidden data...|$|E
40|$|A {{color image}} {{contains}} luminance and chrominance components representing {{the intensity and}} color information respectively. The objective of the work {{presented in this paper}} is to show the significance of incorporating the chrominance information for the task of scene classification. An improved color-to-grayscale image conversion algorithm by effectively incorporating the chrominance information is proposed using color-to-gay structure similarity index (C 2 G-SSIM) and singular value decomposition (SVD) to improve the perceptual quality of the converted grayscale images. The experimental result analysis based on the image quality assessment for image decolorization called C 2 G-SSIM and success rate (Cadik and COLOR 250 datasets) shows that the proposed image decolorization technique performs better than 8 existing benchmark algorithms for image decolorization. In {{the second part of the}} paper, the effectiveness of incorporating the <b>chrominance</b> <b>component</b> in scene classification task is demonstrated using the deep belief network (DBN) based image classification system developed using dense scale invariant feature transform (SIFT) as features. The levels of chrominance information incorporated by the proposed image decolorization technique is confirmed by the improvement in the overall scene classification accuracy. Also, the overall scene classification performance is improved by the combination of models obtained using the proposed and the conventional decolorization methods. Comment: This article is accepted in SPIE J. of Electronic Imaging with title: Significance of perceptually relevant image decolorization for scene classificatio...|$|E
40|$|Human visual systems {{detect the}} {{boundary}} of objects best when they are accompanied by sudden changes in brightness. The edge enhancement core exploits this and enhances only the luminance channel [Ref 1]. This has {{the added benefit of}} eliminating color shifts at {{the boundary of}} objects, which are common when enhancing the <b>chrominance</b> <b>components</b> by similar methods. The luminance component is processed through the core in two dimensions using two line buffers. The <b>chrominance</b> <b>components</b> are passed through the core with the proper delay to match luminance processing. This core can accept <b>chrominance</b> <b>components</b> represented as signed or unsigned integers with or without the 128 offset. Defining Gains The amount and direction of the edge enhancement can be controlled through programmable gains gH (horizontal), gV (vertical), gD (diagonal), and gLap (Laplacian). Here, a vertical edge is defined as a feature running from top to bottom of an image. Similarly, a horizontal edge runs from left to right across the image. The diagonal direction covers both upper left to lower right and upper right to lower left diagonals. Gains can be set to values in the range of 0. 0 to 2. 0 (see the "EDK pCore Interface " and "General Purpos...|$|R
40|$|When multi-view {{sequences}} {{are recorded}} using a setup of several cameras, significant discrepancies between the luminance and <b>chrominance</b> <b>components</b> {{of the different}} camera views can often be observed. These variations may well impair {{the performance of a}} multi-view coder or a renderer. In many cases, it is therefore desirabl...|$|R
40|$|Abstract—This article {{presents}} {{a method of}} semi-blind watermarking based on the discrete wavelet transform, that uses the <b>chrominance</b> <b>components</b> of the image for watermark embedding. The watermark is resistant to usual image processing operations such as compression, noise addition, cropping, histogram adjustment and filtering. Keywords—watermarking;discrete wavelet transform I...|$|R
