3785|5834|Public
25|$|<b>Cluster</b> <b>sampling</b> (also {{known as}} {{clustered}} sampling) generally increases {{the variability of}} sample estimates above that of simple random sampling, {{depending on how the}} clusters differ between one another as compared to the within-cluster variation. For this reason, <b>cluster</b> <b>sampling</b> requires a larger sample than SRS to achieve the same level of accuracy – but cost savings from clustering might still make this a cheaper option.|$|E
25|$|<b>Cluster</b> <b>sampling</b> is {{commonly}} implemented as multistage sampling. This {{is a complex}} form of <b>cluster</b> <b>sampling</b> in which two or more levels of units are embedded one in the other. The first stage consists of constructing the clusters {{that will be used}} to sample from. In the second stage, a sample of primary units is randomly selected from each cluster (rather than using all units contained in all selected clusters). In following stages, in each of those selected clusters, additional samples of units are selected, and so on. All ultimate units (individuals, for instance) selected at the last step of this procedure are then surveyed. This technique, thus, is essentially the process of taking random subsamples of preceding random samples.|$|E
25|$|Multistage {{sampling}} can substantially reduce sampling costs, {{where the}} complete population list {{would need to}} be constructed (before other sampling methods could be applied). By eliminating the work involved in describing clusters that are not selected, multistage sampling can reduce the large costs associated with traditional <b>cluster</b> <b>sampling.</b> However, each sample may not be a full representative of the whole population.|$|E
40|$|When {{selecting}} flux-limited <b>cluster</b> <b>samples,</b> {{the detection}} efficiency of X-ray instruments {{is not the}} same for centrally-peaked and flat objects, which introduces a bias in flux-limited <b>cluster</b> <b>samples.</b> We quantify this effect {{in the case of a}} well-known <b>cluster</b> <b>sample,</b> HIFLUGCS. We simulate a population of X-ray clusters with various surface-brightness profiles, and use the instrumental characteristics of the ROSAT All-Sky Survey (RASS) to select flux-limited samples similar to the HIFLUGCS sample and predict the expected bias. For comparison, we also estimate observationally the bias in the HIFLUGCS sample using XMM-Newton and ROSAT data. We find that the selection of X-ray <b>cluster</b> <b>samples</b> is significantly biased (∼ 29...|$|R
40|$|In {{this paper}} we split up the {{sampling}} error occurred in stratified and <b>clustering</b> <b>sampling,</b> called global error and {{measured by the}} variance of estimator, in many partial errors each one referred to a single stratum or cluster. In particular, we study, for <b>clustering</b> <b>sampling,</b> the empirical distribution of the homogeneity coefficient {{that is very important}} for settlement of partial errors. Global Sampling Error, Partial Sampling Errors, Homogeneity Coefficient, Stratified <b>Sampling,</b> <b>Clustering</b> <b>Sampling,...</b>|$|R
40|$|We {{present a}} sample of 383 X-ray {{selected}} galaxy groups and clusters with spectroscopic redshift measurements (up to z ~ 0. 79) from the 2 XMMi/SDSS Galaxy Cluster Survey. The X-ray cluster candidates were selected as serendipitously detected sources from the 2 XMMi-DR 3 catalogue that were located in the footprint of the Sloan Digital Sky Survey (SDSS-DR 7). The cluster galaxies with available spectroscopic redshifts were selected from the SDSS-DR 10. We developed an algorithm for identifying the cluster candidates {{that are associated with}} spectroscopically targeted luminous red galaxies and for constraining the cluster spectroscopic redshift. A cross-correlation of the constructed <b>cluster</b> <b>sample</b> with published optically selected cluster catalogues yielded 264 systems with available redshifts. The present redshift measurements are consistent with the published values. The current <b>cluster</b> <b>sample</b> extends the optically confirmed <b>cluster</b> <b>sample</b> from our <b>cluster</b> survey by 67 objects. Moreover, it provides spectroscopic confirmation for 78 clusters among our published <b>cluster</b> <b>sample,</b> which previously had only photometric redshifts. Of the new <b>cluster</b> <b>sample</b> that comprises 67 systems, 55 objects are newly X-ray discovered clusters and 52 systems are sources newly discovered as galaxy clusters in optical and X-ray wavelengths. Based on the measured redshifts and the fluxes given in the 2 XMMi-DR 3 catalogue, we estimated the X-ray luminosities and masses of the <b>cluster</b> <b>sample.</b> Comment: A&A in press, 12 pages, 15 figures, 1 table, [URL]...|$|R
25|$|In 2007–2008, the Gallup Poll {{surveyed}} {{individuals from}} 128 {{countries in the}} first comprehensive study of global opinions. The Gallup Organization aggregated opinion from the adult population fifteen {{years of age and}} older, either through the telephone or personal interviews, and in both rural and urban areas except in areas where the safety of interviewer was threatened and in scarcely populated islands. Personal interviews were stratified by population size or geography and <b>cluster</b> <b>sampling</b> was achieved through one or more stages. Although error bounds vary, they were all below ±6% with 95% confidence.|$|E
25|$|Mixed {{models are}} widely used to analyze linear {{regression}} relationships involving dependent data when the dependencies have a known structure. Common applications of mixed models include analysis of data involving repeated measurements, such as longitudinal data, or data obtained from <b>cluster</b> <b>sampling.</b> They are generally fit as parametric models, using maximum likelihood or Bayesian estimation. In the case where the errors are modeled as normal random variables, there is a close connection between mixed models and generalized least squares. Fixed effects estimation is an alternative approach to analyzing this type of data.|$|E
2500|$|... 1997 – A poll of over 400 BYU {{students}} {{found that}} 42% of students believed {{that even if}} a same-sex attracted person keeps the honor code {{they should not be}} allowed to attend BYU and nearly 80% said they would not live with a roommate attracted to people of the same sex. The poll's stated 5 percent margin of error was criticized as being too low an estimate because of the <b>cluster</b> <b>sampling</b> in classes, however.|$|E
40|$|A {{class of}} linear models for a {{two-stage}} <b>cluster</b> <b>sample</b> is considered. The best linear unbiased predictor of the finite population total {{can be obtained}} through extended least squares under these models. The effort of computing the prediction variance of the predictor may be reduced. two-stage <b>cluster</b> <b>sample</b> prediction variance extended least squares model-based approach...|$|R
40|$|In {{this thesis}} {{we present a}} {{hierarchical}} Bayesian methodology for analyzing polychotomous data from multi-stage <b>cluster</b> <b>samples.</b> We begin with a model for multinomial data drawn from a two-stage <b>cluster</b> <b>sample</b> of a finite population. This model is then extended to incorporate partially observed data assuming that the data are missing at random (MAR), in the terminology of Little and Rubin (1987). We next develop a model for polychotomous data collected via a three-stage <b>cluster</b> <b>sample.</b> As with the two-stage model, we describe the methodology for dealing with partially observed data assuming they are MAR. We apply these two methodologies to the 1990 Slovenian Public Opinion Survey and present {{the results of these}} analyses. Finally, we fashion a multivariate probit model for a special type of multinomial data, multivariate binary data. We then construct this model that incorporates covariate information for the case of a two-stage <b>cluster</b> <b>sample.</b> Specifically, we outline this methodology for a two-stage <b>cluster</b> <b>sample.</b> This approach also allows for the integration of missing data into the analysis if the data are MAR. For all of the above models we use Markov chain Monte Carlo techniques to simulate samples from the posterior distribution. These samples are then utilized in making inference from the models...|$|R
3000|$|Distribution of samples. For given K central points (the mean {{points of}} the <b>cluster</b> <b>samples),</b> each sample is {{allocated}} in a cluster represented by the nearest mean point of its Euclidean distance, and the samples are divided into K <b>clusters.</b> Each <b>sample</b> can only be in a deterministic cluster to minimize the sum of squares within a group, i.e., each sample x [...]...|$|R
50|$|The main {{difference}} between <b>cluster</b> <b>sampling</b> and stratified sampling {{is that in}} <b>cluster</b> <b>sampling</b> the cluster is treated as the sampling unit so sampling is done on a population of clusters (at least in the first stage). In stratified sampling, the sampling is done on elements within each strata. In stratified sampling, a random sample is drawn {{from each of the}} strata, whereas in <b>cluster</b> <b>sampling</b> only the selected clusters are sampled. A common motivation of <b>cluster</b> <b>sampling</b> is to reduce costs by increasing sampling efficiency. This contrasts with stratified sampling where the motivation is to increase precision.|$|E
50|$|Although <b>cluster</b> <b>sampling</b> and {{stratified}} sampling {{bear some}} superficial similarities, they are substantially different. In stratified sampling, {{a random sample}} is drawn from all the strata, where in <b>cluster</b> <b>sampling</b> only the selected clusters are studied, either in single- or multi-stage.|$|E
5000|$|... #Subtitle level 3: Extension to <b>cluster</b> <b>sampling</b> of {{binary data}} ...|$|E
40|$|Summary. We {{report on}} the status of our effort to {{constrain}} the nature of dark energy through the evolution of the cluster mass function. Chandra temperature profiles for 31 clusters from a local <b>cluster</b> <b>sample</b> are shown. The X-ray appearance of the proto supermassive binary black hole {{at the center of the}} cluster Abell 400 is described. Preliminary weak lensing results obtained with Megacam@MMT for a redshift z = 0. 5 cluster from a distant <b>cluster</b> <b>sample</b> are given. 1 Introduction Understanding the nature of dark energy is one of the major goals of con-temporary cosmological and particle physics. The fate of the universe seems to be entirely determined by dark energy and a deeper understanding of itsproperties may shed light on the unification of general relativity and quantum theory. At the moment, astronomical measurements seem most likely to provide further information about dark energy. Measurements of the evolution of thegalaxy cluster abundance are among the most promising tools; they have the potential to yield tight constraints on the equation of state of dark energy. Here, we {{report on the}} status of our project to measure the evolution of the cluster mass function with very high quality observations of moderately sizedlocal and distant <b>cluster</b> <b>samples.</b> 2 Local <b>Cluster</b> <b>Sample</b> X-ray selection is well suited for the construction of complete cluster sam-ples useful for cosmological tests, because the X-ray luminosity of clusters is tightly correlated with their total gravitational mass [1, 2]. The HIghestX-ray FLUx Galaxy <b>Cluster</b> <b>Sample...</b>|$|R
40|$|This {{dissertation}} describes {{three distinct}} research papers. Although each research topic {{is different and}} {{there is very little}} binding some of the chapters together, all three deal with innovations to model-assisted estimators. Moreover, all three papers explore different aspects of estimating totals, means, and rates from <b>clustered</b> <b>samples.</b> New estimators are presented. Their theoretical properties are explored; and, simulations are used to explore their design-based properties in realistic situations. After an introductory chapter, we show how leverage adjustments can be made to sandwich variance estimators to improve variance estimates of Generalized Regression estimators in two-staged samples. In the third chapter, we explore multinomial logistic-assisted estimators of finite population totals in <b>clustered</b> <b>samples.</b> In the final chapter, we use generalized linear models to assist estimating finite population totals in <b>cluster</b> <b>samples...</b>|$|R
40|$|The cosmologically most {{important}} cluster parameter is its gravitational mass. In order to constrain cosmological models of structure formation by comparing simulations or analytic models with, e. g., observational mass functions of statistical <b>cluster</b> <b>samples,</b> <b>cluster</b> masses are needed. Precise cluste...|$|R
5000|$|Normally more {{accurate}} than <b>cluster</b> <b>sampling</b> for the same size sample ...|$|E
5000|$|... #Caption: A visual {{representation}} of selecting {{a random sample}} using the <b>cluster</b> <b>sampling</b> technique ...|$|E
5000|$|<b>Cluster</b> <b>{{sampling}}</b> is {{a sampling}} plan used when mutually homogeneous yet internally heterogeneous groupings are evident in a statistical population. It is often used in marketing research. In this sampling plan, the total population is divided into these groups (known as clusters) and a simple random sample of the groups is selected. The elements in each cluster are then sampled. If all elements in each sampled cluster are sampled, then this {{is referred to as}} a [...] "one-stage" [...] <b>cluster</b> <b>sampling</b> plan. If a simple random subsample of elements is selected within each of these groups, this is referred to as a [...] "two-stage" [...] <b>cluster</b> <b>sampling</b> plan. A common motivation for <b>cluster</b> <b>sampling</b> is to reduce the total number of interviews and costs given the desired accuracy. For a fixed sample size, the expected random error is smaller when most of the variation in the population is present internally within the groups, and not between the groups.|$|E
40|$|Keywords: We {{report on}} {{preliminary}} {{results of our}} X-ray survey of the most massive clusters currently identified from the Deep Lens Survey (DLS). The DLS <b>cluster</b> <b>sample</b> is selected based on weak lensing shear, which {{makes it possible for}} the first time to study clusters in a baryon-independent way. In this article we present X-ray properties of a subset of the shear-selected <b>cluster</b> <b>sample.</b> dark matter, gravitational lensing, large-scale structure of universe, X-rays: galaxies: clusters 1...|$|R
40|$|Summary. We {{report on}} the status of our effort to {{constrain}} the nature of dark energy through the evolution of the cluster mass function. Chandra temperature profiles for 31 clusters from a local <b>cluster</b> <b>sample</b> are shown. The X-ray appearance of the proto supermassive binary black hole {{at the center of the}} cluster Abell 400 is described. Preliminary weak lensing results obtained with Megacam@MMT for a redshift z = 0. 5 cluster from a distant <b>cluster</b> <b>sample</b> are given. ...|$|R
40|$|Abstract. Selection {{of galaxy}} {{clusters}} by mass {{is now possible}} due to weak gravitational lensing effects. It is an important question then whether this type of selection reduces the projection effects prevalent in optically selected <b>cluster</b> <b>samples.</b> We address this question using simulated data, from which we construct synthetic cluster catalogues both with Abell’s criterion and an aperture-mass estimator sensitive to gravitational tidal effects. The signal-to-noise ratio of the latter allows to some degree to control {{the properties of the}} <b>cluster</b> <b>sample.</b> For the first time, we apply the cluster-detection algorithm proposed by Schneider to large-scale structure simulations. We find that selection of clusters through weak gravitational lensing is more reliable in terms of completeness and spurious detections. Choosing the signal-to-noise threshold appropriately, the completeness can be increased up to 100 %, and the fraction of spurious detections can significantly be reduced compared to Abell-selected <b>cluster</b> <b>samples.</b> We also investigate the accuracy of mass estimates in <b>cluster</b> <b>samples</b> selected by both luminosity and weak-lensing effects. We find that mass estimates from gravitational lensing, for which we employ the ζ-statistics by Kaiser et al., are significantly more accurate than those obtained from galaxy kinematics via the virial theorem...|$|R
50|$|<b>Cluster</b> <b>sampling</b> (also {{known as}} {{clustered}} sampling) generally increases {{the variability of}} sample estimates above that of simple random sampling, {{depending on how the}} clusters differ between one another as compared to the within-cluster variation. For this reason, <b>cluster</b> <b>sampling</b> requires a larger sample than SRS to achieve the same level of accuracy - but cost savings from clustering might still make this a cheaper option.|$|E
50|$|<b>Cluster</b> <b>sampling</b> {{is used to}} {{estimate}} high mortalities in cases such as wars, famines and natural disasters.|$|E
5000|$|... market {{research}} to locate competitors or determine the market reach of competing companies or for <b>cluster</b> <b>sampling</b> ...|$|E
30|$|The {{following}} subsections {{presents the}} grouping analysis performed (<b>clustered</b> <b>sampling</b> and stratified sampling) over the sampling frame, as planned in the subsection 4.7.|$|R
40|$|We {{present the}} results from {{two-point}} spatial correlation analyses on X-ray confirmed northern Abell <b>clusters.</b> The <b>cluster</b> <b>samples</b> are subsets of a volume-limited ROSAT All-Sky Survey study of 294 R ≥ 0 Abell clusters of which 240 are X-ray luminous. This large number of clusters has allowed for magnitude- and volume-complete samples to be analysed according to richness and X-ray luminosity. For R ≥ 1 clusters, we find r 0 = 22 h− 1 Mpc and γ = − 1. 7, {{which is consistent with}} previous analyses of visually selected R ≥ 1 Abell clusters. We also find no indications of line-of-sight anisotropies within the R ≥ 1 clusters. For R ≥ 0 clusters, we find r 0 = 17. 5 h− 1 Mpc (and γ = − 1. 8) which is considerably lower than recent determinations of the correlation length for similar R ≥ 0 X-ray bright <b>cluster</b> <b>samples</b> (e. g. the X-ray Brightest Abell <b>Cluster</b> <b>sample</b> (XBACs) with 21 ≤ r 0 ≤ 26 h− 1 Mpc and the RASS 1 X-ray <b>cluster</b> <b>sample</b> with r 0 ∼ 23 h− 1 Mpc). All of the R ≥ 0 X-ray confirmed samples, including the XBACs and RASS 1 clusters sho...|$|R
3000|$|... eThis general particularity of <b>cluster</b> <b>samples</b> can be {{measured}} by the intraclass correlation coefficient and calls for specific variance estimation methods. For more information, see Joncas (2008).|$|R
50|$|There is also {{multistage}} <b>cluster</b> <b>sampling,</b> {{where at}} least two stages are taken in selecting elements from clusters.|$|E
50|$|Two-stage <b>cluster</b> <b>sampling,</b> {{a simple}} case of {{multistage}} sampling, is obtained by selecting cluster samples {{in the first}} stage and then selecting sample of elements from every sampled cluster. Consider a population of N clusters in total. In the first stage, n clusters are selected using ordinary <b>cluster</b> <b>sampling</b> method. In the second stage, simple random sampling is usually used. It is used separately in every cluster and the numbers of elements selected from different clusters are not necessarily equal. The total number of clusters N, number of clusters selected n, and numbers of elements from selected clusters need to be pre-determined by the survey designer. Two-stage <b>cluster</b> <b>sampling</b> aims at minimizing survey costs {{and at the same time}} controlling the uncertainty related to estimates of interest. This method can be used in health and social sciences. For instance, researchers used two-stage <b>cluster</b> <b>sampling</b> to generate a representative sample of the Iraqi population to conduct mortality surveys. Sampling in this method can be quicker and more reliable than other methods, which is why this method is now used frequently.|$|E
50|$|In {{adaptive}} <b>cluster</b> <b>sampling,</b> {{samples are}} taken using simple random sampling, and additional samples are taken at locations where measurements exceed some threshold value. Several additional rounds of {{sampling and analysis}} may be needed. Adaptive <b>cluster</b> <b>sampling</b> tracks the selection probabilities for later phases of sampling so that an unbiased estimate of the population mean can be calculated despite oversampling of certain areas. An example application of adaptive <b>cluster</b> <b>sampling</b> is delineating the borders of a plume of contamination. Adaptive sampling is useful for estimating or searching for rare characteristics in a population and is appropriate for inexpensive, rapid measurements. It enables delineating the boundaries of hot spots, while also using all data collected with appropriate weighting to give unbiased estimates of the population mean.|$|E
40|$|We {{present the}} results of a spectroscopic {{investigation}} of 108 nearby field B-stars. We derive their key stellar parameters, V sin i, T_ eff, g, and g_ polar, using the same methods that we used in our previous cluster B-star survey. By comparing the results of the field and the <b>cluster</b> <b>samples,</b> we find that the main reason for the overall slower rotation of the field sample is that it contains a larger fraction of older stars than found in the (mainly young) <b>cluster</b> <b>sample.</b> Comment: 20 pages, 5 figures, accepted for publication in Ap...|$|R
40|$|We {{report on}} {{preliminary}} {{results of our}} X-ray survey of the most massive clusters currently identified from the Deep Lens Survey (DLS). The DLS <b>cluster</b> <b>sample</b> is selected based on weak lensing shear, which {{makes it possible for}} the first time to study clusters in a baryon-independent way. In this article we present X-ray properties of a subset of the shear-selected <b>cluster</b> <b>sample.</b> Comment: 4 pages, including 6 postscript figs, LaTeX, to appear in the proceedings of the conference "Multiwavelength Cosmology" held 17 - 20 June, 2003, ed M. Plioni...|$|R
40|$|We {{compute the}} {{redshift}} space power spectrum of two X-ray cluster samples: the X-ray Brightest Abell <b>Cluster</b> <b>Sample</b> (XBACS) and the Brightest <b>Cluster</b> <b>Sample</b> (BCS) {{using the method}} developed by Feldman, Kaiser & Peacock. The power spectrums derived for these samples are in agreement with determinations of other optical and X-ray <b>cluster</b> <b>samples.</b> For XBACS we find the largest power spectrum amplitude expected given the high richness of this sample (R > 2). In the range 0. 05 < k < 0. 4 the power spectrum shows a power law behavior P(k) ∝ k^n with an index n≃- 1. 2. In a similar range 0. 04 < k < 0. 3 BCS power spectrum has a smaller amplitude with index n≃- 1. 0. We do not find significant evidence for a peak at k ≃ 0. 05 suggesting that claims such of feature detections in some <b>cluster</b> <b>samples</b> could relay on artificial inhomogeneities of the data. We compare our results with power spectrum predictions derived by Moscardini et al. within current cosmological models (LCDM and OCDM). For XBACS we find that both models underestimate the amplitude of the power spectrum but for BCS there is reasonably good agreement at k 0. 03 for both models. Comment: 9 pages (LateX, mn. sty), 9 figures, accepted for publication in MNRA...|$|R
