672|544|Public
25|$|Alternatively, in Bayesian terms, a {{prediction}} interval {{can be described}} as a <b>credible</b> <b>interval</b> for the variable itself, rather than for a parameter of the distribution thereof.|$|E
25|$|Prediction {{intervals}} {{are used}} in both frequentist statistics and Bayesian statistics: a prediction interval bears the same relationship to a future observation that a frequentist confidence interval or Bayesian <b>credible</b> <b>interval</b> bears to an unobservable population parameter: prediction intervals predict the distribution of individual future points, whereas confidence intervals and credible intervals of parameters predict the distribution of estimates of the true population mean or other quantity of interest that cannot be observed.|$|E
25|$|In Bayesian statistics, one can compute (Bayesian) {{prediction}} intervals {{from the}} posterior probability of the random variable, as a <b>credible</b> <b>interval.</b> In theoretical work, credible intervals are not often {{calculated for the}} prediction of future events, but for inference of parameters – i.e., credible intervals of a parameter, not for the outcomes of the variable itself. However, particularly where applications are concerned with possible extreme values of yet to be observed cases, credible intervals for such values can be of practical importance.|$|E
50|$|Severini (1991) {{discusses}} {{conditions under}} which <b>credible</b> <b>intervals</b> and confidence intervals will produce similar results, and also discusses both the coverage probabilities of <b>credible</b> <b>intervals</b> and the posterior probabilities associated with confidence intervals.|$|R
30|$|To {{make sure}} that Bayesian {{reference}} procedures do not bias the data analysis in an undesirable manner, {{it is important to}} study their frequentist properties. To study the frequentist properties of our proposed procedures, we have performed a Monte Carlo study that shows that our proposed Bayesian reference approaches compare favorably to a posterior analysis based on a competing prior in terms of coverage of <b>credible</b> <b>intervals,</b> relative mean squared error, and mean length of <b>credible</b> <b>intervals.</b> While the relative mean squared error and the mean length of <b>credible</b> <b>intervals</b> should be judged in comparison with those yielded by competing priors, the coverage of <b>credible</b> <b>intervals</b> should be {{as close as possible to}} the nominal level.|$|R
40|$|Frequentist {{confidence}} intervals {{were compared with}} Bayesian <b>credible</b> <b>intervals</b> {{under a variety of}} scenarios to determine when Bayesian <b>credible</b> <b>intervals</b> outperform frequentist {{confidence intervals}}. Results indicated that Bayesian interval estimation frequently produces results with precision {{greater than or equal to}} the frequentist method...|$|R
2500|$|Most studies only {{sample part}} of a population, so results don't fully {{represent}} the whole population. Any estimates obtained from the sample only approximate the population value. Confidence intervals allow statisticians to express how closely the sample estimate matches the true value in the whole population. Often they are expressed as 95% confidence intervals. Formally, a 95% confidence interval for a value is a range where, if the sampling and analysis were repeated under the same conditions (yielding a different dataset), the interval would include the true (population) value in 95% of all possible cases. This {{does not imply that}} the probability that the true value is in the confidence interval is 95%. From the frequentist perspective, such a claim does not even make sense, as the true value is not a random variable. [...] Either the true value is or is not within the given interval. However, it is true that, before any data are sampled and given a plan for how to construct the confidence interval, the probability is 95% that the yet-to-be-calculated interval will cover the true value: at this point, the limits of the interval are yet-to-be-observed random variables. One approach that does yield an interval that can be interpreted as having a given probability of containing the true value is to use a <b>credible</b> <b>interval</b> from Bayesian statistics: this approach depends on a different way of interpreting what is meant by [...] "probability", that is as a Bayesian probability.|$|E
5000|$|A Bayesian {{interval}} estimate {{is called a}} <b>credible</b> <b>interval.</b> Using {{much of the same}} notation as above, the definition of a <b>credible</b> <b>interval</b> for the unknown true value of θ is, for a given γ, ...|$|E
5000|$|... a <b>credible</b> <b>interval,</b> i.e. a set {{of values}} containing, for example, 95% of {{posterior}} belief; ...|$|E
5000|$|... <b>credible</b> <b>intervals</b> and {{confidence}} intervals treat nuisance parameters in radically different ways.|$|R
5000|$|... <b>credible</b> <b>intervals</b> {{can readily}} deal with prior information, while {{confidence}} intervals cannot.|$|R
50|$|Monte Carlo {{simulations}} can be run on many routines {{to estimate}} <b>credible</b> <b>intervals.</b>|$|R
5000|$|Credible {{intervals}} are {{not unique}} on a posterior distribution. Methods for defining a suitable <b>credible</b> <b>interval</b> include: ...|$|E
5000|$|A Bayesian {{analysis}} {{based on}} the nuclear genes suggests a date of divergence between Babesia and Theileria of [...] ( [...] 95% <b>credible</b> <b>interval</b> -) ...|$|E
50|$|Alternatively, in Bayesian terms, a {{prediction}} interval {{can be described}} as a <b>credible</b> <b>interval</b> for the variable itself, rather than for a parameter of the distribution thereof.|$|E
5000|$|Bayesian <b>credible</b> <b>intervals</b> can {{be quite}} {{different}} from frequentist confidence intervals for two reasons: ...|$|R
30|$|We used a Bayesian parameter-fitting method, {{sampling}} {{the posterior}} distributions by repeated Metropolis updates {{based on the}} full likelihood function (Eq. 11), generating Monte-Carlo Markov chains of each parameter. The MCMC chains represent full posterior distributions of all parameters and of other estimators derived from parameters. Chains were run 12000 steps for each model, examined visually for mixing, and the initial 2000 steps discarded as burn-in. We report the mean of post-burn-in chains as best estimates, and quartiles 0.025 and 0.975 for 95 % <b>credible</b> <b>intervals.</b> Hypotheses were tested by checking whether <b>credible</b> <b>intervals</b> of one slope parameter overlapped zero, or whether <b>credible</b> <b>intervals</b> of two slope parameters for one species overlapped each other.|$|R
5000|$|... <b>credible</b> <b>intervals</b> {{incorporate}} problem-specific {{contextual information}} from the prior distribution whereas confidence intervals are based only on the data; ...|$|R
50|$|It is {{possible}} to frame {{the choice of a}} <b>credible</b> <b>interval</b> within decision theory and, in that context, an optimal interval will always be a highest probability density set.|$|E
5000|$|For example, in an {{experiment}} that determines the uncertainty distribution of parameter , if the subjective probability that [...] lies between 35 and 45 is 0.95, then [...] is a 95% <b>credible</b> <b>interval.</b>|$|E
5000|$|... where PPOS1 and PPOS2 {{are some}} {{user-defined}} cutoff values. The first equation {{ensures that the}} PPOS is small such that not too many trials will be prevented entering next stage to guard against false negative. The first equation also ensures that the PPOS is not too small such that not too many trials will enter the next stage to guard against false positive. The second equation ensures that the PPOS <b>credible</b> <b>interval</b> is tight such that the PPOS calculation is supported by sufficient information. The second equation also ensures that the PPOS <b>credible</b> <b>interval</b> is not too tight such that it won't demand too much resource.|$|E
3000|$|... -based <b>credible</b> <b>intervals</b> having {{coverage}} {{lower than}} nominal {{leads us to}} prefer the data analysis based on the reference priors.|$|R
3000|$|... -based {{posterior}} median differs tremendously and {{is equal}} to 4.36. Second, the 95 % <b>credible</b> <b>intervals</b> for p based on [...]...|$|R
3000|$|We have {{considered}} the frequentist properties of the proposed Bayesian approaches via a simulation study. In particular, we have shown that <b>credible</b> <b>intervals</b> based on [...]...|$|R
50|$|PPOS is a {{conditional}} probability conditioned on randomly observed data and hence is a random variable itself. Currently common practice of PPOS uses only its point estimate in applications. This can be misleading. For a variable, {{the amount of}} uncertainty {{is an important part}} of the story. To address this issue, Tang introduced PPOS <b>credible</b> <b>interval</b> to quantify the amount of its uncertainty. Tang advocates to use both PPOS point estimate and <b>credible</b> <b>interval</b> in applications such as decision making and clinical trial designs.Another common issue is the mixed use of posterior probability of success and PPOS. As described in the previous section, the 2 statistics are measured in 2 different metrics, comparing them is like comparing apples and oranges.|$|E
5000|$|Posterior {{probability}} is a {{conditional probability}} conditioned on randomly observed data. Hence it is a random variable. For a random variable, {{it is important}} to summarize its amount of uncertainty. One way to achieve this goal is to provide a <b>credible</b> <b>interval</b> of the posterior probability.|$|E
5000|$|The {{definition}} of a <b>credible</b> <b>interval</b> involves probabilities calculated from the distribution of Θ conditional on the observed values of X = x and marginalised (or averaged) over the values of Φ, where this last quantity is the random variable corresponding to the uncertainty about the nuisance parameters in φ.|$|E
50|$|Note {{that the}} {{treatment}} of the nuisance parameters above is often omitted from discussions comparing confidence and <b>credible</b> <b>intervals</b> but it is markedly different between the two cases.|$|R
3000|$|... (p) is a naïve way {{to express}} lack of {{information}} about p. The Bayesian procedures we consider are the posterior modes and posterior medians for point estimation, and the 95 % highest posterior density (HPD) <b>credible</b> <b>intervals</b> for interval estimation. Finally, we consider three frequentist measures of quality. For {{evaluating the quality of}} point estimation, we consider the square root of the frequentist relative mean squared error. For evaluating the performance of interval estimation, we consider two frequentist measures: the frequentist coverage and the mean length of the <b>credible</b> <b>intervals.</b>|$|R
5000|$|For more novel {{situations}} {{there should}} be guidance on how interval estimates can be formulated. In this regard confidence <b>intervals</b> and <b>credible</b> <b>intervals</b> have a similar standing but there are differences: ...|$|R
5000|$|The Jeffreys {{interval}} is the Bayesian <b>credible</b> <b>interval</b> obtained {{when using}} the non-informative Jeffreys prior for the binomial proportion [...] The Jeffreys prior for this problem is a Beta distribution with parameters [...] After observing [...] successes in [...] trials, the posterior distribution for [...] is a Beta distribution with parameters [...]|$|E
5000|$|Traditional {{efficacy}} interim {{is designed}} based on spending functions. Since spending functions don't have an intuitive interpretation, {{it is difficult}} to communicate to non-statistician colleagues. In contrast probability of success has an intuitive interpretation and hence can facilitate communication with non-statistician colleagues. Tang (2016) [...] proposes the use of the following criteria to support efficacy interim decision making:mCPOS>c1lCPOS>c2where mCPOS is the median of CPOS with respect to the distribution of the parameter and lCPOS is the lower bound of the <b>credible</b> <b>interval</b> of CPOS. The first criterion ensures that the probability of success is large. The second criterion ensures that the <b>credible</b> <b>interval</b> of CPOS is tight; the CPOS calculation is supported by enough information; hence the probability of success is not large by chance.Finding the optimal design is equivalent to finding the solution to the following equations: ...|$|E
5000|$|... where [...] is the {{standard}} normal cumulative distribution, [...] is the maximum likelihood estimator of [...] and [...] is its standard deviation; the latter might be estimated from the inverse of the Fisher information matrix or by using the [...] "Asimov" [...] data set. This result happens to be equivalent to a Bayesian <b>credible</b> <b>interval</b> if a uniform prior for [...] is used.|$|E
30|$|This {{cumulative}} distribution function {{makes it possible to}} calculate <b>credible</b> <b>intervals</b> and the probability that the effect studied is lower or higher than a particular value, given the data and prior probabilities.|$|R
3000|$|... (dotted line). In addition, the {{vertical}} lines indicate {{the limits of}} the 95 % HPD <b>credible</b> <b>intervals.</b> The three reference priors lead to similar posterior densities for p, while the π [...]...|$|R
50|$|There {{should be}} ways of testing the {{performance}} of interval estimation procedures. This arises because many such procedures involve approximations of various kinds {{and there is a}} need to check that the actual performance of a procedure is close to what is claimed. The use of stochastic simulations makes this is straightforward in the case of confidence intervals, but it is somewhat more problematic for <b>credible</b> <b>intervals</b> where prior information needs to be taken properly into account. Checking of <b>credible</b> <b>intervals</b> can be done for situations representing no-prior-information but the check involves checking the long-run frequency properties of the procedures.|$|R
