38|89|Public
25|$|The <b>clipping</b> <b>level</b> is an {{important}} indicator of maximum usable level, as the 1%THD figure usually quoted under max SPL is really a very mild level of distortion, quite inaudible especially on brief high peaks. Clipping is much more audible. For some microphones the <b>clipping</b> <b>level</b> may be {{much higher than the}} max SPL.|$|E
2500|$|Sensitivity {{indicates}} {{how well}} the microphone converts acoustic pressure to output voltage. A high sensitivity microphone creates more voltage and so needs less amplification at the mixer or recording device. [...] This is a practical concern but is not directly {{an indication of the}} microphone's quality, and in fact the term sensitivity is something of a misnomer, [...] "transduction gain" [...] being perhaps more meaningful, (or just [...] "output level") because true sensitivity is generally set by the noise floor, and too much [...] "sensitivity" [...] in terms of output level compromises the <b>clipping</b> <b>level.</b> There are two common measures. The (preferred) international standard is made in millivolts per pascal at 1kHz. A higher value indicates greater sensitivity. The older American method is referred to a 1V/Pa standard and measured in plain decibels, resulting in a negative value. Again, a higher value indicates greater sensitivity, so −60 dB is more sensitive than −70dB.|$|E
50|$|The <b>clipping</b> <b>level</b> is an {{important}} indicator of maximum usable level, as the 1% THD figure usually quoted under max SPL is really a very mild level of distortion, quite inaudible especially on brief high peaks. Clipping is much more audible. For some microphones the <b>clipping</b> <b>level</b> may be {{much higher than the}} max SPL.|$|E
5000|$|Change of the W/D <b>clip</b> <b>level</b> (reducing {{the white}} <b>clip</b> <b>level</b> from 210% in SVHS to 190% in SVHS ET) ...|$|R
5000|$|<b>Clip</b> <b>Level</b> (6dB above Standard Output Level, [...] "headroom" [...] {{to allow}} for unusual conditions) ...|$|R
5000|$|A. E. Siegman, M. W. Sasnett and J. T. F. Johnston, [...] "Choice of <b>clip</b> <b>levels</b> for {{beam width}} {{measurements}} using knife-edge techniques," [...] IEEE J. Quantum Electron. QE-27, 1098-1104 (April 1991).|$|R
5000|$|Many {{systems can}} {{generate}} automated reports, based on certain predefined criteria or thresholds, known as clipping levels. For example, a <b>clipping</b> <b>level</b> may {{be set to}} generate a report for the following: ...|$|E
5000|$|Sensitivity {{indicates}} {{how well}} the microphone converts acoustic pressure to output voltage. A high sensitivity microphone creates more voltage and so needs less amplification at the mixer or recording device. This is a practical concern but is not directly {{an indication of the}} microphone's quality, and in fact the term sensitivity is something of a misnomer, [...] "transduction gain" [...] being perhaps more meaningful, (or just [...] "output level") because true sensitivity is generally set by the noise floor, and too much [...] "sensitivity" [...] in terms of output level compromises the <b>clipping</b> <b>level.</b> There are two common measures. The (preferred) international standard is made in millivolts per pascal at 1 kHz. A higher value indicates greater sensitivity. The older American method is referred to a 1 V/Pa standard and measured in plain decibels, resulting in a negative value. Again, a higher value indicates greater sensitivity, so −60 dB is more sensitive than −70 dB.|$|E
50|$|Distortion {{measurements}} on loudspeakers {{can only go}} as low as the distortion of the measurement microphone itself of course, at the level tested. The microphone should ideally have a <b>clipping</b> <b>level</b> of 120 to 140 dB SPL if high-level distortion is to be measured. A typical top-end speaker, driven by a typical 100watt power amplifier, cannot produce peak levels much above 105 dB SPL at 1 m (which translates roughly to 105 dB at listening position {{from a pair of}} speakers in a typical listening room). Achieving truly realistic reproduction requires speakers capable of much higher levels than this, ideally around 130 dB SPL. Even though the level of live music measured on a (slow responding and rms reading) sound level meter might be in the region of 100 dB SPL, programme level peaks on percussion will far exceed this. Most speakers give around 3% distortion measured 468-weighted 'distortion residue' reducing slightly at low levels. Electrostatic speakers can have lower harmonic distortion, but suffer higher intermodulation distortion. 3% distortion residue corresponds to 1 or 2% Total harmonic distortion. Professional monitors may maintain modest distortion up to around 110 dB SPL at 1 m, but almost all domestic speaker systems distort badly above 100 dB SPL.|$|E
40|$|International audienceTo support privacy-preserving video sharing, we have {{proposed}} a novel framework that is able to protect the video content privacy at the individual video <b>clip</b> <b>level</b> and prevent statistical inferences from video collections. To protect the video content privacy at the individual video <b>clip</b> <b>level,</b> we have developed an effective algorithm to automatically detect privacy-sensitive video objects and video events. To prevent the statistical inferences from video collections, we have developed a distributed framework for privacy-preserving classifier training, which is able to significantly reduce the costs of data transmission and reliably limit the privacy breaches by determining the optimal size of blurred test samples for classifier validation. Our experiments on a specific domain of patient training and counseling videos show convincing results...|$|R
50|$|Where YouTube {{and other}} sites are video sharing sites and hosting sites that {{organize}} around the video <b>clip</b> <b>level,</b> Network2 offers {{a guide to}} shows with characters or hosts that repeat from episode to episode, and shows that are the original work of the content producer. Network2 has {{more in common with}} TV Guide than a sharing site, as Network2 points people to the content producer's own sites and work.|$|R
40|$|We {{present an}} {{extended}} theoretical background of so-called fluence scan (f-scan or F-scan) method which is frequently {{being used for}} offline focused short-wavelength (XUV, soft X-ray, and hard X-ray) laser beam characterization (Chalupský et al. 2010 Opt. Express 18 27836). The method exploits ablative imprints in various solids to visualize iso-fluence beam contours at different fluence and/or <b>clip</b> <b>levels.</b> By varying the pulse energy, an f-scan curve (<b>clip</b> <b>level</b> {{as a function of}} the contour area) can be generated for a general non-Gaussian beam. The fluence scan method greatly facilitates transverse characterization of focused non-Gaussian beams and provides important information about energy distribution within the beam profile. Here we for the first time discuss fundamental properties of the f-scan function and its inverse counterpart (if-scan or iF-scan). Furthermore, we extensively elucidate how it is related to the effective beam area, energy distribution, and to the so called Liu’s plot (Liu 1982 Opt. Lett. 7 196). A new method of effective area evaluation based on weighted inverse f-scan fit is introduced and applied to real data obtained at the SCSS (Spring- 8 Compact SASE Source) facility...|$|R
3000|$|... [...]. The {{algorithm}} is iterated until PAPR is essentially decreased or a given iteration time is reached. Another issue concerns the <b>clipping</b> <b>level</b> choice being {{of particular importance}} to achieve the best PAPR reduction. Specifying the ideal <b>clipping</b> <b>level</b> is a difficult task, because this depends on various factors as reported in [19].|$|E
40|$|AbstractThe Active Constellation Extension (ACE) {{based on}} {{clipping}} technique is a lossless, simple and attractive Peak-to-Average Power Ratio (PAPR) reduction technique. However, we observe it cannot achieve the minimum PAR when the target <b>clipping</b> <b>level</b> is set below an initially unknown optimum value. To overcome this low clipping ratio problem, a novel ACE algorithm with adaptive clipping control is proposed in this paper. First, an adaptive strategy {{is used to}} control the size of <b>clipping</b> <b>level</b> ‘A’. Secondly, a novel step factor considering the possible overlap, is adopted to complete iterative computations {{in order to increase}} the convergence speed. Simulation results verify that the modified algorithm has reduced the PAPR and improved the convergence speed significantly without side information and without any extra processing at the receiver end...|$|E
40|$|Abstract-Suboptimal {{detection}} schemes, such as list MIMO detection, often {{face the}} challenge of having to "guess " at the decision reliability for some of the detected bits. A simple yet effective way of doing this is to set the maximum magnitudes of the associated log-likelihood-ratios (LLRs) to a certain predefined value: LLR clipping. However, the choice of the <b>clipping</b> <b>level</b> has {{a significant impact on the}} system performance. A majority of prior approaches attempted to determine appropriate clipping levels by manual optimization. In this work we propose to use an SNR-aware approach for calculating the LLR clipping levels in list MIMO detection. The proposed scheme exploits knowledge of the channel state information to determine the instantaneous bit error probability ofthe list detector, and from this an appropriate level for clipping of the LLRs. Simulation results show that this strategy outperforms schemes using a fixed <b>clipping</b> <b>level.</b> I...|$|E
50|$|As told by Rip Rowan on the ProRec website, {{the damaged}} {{production}} {{is the result}} of overly compressed (<b>clipped)</b> audio <b>levels</b> during mastering.|$|R
40|$|We {{present a}} novel sparse {{representation}} based approach {{for the restoration}} of clipped audio signals. In the proposed approach, the clipped signal is decomposed into overlapping frames and the declipping problem is formulated as an inverse problem, per audio frame. This problem is further solved by a constrained matching pursuit algorithm, that exploits the sign pattern of the clipped samples and their maximal absolute value. Performance evaluation with a collection of music and speech signals demonstrate superior results compared to existing algorithms, over a wide range of <b>clipping</b> <b>levels...</b>|$|R
40|$|Monte Carlo {{simulations}} {{model the}} eflects of partial-band jamming on turbo code performance over a slow frequency-hopped spread spectrum signal. Decoders using both hard and soft decision variables corrupted by Additive White Gaussian Noise (A WGN) are considered. Modulations include both Binary Phase Shzjl Keying (BPSK) and dl~erentially coherent BPSK (DPSK). The Bit Error Rate (BER) performance {{is measured in}} channels with negligible levels of thermal noise and in channels with similar levels of jammer and thermal noise. The optimum jammer occupancy is measured and found {{to be consistent with}} theoretical predictions. Decoder performance is improved by using side-information or by clipping the decision variable. Optimum <b>clipping</b> <b>levels</b> are estimated...|$|R
40|$|Abstract—In tone {{reservation}} (TR) based OFDM systems, {{the peak}} to average power ratio (PAPR) reduction performance mainly {{depends on the}} selection of the peak reduction tone (PRT) set and the optimal target <b>clipping</b> <b>level.</b> Finding the optimal PRT set requires an exhaustive search of all combinations of possible PRT sets, which is a nondeterministic polynomial-time (NP-hard) problem, and this search is infeasible for the number of tones used in practical systems. The existing selection methods, such as the consecutive PRT set, equally spaced PRT set and random PRT set, perform poorly compared to the optimal PRT set or incur high computational complexity. In this paper, an efficient scheme based on genetic algorithm (GA) with lower computational complexity is proposed for searching a nearly optimal PRT set. While TR-based clipping is simple and attractive for practical implementation, de-termining the optimal target <b>clipping</b> <b>level</b> is difficult. To overcome this problem, we propose an adaptive clipping control algorithm. Simulation results show that our proposed algorithms efficiently obtain a nearly optimal PRT set and good PAPR reductions...|$|E
40|$|Presented at the 2 nd Web Audio Conference (WAC), April 4 - 6, 2016, Atlanta, Georgia. This {{presentation}} {{was presented as}} part of a lightning talks session on April 4, 2016. Timestamp: 00 : 12 - 00 : 36. Clipping is an unpleasant recording artifact that occurs when an audio signal’s level rises above a microphone’s or AD converter’s maximum input level. As more audio and video recordings are being taken on mobile devices (sometimes in high sound level conditions such as live concerts), clipping has become an issue that users encounter frequently. We present ClipAway: a web application that analyzes an audio file and automatically removes clipping from the audio file. The following scenario illustrates the service we supply: 1) A user attends a live concert and creates an audio recording of the concert. 2) The user listens to the recording at home and notices clipping, which causes the listening experience to be unsatisfactory. 3) The user uploads the audio recording to the ClipAway website. 4) Audio processing occurs in the browser, and the user then exports a qualityenhanced version of the recording. 5) The listening experience with the resulting audio file has significantly improved. The advantage of browser-based processing is that it is more familiar and accessible to most users than a native solution, which would likely require the user to install a standalone software or a digital audio workstation hosting a plugin for quality enhancement. The declipping algorithm is split into two sections: clipping detection and clipping correction. Clipping detection involves the automatic estimation of the <b>clipping</b> <b>level</b> and the subsequent localization of clipped regions. The <b>clipping</b> <b>level</b> is determined by identifying anomalies in the signal’s amplitude histogram near the positive and negative endpoints. The locations of clipping are determined by identifying samples with amplitudes close to the <b>clipping</b> <b>level</b> where the signal has a near-horizontal slope. Clipping correction involves replacing short clipped regions using spline interpolation and replacing long clipped regions through linear interpolation of time-frequency bin magnitudes...|$|E
40|$|In this paper, we derive {{and analyze}} a {{companding}} algorithm {{based on the}} hyperbolic tangent and inverse hyperbolic tangent functions for use in orthogonal frequency division multiplexing (OFDM) transceivers. Probability density functions (PDFs) that approximate the transmitted and received OFDM signals {{in the presence of}} additive white Gaussian noise (AWGN) are derived and used to analyze the degree of companding relative to the signal-to-noise ratio (SNR) and <b>clipping</b> <b>level.</b> A set of optimal companding linearity coefficients for the multiband OFDM (MB-OFDM) ultra-wideband (UWB) standard are presented...|$|E
40|$|This article {{presents}} a new method for Peakto- Average Power Ratio (PAPR) reduction of Orthogonal Frequency Division Multiplexing (OFDM) signal. The proposed method {{is based on}} a relatively simple processing – pre-scrambling of OFDM symbol bit-block. The modified msequence with the least peak-factor for scrambling is used. The stability of pre-scrambled OFDM signal to the clipping is examined as well. C/C++ computer simulation of OFDM system with 64 subcarriers and frequency domain blocktypepilot channel estimation is performed for AWGN multipath channel. As a result, bit error rate (BER) performance for various <b>clipping</b> <b>levels</b> is presented due to computer simulation. In addition, the Efficiency of joined pre-scrambling and clipping method is considered...|$|R
40|$|Abstract—Consider a {{communications}} system where the detector generates {{a mix of}} hard and soft outputs, which are then fed into a soft-input channel decoder. In such a setting, it is of interest to find the optimal soft representation for the hard detected bits, which minimizes the probability of error at the decoder output. In this contribution we prove that for repetition codes transmitted over the AWGN channel using antipodal signaling, the optimal soft representation is given by the error probability at the detector output. This provides {{an indication of how}} “LLR <b>clipping</b> <b>levels</b> ” should be chosen, e. g., in the context of list based detection of multiple-input multiple-output (MIMO) signals. I...|$|R
40|$|CONCLUSION ILAH, LSR and LILAH from [4] {{exceed the}} {{performance}} of the optimized baseline on unencoded speech, and at <b>clipping</b> <b>levels</b> between- 3 and- 14 dBFS on decoded speech, an important range in mobile telephony applications. Performance is maintained at SNRs down to 5 dB. The averaging nature of histogram approach in ILAH, and the spectral approach of LSR both provide robustness to noise. The baseline method with ε = 0. 71 (optimized) in decoded speech generates many FPs, and loses accuracy at high ODF because it does not adapt to each speaker, whilst the F 1 score improves at high ODF because it crudely labels all samples of significant amplitude as clipped...|$|R
40|$|This study {{examines}} {{whether it would}} be better to deploy a velocity-recording strong-motion instrument in place of existing force-balance accelerometers. The proposed instrument would be comparable to a low-gain version of existing broadband seismometers. Using a large suite of Earth signals, we compare such a hypothetical long-period low-gain velocity seismometer (with a <b>clipping</b> <b>level</b> set to ± 5 m/s) with the existing ± 2 g clipping Kinemetrics FBA- 23 accelerometer. We show that there are significant advantages in the deployment of the proposed instrument over an accelerometer. ...|$|E
40|$|We {{discuss the}} {{accuracy}} of a measurement of a spectral linewidth using the method of digital correlation of single-clipped photon counting fluctuations with a given light flux and a given duration of experiment. Statistical effects due to the random nature of the light field and the photoelectric process limit this accuracy, so that the longer {{the duration of the}} experiment the more accurate the result, if all other factors are equal. Theoretical and experimental results are presented which show the accuracies obtainable as functions of the sample time, detector area and <b>clipping</b> <b>level...</b>|$|E
40|$|In {{this paper}} a simple {{programmable}} optical interface circuit {{with a high}} range <b>clipping</b> <b>level</b> value to become suitable for higher velocity and mass flow rate measurements is presented. This interface converts the data received from photo multiplier electronics as an optical transducer to a manageable form {{that can be easily}} correlated using zero crossing microprocessor-based correlator. The circuit is built using off-the-shelf EEPROM based programmable logic device (PLD) which enables the user to program it several times. The simulation results are also includedInternational Symposium on Intelligent Signal Processing and Communication System...|$|E
40|$|Abstract—We propose {{semantic}} model vectors, {{an intermediate}} level semantic representation, {{as a basis}} for modeling and detecting complex events in unconstrained real-world videos, such as those from YouTube. The semantic model vectors are extracted using a set of discriminative semantic classifiers, each being an ensemble of SVM models trained from thousands of labeled web images, for a total of 280 generic concepts. Our study reveals that the pro-posed semantic model vectors representation outperforms—and is complementary to—other low-level visual descriptors for video event modeling. We hence present an end-to-end video event detection system, which combines semantic model vectors with other static or dynamic visual descriptors, extracted at the frame, segment, or full <b>clip</b> <b>level.</b> We perform a comprehensive empir-ical study on the 2010 TRECVID Multimedia Event Detection tas...|$|R
40|$|Detecting {{the time}} of {{occurrence}} of an acoustic event (for instance, a cheer) embedded in a longer soundtrack is useful and important for applications such as search and retrieval in consumer video archives. We present a Markov-model based clustering algorithm able to identify and segment consistent sets of temporal frames into regions associated with different ground-truth labels, and simultaneously to exclude a set of uninformative frames shared in common from all clips. The labels are provided at the <b>clip</b> <b>level,</b> so this refinement of the time axis represents a variant of Multiple-Instance Learning (MIL). Evaluation shows that local concepts are effectively detected by this clustering technique based on coarse-scale labels, and that detection performance is significantly better than existing algorithms for classifying real-world consumer recordings...|$|R
60|$|CLARE. [In her <b>level,</b> <b>clipped</b> voice] Perfectly beastly of me! I'm so sorry. I simply can't help running amok to-night.|$|R
40|$|Estimation of the {{acoustic}} parameters Signal-to-Noise Ratio (SNR), Reverberation Time (T 60), Direct-to-Reverberant Ratio (DRR), and <b>clipping</b> <b>level</b> from degraded speech are open research questions. These parameters {{are important for}} determining speech quality and intelligibility, and they are widely applicable to speech enhancement and speech recognition systems. Whilst SNR, T 60, and DRR are useful priors for dereverberation schemes, indications of clipping and the <b>clipping</b> <b>level</b> are useful for signal restoration. This thesis investigates how accurately and robustly to noise and, {{in the case of}} clipping detection, robustness to the coding and decoding process it is possible to estimate these parameters non-intrusively from degraded speech in real-time or near real-time, and introduces a range of novel algorithms. Alongside the algorithms, an international research challenge was staged for which a novel noisy reverberant speech corpus was developed to determine the state-of-the-art in T 60 and DRR estimation. In tests, the algorithms presented in this thesis were highly competitive, being able to estimate T 60 with Pearson correlation coefficient, ρ = 0. 608 and DRR with ρ = 0. 314. Both algorithms achieved very low computational complexity with Real-Time Factors (RTFs) of 0. 0164 and 0. 0589 respectively. The clipping detection algorithms achieved F 1 approximately 0. 6 for Global System For Mobile Communications (GSM) 06. 10 decoded speech, babble noise at 20 dB SNR clipping levels in the range - 5 to - 20 dBFS, and also produce an estimate of the original unclipped signal level. Open Acces...|$|E
40|$|The three-state-polarity-coincidence {{correlator}} (PCC'), a two-input {{detection device}} with dead zone clippers, {{has been investigated}} in detail. A criterion is devised to compare two detectors. Comparisons are made between the PCC' and several other types of detectors. The superiority of the PCC' in the detection of a weak signal embedded in an additive noise over the PCC and other detectors is demonstrated. It is shown, particularly for certain Gaussian inputs, that there exists a maximum relative efficiency {{with respect to the}} dead zone width of clippers or the <b>clipping</b> <b>level</b> "b". It is concluded that the PCC' can always be used to replace the PCC in a weak signal detection...|$|E
40|$|Abstract: In OFDM systems, {{the major}} {{obstacle}} {{is that the}} multiplex signal exhibits a very high peak-to-average power ratio (PAR) In this paper propose a new novel method to reduce the PAR. A simple and attractive technique is Active cancellation extension used. However, we observe it cannot achieve the minimum PAR when the target <b>clipping</b> <b>level</b> is set below an initially unknown optimum value. A low clipping ratio is the problem in OFDM system to overcome this AEC algorithm with adaptive clipping control. However the simulation results shows our algorithm can reach the minimum Peak to Average for several clipping ratios, and also in AWGN channel we calculate the tradeoff between PAR and the loss i...|$|E
40|$|The goal of {{this work}} is to {{recognise}} and localise short temporal signals in image time series, where strong supervision is not available for training. To this end we propose an image encoding that concisely represents human motion in a video sequence {{in a form that}} is suitable for learning with a ConvNet. The encoding reduces the pose information from an image to a single column, dramatically diminishing the input requirements for the network, but retaining the essential information for recognition. The encoding is applied to the task of recognizing and localizing signed gestures in British Sign Language (BSL) videos. We demonstrate that using the proposed encoding, signs as short as 10 frames duration can be learnt from clips lasting hundreds of frames using only weak (<b>clip</b> <b>level)</b> supervision and with considerable label noise...|$|R
40|$|With the {{explosive}} growth of motion capture data, it becomes very imperative in animation production to have an efficient search engine to retrieve motions from large motion repository. However, {{because of the high}} dimension of data space and complexity of matching methods, most of the existing approaches cannot return the result in real time. This paper proposes a high level semantic feature in a low dimensional space to represent the essential characteristic of different motion classes. On the basis of the statistic training of Gauss Mixture Model, this feature can effectively achieve motion matching on both global <b>clip</b> <b>level</b> and local frame level. Experiment results show that our approach can retrieve similar motions with rankings from large motion database in real-time and also can make motion annotation automatically on the fly. Copyright © 2013 John Wiley & Sons, Ltd...|$|R
40|$|Video {{applications}} {{are characterized by}} their increased requirements for hug storag spaces andtiming synchronization. Video data storag is a critical issue due to the so-called I/O bottleneck problem {{in relation to the}} quality of service while accessing video applications. The main contribution of the paper is that it considers video data dependencies, access frequencies andtiming constraints in order to introduce a video data representation model whichg ides the storag policies. Two video data representation levels are considered to capture the frequencies of accesses at external (video objects) and internal (video <b>clips)</b> <b>levels.</b> A simulation model has been developed in order to evaluate the placement strateg 2 C [...] Video data placement is performed on a tertiary storag subsystem by both constructive and iterative improvement policies. Iterative improvement placement has been proven to outperform the other video data placement approaches...|$|R
