29|180|Public
2500|$|Wikipedia {{receives}} between 25,000 and 60,000 page requests per second, {{depending on}} time of day. [...] page requests are first passed to a front-end layer of Squid caching servers. Further statistics, {{based on a}} publicly available 3-month Wikipedia access trace, are available. Requests that cannot be served from the Squid cache are sent to load-balancing servers running the Linux Virtual Server software, which in turn pass them {{to one of the}} Apache web servers for page rendering from the database. The web servers deliver pages as requested, performing page rendering for all the language editions of Wikipedia. To increase speed further, rendered pages are cached in a distributed memory cache until invalidated, allowing page rendering to be skipped entirely for most <b>common</b> <b>page</b> accesses.|$|E
5000|$|Breezi {{allows users}} to choose from a {{selection}} of grid-based wireframes or pre-designed themes. [...] All of the specific areas of design customization are separated. The areas, or units, of design can be managed individually and also combined in various ways. This approach departs from the more <b>common</b> <b>page</b> template model.|$|E
5000|$|Wikipedia {{receives}} between 25,000 and 60,000 page requests per second, {{depending on}} time of day. [...] page requests are first passed to a front-end layer of Squid caching servers. Further statistics, {{based on a}} publicly available 3-month Wikipedia access trace, are available. Requests that cannot be served from the Squid cache are sent to load-balancing servers running the Linux Virtual Server software, which in turn pass them {{to one of the}} Apache web servers for page rendering from the database. The web servers deliver pages as requested, performing page rendering for all the language editions of Wikipedia. To increase speed further, rendered pages are cached in a distributed memory cache until invalidated, allowing page rendering to be skipped entirely for most <b>common</b> <b>page</b> accesses.|$|E
50|$|Pictures of Glen Echo Park are {{available}} on Wikimedia <b>Commons</b> <b>page</b> on Glen Echo.|$|R
50|$|Taylor {{became known}} for hosting an annual hockey {{game between the}} Members of Parliament and the House of <b>Commons</b> <b>Pages.</b>|$|R
5000|$|... b) Not have {{previous}} {{experience as a}} Page on Parliament Hill (such as experience in the Canadian House of <b>Commons</b> <b>Page</b> Program); ...|$|R
40|$|This paper {{presents}} an automated approach {{to detect and}} partition data objects or product description from complex Web pages. First, we derive the <b>common</b> <b>page</b> structure by comparing similar pages, and then identify data region covering the descriptions of data objects. Second, we partition the nodes belonging to different data objects in the data region and construct the selfexplainable XML output files. The experiments indicate that our technique is effective. 1...|$|E
40|$|Campus: Men with Integrity tackles {{issues of}} sexual assault and rape, page 3. Politics: Republicans have squandered their {{political}} victory, page 2. Culture: Eli Manning is not Pope John Paul II: Hero worship gone too far, page 3. Religion: What do genetics, a cow, and the anti-Christ have in <b>common?</b> <b>Page</b> 4. On the web: Go to www. smu. edu/honors/hilltopics to read all of the stories in this issue and more. You can also submit your thoughts to hilltopics@hotmail. com...|$|E
40|$|Abstract: Large {{scientific}} applications which rely on highly parallel computational analysis require highly parallel data access. We {{describe an}} object-oriented, scientific database system that achieves nearly linear scale-up over large, million object data sets. Of primary importance are those features which seem {{central to the}} development of this, or any other parallel database system. These include techniques of object distribution, of multi-operator parallelism, and of indirect object referencing. It also appears to require a query server architecture instead of the more <b>common</b> <b>page</b> server configurations. 1...|$|E
5000|$|A House of <b>Commons</b> <b>Page</b> is a non-partisan {{employee}} of the Canadian House of Commons. They perform both ceremonial and administrative duties including: ...|$|R
5000|$|... #Caption: Example at our Sisterproject Commons: View {{the photo}} of Nobel Laureates 2015 (press conference Stockholm) in <b>Commons</b> <b>page</b> December 2015 (no mouseovers in Wikipedia at the moment ...).|$|R
5000|$|... #Caption: CIMRM 1083: Tauroctony {{relief from}} the [...] "Heidenfeld" [...] Mithraeum (Mithraeum I, Heddernheim, Germany), now in Wiesbaden. An {{extensive}} description is available at this image's Wikipedia <b>commons</b> <b>page.</b>|$|R
40|$|Content-related {{metadata}} {{plays an}} important role in the effort of developing intelligent web applications. One of the most established form of providing contentrelated metadata is the assignment of web-pages to content categories. We describe the Spectacle system for classifying individual web pages on the basis of their syntactic structure. This classification requires the specification of classification rules associating <b>common</b> <b>page</b> structures with predefined classes. In this paper, we propose an approach for the automatic acquisition of these classification rules using techniques from inductive logic programming and describe experiments in applying the approach to an existing web-based information system...|$|E
40|$|Licensed under Creative <b>Common</b> <b>Page</b> 2 The {{purpose of}} this paper was to {{evaluate}} the role that performance-based rewards plays in productivity in Ghana. The study adopted both qualitative (case study) and quantitative methods respectively. Second cycle institutions were selected to gather data, which was acquired from answers obtained from our administered questionnaire and also through interviews. The population of the survey constituted the management and non-management staff and the teaching staff of, New Juabeng High, Accra Academy and Tema High School. Hypotheses of the study were analyzed using correlation and regression. Results of the study showed that there are high positive correlation between the constructs of performance-based rewards and productivity...|$|E
40|$|This paper {{deals with}} {{techniques}} {{for reducing the}} amount of work that needs to be redone each semester when one prepares an existing course Web site for a new class. The key concept is algorithmic generation of <b>common</b> <b>page</b> elements while still allowing full control over page content via WYSIWYG tools like Microsoft FrontPage and Macromedia Dreamweaver. The paper explores both client- and server-side techniques and discusses their advantages and disadvantages. The most advanced techniques are those that encode control information in XML rather than HTML or JavaScript and apply that information on the server side using XSL and JavaServer Pages. The paper also touches on course organization techniques that might involve students in the creation and maintenance of course Web sites, thereby fostering more studentcentered learning...|$|E
50|$|Growing {{up in the}} Ottawa-Hull area, {{he served}} as a House of <b>Commons</b> <b>page,</b> then went on to work as a {{journalist}} for the Montreal Gazette and several other newspapers.|$|R
50|$|In {{addition}} to colored fibers in all <b>common</b> <b>pages,</b> Cuban passports feature a UV-reaction-based {{mark of the}} Cuban flag and the words República de Cuba (Spanish for Republic of Cuba) on the front endpaper.|$|R
50|$|Proper People Watching {{should follow}} Expectation of Privacy principles, as well not be {{unethical}} or degrading the subjects. The legislation concerning non-consented pictures of people varies between countries and {{should also be}} observed, such as with Wikipedia's own <b>Commons</b> <b>page.</b>|$|R
40|$|This paper {{discusses}} {{the use of}} character images to determine the parameters of an image degradation model. The acute angles in character images provide information used to find the model parameters. Three experiments are conducted {{to evaluate the use}} of characters. In the first experiment, large quantities of corners from character images are used to investigate how their contribution affects the mean and the standard deviation of the parameter estimators. In the second experiment, we focus on the relationship between the angles of the corners used in estimation and the estimation results. In the last experiment, we examine how likely the text in a <b>common</b> <b>page</b> would offer a reasonable estimation result compared to the results from experiments 1 and 2...|$|E
40|$|Abstract: This paper {{deals with}} {{techniques}} {{for reducing the}} amount of work that needs to be redone each semester when one prepares an existing course Web site for a new class. The key concept is algorithmic generation of <b>common</b> <b>page</b> elements while still allowing full control over page content via WYSIWYG tools like Microsoft FrontPage and Macromedia Dreamweaver. The paper explores both client- and server-side techniques and discusses their advantages and disadvantages. The most advanced techniques are those that encode control information in XML rather than HTML or JavaScript and apply that information on the server side using XSL and JavaServer Pages. The paper also touches on course organization techniques that might involve students in the creation and maintenance of course Web sites, thereby fostering more studentcentered learning...|$|E
40|$|Abstract. Extracting and {{processing}} information from web pages {{is an important}} task in many areas like constructing search engines, information retrieval, and data mining from the Web. Common approach in the extraction process is to represent a page as a “bag of words ” and then to perform an additional processing on such a flat representation. In this {{paper we propose a}} new, hierarchical representation that includes the browser screen coordinates for every HTML object in a page. Using a spatial information one is able to define heuristics for recognition of <b>common</b> <b>page</b> areas such as a header, left and right menu, footer and the center of a page. We show in initial experiments that using our heuristics, defined objects are recognized properly in 73 % of cases. ...|$|E
5000|$|... #Caption: Cordova Bay {{lies between}} Prince of Wales Island {{on the east}} and Dall Island, Long Island, and Sukkwan Islands on the west. US Coast Survey chart detail. Click through to the <b>Commons</b> <b>page</b> to view {{annotations}} including village sites.|$|R
50|$|Prior to {{operating}} his {{own business}} and eventually running for political office, McLarnon pursued his higher education at Carleton University (Ottawa) and the British Columbia Institute of Technology (Vancouver). While at Carleton University, McLarnon served in the House of <b>Commons</b> <b>Page</b> Program.|$|R
5000|$|For the <b>Common</b> Good.http://www.ucc.org/synod/resolutions/gs25-5.pdfMinutes <b>Page</b> 40 ...|$|R
40|$|Ntiamoah, Abrokwah, Agyei-Sakyi, Opoku & Siaw Licensed under Creative <b>Common</b> <b>Page</b> 2 The core {{objective}} {{of this study is}} to evaluate the impact of recruitment & selection tool on performance of the Ghana Revenue Authority in the Greater Accra region. For that purpose, data were collected by structured questionnaire. Total 160 respondents were chosen from the district offices of the Ghana Revenue Authority in Greater Accra region of Ghana by convenience sampling technique. The condition was that all of the respondents were working in different positions of selected district in Ghana except the human resource department. Data were analyzed by using software SPSS- 20. 0 version by adopting the statistical techniques, correlation and regression. Results of the study showed that there are high positive correlation between the constructs of performance-based rewards and productivity. And also the hypothesis established for this study was supported by the researchers ’ findings...|$|E
40|$|CCAM is {{an access}} method for general networks. It uses {{connectivity}} clustering. The nodes {{of the network}} are assigned to disk pages via the graph partitioning approach to maximize the CRR, i. e., the chances that a pair of connected nodes are allocated to a <b>common</b> <b>page</b> of the file. CCAM supports the operations of insert, delete, create, and find {{as well as the}} new operations, get-A-successor and get-successors, which retrieve one or all successors of a node to facilitate aggregate computations on networks. CCAM includes methods for static clustering, as well as dynamic incremental reclustering, to maintain high CRR, in the face of updates without incurring high overheads. Experimental analysis indicates that CCAM can outperform many other access methods for network operations. 1 Introduction Aggregate queries on networks arise in many important database applications, including transportation planning, air traffic control, electric and gas utilities, telephone networks, sewer maintenan [...] ...|$|E
40|$|Extracting and {{processing}} information from web pages {{is an important}} task in many areas like constructing search engines, information retrieval, and data mining from the Web. Common approach in the extraction process is to represent a page as a "bag of words" and then to perform additional processing on such a flat representation. In this {{paper we propose a}} new, hierarchical representation that includes browser screen coordinates for every HTML object in a page. Such spatial information allows the definition of heuristics for recognition of <b>common</b> <b>page</b> areas such as header, left and right menu, footer and center of a page. We show a preliminary experiment where our heuristics are able to correctly recognize objects in 73 % of cases. Finally, we show that a Naive Bayes classifier, taking into account the proposed representation, clearly outperforms the same classifier using only information about the content of documents...|$|E
50|$|India {{does not}} {{have a long history of}} {{publishing}} school yearbooks. However, top Business schools and Engineering colleges publish custom yearbooks. This is typically created by the final year students of the batch. A yearbook or a memory book would consist of testimonials and <b>common</b> <b>pages</b> such as Directors address and events, festivals picture collages.|$|R
25|$|The {{familiar}} tones {{that called}} Station 51 into service were initiated by dispatch using a Motorola Quik Call I unit, a radio listening on a <b>common</b> <b>paging</b> frequency {{for a pair}} of special audio tones assigned to that station. For a large incident, one could often hear many sets of tones calling many stations, but only a specific pair would sound the buzzer for Station 51.|$|R
30|$|The annual {{population}} {{estimates were}} obtained from annual population estimates from the ABS creative <b>commons</b> web <b>page.</b>|$|R
40|$|Given {{a set of}} {{operators}} and a spatio-temporal network, {{the goal of the}} Storing Spatio-Temporal Networks (SSTN) problem is to produce an efficient data storage method that minimizes disk I/O access costs. Storing and accessing spatiotemporal networks is increasingly important in many societal applications such as transportation management and emergency planning. This problem is challenging due to strains on traditional adjacency list representations when storing temporal attribute values from the sizable increase in length of the time-series. Current approaches for the SSTN problem focus on orthogonal partitioning (e. g., snapshot, longitudinal, etc.), which may produce excessive I/O costs when performing traversal-based spatio-temporal network queries (e. g., route evaluation, arrival time prediction, etc) due to the desired nodes not being allocated to a <b>common</b> <b>page.</b> We propose a Lagrangian-Connectivity Partitioning (LCP) technique to efficiently store and access spatio-temporal networks that utilizes the interaction between nodes and edges in a network. Experimental evaluation using the Minneapolis, MN road network showed that LCP outperforms traditional orthogonal approaches...|$|E
40|$|Current Spatial Database Management Systems (SDBMS) provide {{efficient}} access {{methods and}} operators for point and range queries over collections of spatial points, line segments, and polygons. However, {{it is not}} clear if existing spatial access methods can efficiently support network computations which traverse linesegments in a spatial network based on connectivity rather than geographic proximity. The expected I/O cost for many network operations can be reduced by maximizing the Weighted Connectivity Residue Ratio (WCRR), i. e., the chance that a pair of connected nodes that {{are more likely to be}} accessed together are allocated to a <b>common</b> <b>page</b> of the file. CCAM is an access method for general networks that uses connectivity clustering. CCAM supports the operations of insert, delete, create, and find as well as the new operations, get-A-successor and get-successors, which retrieve one or all successors of a node to facilitate aggregate computations on networks. The nodes of th [...] ...|$|E
40|$|Licensed under Creative <b>Common</b> <b>Page</b> 2 This study {{aimed to}} access the impact of small and {{medium-sized}} businesses to Ghana’s economic growth using the New Juabeng Municipal Assembly as a case study. This study aimed at filling the gap by gathering relevant data on the roles of Small and Medium-sized Enterprises (SMEs) to the economy. Primary data were obtained through the administering of questionnaires to 200 respondents operating within the SME businesses. Data collected were coded and analyzed using the Statistical Package for Social Sciences (SPSS) analytical tool and subject to both descriptive and inferential statistics. Multiple regression analysis was carried out to see if any, relationship existed between the dependent variables, employment growth and increase in income and the independent variables, higher education levels, and support from government and NGOs. The findings of the study showed that SMEs contribute immensely to job creation, especially to people with less formal education in the rural economy. With regards to income generation, the study showed that SMEs served as an important catalyst in th...|$|E
5000|$|Voltz {{focused on}} {{illustrations}} of battles and other historical events. He depicted events {{of his own}} time - the Napoleonic Wars since 1805, the German War of Liberation against Napoleon, and later the Greek War of Independence, {{as well as from}} earlier history such as [...] "Luther at the Diet of Worms". In 1828 he made a series of drawings on Children's games (see linked Wikimedia <b>Commons</b> <b>page).</b>|$|R
50|$|Fifty-five preprints {{were posted}} {{in the first}} 15 days of Nature Precedings. Of those, 26 were {{submitted}} as manuscripts and 29 as posters/presentations. Corresponding numbers for the first 50 days were 89, 48, and 41, {{and for the first}} six months, 303, 227, and 76. About 500 and 650 preprints were published during the first and second years, respectively. The growth of the repository can be tracked graphically on the Scientific <b>Commons</b> <b>page</b> for Nature Precedings.|$|R
50|$|The Canadian House of <b>Commons</b> <b>Page</b> Program employs {{part-time}} first-year {{university students}} who work roughly 15 {{hours a week}} and are paid approximately $12,000 (CDN) for a one-year term. They perform both ceremonial and administrative duties and participate in enrichment activities such as meetings with MPs and government leaders. They also meet with student groups to explain {{the workings of the}} House of Commons and their duties as Pages. The Canadian Senate Page Program is similar.|$|R
