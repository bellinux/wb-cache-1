2839|10000|Public
25|$|The Ethiopian Jews' {{autosomal}} DNA {{has been}} examined {{in a comprehensive}} study by Tishkoff et al. (2009) on the genetic affiliations of various populations in Africa. According to Bayesian <b>clustering</b> <b>analysis,</b> the Beta Israel generally grouped with other Afroasiatic-speaking populations inhabiting the Horn of Africa, North Africa and the Sahara.|$|E
25|$|There {{is great}} {{flexibility}} {{in the choice of}} statistical test (and thus the questions that an experiment can be designed to answer), and common choices include the Student's t test or linear regression. An important consideration with SPM, however, is that the large number of comparisons requires one to control the false positive rate with a more stringent significance threshold. This can be done either by modifying the initial statistical test to decrease the α value so as to make it harder for a particular voxel to exhibit a significant difference, or by modifying the <b>clustering</b> <b>analysis</b> in the second step by only considering a brain region's activation to be significant if it contains a certain number of voxels that exhibit a statistical difference.|$|E
5000|$|... #Caption: Flowchart of a Usual <b>Clustering</b> <b>Analysis</b> for Structure-Based Drug Design ...|$|E
30|$|<b>Cluster</b> <b>analysis</b> is {{classified}} into two types, Hierarchical <b>cluster</b> <b>analysis</b> and Non-hierarchical <b>cluster</b> <b>analysis.</b>|$|R
40|$|Abstract: The {{method of}} the {{objective}} <b>cluster</b> <b>analysis</b> is appraised by analyzing its algorithm steps. A new consistency criterion is proposed and the method of the GMDH <b>cluster</b> <b>analysis</b> is established. We show, through theoretical analysis and demonstration comparisons, that the GMDH <b>cluster</b> <b>analysis</b> is the further development {{of the objective}} <b>cluster</b> <b>analysis...</b>|$|R
40|$|Handbook of <b>Cluster</b> <b>Analysis</b> {{provides}} a comprehensive and unified {{account of the}} main research developments in <b>cluster</b> <b>analysis.</b> Written by active, distinguished researchers in this area, the book helps readers make informed choices of the most suitable clustering approach for their problem and make better use of existing <b>cluster</b> <b>analysis</b> tools. The book is organized according to the traditional core approaches to <b>cluster</b> <b>analysis,</b> from the origins to recent developments. After an overview of approaches and a quick journey through the history of <b>cluster</b> <b>analysis,</b> the book focuses on the four major approaches to <b>cluster</b> <b>analysis.</b> These approaches include methods for optimizing an objective function that describes how well data is grouped around centroids, dissimilarity-based methods, mixture models and partitioning models, and clustering methods inspired by nonparametric density estimation. The book also describes additional approaches to <b>cluster</b> <b>analysis,</b> including constrained and semi-supervised clustering, and explores other relevant issues, such as {{evaluating the quality of}} a cluster. This handbook is accessible to readers from various disciplines, reflecting the interdisciplinary nature of <b>cluster</b> <b>analysis.</b> For those already experienced with <b>cluster</b> <b>analysis,</b> the book offers a broad and structured overview. For newcomers to the field, it presents an introduction to key issues. For researchers who are temporarily or marginally involved with <b>cluster</b> <b>analysis</b> problems, the book gives enough algorithmic and practical details to facilitate working knowledge of specific clustering areas...|$|R
5000|$|Cluster {{analysis}} (K-means <b>clustering</b> <b>analysis</b> (single and multi pass), Fuzzy (C-means) algorithm, agglomerative hierarchical clustering) ...|$|E
5000|$|Won Asian Marketing Effectiveness & Strategy Award 2014 (AMES), Category: Data Mining - Audience Association and <b>Clustering</b> <b>Analysis</b> ...|$|E
5000|$|Lee, R. C. T., 1981, <b>Clustering</b> <b>Analysis</b> and its Applications, in “Advances in Information System Science”, (edited by J. T. Tou), Plenum Press, N.Y., pp. 169-287.|$|E
50|$|Tryon {{was also}} {{a pioneer in the}} use of <b>cluster</b> <b>analysis</b> to analyze data. His 1939 {{monogram}} <b>Cluster</b> <b>Analysis</b> {{was one of the first}} works to outline a <b>cluster</b> <b>analysis</b> method, and he continued to develop this method over the course of his career.|$|R
40|$|<b>Cluster</b> <b>Analysis</b> is {{a multivariate}} method in statistics. Agglomerative Hierarchical <b>Cluster</b> <b>Analysis</b> {{is one of}} {{approaches}} in <b>Cluster</b> <b>Analysis.</b> There are two linkage methods in Agglomerative Hierarchical <b>Cluster</b> <b>Analysis</b> which are Single Linkage and Complete Linkage. The {{purpose of this study}} is to compare between Single Linkage and Complete Linkage in Agglomerative Hierarchical <b>Cluster</b> <b>Analysis.</b> The comparison of performances between these linkage methods was shown by using Kruskal-Wallis test. The result of the comparison used for segmenting tourists of Kapas Island. The statistical software SPSS has been applied to analyze data of this research. The result from Kruskal-Wallis test shows Complete Linkage is more useful in identifying tourists segments.   Keywords : Agglomerative Hierarchical <b>Cluster</b> <b>Analysis,</b> Single Linkage, Complete Linkage, Kruskal-Wallis test, tourists</p...|$|R
40|$|One of {{functions}} of multivariate analysis is to group data. Multivariate analysis {{often used in}} grouping  data are <b>cluster</b> <b>analysis</b> and biplot analysis. In this paper, a comparative analysis will be made between <b>clusters</b> <b>analysis</b> and biplot analysis  for grouping the data. Technique used in the <b>cluster</b> <b>analysis</b> is k-mean method  and biplot analysis used two-dimensional display.   The results ware that biplot analysis produces are better in grouping accuracy than <b>clusters</b> <b>analysis.</b> But in general, biplot analysis {{can not be said}} to be better than <b>clusters</b> <b>analysis</b> in grouping the data and vice versa. </p...|$|R
5000|$|Narasimha Rao. G, Jagadeeswara Rao, P. 2014. A <b>Clustering</b> <b>Analysis</b> for Heart Failure Alert System Using RFID and GPS. ICT and Critical Infrastructure: Proceedings of the 48th Annual Convention of Computer Society of India- Vol-248, SPRINGER, Advances in Intelligent Systems and Computing Volume 248:729-737.|$|E
50|$|The Ethiopian Jews' {{autosomal}} DNA {{has been}} examined {{in a comprehensive}} study by Tishkoff et al. (2009) on the genetic affiliations of various populations in Africa. According to Bayesian <b>clustering</b> <b>analysis,</b> the Beta Israel generally grouped with other Afroasiatic-speaking populations inhabiting the Horn of Africa, North Africa and the Sahara.|$|E
5000|$|Tools: A {{wide variety}} of {{analysis}} and visualization Tools are available in ArrayTrack, including {{but are not limited}} to: statistical analysis Tools including T-Test, ANOVA, and SAM-Test; unsupervised pattern discovery Tools including Hierarchical <b>Clustering</b> <b>Analysis</b> and Principal Component Analysis; and model prediction Tools including K-Nearest Neighbors and Linear Discriminant Analysis. Although ArrayTrack's Tools are designed to accommodate imported data, they are also compatible with external data.|$|E
40|$|In {{this paper}} we survey the main {{approaches}} to fuzzy shell <b>cluster</b> <b>analysis</b> which {{is simply a}} generalization of fuzzy <b>cluster</b> <b>analysis</b> to shell like clusters, i. e. clusters that lie in nonlinear subspaces. Therefore we introduce the main principles of fuzzy <b>cluster</b> <b>analysis</b> first. In the following we present some fuzzy shell clustering algorithms. In many applications {{it is necessary to}} determine the number of clusters as well as the classification of the data set. Subsequently therefore we review the main ideas of unsupervised fuzzy shell <b>cluster</b> <b>analysis.</b> Finally we present an application of unsupervised fuzzy shell <b>cluster</b> <b>analysis</b> in computer vision...|$|R
50|$|Another paper {{published}} in 2012 uses <b>cluster</b> <b>analysis</b> <b>cluster</b> <b>analysis</b> and suggested once more {{that they may}} have detected biological activity.|$|R
3000|$|The {{automated}} {{grouping of}} the pixels in an image {{having the same}} characteristic bands is called spatial clustering. This is done by considering two important criteria: (i) pixels in the same group are as similar as possible and (ii) pixels in different groups are as dissimilar as possible. Various multivariate methods (unsupervised) such as K-means <b>Cluster</b> <b>Analysis</b> (KMCA), Agglomerative Hierarchical <b>Cluster</b> <b>Analysis</b> (AHCA), Principal Component Analysis (PCA), Fuzzy C Means <b>Cluster</b> <b>Analysis</b> (FCMCA), Vertex Component Analysis (VCA), and Divisive Correlation <b>Cluster</b> <b>Analysis</b> (DCCA) are being widely used for <b>cluster</b> <b>analysis</b> of Raman and IR images [45, 81, 82]. Spatial clustering algorithms {{can be divided into}} two main categories: [...]...|$|R
50|$|In neuroscience, PCA is {{also used}} to discern the {{identity}} of a neuron from the shape of its action potential. Spike sorting is an important procedure because extracellular recording techniques often pick up signals from more than one neuron. In spike sorting, one first uses PCA to reduce the dimensionality of the space of action potential waveforms, and then performs <b>clustering</b> <b>analysis</b> to associate specific action potentials with individual neurons.|$|E
5000|$|The pbdR {{built on}} pbdMPI uses SPMD {{parallelism}} where every processor is considered as worker and owns parts of data. The SPMD parallelism introduced in mid 1980 is particularly efficient in homogeneous computing environments for large data, for example, performing singular value decomposition {{on a large}} matrix, or performing <b>clustering</b> <b>analysis</b> on high-dimensional large data. On the other hand, there is no restriction to use manager/workers parallelism in SPMD parallelism environment.|$|E
50|$|A {{citation}} graph having vertices {{representing the}} papers in the 1994-2000 Graph Drawing symposia and having edges representing citations between these papers was made available {{as part of the}} graph drawing contest associated with the 2001 symposium. The largest connected component of this graph consists of 249 vertices and 642 edges; <b>clustering</b> <b>analysis</b> reveals several prominent subtopics within graph drawing that are more tightly connected, including three-dimensional graph drawing and orthogonal graph drawing.|$|E
40|$|This {{bachelor}} {{thesis is}} engaged in problematics of automatic <b>cluster</b> <b>analysis</b> for ECG sinals. This bachelor thesis contains theory of pathology in cardiac rhythm and problematics of <b>cluster</b> <b>analysis.</b> Based on a gained knowledge, set of symptoms is made, which are used for <b>cluster</b> <b>analysis</b> using MATLAB interface and which results are evaluated...|$|R
30|$|Whereas, <b>cluster</b> <b>analysis</b> allowed {{researcher}} to make grouping base on objects or distance (Hair et al., 2010). The patterns of relationships among surface, deep and achieving approaches were examined using non-hierarchical k-means <b>cluster</b> <b>analysis.</b> K-means <b>cluster</b> <b>analysis</b> has proved effective in minimizing differences within, and maximizing differences between, the clusters (Meyer and Shanahan, 2003).|$|R
40|$|The {{focus of}} this paper is on {{connections}} between lot sizing and <b>cluster</b> <b>analysis.</b> The similarities between integer programming formulations for minimizing the total within-clusters sum of squares in <b>cluster</b> <b>analysis,</b> and the single item uncapacitated lot sizing problem, are discussed. The development of heuristics in <b>cluster</b> <b>analysis</b> is expected to benefit from this comparison...|$|R
5000|$|In a {{response}} to Serre and Pääbo (2004), Rosenberg et al. (2005) maintain that their <b>clustering</b> <b>analysis</b> is robust. Additionally, they agree with Serre and Pääbo that membership of multiple clusters {{can be interpreted as}} evidence for clinality (isolation by distance), though they also comment that this may also be due to admixture between neighbouring groups (small island model). Thirdly they comment that evidence of clusterdness is not evidence for any concepts of [...] "biological race".|$|E
5000|$|In contrast, {{post-hoc}} segmentation {{makes no}} {{assumptions about the}} optimal theoretical framework. Instead, the analyst's role {{is to determine the}} segments that are the most meaningful for a given marketing problem or situation. In this approach, the empirical data drives the segmentation selection. Analysts typically employ some type of <b>clustering</b> <b>analysis</b> or structural equation modeling to identify segments within the data. The figure alongside illustrates how segments might be formed using clustering, however note that this diagram only uses two variables, while in practice clustering employs a large number of variables. Post-hoc segmentation relies on access to rich data sets, usually with {{a very large number of}} cases and uses sophisticated algorithms to identify segments.|$|E
50|$|There {{is great}} {{flexibility}} {{in the choice of}} statistical test (and thus the questions that an experiment can be designed to answer), and common choices include the Student's t test or linear regression. An important consideration with SPM, however, is that the large number of comparisons requires one to control the false positive rate with a more stringent significance threshold. This can be done either by modifying the initial statistical test to decrease the α value so as to make it harder for a particular voxel to exhibit a significant difference, or by modifying the <b>clustering</b> <b>analysis</b> in the second step by only considering a brain region's activation to be significant if it contains a certain number of voxels that exhibit a statistical difference.|$|E
40|$|<b>Cluster</b> <b>Analysis</b> for Applications {{deals with}} methods and various {{applications}} of <b>cluster</b> <b>analysis.</b> Topics covered range from variables and scales to measures of association among variables and among data units. Conceptual problems in <b>cluster</b> <b>analysis</b> are discussed, along with hierarchical and non-hierarchical clustering methods. The necessary elements of data <b>analysis,</b> statistics, <b>cluster</b> <b>analysis,</b> and computer implementation are integrated vertically {{to cover the}} complete path from raw data to a finished analysis. Comprised of 10 chapters, this book begins with {{an introduction to the}} subject...|$|R
40|$|AbstractA <b>cluster</b> <b>analysis</b> classifies {{objects on}} the basis that {{similarity}} of objects in cluster is as high as possible, and simultaneously, similarity of cluster is as low as possible. This article deals with the comparation of <b>cluster</b> <b>analysis</b> methods and of measure of objects similarity (dissimilarity). <b>Cluster</b> <b>analysis</b> is a multidimensional method of the experimental modeling...|$|R
40|$|Choice of {{variables}} {{is the one}} of the most important steps in a <b>cluster</b> <b>analysis.</b> Variables used in applied clustering should be selected and weighted carefully. In <b>cluster</b> <b>analysis</b> we should include only those variables that are believed to help discriminate the data. In article: – main aspects of selection and weighting {{of variables}} to cluster were characterised, – point at limitations of variable selection for <b>cluster</b> <b>analysis</b> based on data generated from normal distribution, – main approaches to variable selection and weighting for <b>cluster</b> <b>analysis</b> were discussed. Marek Walesia...|$|R
50|$|Kernel-based {{functions}} are managed through a common kernel layer. In particular, the user can choose between supplying the data or a precomputed kernel in input space. Linear, polynomial, Gaussian, exponential and sigmoid kernels are available as default choices, and custom kernels {{can be defined}} as well. Many classification and regression algorithms are endowed with an internal feature ranking procedure: in alternative, mlpy implements the I-Relief algorithm. Recursive feature elimination (RFE) for linear classifiers and the KFDA-RFE algorithm are available for feature selection. Methods for feature list analysis (for example the Canberra stability indicator), data resampling and error evaluation are provided, together with different <b>clustering</b> <b>analysis</b> methods (Hierarchical, Memory-saving Hierarchical, k-means). Finally, dedicatedsubmodules are included for longitudinal data analysis through wavelet transform (Continuous, Discrete and Undecimated) and dynamic programming algorithms (Dynamic Time Warping and variants).|$|E
50|$|These studies {{generally}} {{make use}} of multiple fluency lists {{in order to make}} estimates of the semantic distance between pairs of concepts. Techniques such as multidimensional scaling and hierarchical clustering can then be used to visualize the semantic organization of the conceptual space. Such studies have generally found that semantic memory, at least as reflected by this test, has a schematic, or script-based, organization.whose core aspects may remain stable throughout life.For instance, the figure on the right shows a hierarchical <b>clustering</b> <b>analysis</b> of animal semantic fluency data from 55 British schoolchildren aged 7-8. The analysis reveals that children have schematic organization for this category according to which animals are grouped by where they are most commonly seen (on the farm, at home, in the ocean, at the zoo). Children, adults, and even zoology PhD candidates, all show this same tendency to cluster animals according to the environmental context in which they are observed.|$|E
50|$|Once {{immunostaining}} {{has been}} performed protein expression must then be quantified. The signal levels {{can be obtained}} by using the reflective mode of an ordinary optical flatbed scanner if a colorimetric detection technique is used or by laser scanning, such as with a TECAN LS system, if fluorescent techniques are used. Two programs available online (P-SCAN and ProteinScan) can then be used to convert the scanned image into numerical values. These programs quantify signal intensities at each spot and use a dose interpolation algorithm (DI25) to compute a single normalized protein expression level value for each sample. Normalization is necessary to account for differences in total protein concentration between each sample and so that antibody staining can be directly compared between samples. This can be achieved by performing an experiment in parallel in which total proteins are stained by colloidal gold total protein staining or Sypro Ruby total protein staining. When multiple RPMAs are analyzed, the signal intensity values can be displayed as a heat map, allowing for Bayesian <b>clustering</b> <b>analysis</b> and profiling of signaling pathways. An optimal software tool, custom designed for RPMAs is called Microvigene, by Vigene Tech, Inc.|$|E
40|$|AbstractObjective: To {{evaluate}} the typing power of <b>cluster</b> <b>analysis</b> of antimicrobial susceptibility. Methods: Results of {{pulsed-field gel electrophoresis}} in 71 strains of meth icillin-resistant Staphylococcus aureus were compared with <b>cluster</b> <b>analysis</b> of the diameter of growth inhibition in 11 drugs. Subjects were a consecutive series of patients (n = 71) from the wards and outpatient units of a community teaching hospital. Results: The <b>cluster</b> <b>analysis</b> took 2 to 3 seconds once the data were entered into a computer. The sensitivity, specificity, and accuracy of the <b>cluster</b> <b>analysis</b> were 76. 3 %, 58. 3 %, and 73. 2 %, respectively, using genotyping as the reference. Conclusions: The <b>cluster</b> <b>analysis</b> offered real-time epidemiologic data at minimal cost and labor, warranting its cost-effective role...|$|R
40|$|The paper {{deals with}} <b>cluster</b> <b>analysis</b> and {{comparison}} of <b>clustering</b> methods. <b>Cluster</b> <b>analysis</b> belongs to multivariate statistical methods. <b>Cluster</b> <b>analysis</b> {{is defined as}} general logical technique, procedure, which allows clustering varia ble objects into groups - clusters {{on the basis of}} similarity or dissimilarity. <b>Cluster</b> <b>analysis</b> involves computational procedures, of which purpose is to reduce a set of data on several relatively homogenous groups - clusters, while the condition of reduction is maximal and simultaneously minimal similarity of clusters. Similarity of objects is studied by the degree of similarity (correlation coefficient and association coefficient) or the degree of dissimilarity - degree of distance (distance coefficient). Methods of <b>cluster</b> <b>analysis</b> are on the basis of clustering classified as hierarchical or non-hierarchical methods. </p...|$|R
40|$|The {{purpose of}} this study is to apply {{vertical}} <b>cluster</b> <b>analysis</b> method to interpret and analyze habituation of the leg movement response, to different odors, in fruit flies. In most cases <b>cluster</b> <b>analysis</b> methods are used to analyze data sets, which can be classified into categories. We define this type of method as horizontal <b>cluster</b> <b>analysis</b> method. In this study, instead of dividing the data into categories, we divide the data based on different periods of time. We define this method as a vertical <b>cluster</b> <b>analysis</b> method. Here we apply vertical <b>cluster</b> <b>analysis</b> method to evaluate the habituation of leg movement responses of fruit fly, Drosophila melanogaster. The vertical cluster analyses helped us to identify hidden features of fruit fly behavior...|$|R
