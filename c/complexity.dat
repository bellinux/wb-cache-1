10000|10000|Public
5|$|As {{the number}} of {{cavities}} {{play a vital role}} in moulding costs, so does the <b>complexity</b> of the part's design. <b>Complexity</b> can be incorporated into many factors such as surface finishing, tolerance requirements, internal or external threads, fine detailing or {{the number of}} undercuts that may be incorporated.|$|E
5|$|Evolution {{also does}} not require that organisms become more complex. Although the history of life shows an {{apparent}} trend towards the evolution of biological complexity; {{there is a question}} if this appearance of increased <b>complexity</b> is real, or if it comes from neglecting the fact that the majority of life on Earth has always consisted of prokaryotes. In this view, <b>complexity</b> is not a necessary consequence of evolution, but that specific circumstances of evolution on Earth frequently made greater <b>complexity</b> advantageous and thus naturally selected for. Depending on the situation, organisms' <b>complexity</b> can either increase, decrease, or stay the same, and all three of these trends have been observed in evolution.|$|E
5|$|It was the {{aesthetic}} <b>complexity</b> of insects that led Nabokov to reject natural selection.|$|E
30|$|The <b>complexities</b> {{of the direct}}, RBS and UOV-R {{attacks were}} {{discussed}} by Petzoldt et al. [16], and we follow their data regarding the <b>complexities</b> of these attacks. In particular, the <b>complexities</b> of the direct and UOV-R attacks are equivalent.|$|R
40|$|In this paper, {{we study}} the state <b>complexities</b> of union and {{intersection}} combined with star and reversal, respectively. We obtain the state <b>complexities</b> of these combined operations on regular languages {{and show that}} they are less than the mathematical composition of the state <b>complexities</b> of their individual participating operations. Comment: 16 pages, 4 figure...|$|R
40|$|This project {{discusses}} the <b>complexities</b> and constraint for women's participation in 'Prevention of mother to child programmes' in South Africa. These <b>complexities</b> are identified {{in both the}} national level, a community level and an interpersonel psycological level. While identifying we analyse these from an empowerment approach and suggest how empowerment in a theoretical manner could mitigate and reduce the <b>complexities...</b>|$|R
5|$|Much of Lewis' {{subsequent}} research {{concerned the}} computational <b>complexity</b> {{of problems in}} mathematical logic.|$|E
5|$|Natural {{simplicity}} as {{superior to}} technological <b>complexity.</b>|$|E
5|$|Scholars {{agree that}} there are no {{completely}} reliable methods of determining the exact chronology of musical instruments across cultures. Comparing and organizing instruments based on their <b>complexity</b> is misleading, since advancements in musical instruments have sometimes reduced <b>complexity.</b> For example, construction of early slit drums involved felling and hollowing out large trees; later slit drums were made by opening bamboo stalks, a much simpler task.|$|E
30|$|We {{have also}} {{compared}} the <b>complexities</b> {{of the proposed}} methods with those of M-CLMS when M= 2, 4, 8, and D-CLMS schemes in [49]. Note that the <b>complexities</b> of M-CLMS and D-CLMS schemes are 3 MN+ 5 M+ 1 and 10 N+ 3 respectively and that these <b>complexities</b> also increase by an amount of 2 MN+ 5 M−N+ 3 when the transfer and momentum terms are implemented. In these figures, {{it can be seen}} that the <b>complexities</b> of the M-CLMS and D-CLMS schemes are advantageous comparing to the R-CMLF and D-CMLF schemes mainly due to the well known simplicity of LMS filters, and this advantage becomes larger with increasing number of combining filters (M). However, it can be also noted that the <b>complexities</b> of transfer and momentum terms are comparable to those of the core M-CLMS and D-CLMS schemes, and therefore, the addition of transfer and momentum terms influences the <b>complexities</b> of M-CLMS and D-CLMS schemes more noticeably.|$|R
5000|$|A {{suggested}} {{approach to}} supposedly minimize the <b>complexities</b> of schema evolution {{is to use}} a so-called [...] "schema-agnostic" [...] NoSQL database which allegedly reduces the <b>complexities</b> of modeling bitemporal data.|$|R
5000|$|... <b>compLexity's</b> Dota 2 {{team was}} {{not invited to}} The International 2015 but {{qualified}} in the regional qualifying tournament. <b>compLexity's</b> Dota team is based in a gaming house near Fort Lauderdale, Florida.|$|R
25|$|Analogous {{definitions}} can be {{made for}} space requirements. Although time and space are the most well-known <b>complexity</b> resources, any <b>complexity</b> measure {{can be viewed as a}} computational resource. <b>Complexity</b> measures are very generally defined by the Blum <b>complexity</b> axioms. Other <b>complexity</b> measures used in <b>complexity</b> theory include communication <b>complexity,</b> circuit <b>complexity,</b> and decision tree <b>complexity.</b>|$|E
25|$|Combinatorial {{game theory}} has several ways of {{measuring}} game <b>complexity.</b> This article describes five of them: state-space <b>complexity,</b> game tree size, decision <b>complexity,</b> game-tree <b>complexity,</b> and computational <b>complexity.</b>|$|E
25|$|Specified <b>complexity</b> is an {{argument}} proposed by Dembski and used by him in his works promoting intelligent design. According to Dembski, the concept is intended to formalize a property that singles out patterns that are both specified and complex. Dembski states that specified <b>complexity</b> is a reliable marker of design by an intelligent agent, a central tenet to intelligent design and which Dembski argues for in opposition to modern evolutionary theory. The concept of specified <b>complexity</b> {{is widely regarded as}} mathematically unsound and has not been the basis for further independent work in information theory, <b>complexity</b> theory, or biology. Specified <b>complexity</b> is one of the two main arguments used by intelligent design proponents, the other being irreducible <b>complexity.</b>|$|E
40|$|Innovation {{is often}} thought of as an outcome. In this chapter, we review the literatures on {{innovation}} processes pertaining to the invention, development, and implementation of ideas. In particular, we explore how these processes unfold within firms, across multi-party networks, and within communities. Moreover, we identify four different kinds of <b>complexities</b> associated with innovation processes that we label as evolutionary, relational, temporal, and cultural <b>complexities.</b> While one approach is to manage or control such <b>complexities,</b> we draw attention to literatures that {{suggest that it is}} far more productive to harness these <b>complexities</b> for sustaining ongoing innovation. We conclude the chapter by highlighting some areas for future research...|$|R
3000|$|The <b>complexities</b> of our {{proposal}} and the schemes for suppressing all-group and intra-group interferences in Table 6 are {{the sum of}} the <b>complexities</b> of 2 D-FQUG user grouping algorithm and the SLNR precoding, which are given by C [...]...|$|R
40|$|A right {{ideal is}} a {{language}} L over an alphabet A that satisfies L = LA*. We {{show that there}} exists a stream (sequence) (R_n : n > 3) of regular right ideal languages, where R_n has n left quotients and is most complex under the following measures of complexity: the state <b>complexities</b> of the left quotients, the number of atoms (intersections of complemented and uncomplemented left quotients), the state <b>complexities</b> of the atoms, {{the size of the}} syntactic semigroup, the state <b>complexities</b> of the operations of reversal, star, and product, and the state <b>complexities</b> of all binary boolean operations. In that sense, this stream of right ideals is a universal witness. Comment: 19 pages, 4 figures, 1 tabl...|$|R
25|$|The Blum axioms {{can be used}} {{to define}} an {{abstract}} computational <b>complexity</b> theory on the set of computable functions. In computational <b>complexity</b> theory, the problem of determining the <b>complexity</b> of a computable function is known as a function problem.|$|E
25|$|It is {{a measure}} of the {{computational}} resources needed to specify the object, and is also known as descriptive <b>complexity,</b> Kolmogorov–Chaitin <b>complexity,</b> algorithmic entropy, or program-size <b>complexity.</b> It is named after Andrey Kolmogorov, who first published on the subject in 1963.|$|E
25|$|The {{asymptotic}} <b>complexity</b> {{is defined}} by the most efficient (in terms of whatever computational resource one is considering) algorithm for solving the game; the most common <b>complexity</b> measure (computation time) is always lower-bounded by the logarithm of the asymptotic state-space <b>complexity,</b> since a solution algorithm must work for every possible state of the game. It will be upper-bounded by the complexities of each individual algorithm for the family of games. Similar remarks apply to the second-most commonly used <b>complexity</b> measure, the amount of space or computer memory used by the computation. It is not obvious that there is any lower bound on the space <b>complexity</b> for a typical game, because the algorithm need not store game states; however many games of interest are known to be PSPACE-hard, and it follows that their space <b>complexity</b> will be lower-bounded by the logarithm of the asymptotic state-space <b>complexity</b> as well (technically the bound is only a polynomial in this quantity; but it is usually known to be linear).|$|E
40|$|Developing {{software}} for networked applications is hard and developing reusable {{software for}} networked applications is even harder. First, {{there are the}} <b>complexities</b> inherent to distributed systems, such as optimally mapping application services onto hardware nodes, synchronizing service initialization, and ensuring availability while masking partial failures. These <b>complexities</b> can stymie even experienced software developers because they arise from fundamental challenges {{in the domain of}} network programming. Unfortunately, developers must master the accidental <b>complexities,</b> such as low-level and non-portable programming interfaces and the use of function-oriented design techniques that require tedious and error-prone revisions as requirements and/or platforms evolve. These <b>complexities</b> arise largely from limitations with the software tools and techniques applied historically by developers of networked software. Despite the use of object-oriented technologies in many domains, such as graphical user interfaces and productivity tools, much networked software still uses C-level operating system (OS) application programmatic interfaces (APIs), such as the UNIX socket API or the Windows threading API. Many accidental <b>complexities</b> of networked programmin...|$|R
40|$|In {{the model}} of local {{computation}} algorithms (LCAs), we aim to compute the queried part of the output by examining only a small (sublinear) portion of the input. Many recently developed LCAs on graph problems achieve time and space <b>complexities</b> with very low dependence on n, the number of vertices. Nonetheless, these <b>complexities</b> are generally at least exponential in d, the upper bound {{on the degree of}} the input graph. Instead, we consider the case where parameter d can be moderately dependent on n, and aim for <b>complexities</b> with subexponential dependence on d, while maintaining polylogarithmic dependence on n. We present: a randomized LCA for computing maximal independent sets whose time and space <b>complexities</b> are quasi-polynomial in d and polylogarithmic in n; for constant ϵ > 0, a randomized LCA that provides a (1 -ϵ) -approximation to maximum matching whose time and space <b>complexities</b> are polynomial in d and polylogarithmic in n...|$|R
40|$|This {{research}} {{investigates the}} entrepreneur’s challenges and motivation in SME businesses in Nigeria and its <b>complexities.</b> Previous researchers have identified {{many of these}} challenges and motivations especially Rosa and Fadahunsi (2002); OECD (2006) but none has given sufficient detailed attention to their <b>complexities...</b>|$|R
25|$|There {{is also a}} length-conditional <b>complexity</b> , {{which is}} the <b>complexity</b> of x given the length of x as known/input.|$|E
25|$|Algorithmic {{information}} theory {{is the area}} of computer science that studies Kolmogorov <b>complexity</b> and other <b>complexity</b> measures on strings (or other data structures).|$|E
25|$|The {{artificial}} intelligence researcher Marvin Minsky thinks the problems posed by qualia are essentially issues of <b>complexity,</b> or rather of mistaking <b>complexity</b> for simplicity.|$|E
2500|$|A {{textbook}} for undergraduates avoiding mathematical <b>complexities</b> ...|$|R
5000|$|The Infinite <b>Complexities</b> Of Christmas (04:12) from Carrington ...|$|R
40|$|This {{thesis is}} about {{understanding}} organizational <b>complexities</b> {{that can occur}} during project execution. By focusing on the project team structures using a simulation modeling process, characteristics of project team structures were identified that influenced seven organizational <b>complexities.</b> System Engineering, Policy Analysis and ManagementSection Systems EngineeringTechnology, Policy and Managemen...|$|R
25|$|The {{concept of}} {{polynomial}} time leads to several <b>complexity</b> classes in computational <b>complexity</b> theory. Some important classes defined using polynomial time are the following.|$|E
25|$|The {{following}} <b>complexity</b> figures {{assume that}} arithmetic with individual elements has <b>complexity</b> O(1), {{as is the}} case with fixed-precision floating-point arithmetic or operations on a finite field.|$|E
25|$|As a middle-range {{theoretical}} platform, social <b>complexity</b> can {{be applied}} to any research in which social interaction or the outcomes of such interactions can be observed, but particularly where they can be measured and expressed as continuous or discrete data points. One common criticism often cited regarding the usefulness of <b>complexity</b> science in sociology is the difficulty of obtaining adequate data. Nonetheless, application of the concept of social <b>complexity</b> and the analysis of such <b>complexity</b> has begun and continues to be an ongoing field of inquiry in sociology. From childhood friendships and teen pregnancy to criminology and counter-terrorism, theories of social <b>complexity</b> are being applied in almost all areas of sociological research.|$|E
40|$|This study {{examines}} the <b>complexities</b> of achieving sufficient management measures for the Atlantic Bluefin Tuna, with {{an attempt to}} specify failure and shortcomings within the management system. The key to the solution is embedded in man-made governance systems and legal frameworks. With this thesis I will try to unfold the <b>complexities</b> of governance systems, the legal framework of fisheries management and the regional fisheries management organisation responsible {{for the management of}} the Atlantic Bluefin Tuna (ICCAT). Key words: Atlantic Bluefin Tuna, management, <b>complexities,</b> ICCAT, Governance, UNCLOS, framework, wicked problem, RMF...|$|R
40|$|AbstractBased on single cycle T-functions over Z/(2 n), {{two classes}} of {{pseudorandom}} sequences are proposed in this paper. The periods of all their coordinate sequences can reach the maximal value 2 n, and the distribution properties and linear <b>complexities</b> of the sequences are also studied. For the first class of sequences, it is shown that the less significant half of the coordinate sequences are uniformly distributed over F 2 and the exact linear <b>complexities</b> are also derived. For the second class of sequences, lower bounds on the linear <b>complexities</b> of their coordinate sequences are given...|$|R
40|$|In {{the model}} of local {{computation}} algorithms (LCAs), we aim to compute the queried part of the output by examining only a small (sublinear) portion of the input. Many recently developed LCAs on graph problems achieve time and space <b>complexities</b> with very low dependence on n, the number of vertices. Nonetheless, these <b>complexities</b> are generally at least exponential in d, the upper bound {{on the degree of}} the input graph. Instead, we consider the case where parameter d can be moderately dependent on n, and aim for <b>complexities</b> with quasi-polynomial dependence on d, while maintaining polylogarithmic dependence on n. In this thesis, we give randomized LCAs for com-puting maximal independent sets, maximal matchings, and approximate maximum matchings. Both time and space <b>complexities</b> of our LCAs on these problems ar...|$|R
