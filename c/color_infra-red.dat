7|7|Public
50|$|The E-4 {{process was}} {{generally}} stopped after 1977, although continued in use for Kodak PCF (Photomicrography Color Film) until the 1980s, and for Kodak IE (<b>Color</b> <b>Infra-red</b> film) until 1996. This {{was due to}} a legal commitment by Kodak to provide the process for 30 years.|$|E
5000|$|In 1995, the Center for Geographic Information Systems (CGIS) was created. [...] The CGIS {{has worked}} on {{projects}} for the 1999 <b>Color</b> <b>Infra-Red</b> (CIR) Digital Ortho Photo Program, for the Georgia GIS Data Clearinghouse, for the NWI-Wetlands statewide digital wetland database with GIS tools, for the Trees Atlanta-Greenspace Acquisition Support System, the U.S. Environmental Protection Agency-Air Quality, natural hazards, hydrography, and for infrastructure management.|$|E
50|$|The Forest Resources Division administers 6300000 acre {{of mineral}} estate {{ownership}} and leasing rights to explore for oil, gas and other minerals on state-owned lands which contributes nearly $20-$30 million {{each year in}} royalties to the Natural Resources Trust Fund.Furthermore, the FRD division maintains statewide aerial photographs in <b>color</b> <b>infra-red</b> and black and white formats, and provides detailed computerized map information for land utilization, management and resource protection. In the field, the division {{is responsible for the}} management of all aspects of the state forests, except for State Forest Recreation (Such as State Forest Campgrounds and trails). The Parks and Recreation Division took over the recreation responsibilities in January 2012. The FR Division also manages the use of forests for timber production, new tree growth, and wildlife habitat. The FR Division mainly consists of Foresters who regularly examine trees, plants and soil characteristics to determine the best management practices to keep the forests healthy and Fire Officers which protect both public and private lands from wildfires. The FR division consists on about 270 employees, from foresters and technicians, to fire officers and specialists. Most FR staff works out of DNR field offices, mainly in the Upper Peninsula and Northern/Central Lower Peninsula.|$|E
40|$|A {{transmission}} densitometer utilizing {{fiber optics}} for the efflux geometry was designed, constructed, and tested with several {{black and white}} films, and one color film. The system was semi-specularly illuminated and used semi-specular collection. The system demonstrates the feasibility of using fiber optic bundles in sensitometric equipment. Scattering properties of silver emulsions, <b>color</b> dye <b>infra-red</b> radiation transmission, and assorted electronic factors which introduce error in densitometric values are observed and discussed...|$|R
40|$|Image quality {{measures}} {{to analyze the}} quality of <b>color</b> and <b>infra-red</b> images acquired at various time instants of the day (morning, noon, evening) are discussed in detail with sufficient statistical results. Images are captured once every 30 minutes all through one day and night. It is observed that color images are efficient only under good lighting conditions with responses to metrics being abrupt during dawn and dusk, whereas IR images are influenced {{to a certain extent}} by illumination and contain sufficient information even under less favorable conditions. IR responses to metrics are consistent throughout day and night as expected. It is presumed that this analysis would be helpful in deriving a weighting factor {{that can be used in}} the fusion of EO and IR images...|$|R
40|$|International audienceAbstract. Many modern systems {{must run}} in {{continually}} changing contexts. For example, a {{computer vision system}} to detect vandalism in train stations must function {{during the day and}} at night. The software components for image acquisition and people detection used during daytime may not be the same as those used at night. The system must adapt by replacing running components such as image acquisition from <b>color</b> to <b>infra-red.</b> This adaptation involves context detection, decision on change in components, followed by seamless execution of a new conﬁguration of components. All this must occur at runtime while minimizing the impact of dynamic change on continuity and loss in performance. We present Girgit, a lightweight Python-based framework for building dynamic adaptive software systems. We evaluate it by building a dynamically adaptive vision system followed by performing rigorous experiments to determine its continuity and performanc...|$|R
40|$|A mapping {{study using}} remote sensing {{software}} called ENVI was conducted utilizing four software algorithms {{to investigate whether}} these techniques could accurately classify habitat types and vegetation communities along West Bay of the Galveston Bay Ecosystem from <b>color</b> <b>infra-red</b> (CIR) imagery. The algorithms were used in a small-scale study to investigate which of these techniques could most accurately distinguish habitat types and vegetation communities from the imagery at a site specific location. The most accurate algorithm of the four was used in a large-scale classification study in which entire images were classified utilizing the same data from the small-scale study. Regions of interest (ROIs) were used within ENVI to specify areas of interest within each image that was classified. The locations of ROIs were recorded using a GPS prior to classification, then each was added into ENVI as data points, and each ROI polygon was digitized according to its respective pixel color. Once all of the ROI polygons were completed, each software algorithm was employed. After classification, each habitat type and vegetation community was ground-truthed in order t...|$|E
30|$|Most {{text was}} {{executed}} in black carbon-based (infrared opaque) ink, sometimes with red vermilion-based ink text and accents. However, a brown ink was employed for the text {{on all the}} folios examined from a manuscript produced in Iraq in 1224 (Table  1, # 1 – 4). This ink was transparent in infrared and lacked distinctive elements, suggesting used of a natural organic compound. XRF analysis did show slightly more iron in the inked areas {{but not enough to}} confirm iron-gall ink. As the ink lacks the characteristic haloing or cellulose degradation associated with iron-gall ink, it may be another type of brown organic ink. Historical recipes for the manufacture of Persian inks show that these consisted of multi-component mixtures, many of which contained soot and/or iron gall [26, 27]. Distinction between inks produced with different recipes relied on the use of false <b>color</b> <b>infra-red</b> imaging [26], which was not undertaken in this project. Colored inks were rare, although multiple colors of ink were identified in a manuscript currently attributed to late 17 th century Iran, Table  1, # 36, and are discussed below. Other studies have found colored inks on Islamic manuscripts from the 15 th to 17 th centuries to contain malachite, iron gall, red lead, vermilion, ultramarine and a range of yellow and red arsenic sulfides [24, 25].|$|E
40|$|Elkhorn Slough, a National Estuarine Research Reserve, {{is one of}} {{the most}} {{important}} estuarine systems in California. Despite the protection status of Elkhorn Slough, agriculture in its watershed has increased dramatically since 1970. Associated with this agriculture is an increase in sedimentation, which deposits in creek bottoms, marshes, mudflats, and channels. This sedimentation may alter wetland structural features, which are a major component of habitat for rare species, and drive patterns of plant and animal community assemblages. This research addresses the questions: Has the structure of salt marsh wetlands within Elkhorn Slough changed since 1970 ? If yes, can these changes be linked to increased agriculture? Are there differences in wetland changes between sub-catchments of the watershed? The following wetland features will be examined: plant community type and distribution, width of tidal channels, length of channels, and sinuosity of the channel network. If the research identifies changes to these features, effort will be made to link them to changes in upland features indicative of increased sediment through multiple regression analysis. Remote sensing technologies will be used to quantify historic modifications to the Elkhorn Slough watershed and wetlands. Landsat Multispectral Scanner (MSS) and Thematic Mapper (TM) imagery will be analyzed to quantify the extent of land use change from 1973 to 2000, through the process of land use classification and a post-classification change analysis. Color and <b>color</b> <b>infra-red</b> aerial photos will be used in conjunction with Geographic Information Systems (GIS) to measure changes in wetland structural features over this same time period. This research will assess the extent of habitat degradation in tidal channels, which serve as a nursery for juvenile fish in Elkhorn Slough and Monterey Bay. The research will also provide information about wetland conditions prior to intensive agriculture, and the extent to which changes have occurred, which the Natural Resources Conservation Service and the Elkhorn Slough Foundation will use to guide decisions related to wetland restoration and management...|$|E
40|$|Visual {{surveillance}} {{systems are}} {{getting a lot of}} attention over the last few years, due to a growing need for surveillance applications. In this thesis, we present a visual surveillance system that integrates modules for motion detection, tracking, and trajectory characterization to achieve robust monitoring of moving objects in scenes under surveillance. The system operates on video sequences acquired by stationary <b>color</b> and <b>infra-red</b> surveillance cameras. Motion detection is implemented using an algorithm that combines thresholding of temporal variance and background modeling. The tracking algorithm combines motion and appearance information into an appearance model and uses a particle filter framework for object tracking. The trajectory analysis module builds a model for a given normal activity using a factorization approach, and uses this model for the detection of any abnormal motion pattern. The system was tested on a large ground-truthed data set containing hundreds of color and FLIR image sequences. Results of performance evaluation using these sequences are reported in this thesis...|$|R
40|$|International audienceAbstract. Modernvisionsystemsmustrunincontinuallychangingcontexts. For example, {{a system}} to detect {{vandalism}} in train stations must function {{during the day and}} at night. The vision components for acquisition and detection used dur- ing daytime may not be the same as those used at night. The system must adapt to a context by replacing running components such as image acquisition from <b>color</b> to <b>infra-red.</b> This adaptation must be dynamic with detection of context, decision on change in system configuration, followed by the seamless execution of the new configuration. All this must occur while minimizing the impact of dy- namic change on validity of detection and loss in performance. We present Girgit, a context-aware vision system for scene understanding, that dynamically orches- trates a set of components. A component encapsulates a vision-related algorithm such as from the OpenCV library. Girgit inherently provides loading/caching of multiple component instances, system reconfiguration, management of incoming events to suggest actions such as component re-configuration and replacement of components in pipelines. Given the surplus architectural layer for dynamic adap- tation one may ask, does Girgit degrade scene understanding performance? We perform several empirical evaluations on Girgit using metrics such as frame-rate and adaptation time to answer this question. For instance, the average adaptation time between change in configurations is less than 2 μs with caching, while 8 ms without caching. This in-turn has negligible effect on scene understanding perfor- mance with respect to static C++ implementations for most practical purposes...|$|R
40|$|High Resolution Stereo Camera (HRSC). This {{multi-line}} sensor images the Martian {{surface with}} a resolution of up to 12 m per pixel in three dimensions and provides RGB and <b>infra-red</b> <b>color</b> information. The usage of the stereoscopic image information {{for the improvement of}} the observed position and attitude information via bundle adjustment is important to derive high quality 3 D surface models, color orthoimages and other data products. In many cases overlapping image strips of different orbits can be used to form photogrammetric blocks, thus allowing the simultaneous adjustment of the exterior orientation data. This reduces not only local, but also regional inconsistencies in the data. With the growing number of HRSC image strips in this ongoing mission, the size and complexity of potential blocks is increasing. Therefore, a workflow has been built up for the systematic improvement of the exterior orientation using single orbit strips and regional blocks. For a successful bundle adjustment of blocks using multiple image strips a sufficient number of tie points in the overlapping area is needed. The number of tie points depends mainly on the geometric and radiometric quality of the images. This is considered by detailed analysis of the tie point accuracy and distribution. The combination of methods for image pre-processing, tie point matching, bundle adjustment and evaluation of the results in an automated workflow allows for all HRSC images a global assessment of the quality and a systematic selection of data for larger blocks. ...|$|R
40|$|Satellite {{remote sensing}} imagery {{is used for}} forestry, {{conservation}} and environmental applications, but insufficient spatial resolution, and, in particular, unavailability of images at the precise timing required for a given application, often prevent achieving a fully operational stage. Airborne remote sensing {{has the advantage of}} custom-tuned sensors, resolution and timing, but its price prevents using it as a routine technique for the mentioned fields. Some Unmanned Aerial Vehicles might provide a “third way” solution as low-cost techniques for acquiring remotely sensed information, under close control of the end-user, albeit at the expense of lower quality instrumentation and instability. This report evaluates a light remote sensing system based on a remotely-controlled mini-UAV (ATMOS- 3) equipped with a <b>color</b> <b>infra-red</b> camera (VEGCAM- 1) designed and operated by CATUAV. We conducted a testing mission over a Mediterranean landscape dominated by an evergreen woodland of Aleppo pine (Pinus halepensis) and (Holm) oak (Quercus ilex) in the Montseny National Park (Catalonia, NE Spain). We took advantage of state-of-the-art ortho-rectified digital aerial imagery (acquired by the Institut Cartogràfic de Catalunya over the area during the previous year) and used it as quality reference. In particular, we paid attention to: 1) Operationality of flight and image acquisition according to a previously defined plan; 2) Radiometric and geometric quality of the images; and 3) Operational use of the images in the context of applications. We conclude that the system has achieved an operational stage regarding flight activities, although with meteorological limits set by wind speed and turbulence. Appropriate landing areas can be sometimes limiting also, but the system is able to land on small and relatively rough terrains such as patches of grassland or short matorral, and we have operated the UAV as far as 7 km from the control unit. Radiometric quality is sufficient for interactive analysis, but probably insufficient for automated processing. A forthcoming camera is supposed to greatly improve radiometric quality and consistency. Conventional GPS positioning through time synchronization provides coarse orientation of the images, with no roll information. Nota: Informe relacionat amb el titulat "Adquisició d’imatges en infraroig proper de baixa alçària sobre zones d’interès al Montseny (I) ", del mateix autor...|$|E
40|$|The European Mars Express {{mission was}} {{launched}} in June 2003 and sent into orbit around Mars. On board the orbiter is the German High Resolution Stereo Camera (HRSC). This multi-line sensor images the Martian surface with a resolution of up to 12 m per pixel in three dimensions and provides RGB and <b>infra-red</b> <b>color</b> information. The usage of the stereoscopic image information {{for the improvement of}} the observed position and attitude information via bundle adjustment is important to derive high quality 3 D surface models, color orthoimages and other data products. In many cases overlapping image strips of different orbits can be used to form photogrammetric blocks, thus allowing the simultaneous adjustment of the exterior orientation data. This reduces not only local, but also regional inconsistencies in the data. With the growing number of HRSC image strips in this ongoing mission, the size and complexity of potential blocks is increasing. Therefore, a workflow has been built up for the systematic improvement of the exterior orientation using single orbit strips and regional blocks. For a successful bundle adjustment of blocks using multiple image strips a sufficient number of tie points in the overlapping area is needed. The number of tie points depends mainly on the geometric and radiometric quality of the images. This is considered by detailed analysis of the tie point accuracy and distribution. The combination of methods for image pre-processing, tie point matching, bundle adjustment and evaluation of the results in an automated workflow allows for all HRSC images a global assessment of the quality and a systematic selection of data for larger blocks...|$|R

