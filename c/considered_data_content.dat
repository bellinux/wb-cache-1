0|10000|Public
40|$|Peer group {{management}} for personal data adaptive access Nowadays Peer-to-Peer (P 2 P) Systems {{are essential to}} develop scalable application for resources sharing like file, data, documents, etc. In order to improve resource sharing in unstructured P 2 P architecture, peer clustering solutions have been proposed. The main idea is to logically cluster the peers which have similar content or which have frequent interactions {{in order to improve}} the global behavior of the system. Actually a large amount of personal data is shared through Internet, in particular through blogs and community sites. Those systems perform as social network where profiles are exploited to put in tough peoples. User profiles can be manually defined or automatically discovered from the own published data. Thus, profiles and data are in free access for all users. The purpose of this thesis is to define a privacy data model on which can be based an efficient network auto-organization strategy. This research aims to <b>consider</b> <b>data</b> <b>content</b> and <b>data</b> privacy to cluster peer and define an access control on shared data. A learning approach should be defined in order to discovery some knowledge about peer. However, considering learning techniques in the dynamic and scalable context of P 2 P architecture is not easy and relevant. In order to avoid the inconsistency of learnt knowledge, a distributed strategy of peer group building, memorization and management should b...|$|R
40|$|This paper <b>considers</b> how context-independent <b>data</b> (<b>content</b> <b>data)</b> and context-dependent data (metadata) about {{consumer}} choices {{can capture}} brand loyalty and affect {{the creation of}} new business models. We find that metadata can provide more precise account of consumer preferences and more accurately predict future user choices by increasing the visibility of user context. This implies that metadata should be preferred to <b>content</b> <b>data</b> to achieve more efficient business model innovation. By applying theories on information processing, we reinterpret two types of value consciousness: a phenomenal and an access consciousness. We propose that different information processing systems are in operation in a phenomenal consciousness of value (active in the raw experience) than in an access consciousness of value (active pre- or post-experience). In so doing, suggesting consumer consciousness of value is different at consumption than at choice, and challenging the consciousness assumption implicit in the extant value literature...|$|R
40|$|Among aminoacidopathies, {{phenylketonuria}} (PKU) is {{the most}} prevalent one. Early diagnosis in the neonatal period with a prompt nutritional therapy (low natural-protein and phenylalanine diet, supplemented with phenylalanine-free amino acid mixtures and special low-protein foods) remains the mainstay of the treatment. <b>Data</b> <b>considering</b> nutrient <b>contents</b> of cooked dishes is lacking. In this study, fourteen dishes specifically prepared for PKU individuals were analysed, regarding the lipid profile and iron and zinc contents. These dishes are poor sources of essential nutrients like Fe, Zn or n- 3 fatty acids, reinforcing the need for adequate supplementation to cover individual patients’ needs. This study can contribute to a more accurate adjustment of PKU diets and supplementation {{in order to prevent}} eventual nutritional deficiencies. This study contributes {{to a better understanding of}} nutrient intake from PKU patients’ meals, showing the need for dietary supplementation...|$|R
5000|$|... require {{specific}} and defined instructions through implementation guides to support uniform <b>data</b> <b>content</b> and coding structures (Standards Implementation and Uniform <b>Data</b> <b>Content)</b> ...|$|R
40|$|Background: {{efficient}} {{communication of}} data is inevitable requirement for general practice. Any issue in <b>data</b> <b>content</b> and its exchange among GP and other related entities hinders continuity of patient care. Methods: literature search for this review was conducted on three electronic databases including Medline, Scopus and Science Direct. Results: through reviewing papers, we extracted information on the GP <b>data</b> <b>content,</b> use cases of GP information exchange, its participants, tools and methods, incentives and barriers. Conclusion: consid-ering importance of <b>data</b> <b>content</b> and exchange for GP systems, it seems that {{more research is needed}} to be conducted toward providing a comprehensive framework for <b>data</b> <b>content</b> and exchange in GP systems...|$|R
40|$|A {{conversation}} protocol is a top-down specification framework which specifies desired global {{behaviors of}} a web service composition. In our earlier work [6] we studied the problem of realizability, i. e., given a conversation protocol, can a web service composition be synthesized to generate behaviors as specified by the protocol. Several sufficient realizability conditions were proposed in [6] to ensure realizability. Conversation protocols studied in [6], however, are essentially abstract control flows without data semantics. This paper extends the work in [6] and achieves more accurate analysis by <b>considering</b> <b>data</b> semantics. To overcome the state-space explosion caused by the <b>data</b> <b>content,</b> we propose a symbolic analysis technique for each realizability condition. In addition, we show that {{the analysis of the}} autonomy condition can be done using an iterative refinement approach...|$|R
5000|$|<b>Data</b> <b>content</b> {{standards}} provide {{guidelines for}} the formatting of information being entered into the fields, “controlling the syntax, style, grammar, and abbreviations” that should be used. Examples of <b>data</b> <b>content</b> standards used in institutions that collect cultural objects include Cataloging of Cultural Objects (CCO) and Describing Archives: A Content Standard (DACS).|$|R
2500|$|... <b>data</b> <b>content</b> {{standard}} {{that describes the}} essential information needed to ...|$|R
5000|$|... a {{software}} or programming interface {{for access to}} OMC <b>data</b> <b>contents</b> ...|$|R
2500|$|... <b>data</b> <b>content</b> minimum {{information}} standard {{that describes the}} essential information needed to ...|$|R
30|$|ITS {{wireless}} communication {{can also be}} classified according to the <b>data</b> <b>contents.</b>|$|R
5000|$|EDI {{awareness}} and participation heightened {{as well as}} efforts to standardize <b>data</b> <b>content</b> ...|$|R
5000|$|Information Models: {{providing}} banking <b>data</b> <b>content</b> {{to address}} {{areas such as}} enterprise-wide view of information ...|$|R
50|$|This is {{an example}} of a one line order. Some of the <b>data</b> <b>content</b> has been anonymised.|$|R
5000|$|... {{develop an}} ASC X12 {{standard}} for <b>data</b> <b>content</b> and format for health identification cards (Health Identification Cards) ...|$|R
40|$|This Draft Standard for Trial Use {{contains}} the format and establishes the <b>data</b> <b>contents</b> of the Application Advice Transaction Set (824) for use {{within the context}} of an Electronic Data Interchange (EDI) environment. The transaction set can be used to provide the ability to report the results of an application system's <b>data</b> <b>content</b> edits of transaction sets. The results of editing transaction sets can be reported at th...|$|R
40|$|The lack of {{satisfaction}} {{about using the}} traditional performance assessment has resulted in presenting several suggestions about new performance assessment criteria. Economic value added {{is one of the}} most important items among these criteria. In this research the superiority of economic value added as an economic criterion of performance assessment, was tested in comparison with other accounting performance assessment criteria. Our sample involves 120 companies accepted in Tehran Stock Exchange during the time period between the years 2003 and 2010. We have used panel regression to test the relative <b>data</b> <b>content</b> of economic value added and other accounting criteria and also to test differential (growing) <b>data</b> <b>content</b> of economic value added elements. The results of testing the research hypotheses showed that accounting profit (net profit and net operational profit after taxation) has more <b>data</b> <b>content</b> to describe the traits of stock return compared to economic value added and operational cash flows. The promissory goods and operational cash flows also have differential (growing) <b>data</b> <b>content</b> compared to other economic value added elements in describing the traits of stock return...|$|R
50|$|The {{content of}} each smart message sent {{is divided into}} two parts. The data header and the <b>data</b> <b>content.</b>|$|R
5000|$|... alt.binaries.boneless is a Usenet {{discussion}} forum primarily used to transfer binary <b>data</b> <b>content,</b> {{rather than being}} used for textual communications.|$|R
5000|$|A {{document}} {{accompanying the}} Adobe specification grants [...] "non-exclusive, royalty-free, nontransferable, non-sublicensable, personal, worldwide" [...] patent license to all implementations of the protocol, with two restrictions: one forbids use for intercepting streaming data ("any technology that intercepts streaming video, audio and/or <b>data</b> <b>content</b> for storage in any device or medium"), and another prohibits circumvention of [...] "technological measures {{for the protection}} of audio, video and/or <b>data</b> <b>content,</b> including any of Adobe’s secure RTMP measures".|$|R
5000|$|Large-scale <b>data</b> <b>content</b> distribution. These include {{point-to-point}} and multicast services, {{as well as}} transmission to head-ends for (re-)distribution {{over other}} media.|$|R
5000|$|... {{method that}} is called with the text <b>data</b> <b>contents</b> {{contained}} between the start and end tags of an XML document element.|$|R
5000|$|The <b>data</b> <b>content</b> (frequently {{called the}} payload) of the packet {{is used to}} provide some content-specific {{transformation}} or take a content-driven action.|$|R
40|$|Abstract—Data {{integrity}} {{is the fundamental}} for data authentication. A major problem for XML data authentication is that signed XML data can be copied to another document but still keep signature valid. This is caused by XML data integrity protecting. Through investigation, the paper discovered that besides <b>data</b> <b>content</b> integrity, XML <b>data</b> integrity should also protect element location information, and context referential integrity under fine-grained security situation. The aim {{of this paper is}} to propose a model for XML <b>data</b> integrity <b>considering</b> XML <b>data</b> features. The paper presents an XML data integrity model named as CSR (content integrity, structure integrity, context referential integrity) based on a concatenated hash function. XML <b>data</b> <b>content</b> {{integrity is}} ensured using an iterative hash process, structure integrity is protected by hashing an absolute path string from root node, and context referential integrity is ensured by protecting context-related elements. Presented XML data integrity model can satisfy integrity requirements under situation of fine-grained security, and compatible with XML signature. Through evaluation, the integrity model presented has a higher efficiency on digest value-generation than the Merkle hash tree-based integrity model for XML data. Keywords- Fine-grained security, XML data integrity, Diges...|$|R
40|$|Data {{integrity}} {{is the fundamental}} for data authentication. A major problem for XML data authentication is that signed XML data can be copied to another document but still keep signature valid. This is caused by XML data integrity protecting. Through investigation, the paper discovered that besides <b>data</b> <b>content</b> integrity, XML <b>data</b> integrity should also protect element location information, and context referential integrity under fine-grained security situation. The aim {{of this paper is}} to propose a model for XML <b>data</b> integrity <b>considering</b> XML <b>data</b> features. The paper presents an XML data integrity model named as CSR (content integrity, structure integrity, context referential integrity) based on a concatenated hash function. XML <b>data</b> <b>content</b> {{integrity is}} ensured using an iterative hash process, structure integrity is protected by hashing an absolute path string from root node, and context referential integrity is ensured by protecting context-related elements. Presented XML data integrity model can satisfy integrity requirements under situation of fine-grained security, and compatible with XML signature. Through evaluation, the integrity model presented has a higher efficiency on digest value-generation than the Merkle hash tree-based integrity model for XML data. Comment: 10 pages, International Journal of Computer Science and Information Security (IJCSIS...|$|R
5000|$|... {{work with}} {{appropriate}} parties {{to ensure the}} health care industry can meet WEDI's target of universal adherence to uniform <b>data</b> <b>content</b> by 1996 ...|$|R
50|$|Data {{confidentiality}} is {{the property}} that <b>data</b> <b>contents</b> {{are not made}} available or disclosed to illegal users. Outsourced data is stored in a cloud {{and out of the}} owners' direct control. Only authorized users can access the sensitive data while others, including CSPs, should not gain any information of the data. Meanwhile, data owners expect to fully utilize cloud data services, e.g., data search, data computation, and data sharing, without the leakage of the <b>data</b> <b>contents</b> to CSPs or other adversaries.|$|R
50|$|JSword is a {{separate}} implementation, written in Java, which reproduces most of the API features of the C++ API and supports most SWORD <b>data</b> <b>content.</b>|$|R
5000|$|... • Publisher - Used {{to create}} <b>data</b> <b>content</b> and reports {{that can be}} shared via alerts and email {{as well as in}} {{multiple}} file formats.|$|R
30|$|User Revocation. User {{revocation}} can be efficiently {{processed and}} {{is suitable for}} e-health cloud application. It also ensures the privacy of queries and secrecy of <b>data</b> <b>contents.</b>|$|R
50|$|CD-i Ready is {{a compact}} disc format for mixing audio and <b>data</b> <b>content</b> on a CD. It was {{developed}} by Phillips in 1991, based on the CD-i format.|$|R
5000|$|Clicking {{on a given}} DrugCard button {{brings up}} the full <b>data</b> <b>content</b> for the {{corresponding}} drug. A complete explanation of all the DrugCard fields and sources is given there.|$|R
40|$|Information Centric Networking (ICN) {{is a new}} and {{promising}} network concept which is founded upon the idea that most users in the internet are interested in accessing digital objects, irrespectively of their locations. Digital objects in ICN have unique names {{that are used in}} order to route <b>data</b> <b>content</b> from the source node to the destination node. During the content delivery from sources to destinations, the <b>data</b> <b>contents</b> are cached to intermediate nodes in order to achieve efficient and reliable distribution of the <b>data</b> <b>content</b> among the network infrastructure (in-network caching). In this research project we focus on the efficiency of ICN for delivering Big Data with Persistent Identifiers. We proposed a Mapping Architecture for resolving PIDs to ICN names and we evaluate the efficiency of in-network caching when delivering Big Data objects. Our results showed that in-network caching can offer significant performance benefits when the cache size of the network elements that perform in-network caching is bigger than the Big Data object size...|$|R
5000|$|Clusterpoint {{software}} automatically builds {{and maintains}} document-type XML and JSON <b>data</b> <b>content</b> index when <b>data</b> us loaded, updated or deleted. A single database index (ranking index) is maintained {{to support these}} types of querying: ...|$|R
5000|$|The term [...] "enhanced CD" [...] {{is also an}} {{umbrella}} term and a certification mark {{used to refer to}} different CD formats that support audio and <b>data</b> <b>content,</b> including mixed mode CDs, CD-i and CD-i Ready.|$|R
50|$|DVB-S2 is envisaged (contemplate) for {{broadcast}} services including {{standard and}} HDTV, interactive services including Internet access, and (professional) <b>data</b> <b>content</b> distribution. The development of DVB-S2 {{coincided with the}} introduction of HDTV and H.264 (MPEG-4 AVC) video codecs.|$|R
