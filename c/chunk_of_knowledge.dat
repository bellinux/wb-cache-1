8|10000|Public
3000|$|... γ> 1 is {{the control}} {{factor for the}} size of the <b>chunk</b> <b>of</b> <b>knowledge</b> δ skill that agent i' could learn from agent i"; [...]...|$|E
40|$|An {{important}} aspect of context in medical reasoning {{is the notion of}} "variation" of a <b>chunk</b> <b>of</b> <b>knowledge</b> according to various contingencies, such as course of patient's disease, response to therapies, or team specificity. Our position is to represent these variations implicitly, by proposing mechanisms to factor knowledge and to refine it. We propose three mutually compatible mechanisms that effectively contribute to represent slight variations of knowledge in a representation framework integrating object-oriented programming and rule-based programming. We illustrate them with examples extracted from various knowledge bases for the management of mechanical ventilation...|$|E
40|$|Knowledge Management {{literature}} lays {{emphasis on}} the fact that a major <b>chunk</b> <b>of</b> <b>knowledge</b> dissemination occurs through the various forms of social networks that exist within the organizations. A social network is a simple structure comprising of set of actors or nodes that may have relationships ties with one another. The social network analysis (SNA) will help in mapping and measuring formal and informal relationships to understand what facilitates or impedes the knowledge flows that bind interacting units. This paper aims at studying the knowledge flows that happen through the social networks. It first, provides a conceptual framework and review of literature on the recent research and application of knowledge mapping and SNA, followed by a discussion on application of SNA for mapping knowledge flows in a pharmaceutical firm. In the last part, Knowledge maps are presented to illustrate the actual knowledge flow in firm...|$|E
40|$|In {{this paper}} three models <b>of</b> <b>knowledge</b> {{transfer}} in organization are considered. In {{the first model}} (A) the transfer <b>of</b> <b>chunks</b> <b>of</b> <b>knowledge</b> among agents is possible only when the sender has exactly one more <b>chunks</b> <b>of</b> <b>knowledge</b> than recipient. This is not dissimilar with bounded confidence model of opinion dynamics. In the second model (B) the knowledge transfer take place when sender is "smarter" than recipient. Finally, in the third scenario (model C) we allow for knowledge transfer also when sender posses the same or greater number <b>of</b> <b>chunks</b> <b>of</b> <b>knowledge</b> as recipient. The simulation bases on cellular automata technique. The organization members occupy nodes of square lattice and they interact only with their nearest neighbors. With computer simulations we show, that the efficiency and the effectiveness <b>of</b> <b>knowledge</b> transfer i) for model C is better than for model B ii) and it is worse for model A than for model B. Comment: 8 pages, 5 figures (in 19 files), for 10 th International Conference on Agents and Artificial Intelligenc...|$|R
50|$|This {{definition}} {{leads us}} to the view of Joseph Schwab that discipline is the sole source of curriculum. Thus in our education system, curriculum is divided into <b>chunks</b> <b>of</b> <b>knowledge</b> we call subject areas in basic education such as English, Mathematics, Science, Social Studies and others. In college, discipline may include humanities, sciences, languages and many more. Curriculum should consist entirely <b>of</b> <b>knowledge</b> which comes from various disciplines.To learn the lesson is more interesting than to take a scolding, be held up to general ridicule, stay after school, receive degrading low marks, or fail to be promoted.|$|R
40|$|In {{a unified}} {{knowledge}} representation, data, information and knowledge are all represented {{in a single}} formalism. A unified knowledge representation based on "items" is described. Items contain two classes of constraints that apply equally to knowledge and to data. Items are compared to an if-then, or rule-based, <b>knowledge</b> representation. Simple <b>chunks</b> <b>of</b> <b>knowledge</b> {{that can only be}} represented by a number of rules are represented as single items. Rule-based formalisms are prone to the introduction of potential maintenance hazards caused by one rule being hidden within another. A single operation for items enables some of these hidden relationships to be removed. Items make i...|$|R
40|$|We {{present an}} {{assistance}} {{tool for the}} incremental construction of knowledge bases. First it divides the construction process into many phases. Each one is characterised by particular functionalities aiming at structuring treatments and checks in the most adaptive way, according {{to the needs of}} the expert, and to the contents of the base. This will avoid accomplishing non adapted checks that might generate invalid or redundant results. Moreover and throughout the different treatments and checks applied on each <b>chunk</b> <b>of</b> <b>knowledge,</b> the system generates a large number of metaattributes. Being semantically related to the domain or specific {{to the needs of the}} checks, they allow the system to enhance the information that it possess about the knowledge contained in the base. This leads to a metaknowledge base that speeds up future process. For example, some significant describing properties concerning concepts and rules will be used to considerably reduce the combinatory. Others, consistin [...] ...|$|E
40|$|To {{deal with}} {{autonomous}} agents ’ knowledge and subjective beliefs in open, het-erogeneous and inherently distributed settings, we need special formalisms that combine knowledge from multiple and potentially heterogeneous interconnected contexts. Each context contains a <b>chunk</b> <b>of</b> <b>knowledge</b> defining a logical theory, called ontology unit). While standard logics may be used, subjectiveness and heterogeneity {{issues have been}} tackled by knowledge representation formalisms called contextual logics or modular ontology languages (e. g. [1] [2]). Nevertheless, in distributed and open settings we may expect that different ontology units should be combined in many different, subtle ways without making any assump-tion about the disjointness of the domains covered by different units. To address this issue we need to increase the expressivity of the language used for defining correspondences. Towards this goal, we have been motivated to propose the rep-resentation framework EDDLHQ+ SHIQ (or simply E − SHIQ). The EDDLHQ+ SHIQ framework. Given a finite index set of units ’ identifiers I, each unit Mi consists of a TBox Ti, RBox Ri, and ABox Ai in the SHI...|$|E
30|$|After a {{successful}} interaction, the agent {{that started the}} communication is updated. For simplicity, {{no change in the}} respondent’s state is produced, assuming that knowledge, being an intangible good, does not decrease when shared, and there is no cost of processing and transmission. Skill and interest are always non-negative quantities. For the skill parameter associated to each topic an agent owns, we assumes that it simply increases in chunks calculated as a fraction of the knowledge difference between two interacting agents. This implies that in subsequent interactions between two agents the less skilled one accumulates knowledge in chunks of diminishing size. In this simple model of knowledge transmission, skill is a monotonic positive function with diminishing marginal increments. For completeness, although not specifically relevant for this work, the model also considers the effect of trust as an enabling factor for sharing knowledge: the more the trust between the two agents, the better the diffusion of knowledge. Here the assumption is that trust between two interacting agents is built with successful communication. In this case, when agents interact for the first time, the <b>chunk</b> <b>of</b> <b>knowledge</b> transferred is reduced by a discounting factor representing the absence of trust. This discount factor progressively vanishes with subsequent communications. This is a simplified form of trust (and distrust) modeling, but motivations could be found in the literature about collective behavior [39, 40] and refers both to the prevalence of egocentrism in assimilating new information and to trust dynamics.|$|E
50|$|First, the <b>knowledge</b> <b>of</b> {{individual}} subject-matter experts {{engaged in}} knowledge engineering often {{is not fully}} integrated when dealing with complex problems, at least initially. Rather, this knowledge may exist in a somewhat more loosely organized state, a sort <b>of</b> <b>knowledge</b> soup with <b>chunks</b> <b>of</b> <b>knowledge</b> floating about in it. A common observation <b>of</b> <b>knowledge</b> engineers experienced in graphically designing knowledgebases is {{that the process of}} constructing a graphic representation <b>of</b> problem-solving <b>knowledge</b> in a formal logical framework seems to be synergistic, with new insights into the expert’s knowledge emerging as the process unfolds. (At the moment, this assertion is largely anecdotal. Contributors to this article need to find a suitable way to document this point, because it is actually a rather important finding not simply limited to NetWeaver, but knowledge engineering more broadly).|$|R
40|$|Many {{studies show}} that the {{acquisition}} <b>of</b> <b>knowledge</b> is the key to build competitive advantage of companies. We propose a simple model <b>of</b> <b>knowledge</b> transfer within the organization and we implement the proposed model using cellular automata technique. In this paper the organisation is considered in the context of complex systems. In this perspective, the main role in organisation is played by the network of informal contacts and the distributed leadership. The goal {{of this paper is to}} check which factors influence the efficiency and effectiveness <b>of</b> <b>knowledge</b> transfer. Our studies indicate a significant role of initial concentration <b>of</b> <b>chunks</b> <b>of</b> <b>knowledge</b> for knowledge transfer process, and the results suggest taking action in the organisation to shorten the distance (social distance) between people with different levels <b>of</b> <b>knowledge,</b> or working out incentives to share knowledge. Comment: 28 pages, 9 figures, 2 Fortran 77 code...|$|R
40|$|Individual {{differences}} in memory {{performance in a}} domain of expertise have traditionally been accounted for by previously acquired <b>chunks</b> <b>of</b> <b>knowledge</b> and patterns. These accounts have been examined experimentally mainly in chess. The role <b>of</b> <b>chunks</b> (clusters <b>of</b> chess pieces recalled in rapid succession during recall of chess positions) and their relations to chess skill are, however, under debate. By introducing an independent chunk-identification technique, namely repeated-recall technique, this study identified individual chunks for particular chess players. The study not only tested chess players with increasing chess expertise, but also tested non-chess players who should not have previously acquired any chess related chunks in memory. For recall of game positions significant differences between players and non-players were found in virtually all the characteristics <b>of</b> <b>chunks</b> recalled. Size <b>of</b> the largest <b>chunks</b> also correlates with chess skill within the group of rated chess players. Further research will help us understand how these memory encodings can explain large {{differences in}} chess skill...|$|R
40|$|To {{deal with}} {{autonomous}} agents ’ knowledge and subjective {{beliefs in the}} open, heterogeneous and inherently distributed settings concerned by Agreement Technologies, we need special formalisms that combine knowledge, taking also into account disagreements and heterogeneity from multiple interconnected contexts. For agents to reason jointly, they need to combine knowledge by means of correspondences and links between context elements. Each context contains a <b>chunk</b> <b>of</b> <b>knowledge</b> defining a logical theory, that we call ontology or ontology unit. While standard logics may be used, {{to deal with the}} issues of subjectiveness and heterogeneity in the semantic web, special knowledge representation formalisms based on web standards have been proposed, sometimes called contextual logics or modular ontology languages (e. g. [1] [2]). Among others, assumptions about the domains covered by the distinct ontology units affect the expressivity of the languages used for defining correspondences. Nevertheless, in distributed and open settings we may expect that different units should be combined in many different, subtle ways. Towards this goal, we have been motivated to propose the representation framework EDDL HQ + SHIQ (or simply E − SHIQ). The proposed framework alleviates the assumptions for overlapping or disjoint domains posed by DDL and E-connections, respectively. The E-SHIQ framework. Given a finite index set of units ’ identifiers I, each unit Mi consists of a TBox Ti, RBox Ri, and ABox Ai in the SHIQ fragment of Description Logics (DL) [3]. SHIQ provides role transitivity and hierarchy, qualified cardinality restrictions and inverse roles. For each unit i ∈ I, le...|$|E
40|$|This paper {{describes}} {{an application of}} an adaptive planning system for automatic tool changers in flexible manufacturing systems. The conventional models of predictive control usually cannot adapt to a real time dynamic environment. The proposed adaptive control model is capable of self adjusting to changing environments. The algorithm {{is based on a}} decision logic, which is constructed by breaking up knowledge and converting them into mathematical form in order to cover all possible conditions that can exist during the implementation phase. Expert thoughts and knowledge from decision logic are stored in the decision tree, which consists of circular nodes, arcs and decision nodes. The suggested system is capable of accepting further rules, new nodes and branches to the tree when additional attributes are needed. This whole knowledge is encoded in the form of production rules and each rule represents a small <b>chunk</b> <b>of</b> <b>knowledge</b> relating to the given domain of tool replacement. A number of related rules collectively respond to highly useful conclusions. The system uses VP Expert development shell, contains an inference engine and, a user interface. The originality of the proposed strategy lies in that a knowledge-based expert system is developed to identify and analyze the current conditions and then readjust the output that reflects the real-time environment. Compared with the various classical models, the approach can synthesize and analyze as many variables as possible to adequately and reliably identify the real-time conditions. Simulation results demonstrate the effectiveness and practicality of this tool-change planning and control strategy...|$|E
40|$|This paper {{describes}} {{various types}} <b>of</b> <b>knowledge</b> and postulates the notion <b>of</b> <b>knowledge</b> types {{as a method}} for integrating various types of diverse and heterogeneous knowledge. It defines knowledge types as an integration of the physical representation and the visualisation and behaviour <b>of</b> <b>chunks</b> <b>of</b> <b>knowledge.</b> It demonstrates this hypothesis b y considering the electronic publication of conventional documents in an environment called IntelliText. IntelliText is implemented as a hypertext <b>of</b> basic <b>knowledge</b> types that can be coupled to form more complex knowledge types. The paper focuses on two knowledge types in particular, context and assertions, and shows how they are implemented in IntelliText using the path and note knowledge types. These two knowledge types are singled out in particular as are claimed they contribute most to the improvement of relevance and appropriateness <b>of</b> <b>knowledge.</b> context, electronic book, path, knowledge type, knowledge acquisition, knowledge representation, explanation, assertion, IntelliTex...|$|R
40|$|Combining {{technology}} enabled {{learning and}} knowledge management {{is a very}} promising strategy to systematic competence building in software organizations. In order to set-up a combined learning and knowledge management environment and to support organization members in packaging small <b>chunks</b> <b>of</b> <b>knowledge</b> into courseware modules, Fraunhofer IESE developed the IntView-KM methodology. IntView-KM defines how to provide the organizational, methodological, and technological prerequisites that enable software engineers to produce small courseware modules (contents) as a byproduct of their daily work. This paper presents the two phases of the IntView-KM methodology. Furthermore, tool support for courseware module production is recommended and the existing tool support summarized. Finally, experiences in applying IntView-KM and results of a first evaluation of the tool support for IntView-KM are described. Copyright 2002 ACM...|$|R
40|$|The paper {{presents}} {{an approach to}} a memory structure of design ideas in a library of design precedents. A model of case memory for design is developed. The model is composed <b>of</b> distinct <b>chunks</b> <b>of</b> <b>knowledge</b> called design stories. A formalism for the design story is proposed which represents the linkage between design issue, concept and form in stories. Stories are structured in memory according to a semantic network. The lexicon of the semantic network acts as a memory index. The memory structure and indexing system are demonstrated to enhance search and to support crosscontextual browsing and exploration in the precedent library. The approach is demonstrated in a pilot design aid system in the task domain of early conceptual design in architecture...|$|R
40|$|There {{are many}} {{applications}} {{which may be}} done by an expert system in real time, if the system is capable of real-time response. The LISP and PROLOG-based expert systems have typically been too slow for real-time response. This {{has led to an}} effort to use other languages, the development of fast pattern matching techniques and other methods of improving the speed of expert systems. Another approach to developing faster expert systems is {{to make use of the}} emerging parallel processing computer technology. A further use for parallelism is to allow reasonable response time for large knowledge bases. The size <b>of</b> <b>knowledge</b> bases may become as large as 20, 000 <b>chunks</b> <b>of</b> <b>knowledge</b> (and more) in the near future in medical and space applications. This paper describes the use of parallel processing in the EMYCIN backward chained rule-based model...|$|R
40|$|First-year law {{has always}} been a {{challenge}} for both students and teachers alike. Both groups have high expectations of what can be achieved in an introductory law subject. Students want to master “it”, usually understood as <b>chunks</b> <b>of</b> <b>knowledge,</b> immediately. Teachers understand that the foundations of a good legal education are much more elusive and involve mastery of method, as much as substance. An introductory subject requires finding an appropriate balance between these two elements. Too often the first year curriculum also gets bogged down in abstract “either-or” debates about the importance of “black-letter law” versus critical perspectives about law. Missing from much of the discussion of the first year curriculum are theoretically informed practical strategies which simultaneously develop first year students’ skills in legal analysis, and preserve their capacity to look at law and legal institutions critically...|$|R
40|$|With {{the aim of}} verifying the {{coherence}} of large rule bases, the vital objective that guided our work is {{to find ways to}} reduce the combinatory while trying to find as many anomalies as possible. The satisfaction of this compromise was attained thanks to the use of metaknowledge. First they allow, using meta-attributes describing significant properties of concepts and rules, to make judicious selections of those that will be handled. Then, again thanks to these meta-attributes, heuristics will be able to reduce the amount <b>of</b> <b>knowledge</b> concerned by the treatments while comparing two rules. In addition, some attributes linking <b>chunks</b> <b>of</b> <b>knowledge</b> constitute access paths allowing to reduce the search duration for a particular information. They allow also to keep trace of the results of previously accomplished treatments that will be useful in future process, in order to avoid needlessly repeating treatments. Finally, as the knowledge used to accomplish these treatments and checks is itse [...] ...|$|R
40|$|We {{present a}} tool for {{detecting}} conflicts and redundancies among large knowledge bases. First it allows {{the reduction of the}} combinatory by selecting among all the rules only those liable to generate conflicts; it does this using properties of the rules and heuristics. Then some attributes linking <b>chunks</b> <b>of</b> <b>knowledge</b> constitute access paths allowing to reduce the search duration for a particular information. They allow also to keep trace of the results of previously accomplished treatments that will be useful in future process, in order to avoid needlessly repeating treatments. Finally as the knowledge used to accomplish these treatments and checks is itself expressed in inference rule formalism, the system may be applied to itself. Introduction To respond to the increasing importance <b>of</b> <b>knowledge</b> based systems, many methodologies and tools have been developed in order to assist building these systems. Aiming at modelling experts' knowledge and reasoning, the knowledge contained in t [...] ...|$|R
40|$|Cases in {{the domain}} of {{architecture}} and engineering are commonly stored and presented as graphical representations in the form of drawings. The way creative designers fit and adapt graphical representations through drawing and re-drawing {{is still one of the}} least understood phenomena in design. Modelling stich processes appears to be a key to graphic knowledge base integration in CAAD environments. The paper reports on a new approach to modelling design adaptation in a graphical environment. This approach is based upon a theory of creativity, the Representation - Re-representation Hypothesis which is here employed in the formalization of design adaptation. A'multi-layer re-representational model'which assists in the adaptation of design drawings is developed and presented. The model is based on the transformation <b>of</b> <b>chunks</b> <b>of</b> <b>knowledge</b> in design cases into explicit re-representational structures which can support creative design in a graphic environment. This model is utilized in our current work in development of a prototype graphical case-based CAAD system...|$|R
40|$|This paper {{presents}} an adaptation scenario for tailoring instructional content towards individual learner characteristics {{taking into consideration}} his/her learning style type and subject matter motivation level. Learning resources are organized through shareable content objects (SCOs) – a small digital <b>chunks</b> <b>of</b> <b>knowledge,</b> independent and self described pieces of instructional material delivered via Learning Management System (LMS). We use an ontology based student model for storing student information. The scenario of designing lesson content {{is presented as a}} cross section of learning style and motivation level, based on the learning object’s educational metadata. Adaptation is made through discovering those SCO’s whose educational category metadata implies that SCO is to be delivered for the learning style of user. Our future work will be to provide experiment and to test our proposed guidelines in order to get feedback on how learners see the adaptive learning environments tailored to their individual learning style and motivation characteristics...|$|R
40|$|Abstract. The idea <b>of</b> <b>knowledge</b> sharing {{has strong}} {{roots in the}} {{education}} process. With the current development of the technology and moving learning material into the web environment it acquired a new dimension. Learning objects are the <b>chunks</b> <b>of</b> <b>knowledge</b> shared by e-learning community. Organizations and individuals are building repositories of learning objects and annotate them with metadata to describe their educational values and standardization efforts {{are on the way}} to provide a franca lingua for the educators. In this paper we describe the peer-to-peer infrastructure for sharing learning object we are building in Canada. The POOL projects builds on the three types of nodes: SPLASH is an freely downloadable application which allows individuals to create metadata and maintain their collection of learning objects, PONDs are bigger repositories of learning objects connected to the peer-to-peer network and POOL centrals increase the speed and breadth of the searches in the peer-to-peer network. The POOL project uses CanCore- a subset of the IMS metadata protocol- to describe learning objects. In th...|$|R
40|$|How can we {{insure that}} {{knowledge}} {{embedded in a}} program is applied effectively? Traditionally {{the answer to this}} question has been sought in different problem solving paradigms and in different approaches to encoding and indexing <b>knowledge.</b> Each <b>of</b> these is useful with a certain variety of problem, but they all share a common problem: they become ineffective in the face of a sufficiently large knowledge base. How then can we make it possible for a system to continue to function in the face of a very large number <b>of</b> plausibly useful <b>chunks</b> <b>of</b> <b>knowledge?</b> In response to this question we propose a framework for viewing issues <b>of</b> <b>knowledge</b> indexing and retrieval, a framework that includes what appears to be a useful perspective on the concept of a strategy. We view strategies as a means of controlling invocation in situations where traditional selection mechanisms become ineffective. We examine ways to effect such control, and describe meta-rules, a means of specifying strategies which offers a number of advantages. We consider at some length how and when it is useful to reason about control, and explore the advantages meta-rules offer for doing this...|$|R
40|$|The rational-empirical {{process was}} first {{proposed}} by the pragmatic philosopher Peirce to describe {{the manner in which}} a rational agent’s hypotheses are empirically validated and functioning in a social context. Sowa (2002) has updated and broadened these ideas as part <b>of</b> a <b>knowledge</b> cycle made up interacting abductive processes and a “knowledge soup ” of micro-theories that are loosely assembled in lattices. Abductive process select <b>chunks</b> <b>of</b> <b>knowledge</b> from the “soup”, evaluate their relevance to the situation/problem at hand, and form locally consistent theories to predict observations. In this view the human mind is not a highly organized knowledge base so much as cognitive content that is assembled as needed into pragmatically consistent, local theory. This allows for a natural growth <b>of</b> <b>knowledge</b> flowing inconsistent, loosely organized, and in perpetual flux. The concept is captured by the term knowledge soup: fluid, lumpy, with adherable <b>chunks</b> <b>of</b> theories and hypotheses that float in and out of awareness. This formulation, which is centered in agent’s intentions and empirical learning may be useful for designing cognitive architecture supporting interactive and inherently scruffy tasks, such as found in medicine and investigatory activities including planetary exploration. The paper connects Sowa’s framework with Bratman’s formulation of intention as a mental state that constrains future actions. Intention-based models of clinical guidelines, such as investigated in the Asgaard project, are discussed as fruitful avenues of research on the interaction between abductive reasoning and the weighing of alternative courses of action...|$|R
40|$|OBJECTIVES: To {{develop a}} model for {{breaking}} bad news that {{meets the needs of}} people with intellectual disabilities (IDs). DESIGN: A two-phase qualitative study featuring: (I) focus group meetings, on-line focus groups and one-to-one interviews; (II) structured feedback from participants and other stakeholders. SETTING: Participants were drawn from National Health Service hospitals, Primary Care Trusts, independent organisations and on-line forums across England. PARTICIPANTS: 109 participants were purposively selected: 21 people with mild/moderate IDs, 28 family carers, 26 ID professionals and 34 general health professionals. OUTCOME MEASURE: Feedback on a preliminary model for breaking bad news to people with IDs was collected from 60 participants and other stakeholders to assess relevance and acceptability, before the model was finalised. RESULTS: Breaking bad news is best seen as a process, not an event or a linear series of events. Bad news situations usually constitute a wide range of discrete items or <b>chunks</b> <b>of</b> information. 'Building a foundation of knowledge' is central to the model. Information needs to be broken down into singular <b>chunks</b> <b>of</b> <b>knowledge</b> that can be added over time to people's existing framework <b>of</b> <b>knowledge.</b> Three other aspects should be considered at all times: capacity, people and support. CONCLUSIONS: Patients who have IDs do not easily process verbal information in a clinical setting. The new model for breaking bad news to people with IDs needs to be tested in practice using robust outcome measures. The model's relevance to wider patient groups should also be evaluated...|$|R
40|$|Abstract. Semantic Web {{technologies}} {{are available and}} gain popularity both on the Web and on the desktop. However, in spite of common representation formats, personal and online data is still difficult to interlink, notably because of the different vocabularies used to describe it, {{as well as the}} lack of common identifiers between desktop and Web-based applications. In this paper, we describe a process for easily publishing and sharing of personal notes as Linked Data. Our approach can be used to publish any kind of information from the desktop to the Web, enabling integration <b>of</b> small <b>chunks</b> <b>of</b> personal <b>knowledge</b> into the Web of Data and focusing on a user-driven approach <b>of</b> <b>knowledge</b> management. ...|$|R
40|$|Incremental change adds new {{functionality}} and new {{properties to}} software. It’s {{an essential part}} of software processes such as maintenance, evolution, iterative development and enhancements, and agile development. Because of that, it {{plays an important role in}} practical software engineering. In this article, we concentrate on IC in the context of object-oriented Java programs and study selected IC activities. Because change requests are formulated in terms <b>of</b> program concepts— <b>chunks</b> <b>of</b> <b>knowledge</b> about the program and application domain—the resulting IC activities also focus on program concepts. Moreover, most change requests originate from the end user, so the end user’s view of the program is the source of most concepts that govern IC. Additional concepts might originate from other programmers and deal with the program architecture or algorithms. Program dependencies also play a crucial role in IC; if a program component changes, other dependent components might also have Incremental changes introduce new functionality and new properties to software. Here, an example presents IC activities in which program concepts and dependencies play a key role. to change. This is true even for well-designed object-oriented programs, as this article’s example demonstrates. IC at work We illustrate IC in an example involvin...|$|R
40|$|We {{describe}} an editor for problem-solving knowledge that communicates with the user through English paraphrases <b>of</b> the <b>knowledge.</b> Although {{it does not}} support the full range of modifications one might want to make, the value of the tool {{lies in the fact that}} the user need not understand the syntax of the expert system to make modifications. By analyzing the problem-solving knowledge, the tool can allow the user to select semantically coherent <b>chunks</b> <b>of</b> the <b>knowledge.</b> It then presents English paraphrases of possible substitutions which would result in new problem-solving knowledge that is syntactically correct. In this way the tool expands the range of modifications that a naïve user can make to problem-solving knowledge in an expert system...|$|R
40|$|Abstract: This paper {{reports on}} results of {{experiments}} {{carried out with}} TRIANGLE. The software has been designed and developed since 2001 in several modifications as an experimental prototype for an interactive multimedia learning object. During the design, it was essential to provide a user interface with good usability {{in order to support}} the teachers with only a minimum <b>knowledge</b> <b>of</b> computers. It was also necessary to provide a simple data structure and open architecture including runtime evaluation. The basic idea was to provide a quiz show game in order to uphold as strong a level of motivation as possible. The purpose of this prototype was to test the efficiency of three main psychological concepts in terms of learning: motivation, incidental learning, and something we call the Tamagotchi effect, which refers to the concept of personal responsibility. A pre-test/post-test control group design was chosen. The experiments were carried out in real-life classroom settings including N= 44 K 8 students. Mathematics was chosen as the subject. Three hypotheses were tested: 1) This game based learning software provides a level of motivation high enough to make learning fun, even with less popular subjects; 2) <b>Chunks</b> <b>of</b> <b>knowledge</b> mixed into informational text, within a hypertext structure, are efficient enough to facilitate student learning; 3) An additional virtua...|$|R
5000|$|In the {{competitive}} <b>chunking</b> hypothesis, <b>knowledge</b> <b>of</b> a letter string develops along {{a hierarchy of}} [...] "chunks", beginning with bigrams (two letters), leading to trigrams, four-grams, and so on. [...] "Chunk strength" [...] refers to the frequency of occurrence <b>of</b> any given <b>chunk</b> during the learning phase. The higher the <b>chunk</b> strength <b>of</b> an item, {{the more likely it}} is to be determined grammatical.|$|R
40|$|This paper {{gives an}} insight {{to some of}} the {{intrinsic}} issues related to the understanding and the computer support of conceptual design. On the one hand, the academic research and development have produced innumerable methods and techniques to support product conceptualization. Reasonable progress has been achieved in (a) the understanding of the fundamental reasoning mechanisms, (b) the development of dedicated aspect models, (c) the application of artificial intelligence techniques in computer support, and (d) clarifying the role of conceptualization in the global product development process. On the other hand, the industry still follows intuitive methodologies and applies less-sophisticated techniques to solve conceptualization problems. With a few exceptions, it is rare when a company uses computer aided conceptual design methods and tools from the academia as a daily routine. The author has tried to explore the reasons of this phenomenon. He has become convinced that the problems originate in the endeavor of the academia to introduce abstract models, to develop highly specialized non-integral tools, and to give preference to automated, rather than highly interactive means. He finds the solution in the development of methods, tools and representations that feature very low level of abstraction, but high level <b>of</b> knowledgeintensiveness. The <b>chunks</b> <b>of</b> <b>knowledge</b> <b>of</b> designers have {{to be taken into account}} as patterns of conceptualization that describe the design and other concepts as well as the associations among concepts. Any model created in the course of conceptual design should be transferable to CAD/E systems without any loss of data, and without the need for extreme user involvement. Natural communication means (e. g., speaking, gesturing) have to be used to exteriorize the concepts. In handling, manipulation and further elaboration of concepts, we need smart, knowledge-intensive software agents...|$|R
40|$|This {{tutorial}} {{explains a}} typical data mining algorithm, i. e., ID 3 and shows some examples. Knowledge for Making Decisions (classifications) There are three {{ways in which}} humans acquire knowledge: {{learning by being told}} learning by observation and discovery; and learning by induction. The knowledge engineer acquires knowledge from the domain expert by the first two means. These means may be augmented by software, but not automated. This process is very time consuming averaging between 2 and 5 rules per person day! The latter means however may be automated and is a most efficient method <b>of</b> capturing <b>knowledge.</b> Knowledge acquisition is the activity whereby the machine acquires expert knowledge in order to solve some specific problems. It results in a knowledge base. Probably, knowledge acquisition is the most difficult aspect in developing an expert system because experts are more likely to know how to solve a particular problem under certain circumstances rather than saying how to solve problems under various circumstances. Expert systems need large <b>chunks</b> <b>of</b> <b>knowledge</b> to achieve high levels of performances, and the process to obtain knowledge from experts is tedious and time-consuming; this impasse is universally known as Feigenbaum bottleneck (see figure 1). To circumvent this problem, the research believes that: The only realistic approach to the knowledge acquisition bottleneck is to automate the process (Quinlan, 1987) ...|$|R
40|$|This paper {{presents}} {{results of}} a research program into the utilisation of printed material as a knowledge representation in Knowledge Based Systems. Knowledge Based Systems are generally unable to explain or justify their behaviour, and we attribute this to their general lack <b>of</b> suitable <b>knowledge</b> in a suitable format. This research program is evaluating the representation of printed material using hypertext and hypermedia technologies to provide a navigable hyperspace; using explicit representations <b>of</b> the <b>chunks</b> <b>of</b> the domain <b>knowledge</b> as found in the printed material to guide the navigation process...|$|R
40|$|Objectives: As in {{software}} product lifecycle, the effort spent in maintaining medical knowl edge in guidelines can be reduced, if modularization, formalization and tracking <b>of</b> domain <b>knowledge</b> are employed across the guideline development phases. Methods: We propose to exploit and combine knowledge templates with medical background knowledge from existing thesauri {{in order to}} produce reusable building blocks used in guideline development. These tem- plates enable easier guideline formalization, by describing how <b>chunks</b> <b>of</b> medical <b>knowledge</b> can be combined into more complex ones and how they are linked to a textual representation. Results: By linking our ontology used in guideline formalization with existing thesauri, we can use compilations <b>of</b> thesauri <b>knowledge</b> as building blocks for modeling and maintaining the content of a medical guideline. Conclusions: Our paper investigates whether medical knowledge acquired from several medical thesauri can be molded on a guideline pattern, such that it supports building of executable models of guidelines. © 2009 Schattauer...|$|R
