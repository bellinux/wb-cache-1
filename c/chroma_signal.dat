14|14|Public
2500|$|... 8-pin DIN {{connector}} containing composite video output, separate Y/C outputs {{and sound}} input/output. Beware {{that this is}} the 262° (horseshoe) version of the plug, not the 270° circular version. Early C64 units (with motherboard Assy 326298) use a 5-pin DIN connector that carries composite video and luminance signals, but lacks a <b>chroma</b> <b>signal.</b>|$|E
5000|$|... 6AR8, 6JH8, 6ME8 - Analog {{television}} <b>chroma</b> <b>signal</b> demodulators used {{in color}} TV receivers ...|$|E
50|$|C is the <b>chroma</b> <b>signal,</b> {{which carries}} the {{chrominance}} - or coloring-in - of the picture. This signal contains both the saturation and the hue of the video.|$|E
40|$|A {{method for}} obtaining {{electronic}} <b>chroma</b> <b>signals</b> {{with a single}} scanning-type image device is described. A color multiplexed light signal is produced using an arrangement of dichroic filter stripes. In the particular system described, a two layer filter is used to color modulate external light which is then detected by an image pickup tube. The resulting time division multiplexed electronic signal from the pickup tube is converted by a decoder into a green color signal, and a single red-blue multiplexed signal, which is demultiplexed to produce red and blue color signals. The three primary color signals can be encoded as standard NTSC color signals...|$|R
50|$|Dot crawl can {{be greatly}} reduced {{by using a}} good comb filter in the {{receiver}} to separate the encoded chrominance signal from the luminance signal. When the NTSC standard was adopted in the 1950s, TV engineers realized that it should theoretically be possible to design a filter to properly separate the luminance and <b>chroma</b> <b>signals.</b> However, the vacuum tube-based electronics of the time did not permit any cost-effective method of implementing a comb filter. Thus, the early color TVs used only notch filters, which cut the luminance off at 3.5 MHz. This effectively reduced the luminance bandwidth (normally 4 MHz) {{to that of the}} chroma, causing considerable color bleed. By the 1970s, TVs had begun using solid-state electronics and the first comb filters appeared. However, they were expensive and only high-end models used them, while most color sets continued to use notch filters.|$|R
50|$|It {{was then}} {{forbidden}} for broadcasters to transmit the <b>chroma</b> burst <b>signal,</b> until the designated day, 1 March 1975. The broadcasters {{were allowed to}} experiment with transmitting colour signals in the picture area, and get their transmission up and running while people who had already bought colour TV sets could only watch the shows {{in black and white}} monochrome. There were some people who built a circuit to circumvent this, where they would synchronise the chrominance decoding oscillator manually.|$|R
5000|$|... 8-pin DIN {{connector}} containing composite video output, separate Y/C outputs {{and sound}} input/output. Beware {{that this is}} the 262° (horseshoe) version of the plug, not the 270° circular version. Early C64 units (with motherboard Assy 326298) use a 5-pin DIN connector that carries composite video and luminance signals, but lacks a <b>chroma</b> <b>signal.</b>|$|E
5000|$|Flat fields, {{a signal}} {{consisting}} {{of nothing but}} a specific color (typically white, black, a shade of gray, {{or one of the}} primary colors (red, green, and blue) at maximum saturation). A red field is especially important in PAL applications, as it is the [...] "red difference" [...] portion of the <b>chroma</b> <b>signal</b> whose phase alternates every line; the red field should appear as a solid block of color, with no visible [...] "bands" [...] going across the screen.|$|E
50|$|So {{to extract}} U, a {{synchronous}} demodulator is utilized, which uses the subcarrier to briefly gate (sample) the chroma every 280 nanoseconds, {{so that the}} output is only a train of discrete pulses, each having an amplitude {{that is the same}} as the original U signal at the corresponding time. In effect, these pulses are discrete-time analog samples of the U signal. The pulses are then low-pass filtered so that the original analog continuous-time U signal is recovered. For V, a 90 degree shifted subcarrier briefly gates the <b>chroma</b> <b>signal</b> every 280 nanoseconds, and the rest of the process is identical to that used for the U signal.|$|E
40|$|The {{extraction}} of local tempo and beat information from audio recordings constitutes a challenging task, particularly for music that reveals significant tempo variations. Furthermore, {{the existence of}} various pulse levels such as measure, tactus, and tatum often makes the determination of absolute tempo problematic. In this paper, we present a robust mid-level representation that encodes local tempo information. Similar to the well-known concept of cyclic chroma features, where pitches differing by octaves are identified, we introduce the concept of cyclic tempograms, where tempi differing by a power of two are identified. Furthermore, we describe how to derive cyclic tempograms from music signals using two different methods for periodicity analysis and finally sketch some applications to tempo-based audio segmentation. Index Terms — tempo, tempogram, <b>chroma,</b> music <b>signals,</b> audio segmentatio...|$|R
25|$|The {{first two}} series were {{recorded}} and screened {{in black and}} white, while Series 3 to 9 were recorded and screened in colour. Even so, one episode in Series 3, Room at the Bottom, formerly only survived {{in black and white}} and remains on the official DVDs in this form. This episode has benefited from colour recovery technology, using a buried colour <b>signal</b> (<b>chroma</b> dots) in the black-and-white telerecording to restore the episode back to colour and was transmitted on 13 December 2008 on BBC Two.|$|R
50|$|The Commodore 1701 and 1702 were 13-inch (33 cm) color {{monitors}} for the C64 which {{accepted as}} input either composite video or separate chrominance and luminance signals, {{similar to the}} S-Video standard, for superior performance with the C64 (or other devices capable of outputting a separated signal). Other monitors available included the 1802 and 1902. Introduced in 1986, the 1802 featured separate <b>chroma</b> and luma <b>signals,</b> {{as well as a}} composite green screen mode suitable for the C-128's 80 column screen. The 1902 had a true RGBI 80-column mode compatible with IBM PCs.|$|R
50|$|Multi-standard video {{monitors}} {{were already}} in use in Europe to accommodate broadcast sources in PAL, SECAM, and NTSC video formats. The heterodyne color-under process of U-Matic, Betamax & VHS lent itself to minor modification of VCR players to accommodate NTSC format cassettes. The color-under format of VHS uses a 629 kHz subcarrier while U-Matic & Betamax use a 688 kHz subcarrier to carry an amplitude modulated <b>chroma</b> <b>signal</b> for both NTSC and PAL formats. Since the VCR was ready to play the color portion of the NTSC recording using PAL color mode, the PAL scanner and capstan speeds had to be adjusted from PAL's 50 Hz field rate to NTSC's 59.94 Hz field rate, and faster linear tape speed.|$|E
50|$|The {{original}} modulating {{signal was}} then {{compared with the}} amplified return signal from the secondary emission process, producing a net output that varied in phase by the difference in position between the estimated and real position of the beam. This phase signal was then sent into the conventional color decoder, adjusting the chroma on the fly. The writing beam, positioned to sweep the spaces between the indexes while the pilot beam was on them, received the <b>chroma</b> <b>signal</b> so that its power was modulated to produce the correct amounts of color when it {{was on top of}} those stripes. By the time it reached the index stripe the pilot's modulating signal would be at its minimum, and the strong signal given off by the writing beam would simply be ignored.|$|E
5000|$|Video codecs seek to {{represent}} a fundamentally analog data set in a digital format. Because of the design of analog video signals, which represent luminance ("luma") and color information (chrominance, [...] "chroma") separately, a common first step in image compression in codec design is {{to represent}} and store the image in a YCbCr color space. The conversion to YCbCr provides two benefits: first, it improves compressibility by providing decorrelation of the color signals; and second, it separates the luma signal, which is perceptually much more important, from the <b>chroma</b> <b>signal,</b> which is less perceptually important and which can be represented at lower resolution to achieve more efficient data compression. It is common to represent the ratios of information stored in these different channels {{in the following way}} Y:Cb:Cr. Refer to the following article for more information: Chroma subsampling.|$|E
40|$|Colour {{variation}} is widespread among lizard species {{and has been}} interpreted as an adaptive compromise between conflicting selective pressures arising from antipredatory and thermoregulatory requirements and sexual selection. In many species colour is used in social signalling and may serve as an honest signal of individual quality. Studies on several species have shown that characteristics of colour {{may be related to}} dominance status, aggression and immune response. We studied aspects of colour (e. g. UV and blue chroma of the blue lateral spot and throat colour) in two populations of Podarcis siculus in Italy and investigated if they were correlated to other individual traits that are related to fitness. To this end we measured the SVL, body mass, body condition and the immune response with the delayed cutaneous hypersensitivity (DCH) test. We also assessed the level of sexual dichromatism of the two populations. Preliminary results suggest that certain colour traits, like UV <b>chroma,</b> may <b>signal</b> aspects of individual quality in Podarcis siculus...|$|R
40|$|Video coding in the YCbCr {{color space}} {{has been widely}} used, since it is {{efficient}} for compression, but it can result in color distortion due to conversion error. Meanwhile, coding in RGB color space maintains high color fidelity, having the drawback of a substantial bit-rate increase with respect to YCbCr coding. Cross-component prediction (CCP) efficiently compresses video content by decorrelating color components while keeping high color fidelity. In this scheme, the <b>chroma</b> residual <b>signal</b> is predicted from the luma residual signal inside the coding loop. This paper gives {{a description of the}} CCP scheme from several point-of-view, from theoretical background to practical implementation. The proposed CCP scheme has been evaluated in standardization communities and adopted into H. 265 /HEVC Range Extensions. Experimental results show significant coding performance improvements both for natural and screen content video, while the quality of all color components is maintained. The average coding gains for natural video are 17 % and 5 % bit-rate reduction in case of intra coding, and 11 % and 4 % in case of inter coding for RGB and YCbCr coding, respectively, while the average increment of encoding and decoding times in the HEVC reference software implementation are 10 % and 4 %, respectively...|$|R
5000|$|The high tape-to-head speed {{created by}} the {{rotating}} head results in a far higher bandwidth than could be practically achieved with a stationary head. VHS tapes have approximately 3 MHz of video bandwidth and 400 kHz of chroma bandwidth. The luminance (black and white) portion of the video is recorded as a frequency modulated, with a down-converted [...] "color under" [...] <b>chroma</b> (color) <b>signal</b> recorded directly at the baseband. Each helical track contains a single field ('even' or 'odd' field, equivalent to half a frame) encoded as an analog raster scan, similar to analog TV broadcasts. The horizontal resolution is 240 lines per picture height, or about 320 lines across a scan line, and the vertical resolution (the number of scan lines) {{is the same as}} the respective analog TV standard (576 for PAL or 486 for NTSC; usually, somewhat fewer scan lines are actually visible due to overscan). In modern-day digital terminology, NTSC VHS is roughly equivalent to 333×480 pixels luma and 40×480 chroma resolutions (333×480 pixels=159,840 pixels or 0.16MP (1/6 of a MegaPixel))., while PAL VHS offers the equivalent of about 335×576 pixels luma and 40×240 chroma (the vertical chroma resolution of PAL is limited by the PAL color delay line mechanism).|$|R
50|$|Though most of {{the pattern}} is removed from PAL and NTSC-encoded signals with a comb filter (designed to {{segregate}} the two signals where the luma spectrum may overlap into the spectral space used by the chroma) by modern displays, some can still be left {{in certain parts of}} the picture. Such parts are usually sharp edges on the picture, sudden color or brightness changes along the picture or certain repeating patterns, such as a checker board on clothing. Dot crawl patterns can be completely removed by connecting the display to the signal source through a cable or signal format different from composite video (yellow RCA cable) or a coaxial cable, such as S-Video, which carries the <b>chroma</b> <b>signal</b> in a separate band all its own, leaving the luma to use its entire band, including the usually empty parts when they are needed. FM SECAM is a continuous spectrum, so unlike PAL and NTSC even a perfect digital comb filter could not entirely separate SECAM Colour and Luminance.|$|E
50|$|PenTile RGBG layout used in AMOLED and plasma {{displays}} uses green pixels interleaved with alternating red {{and blue}} pixels. The human eye is most sensitive to green, especially for high resolution luminance information. The green subpixels are mapped to input pixels on a one-to-one basis. The {{red and blue}} subpixels are subsampled, reconstructing the <b>chroma</b> <b>signal</b> at a lower resolution. The luminance signal is processed using adaptive subpixel rendering filters to optimize reconstruction of high spatial frequencies from the input image, wherein the green subpixels provide {{the majority of the}} reconstruction. The red and blue subpixels are capable of reconstructing the horizontal and vertical spatial frequencies, but not the highest of the diagonal. Diagonal high spatial frequency information in the red and blue channels of the input image are transferred to the green subpixels for image reconstruction. Thus the RG-BG scheme creates a color display with one third fewer subpixels than a traditional RGB-RGB scheme but with the same measured luminance display resolution. This is similar to the Bayer filter commonly used in digital cameras.|$|E
5000|$|Japanese {{broadcast}} {{engineers had}} studied {{many kinds of}} HDTV broadcasts for long time. At first {{it was thought that}} SHF, EHF or optic fiber would have to be used to transmit HDTV due to the high bandwidth of the signal, and HLO-PAL would be used for terrestrial broadcast. HLO-PAL is a conventionally constructed composite signal (Y+C, like NTSC and PAL). It uses a Phase Alternating by Line with Half-Line Offset carrier encoding of the wideband/narrowband chroma components. Only the very lowest part of the wideband chroma component overlapped the high-frequency chroma. The narrowband chroma was completely separated from luminance. PAF, or Phase Alternating by Field (like the first NTSC color system trial) was also experimented with, and gave much better decoding results, but NHK abandoned all composite encoding systems. Because of the use of satellite transmission, Frequency modulation(FM) should be used with power-limitation problem. FM incurs triangular noise, so if a sub-carrierred composite signal is used with FM, demodulated <b>chroma</b> <b>signal</b> has more noise than luminance. Because of this they studied and decided to use Y/C component emission for satellite. At one stage, it seemed that FCFE (Frame Conversion Fineness Enhanced), I/P conversion compression system, would be chosen, but MUSE was adopted in the end.|$|E
5000|$|The {{first two}} series were {{recorded}} and screened {{in black and}} white, while Series 3 to 9 were recorded and screened in colour. Even so, one episode in Series 3, Room at the Bottom, formerly only survived {{in black and white}} and remains on the official DVDs in this form. This episode has benefited from colour recovery technology, using a buried colour <b>signal</b> (<b>chroma</b> dots) in the black-and-white telerecording to restore the episode back to colour and was transmitted on 13 December 2008 on BBC Two.Dad's Army is less affected than most from the wiping of videotape, but three second-series episodes remain missing - episode 9 [...] "The Loneliness of the Long Distance Walker", episode 11 [...] "A Stripe for Frazer" [...] and episode 12 [...] "Under Fire". Two further Series 2 episodes were believed lost until 2001. Two of the three missing episodes have since been performed as part of the latest stage show.|$|R
50|$|However, {{this color}} space {{conversion}} is lossy, particularly obvious in crosstalk from the luma to the chroma-carrying wire, and vice versa, in analogue equipment (including RCA connectors to transfer a digital signal, as all they carry is analogue composite video, which is either YUV, YIQ, or even CVBS). Furthermore, NTSC and PAL encoded color signals {{in a manner}} that causes high bandwidth <b>chroma</b> and luma <b>signals</b> to mix with each other in a bid to maintain backward compatibility with black and white television equipment, which results in dot crawl and cross color artifacts. When the NTSC standard was created in the 1950s, this was not a real concern since the quality of the image was limited by the monitor equipment, not the limited-bandwidth signal being received. However today′s modern television is capable of displaying more information than is contained in these lossy signals. To keep pace with the abilities of new display technologies, attempts were made since the late 1970s to preserve more of the Y′UV signal while transferring images, such as SCART (1977) and S-Video (1987) connectors.|$|R
40|$|Whether it`s photography, {{computer}} graphics, publishing, or video; each medium has {{a defined}} color space, or gamut, which defines the extent that a given set of RGB colors can be mixed. When converting from one medium to another, an image must go through some form of conversion which maps colors into the destination color space. The conversion process isn`t always straight forward, easy, or reversible. In video, two common analog composite color spaces are Y`tjv (used in PAL) and Y`IQ (used in NTSC). These two color spaces have {{been around since the}} beginning of color television, and are primarily used in video transmission. Another analog scheme used in broadcast studios is Y`, R`-Y`, B`-Y` (used in Betacam and Mll) which is a component format. Y`, R`-Y`,B`-Y` maintains the color information of RGB but in less space. From this, the digital component video specification, ITU-Rec. 601 - 4 (formerly CCIR Rec. 601) was based. The color space for Rec. 601 is symbolized as Y`CbCr. Digital video formats such as DV, Dl, Digital-S, etc., use Rec. 601 to define their color gamut. Digital composite video (for D 2 tape) is digitized analog Y`UV and is seeing decreased use. Because so much information is contained in video, segments of any significant length usually require some form of data compression. All of the above mentioned analog video formats are a means of reducing the bandwidth of RGB video. Video bulk storage devices, such as digital disk recorders, usually store frames in Y`CbCr format, even if no other compression method is used. Computer graphics and computer animations originate in RGB format because RGB must be used to calculate lighting and shadows. But storage of long animations in RGB format is usually cost prohibitive and a 30 frame-per-second data rate of uncompressed RGB is beyond most computers. By taking advantage of certain aspects of the human visual system, true color 24 -bit RGB video images can be compressed with minimal loss of visual information. For example, humans `see` more white-to-black (luminance) detail then red, green, or blue color detail. Also, the eye is most sensitive to green colors. Taking advantage of this, both composite and component video allocates more bandwidth for the luma (Y`) <b>signal</b> than the <b>chroma</b> <b>signals.</b> Y` 611 is composed of 59 % green`, 30 % red`, and 11 % blue` (prime symbol denotes gamma corrected colors). This luma signal also maintains compatibility with black and white television receivers. Component digital video converts R`G`B` signals (either from a camera or a computer) to a monochromatic brightness signal Y` (referred here as luma to distinguish it from the CIE luminance linear- light quantity), and two color difference signals Cb and Cr. These last two are the blue and red signals with the luma component subtracted out. As you know, computer graphic images are composed of red, green, and blue elements defined in a linear color space. Color monitors do not display RGB linearly. A linear RGB color space image must be gamma corrected to be displayed properly on a CRT. Gamma correction, which is approximately a 0. 45 power function, must also be employed before converting an RGB image to video color space. Gamma correction is defined for video in the international standard: ITU-Rec. BT. 709 - 4. The gamma correction transform is the same for red, green, and blue. The color coding standard for component digital video and high definition video symbolizes gamma corrected luma by Y`, the blue difference signal by Cb (Cb = B` -Y`), and the red color difference signal by Cr (Cr = R` - Y`). Component analog HDTV uses Y`PbPr. To reduce conversion errors, clip in R`G`B`, not in Y`CbCr space. View video on a video monitor, computer monitor phosphors are wrong. Use a large word size (double precision) to avoid warp around, the 0232 n round the results to values between 0 and 255. And finally, recall that multiplying two 8 - bit numbers results in a 16 -bit number, so values need to be clipped to 8 -bits...|$|R
5000|$|Like VHS, the S-VHS format uses a color under {{modulation}} scheme. [...] S-VHS improves luminance (luma) resolution {{by increasing}} luminance bandwidth. [...] Increased bandwidth is {{possible because of}} increased luminance carrier from 3.4 megahertz (MHz) to 5.4 MHz. [...] Increased luminance bandwidth produces a 60% improvement in (luminance) picture detail, or a horizontal resolution of 420 vertical lines per picture height - versus VHS's 240 lines. The often quoted horizontal resolution of [...] "over 400" [...] means S-VHS captures greater picture detail than even NTSC analog cable and broadcast TV, which is limited to about 330 television lines (TVL). In practice, when time shifting TV programs on S-VHS equipment, the improvement over VHS is quite noticeable. Yet, the trained eye can easily spot the difference between live television and a S-VHS recording of it. This is because S-VHS does not improve other key aspects of the video signal, particularly the chromanance (<b>chroma)</b> <b>signal.</b> In VHS, the chroma carrier is both severely bandlimited and rather noisy, a limitation that S-VHS does not address. Poor color resolution was a deficiency shared by S-VHS's contemporaries, such as Hi8 and ED-Beta - {{all of which were}} limited to 0.4 megahertz or 30 TVL resolution.|$|E
5000|$|The two FM audio {{channels}} {{occupied the}} disc spectrum at 2.3 and 2.8 MHz on NTSC formatted discs and each channel had a 100 kHz FM deviation. The FM audio carrier frequencies {{were chosen to}} minimize their visibility in the video image, so that even with a poorly mastered disc, audio carrier beats in the video {{will be at least}} ‑35 dB down, and thus, invisible. Due to the frequencies chosen, the 2.8 MHz audio carrier (Right Channel) and the lower edge of the <b>chroma</b> <b>signal</b> are very close together and if filters are not carefully set during mastering, there can be interference between the two. In addition, high audio levels combined with high chroma levels can cause mutual interference, leading to beats becoming visible in highly saturated areas of the image. To help deal with this, Pioneer decided to implement the CX Noise Reduction System on the analog tracks. By reducing the dynamic range and peak levels of the audio signals stored on the disc, filtering requirements were relaxed and visible beats greatly reduced or eliminated. The CX system gives a total NR effect of 20 dB, but in the interest of better compatibility for non-decoded playback, Pioneer reduced this to only 14 dB of noise reduction (the RCA CED system used the [...] "original" [...] 20 dB CX system). This also relaxed calibration tolerances in players and helped reduce audible pumping if the CX decoder was not calibrated correctly.|$|E
40|$|This paper {{describes}} an audio music classification algorithm {{submitted to the}} MIREX 2011. A k-NN classifier employs a cosine-based similarity measure of scaled versions of the periodicity vectors that are extracted from the audio signal. It be considered as rhythmic similarity measure. 1. 1 Pre-analysis The constant Q transform (CQT) of the audio signal is calculated on the whole input signal, using 12 bins per octave, with 25 Hz and 5 kHz minimum/maximum frequencies respectively (Q value equals to 17), and a Hanning window with half overlap. Frequency bins are aligned to the western scale musical pitches. The frequency bins are rescaled by bicubic interpolation/decimation to have equal frames per time unit (200 frames/s), resulting the log-frequency spectro-{ S} where i and f denote the time and fre-gram S = i, f quency bin indices respectively. 1. 2 Chroma and Filterbank Energies The percussive/harmonic separation algorithm presented in [1] {{is applied to the}} CQT of the <b>signal.</b> <b>Chroma</b> vectors and the energies of 8 triangular filters in the mel scale are calculated from the harmonic/percussive part of the signal respectively. 2. PERIODICITY ANALYSIS Feature vectors are differentiated and convolved with a bank of resonators as in [2] in the range of [40, 250] bmp, fl ch resulting TG and TG periodicity vectors for filterbank energies and chroma features respectively. To estimate the global periodicity vector T for the whole ex-fl ch cerpt TG and TG are summed across all segments and then multiplied: gl 3. SIMILARITY MEASURE The similarity measure of an audio excerpt with periodicity vector...|$|R
40|$|This paper {{describes}} a beat tracking system {{submitted to the}} MIREX 2011 and {{is an extension of}} the work presented in [1]. Two main feature classes are extracted by utilizing percussive/harmonic separation of the audio signal, in order to extract filterbank energies and chroma features from the respective components. Periodicity analysis is carried out by the convolution of feature sequences with a bank of resonators. Target tempo is estimated from the resulting periodicity vector by incorporating metrical relations knowledge. Beat tracking involves the computation of the beat saliencies derived from the resonators responses and defines a distance measure between candidate beats locations. A dynamic programming algorithm is adopted to the find the optimal “path ” of beats. 1. 1 Pre-analysis 1. FEATURE EXTRACTION The constant Q transform (CQT) of the audio signal is calculated on the whole input signal, using 12 bins per octave, with 25 Hz and 5 kHz minimum/maximum frequencies respectively (Q value equals to 17), and a Hanning window with half overlap. Frequency bins are aligned to the western scale musical pitches. The frequency bins are rescaled by bicubic interpolation/decimation to have equal frames per time unit (200 frames/s), resulting the log-frequency spectro-{ S} where i and f denote the time and fre-gram S = i, f quency bin indices respectively. 1. 2 Chroma and Filterbank Energies The percussive/harmonic separation algorithm presented in [2] is applied to the CQT of the <b>signal.</b> <b>Chroma</b> vectors and the energies of 8 triangular filters in the mel scale are calculated from the harmonic/percussive part of the signal respectively. We denote filterbank energies as x and chroma features as x ch f...|$|R

