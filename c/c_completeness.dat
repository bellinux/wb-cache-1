1|37|Public
40|$|The Propositional CalculusPropositional Connectives. Truth TablesTautologies Adequate Sets of Connectives An Axiom System for the Propositional Calculus Independence. Many-Valued LogicsOther AxiomatizationsFirst-Order Logic and Model TheoryQuantifiersFirst-Order Languages and Their Interpretations. Satisfiability and Truth. ModelsFirst-Order TheoriesProperties of First-Order Theories Additional Metatheorems and Derived Rules Rule <b>C</b> <b>Completeness</b> Theorems First-Order Theories with EqualityDefinitions of New Function Letters and Individual Constants Prenex Normal Forms Isomorphism of Interpretat...|$|E
40|$|A {{well-known}} {{generating function}} of the classical Laguerre polynomials was recently rederived probabilistically by Lee. In this paper, some other (presumably new) generating functions for the Laguerre polynomials are derived by means of probabilistic considerations. A direct (analytical) proof {{of each of these}} generating functions is also presented for the sake of <b>completeness.</b> (<b>C)</b> 1999 Elsevier Science Ltd. All rights reserved...|$|R
40|$|Abstract. Using Local Residues and the Duality Principle {{a multidimensional}} {{variation}} of the completeness theorems by T. Carleman and A. F. Leontiev is proven for the space of holomorphic functions defined on a suitable open strip Tα ⊂ <b>C</b> 2. The <b>completeness</b> theorem is {{a direct consequence of}} the Cauchy Residue Theorem in a torus. With suitable modifications the same result holds in Cn...|$|R
30|$|The {{evaluation}} {{has been}} based on the quality indicators developed within the ILCD handbook (EC-JRC 2010 a, b, 2011): Technological representativeness (TeR), Geographical representativeness (GR), Time-related representativeness (TiR), <b>Completeness</b> (<b>C),</b> Precision/Uncertainty (P) and Methodological appropriateness and consistency (M). Each of those has been evaluated according to the degree of accomplishment of the criterion, from 1 (very good, so meets the criterion to a very high degree) to 5 (very poor, so does not at all meet the criterion).|$|R
40|$|Abstract—Combining goal-oriented and {{use case}} {{modeling}} {{has been shown}} as an effective method of requirements engineering. To ensure the quality of such modeled artifacts, a conceptual foundation is needed to govern the process of determining what types of artifacts to be modeled, and how they should be specified and analyzed for 3 <b>Cs</b> problems (<b>completeness,</b> consistency and correctness). However, such a foundation is missing in current goal-use case integration approaches. In this paper, we present GUIMeta, a meta-model, to address this problem. GUIMeta consists of three layers. The artifact layer defines the semantics and classification of artifacts and their relationships. The specification layer offers specification rules for each artifact class. The ontology layer allows semantics to {{be integrated into the}} entire model. Our promising evaluation shows the suitability of GUIMeta in modeling goals and use cases...|$|R
40|$|Property <b>C,</b> that is, <b>completeness</b> {{of the set}} of {{products}} of some solutions to Sturm-Liouville equations is proved. Several uniqueness theorems for various inverse scattering problems are obtained in a very simple way {{with the help of}} property C. Two classical uniqueness results for inverse scattering problem on the half-axis and for the inverse spectral problem are proved in a very short new way. Earlier the author introduced property C for partial differential equations and used it extensively for proving uniqueness theorems for many inverse problems...|$|R
40|$|Property <b>C</b> {{stands for}} <b>completeness</b> {{of the set}} of {{products}} of solutions to homogeneous linear differential equations. property C is proved in various formulations for Schrödinger operators. Many applications of this property to inverse problems and inverse scattering problems are given. It is shown {{what part of the}} fixed-energy phase shifts determines a compactly supported potential uniquely. It is shown that the Newton-Sabatier method is not really an inversion method but a parameter-fitting procedure and it is proved that this procedure cannot recover a generic potential, in particular, any potential which is not analytic in a neighborhood of the positive real axis...|$|R
40|$|In this paper, we {{introduce}} {{the logic of}} a control action S 4 F and the logic of a continuous control action S 4 C on the state space of a dynamical system. The state space here is represented by a topological space (X; T) and the control action by a function f from X to X. We present an intended topological semantics and a Kripke semantics, give both a Hilbert-style and Gentzen-style axiomatization for S 4 F and S 4 <b>C,</b> prove <b>completeness</b> with respect to both semantics {{as well as a}} cut-elimination for the corresponding sequent calculi and show the logics to be decidable. 1 Introduction Let L 2 be the propositional modal language generated from a countable set PV of propositional variables, the propositional constant ? (falsum), the propositional connective ! (implication), and the modal operator 2. Let L 2 a be the propositional language extending L 2 which includes, in addition, a new modal operator [a]. Let S 4 denote the subset of L 2 a consisting of all formulas derivable from a standard axi [...] ...|$|R
40|$|A b s t r a <b>c</b> t. The <b>completeness</b> theorem of equational {{logic of}} Birkhoff asserts the {{coincidence}} of the model-theoretic and prooftheoretic consequence relations. Goguen and Meseguer, giving a sound and adequate system of inference rules for many-sorted deduction, founded ultimately on the congruences on Hall algebras, generalized the completeness theorem of Birkhoff to the completeness theorem of many-sorted equational logic. In this paper, after simplifying the specification of Hall algebras {{as given by}} Goguen-Meseguer, we obtain another many-sorted equational calculus from which we prove that the inference rules of abstraction and concretion due to Goguen-Meseguer are derived rules. Finally, after defining the Bénabou algebras {{for a set of}} sorts...|$|R
40|$|A wide {{spectrum}} of certificate revocation mechanisms is currently in use. A number {{of them have been}} proposed by standardisation bodies, while some others have originated from academic or private institutions. What is still missing is a systematic and robust framework for the sound evaluation of these mechanisms. We present a mechanism-neutral framework for the evaluation of certificate status information (CSI) mechanisms. These mechanisms collect, process and distribute CSI. A detailed demonstration of its exploitation is also provided. The demonstration is mainly based on the evaluation of Certificate Revocation Lists, {{as well as of the}} Online Certificate Status Protocol. Other well-known CSI mechanisms are also mentioned for <b>completeness.</b> (<b>C)</b> 2003 Elsevier B. V. All rights reserved. status: publishe...|$|R
40|$|Abstract: In Smith and Brogaard (2000, 2001) {{the notion}} of {{partition}} is introduced as a generalization of David Lewis’s (1991) conception of a class as the mereological sum of its singletons. A partition is a mereological sum of labeled cells. Partitions thus conceived are involved in all human mapping, classifying, listing and theorizing activity. We here provide a more detailed formal characterization of partitions. We define notions of wellformedness and truth for partitions and we classify partitions along three axes: (a) degree of correspondence between partition cells and objects in reality; (b) degree of how well a partition represents the mereological structure of the domain it is projected onto; and (<b>c)</b> degree of <b>completeness</b> and exhaustiveness. 1...|$|R
30|$|The {{evaluation}} {{has been}} based on the quality indicators developed within the ILCD handbook (EC-JRC, 2010 a, 2010 b, 2011): Technological representativeness (TeR), Geographical representativeness (GR), Time-related representativeness (TiR), <b>Completeness</b> (<b>C),</b> Precision/Uncertainty (P) and Methodological appropriateness and consistency (M). Each of those has been evaluated according to the degree of accomplishment of the criterion (from 1 to 5), and an overall DQR of the datasets has been calculated by summing up the achieved quality rating for each of the quality criteria indicator, divided {{by the total number of}} considered indicators, as described in Garraín et al. Background qualitative analysis of the European Reference Life Cycle Database (ELCD) energy datasets – Part I: Fuel datasets. Springer Plus - Submitted in 2014.|$|R
40|$|Despite {{widespread}} use of communicable disease surveillance data to inform public health intervention and control measures, the reporting completeness of the notifi-able disease surveillance system remains incompletely assessed. Therefore, we conducted a comprehensive study of reporting completeness with an analysis of 53 diseases reported by 8 health care systems across North Carolina, USA, during 1995 – 1997 and 2000 – 2006. All patients who were assigned an International Classifi cation of Diseases, 9 th Revision, Clinical Modifi cation, diagnosis code for a state-required reportable communicable disease were matched to surveillance records. We used logistic regression techniques to estimate reporting completeness by disease, year, and health care system. The completeness of reporting varied among the health care systems from 2 % to 30 % and improved over time. Disease-specifi <b>c</b> reporting <b>completeness</b> proportions ranged from 0 % to 82 %, but were generally low even for diseases with great public health importance and opportunity for interventions. Surveillance has been the cornerstone of public health since the US Congress authorized the Public Health Service to collect morbidity data for cholera, smallpox, plague, and yellow fever in 1878. Currently, all states conduct notifiable disease surveillance following guidelines from the Centers for Disease Control and Prevention (CDC) and th...|$|R
40|$|We {{describe}} the algorithm that selects the main sample of galaxies for spectroscopy in the Sloan Digital Sky Survey from the photometric {{data obtained by}} the imaging survey. Galaxy photometric properties are measured using the Petrosian magnitude system, which measures flux in apertures determined by {{the shape of the}} surface brightness profile. The metric aperture used is essentially independent of cosmological surface brightness dimming, foreground extinction, sky brightness, and the galaxy central surface brightness. The main galaxy sample consists of galaxies with r-band Petrosian magnitude r < 17. 77 and r-band Petrosian half-light surface brightness < 24. 5 magnitudes per square arcsec. These cuts select about 90 galaxy targets per square degree, with a median redshift of 0. 104. We carry out a number of tests to show that (a) our star-galaxy separation criterion is effective at eliminating nearly all stellar contamination while removing almost no genuine galaxies, (b) the fraction of galaxies eliminated by our surface brightness cut is very small (0. 1 %), (<b>c)</b> the <b>completeness</b> of the sample is high, exceeding 99 %, and (d) the reproducibility of target selection based on repeated imaging scans is consistent with the expected random photometric errors. (abridged) Comment: 42 pages, including 12 figures. Accepted for September 2002 A...|$|R
40|$|Body {{shortening}} {{was observed}} in the pearlfish Carapus homei during metamorphosis. The tenuis larva at first possessed a suite of osseous vertebral bodies of similar length. The reduction in both the number and size of vertebrae followed increasing decalcification, degeneration of organic tissue and shortening. This involved a complete degradation and disappearance of the caudal tip vertebrae, {{and there was a}} reduction in the size of most of the remaining vertebrae. The further development of the vertebrae began with ossification of the neural and haemal arches before that of the vertebral body. This second part of the development followed a gradient: a gradual decreases towards the caudal tip {{in the size of the}} vertebrae and their <b>completeness.</b> (<b>C)</b> 2004 The Fisheries Society of the British Isles. Peer reviewe...|$|R
40|$|Dewey's {{forthcoming}} AGI- 12 paper [1] (congratulations Daniel) proves {{a result}} about when preferences {{can be represented}} by utility functions. His result bears a strong resemblance to the von Neumann-Morgenstern Theorem [2, 3, 4]. But he does not mention that theorem which piqued my curiosity to investigate the relation between these two results. The investigation gave me {{a clearer understanding of}} both results, so I am sharing it in this note. The von Neumann-Morgenstern Theorem Define a set of mutually exclusive outcomes Oi, i = 1, 2, 3, [...] . and a space L of lotteries as sums Σi pi Oi where Σi pi = 1 and each pi ≥ 0. Define a preference relation ≼ on L including indifference ≈ (please see the references [2, 3, 4] for more detailed explanations). The von Neumann-Morgenstern Theorem says that the preference relation can be represented by a utility function u: L → R mapping lotteries to real numbers (the representation is: l ≼ m ⇔ u(l) ≤ u(m)) if and only if a set of four conditions are true. The utility function is linear in the sense that u(Σi pi Oi) = Σi pi u(Oi). The conditions are: <b>C</b> 1 (<b>Completeness)</b> ∀l, m ∈ L exactly one of l ≺ m, m ≺ l or l ≈ m is true...|$|R
40|$|We {{consider}} incompressible {{flows in}} the rapid-rotation limit of small Rossby number and vanishing Ekman number, in a bounded volume with a rigid impenetrable rotating boundary. Physically the flows are inviscid, almost rigid rotations. We interpret the Coriolis force, modified by a pressure gradient, as a linear operator acting on smooth inviscid incompressible flows in the volume. The eigenfunctions of the Coriolis operator C so defined are the inertial modes (including any Rossby modes) and geostrophic modes of the rotating volume. We show C is a bounded operator and that -iC is symmetric, {{so that the}} Coriolis modes of different frequencies are orthogonal. We prove that the space of incompressible polynomial flows of degree N or less in a sphere is invariant under C. The symmetry of -iC thus implies the Coriolis operator is non-defective on the finite-dimensional space of spherical polynomial flows. This enables us to enumerate the Coriolis modes, and to establish their completeness using the Weierstrass polynomial approximation theorem. The fundamental tool, which is required to establish invariance of spherical polynomial flows under <b>C</b> and <b>completeness,</b> is that {{the solution of the}} polynomial Poisson-Neumann problem, i. e. Poisson's equation with a Neumann boundary condition and polynomial data, in a sphere is a polynomial. We also enumerate the Coriolis modes in a sphere, with careful consideration of the geostrophic modes, directly from the known analytic solution...|$|R
40|$|Abstract This study {{aimed to}} {{describe}} the ideology of: (a) journalists, (b) politicians, and (c) observers/community in framing President Joko Widodo in Suara Merdeka, Kompas, and Republika daily newspapers. The data sources were the three newspapers published in 2016. The data were collected through: (a) literature study, (b) discourse analysis, and (c) in-depth interviews with linguists and mass media experts. The data analysis was carried out using Pan and Kosicki’s framing analysis model. The results show that there are ideological differences among the three media in framing President Joko Widodo. The differences are manifested in the aspects of: (a) syntax, (b) script, (c) theme, and (d) rhetoric. The three media also differ in presenting: (a) news schemes, (b) news <b>completeness,</b> (<b>c)</b> details, (d) lexicon, and (e) completeness of 5 W + 1 H elements in reporting President Joko Widodo. Keywords: frame, ideology, media, framing analysi...|$|R
40|$|For {{collating}} point-source flux measurements {{derived from}} multiple infrared passbands of Spitzer-Space-Telescope data – e. g., channels 1 - 4 of the Infrared Array Camera (IRAC) and channels 1 - 3 of the Multiband Imaging Pho- tometer for Spitzer (MIPS) – {{it is best}} to use the ‘bandmerge’ software developed at the Spitzer Science Center rather than the relatively simple method of general source association (GSA). The former method uses both source positions and positional uncertainties to form a chi-squared statistic that can be thresholded for optimal matching, while the latter method finds nearest neighbors across bands that fall within a user-specified radius of the primary source. Our assertion is supported by our study of <b>completeness</b> (<b>C)</b> vs. reliability (R) for the two methods, which involved MIPS- 24 /IRAC- 1 matches in the SWIRE Chandra Deep Field South. Both methods can achieve C = 98...|$|R
40|$|This report W ~ S prcpared as {{an account}} of work sponsolcd by an a g c x, of the l lnited StatesGoverrlmciii Nsithei ihellni! & StatesGoverninent nor any ayeiicy tht?:oof, nor any of their ernployses, makes anv {{warranty}} express cr rrrlplied or assumes any legal liability or responsibility for tile accuracy, <b>completeness,</b> <b>c)</b> : usefillness of any information, apparatus, product, or PiOCZSS disclosed, or represents that 1;s use wculd not infilnge PI ivaiely owned rights Rzfxoncs herein to any specific coiniil?rcial product, grocess or service by trhde name tradci-raik, mamfacturer or otherwise, does not necess;lrily constitute or impiy Its endorsement. recornitwildation. or fzvoring b y the United Sta!ssGo any aqency thereof I h e vie and opinions of authors expressed 5 erslR do not riac. ?ssarily state or reflect thcse of the United States(Govc-,m;?eiii C I any agency liie: enf ORNL/TM- 10691 Engineering Physics and Mathematics Divisio...|$|R
40|$|Problem {{complexity}} and interest diversity often cause a city {{not able to}} accommodate its population’s needs, among which are the children's needs. It has initiated {{the idea of the}} child-friendly city, which got a positive response from the Indonesian government, proven by the policy of child-friendly city/ regency. Surakarta is one of the cities having a strong commitment to being a child-friendly city; however, the implementation has not been comprehensive to the level of neighborhood unit. Elementary school is an essential social infrastructure for children that should be available at a neighborhood unit. However, problems are still there, such as the capacity of elementary schools that is below the national standard and also the children's less safety and comfort in accessing the schools. This paper assesses the suitability of elementary school as a social infrastructure in supporting a child-friendly Surakarta based on four criteria, namely, (a) the serving capacity of the education facility, (b) the safe and comfortable access, (<b>c)</b> the <b>completeness</b> of the elementary schools, and (d) the prevalent access including for disabled children. The suitability measurement was done by using scoring analysis from the results of the field observation as well as the citizens’ and the children's perceptions. The scoring results have shown that most of the elementary schools in Surakarta are still not suitable with the criteria so that they {{have not been able to}} support Surakarta as a child-friendly city...|$|R
40|$|A {{property}} tester is a fast, randomized algorithm {{that reads}} {{only a few}} entries of the input, {{and based on the}} values of these entries, it distinguishes whether the input has a certain property or is “different ” from any input having this property. Furthermore, we say that a property tester has <b>completeness</b> <b>c</b> and soundness s if it accepts all inputs having the property with probability at least c and accepts “different ” inputs with probability at most s+ o(1). In this thesis we present two property testers for boolean functions on the boolean cube { 0, 1 }n. We summarize our contribution as follows. • We present a new dictatorship test that determines whether the function is a dictator (of the form f(x) = xi for some coordinate i), or a function that is an “anti-dictator. ” Our test is “adaptive, ” makes q queries, has completeness 1, and soundness O(q 3) · 2 −q. Previously, a dictatorship test that has sound...|$|R
40|$|We {{prove the}} refutational {{completeness}} of P mep by proof techniques employed {{in establishing the}} completeness of weak superposition [9]. By giving a counter-example we show that the same approach is impossible wrt. P eqf. Hence, this result shows a semantic differences between P mep and P eqf. We apply the result to Automated Model Building. 1 Introduction We study the relationship between two possible instances of the superposition calculus [1], the equality factoring fragment, denoted by P eqf, and the merging paramodulation fragment, P mep. We establish refutational completeness for P mep by methods extending the techniques used in the completeness proof for weak superposition [9]. From this result we conclude that the model I H generated from the initial clause set <b>C</b> in the <b>completeness</b> proof for superposition [1] coincides exactly with the model I P described by the (infinite) right-most maximal path P in a transfinite E-semantic tree corresponding to C, where C is a sa [...] ...|$|R
40|$|Uffe Engberg Glynn Winskel Computer Science Department Aarhus University Ny Munkegade DK- 8000 Aarhus <b>C,</b> Denmark Abstract <b>Completeness</b> {{is shown}} for several {{versions}} of Girard's linear logic {{with respect to}} Petri nets as the class of models. The strongest logic considered is intuitionistic linear logic, withΩ, Γ,-, &, Φ and the exponential ! ("of course"), and forms of second-order quantification. This logic is shown sound and complete with respect to atomic nets (these include nets in which every transition leads to a nonempty multiset of places). The logic is remarkably expressive, enabling descriptions {{of the kinds of}} properties one might wish to show of nets; in particular, negative properties, asserting the impossibility of an assertion, can also be expressed. e-mail address: fengberg,gwinskelg@daimi. aau. dk, fax: ++ 45 86 13 57 25 0 1 Introduction In [EW 90] it was shown how Petri nets can naturally be made into models of Girard's linear logic [...] ...|$|R
40|$|Many {{researches}} {{to testing}} object-oriented programs (OOPs) {{have been proposed}} for the past decade. However, most of these researches have centered only around the class-level testing instead of the whole profiles of OOP development. This paper presents a framework to test OOPs from em formal specification to em test data generation. The formal specification of object-oriented program is specified in Z notation which is a mathematically rigorous specification language. A state transition diagram (STD) derived from Z specification provides a complementary representation of the dynamic behavior of a given OOP. In addition, the STD {{can be used to}} generate a test data which consists of anticipated operation sequences of OOPs. Moreover, a testing algorithm modeled by em finite state machine is proposed to run against test data. Two important testing criteria, consistency and <b>completeness</b> (<b>C</b> & C), are used to evaluate testing result. The final test result shows that the testing framework is executable and pragmatic. 1...|$|R
40|$|Abstract: In {{this paper}} we propose a formal theory of {{partitions}} (ways of dividing up or sorting or mapping reality) and we show how the theory can be applied in the geospatial domain. We characterize partitions at two levels: as systems of cells (theory A), and in terms of their projective relation to reality (theory B). We lay down conditions of well-formedness for partitions and we define what it means for partitions to project truly onto reality. We continue by classifying well-formed partitions along three axes: (a) degree of correspondence between partition cells and objects in reality; (b) degree to which a partition represents the mereological structure of the domain it is projected onto; and (<b>c)</b> degree of <b>completeness</b> and exhaustiveness with which a partition represents reality. This classification is used to characterize three types of partitions that {{play an important role in}} spatial information science: cadastral partitions, categorical coverages, and the partitions involved in folk categorizations of the geospatial domain. ...|$|R
40|$|This paper {{presents}} a general space-efficient method for error reduction for unitary quantum computation. Consider a polynomial-time quantum computation with <b>completeness</b> <b>c</b> and soundness s, either {{with or without}} a witness (corresponding to QMA and BQP, respectively). To convert this computation into a new computation with error at most 2 ^{-p}, the most space-efficient method known requires extra workspace of O(p*log(1 /(c-s))) qubits. This space requirement is too large for scenarios like logarithmic-space quantum computations. This paper shows an errorreduction method for unitary quantum computations (i. e., computations without intermediate measurements) that requires extra workspace of just O(log(p/(c-s))) qubits. This in particular gives the first method of strong amplification for logarithmic-space unitary quantum computations with two-sided bounded error. This also leads to a number of consequences in complexity theory, such as the uselessness of quantum witnesses in bounded-error logarithmic-space unitary quantum computations, the PSPACE upper bound for QMA with exponentially-small completeness-soundness gap, and strong amplification for matchgate computations...|$|R
40|$|We report VLA radio {{observations}} of 29 SNe with ages ranging from 10 days to about 90 years past explosion. These observations significantly {{contribute to the}} existing data pool on such objects. Included are detections of known radio SNe 1950 B, 1957 D, 1970 G, 1983 N, the suspected radio SN 1923 A, and the possible radio SN 1961 V. None of the remaining 23 observations resulted in detections, providing further {{evidence to support the}} observed trend that most SNe are not detectable radio emitters. To investigate the apparent lack of radio emission from the SNe reported here, we have followed standard practice and used Chevalier’s “standard model ” to derive (upper limits to) the mass-loss rates for the supernova progenitors. These upper limits to the fluxes are consistent with a lack of circumstellar material needed to provide detectable radio emission for SNe at these ages and distances. Comparison of the radio luminosities of these supernovae as a function of age past explosion to other well-observed radio SNe indicates that the Type II SNe upper limits are more consistent with the extrapolated light curves of SN 1980 K than of SN 1979 C, suggesting that SN 1980 K may be a more typical radio emitter than SN 1979 <b>C.</b> For <b>completeness,</b> we have included an appendix where the results of analyses of the non-SN radio sources are presented. Where possible, we make (tentative) identifications of these sources using various methods. Subject headings: circumstellar matter — supernovae: general – 3 – 1...|$|R
50|$|As {{bishop and}} {{chairperson}} of the EKD’s Council Huber initiated and supported numerous reform programs. In {{the context of the}} challenges mainline Protestantism face, especially in the eastern parts of Germany, Huber advocated for a missionary reorientation of the church. For him church reform is closely connected to the rediscovery of the church’s evangelical essence and requires openness to those who have distanced themselves from the Christian faith. These impulses characterize the large-scale reform process, subsumed under the theme “Church of freedom”, which Huber headed. The document Kirche der Freiheit describes how the church can set its profile in society, whilst respecting societal plurality. This document formulates four goals for the reform of the Protestant church in Germany, namely (a) spiritual profiling instead of indistinct activity, (b) prioritising instead of aiming for <b>completeness,</b> (<b>c)</b> structural mobility and (d) shifting the focus of the activities of the church to the outside instead of self-contentment. In his own regional church Huber also oversaw a reform process, “Salt of the earth”. Huber’s tenure as {{chairperson of the}} EKD’s Council also saw the incorporation of the Vereinigte Evangelisch-Lutherische Kirche Deutschlands and the Union Evangelischer Kirchen with the EKD, the streamlining of regional churches from 23 to 21, and the initiation of further reform processes.|$|R
40|$|The {{research}} purpose are to find: a) BBM strategy application with portfolio {{assessment in}} math learning; b) Student’s activity in BBM strategy application with portfolio assessment in math learning; and <b>c)</b> student’s learning <b>completeness</b> using BBM strategy with portfolio assessment in math learning. Approach {{used in this}} research was qualitative. The research kind was descriptive. The subject was BBM strategy with portfolio assessment in math learning. Research object were all students of VIII grade in Junior High School SMP Negeri 2 Prajekan consisted of 36 students. BBM application with portfolio assessment data in math learning was collected using observation sheet, students activity data collected using activity observation sheet, while learning completeness could be found from final determination and test consisted of collection portfolio result (Student’s Working Sheet and Homework), determination portfolio, and final test. Data analysis used are qualitative and quantitative descriptive. The research showed: a) learning application with BBM strategy with Portfolio assessment applied as the concept. In BBM component collection portfolio determination, what existed were thinking and writing, it could be proven by the students who fulfilled the test as the order. In determination portfolio, BBM component showed up were thinking, talking, and writing. b) In general, all activities had increased since first meeting to fourth meeting. The average of students activities percentage had from first meeting to fourth meeting was 74. 07...|$|R
40|$|The {{governing}} {{equation is}} u_t = (a(x) u_x) _x, 0 0, u(x, 0) = 0, u(0,t) = 0, a(1) u'(1,t) =f(t). The extra data are u(1,t) =g(t). It {{is assumed that}} a(x) is a piecewise-constant function, and f≡ 0. It is proved that the function a(x) is uniquely defined by the above data. No restrictions {{on the number of}} discontinuity points of a(x) and on their locations are made. The number of discontinuity points is finite, but this number can be arbitrarily large. If a(x) ∈ C^ 2 [0, 1], then a uniqueness theorem has been established earlier for multidimensional problem, x∈R^n, n> 1 (see MR 1211417 (94 e: 35004)) for the stationary problem with infinitely many boundary data. The novel point in this work is the treatment of the discontinuous piecewise-constant function a(x) and the proof of Property C for a pair of the operators {ℓ_ 1, ℓ_ 2 }, where ℓ_j:= -d^ 2 /dx^ 2 + k^ 2 q_j^ 2 (x), j= 1, 2, and q_j^ 2 (x) > 0 are piecewise-constant functions, and for the pair {L_ 1, L_ 2 }, where L_ju:=-[a_j(x) u'(x) ]'+λ u, j= 1, 2, and a_j(x) > 0 are piecewise-constant functions. Property <b>C</b> stands for <b>completeness</b> of the set of products of solutions of homogeneous differential equations (see MR 1759536 (2001 f: 34048) ...|$|R
40|$|The goal of {{this work}} is a {{systematic}} presentation of some classes of mixed weak formulations, for general multi-dimensional dipolar gradient elasticity (fourth order) boundary value problems. The displacement field main variable is accompanied by the double stress tensor and the Cauchy stress tensor (case 1 or mu - tau - u formulation), the double stress tensor alone (case 2 or mu - u formulation), the double stress, the Cauchy stress, the displacement second gradient and the standard strain field (case 3 or mu - tau - kappa - epsilon - u formulation) and the displacement first gradient, along with the equilibrium stress (case 4 or u - theta - gamma formulation). In all formulations, the respective essential conditions are built {{in the structure of}} the solution spaces. For cases 1, 2 and 4, one-dimensional analogues are presented for the purpose of numerical comparison. Moreover, the standard Galerkin formulation is depicted. It is noted that the standard Galerkin weak form demands C- 1 -continuous conforming basis functions. On the other hand, up to first order derivatives appear in the bilinear forms of the current mixed formulations. Hence, standard C- 0 -continuous conforming basis functions may be employed in the finite element approximations. The main purpose of this work is to provide a reference base for future numerical applications of this type of mixed methods. In all cases, the associated quadratic energy functionals are formed for the purpose of <b>completeness.</b> (<b>C)</b> 2008 Elsevier Ltd. All rights reserved...|$|R
40|$|We use N_t, {{the number}} of exoplanets {{observed}} in time t, as a science metric to study direct-search missions like Terrestrial Planet Finder. In our model, N has 27 parameters, divided into three categories: 2 astronomical, 7 instrumental, and 18 science-operational. For various " 27 -vectors" of those parameters chosen to explore parameter space, we compute design reference missions to estimate N_t. Our treatment includes the recovery of <b>completeness</b> <b>c</b> after a search observation, for revisits, solar and antisolar avoidance, observational overhead, and follow-on spectroscopy. Our baseline 27 -vector has aperture D = 16 m, inner working angle IWA = 0. 039 ", mission time t = 0 - 5 years, occurrence probability for earthlike exoplanets η = 0. 2, and typical values for the remaining 23 parameters. For the baseline case, a typical five-year design reference mission has an input catalog of ∼ 4700 stars with nonzero completeness, ∼ 1300 unique stars observed in ∼ 2600 observations, of which ∼ 1300 are revisits, and it produces N_ 1 ∼ 50 exoplanets after one year and N_ 5 ∼ 130 after five years. We explore offsets from the baseline for ten parameters. We find that N depends strongly on IWA and only weakly on D. It also depends only weakly on zodiacal light for Z 0. 2, and scattered starlight for ζ < 10 ^- 10. We find that observational overheads, completeness recovery and revisits, solar and antisolar avoidance, and follow-on spectroscopy are all important factors in estimating N. Comment: 37 pages, 11 figures, 11 tables; ApJ accepted versio...|$|R
40|$|The Mopex {{software}} is {{used at the}} Spitzer Science Center (SSC) to produce co-added and mosaicked images from sets of individually processed Spitzer images. Until now, quantitative studies {{of the performance of}} Mopex's outlier-detection methods had never been performed. This particular study focuses only on Mopex's multiframe outlier-detection algorithm, and future studies are still needed to characterize its so-called box and dual methods. The performance of the multiframe method varies with two adjustable parameters, ΓTOP and ΓRM. For a given ΓTOP value, we computed the <b>completeness</b> (<b>C)</b> and reliability (R) of the outlier detection for 101 discrete values of ΓRM uniformly distributed in the full range of possible settings for this parameter, which lie continuously between 0 and 1, inclusive. We characterized the C and R performance as a function of ΓRM in this manner for ΓTOP values of 2, 2. 5, 3, 5, and 10 for image data in all four IRAC channels (infrared passbands). Not surprisingly, the performance for IRAC channel 3 is relatively poor because the image data for this channel are markedly noisier. The best performance was obtained for a ΓTOP value of 3, and this applies to all four channels. Generally, setting ΓRM low will maximize completeness at the expense of reliability, and vice versa for setting ΓRM high. For example, for IRAC channel 1 and ΓTOP = 3, setting ΓRM = 0. 3 gives C = 83 % and R = 41 %, and setting ΓRM = 0. 8 gives C = 52 % and R = 86 %...|$|R
40|$|In most mature welfare states, policy {{evaluations}} are {{sponsored by}} the very organisations that designed and implemented the intervention in the first place. Research {{in the area of}} clinical trials has consistently shown that this type of arrangement creates a moral hazard and may lead to overestimates of the effect of the treatment. Yet, no one so far has investigated whether social interventions were subject to such ‘confirmation bias’. The objective of this study was twofold. Firstly, it assessed the scientific credibility of a sample of government-sponsored pilot evaluations. Three common research prescriptions were considered: (a) the proportionality of timescales, (b) the representativeness of pilot sites; and (<b>c)</b> the <b>completeness</b> of outcome reporting. Secondly, it examined whether the known commitment of the government to a reform was associated with less credible evaluations. These questions were answered using a ‘meta-research’ methodology, which departs from the traditional interviews and surveys of agents that have dominated the literature so far. I developed the new PILOT dataset for that specific purpose. PILOT includes data systematically collected from over 230 pilot and experimental evaluations spanning 13 years of government-commissioned research in the UK (1997 - 2010) and four government departments (Department for Work and Pensions, Department for Education, Home Office and Ministry of Justice). PILOT was instrumental in (a) modeling pilot duration using event history analysis; (b) modeling pilot site selection using logistic regression; and (c) the systematic selection of six evaluation reports for qualitative content analysis. A total of 17 interviews with policy researchers were also conducted to inform the case study and the overall research design. The results show little overt evidence of crude bias or ‘bad’ design. On average, government-sponsored pilots (a) were based on timescales that were proportional to the scope of the research; (b) were not primarily designed with the aim of warranting representativeness; and (c) were rather comprehensively analysed in evaluation reports. In addition, the results indicate that the known commitment of the government to a reform had no significant effect on the selection of pilot sites and on the reporting of outcomes. However, it was associated with significantly shorter pilots. In conclusion, {{there is some evidence that}} the known commitment of a government to a reform is associated with less credible evaluations; however this effect is only tangible in the earlier stages of the research cycle. In this respect, sponsorship bias would appear to be more limited than in the context of industry-sponsored clinical trials. Policy recommendations are provided, as this project was severely hindered by important ‘black box’ issues and by the poor quality of evaluation reports...|$|R
40|$|Abridged] We {{present a}} {{homogeneous}} and complete catalogue of optical groups {{identified in the}} purely flux limited (17. 5 <=I<= 24. 0) VIMOS-VLT Deep Survey (VVDS). We use mock catalogues extracted from the MILLENNIUM simulation, to correct for potential systematics that might affect the overall distribution {{as well as the}} individual properties of the identified systems. Simulated samples allow us to forecast the number and properties of groups that can be potentially found in a survey with VVDS-like selection functions. We use them to correct for the expected incompleteness and also to asses how well galaxy redshifts trace the line-of-sight velocity dispersion of the underlying mass overdensity. In particular, we train on these mock catalogues the adopted group-finding technique (the Voronoi-Delaunay Method, VDM). The goal is to fine-tune its free parameters, recover in a robust and unbiased way the redshift and velocity dispersion distributions of groups and maximize the level of <b>completeness</b> (<b>C)</b> and purity (P) of the group catalogue. We identify 318 VVDS groups with at least 2 members within 0. 2 <=z<= 1. 0, among which 144 (/ 30) with at least 3 (/ 5) members. The sample has globally C= 60 % and P= 50 %. Nearly 45 % of the groups with at least 3 members are still recovered if we run the algorithm with a parameter set which maximizes P (75 %). We exploit the group sample to study the redshift evolution of the fraction f_b of blue galaxies (U-B<= 1) within 0. 2 <=z<= 1. We find that f_b is significantly lower in groups than in the whole ensemble of galaxies irrespectively of their environment. These quantities increase with redshift, with f_b in groups showing a marginally significant steeper increase. We also confirm that, at any explored redshift, f_b decreases for increasing group richness, and we extend towards fainter luminosities the magnitude range over which this result holds. Comment: Submitted to A&A, revised version after referee comments, Table 5 adde...|$|R
