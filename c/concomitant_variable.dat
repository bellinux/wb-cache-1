36|77|Public
40|$|The {{standard}} mixture model, the <b>concomitant</b> <b>variable</b> mixture model, {{the mixture}} regression {{model and the}} <b>concomitant</b> <b>variable</b> mixture regression model all enable simultaneous identification and description of groups of observations. This study reviews the {{different ways in which}} dependencies among the variables involved in these models are accommodated. It is demonstrated that the standard and <b>concomitant</b> <b>variable</b> mixture models identify groups of observations {{and at the same time}} discriminate them analogous, respectively, to discriminant analysis and logistic regression. While the mixture regression model is shown to have limited use for classifying new observations. An extension of it, called the saturated mixture regression model, is shown to be more useful in that respect. Advantages of that model in model estimation when missing data are present and as a framework for model selection are also discussed...|$|E
40|$|By {{employing}} a <b>concomitant</b> <b>variable,</b> block designs {{and analysis of}} covariance (ANCOVA) {{can be used to}} improve the power of traditional analysis cf variance (ANOVA) by reducing error. If subjects are randomly assigned to treatments without considering the <b>concomitant</b> <b>variable,</b> an experiment uses a post-hoc approach. Otherwise, an a priori approach is used if the <b>concomitant</b> <b>variable</b> is utilized for assigning subjects to treatments. Traditionally, a priori has been considered the more powerful approach. This study compared ANOVA, block designs, and ANCOVA under various experimental conditions. The experimental conditions were 48 combinations of 4 levels of the number of treatments (T at 2, 3, 4, and 5), 3 levels of the number of subjects per treatment (n at 8, 40, and 72), and 4 levels of the correlation coefficient between the concomitant and dependent variables (p at 0. 00, 0. 28, 0. 56, and 0. 84). The optima...|$|E
40|$|This {{article is}} a (slightly) {{modified}} version of Grün and Leisch (2008 a), published in the Journal of Statistical Software. flexmix provides infrastructure for flexible fitting of finite mixture models in R using the expectation-maximization (EM) algorithm or one of its variants. The functionality of the package was enhanced. Now <b>concomitant</b> <b>variable</b> models as well as varying and constant parameters for the component specific generalized linear regression models can be fitted. The application of the package is demonstrated on several examples, the implementation described and examples given to illustrate how new drivers for the component specific models and the <b>concomitant</b> <b>variable</b> models can be defined. Keywords:˜R, finite mixture models, generalized linear models, concomitant variables. 1...|$|E
50|$|The {{regression}} {{relationship between}} the dependent <b>variable</b> and <b>concomitant</b> <b>variables</b> must be linear.|$|R
40|$|In this paper, {{we propose}} an {{efficient}} class of ratio-in-exponential-type estimators with two <b>concomitant</b> <b>variables</b> using Ranked Set Sampling (RSS) scheme which improves the available estimators. The biases and mean square errors (MSEs) {{of the proposed}} estimators are obtained up to first degree approximation. Comparisons among the proposed and competitor estimators are made both theoretically and through simulation study. It turned out that when the variable of interest and the <b>concomitant</b> <b>variables</b> jointly followed a trivariate Gamma distribution, the proposed class of estimators dominates all other competitor estimators...|$|R
40|$|In {{order to}} fully analyze spatial data, from {{satellite}} images to precision agricultural data, the user {{needs to do}} these three things: (1) display spatial locations and <b>concomitant</b> geographic <b>variables</b> on maps, (2) visualize these <b>concomitant</b> <b>variables</b> using more general interactive multivariate visualization methods, and (3) execute statistical analyses. At present, {{in order to accomplish}} those goals, three di erent kinds of software must b...|$|R
40|$|Optimal design {{theory is}} {{developed}} for an inverse Gaussian regression {{model in which}} the reciprocal mean is a polynomial function of a <b>concomitant</b> <b>variable.</b> Comparisons are made to the traditional normal theory optimal designs for linear and nonlinear regression. regression optimal design inverse Gaussian distribution...|$|E
40|$|By {{employing}} a <b>concomitant</b> <b>variable,</b> researchers {{can reduce the}} error, increase the precision, and maximize {{the power of a}}n experimental design. Blocking and analysis of covariance (ANCOVA) are most often used to harness the power of a <b>concomitant</b> <b>variable.</b> Whether to block or covary and how many blocks to be used if a block design is chosen become important. This paper provides an historical review of the problem and recommends future research to examine the problem based on how subjects are assigned, how data are analyzed, and the distributions of the variables. In this study, subjects were randomly assigned to treatments ignoring the <b>concomitant</b> <b>variable,</b> and data were analyzed by one-way analysis of variance (ANOVA), post-hoc two-block, four-block, and eight-block ANOVA and ANCOVA. Distributions of the concomitant and dependent variables were normal. The Monte Carlo method was used to generate 20, 000 data sets for 8 experimental conditions (2 levels of subject and 4 levels of correlation between concomitant and dependent variables. The five analysis procedures were examined under each experimental condition. Results show that ANCOVA is more powerful than post-hoc rank blocking. Eight tables present analysis results. (Contains 36 references.) (Author/SLD) Reproductions supplied by EDRS are the best that can be made Ic from the original document...|$|E
40|$|Summary. A general model {{class of}} finite {{mixtures}} of linear regression models is presented. It allows (nested) varying and fixed effects for the regression coefficients and the variance. A combination of varying and fixed effects {{is useful in}} applications {{because it can be}} used to account for overdispersion as a nuisance parameter or to reduce the number of estimated parameters. In addition <b>concomitant</b> <b>variable</b> models for the component weights provide the possibility to partition the data into the mixture components through other variables. Maximum likelihood parameter estimation using the EM algorithm is outlined and the implementation in R by extending package flexmix is described. In this paper multinomial logit <b>concomitant</b> <b>variable</b> models are considered, but the provided infrastructure allows to easily define new concomitant models and rapid prototyping is possible if functionality already available in R can be used. Key words: concomitant variables, finite mixture models, linear regression, R, unobserved heterogeneity...|$|E
40|$|This paper {{considers}} the Bayes and hierarchical Bayes approaches for analyzing clinical data on response times with available values {{for one or}} more <b>concomitant</b> <b>variables.</b> Response times are assumed to follow simple exponential distributions, with a different parameter for each patient. The analyses are carried out in case of progressive censoring assuming squared error loss function and gamma distribution as priors and hyperpriors. The possibilities of using the methodology in more general situations like dose- response modeling have also been explored. Bayesian estimators derived in this paper are applied to lung cancer data set with <b>concomitant</b> <b>variables...</b>|$|R
40|$|Psychometric mixture models {{based on}} flexmix infrastructure. At the moment only Rasch mixture models are {{implemented}} in various flavors: with/without <b>concomitant</b> <b>variables,</b> different parametrizations {{of the score}} distribution (saturated vs. mean/variance specification). See vignette(‘‘raschmix’’, package = ‘‘psychomix’’) for details. Depends R (>= 2. 10. 0), graphics, stats, methods, Formula, flexmix,psychotool...|$|R
50|$|The fifth issue, {{concerning}} the homogeneity of different treatment regression slopes {{is particularly important}} in evaluating the appropriateness of ANCOVA model. Also note that we only need the error terms to be normally distributed. In fact both the independent <b>variable</b> and the <b>concomitant</b> <b>variables</b> will not be normally distributed in most cases.|$|R
40|$|Early {{heart disease}} control can be {{achieved}} by high disease prediction and diagnosis efficiency. This paper focuses on the use of model based clustering techniques to predict and diagnose heart disease via Poisson mixture regression models. Analysis and application of Poisson mixture regression models is here addressed under two different classes: standard and <b>concomitant</b> <b>variable</b> mixture regression models. Results show that a two-component <b>concomitant</b> <b>variable</b> Poisson mixture regression model predicts heart disease better than both the standard Poisson mixture regression model and the ordinary general linear Poisson regression model due to its low Bayesian Information Criteria value. Furthermore, a Zero Inflated Poisson Mixture Regression model {{turned out to be the}} best model for heart prediction over all models as it both clusters individuals into high or low risk category and predicts rate to heart disease componentwise given clusters available. It is deduced that heart disease prediction can be effectively done by identifying the major risks componentwise using Poisson mixture regression model...|$|E
40|$|Ranked set {{sampling}} (RSS) utilizes inexpensive auxiliary {{information about}} the ranking of the units in a sample {{to provide a more}} precise estimator of the population mean of the variable of interest Y, which is either difficult or expensive to measure. However, the ranking may not be perfect in most situations. In this paper, we assume that the ranking is done {{on the basis of a}} <b>concomitant</b> <b>variable</b> X. Regression-type RSS estimators of the population mean of Y will be proposed by utilizing this <b>concomitant</b> <b>variable</b> X in both the ranking process of the units and the estimation process when the population mean of X is known. When X has unknown mean, double sampling will be used to obtain an estimate for the population mean of X. It is found that when X and Y jointly follow a bivariate normal distribution, our proposed RSS regression estimator is more efficient than RSS and simple random sampling (SRS) naive estimators unless the correlation between X and Y is low (|p| < 0. 4). Moreover, it is always superior to the regression estimator under SRS for all ρ. When normality does not hold, this approach could still perform reasonably well as long as the shape of the distribution of the <b>concomitant</b> <b>variable</b> X is only slightly departed from symmetry. For heavily skewed distributions, a remedial measure will be suggested. An example of estimating the mean plutonium concentration in surface soil on the Nevada Test Site, Nevada, U. S. A., will be considered. link_to_subscribed_fulltex...|$|E
40|$|A split-plot data {{structure}} is usually modelled by a linear classificatory {{model with a}} 0, 1 model matrix and with error consisting additively of independent Gaussian errors. Statistical analysis of such a {{data structure}} in the usual mode involves then two components of error variance. The usual model is then a special case of what is commonly called a mixed linear model. Consequently, the well-known problems of mixed linear models are encountered. However, the standard balance split-plot data structure has special features of balance that enable progress, as will be explained;With {{the presence of a}} <b>concomitant</b> <b>variable</b> and the assumed error structure, the problem of estimation of the dependence of the observations to be explained on the <b>concomitant</b> <b>variable</b> becomes complicated. The model considered is y(,ijk) = (mu) + (alpha) (,i) + (gamma) (,j) + (nu) (,k) + (eta) (,jk) + x(,ijk) c + e(,ij) + s(,ijk) where x(,ijk) is the value of the <b>concomitant</b> <b>variable</b> or the covariate, c is the regression coefficient, e(,ij) and s(,ijk) are errors. The difficulties arise from the existence of the two types of error;The nature of split-plot designs will be exposited, along with special features arising from the balance in the structure;The problem considered is estimation of c, the regression coefficient, because if this is solved, the remainder of the problem of fitting the model seems clear. There is no best way of estimating c because var(e(,ij)) and var(s(,ijk)) are not known and various methods of doing this are discussed;The problem is simple if the ratio of the two variance components is known. So, attention is turned to estimation of a basic parameter related to this ratio, with consideration of various methods, including Bayesian estimation;The widely used method of maximum likelihood fitting of the model is examined. Also, a method of restricted maximum likelihood estimation is examined;Residual problems such as attaching 2 ̆ 2 reasonable 2 ̆ 2 standard errors to estimates are not solved. It seems that understanding these problems can be achieved only by simulation...|$|E
40|$|Abstract This article applies Bayesian {{reference}} analysis, {{widely considered}} {{as the most}} successful method to produce objective, model-based, posterior distributions, to a problem of inference in survival analysis. A formulation is considered where indi-viduals are expected to experience repeated events, along with <b>concomitant</b> <b>variables.</b> The sampling distribution of the observations is modeled through a proportional in-tensity homogeneous Poisson process...|$|R
40|$|Chih-Kuang Chang, 1 Chi-Chang Chang 2 1 Department of Cardiology, Jen-Ai Hospital, Dali District, Taichung, Taiwan; 2 School of Medical Informatics, Chung Shan Medical University, Information Technology Office of Chung Shan Medical University Hospital, Taichung, TaiwanAbstract: In medical research, {{clinical}} practice must often be undertaken with imperfect information from limited resources. This study applied Bayesian imperfect information-value analysis to realistic situations to produce likelihood functions and posterior distributions, to a clinical decision-making problem for recurrent events. In this study, {{three kinds of}} failure models are considered, and our methods illustrated with an analysis of imperfect information from a trial of immunotherapy {{in the treatment of}} chronic granulomatous disease. In addition, we present evidence toward {{a better understanding of the}} differing behaviors along with <b>concomitant</b> <b>variables.</b> Based on the results of simulations, the imperfect information value of the <b>concomitant</b> <b>variables</b> was evaluated and different realistic situations were compared to see which could yield more accurate results for medical decision-making. Keywords: Bayesian value-of-information, recurrent events, chronic granulomatous diseas...|$|R
40|$|<b>Concomitant</b> <b>variables</b> (~) {{introduced}} into survival models are often regarded as risk or aging factors which {{contribute to the}} mortality patterns in various study groups. <b>Concomitant</b> <b>variables</b> observed at the time point t = 0 (and having values ~) can also be regarded as random variables, ~, with some prior joint distribution. If the Z's do, indeed, contribute to mortality, their posterior distribution among the survivors to time t will be different from that at t = 0, even when {{the values of the}} z's do not depend on t, General formulae for the posterior distributions are given in Section 2 (assuming z's not to depend on t), and in Section 4 (for z's varying with t). Our interest is especially focussed on models with linear additive hazard functions of the form (3. 2). It is shown that in such cases the posterior distribution does not depend on the "underlying" hazard; its general form is given by (3. 6), and by (3. 7) wher...|$|R
40|$|Analysis of {{covariance}} (ancova) {{is a technique}} that combines features of analysis of variance and regression {{which is used to}} increase precision (accuracy) of the experiment. Ancova can be used for any experimental design include Graeco Latin square design. Graeco Latin square design is a combination of two orthogonal Latin square, two Latin square are orthogonal if when they are combined, the same pair of symbols occurs no more than once in the composite square. Application ancova on Graeco Latin square design in the field of agriculture is given to observe the effect of different fertilizer dose towards outcome of corn production. In this experiment there are three blocking factors (soil pH, soil slopes, and corn varieties) and two variable concomitant (quantity of corn plant and quantity of baby corn). The result shows that both of concomitant variables effect the respons, that’s mean using these two <b>concomitant</b> <b>variable</b> on this ancova method is appropriate. More than that, ancova give result way much better than anova, shows from the result coefficient of variation ancova less than anova, means that there is an increase precision (accuracy) of the experiment. So, <b>concomitant</b> <b>variable</b> can’t be ignored from the experiment. Keywords: Analysis of Covariance (ancova), Graeco Latin square design, Analysis of Variance (anova) ...|$|E
40|$|Analysis of Covariance (ANCOVA) {{is mostly}} {{used in the}} {{analysis}} of research or experimental design. ANCOVA is the combination between regression analysis and Analysis of Variance (ANOVA). ANCOVA were used because there are some <b>concomitant</b> <b>variable,</b> which is variable that difficult to control by the researchers but an impact on observed the response variable. The purpose from <b>concomitant</b> <b>variable</b> is reduces variability in the experiment. If there is missing data on Randomized Complete Block Design (RCBD) the first must be done estimating the missing data before ANCOVA done. ANCOVA on RCBD with complete data or missing data isn 2 ̆ 7 t much different, if there are missing data, the degrees of freedom is reduced by the total amount of missing data and the sum of square treatment reduced by the value of the bias. Application of tensile strength of the glue experiment to the case ANCOVA on RCBD with one missing data show no effect of treatment and group by the tensile strength of the glue. For Fe toxicity experiment with two missing data are found only treatment effect to Fe texicity. Based on value from the coefficient of variance for one missing data and two missing data showed that ANCOVA is more appropriately used than ANOVA...|$|E
40|$|The {{method of}} ranked set {{sampling}} is widely applicable in environmental research {{mainly in the}} estimation of the mean and distribution function of the variable of interest, Y. Ranking of the Ys by visual judgment may be imperfect sometimes. When the Ys are expensive to measure, {{it would be more}} convenient to determine the 'rankings' of the Ys by a <b>concomitant</b> <b>variable,</b> X, which is relatively easy and cheap to make measurements. The information carried in X is not utilized in all estimation methods available in the literature except in determining the rankings of Ys unless extra distributional or linearity assumptions are made. However, these assumptions may be too stringent in environmental research. Nonparametric estimators for the distribution function and the mean of Y utilizing the <b>concomitant</b> <b>variable</b> and auxiliary information in a ranked set sampling setup are proposed in this article. The estimators are robust to model misspecification, and the performance of the estimators is highly satisfactory, supported by some simulation studies. The estimators are applied to a real data set to estimate the mean and distribution function of plutonium concentration in surface soil on the Nevada Test Site, Nevada, U. S. A. Copyright © 2002 John Wiley & Sons, Ltd. link_to_subscribed_fulltex...|$|E
40|$|R package flexmix {{provides}} flexible modelling of finite {{mixtures of}} regression models using the EM algorithm. Several new {{features of the}} software such as fixed and nested varying effects for mixtures of generalized linear models and multinomial regression for a priori probabilities given <b>concomitant</b> <b>variables</b> are introduced. The use of the software in addition to model selection is demonstrated on a logistic regression example...|$|R
40|$|Mini-Mental State Exam (MMSE) {{scores for}} 247 community-dwelling, well-functioning {{individuals}} in their 60 s (n = 88), in their 80 s (n = 92), and 100 or older (n = 67) {{were compared to}} examine overall and component MMSE differences. The concomitant influences of visual or literacy deficits, gender, education, race, income, and {{activities of daily living}} on MMSE performance were analyzed. Mean MMSE scores of 27. 8, 27. 1, and 24. 8, respectively, for the three cohorts were significantly different, even when all <b>concomitant</b> <b>variables</b> were controlled. After the <b>concomitant</b> <b>variables</b> were controlled, results indicated that there were no age group differences on five MMSE items: naming, repeating, listening and obeying, reading and obeying, and writing sentences. Participants with visual or literacy deficits scored 1. 5 points lower than other partimcipants, and displayed performance deficits in four items form the Read 2 ̆ 6 Write MMSE division: naming, reading and obeying, writing sentences, and praxis. Education and gender were significant covariates for total and divisional MMSE scores...|$|R
40|$|Description Psychometric mixture models {{based on}} flexmix infrastructure. At the moment Rasch mix-ture models with {{different}} parametrizations {{of the score}} distribution (saturated vs. mean/variance specifica-tion) and Bradley-Terry mixture models are implemented. Both mixture models can be esti-mated with or without <b>concomitant</b> <b>variables.</b> See vignette(``raschmix'', package = ``psychomix'') for de-tails on the Rasch mixture models. Depends R (> = 2. 10. 0), flexmix (> = 2. 3 - 7), psychotools (> = 0. 2 - 0...|$|R
40|$|Novel linked employer-employee {{data for}} {{multinational}} enterprises and their global workforces show that multinational enterprises that expand abroad retain more domestic jobs than competitors without foreign expansions. Propensity-score estimation {{demonstrates that the}} foreign expansion itself is a dominant explanatory factor for reduced worker separation rates. Bounding, <b>concomitant</b> <b>variable</b> tests, and further robustness checks show competing hypotheses to be less plausible. The {{finding is consistent with}} the hypothesis that, given global wage differences, a prevention of enterprises from outward FDI would lead to more domestic job losses. FDI raises domestic-worker retention more pronouncedly among highly educated workers. ...|$|E
40|$|A novel linked employer-employee {{data set}} {{documents}} that expanding multinational enterprises retain more domestic jobs than competitors without foreign expansion. In contrast to prior research, a propensity score estimator allows enterprise performance to vary with {{foreign direct investment}} (FDI) and shows that the foreign expansion itself is the dominant explanatory factor for reduced worker separation rates. Bounding, <b>concomitant</b> <b>variable</b> tests, and robustness checks rule out competing hypotheses. The {{finding is consistent with}} the idea that, given global factor price differences, a prevention of enterprises from outward FDI would lead to more domestic worker separations. FDI raises domestic-worker retention more pronouncedly among highly educated workers and for expansions to distant locations...|$|E
40|$|Abstract—Ranked set {{sampling}} (RSS) {{was first}} suggested {{to increase the}} efficiency of the population mean. It has been shown that this method is highly beneficial to the estimation based on simple random sampling (SRS). There has been considerable development and many modifications were done on this method. When a <b>concomitant</b> <b>variable</b> is available, ratio estimation based on ranked set sampling was proposed. This ratio estimator is more efficient than that based on SRS. In this paper some ratio type estimators of the population mean based on RSS are suggested. These estimators are found to be more efficient than the estimators of similar form using simple random sample...|$|E
40|$|The {{purpose of}} this paper is to give a log-linear {{representation}} of a generalized Bradley-Terry (BT-) Model for paired comparisons which allows the incorporation of ties, order effects, <b>concomitant</b> <b>variables</b> for the objects and categorical subject specific covariates and interactions between all of them. An advantage of this approach is that standard software for fitting log-linear models, such as GLIM, can be used. The approach is exemplified by analysing data from an experiment concerning the ranking of European universities. (author's abstract) Series: Forschungsberichte / Institut für Statisti...|$|R
40|$|Finite {{mixtures}} of regression models offer a flexible framework for investigating heterogeneity in data with functional dependencies. These models can be conveniently used for unsupervised learning on data with clear regression relationships. We extend such models by imposing an eigen-decomposition on the multivariate error covariance matrix. By constraining {{parts of this}} decomposition, we obtain families of parsimonious {{mixtures of}} regressions and mixtures of regressions with <b>concomitant</b> <b>variables.</b> These families of models account for correlations between multiple responses. An expectation-maximization algorithm is presented for parameter estimation and performance is illustrated on simulated and real data...|$|R
40|$|In {{order to}} fully analyze spatial data, from {{satellite}} images to precision agricultural data, the user {{needs to do}} these three things: (1) display spatial locations and <b>concomitant</b> geographic <b>variables</b> on maps, (2) visualize these <b>concomitant</b> <b>variables</b> using more general interactive multivariate visualization methods, and (3) execute statistical analyses. At present, {{in order to accomplish}} those goals, three different kinds of software must be used: a Geographic Information System (GIS), a Dynamic Statistical Graphics (DSG) program, and a Statistical Computing Environment (SCE). We have developed a method to dynamically link three pieces of software, one in each category, so that they can exchange commands and data. The different data analytic and graphical methods of these packages complement each other. This linking increases ease and efficiency at all stages of spatial data analysis. The three programs are the GIS ArcView 3. 0 TM, the DSG program XGobi, and the SCE XploRe 4. The A [...] ...|$|R
40|$|Finite {{mixture of}} {{regression}} models are a popular technique for modelling the unobserved heterogeneity {{that occurs in}} the population. This method acquires parameters estimates by modelling a mixture conditional distribution of the response given explanatory variables. Since this optimization problem appears to be too computationally demanding, the expectation-maximization (EM) algorithm, an iterative algorithm for computing maximum likelihood estimates from incomplete data, is used in practice. In order to specify different components with higher accuracy and to improve regression parameter estimates and predictions the use of concomitant variables has been proposed. Based on a simulation study, performance and obvious advantages of concomitant variables are presented. A practical choice of appropriate <b>concomitant</b> <b>variable</b> {{and the effect of}} predictors' domains on the estimation are discussed as well...|$|E
40|$|Thermal {{factor is}} one of the main factors of the green {{building}} concept. The purpose of this research is to test building performance through design aspect that influences thermal comfort, the design aspects include: orientation, building type, and position of the flat. Method used in this research is covariance analysis, testing the influence of factor variable toward respond variable (indoor temperature) with taking outdoor temperature as <b>concomitant</b> <b>variable.</b> The cases tested on this research are Cigugur Tengah, Industri Dalam, and Sarijadi flat s. Result of covariance analysis shows that the building orientation factor variable is most influentially variable toward thermal comfort, compared with building type factor variable; even the unit position factor variable has n o significant influence toward thermal comfort. </p...|$|E
40|$|Regression {{is used to}} {{estimate}} the population mean of the response variable,, in the two cases where the population mean of the concomitant (auxiliary) variable,, is known {{and where it is}} unknown. In the latter case, a double sampling method is used {{to estimate}} the population mean of the <b>concomitant</b> <b>variable.</b> We invesitagate the performance of the two methods using extreme ranked set sampling (ERSS), as discussed by Samawi et al. (1996). Theoretical and Monte Carlo evaluation results as well as an illustration using actual data are presented. The results show that if the underlying joint distribution of and  is symmetric, then using ERSS to obtain regression estimates is more efficient than using ranked set sampling (RSS) or  simple random sampling (SRS) ...|$|E
40|$|In {{treatment}} comparison experiments, {{the treatment}} responses are often correlated with some <b>concomitant</b> <b>variables</b> {{which can be}} measured before or {{at the beginning of}} the experiments. In this article, we propose schemes for the assignment of experimental units that may greatly improve the efficiency of the comparison in such situations. The proposed schemes are based on general ranked set sampling. The relative efficiency and cost-effectiveness of the proposed schemes are studied and compared. It is found that some proposed schemes are always more efficient than the traditional simple random assignment scheme when the total cost is the same. Numerical studies show promising results using the proposed schemes...|$|R
30|$|Furthermore, we {{hypothesized}} a specific pattern of moderation effects. To this end, we profiled participants {{in terms of}} their: (i) basic arithmetic skills, (ii) level of mathematics anxiety, and (iii) executive function with an attention switching task. We used these <b>concomitant</b> <b>variables</b> to confirm that they moderate the impact of suppression on mental arithmetic, and that {{their impact on the}} low and high interactivity conditions would differ. We expected all three variables to moderate the impact of suppression primarily in the low interactivity condition; if a higher degree of interactivity augments overall or systemic working memory resources, then participants’ performance would be more resilient and the moderating properties of these factors might be attenuated.|$|R
40|$|In total hip {{replacement}} studies orthopaedic surgeons are often interested {{in assessing the}} performance of a prosthetic implant {{as a function of the}} time interval since surgery and <b>concomitant</b> <b>variables.</b> Performance is measured by several endpoints, the occurrence of one or more of which may indicate a failed implant. Furthermore, it is common for some patients to have both hips replaced. so that several response times may be observed for the left and right hips. Thus. one is faced with so-called multivariate failure time data. Closely allied to this setup is the problem of competing risks, in which each individual is subject to a number of mutually exclusive causes of failure. Under thi...|$|R
