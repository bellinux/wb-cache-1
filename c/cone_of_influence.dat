27|10000|Public
40|$|Abstract—Cone of {{influence}} analysis, i. e. determining {{the parts of}} the circuit which are relevant to a considered circuit signal, is an established methodology applied in several design tasks. In abstractions like the Register Transfer Level (RTL) or the gate level, <b>cone</b> <b>of</b> <b>influence</b> analysis is simple. However, the introduction of higher levels of abstractions, particularly the Electronic System Level (ESL), made it significantly harder to reliably extract a <b>cone</b> <b>of</b> <b>influence.</b> In this paper, we propose a methodology that enables <b>cone</b> <b>of</b> <b>influence</b> analysis at the ESL. Instead of a structural analysis, a behavioral scheme is proposed, i. e. stimuli representing different system executions are analyzed. To this end, machine learning techniques are exploited. This enables a very good approximation of the desired <b>cone</b> <b>of</b> <b>influence</b> which is non-invasive, does not rely on the availability of the source code, and performs fast. Case studies confirm the applicability of the proposed approach. I...|$|E
40|$|AbstractThe <b>Cone</b> <b>of</b> <b>Influence</b> Reduction is a {{fundamental}} abstraction technique for reducing the size of models used in symbolic model checking. We develop coalgebraic representations of systems as composites of state transition maps and connectors. These representations include synchronous systems, asynchronous systems, asynchronous systems with synchronization by channels, and those with shared variables, probabilistic synchronous systems and so on. We schematically show the <b>cone</b> <b>of</b> <b>influence</b> reduction using these coalgebraic representations, which give a unified framework for providing the technique for various kinds of systems...|$|E
40|$|Abstract We {{present a}} case study {{illustrating}} how to exploit the expressive power of higher-order logic to complete a proof whose main lemma is already proved in a firstorder theorem prover. Our proof exploits {{a link between the}} HOL 4 and ACL 2 proof systems to show correctness of a <b>cone</b> <b>of</b> <b>influence</b> reduction algorithm, implemented in ACL 2, with respect to the classical semantics of linear temporal logic, formalized in HOL 4...|$|E
40|$|Our {{perception}} of fluid instabilities and turbulence is {{largely based on}} properties of incompressible vorticity distributions, omega, and the Biot-Savart Law of 'instantaneous' induction at distance. In high-speed shear layers it is the distribution of local angular momentum rho-omega that matters; modified interaction-induction between vortical elements {{is likely to take}} place only within relative Mach <b>cones</b> <b>of</b> <b>influence,</b> with acoustic time delay. This and the large mean density stratifications influence strongly instability vortex roll-ups, vortex mergings, and large-scale turbulent structures. Consequences of these observations on transition to turbulence and turbulence energetics are discussed in physical terms. Free shear layers and wall layers may require distinct M modeling...|$|R
40|$|Abstract. Transformation-based {{verification}} {{has been}} proposed to synergistically leverage various transformations to successively simplify and decompose large problems to ones which may be formally discharged. While powerful, such systems require {{a fair amount of}} user sophistication and experimentation to yield greatest benefits – every verification problem is different, hence the most efficient transformation flow differs widely from problem to problem. Finding an efficient proof strategy not only enables exponential reductions in computational resources, it often makes the difference between obtaining a conclusive result or not. In this paper, we propose the use of an expert system to automate this proof strategy development process. We discuss the types of rules used by the expert system, and the type of feedback necessary between the algorithms and expert system, all oriented towards yielding a conclusive result with minimal resources. Experimental results are provided to demonstrate that such a system is able to automatically discover efficient proof strategies, even on large and complex problems with more than 100, 000 state elements in their respective <b>cones</b> <b>of</b> <b>influence.</b> These results also demonstrate numerous types of algorithmic synergies that are critical to the automation of such complex proofs. ...|$|R
50|$|Because {{signals and}} other causal {{influences}} cannot travel faster than light (see special relativity and quantum entanglement), the light cone plays {{an essential role}} in defining the concept of causality: for a given event E, the set of events that lie on or inside the past light <b>cone</b> <b>of</b> E would also be the set of all events that could send a signal that would have time to reach E and influence it in some way. For example, at a time ten years before E, if we consider the set of all events in the past light <b>cone</b> <b>of</b> E which occur at that time, the result would be a sphere (2D: disk) with a radius of ten light-years centered on the future position E will occur. So, any point on or inside the sphere could send a signal moving {{at the speed of light}} or slower that would have time to influence the event E, while points outside the sphere at that moment would not be able to have any causal influence on E. Likewise, the set of events that lie on or inside the future light <b>cone</b> <b>of</b> E would also be the set of events that could receive a signal sent out from the position and time of E, so the future light cone contains all the events that could potentially be causally influenced by E. Events which lie neither in the past or future light <b>cone</b> <b>of</b> E cannot <b>influence</b> or be influenced by E in relativity.|$|R
40|$|In {{the problem}} of image interpolation, most of the {{difficulties}} arise in areas around edges and sharp changes. Around edges, many interpolation methods tend to smooth and blur image detail. Fortunately, most of the signal information is often carried around edges and areas of sharp changes {{and can be used}} to predict these missing details from a sampled image. A method for adding image detail based on the <b>cone</b> <b>of</b> <b>influence,</b> the evolution of the wavelet coefficients across scales, is presented in this paper. 1...|$|E
40|$|In signal approximation, {{classical}} wavelet synthesis {{are known}} to produce Gibbs-like phenomenon around discontinuities when wavelet coefficients in the <b>cone</b> <b>of</b> <b>influence</b> of the discontinuities are quantized. By analyzing a function in a piecewise manner, filtering across discontinuities can be avoided. Using this principle, the interval wavelet transform can generate sparser representations {{in the vicinity of}} discontinuities than classical wavelet transforms. This work introduces two new constructions of interval wavelets and shows how they can be used for image compression and upscaling. Index Terms wavelets on the interval, boundary filters, image approximation. I...|$|E
40|$|Scientists and {{engineers}} use hyperbolic partial differential equations (PDEs) to model wave propagation phenomena. Anisotropy of the transmitting medium can cause waves to propagate asymmetrically, with different speeds in different directions. Shocks (discontinuities) can form spontaneously when the PDE is nonlinear. In this case, the local wave speeds are nonuniform, solution-dependent functions over the spacetime analysis domain, and the wave speeds {{at a given}} spatial location can change discontinuously with time. Spacetime discontinuous Galerkin finite element methods provide efficient and accurate solutions to hyperbolic PDEs when implemented on spacetime meshes that are causal, as described below. This paper unifies previous work [1, 2] to define a new adaptive meshing algorithm for nonlinear and anisotropic hyperbolic problems in 2 D×time. The new algorithm generates causal spacetime meshes comprised of tetrahedral elements with provable worst-case guarantees for the element temporal aspect ratios. Our meshing algorithm constructs an unstructured, nonconforming tetrahedral partition of a given spacetime analysis domain, Ω ⊂ E 2 × R. The algorithm advances the mesh {{through a series of}} triangulated terrains embedded in Ω called fronts. A front τ is causal if and only if it lies below the <b>cone</b> <b>of</b> <b>influence</b> of every point p on τ. The slope in any spatial direction of the <b>cone</b> <b>of</b> <b>influence</b> of p is the reciprocal of the maximum wave speed at p in that direction. The algorithm advances a local neighborhood N of τ t...|$|E
40|$|It {{is shown}} that spin-orbit {{interaction}} leads to drastic changes in wave patterns {{generated by a}} flow of two-component Bose-Einstein condensate (BEC) past an obstacle. The combined Rashba and Dresselhaus spin-orbit interaction affects in different ways two types of excitations [...] -density and polarization waves [...] -which can propagate in a two-component BEC. We show that the density and polarization "ship wave" patterns rotate in opposite directions around the axis located at the obstacle position and the angle of rotation depends {{on the strength of}} spin-orbit interaction. This rotation is accompanied by narrowing <b>of</b> the Mach <b>cone.</b> The <b>influence</b> <b>of</b> spin-orbit coupling on density solitons and polarization breathers is studied numerically. Comment: 5 pages, 3 figure...|$|R
40|$|Abstract. The article {{presents}} the results of the experimental research on the placement <b>of</b> the <b>cone</b> <b>of</b> substitute sediment {{at the bottom of the}} laboratory whirlpool tank with capacity of V= 2 hl and diameter D= 640 mm. The subject of the research was the <b>influence</b> <b>of</b> the whirl-pool tilt angle on the process <b>of</b> forming the <b>cone</b> <b>of</b> break. Different tilt angles of the tank's inlet were also taken into account and, for each characteristic states <b>of</b> forming the <b>cone</b> <b>of</b> break were registered. The research led to finding a tilt angle beneficial in terms of movement <b>of</b> the <b>cone</b> <b>of</b> substitute sediment in comparison to cycling in a tank without any tilt. Key words: <b>cone</b> <b>of</b> break, tank's bottom, whirlpool, rotating fluid flo...|$|R
40|$|We {{discuss a}} couple of {{problems}} concerning the pseudoeffective <b>cone</b> <b>of</b> a projective variety. In the first part {{we deal with the}} <b>influence</b> <b>of</b> a generalization of the Segre Conjecture on the Mori <b>cone</b> <b>of</b> a blown-up surface. In the second part we prove the existence of a weak Zariski decomposition for the pseudoeffective divisors of a number of projectivized vector bundle...|$|R
40|$|Formal {{verification}} {{has become}} a recommended practice in the safety-critical application areas. However, due {{to the complexity of}} practical control and safety systems, the state space explosion often prevents the use of formal analysis. In this paper we extend our former verification methodology with effective property preserving reduction techniques. For this purpose we developed general rule-based reductions and a customized version of the <b>Cone</b> <b>of</b> <b>Influence</b> (COI) reduction. Using these methods, the verification of complex requirements formalised with temporal logics (e. g. CTL, LTL) can be orders of magnitude faster. We use the NuSMV model checker on a real-life PLC program from CERN to demonstrate the performance of our reduction techniques...|$|E
40|$|In this paper, {{we propose}} an {{adaptive}} algorithm for scalable wavelet image coding, {{which is based}} on the general feature, the regularity, of images. In pattern recognition or computer vision, regularity of images is estimated from the oriented wavelet coefficients and quantified by the Lipschitz exponents. To estimate the Lipschitz exponents, evaluating the interscale evolution of the wavelet transform modulus sum (WTMS) over the directional <b>cone</b> <b>of</b> <b>influence</b> was proven to be a better approach than tracing the wavelet transform modulus maxima (WTMM). This is because the irregular sampling nature of the WTMM complicates the reconstruction process. Moreover, examples were found to show that the WTMM representation cannot uniquel...|$|E
40|$|Part 4 : Bisimulation, Abstraction and ReductionInternational audienceFormal {{verification}} {{has become}} a recommended practice in the safety-critical application areas. However, due {{to the complexity of}} practical control and safety systems, the state space explosion often prevents the use of formal analysis. In this paper we extend our former verification methodology with effective property preserving reduction techniques. For this purpose we developed general rule-based reductions and a customized version of the <b>Cone</b> <b>of</b> <b>Influence</b> (COI) reduction. Using these methods, the verification of complex requirements formalised with temporal logics (e. g. CTL, LTL) can be orders of magnitude faster. We use the NuSMV model checker on a real-life PLC program from CERN to demonstrate the performance of our reduction techniques...|$|E
5000|$|Breath weapon: <b>Cone</b> <b>of</b> {{superheated}} sparks (fire {{and electric}} damage) and <b>cone</b> <b>of</b> sleep gas ...|$|R
40|$|Let Sn {{denote the}} set of n×n real {{symmetric}} matrices, S+n denote the <b>cone</b> <b>of</b> n×n real symmetric positive semidefinite matrices and Nn denote the <b>cone</b> <b>of</b> symmetric nonnegative n × n matrices. CP and DNN matrices Let Sn denote {{the set of}} n×n real symmetric matrices, S+n denote the <b>cone</b> <b>of</b> n×n real symmetric positive semidefinite matrices and Nn denote the <b>cone</b> <b>of</b> symmetric nonnegative n × n matrices. • The <b>cone</b> <b>of</b> n×n doubly nonnegative (DNN) matrices is then Dn = S+n ∩Nn. CP and DNN matrices Let Sn denote the set of n×n real symmetric matrices, S+n denote the <b>cone</b> <b>of</b> n×n real symmetric positive semidefinite matrices and Nn denote the <b>cone</b> <b>of</b> symmetric nonnegative n × n matrices. • The <b>cone</b> <b>of</b> n×n doubly nonnegative (DNN) matrices is then Dn = S+n ∩Nn. • The <b>cone</b> <b>of</b> n × n completely positive (CP) matrices is Cn = X |X = AAT for some n × k nonnegative matrix A. CP and DNN matrices Let Sn denote the set of n×n real symmetric matrices, S+n denote the <b>cone</b> <b>of</b> n×n real symmetric positive semidefinite matrices and Nn denote the <b>cone</b> <b>of</b> symmetric nonnegative n × n matrices. • The <b>cone</b> <b>of</b> n×n doubly nonnegative (DNN) matrices is then Dn = S+n ∩Nn. • The <b>cone</b> <b>of</b> n × n completely positive (CP) matrices is Cn = X |X = AAT for some n × k nonnegative matrix A. • Dual of Cn is the <b>cone</b> <b>of</b> n × n copositive matrices, C∗n = X ∈ Sn | yTXy ≥ 0 ∀ y ∈ 4. Goal: Given a matrix X ∈ Dn Cn, separate X from Cn using a matrix V ∈ C∗n having V •X < 0. Goal: Given a matrix X ∈ Dn Cn, separate X from Cn using a matrix V ∈ C∗n having V •X < 0. Why Bother? Goal: Given a matrix X ∈ Dn Cn, separate X from Cn using...|$|R
5000|$|The set of {{positive}} functionals [...] is the dual <b>cone</b> <b>of</b> the <b>cone</b> <b>of</b> positive elements of [...]|$|R
40|$|Model {{checking}} techniques {{applied to}} large industrial circuits {{suffer from the}} state space explosion problem. A major technique {{to address this problem}} is abstraction. The most commonly used abstraction technique for hardware verification is localization reduction, which removes latches that are not relevant to the property. However, localization reduction fails {{to reduce the size of}} the model if the property actually depends on most of the latches. This paper proposes to use predicate abstraction for verifying RTL Verilog, a technique successfully used for software verification. The main challenge when using predicate abstraction is the discovery of suitable predicates. We propose to use weakest preconditions of Verilog statements in order to obtain new predicates during abstraction refinement. This technique has not been applied to circuits before. On benchmarks taken from an industrial microprocessor, we successfully verified safety properties with more than 32, 000 latches in the <b>cone</b> <b>of</b> <b>influence.</b> We compare the performance of our technique with a modern model checker that implements localization reduction...|$|E
40|$|In [1] Bounded Model Checking {{with the}} aid of satisfiability solving (SAT) was {{introduced}} as an alternative to symbolic model checking with BDDs. In this paper we show how bounded model checking can take advantage of specialized optimizations. We present a bounded version of the <b>cone</b> <b>of</b> <b>influence</b> reduction. We have successfully applied this idea in checking safety properties of a PowerPC microprocessor at Motorola 's Somerset PowerPC design center. Based on that experience, we propose a verification methodology that we feel can bring model checking into the mainstream of industrial chip design. 1 Introduction Model checking has only been partially accepted by industry as a supplement to traditional verification techniques. The reason is that model checking, which, to date, has been based on BDDs or on explicit state graph exploration, has not been robust enough for industry. Model checking [3, 12] was first proposed as a verification technique eighteen years ago. However, [...] ...|$|E
40|$|Livelock/deadlock is a {{well known}} and {{important}} problem in both hardware and software systems. In hardware verification, a livelock {{is a situation where}} the state of a design changes within only a smaller subset of the states reachable from the initial states of the design. Deadlock is a special case in which there is only one state in a livelock. However, livelock/deadlock checking has never been actively used in hardware verification in practice, mainly due to the complexity of the computation which involves finding strongly connected components. This paper presents a practical abstraction-based livelock/deadlock checking algorithm for hardware verification. The proposed livelock/deadlock checking works on FSMs rather than the whole design. For each FSM, we make an abstract machine of manageable size from the <b>cone</b> <b>of</b> <b>influence</b> machine, the livelock is justified on the concrete machine with trace concretization. Experimental results shows that the proposed abstraction-based livelock checking finds real livelock errors in industrial designs...|$|E
40|$|We study metric {{properties}} <b>of</b> the <b>cone</b> <b>of</b> homogeneousnonnegative multivariate polynomials and the <b>cone</b> <b>of</b> sums ofpowers {{of linear}} forms, {{and the relationship}} between the twocones. We compute the maximum volume ellipsoid of the natural baseof the <b>cone</b> <b>of</b> nonnegative polynomials and the minimum volumeellipsoid of the natural base <b>of</b> the <b>cone</b> <b>of</b> powers of linearforms and compute the coefficients of symmetry of the bases. Themultiplication by (x 1 2 + ··· + x n 2) m induces anisometric embedding of the space of polynomials of degree 2 kinto the space of polynomials of degree 2 (k+m), which allows usto compare the <b>cone</b> <b>of</b> nonnegative polynomials of degree 2 k andthe <b>cone</b> <b>of</b> sums of 2 (k+m) -powers of linear forms. We estimatethe volume ratio of the bases <b>of</b> the two <b>cones</b> and the rate atwhich it approaches 1 as m grows...|$|R
5000|$|The <b>cone</b> <b>of</b> curves {{is defined}} {{to be the}} convex <b>cone</b> <b>of</b> linear {{combinations}} of curves with nonnegative real coefficients in the real vector space N1(X) of 1-cycles modulo numerical equivalence. The vector spaces N1(X) and N1(X) are dual to each other by the intersection pairing, and the nef cone is the dual of the closure <b>of</b> the <b>cone</b> <b>of</b> curves. (The <b>cone</b> <b>of</b> curves need not be closed. For example, the class of the line bundle L on Mumford's surface is a 1-cycle which {{is not in the}} <b>cone</b> <b>of</b> curves, but is in its closure.) ...|$|R
40|$|Abstract. In {{these notes}} we {{investigate}} the <b>cone</b> <b>of</b> nef curves of projective varieties, {{which is the}} dual cone to the <b>cone</b> <b>of</b> pseudo-effective divisors. We prove a structure theorem for the <b>cone</b> <b>of</b> nef curves of projective Q-factorial klt pairs of arbitrary dimension {{from the point of}} view of the Minimal Model Program. This is a generalization of Batyrev’s structure theorem for the <b>cone</b> <b>of</b> nef curves of projective terminal threefolds. 1...|$|R
40|$|Fault tree {{analysis}} {{is a traditional}} and well-established technique for analyzing system design and robustness. Its purpose is to identify sets of basic events, called cut sets, which can cause a given top level event, e. g. a system malfunction, to occur. Generating fault trees is particularly critical {{in the case of}} reactive systems, as hazards can be the result of complex interactions involving the dynamics of the system and of the faults. Recently, there has been a growing interest in model-based fault tree analysis using formal methods, and in particular symbolic model checking techniques. In this paper we present a broad range of algorithmic strategies for efficient fault tree analysis, based on binary decision diagrams (BDDs). We describe different algorithms encompassing different directions (forward or backward) for reachability analysis, using dynamic <b>cone</b> <b>of</b> <b>influence</b> techniques to optimize the use of the finite state machine of the system, and dynamically pruning of the frontier states. We evaluate the relative performance of the different algorithms on a set of industrial-size test cases...|$|E
40|$|We analyse {{the general}} {{solutions}} for the stress field in planar annuli of isostatic media, a model often used for marginally rigid granular materials in Couette cells. We demonstrate that these solutions are much richer than in rectangular symmetries. Even for uniform media, stress chains are found to curve, broaden away from the stress source, attenuate and leak stress into a <b>cone</b> <b>of</b> <b>influence.</b> Most spectacularly, stress chains may bend back and transmit forces oppositely to the original direction. None of these phenomena arises in solutions for uniform media in Cartesian coordinates. We further analyse non-uniform media, which exhibit chain branching and stress leakage from the chains. These results are directly relevant to the many experiments on granular materials, carried out in Couette cells. They also shed light on, and are supported by, hitherto unexplained experimental observations of curved and back-bending chains, which we point out. In particular, we use our results to provide a new interpretation for the pattern of slip lines observed experimentally. Comment: 12 pages, 6 figures (12, including all sub-figures), submitted to Granular Matte...|$|E
40|$|We {{introduce}} a SAT based automatic abstraction refinement framework for model checking systems with several thousand state {{variables in the}} <b>cone</b> <b>of</b> <b>influence</b> of the specification. The abstract model is constructed by designating {{a large number of}} state variables as invisible. In contrast to previous work where invisible variables were treated as free inputs we describe a computationally more advantageous approach in which the abstract transition relation is approximated by pre-quantifying invisible variables during image computation. The abstract counterexamples obtained from model-checking the abstract model are symbolically simulated on the concrete system using a state-of-the-art SAT checker. If no concrete counterexample is found, a subset of the invisible variables is reintroduced into the system and the process is repeated. The main contribution of this paper are two new algorithms for identifying the relevant variables to be reintroduced. These algorithms monitor the SAT checking phase in order to analyze the impact of individual variables. Our method is complete for safety properties (AG p) in the sense that-performance permitting - a property is either verified or disproved by a concrete counterexample. Experimental results are given to demonstrate the power of our method on real-world designs...|$|E
40|$|In {{these notes}} we {{investigate}} the <b>cone</b> <b>of</b> nef curves of projective varieties, {{which is the}} dual cone to the <b>cone</b> <b>of</b> pseudo-effective divisors. We prove a structure theorem for the <b>cone</b> <b>of</b> nef curves of projective Q-factorial klt pairs of arbitrary dimension {{from the point of}} view of the Minimal Model Program. This is a generalization of Batyrev's structure theorem for the <b>cone</b> <b>of</b> nef curves of projective terminal threefolds. Comment: 15 pages. v 2 : Completely rewritten paper. Structure theorem for the <b>cone</b> <b>of</b> nef curves proved in arbitrary dimension using results of Birkar, Cascini, Hacon and McKernan. To appear in Mathematische Zeitschrif...|$|R
40|$|Abstract. We study metric {{properties}} <b>of</b> the <b>cone</b> <b>of</b> homogeneous nonnegative multi-variate polynomials and the <b>cone</b> <b>of</b> sums {{of powers}} of linear forms, {{and the relationship}} between the two cones. We compute the maximum volume ellipsoid of the natural base <b>of</b> the <b>cone</b> <b>of</b> nonnegative polynomials and the minimum volume ellipsoid of the natural base <b>of</b> the <b>cone</b> <b>of</b> powers of linear forms and compute the coefficients of symmetry of the bases. The multiplication by (x 21 + · · · + x 2 n) m induces an isometric embedding of the space of polynomials of degree 2 k into the space of polynomials of degree 2 (k+m), which allows us to compare the <b>cone</b> <b>of</b> nonnegative polynomials of degree 2 k and the <b>cone</b> <b>of</b> sums of 2 (k +m) -powers of linear forms. We estimate the volume ratio of the bases <b>of</b> the two <b>cones</b> and the rate at which it approaches 1 as m grows...|$|R
40|$|In {{this paper}} {{numerical}} solutions of a two-phase natural convection dusty fluid flow are presented. The two-phase particulate suspension is investigated along a vertical cone by keeping variable viscosity and thermal conductivity of the carrier phase. Comprehensive flow formations {{of the gas}} and particle phases are given with the aim to predict the behavior of heat transport across the heated <b>cone.</b> The <b>influence</b> <b>of</b> i) air with particles, water with particles and oil with particles are shown on shear stress coefficient and heat transfer coefficient. It is recorded that sufficient increment in heat transport rate {{can be achieved by}} loading the dust particles in the air. Further, distribution of velocity and temperature of both the carrier phase and the particle phase are shown graphically for the pure fluid (air, water) {{as well as for the}} fluid with particles (air-metal and water-metal particle mixture) ...|$|R
40|$|Abstract. We {{introduce}} a SAT based automatic abstraction refinement framework for model checking systems with several thousand state {{variables in the}} <b>cone</b> <b>of</b> <b>influence</b> of the specification. The abstract model is constructed by designating {{a large number of}} state variables as invisible. In contrast to previous work where invisible variables were treated as free inputs we describe a computationally more advantageous approach in which the abstract transition relation is approximated by pre-quantifying invisible variables during image computation. model are symbolically simulated on the concrete system using a state-of-the-art SAT checker. If no concrete counterexample is found, a subset of the invisible variables is reintroduced into the system and the process is repeated. The main contribution of this paper are two new algorithms for identifying the relevant variables to be reintroduced. These algorithms monitor the SAT checking phase in order to analyze the impact of individual variables. Our method is complete for safety properties in the sense that – performance permitting – a property is either verified or disproved by a concrete counterexample. Experimental results are given to demonstrate the power of our method on real-world designs. ...|$|E
40|$|In this correspondence, a new {{algorithm}} for {{noise reduction}} using the wavelet transform is proposed. Similar to Mallat's wavelet transform modulus maxima denoising approach, we estimate the regularity of {{a signal from}} the evolution of its wavelet transform coefficients across scales. However, we do not perform maxima detection and processing; therefore, complicated reconstruction is avoided. Instead, the local regularities of a signal are estimated by computing {{the sum of the}} modulus of its wavelet coefficients inside the corresponding “cone of influence,” and the coefficients that correspond to the regular part of the signal for reconstruction are selected. The algorithm gives an improved denoising result, as compared with the previous approaches, in terms of mean squared error and visual quality. The new denoising algorithm is also invariant to translation. It does not introduce spurious oscillations and requires very little a priori information of the signal or noise. Besides, we extend the method to two dimensions to estimate the regularity of an image by computing the sum of the modulus of its wavelet coefficients inside the so-called “directional <b>cone</b> <b>of</b> <b>influence.</b> ” The denoising technique is applied to tomographic image reconstruction, where the improved performance of the new approach can clearly be observed. Department of Electronic and Information Engineerin...|$|E
40|$|In this paper, a new {{algorithm}} for {{noise reduction}} using the wavelet transform is proposed. The new {{approach can be}} viewed as a combination of Mallat and Donoho's denoising methods. Similar to Mallat's approach, we estimate the regularity of a signal from the evolution of its wavelet transform coefficients across scales. However, we do not perform maxima detection and processing, and therefore, complicated reconstruction is avoided. Instead, we propose to estimate the regularity of a signal by computing the sum of the modulus of its wavelet coefficients inside the corresponding "cone of influence" and select the coefficients that correspond to the regular part of the signal for reconstruction. In the selection procedure, we propose to use both the techniques of "interscale ratio" and "interscale difference" to obtain the required wavelet coefficients. The algorithm gives an improved denoising result as compared with the previous approaches in terms of mean squared error and visual quality. The new denoising algorithm is also invariant to translation. It does not introduce spurious oscillations and requires very little a priori information of the signal or noise. Besides, we extend the method to two-dimensions to estimate the regularity of an image by computing the sum of the modulus of its wavelet coeflicients inside the so-called "directional <b>cone</b> <b>of</b> <b>influence.</b> " The denoising technique is applied to tomographic image reconstruction, where the improved performance of the new approach can clearly be observed. Department of Electronic and Information Engineerin...|$|E
30|$|From Definitions 2.6 and 2.7 {{it follows}} that the set <b>of</b> <b>cones</b> <b>of</b> the same sense is {{disjoint}} with the set <b>of</b> <b>cones</b> <b>of</b> the opposite sense. If a certain subsystem <b>of</b> <b>cones</b> is <b>of</b> the opposite sense, then the whole system is also of the opposite sense.|$|R
40|$|Abstract. The nef <b>cone</b> <b>of</b> a {{projective}} variety Y is {{an important}} and often elusive invariant. In this paper we construct two polyhedral lower bounds and one polyhedral upper bound for the nef <b>cone</b> <b>of</b> Y using an embedding of Y into a toric variety. The lower bounds generalize the combinatorial description <b>of</b> the nef <b>cone</b> <b>of</b> a Mori dream space, while the upper bound generalizes the F-conjecture for the nef <b>cone</b> <b>of</b> the moduli space M 0,n to a wide class of varieties. 1...|$|R
30|$|C is {{such that}} u∈ C and λ∈Kλ u∈ C; C is {{sometimes}} called a generalized <b>cone</b> <b>of</b> E. Clearly, every generalized <b>cone</b> <b>of</b> E is a cone.|$|R
