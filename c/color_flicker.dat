5|39|Public
5000|$|A variant {{method was}} {{promoted}} by William Friese-Greene. He called his additive color system [...] "Biocolour". It differed from Kinemacolor {{only in that}} the need for a filter-equipped projector was eliminated by staining alternate frames of the film itself with red and green dyes. An ordinary projector could therefore be used, if it would bear being cranked at a sufficient rate. Like Kinemacolor, Biocolour suffered from noticeable <b>color</b> <b>flicker</b> and from red and green fringing when the subject was in rapid motion.|$|E
5000|$|Both {{devices were}} {{operated}} {{at twice the}} usual frame rate to reduce the <b>color</b> <b>flicker</b> (technically known as [...] "color bombardment") produced by non-simultaneous projection of the two color components, a defect which some viewers barely noticed but which others found obtrusive and headache-inducing. A related defect was the most obvious shortcoming of this process: because the two components had not been photographed at the same time, as pairs of frames, rapidly moving subjects did not adequately match up from one frame to the next when projected on the screen, resulting in color [...] "fringes" [...] or in extreme cases vividly colored [...] "ghosts". A white dog wagging its tail {{in front of a}} dark background could appear to have several tails, variously red, green and white.|$|E
50|$|After experimenting from 1915 to 1921 with {{additive}} color systems that filmed and projected the two color components simultaneously, {{rather than in}} rapid alternation (thereby eliminating Kinemacolor's <b>color</b> <b>flicker</b> and false color fringes around rapidly moving objects), the Technicolor Motion Picture Corporation developed a subtractive color print process. As in its last additive system, the camera had only one lens but used a beam splitter that allowed red and green-filtered images to be photographed simultaneously on adjacent frames of a single strip of black-and-white 35 mm film, which ran through the camera at twice the normal rate. By skip-frame printing from the negative, two prints were made, on film stock with half the normal base thickness. They were chemically toned (i.e., the silver particles forming the black-and-white images were proportionally replaced by coloring matter) to colors roughly complementary to the filter colors (red for the green-filtered images and vice versa), as subtractive color reproduction requires. They were then cemented together, base to base, into a single strip of film. No special projection equipment was needed.|$|E
60|$|Again the {{tell-tale}} <b>color</b> <b>flickered</b> in her face; then it vanished, and {{her voice}} shook a little.|$|R
5000|$|Nicedisc are an {{experimental}} audio/video duo consisting of Jeffrey Pash and Nick Phillips. Influenced by the structural film movement, Nicedisc's work {{thus far has}} tended towards minimalism and austerity. In 2004, the duo released the DVD [...] "Untitled" [...] on Brooklyn label Rebuild All Your Ruins. The DVD features three extended audio/video pieces centered {{on the use of}} full-screen <b>color</b> <b>flickers</b> and fades.|$|R
6000|$|At last, {{when the}} lights of Brandon glimmered ahead, Heysham fell over the fireman as the {{locomotive}} jumped to the checking of the brake, and a <b>colored</b> <b>flicker</b> blinked beside the track. The glare of another head-lamp beat upon us as we rolled through the station, while amid the clash of shocking wheat-cars that swept past I caught the warning: ...|$|R
5000|$|The use of {{sequential}} color {{systems for}} moving images predates {{the invention of}} fully electronic television. Although usually known at the time simply as [...] "additive" [...] rather than sequential color systems, two-color Kinemacolor, in commercial use since 1906, and its predecessor three-color format, invented by Edward Raymond Turner and patented in 1899, were both sequential natural color systems for use with motion picture film. They utilized black-and-white film and rotating color filter wheels to record the amount of each color in the scene on alternating frames of the film, {{so that when the}} frames were projected by light of similar colors at a sufficiently rapid rate, those colors blended together in the viewer's eye and produced a wider range of hues. Due to litigation by William Friese-Greene, Kinemacolor ended up in the public domain in 1915, after which several derivative sequential color processes (such as Friese-Greene's Biocolour and the original Prisma Color) were developed. Some were brought {{to the point of being}} publicly shown, but during the 1920s they could not compete with rival bipack and other subtractive color processes, which were free of <b>color</b> <b>flicker</b> and did not require special projection equipment—the final multicolored images were right there on the film as transparent coloring matter.|$|E
40|$|AbstractThis study {{analyzed}} the luminance and color emmetropization response in chicks {{treated with the}} nonselective parasympathetic antagonist atropine and the sympathetic β-receptor blocker timolol. Chicks were binocularly exposed (8 h/day) for 4 days {{to one of three}} illumination conditions: 2 Hz sinusoidal luminance flicker, 2 Hz sinusoidal blue/yellow <b>color</b> <b>flicker,</b> or steady light (mean 680 lux). Atropine experiments involved monocular daily injections of either 20 μl of atropine (18 nmol) or 20 μl of phosphate-buffered saline. Timolol experiments involved monocular daily applications of 2 drops of 0. 5 % timolol or 2 drops of distilled H 2 O. Changes in the experimental eye were compared with those in the fellow eye after correction for the effects of saline/water treatments. Atropine caused a reduction in axial length with both luminance flicker (− 0. 078 ± 0. 021 mm) and <b>color</b> <b>flicker</b> (− 0. 054 ± 0. 017 mm), and a reduction in vitreous chamber depth with luminance flicker (− 0. 095 ± 0. 023 mm), evoking a hyperopic shift in refraction (3. 40 ± 1. 77 D). Timolol produced an increase in axial length with luminance flicker (0. 045 ± 0. 030 mm) and a myopic shift in refraction (− 4. 07 ± 0. 92 D), while <b>color</b> <b>flicker</b> caused a significant decrease in axial length (− 0. 046 ± 0. 017 mm) that was associated with choroidal thinning (− 0. 046 ± 0. 015 mm). The opposing effects on growth and refraction seen with atropine and timolol suggest a balancing mechanism between the parasympathetic and β-receptor mediated sympathetic system through stimulation of the retina with luminance and color contrast...|$|E
5000|$|Originally, {{film was}} {{a strip of}} {{cellulose}} nitrate coated with black-and-white photographic emulsion. Early film pioneers, like D. W. Griffith, color tinted or toned portions of their movies for dramatic impact, and by 1920, 80 to 90 percent of all films were tinted. The first successful natural color process was Britain's Kinemacolor (1908-1914), a two-color additive process that used a rotating disk with red and green filters {{in front of the}} camera lens and the projector lens. But any process that photographed and projected the colors sequentially was subject to color [...] "fringing" [...] around moving objects, and a general <b>color</b> <b>flickering.</b>|$|R
5000|$|On December 6, 1908 new {{colors were}} chosen as red and yellow. Ali Sami Yen stated, [...] "After {{we have been}} in and out of several shops, we saw two {{different}} elegant-looking wool materials in Fatty Yanko's store at Bahçekapısı (between Eminönü and Sirkeci in Istanbul, now called Bahçekapı). One of them was quite dark red, resembling the cherry color, and the other a rich yellow with a touch of orange. When the sales clerk made the two fabrics fly together with a twist of his hand they became so bright that it reminded us the beauty of a goldfinch. We thought we were looking at the <b>colors</b> <b>flickering</b> in burning fire. We were picturing the yellow-red flames shining on our team and dreaming that it would take us to victories. Indeed it did." ...|$|R
50|$|Benham's top, {{also called}} Benham's disk, {{is named after}} the English newspaper-man and toymaker Charles Benham, who in 1895 sold a top painted with the pattern shown. When the disk is spun, arcs of pale color, called Fechner <b>colors</b> or pattern-induced <b>flicker</b> <b>colors</b> (PIFCs), are visible at {{different}} places on the disk. Not everyone sees the same colors. Benham was inspired to propagate the Fechner color effect through his top after his correspondence with Dr. Gustav Theodor Fechner, who had observed and demonstrated the said effect.|$|R
50|$|The Fechner color {{effect is}} an {{illusion}} of color seen when looking at certain rapidly changing or moving black-and-white patterns. They are also called pattern induced <b>flicker</b> <b>colors</b> (PIFCs). Not everyone sees the same colors.|$|R
5000|$|We were picturing the yellow-red flames {{shining on}} our team and dreaming {{that it would take}} us to victories. Indeed it did. Ali Sami Yen On 6 December 1908, for a match against the {{football}} team of the Royal Navy cruiser HMS Barham's crewmen, Galatasaray finally settled on playing in red and yellow, inspired by the roses which Gül Baba offered to Sultan Bayezid II. Ali Sami Yen stated, [...] "After we have {{been in and out of}} several shops, we saw two different elegant-looking wool materials in Fatty Yanko's store at Bahçekapısı (between Eminönü and Sirkeci in Istanbul, now called Bahçekapı). One of them was quite dark red, resembling the cherry color, and the other a rich yellow with a touch of orange. When the sales clerk made the two fabrics fly together with a twist of his hand they became so bright that it reminded us the beauty of a goldfinch. We thought we were looking at the <b>colors</b> <b>flickering</b> in burning fire. We were picturing the yellow-red flames shining {{on our team}} and dreaming that it would take us to victories. Indeed it did." ...|$|R
60|$|Whilst the Seneschal of Villefranche {{had been}} {{detailing}} the evil doings of his tenants, Alleyne {{had been unable}} to take his eyes from the face of Lady Tiphaine. She had lain back in her chair, with drooping eyelids and bloodless face, so that he had feared at first her journey had weighed heavily upon her, and that the strength was ebbing out of her. Of a sudden, however, there came a change, for a dash of bright <b>color</b> <b>flickered</b> up on to either cheek, and her lids were slowly raised again upon eyes which sparkled with such lustre as Alleyne had never seen in human eyes before, while their gaze was fixed intently, not on the company, but on the dark tapestry which draped the wall. So transformed and so ethereal was her expression, that Alleyne, in his loftiest dream of archangel or of seraph, had never pictured so sweet, so womanly, and yet so wise a face. Glancing at Du Guesclin, Alleyne saw that he also was watching his wife closely, and from the twitching of his features, and the beads upon his brick-colored brow, {{it was easy to see}} that he was deeply agitated by the change which he marked in her.|$|R
40|$|Male Siamese {{fighting}} fish exhibit stereotyped aggression {{reactions to}} their mirror reflections. When distinctive neutral stimuli (<b>flickering</b> <b>colored</b> lights) were repeatedly associated with drug-potentiated aggression (morphine sulfate) and drug-depressed aggression (phenergan), the stimuli came to exert specific stimulus control over aggressive display {{even after the}} drugs were discontinued...|$|R
50|$|A weather beacon shaped as {{a natural}} gas flame {{was added to the}} top of the Wisconsin Gas Building in 1956. It {{indicates}} the weather forecast by its <b>color</b> and <b>flicker.</b> The flame was turned off in 1973 because of that year's energy crisis. It was turned on again in 1985. The flame stands 21 feet tall and weighs four tons. In 2013, the neon tube lighting system was replaced with an LED lighting system. The new LED system allows millions of colors and various other lighting schemes outside the traditional red-gold-blue system, including charity efforts and sports team colors.|$|R
40|$|A novel {{method to}} detect smoke and/or flame by {{processing}} the video data generated by an ordinary camera monitoring a scene is proposed. It is assumed {{the camera is}} stationary. Since the smoke is semi-transparent, edges of image frames start loosing their sharpness and {{this leads to a}} decrease in the high frequency content of the image. To determine the smoke, the background of the scene is estimated and decrease of high frequency energy of the scene is monitored using the spatial wavelet transforms of the current and the background images. For the detection of flames, in addition to ordinary motion and <b>color</b> clues, <b>flicker</b> analysis is also carried out by analyzing the video in wavelet domain. These clues are combined to reach a final decision. © 2005 IEEE...|$|R
40|$|Abstract—The field {{sequential}} color (FSC) mechanism {{can effectively}} generate multi-primary color fields in temporal se-quence {{to form a}} full-color image. Color breakup (CBU), however, has appeared intrinsically in conventional FSC displays to de-grade visual qualities. A novel CBU suppression method, color fields arrangement (CFA), was proposed to eliminate the artifacts for FSC liquid crystal displays (LCDs). The modified order of consecutive color fields results in superimposed color images on a retina without CBU. Additionally, the 4 -CFA method with a field rate of 240 Hz was found to avoid the flicker phenomenon on static images. The proposed method was successfully implemented on a 5. 6 -in optically compensated bend (OCB) LC panel. Our results confirm that the visibility of CBU artifacts can be reduced as the evaluation of dynamic and static models. Index Terms—Color breakup (CBU), field sequential <b>color</b> (FSC), <b>flicker.</b> I...|$|R
40|$|Visual {{saliency}} is a probabilistic {{estimate of}} how likely a given spatial area in an image or video is to attract human visual attention {{relative to other}} areas. Bottom-up saliency models aggregate low-level image features like luminance and <b>color</b> contrast, <b>flicker,</b> 2 D motion, etc. to construct a plausible saliency map. In this paper, we introduce 3 D motion (object movements towards or away from the observer) into bottom-up video saliency modeling. Given availability of per-pixel depth maps, we first propose a novel algorithm to estimate 3 D motion vectors (3 DMVs) for arbitrarily shaped sub-blocks in texture-plus-depth videos. We then derive two feature channels from 3 DMVs to be incorporated into a widely accepted bottom-up saliency model. Experiments on subjective quality of Region-of-Interest (ROI) based video coding show that our enriched saliency model with 3 DMV channels is more accurate in estimating human visual attention. © 2013 IEEE...|$|R
5000|$|Coleco also ported Mouse Trap to the Atari 2600, {{simplifying}} {{graphics and}} gameplay. The maze is more squat with brighter walls, and doors form a single <b>colored</b> set that <b>flickers.</b> Gameplay basics are the same, but the hawk, the [...] "IN" [...] area, and the bonus prizes are missing, {{there are three}} cats instead of six, and all doors move at once. Scoring is also reduced significantly: cheese is worth 1 point instead of 10 points, cats are worth 10 points and do not increase in value, and clearing a maze awards only 100 points.|$|R
40|$|AbstractCan vision tests predict {{subsequent}} loss of acuity? The {{association between}} performance on several low contrast spatial vision measures, glare recovery, <b>color</b> discrimination, <b>flicker</b> sensitivity, stereopsis and ocular disease status at baseline and acuity loss 4. 4 years later was examined {{in a large}} aged random sample with good initial acuity. In univariate analyses, several vision measures, retinal disease status and age were each significant predictors of subsequent acuity loss. In a multiple regression analysis, only low contrast spatial vision was a significant predictor, but the other vision measures, retinal disease status and age were not. For each doubling of low contrast spatial vision threshold at baseline, individuals were more than two {{times as likely to}} suffer subsequent significant visual acuity loss. Tests of low contrast spatial vision are strong predictors of significant subsequent visual acuity loss. These findings have implications for clinical trials, clinical management, and acceptance of these measures into clinical practice...|$|R
500|$|The {{game has}} {{remained}} poorly rated. [...] In 1998, Next Generation magazine editors {{called it the}} [...] "worst coin-op conversion of all time", and attributed the mass dissatisfaction to its poor quality. In 2006, IGN's Craig Harris echoed similar statements and listed it as the worst arcade conversion, citing poor audio-visuals that did not resemble the original. Another IGN editor, Levi Buchanan, {{described it as a}} [...] "disastrous port", citing the <b>color</b> scheme and <b>flickering</b> ghosts. Skyler Miller of AllGame said that although the game was only a passing resemblance to the original, it was charming despite its many differences and faults.|$|R
30|$|Furthermore, we {{discussed}} various sensor dynamic-range extension techniques and {{have chosen the}} exposure bracketing for this task. In {{the remainder of the}} paper, we have discussed some solutions for the problem of moving scene objects and nonconstant light sources such as fluorescent light, that introduce false <b>colors</b> and light <b>flickering.</b> In particular, two methods were proposed for fluorescent-light handling: automatic fluorescent light detection and fluorescence locking. Our experiments showed {{that it is possible to}} design such a detector as well as control mechanisms based on PLL principles. However, the robustness of such a system is difficult to achieve when various interferences occur simultaneously.|$|R
40|$|The effects upon {{range of}} {{accommodation}} and color vision of reduced atmospheric pressure, at partial and complete elimination of nitrogen, of hypoxia, and of exposure for varying {{periods of time}} to restricted visual environment, have been studied alone or in various combinations. Measurements were made on the electroretinogram, the electrooculogram, and {{the diameter of the}} retinal vessels as an indicator of blood flow to the retina at the time of total elimination of nitrogen. An objective method was used to test range of accommodation. In the color vision test the <b>flicker</b> <b>colors</b> of a Benham's top were matched with a colorimeter...|$|R
5000|$|The {{game has}} {{remained}} poorly rated. In 1998, Next Generation magazine editors {{called it the}} [...] "worst coin-op conversion of all time", and attributed the mass dissatisfaction to its poor quality. In 2006, IGN's Craig Harris echoed similar statements and listed it as the worst arcade conversion, citing poor audio-visuals that did not resemble the original. Another IGN editor, Levi Buchanan, {{described it as a}} [...] "disastrous port", citing the <b>color</b> scheme and <b>flickering</b> ghosts. Skyler Miller of AllGame said that although the game was only a passing resemblance to the original, it was charming despite its many differences and faults.|$|R
40|$|What are {{the visual}} causes, rather than mere correlates, of attentional {{selection}} {{and how do}} they compare to each other during natural vision? To address these questions, we first strung together semantically unrelated dynamic scenes into MTV-style video clips, and performed eye tracking experiments with human observers. We then quantified predictions of saccade target selection based on seven bottom-up models, including intensity variance, orientation contrast, intensity contrast, <b>color</b> contrast, <b>flicker</b> contrast, motion contrast, and integrated saliency. On average, all tested models predicted saccade target selection well above chance. Dynamic models were particularly predictive of saccades that were most likely bottom-up driven-initiated shortly after scene onsets, leading to maximal interobserver similarity. Static models showed mixed results in these circumstances, with intensity variance and orientation contrast featuring particularly weak prediction accuracy (lower than their own average, and approximately 4 times lower than dynamic models). These results indicate that dynamic visual cues play a dominant causal role in attracting attention. In comparison, some static visual cues play a weaker causal role, while other static cues are not causal at all, and may instead reflect top-down causes...|$|R
40|$|This paper {{proposes a}} novel method to detect flames in video by {{processing}} the data generated by an ordinary camera monitoring a scene. In addition to ordinary motion and <b>color</b> clues, flame <b>flicker</b> process is also detected by using a hidden Markov model. Markov models representing the flame and flame colored ordinary moving objects are used to distinguish flame flicker process from motion of flame colored moving objects. Spatial color variations in flame are also evaluated by the same Markov models, as well. These clues are combined to reach a final decision. False alarms due to ordinary motion of flame colored moving objects are greatly reduced {{when compared to the}} existing video based fire detection systems. © 2005 IEEE...|$|R
40|$|AbstractIt is well {{established}} that the spectral sensitivity under photopic conditions varies across the human retina. We investigate the mechanisms underlying these spectral changes. Through the use of <b>color</b> appearance, <b>flicker</b> sensitivity, additivity, discrimination at threshold and modeling, we show that the changes in spectral sensitivity on a photopic white background across parafoveal retina are consistent with shifts in cone weightings to (LM) and (ML) chromatic channels. This two channel model, developed to account for foveal spectral sensitivity curves (Sperling & Harwerth, 1971 Science, 172, 180 – 184), provides a better description of parafoveal data than both a single color channel upper envelope model (comprised of a single red-green opponent channel and an achromatic mechanism) and a vector model (combining a red-green opponent channel with an achromatic component). Thus while the two channel model ([LM] and [ML]) of foveal color vision is generalizable to the parafovea, simple models with a unitary red/green process are not. Although the two channel model can accurately fit parafoveal spectral sensitivity curves without it, a small contribution from a luminance mechanism might improve {{the ability of the}} two channel model to account for threshold discrimination and additivity data...|$|R
5000|$|Much of Kessler’s {{work from}} the 1990s {{examined}} the interactions and tensions between Orient and Occident. He often presented Asia as a construct of Western Orientalism, {{while at the same}} time portraying the West in a steady state of decline. Kessler blended these visions with equal parts humor and tragedy in pieces such as The Last Birdrunner (1994), a kinetic sculpture based on the science fiction movie Blade Runner. Shown in a solo exhibition at the Luhring Augustine Gallery in New York in 1994, The Last Birdrunner consists of a stuffed bird outfitted in a parachute pack and perched on a ledge that slowly travels up and down while a motor-driven apparatus plays out a haunting dirge on a toy piano. Meanwhile, <b>colored</b> lights <b>flicker</b> in and out of focus against a geodesic dome in the background so that the scene takes on the appearance - though none of the care-free energy - of a Tokyo night club. The Last Birdrunner represents, according to Artforum critic Neville Wakefield, “the nemesis of … utopian dreams in the guise of a lonely cockatoo wearing a life vest.” ...|$|R
40|$|We used an {{electrophysiological}} {{measure of}} selective stimulus processing (the steady-state visual evoked potential, SSVEP) to investigate feature-specific attention to color cues. Subjects viewed a display consisting of spatially intermingled {{red and blue}} dots that continually shifted their positions at random. The red and blue dots flickered at different frequencies and thereby elicited distinguishable SSVEP signals in the visual cortex. Paying attention selectively to either the red or blue dot population produced an enhanced amplitude of its frequency-tagged SSVEP, which was localized by source modeling to early levels of the visual cortex. A control experiment showed that this selection was based on <b>color</b> rather than <b>flicker</b> frequency cues. This signal amplification of attended color items provides an empirical basis for the rapid identification of feature conjunctions during visual search, as proposed by “guided search” models...|$|R
40|$|This paper {{proposes a}} flame {{detection}} framework {{based on the}} <b>color,</b> dynamics and <b>flickering</b> properties of flames. The distribution of flame colors is modelled by a Gaussian Mixture Model whose number of Gaussian component is estimated by a Dirichlet process from training data rather than set empirically. The proposed approach estimates the flame color distribution more accurately as it can {{determine the number of}} Gaussian components of the mixture model automatically. Additionally, a probabilistic saliency analysis method and a one-dimensional wavelet transform are used to extract motion saliency and filtered temporal series as features, describing the dynamics and flickering properties of flames. The developed Dirichlet Process Gaussian Mixture Model based approach for autonomous flame detection is tested on various videos and achieves frame-wise accuracy higher than 95 %...|$|R
40|$|AbstractTwo {{distinctive}} fire flame characteristics, i. e., <b>color</b> {{information and}} <b>flickering</b> {{are discussed in}} this paper to provide basic criteria to improve the anti-jamming ability and reliability of the video flame detection technology in complex scenes. An effective real-time flame color detection criterion is firstly proposed by the method of two-dimensional color space reconstruction and saturation fitting for the manually collected flame-pixel sample database. The flame size and accumulated gray value are then extracted to construct the time series of video sequences of four combustion experiments. At last, the oscillation frequency of the flame flickering is calculated by performing the Fourier Transform for these time series. It is found that oscillation frequencies are in good agreement with the ones calculated by Pagni's law. The results of this paper {{can be used as}} bases of multi-feature fusion video flame detection method...|$|R
40|$|Bottom-up visual {{attention}} allows primates {{to quickly}} select regions {{of an image}} that contain salient objects. In artificial systems, restricting the task of object recognition to these regions allows faster recognition and unsupervised learning of multiple objects in cluttered scenes. A problem with {{this approach is that}} objects superficially dissimilar to the target are given the same consideration in recognition as similar objects. In video, objects recognized in previous frames at locations distant to the current fixation point are given the same consideration in recognition as objects previously recognized in locations closer to the current target of attention. Due to the continuity of smooth motion, objects recently recognized in previous frames at locations close to the current focus of attention have a high probability of matching the current target. Here we investigate rapid pruning of the facial recognition search space using the already-computed low-level features that guide attention and spatial information derived from previous video frames. For each video frame, Itti & Koch’s bottom-up visual attention algorithm is used to select salient locations based on low-level features such as contrast, orientation, <b>color,</b> intensity, <b>flicker</b> and motion. This algorithm has shown to be highly effective in selecting faces as salient objects. Lowe’s SIFT object recognition algorithm then extracts a signature of the attended object, for comparison with the facial database. The database search is prioritized for faces which better match the low-level features used to guide attention to the current candidate for recognition or those that were previously recognized near the current candidate’s location. The SIFT signatures of the prioritized faces are then checked against the attended candidate for a match. By comparing performance of Lowe’s recognition algorithm and Itti & Koch’s bottom-up attention model with or without search space pruning we demonstrate that our pruning approach improves the speed of facial recognition in video footage...|$|R
40|$|Visualizations enable {{scientists}} to inspect, interpret, and analyze large multi-dimensional data sets. Effective visualizations {{are designed to}} both orient and engage viewers by directing attention {{in response to a}} visual stimulus, and then encouraging a viewer’s vision to linger at a given image location. Research into human visual perception provides information about how to orient viewers, using salient visual features, such as <b>color,</b> orientation, and <b>flicker.</b> Less is known about how to build engaging visualizations. Increasing the aesthetic merit of visualizations is a promising approach to increasing engagement. Intuition suggests that visualizations with a more aesthetic presentation style will be judged as more artistic, but this is an open problem. In this thesis, we explored an important question pertaining to creating aesthetic visualizations: Is it possible to affect the perceived artistic merit of a scientific visualization? To investigate this question, we developed three new painterly visualization techniques, designed to vary different visual qualities important to aesthetics: interpretational complexity (IC), indication and detail (ID), and visual complexity (VC). We conducted four experiments to investigate how these qualities affect the aesthetics. Observers were asked to rank IC, ID, and VC images, together with Master abstract and Impressionist paintings on five questions...|$|R
40|$|In this paper, a video based {{algorithm}} {{for fire}} and flame detection is developed. In addition to ordinary motion and <b>color</b> clues, flame <b>flicker</b> is distinguished from motion of flame colored moving objects using Markov models. Irregular nature of flame boundaries is detected by performing temporal wavelet analysis using Hidden Markov Models as well. Color variations in fire is detected by computing the spatial wavelet transform of moving fire-colored regions. Boundary of flames {{are represented in}} wavelet domain and irregular nature of the boundaries of fire regions is also used {{as an indication of}} the flame flicker. Decisions from sub-algorithms are linearly combined using an adaptive active fusion method. The main detection algorithm is composed of four sub-algorithms (i) detection of fire colored moving objects, (ii) temporal, and (iii) spatial wavelet analysis for flicker detection and (iv) contour analysis of fire colored region boundaries. Each algorithm yields a continuous decision value as a real number in the range [- 1, 1] at every image frame of a video sequence. Decision values from sub-algorithms are fused using an adaptive algorithm in which weights are updated using the least mean square (LMS) method in the training (learning) stage. © 2009 Springer Science+Business Media, LLC...|$|R
40|$|In {{our earlier}} study {{dealing with the}} {{analysis}} of neuromagnetic responses (magnetoencephalograms—MEG) to flickering-color stimuli {{for a group of}} control human subjects (9 volunteers) and a patient with photosensitive epilepsy (a 12 -year old girl), it was shown that Flicker-Noise Spectroscopy (FNS) was able to identify specific differences in the responses of each organism. The high specificity of individual MEG responses manifested itself in the values of FNS parameters for both chaotic and resonant components of the original signal. The present study applies the FNS cross-correlation function to the analysis of correlations between the MEG responses simultaneously measured at spatially separated points of the human cortex processing the red-blue <b>flickering</b> <b>color</b> stimulus. It is shown that the cross-correlations for control (healthy) subjects are characterized by frequency and phase synchronization at different points of the cortex, with the dynamics of neuromagnetic responses being determined by the low-frequency processes that correspond to normal physiological rhythms. But for the patient, the frequency and phase synchronization breaks down, which is associated with the suppression of cortical regulatory functions when the flickering-color stimulus is applied, and higher frequencies start playing the dominating role. This suggests that the disruption of correlations in the MEG responses is the indicator of pathological changes leading to photosensitive epilepsy, which can be used for developing a method of diagnosing the disease based on the analysis with the FNS cross-correlation function...|$|R
