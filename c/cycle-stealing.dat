23|0|Public
50|$|The IBM 1800 Data Acquisition and Control System (DACS) was {{a process}} control {{variant of the}} IBM 1130 with two extra {{instructions}} (CMP and DCM), extra I/O capabilities, 'selector channel like' <b>cycle-stealing</b> capability and three hardware index registers.|$|E
5000|$|The <b>cycle-stealing</b> {{concept of}} the 1130permits the CPU program to start an {{operation}} on an I/O device and then continue the mainline program while the I/O device is performing its operation. Each I/O device that operates in this manner takes (steals) a cycle from the CPU when it is needed.The CPU is [...] "tied up" [...] only one cycle while a data character is being transferred. The frequency at which devices steal cycles depends {{on the type of}} device.Since the CPU is much faster than any I/O device on the system, the CPU may be performing another function, such as arithmetic, at the same time an I/O operation is being performed. In fact, several I/O operations may be overlapped {{with each other and with}} other CPU functions.|$|E
40|$|A DMA {{controller}} {{that operates}} in the <b>cycle-stealing</b> mode transfers data by stealing bus cycles from the CPU. The concurrent contention for the I/O bus by a CPU task and a <b>cycle-stealing</b> DMA I/O task retards their progress and extends their execution times. In this paper we first describe {{a method for}} bounding the worst-case execution time (WCET) of a CPU task when <b>cycle-stealing</b> DMA I/O is present. We next use the dynamic-programming technique to develop a method for bounding the WCET of a <b>cycle-stealing</b> DMA I/O task executing concurrently {{with a set of}} CPU tasks. We conducted exhaustive simulations on a widely-used embedded processor. The experimental results demonstrate that our methods tightly bound the WCETs of CPU tasks and of <b>cycle-stealing</b> DMA I/O tasks. Keywords: hard-real-time systems, worst-case execution time, <b>cycle-stealing</b> DMA I/O, concurrent execution, embedded systems 1...|$|E
40|$|Existing <b>cycle-stealing</b> {{frameworks}} {{are generally}} based on simple client-server or hierarchical style architectures. G 2 :P 2 P moves <b>cycle-stealing</b> into the "pure" peer-to-peer (P 2 P), or fully decentralised arena, removing the bottleneck and {{single point of failure}} that centralised systems su#er from. Additionally, by utilising direct P 2 P communication, G 2 :P 2 P supports a far {{broader range of}} applications than the master-worker style that most <b>cycle-stealing</b> frameworks o#er...|$|E
40|$|A DMA {{controller}} {{that operates}} in the <b>cycle-stealing</b> mode {{is allowed to}} transfer data only when the CPU does not need the system bus. Thus, the execution time of a <b>cycle-stealing</b> DMA I/O task depends on the sequence of instructions executing concurrently with it. This paper describes a method for bounding the worst-case execution time (WCET) of a <b>cycle-stealing</b> DMA I/O task. We first define the task model. We next describe several properties of instruction sequences that can execute concurrently with a <b>cycle-stealing</b> DMA I/O task. Based on these properties we develop a recursive formula to compute the WCET of the DMA I/O task. The recursive formula gives {{the basis of a}} dynamic programming method to find the WCET of the DMA I/O task. We conducted a simulation experiment to evaluate the performance of the dynamic programming method. Keywords: worst-case execution time, <b>cycle-stealing</b> DMA I/O, hard-real-time systems 1 Introduction In a hard-real-time system, many tasks are required to [...] ...|$|E
40|$|We derive {{efficient}} {{guidelines for}} scheduling dataparallel computations within a draconian mode of cyclestealing in networks of workstations wherein an interruption {{by the owner}} of the “borrowed ” workstation kills all jobs currently in progress. We derive both adaptive and non-adaptive scheduling guidelines that maximize, up to low-order additive terms, the amount of work that one is guaranteed to accomplish during a <b>cycle-stealing</b> opportunity, no matter when the opportunity is interrupted—up to a prespecified number of times. 1. <b>Cycle-Stealing</b> in Clusters Many sources eloquently argue the technological and economic inevitability of an increasingly common modality of parallel computation, the use of a network of workstations (NOW) as a parallel computer; see, e. g., [8]. Numerous sources describe systems that facilitate the mechanics of NOW-based computing, especially via cycle stealing—the use by one workstation of idle computing cycles of another. However, few sources study the problem of scheduling individual computations on NOWs; even fewer present models that facilitate such scheduling for broad classes of computations. In the current paper, we refine the model developed in [3] and derive guidelines for crafting <b>cycle-stealing</b> schedules for data-parallel computations, which approximately maximize the amount of work that one is guaranteed to accomplish during a <b>cycle-stealing</b> opportunity. 1. 1. Background. In [3], we developed and studied a mathematical model for the problem of scheduling dataparallel computations under the following draconian version of <b>cycle-stealing.</b> The owner of workstation A contracts with the owner of workstation B to take control of B’...|$|E
40|$|Existing <b>cycle-stealing</b> {{frameworks}} {{are generally}} based on simple client-server or hierarchical style architectures. G 2 :P 2 P moves <b>cycle-stealing</b> into the 'pure' peer-to-peer (P 2 P), or fully decentralised arena, removing the bottleneck and {{single point of failure}} that centralised systems suffer from. Additionally, by utilising direct P 2 P communication, G 2 :P 2 P supports a far {{broader range of}} applications than the master-worker style that most <b>cycle-stealing</b> frameworks offer. G 2 :P 2 P moves away from the task based programming model typical of <b>cycle-stealing</b> systems to a distributed object abstraction which simplifies communication. It uses a distributed hash table based overlay network to provide an efficient method of referencing application objects while still allowing volunteer machines to come and go from the network. Most importantly, G 2 :P 2 P provides a sophisticated fault tolerance mechanism to ensure applications execute correctly. This mechanism is entirely automated, requiring no special effort on the application developer's part. The framework is implemented as an extension to. NET's Remoting framework, providing a familiar model for application programmers and an easy upgrade path for existing. NET sequential applications...|$|E
40|$|A DMA {{controller}} {{that operates}} in <b>cycle-stealing</b> mode transfers data by "stealing" bus cycles from an executing program. This cycle stealing operation retards {{the progress of}} the executing program and extends its execution time. In this paper we first present a method that bounds the worst-case execution time of a program executing concurrently with a <b>cycle-stealing</b> DMA I/O operation in the simple case where the execution time of each machine instruction is fixed. We next extend this method to deal with the case of instruction-cache architectures. We demonstrate the effectiveness of our methods by the results of simulations of several programs. Keywords: worst-case execution time, <b>cycle-stealing</b> DMA I/O, hard-real-time systems 1 Introduction In a hard-real-time system, tasks are required to complete by their deadlines. A task that executes longer than its allocated computation time may lead to missed deadlines and the failure of the whole system. In such a system, it is essential f [...] ...|$|E
40|$|We derive {{efficient}} {{guidelines for}} scheduling dataparallel computations within a draconian mode of cyclestealing in networks of workstations wherein an interruption {{by the owner}} of the “borrowed” workstation kills all jobs currently in progress. We derive both adaptive and non-adaptive scheduling guidelines that maximize, up to low-order additive terms, the amount of work that one is guaranteed to accomplish during a <b>cycle-stealing</b> opportunity, no matter when the opportunity is interrupted—up to a prespecified number of times...|$|E
40|$|We derive {{guidelines}} for nearly optimally scheduling data-parallel computations within a draconian mode of <b>cycle-stealing</b> in NOWs. In this computing regimen, workstation A takes control of workstation B’s processor whenever B is idle, {{with the promise}} of relinquishing control immediately upon demand—thereby losing work in progress. The typically high communication overhead for supplying workstation B with work and receiving its results militates in favor of supplying B with large amounts of work at a time; the risk of losing work in progress when B is reclaimed militates in favor of supplying B with a succession of small bundles of work. The challenge is to balance these two pressures in a way that maximizes (some measure of) the amount of work accomplished. Our guidelines attemp...|$|E
40|$|Circuits {{implemented}} in FPGAs have delays that {{are dominated by}} its programmable interconnect. This interconnect provides the ability to implement arbitrary connections. However, it contains both highly capacitive and resistive elements. The delay encountered by any connection depends strongly {{on the number of}} interconnect elements used to route the connection. These delays are only completely known after the place and route phase of the CAD flow. We propose the use of Clock Shifting optimization techniques to improve the clock frequency as a post place and route step. Clock Shifting Optimization is a technique first formalized in [4]. It is a <b>cycle-stealing</b> algorithm that allows one to reduce the critical path delay of a synchronous circuit by shifting the clock signals at each register. This techniqu...|$|E
40|$|Abstract. This paper {{presents}} G 2 Remoting, {{a generic}} remote-object based framework for creating <b>cycle-stealing</b> parallel applications. The framework is built using the extensibility features of the. NET Remoting framework. The G 2 Remoting framework enables programmers to {{program in a}} normal. NET Remoting fashion, without being concerned about the changing set of volunteer machines on which the computation is actually performed. A dedicated server machine is used as the physical manifestation of a virtual parallel machine on which remote objects logically reside from the programmers perspective. The remote objects are not, however, physically created on this server machine; they come into being, and have their methods actually executed, on the various volunteer machines. The remote objects do not, however, permanently reside on any given volunteer machine, they transparently move from one volunteer to another as necessary during their lifetime. ...|$|E
40|$|Abstract- This paper {{describes}} and verifies {{a convergence}} model {{that allows the}} islands in a parallel genetic algorithm to run at different speeds, and to simulate the effects of communication or machine failure. The model extends on present theory of parallel genetic algorithms and furthermore it provides insight into the design of asynchronous parallel genetic algorithms that work efficiently on volatile and heterogeneous networks, such as <b>cycle-stealing</b> applications working over the Internet. The model is adequate for comparing migration parameter settings in terms of convergence and fault tolerance, {{and a series of}} experiments show how the convergence is affected by varying the failure rate and the migration topology, migration rate, and migration interval. Experiments conducted show that while very sparse topologies are inefficient and failure-prone, even small increases in topology order result in more robust models with convergence rates that approach the ones found in fullg-connected topologies. ...|$|E
40|$|The idea of {{stealing}} cycles has been hyped for some years, boasting unlimited potential by tapping the computational power {{of millions of}} under utilized PCs connected to the Internet. Despite a few spectacular success stories (e. g. SETI@HOME), <b>cycle-stealing</b> is today not a widely used technology. We believe two principal impediments need to be overcome. The first is ease of development and use. Most of the problems faced in developing cycle stealing applications are not specific to those applications, so generic cycle stealing frameworks such as our G 2 framework can {{play a vital role}} in this regard. The second is uncertainty. Potential developers don't know whether if they went to the effort of developing a parallel application for a cycle stealing environment, it would pay off, i. e. whether they would get a reasonable speedup. To minimize this risk, we propose the development and use of detailed performance models...|$|E
40|$|Arnold L. Rosenberg # Department of Computer Science University of Massachusetts Amherst, MA 01003 rsnbrg@cs. umass. edu Abstract We derive {{guidelines}} for nearly optimally scheduling data-parallel computations within a draconian mode of <b>cycle-stealing</b> in NOWs. In this computing regimen, workstation A takes control of workstation B's processor whenever B is idle, {{with the promise}} of relinquishing control immediately upon demand [...] -thereby losing work in progress. The typically high communication overhead for supplying workstation B with work and receiving its results militates in favor of supplying B with large amounts of work at a time; the risk of losing work in progress when B is reclaimed militates in favor of supplying B with a succession of small bundles of work. The challenge is to balance these two pressures in a way that maximizes (some measure of) the amount of work accomplished. Our guidelines attempt to maximize the expected work accomplished by workstation B in a [...] ...|$|E
40|$|Database {{systems have}} {{a large number of}} {{configuration}} parameters that control memory distribution, I/O optimization, costing of query plans, parallelism, many aspects of logging, recovery, and other behavior. Regular users and even expert database administrators struggle to tune these parameters for good performance. The wave of research on improving database manageability has largely overlooked this problem which turns out to be hard to solve. We describe iTuned, a tool that automates the task of identifying good settings for database configuration parameters. iTuned has three novel features: (i) a technique called Adaptive Sampling that proactively brings in appropriate data through planned experiments to find high-impact parameters and high-performance parameter settings, (ii) an executor that supports online experiments in production database environments through a <b>cycle-stealing</b> paradigm that places near-zero overhead on the production workload; and (iii) portability across different database systems. We show the effectiveness of iTuned through an extensive evaluation based on different types of workloads, database systems, and usage scenarios. 1...|$|E
40|$|This paper {{describes}} an efficient algorithm which gives a bound on the worst-case execution {{times of the}} concurrent execution of CPU instructions and <b>cycle-stealing</b> DMA I/O operations. Simulations of several programs were conducted to evaluate this algorithm. Compared with the traditional pessimistic approach, the bound on the worst-case execution time produced by the algorithm is significantly tighter. For a sample program that multiplies two matrices while the I/O bus is fully utilized, our algorithm achieves a 39 % improvement in {{the accuracy of the}} prediction. 1 Introduction Algorithms for scheduling tasks in hard-real-time systems typically assume that their worst-case execution times are known. Such a system is deigned to ensure that all tasks can complete by their deadlines as long as no task in a system executes longer than its worst-case execution time (WCET). A task which overruns may lead to missed deadlines and the failure of the whole system. For this reason, how to bound [...] ...|$|E
40|$|The growing {{importance}} of networked workstations as a computing milieu {{has created a}} new modality of parallel computing, namely, the possibility of having one workstation "steal cycles" from another. In a typical episode of <b>cycle-stealing,</b> the owner of workstation B allows the owner of workstation A to take control of B's processor whenever it is idle, with the promise of relinquishing control immediately upon the demand of the owner of B. Typically, the costs for an episode reside in the overhead required to supply workstation B with work (data and, perhaps, the programs to process the data), coupled with the fact that work in progress when the owner of B reclaims the workstation is lost to the owner of A. The first cost militates toward supplying B with a large amount of work at once; the second cost militates toward repeatedly supplying B with small amounts of work. It is this tension that makes the problem interesting. In this paper, we formulate two models of cycle-s [...] ...|$|E
40|$|Peer-to-peer (P 2 P) {{networks}} such as Gnutella and BitTorrent have revolutionised Internet based applications. P 2 P approaches {{provide a}} number of benefits, however most cycle stealing projects, such as SETI@home, have concentrated on centralised methods which still require massive amounts of concentrated network bandwidth in order to scale. More recent P 2 P research has developed the concept of distributed hash table (DHT) P 2 P overlays. These overlays provide efficient and guaranteed message delivery unlike earlier P 2 P networks which relied on large scale replication to probabilistically find data. Our G 2 :P 2 P framework makes use of a DHT overlay to provide a fully decentralised P 2 P cycle stealing system. Its distributed object programming model allows direct communication between objects and it remains reliable even as the set of peer nodes changes. In this paper we describe extensions to G 2 :P 2 P which allow us to optimise object distribution for locality. The importance of optimising data locality is well understood and has received extensive research, however, {{in the context of}} <b>cycle-stealing</b> systems and more generally DHT based P 2 P networks it is completely unexplored. Whilst our work is motivated by parallel programming, it is generic in nature and may have applicability to other DHT applications. 1...|$|E
40|$|This paper {{investigates the}} {{performance}} of task assignment policies for server farms as the variability of job sizes (service demands) approaches infinity. The Size-Interval-Task-Assignment policy (SITA), which separates short jobs from long jobs, has long been viewed as the panacea for dealing with high-variability job-size distributions. A very recent paper showed that this common wisdom is flawed: SITA can actually be inferior to the much simpler greedy policy, Least-Work-Left (LWL), for certain common job-size distributions, including many modal, hyperexponential, and Pareto distributions. The above finding leads one to question whether providing isolation for short jobs from long ones is inherently bad, {{or whether it is}} just SITA 2 ̆ 7 s strict isolation of short jobs that sometimes leads to poor performance. To answer this question, we consider a much more flexible policy, which we call 2 ̆ 2 <b>Cycle-Stealing</b> 2 ̆ 2 (CS). The CS policy is very similar to LWL, in that short jobs can go to any queue, but it still provides short jobs isolation from longs (one server is reserved for short jobs). While CS has many of the same properties as LWL, including high utilization of both servers, we prove, surprisingly, that, for high variability job sizes, CS performs poorly whenever SITA performs poorly. This result suggests that the notion of isolating short jobs from long jobs, under high variability workloads, is sometimes simply not the right thing to do...|$|E
40|$|AbstractOrganisations such as {{research}} institutions and universities often increase utilisation of their office workstations by deploying a high-throughput <b>cycle-stealing</b> distributed system. Such systems allow users {{to submit a}} large number of computing tasks into a central pool. The system observes activity of workstations and continually assigns tasks to idle machines. When a user becomes active on the machine, the scheduler interrupts the task execution. This approach can significantly increase utilisation of the resources. However, it can also lead to wastage of computing cycles if tasks get interrupted too often. In this paper, we develop a detailed Population Continuous Time Markov Chain (PCTMC) model of the whole system that accurately captures the contention between the interactive users and high-throughput tasks. The PCTMC framework is well suited to the inherently time-inhomogeneous nature of the user behaviour and allows to capture {{a large number of}} performance and energy consumption metrics. We fit the PCTMC model to real data and propose a methodology to forecast cluster availability in the near future. We show how to use historically collected and live data to parametrise the PCTMC model and use efficient fluid analysis techniques to predict the desired metrics. Additionally, the fast analysis enables exploration of various what-if scenarios. We demonstrate a working implementation of the method using the existing GPA tool for analysis of PCTMC models. We argue that this methodology could allow the system maintainers to optimise the energy and performance parameters of the system. Moreover, it would benefit the users who could use the model forecasts to better distribute and plan their large scale computations...|$|E
40|$|Abstract — Cycle-harvesting {{software}} on commodity computers {{is available from}} a number of companies and {{a significant part of the}} Grid computing landscape. However, creating commercial service contracts based on resources made available by cycle-harvesting is a significant challenge for two reasons. Firstly, the characteristics of the harvested resources are inherently stochastic. Secondly, in a commercial environment, purchasers can expect the providers of such contracts to optimize against the quality of service (QoS) definitions provided. These challenges have been successfully met in conventional commodities, e. g. Random Length Lumber, traded on financial exchanges and we draw inspiration from there. The essential point for creating commercially valuable QoS definitions is to guarantee a set of statistical parameters for each and every contract instance. In statistical terms this is the difference between guaranteeing the properties of what is delivered versus the source from which the delivery will be made. In this paper we describe an appropriate QoS definition, Hard Statistical QoS (HSQ), and show how this can be implemented for cycleharvested resources using a hybrid stochastic-deterministic system. We present an architecture and algorithms to support HSQ contracts. We analyze algorithm behavior analytically using a distribution-free approach versus the expected proportion of deterministic resources required for an HSQ specification. For example, where slot lengths are log-Normally distributed we find that for hard guarantees on 8 quantiles with contract sizes 16 to 1024 slots, from 13 % to 1 % deterministic resources are required. Permitting oversampling is relatively inefficient leading to up to 61 % of the stochastic resources being wasted in a typical case. Including downwards substitution reduces deterministic resource requirements by roughly half. We conclude that commercial service contracts based on cycle-harvested resources are viable both from a conceptual point of view and quantitatively for contracts of sufficient size. Keywords — <b>Cycle-stealing,</b> cycle-scavenging, QoS, Grid computing...|$|E
40|$|Circuits {{implemented}} in FPGAs have delays that are dom-inated by its programmable interconnect. This intercon-nect provides {{the ability to}} implement arbitrary connec-tions. However, it contains both highly capacitive and re-sistive elements. The delay encountered by any connection depends strongly {{on the number of}} interconnect elements used to route the connection. These delays are only com-pletely known after the place and route phase of the CAD flow. We propose the use of Clock Shifting optimization techniques to improve the clock frequency as a post place and route step. Clock Shifting Optimization is a technique first formal-ized in [4]. It is a <b>cycle-stealing</b> algorithm that allows one to reduce the critical path delay of a synchronous circuit by shifting the clock signals at each register. This technique allows late arriving signals to be sampled at a later point in time by intentionally introducing a skew on the clock input of the sampling register. Typical FPGAs contain a num-ber of special purpose global clock networks that distribute clock signals to every register in the chip. Unused global clock lines in FPGAs can be used to distribute a finite set of clock skews to the entire circuit. We propose an efficient integer programming method to find the optimal circuit im-provement for a finite set of clock skews. This technique is modified to consider inherent uncertainties present in the timing models. The uncertainty controls the aggressiveness of the optimizations as we must take great care in ensuring functionality for any range of possible timing characteristics. Our results confirm intuition that more aggressive speed optimizations can be performed as timing models become more accurate. We also show that providing 4 skewed ver-sions of the nominal clock signal results in the best delay– area tradeoff. This result is evocative as it may suggest future FPGA architectures that contain greater numbers of global clock lines, as we tradeoff gains in speed for greater power requirements from increased clock network flexibility...|$|E

