21|89|Public
40|$|After {{a certain}} time, a {{calibration}} of ADS 40 is essential, including {{determination of the}} coordinate assigned to each pixel in focal plate and IMU misalignment, so-named <b>calibration</b> <b>file.</b> There are two ways of calibration: laboratory calibration and test field calibration. The test field calibration leads to greater precision than the other one, because it is performed under realistic working conditions. In recent years, many papers focused on estimating {{the performance of the}} <b>calibration</b> <b>file</b> and the influence of self-calibration. Nevertheless, the goal of this paper was to generate a sufficient <b>calibration</b> <b>file</b> based on test field calibration. In this paper, mathematic models involved with calibration were introduced, and a calibration workflow was developed, consisting of estimation, calibration and verification. All the experiment data was provided by Wuhan University, including calibration blocks acquired over Songshan Testsite in August 2009, while the certification of <b>calibration</b> <b>file</b> of ADS 40 was provided in February 01, 2007, and the coordinates of all the ground control points (GCPs) with an accuracy of 1 cm. Based on the original <b>calibration</b> <b>file,</b> aerial triangulation was performed. Self-calibration improved accuracy of data processing obviously, which indicated the necessity of calibration. Then a new <b>calibration</b> <b>file</b> was generated, which was different from the original one. With two sets of data in different flight height, a comparison of performance between the original <b>calibration</b> <b>file</b> and the new one was made, which proved the latter one to be sufficient and reliable. 1...|$|E
40|$|XRD-CT and XRF-CT {{data sets}} {{associated}} with publication "Chemical Imaging of Fischer Tropsch Catalysts Under Operating Conditions". Numbered files contain raw XRF and absorption data as collected {{along with the}} meta data. Non-numbered files contain processed and azimuthally integrated XRD data. The XRD <b>calibration</b> <b>file</b> has also been included...|$|E
40|$|The Jurassicprok Interferometric Calibration Software (also called "Calibration Processor" {{or simply}} "CP") {{estimates}} the calibration parameters of an airborne synthetic-aperture-radar (SAR) system, the raw measurement data {{of which are}} processed by the Jurassicprok software described in the preceding article. Calibration parameters estimated by CP include time delays, baseline offsets, phase screens, and radiometric offsets. CP examines raw radar-pulse data, single-look complex image data, and digital elevation map data. For each type of data, CP compares the actual values with values expected {{on the basis of}} ground-truth data. CP then converts the differences between the actual and expected values into updates for the calibration parameters in an interferometric <b>calibration</b> <b>file</b> (ICF) and a radiometric <b>calibration</b> <b>file</b> (RCF) for the particular SAR system. The updated ICF and RCF are used as inputs to both Jurassicprok and to the companion Motion Measurement Processor software (described in the following article) for use in generating calibrated digital elevation maps...|$|E
5|$|Astronomical data {{taken with}} CCDs must undergo several {{calibration}} steps {{before they are}} suitable for astronomical analysis. STScI has developed sophisticated software that automatically calibrates data when they are requested from the archive using the best <b>calibration</b> <b>files</b> available. This 'on-the-fly' processing means that large data requests can take a day or more to be processed and returned. The process by which data is calibrated automatically is known as 'pipeline reduction', and is increasingly common at major observatories. Astronomers may if they wish retrieve the <b>calibration</b> <b>files</b> themselves and run the pipeline reduction software locally. This may be desirable when <b>calibration</b> <b>files</b> other than those selected automatically need to be used.|$|R
40|$|The {{computer}} pipelines used {{to process}} digital infrared astronomical images from NASA's Spitzer Space Telescope require various input calibration-data files for characterizing the attributes {{and behaviors of}} the onboard focal-plane-arrays and their detector pixels, such as operability, dark-current offset, linearity, non- uniformity, muxbleed, droop, and point-response functions. The telescope has three very different science instruments, each {{with three or four}} spectral-band-pass channels, depending on the instrument. Moreover, each instrument has various operating modes (e-g., full array or sub-array in one case) and parameters (e. g., integration time). Calibration data that depend on these considerations are needed by pipelines for generating both science products (production pipelines) and higher-level calibration products (calibration pipelines). The <b>calibration</b> <b>files</b> are created in various formats either 'off-line' or by the aforementioned calibration pipelines, depending on the above configuration details. Also, the <b>calibration</b> <b>files</b> are generally applicable to a certain time period and therefore must be selected accordingly for a given raw input image to be correctly processed. All of this complexity in selecting and retrieving <b>calibration</b> <b>files</b> for pipeline processing is handled by a procedural software-program called 'caltrans'. This software, which is implemented in C and interacts with an Informix database, was developed at the Spitzer Science Center (SSC) and is now deployed in SSC daily operations. The software is rule-based, very flexible, and, for efficiency, capable of retrieving multiple <b>calibration</b> <b>files</b> with a single software-execution command...|$|R
40|$|This TIR {{describes}} {{the process for}} producing a yearly superdark file from one hundred and twenty of the individual weekly dark images taken during the year {{as part of the}} WFPC 2 <b>calibration</b> plan. This <b>file</b> is used to produce weekly dark <b>calibration</b> <b>files</b> that are used to calibrate all WFPC 2 observations throughout the following year...|$|R
40|$|Several {{laboratory}} calibration {{tests were}} {{developed for the}} Airborne Imaging Spectrometer (AIS). The goals of these tests are to adjust the physical alignment of the detector within the optical system and set the spectral endpoints, and produce a <b>calibration</b> <b>file</b> of multipliers which equalizes the relative responses {{of each of the}} detector elements in the entire two-dimensional array. Tests are also performed as part of an ongoing effort to provide absolute radiometric calibration. The tests are described and the merits and limitations of each are discussed...|$|E
40|$|Previous {{work at the}} SMRI {{has shown}} that NIRS {{predictions}} based on calibrations produced from earlier datasets were often biased. Bias-free NIR predictions were obtained by: l daily adjustment of the instrument’s wavelength (WL) constants to avoid instrumental bias l incorporation of a repeatability file, containing three samples scanned at different temperatures. This file is added during calibration to compensate for sample/laboratory temperature variations l adding three random samples from the previous week’s samples to the <b>calibration</b> <b>file.</b> The updated calibration equations were then used for the subsequent weekly samples. Results are described for both MJ and molasses for 17 weeks of the 2000 / 2001 season. A Metrohm autosampler was added to provide unattended operation. Sampling rate is currently 20 samples per hour...|$|E
30|$|Only {{available}} continuous GeoNet GPS {{stations were}} chosen to examine the postseismic deformation of the Kaikoura earthquake. Daily GeoNet GPS time series in the IGS 08 reference frame including GPS data processed using the GNSS-Inferred Positioning System and Orbit Analysis Simulation Software (GIPSY-OASIS-II 6.1. 1) {{are available from the}} Nevada Geodetic Laboratory, University of Nevada, Reno (NGL/UNR, [URL] last accessed on May 20, 2017). The data analysis ([URL] was based on the final, non-fiducial daily products from the Jet Propulsion Laboratory (JPL) archive including satellite orbit and clock estimates, wide-lane and phase bias estimates, Earth orientation parameters, and an IGS antenna <b>calibration</b> <b>file.</b> The tropospheric refractivity was modeled using the global mapping function (GMF); the first-order ionospheric effects were removed by applying ionosphere-free combinations of both carrier phase and pseudo-range measurements, and the ocean tidal loading effects were corrected using the tidal model FES 2004 (Finite element solutions, 2004).|$|E
5000|$|In {{observational}} astronomy an On-The-Fly Calibration (OTFC) system calibrates data when a user's {{request for}} the data is processed so that users can obtain data that are calibrated with up-to-date <b>calibration</b> <b>files,</b> parameters, and software.|$|R
5000|$|The product {{provides}} programmatic interfaces to 3D <b>calibration</b> <b>files</b> for custom C, C++ and MATLAB applications. [...] It supports GigE Allied Vision {{cameras and}} accuracy tools, such as snap-to-corner measurement assistance and accuracy calculator displays.|$|R
50|$|Currently, for example, HST {{data are}} {{calibrated}} {{as they are}} received at the STScI. Raw and calibrated data are stored in the HST archive (DADS). Frequently, users must recalibrate the data at their home sites {{to take advantage of}} better <b>calibration</b> <b>files</b> or software. A large fraction (over 90%) of the calibrated data in the HST archive could be improved by recalibration, although the improvements are not always significant. In the past, instruments that undergo evolution of <b>calibration</b> <b>files</b> or <b>calibration</b> software often required users to carry out their own recalibrations at their home sites. With OTFC, the HST data archives carry out the recalibration.|$|R
40|$|We {{present a}} {{complete}} discussion and a synopsis of the Cycle 4 calibration {{status of the}} FOS to date. A chronology and summary is provided of recent communications to the observer community concerning important FOS calibration issues including recommended re-processing procedures for certain photometric and flat field calibrations and discussions of pipeline processing errors affecting polarimetry and background subtraction. Complete reference guide tabulations of all recommended FOS reference files and reference tables for Cycle 4 AS OF 10 NOVEMBER 1994 are given. Equivalent tabulations for pre-COSTAR observations {{may be found in}} cited references. Comprehensive <b>calibration</b> <b>file</b> and table delivery histories since launch are described and referenced. ASCII-text and Postscript versions of these tabulations and histories, which are updated on a continuing basis, may be found on STEIS in the instrument_news/fos/recommended_reference_files directory and in the “Instrument Status: Calibration Products and Tools ” section of the WWW STScI FOS Homepage. I...|$|E
40|$|Here {{we present}} {{details on the}} WFC 3 /IR spatial {{sensitivity}} test. The {{aim of the test}} is to observe a standard star in a grid pattern covering the IR detector to investigate spatial variations in the measured photometry. Any deviations from a uniform response could be due to errors in the flat field <b>calibration</b> <b>file.</b> We find that the current pipe-line IR flat-fields, which are a combination of a ground-based high frequency (pixel-to-pixel) component and alowfrequencycorrectionbasedonin-flightskyobservations,producesstablephotometry over most of the detector. We estimate that the typical rms in measured photometry due to the flat field uncertainties is less than ∼ 0. 007 mag. We do not find any significant low frequency large scale gradients in the photometry, except possibly for a region near the bottom left of the detector. Overall, these test indicates that the IR flat fields produce consistent photometry over the central 800 x 800 pixels of the detector investigated here. 1...|$|E
40|$|The X-ray Multi-mirror Mission, XMM-Newton was {{launched}} by the European Space Agency, ESA, in 1999. XMM-Newton carries six cameras, including a silicon pn-junction Charge Coupled Device, or pn-CCD camera. This camera has six operating modes, spatially as well as time resolved. The main objective of this project is to refine the Burst mode energy correction in order to align the measured energy spectra observed in the Burst mode with the spectra taken in the Full Frame mode. An observation of the line-rich supernova remnant called Cassiopeia A is {{used to evaluate the}} line positions in each mode such that the energy correction function used for the alignment can be modified accordingly. The analysis further treats the application of the correction on a source with a continuous spectrum, the Crab nebula. Discussion shows how to reduce eventual residuals in the Crab spectrum by modifying the correction function while keeping the alignment of the Cas-A spectra. The final product is an update of the corresponding published <b>calibration</b> <b>file...</b>|$|E
40|$|This paper {{introduces}} the articles that describe detailed {{aspects of the}} XMM-Newton calibration. The unique calibration issues of XMM-Newton are highlighted. The original calibration requirements and aspects of the ground calibration are summarized. The life cycle of the in-orbit calibration observations, analysis and ingestion into <b>calibration</b> <b>files</b> is discusse...|$|R
40|$|The Swift UVOT grisms (uv: 170 - 500 nm; visible: 285 - 660 nm) {{spectral}} data reduction package is {{a replacement for}} the uvotimgrism Ftool from the HEADAS Swift software. This requires a recent HEADAS Swift installation and CALDB as available from HEASARC. Recently the coincidence loss correction was redeveloped and is now formulated in a fully consistent manner to the theory as used successfully for point sources. Updates to the <b>calibration</b> <b>files</b> were made consistent with the reformulated correction. Recent software updates have been described in the Release notes for 2. 1. 0. Tthe latest <b>calibration</b> <b>files</b> that were missing in the previous versions were added in 2. 1. 1, while 2. 12 and 2. 13 fixes small typos affecting the uvotgrism script and output. Documentation sources are described in the Readme {{as well as how}} to cite this software...|$|R
5000|$|The main goals {{behind the}} {{implementation}} of the OTFC system are to take advantage of better <b>calibration</b> <b>files</b> and the much smaller storage area required if only raw files are kept in the archives. The system can also offer more calibration steps than were available when the data was first released and can implement improved pipeline software.|$|R
40|$|The {{confidence}} {{in an individual}} measurement {{is the most important}} factor when selecting the elemental formula candidates from the list of possible elemental compositions following an exact mass measurement. It is the single mass measurement capability rather than the averaged mass measurement potential of the mass spectrometer that is the critical factor when validating the exact mass measurements of small molecules. Here, an experimental protocol has been established to determine the frequency of exact mass measurement by Fourier transform ion cyclotron resonance mass spectrometry (FT-ICRMS) at known relative ion abundance ratios (RA). This in turn allows for statements about the confidence limit for any single exact mass measurement to be made. This is particularly crucial for a high throughput, automated environment where operator intervention is required to be minimal and repeat analyses are to be avoided. The relative ion abundance calculations are essential to determine the working ranges for specific sample ion abundances. Further, {{it has been shown that}} if the sample ion abundance is low, then the ion abundance range for the <b>calibration</b> <b>file</b> does not need to be exactly or closely matched, again benefiting the high throughput application...|$|E
40|$|Snow and ice meltwater {{constitutes}} a signiﬁcant portion of westem Canada 2 ̆ 7 s water resources for residential, industrial and agricultural uses. As a consequence, temporal variations in climate {{will have a}} marked effect on the local hydrology of the Canadian Rocky Mountains, especially as glaciers, glacierettes and snow packs decrease in size or melt out. It is therefore very important for hydrologists to accurately understand the climatic sensitivity of glacierized watersheds in order to predict and prepare for potentially dramatic variations in the future water budget. This thesis proposes a methodology for the estimation of the hydrological response of a large, temperate, glacierized basin to predicted climatic change. The historical hydrologic signature of the upper Bow Valley (2226 km) was estimated by calibrating the UBC Watershed Model to the basin using observed streamﬂows and meteorological data from 1950 to 1990. The areal glacier extents for the Upper Bow Valley between 1950 and 1990 were estimated based on observed trends of glacier recession in the Hector Basin. The <b>calibration</b> <b>ﬁle</b> for hydrologic year 1969 proved to be most successful, and thus was chosen for the climatic sensitivity analysis. A series of climatic scenarios were drafted based on several general circulation model predictions. In addition, glacier areas were adjusted to simulate a 30...|$|E
40|$|CLAMP Online {{is a new}} form-driven web {{facility}} enabling Climate Leaf Analysis Multivariate Program (CLAMP) palaeoclimate determinations to {{be conducted}} in their entirety {{without the need for}} additional software. This facility is demonstrated using physiognomic data from 82 Eocene to Pliocene fossil sites in North America, the Physg 3 brc CLAMP <b>calibration</b> <b>file,</b> and both locally derived climate	data	(Met 3 br) 	and	 0. 5 ° × 0. 5 °	gridded	climate	data (GRIDMet 3 br). All the fossil sites fall within the physiog- nomic space defined by the Physg 3 brc dataset showing the versatility of this calibration for Paleogene to Present sites in North America. The fossil sites also plot in the mesic part of physiognomic space confirming that the source of the fossil material was vegetation growing under conditions where water was not growth-limiting to any significant degree. Regression equations are derived relating the local to the gridded climate predictions showing the relative predictive capabilities of each dataset, as well as offering ways to convert previously published data between the two calibrations. Palaeoclimate data (mean annual, warm month mean and cold month mean temperatures, growing season length, growing season and mean monthly growing season precipitation, precipitation during the three consecutive wettest and three consecutive driest months, and annual averages for relative and specific humidities and enthalpy) are given for all 82 sites...|$|E
50|$|STScI staff {{develops}} the calibration proposals, shepherd {{them through the}} scheduling process, and analyze the data they produce. These programs provide updated <b>calibration</b> and reference <b>files</b> {{to be used in}} the data processing pipeline. The <b>calibration</b> <b>files</b> are also archived so users can retrieve them if they need to manually recalibrate their data. All calibration activity and results are documented, usually in the form of Instrument Science Reports posted to the public website, and occasionally in the form of published papers. Results are also incorporated into the Data Handbooks and Instrument Handbooks.|$|R
40|$|This report {{describes}} {{the analysis of}} the flat field data from Calibration III and the generation of the Build 2 <b>calibration</b> <b>files</b> for RSDP. I report {{the analysis of the}} large spatial scale response of the FOC as a function of time, LED, and wavelength. I find the general repeatability of LED images to be better than 1 - 2 %. Aside from the red LED exposures, the wavelength dependence of both F/ 48 and F/ 96 large scale spatial response appears to be less than 10 %. The determination of flat field response from external illumination is found to be limited by the errors in determination of the illumination nonuniformity. All the data are consistent with the LED illumination being flat to at least 3 % though, because of the errors in calibrating the spatial illumination of the external flat fields, no conclusive statement can be made. I conclude that LED exposures, when available, are preferable to external exposures for flat field calibration, and used them to generate most of the RSDP Build 2 <b>calibration</b> <b>files...</b>|$|R
40|$|The subject {{grant is}} for the {{analysis}} of XMM observations of the galactic supernova remnant CTB- 109. As of the writing of this report, the XMM observations have not been conducted yet. We have begun gaining experience with the XMM analysis SW and <b>calibration</b> <b>files</b> so that we can more quickly analyze our data once they become available. We have downloaded the latest version of the XMM standard analysis SW (SAS 5. 1). We have downloaded some of the public calibration datasets and started manipulating them using the SAS SW...|$|R
40|$|A revised flux {{calibration}} {{is presented}} for the G 800 L grism with the ACS Wide Field Channel. The calibrations {{were derived from}} observations of the HST standard star G 191 B 2 B and cross-checked with observations of the standard star GD 153. The absolute flux calibration of the 1 st order is accurate to better than 2 % for wavelengths from 6000 to 9500 Å at the spatial positions covered in this ISR. The updated flux <b>calibration</b> <b>file</b> shows differences of less than 5 % to the previous one and is made available to users as configuration files for the aXe software package. Furthermore, the spectral resolving power for point sources observed with the G 800 L grism (1 st order) {{was measured to be}} 100 ± 20 Å (FWHM) at 6563 Å. The flux calibration of other orders, which are currently not used for scientific purposes, is also updated. In an investigation of the fringing properties of the WFC CCDs the contribution of fringing to the total error of the flux calibration is examined. Using a Gaussian model of 100 Å (FWHM) for the relative distribution of light falling onto a given CCD pixel (the so called pixel throughput function), we demonstrate that the error due to fringing amounts to less than 0. 1 % for continuum sources and can therefore be neglected. For narrow emission lines fringing can cause in principle line flux variations of 12 % and more. For more realistic scenarios {{as in the case of}} emission lines in a Wolf Rayet star we measure variations of order 4 %...|$|E
40|$|This paper {{presents}} the results of the analysis of the spectral, global, and direct solar irradiance measurements in the visible range (400 700 nm) that were made in the framework of the first Iberian UV visible (VIS) instruments intercomparison. The instruments used in this spectral range were four spectroradiometers: three Licor 1800 s equipped with different receiver optics and one Optronic 754. For the direct solar irradiance measurements the spectroradiometers were equipped with collimators with different fields of view. Parallel studies have been carried out with the data given by the spectroradiometers with their original <b>calibration</b> <b>file</b> and with the same data that is corrected, following in situ calibration of the instruments using a laboratory reference lamp. To compare the series of spectral data the relative values of mean absolute deviation (MAD) and root-mean-square deviation (rmsd) have been used. The results obtained from the measurements of global irradiance show that the Licor 1800 s presented very significant differences at the beginning {{and at the end of}} the day due to the deviation from ideal cosine response of the collection optics (i. e., cosine errors). This forced the analysis to be limited to the measurements corresponding to solar elevations higher than 30 °. For this solar elevation range, the results of the intercomparison between the Licor instruments, before their in situ calibration, showed differences of about 5 % in the visible range. The results from the measurements of direct irradiance show that, if correction factors are considered, these deviations are reduced to 3 %, and when the Licors are compared with the Optronic, the deviations are less than 2 %...|$|E
40|$|Instrument {{effective}} areas affect spectral fitting results, and the derived pa-rameter values {{will depend}} on the particular effective area chosen for the analysis. This is an issue for high-counts, high-quality data more than low-counts spectra because systematic uncertainties may produce a larger variance in the parameters than statistical uncertainties, whereas statistical uncertainties dominate for low counts spectra. With plausible effective areas that span the systematic variations, we show that their effect can be easily computed using existing tools like Sherpa. Here we describe that the variances due to statistical and systematic uncer-tainties can be combined with the well-known multiple imputation combin-ing rule. We demonstrate its effectiveness with simulation examples using typical variations expected of ACIS-S effective areas. We show that ap-proximately 20 full-fledged spectral fits, carried out with different effective areas, are needed to capture the full extent of calibration uncertainty in the parameter error estimate. We apply this technique to a set of observed AGN spectra and directly demonstrate the relevance of such calculations. Effective Area Uncertainty Best fit parameters and errors depend on the choice of a <b>calibration</b> <b>file.</b> A set of effective areas can be synthesized by calibration scientists and its in-formation must be aggregated into spectral fitting analysis. Fig. 1 illustrates a set of 1000 effective area curves {A} showing the systematic uncertainty in the nominal ACIS-S effective areas (Drake et al. 2006; see also Drake et al. 2009 [C. 11]). The top panel shows the set of effective areas, the middle panel shows the deviations from the nominal, and the bottom panel shows the same set reconstructed from a small subset of its Principal Components. Some illustrative curves are shown in the middle panel. The dark gray areas cover 68 % of the variations. E [keV]...|$|E
40|$|The {{accuracy}} of satellite-based single-frequency radar ocean altimeters benefits from calibration {{of the total}} electron content (TEC) of the ionosphere below the satellite. Data from the global network of Global Positioning System (GPS) receivers provides timely, continuous, and globally well-distributed measurements of ionospheric electron content. We have created a daily automated process called Daily Global Ionospheric Map (Daily-GIM) whose primary purpose is to use global GPS data to provide ionospheric calibration data for the Geosat Follow-On (GFO) ocean altimeter. This process also produces an hourly time-series of global maps of the electron content of the ionosphere. This system is designed to deliver "quick-look" ionospheric calibrations within 24 hours with 90 +% reliability and with a root-mean-square {{accuracy of}} 2 cm at 13. 6 GHz. In addition we produce a second product within 72 hours which takes advantage of additional GPS data which were not available {{in time for the}} first process. The diagram shows an example of a comparison between TEC data from the Topographic Experiment (TOPEX) ocean altimeter and Daily-GIM. TEC are displayed in TEC units, TECU, where 5 TECU is 1 cm at 13. 6 GHz. Data from a single TOPEX track is shown. Also shown is the Bent climatological model TEC for the track. Although the GFO satellite is not yet in its operational mode, we have been running Daily-GIM reliably (much better than 90 %) with better than 2 -cm accuracy (based on comparisons against TOPEX) for several months. When timely ephemeris files for the European Remote Sensing Satellite 2 (ERS- 2) are available, daily ERS- 2 altimeter ionospheric <b>calibration</b> <b>files</b> are produced. When GFO ephemeris files are made available to us, we produce GFO ionosphere <b>calibration</b> <b>files.</b> Users of these GFO ionosphere <b>calibration</b> <b>files</b> find they are a great improvement over the alternative International Reference Ionosphere 1995 (IRI- 95) climatological model. In addition, the TOPEX orbit determination team at JPL has been using the global ionospheric maps to calibrate the single frequency GPS data from the TOPEX receiver, and report highly significant improvements in the ephemeris. The global ionospheric maps are delivered daily to the International GPS Service (IGS), making them available to the scientific community. Additional information is contained in the original...|$|R
40|$|Abstract. We {{present an}} {{overview}} of the properties of the NICMOS flight detectors as measured on-orbit, including the flat-field response, the dark current, the linearity, and the read-noise. We show for the first time all the dependencies of the various components of a NICMOS dark exposure, and show how to generate “synthetic ” dark current <b>calibration</b> <b>files.</b> An unexpected time-varying bias known as the “pedestal”, is described, along with some efforts to remedy it. We describe the effects on the detectors of exposure to very bright sources, and finally, we briefly describe the sensitivity of NICMOS to cosmic rays. 1...|$|R
40|$|We have {{established}} a new calibration strategy for the ISOPHOT P- and C-detectors, particularly useful to perform fine absolute photometry at faint signal level. From all suitable ISOPHOT archive data we have reviewed different instrumental effects for P- and C-detectors and determined more accurately the zero point of these detectors, deriving new <b>calibration</b> <b>files.</b> Re-analysis of the reset interval transformation and the dark signal behaviour are presented {{in addition to a}} new method for the transient correction and, for C-detectors, the first determination of the by-passing sky light. The new data reduction procedure can be applied to determine faint signals...|$|R
40|$|This paper {{provides}} an overview of the PACS photometer flux calibration concept, in particular for the principal observation mode, the scan map. The absolute flux calibration is tied to the photospheric models of five fiducial stellar standards (alpha Boo, alpha Cet, alpha Tau, beta And, gamma Dra). The data processing steps to arrive at a consistent and homogeneous calibration are outlined. In the current state the relative photometric accuracy is around 2 % in all bands. Starting from the present calibration status, the characterization and correction for instrumental effects affecting the relative calibration accuracy is described and an outlook for the final achievable calibration numbers is given. After including all the correction for the instrumental effects, the relative photometric calibration accuracy (repeatability) will be as good as 0. 5 % in the blue and green band and 2 % in the red band. This excellent calibration starts to reveal possible inconsistencies between the models of the K-type and the M-type stellar calibrators. The absolute calibration accuracy is therefore mainly limited by the 5 % uncertainty of the celestial standard models in all three bands. The PACS bolometer response was extremely stable over the entire Herschel mission and a single, time-independent response <b>calibration</b> <b>file</b> is sufficient for the processing and calibration of the science observations. The dedicated measurements of the internal calibration sources were needed only to characterize secondary effects. No aging effects of the bolometer or the filters have been found. Also, we found no signs of filter leaks. The PACS photometric system is very well characterized with a constant energy spectrum nu*Fnu = lambda*Flambda = const as a reference. Colour corrections {{for a wide range of}} sources SEDs are determined and tabulated. Comment: 24 pages, 8 figures, 14 tables. Experimental Astronomy in pres...|$|E
40|$|This report {{describes}} {{a set of}} open water trials; performed on a full-scale conventional totally enclosed motor propelled survival craft. These trials were run {{as part of the}} 2 ̆ 01 cPerformance and Survivability of Totally Enclosed Motor Propelled Survival Craft (TEMPSC) in Level and Pack Ice Conditions 2 ̆ 01 d project sponsored by the Program of Energy Research and Development (PERD) Marine Transportation and Offshore Safety Program. The objective of the PERD project is to evaluate the performance of evacuation craft (lifeboat) in environments where floating ice is present, as well as to recognize improvements that may be implemented. The aforementioned trials took place in November 2008, out of MUN/MI 2 ̆ 019 s Holyrood facility, located {{on the north side of}} South Arm, Holyrood Bay, opposite the marina. To fully test the performance of the modified lifeboat, a number of open water tests were performed. These included both non-standard turning circles and collision avoidances. The raw data from the trials initially had to be calibrated, using a <b>calibration</b> <b>file</b> and in-house software called IOTDataLoggerCal. Once each file had been calibrated, it was loaded into IGOR, an integrated program for visualizing, analyzing, transforming and presenting data. Data analysis proved that there is a much smaller diameter for the port side turns than there is for the starboard turns. When comparing upwind and downwind turns the results seemed to be extremely varied, indicating that the direction of travel in terms of wind direction had no significant effect on turn diameter. The initial speeds, speed during the turns, and final speed varied slightly for each trial and this may mislead the comparison. The plots of Turn Diameter verses Rudder Angle indicated that as the rudder angle used in the turn increased, the turn diameter decreased. Peer reviewed: NoNRC publication: Ye...|$|E
40|$|Tactile sensor {{recordings}} {{have been}} analyzed in time domain, frequency domain and visually to identify failure processes along a structural interface. Except for the pre-study to this thesis, {{there was not}} found anywhere in former literature that the spectral analyze method have been applied at small- scale tactile data from a cylindrical indenter. Underlying data have manly been conducted during the Deciphering Ice Inducted Vibration (EU- HYDRALAB DIIV) test campaign at HSVA in 2011. Both global and local forces have been evaluated. Similar to former studies were intermittent crushing found to dominate at lower indentation rates and brittle crushing at higher indentation speeds. For two test series analyzed in this paper transition speeds were found between 80 - 90 mm/s and 60 - 70 mm/s. Contact area in different crushing regimes have been evaluated. Higher correlations in contact area were observed during tendencies to frequency lock-in. Line-like contact tended to prevail in continuous brittle crushing. Trends in time-history plots of experimental data with theoretical results show a decrease in correlation between local forces with increasing indentation velocities. During tendencies to frequency lock-in a resonant frequency of 8. 57 Hz was found. This was slightly below the first natural frequency of the system. A possible sub-harmonic frequency was observed in two of thirteen panels within the same time window. Usability and the tactile sensors ability to reconstruct rapid pressure changes have been evaluated as a second stage of this thesis. In addition have there been search to develop an experimental routine to calibrate the tactile sensor. A sensor recording with 100 Hz failed in reconstructing a hammer-excitation, but was well reconstructing forces during a compression test of ice with ductile behavior. In general, output data from the tactile sensor was strongly dependent of the <b>calibration</b> <b>file.</b> </p...|$|E
40|$|The Swift UVOT grisms (uv: 170 - 500 nm; visible: 285 - 660 nm) {{spectral}} reduction {{package is}} {{a replacement for}} the uvotimgrism Ftool from the HEADAS Swift software. Requires a recent HEADAS Swift installation. Recently the coincidence loss correction was redeveloped and is now formulated in a fully consistent manner to the theory as used successfully for point sources. Updates to the <b>calibration</b> <b>files</b> were made consistent with the reformulated correction. A program was added to help shift the wavelengths due to uncertainties in anchor position. This version fixes {{a problem with the}} background extraction in uvotpy- 2. 0. 2...|$|R
40|$|The Swift UVOT grisms (uv: 170 - 500 nm; visible: 285 - 660 nm) {{spectral}} reduction {{package is}} {{a replacement for}} the uvotimgrism Ftool from the HEADAS Swift software. Requires a recent HEADAS Swift installation. Recently the coincidence loss correction was redeveloped and is now formulated in a fully consistent manner to the theory as used successfully for point sources. Updates to the <b>calibration</b> <b>files</b> were made consistent with the reformulated correction. Minor updates {{to keep up with}} API changes in numpy, astropy, small bug fixes. A paper describing the calibration of, and the UVOT grisms has been published, see the Readme file...|$|R
40|$|Using data {{taken during}} WFC 3 's Thermal Vacuum 3 (TV 3) testing campaign, we have {{characterized}} the dark current {{behavior in the}} IR Channel, which contained IR- 4 (FPA 165). The Contract End Item (CEI) Specifications call for dark current to be below 0. 4 e- /sec/pixel, with a goal of 0. 1 e- /sec/pixel. We measure dark current values well below the spec and goal values. The longest exposure time ramps show dark current values in the 0. 045 – 0. 060 e- /sec/pixel range. Initial dark current <b>calibration</b> <b>files</b> will be created from these TV 3 data...|$|R
