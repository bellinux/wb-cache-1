3|7518|Public
40|$|The car-license-plate (CLP) {{recognition}} {{system is}} an image processing technology issued to identify vehicles by capturing their CLPs. The CLP recognition technology is known as automatic number-plate recognition, automatic vehicle identification CLP for cars. In the previous work on ” Robust license-plate recognition method for passing vehicles under outside environment”, numerous vehicle tracking and pursue systems use outstanding cameras. The scheme has three contributions: The Vertical edge detection algorithm (VEDA) is proposed and used for detecting vertical edges. The <b>color</b> <b>input</b> <b>image</b> is converted to a grayscale image and then, adaptive threshold (AT) i...|$|E
40|$|This paper {{deals with}} car license plate {{detection}} (CLPD) system {{in order to}} identify vehicles by capturing their car license plates (CLP). Car license plate detection (CLPDS) is an emerging area of research due to various applications such as prevention of crime, electronic toll system, intelligent traffic control system etc. In the proposed system, after converting the <b>color</b> <b>input</b> <b>image</b> into grayscale, an adaptive thresholding is used to obtain the binary image. Then the unwanted lines are removed through an unwanted-line elimination algorithm (ULEA). Finally to detect the license plate, vertical edges are detected by Sobel operator. Experiments were carried out for detection of front view as well as rear view of license plates. The experimental evaluation is carried out for 60 images taken from roadside and parking lots. The proposed method yields 96. 9 % detection accuracy...|$|E
40|$|This paper proposes an {{integrated}} system for unconstrained face recognition in complex scenes. The scale and orientation tolerant system comprises a face detector {{followed by a}} recognizer. Given a <b>color</b> <b>input</b> <b>image</b> of a person, the face detector encloses the face from the complex scene within a circular boundary, and locates {{the position of the}} nose. A radial grid mapping centered on the nose is then performed to extract a feature vector within the boundary. The feature vector is input to a radial basis function neural network classifier for face identification. The proposed face detector achieved an average detection rate of 95. 8 % while the face recognizer achieved an average recognition rate of 97. 5 % on a database of 21 persons with variations in scale, orientation, natural illumination and background. The two modules were combined to form an automatic face recognition system that was evaluated {{in the context of a}} security system using a video database of 21 users and 10 intruders, acquired in an unconstrained environment. A recognition rate of 93. 5 % with 0 % false acceptance rate was achieved...|$|E
40|$|An {{efficient}} image simplification method: {{minimizing the}} Mumford-Shah functional {{on the tree}} of shapes [1]; a fast greedy algorithm providing a local optimal solution. A hierarchical image simplification: a variant of morphological shaping [2]; a saliency map representing a hierarchical image simplification. Effective results: <b>color</b> <b>images</b> pre-segmentation <b>Input</b> <b>color</b> <b>image.</b> <b>Input</b> <b>color</b> <b>image.</b> 133 regions. 84 regions. Effective results: hierarchical image simplification Original image. Saliency map. Less simplified. More simplified. Basic idea Minimize the piecewise-constant Mumford-Shah functional [3] [...] subordinated to the tree of shapes [1, 4] of an image f. Piecewise-constant Mumford-Shah functional E...|$|R
40|$|Abstract In {{real world}} scenarios, guiding vision {{to focus on}} salient parts of the visual space is a {{computationally}} demanding tasks. Selective attention is a biolog-ically inspired strategy {{to cope with this}} problem, {{that can be used in}} engineered systems with limited resources. In active vision systems however, the stringent real-time requirements limit the space of solutions that can be achieved with conven-tional machine vision techniques and systems. We propose a hybrid approach where we combine a custom neuromorphic VLSI saliency-map based attention system with a conventional imager and a workstation, to implement both fast contrast-based saccadic eye movements in parallel with standard machine vision attention models using high-resolution <b>color</b> <b>input</b> <b>images.</b> We describe the system and present its response properties using basic control experiments. ...|$|R
40|$|Abstract. In {{real world}} scenarios, guiding vision {{to focus on}} salient parts of the visual space is a {{computationally}} demanding tasks. Selective attention is a biologically inspired strategy {{to cope with this}} problem, {{that can be used in}} engineered systems with limited resources. In active vision systems however, the stringent realtime requirements limit the space of solutions that can be achieved with conventional machine vision techniques and systems. We propose a hybrid approach where we combine a custom neuromorphic VLSI saliency-map based attention system with a conventional machine vision system, to implement both fast contrast-based saccadic eye movements in parallel with conventional visual attention models that use high-resolution <b>color</b> <b>input</b> <b>images.</b> We describe the system and characterize its response properties with experiments using both basic control visual stimuli and natural scenes. ...|$|R
40|$|This report {{proposes a}} face {{detection}} algorithm based on skin color modeling and {{support vector machine}} (SVM) classification. Said classification is based on various face features used to detect specific faces in an <b>input</b> <b>color</b> <b>image.</b> A YCbCr color space is used to filter the skin color pixels from the <b>input</b> <b>color</b> <b>image.</b> Template matching is used on the result with various window sizes of the template created from an ORL face database. The candidates obtained above, are then classified by SVM classifiers using the histogram of oriented gradients, eigen features, edge ratio, and edge statistics features...|$|R
40|$|Abstract—We apply Convolutional Networks (ConvNets) to {{the task}} of traffic sign {{classification}} as part of the GTSRB competition. ConvNets are biologically-inspired multi-stage architectures that automatically learn hierarchies of invariant features. While many popular vision approaches use handcrafted features such as HOG or SIFT, ConvNets learn features at every level from data that are tuned {{to the task}} at hand. The traditional ConvNet architecture was modified by feeding 1 st stage features in addition to 2 nd stage features to the classifier. The system yielded the 2 nd-best accuracy of 98. 97 % during phase I of the competition (the best entry obtained 98. 98 %), above the human performance of 98. 81 %, using 32 x 32 <b>color</b> <b>input</b> <b>images.</b> Experiments conducted after phase 1 produced a new record of 99. 17 % by increasing the network capacity, and by using greyscale images instead of color. Interestingly, random features still yielded competitive results (97. 33 %). I...|$|R
40|$|There {{are many}} {{applications}} which require {{the user to}} be authenticated before being permitted to perform certain tasks. Text password-based authentication is a popularly used authentication mechanism. Despite having greater security, text-passwords are characterized by selection of a weak and easy to remember passwords. Users also tend to write them down and share them with friends, family members and colleagues defeating the security provided by text-passwords. Graphical passwords offer an alternative to text passwords as the password space is typically higher, less prone to dictionary attacks and easier to remember visually. However, they suffer from shoulder-surfing attacks. In this paper, we propose two authentication schemes that support keyboard as well as graphical mouse-based input that map password characters to {{other regions of the}} password space. This shields the user’s password from being known to the adversary thus deflecting shoulder-surfing and spyware attacks. The schemes include both single and multi <b>color</b> <b>input</b> <b>images</b> consisting of printable characters. An analysis of security, usability, memorability and social engineering aspects of the proposed schemes is presented. Future research directions are also presented</span...|$|R
40|$|Color {{correction}} {{refers to}} modifying the <b>color</b> of an <b>input</b> <b>image</b> {{so that it}} is similar to the color of a reference image. They can be classified into two categories: one based on pixel correspondences and the other based on the color statistics of two images. Methods that employ pixel correspondences rely on correspondence accuracy where as statistical method...|$|R
40|$|Computer vision {{algorithms}} {{that use}} color information require color constant images to operate correctly. Color constancy {{of the images}} is usually achieved in two steps: first the illuminant is detected and then image is transformed with the chromatic adaptation transform (CAT). Existing CAT methods use a single transformation matrix for all the <b>colors</b> of the <b>input</b> <b>image.</b> The method proposed in this paper requires multiple corresponding color pairs between source and target illuminants given by patches of the Macbeth color checker. It uses Delaunay triangulation to divide the color gamut of the <b>input</b> <b>image</b> into small triangles. Each <b>color</b> of the <b>input</b> <b>image</b> {{is associated with the}} triangle containing the color point and transformed with a full linear model associated with the triangle. Full linear model is used because diagonal models are known to be inaccurate if channel color matching functions do not have narrow peaks. Objective evaluation showed that the proposed method outperforms existing CAT methods by more than 21 %; that is, it performs statistically significantly better than other existing methods...|$|R
40|$|This report {{described}} a computational model for color constancy in shadows by a computational model which recovers both spatial-illuminance distribution and reflectances of object surfaces from the <b>input</b> <b>image.</b> To solve the ill-posed problem of color constancy, we adopted {{a strategy of}} minimizing the energy function where the constraints of illuminants, reflectance and shadows were embedded. Computer simulation showed that the proposed model successfully removed the shadow edges and illuminant <b>colors</b> from the <b>input</b> <b>image</b> and achieved <b>color</b> constancy...|$|R
40|$|We {{present a}} color-to-gray {{conversion}} algorithm that retains both the overall appearance and the discriminability of {{details of the}} <b>input</b> <b>color</b> <b>image.</b> The algorithm employs a weighted pyramid image fusion scheme to blend the R, G, and B color channels of the <b>input</b> <b>image</b> into a single grayscale image. The use of simple visual quality metrics as weights in the fusion scheme serves to retain visual contrast {{from each of the}} <b>input</b> <b>color</b> channels. We demonstrate the effectiveness of the method by qualitative and quantitative comparison with several state-of-the-art methods. © 2014 SPIE and IS&T...|$|R
40|$|International audienceWe {{describe}} {{a simple but}} capable algorithm to generate sketches from color images. The method {{is based on the}} drawing of dark strokes on a white background, directed by an image-dependent tensor-valued geometry. It is able to produce various sketching styles with different kind of hatching and contours. Combining these grayscale sketches with the <b>colors</b> of the <b>input</b> <b>images</b> allows to produce a wide variety of image stylization renderings...|$|R
40|$|This paper {{focuses on}} a novel {{framework}} for information retrieval of images based only on color information. Regions homogeneous in <b>color</b> of the <b>input</b> <b>image</b> are detected using a multireso- lution analysis. In {{order to avoid the}} selection of regions having similar color, a new clustering scheme based on repulsion between electric charges, is proposed. The resulting model is completely automatic and achieves good results in terms of computational time and performances...|$|R
30|$|Recently, we {{proposed}} {{to create an}} adaptive seed based on detected facial regions [11]. Using the geometrical features extracted from the luminance channel of the <b>input</b> <b>color</b> <b>image,</b> the facial regions are detected. A local skin model is learned using a single multivariate Gaussian, and the model {{is applied to the}} <b>input</b> <b>image</b> to obtain a local skin probability map, which is binarized to determine the final seeds. Afterwards, the propagation is carried out using the skin probability map obtained from a global skin color model.|$|R
40|$|This thesis {{describes}} {{a new line}} segment detection and extraction algorithm for computer vision, image segmentation, and shape recognition applications. This algorithm uses a compilation of different image processing techniques such as normalization, Gaussian smooth, automatic threshold, and Laplace edge detection to extract edge contours from <b>color</b> <b>input</b> <b>images.</b> Contours of each connected component are divided into short segments, which are classified by their orientation into about ten discrete categories. Straight lines are recognized as the minimal number of such consecutive short segments with the same direction. This solution indeed gives us more precise line segments (including line endpoints) and requires a shorter time than the widely used Hough Transform algorithm for detecting line segments given any orientation and location inside an image. Its easy implementation, simplicity, parameter minimization, speed, ability to split an edge into straight line segments using the actual morphology of objects, accuracy {{and the use of}} OpenCV library are key features and advantages of the proposed approach. The algorithm was tested on several simple shape images as well as on real pictures, yielding a more accurate resemblance of straight lines in accordance with the human perception of line taxonomy. The line detection algorithm introduced here requires few parameters and is robust to standard image transformations such as rotation, scaling and translation. Furthermore, some of these parameters are selected by automatic unsupervised methods, thus improving the expected algorithm outcome in terms of the stated problem. Several experimental results are presented to support the validity of the algorithm...|$|R
40|$|Abstract—This paper {{develops}} a computationally efficient process for segmentation of <b>color</b> <b>images.</b> The <b>input</b> <b>image</b> is partitioned into {{a set of}} output images in accordance to color characteristics of various image regions. The algorithm is based on random sampling of the <b>input</b> <b>image</b> and fuzzy clustering of the training data followed by crisp classification of the <b>input</b> <b>image.</b> The user prescribes the number of randomly selected pixels comprising the trainer set {{and the number of}} color classes characterizing the image compartments. The algorithm developed here constitutes an effective preprocessing technique with various applications in machine vision systems. Spectral segmentation of the sensor image can potentially lead to enhanced performance of the object detection, classification, recognition, authentication and tracking modules of the autonomous vision system. Keywords—Clustering; Classification; Image Segmentation; Machine Visio...|$|R
40|$|In {{this paper}} we have {{proposed}} a method for an RGB image encryption supported by lifting scheme based lossless compression. Firstly we have compressed the <b>input</b> <b>color</b> <b>image</b> using a 2 -D integer wavelet transform. Then we have applied lossless predictive coding to achieve additional compression. The compressed image is encrypted by using Secure Advanced Hill Cipher (SAHC) involving a pair of involutory matrices, a function called Mix() and an operation called XOR. Decryption followed by reconstruction shows {{that there is no}} difference between the output <b>image</b> and the <b>input</b> <b>image.</b> The proposed method can be used for efficient and secure transmission of image data...|$|R
40|$|Abstract — In {{this paper}} we have {{proposed}} a method for an RGB image encryption supported by lifting scheme based lossless compression. Firstly we have compressed the <b>input</b> <b>color</b> <b>image</b> using a 2 -D integer wavelet transform. Then we have applied lossless predictive coding to achieve additional compression. The compressed image is encrypted by using Secure Advanced Hill Cipher (SAHC) involving a pair of involutory matrices, a function called Mix() and an operation called XOR. Decryption followed by reconstruction shows {{that there is no}} difference between the output <b>image</b> and the <b>input</b> <b>image.</b> The proposed method can be used for efficient and secure transmission of image data. Keywords- Image compression; Wavelet Transform; image encryption; Lifting Wavelet; Secure Advanced Hill Cipher...|$|R
40|$|We {{propose a}} new polynomial-time {{grayscale}} conversion algorithm applicable to general color images. The output grayscale image is modeled as a linear combination of three color channels where the mixing coefficients are computed by a constrained quadratic pro-gramming scheme using modulation domain {{features of the}} <b>input</b> <b>color</b> <b>image.</b> The optimization is formulated such that local color space distances between pixels in the <b>input</b> <b>image</b> are approximately preserved in the output grayscale image. Our experimental results demonstrate that the proposed method performs favorably com-pared to state-of-the-art conversion algorithms, often producing a grayscale image with better visual distinctions between patches that are close in the color space of the original image. Index Terms — grayscale conversion, quadratic constrained least squares, AM-FM 1...|$|R
30|$|This section {{presents}} {{experimental results}} of the proposed adaptively partitioned block-based contrast enhancement method. The proposed enhancement method first transforms the <b>input</b> <b>color</b> <b>image</b> into the hue-saturation-value (HSV) color space, and performs contrast enhancement for only V channel, which contains brightness information. To {{evaluate the effectiveness of}} the proposed method, this paper compared the proposed method with gain-controllable clipped histogram equalization (GC-CHE) (Kim and Paik 2008) and multi scale Retinex with color restoration (MSRCR) method (Jobson et al. 1997). The MSRCR method restores the color contrast by applying the conventional Retinex method to each RGB channel.|$|R
30|$|We present {{successively}} some {{requirements for}} the optical flow to work optimally: an initial exemplification of optical flow method applied to a white and a dark-skinned hand and to a colored moving hand wearing a glove and a second exemplification of all preprocessing methods, including optical flow, which yield the binary image I containing the hand contour. This binary image is smaller than the <b>input</b> <b>color</b> <b>images,</b> and its size depends on {{the distance between the}} hand and the camera. We have chosen three levels for the pyramids while applying optical flow.|$|R
40|$|The paper {{presents}} the {{image processing method}} for detection forest regions from digitized old maps. The proposed scheme consists of two principal steps. In the first one the <b>input</b> <b>color</b> <b>image</b> is filtered using averaging filter and binarized by thresholding in the HLS color space. The second step is based on morphological image processing of binary images and results in smoothening of contours of forest regions and removing unnecessary objects. As experiments are showing, the proposed method produces correct results of segmentation, allowing extraction of forest regions that can be further effectively processed and analysed...|$|R
40|$|Long-range lateral {{connections}} in the primary visual cortex (V 1) are known to link neurons with similar orientation preferences, {{but it is not}} yet known how color-selective cells are connected. Using a selforganizing model of V 1 with natural <b>color</b> <b>image</b> <b>input,</b> we show that realistic color-selective receptive fields, color maps, and orientation maps develop. Connections between orientation-selective cells match previous experimental results, and the model predicts that color-selective cells will primarily connect to other cells with similar chromatic preferences. These findings suggest that a single self-organizing system may underlie the development of orientation selectivity, color selectivity, and lateral connectivity...|$|R
40|$|Abstract — The paper {{describes}} a self supervised parallel self organizing neural network (PSONN) architecture for true color image segmentation. The proposed architecture is a parallel {{extension of the}} standard single self organizing neural network architecture (SONN) and comprises an input (source) layer of image information, three single self organizing neural network architectures for segmentation of the different primary color components in a color image scene and one final output (sink) layer for fusion of the segmented color component images. Responses to the different shades of color components are induced {{in each of the}} three single network architectures (meant for component level processing) by applying a multilevel version of the characteristic activation function, which maps the <b>input</b> <b>color</b> information into different shades of color components, thereby yielding a processed component color image segmented on the basis of the different shades of component colors. The number of target classes in the segmented image corresponds to the number of levels in the multilevel activation function. Since the multilevel version of the activation function exhibits several subnormal responses to the <b>input</b> <b>color</b> <b>image</b> scene information, the system errors of the three component network architectures are computed from some subnormal linear index of fuzziness of the component color image scenes at the individual level. Several multilevel activation functions are employed for segmentation of the <b>input</b> <b>color</b> <b>image</b> scene using the proposed network architecture. Results of the application of the multilevel activation functions to the PSONN architecture are reported on three real life true color images. The results are substantiated empirically with the correlation coefficients between the segmented images and the original images...|$|R
40|$|AbstractThis paper {{contains}} a concept {{which is the}} combination of image processing and genetic algorithms. Here is {{a proposal for a}} design of a new genetic algorithm, which is introduced to detect the license plate location. It is done by converting the taken image into binary format from gray-scale image. Also connected component analysis is implemented to detect the candidate objects in that given image. A new genetic algorithm is proposed to find out the location of license plate number in the given image. Two new crossover operators, based on sorting, are introduced, which greatly improve the performance of the system. The genetic algorithm phase also takes the color feature extraction of the <b>input</b> <b>color</b> <b>image</b> in calculating the fitness function. The system is implemented using MATLAB and various image samples are experimented with to verify the distinction of the proposed system with the existing methods. More than 100 <b>input</b> <b>images</b> are tested by this proposed method...|$|R
40|$|Abstract—Gamut mapping {{transforms}} the <b>colors</b> of an <b>input</b> <b>image</b> to the <b>colors</b> {{of a target}} device so as to exploit the full potential of the rendering device in terms of color rendition. In this paper we present spatial gamut mapping algorithms that rely on a perceptually-based variational framework. Our algorithms adapt a well-known image energy functional whose minimization leads to image enhancement and contrast modification. We show how by varying {{the importance of the}} contrast term in the image functional we are able to perform gamut reduction and gamut extension. We propose an iterative scheme that allows our algorithms to successfully map the colors from the gamut of the original image to a given destination gamut while keeping the perceived colors close to the original image. Both subjective and objective evaluations validate the promising results achieved via our proposed algorithms...|$|R
40|$|An {{efficient}} and secure visual secret sharing scheme suitable for transmission of color images is introduced and {{discussed in this}} paper. The scheme employs number theory concepts and the pixel level representation of the color image to derive reciprocal encryption and decryption procedures. Using the <b>input</b> <b>color</b> <b>image,</b> the scheme generates n shares which are then distributed to participants. Any subset of k or more participants can perfectly reconstruct the original image using their shares. The perfect reconstruction and the no pixel expansion properties make the proposed secret sharing scheme ideal for transmitting color images over un-trusted, bandwidth limited communication channels. Experimental results and comparative evaluations included in this work confirm the efficiency and effectiveness of the solution. I...|$|R
40|$|This study {{presents}} to construct special networks from images and then apply their topological properties to <b>image</b> retrieval. Each <b>input</b> <b>color</b> <b>image</b> {{is divided into}} three separate gray-level images in the RGB space. For each gray-level image, we view the 256 gray-levels as nodes and construct the Horizontal Gray-level Co-occurrence Network (HGCN) and Vertical Gray-level Co-occurrence Network (VGCN) by counting the number of horizontal and vertical occurrences for each possible gray-level pair. Based on the obtained six directed weighted networks HGCN_R/G/B and VGCN_R/G/B, we extract their topological features including in-degrees, out-degrees, in-strengths and out-strengths for image retrieval. Simulation results demonstrate the superiority of our features to some existing features in terms of P-R curve...|$|R
40|$|To {{automatically}} detect {{faces in}} real-world images presenting challenges such as complex background and multiple foregrounds, we propose a new method {{which is based}} on parametric active contours and which does not require any supervision, model nor training. The proposed face detection technique computes multi-scale representations of an <b>input</b> <b>color</b> <b>image</b> and based on them initializes the multi-feature vector flow active contours which, after their evolution, automatically delineate the faces. In this way, our computationally efficient system successfully detects faces in complex pictures with varying numbers of persons of diverse gender and origins and with different types of face views (front/profile) and variate face alignments straight/oblique), as demonstrated in tests carried out on several datasets...|$|R
40|$|Radiometric {{variations}} between <b>input</b> <b>images</b> can seriously {{degrade the}} performance of stereo matching algorithms. In this situation, mutual information is a very popular and powerful measure which can find any global relationship of intensities between two <b>input</b> <b>images</b> taken from unknown sources. The mutual information-based method, however, is still ambiguous or erroneous as regards local radiometric variations, since it only accounts for global variation between images, and does not contain spatial information properly. In this paper, we present a new method based on mutual information combined with SIFT descriptor to find correspondence for images which undergo local as well as global radiometric variations. We transform the <b>input</b> <b>color</b> <b>images</b> to log-chromaticity color space from which a linear relationship can be established. To incorporate spatial information in mutual information, we utilize the SIFT descriptor which includes near pixel gradient histogram to construct a joint probability in log-chromaticity color space. By combining the mutual information as an appearance measure and the SIFT descriptor as a geometric measure, we devise a robust and accurate stereo system. Experimental results show that our method is superior to the state-of-the art algorithms including conventional mutual information-based methods and window correlation methods under various radiometric changes. 1...|$|R
40|$|This paper proposes {{the design}} of {{high-performance}} histogram of oriented gradient (HOG) feature calculation circuit for real-time pedestrian detection. By utilizing thor-oughly analyzed results of the operations for overlapping blocks and windows and by managing internal memories and registers to store the intermediate results of HOG fea-ture efficiently, not only all redundant operations are totally removed but also trilinear interpolation technique is successfully applied in the proposed circuit. The proposed circuit can process variable sizes of <b>input</b> <b>image</b> up to full high-definition (HD) image and it supports two types of detection window and <b>color</b> format of <b>input</b> <b>image.</b> In order to accelerate the processing time, the proposed circuit adopts the parallel architecture with pipelines, and the external memory bandwidth is minimized by the efficient man-agement of internal memories and registers. The circuit size is reduced by sharing the circuit resources for the common operations and by minimizing the required storage spaces. Even though {{a large amount of}} computations is required due to trilinear inter-polation, the proposed circuit can process full HD images in real time, assuming a scal-ing factor of 0. 9. Therefore, it can be used for real-time pedestrian detection in many applications...|$|R
30|$|By {{easing the}} {{bilateral}} filter, {{the image is}} decomposed into two layers. The detail layer remains unprocessed so that the details can be retained within the adaptive tone mapped image. The color information is kept unchanged before the large-scale layer is obtained from bilateral filtering allowing the <b>color</b> appearance of <b>input</b> <b>image</b> can be remained. The adaptive tone mapping manipulates different regions according to properties of the corresponding regions, so that global smoothness can be accomplished without losing local details, and global dynamic range can be stretched with achieving promising contrast enhancement. Finally, the gamut volume and color difference using CIE 94 color difference equation are calculated to demonstrate the proposed method is capable of producing less color shift while obtaining larger gamut volume than original image. Additionally, the enhancement of color image is effectively performed without requirement of manually parameters setting during the whole process.|$|R
40|$|Detecting objects {{by their}} color is {{essential}} in robotic sensing. A simple way is probably to capture images with a digital camera and then using algorithms to determine <b>colors</b> of an <b>input</b> <b>image.</b> However, this approach is always affected by some issues such as light reflection and shadows on the object’s surface. Although some sensory methodologies for color detection are available, {{they might not be}} a good choice in a ubiquitous robotic system, whereby realtime computation ability and low power consumption are of utmost importance. Too complicated image processing techniques will cause some practical problems when implemented in an embedded system. Here, a real-time algorithm is presented for color detection which can be used with the field programmable gate array (FPGA) technology. By utilizing the proposed approach implemented in circuit designs, realtime color discrimination can be achieved with good performance as demonstrated in this paper. ...|$|R
40|$|Intelligent seal imprint {{identification}} {{has been}} studies from diverse perspectives for decades. Even though {{a number of}} seal registration methods using digital image processing techniques have been proposed, the difficulty of seal registration remains unresolved especially when the concerned patterns are very noisy and rotated. To overcome the problems, we propose an intelligent segmentation for binarizing the <b>input</b> <b>color</b> seal <b>images</b> {{in terms of the}} adaptive thresholds. The FFT (Fast Fourier Transform) is applied to register rectangular and elliptic seals in polar coordinates, and the novel spatial spectrum function called ring-projection is used for circular seal registration. Empirical analysis has demonstrated that the proposed method performs much better than other approaches...|$|R
