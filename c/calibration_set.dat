397|582|Public
5000|$|The {{parameters}} [...] and [...] {{are estimated}} using a maximum likelihood method that optimizes {{on the same}} training set as that for the original classifier [...] To avoid overfitting to this set, a held-out <b>calibration</b> <b>set</b> or cross-validation can be used, but Platt additionally suggests transforming the labels [...] to target probabilities ...|$|E
50|$|BEST {{is based}} on a population, P, {{relative}} to some hyperspace, R, that represents the universe of possible samples. P* is the realized values of P based on a <b>calibration</b> <b>set,</b> T. T is used to find all possible variation in P. P* is bound by parameters C and B. C is the expectation value of P, written E(P), and B is a bootstrapping distribution called the Monte Carlo approximation. The standard deviation can be found using this technique. The values of B projected into hyperspace give rise to X. The hyperline from C to X gives rise to the skew adjusted standard deviation which is calculated in both directions of the hyperline.|$|E
40|$|The {{visible and}} {{near-infrared}} (VNIR) spectroscopy prediction model {{is an effective}} tool for the prediction of soil organic matter (SOM) content. The predictive accuracy of the VNIR model is highly dependent on {{the selection of the}} <b>calibration</b> <b>set.</b> However, conventional methods for selecting the <b>calibration</b> <b>set</b> for constructing the VNIR prediction model merely consider either the gradients of SOM or the soil VNIR spectra and neglect the influence of environmental variables. However, soil samples generally present a strong spatial variability, and, thus, the relationship between the SOM content and VNIR spectra may vary with respect to locations and surrounding environments. Hence, VNIR prediction models based on conventional <b>calibration</b> <b>set</b> selection methods would be biased, especially for estimating highly spatially variable soil content (e. g., SOM). To equip the <b>calibration</b> <b>set</b> selection method with the ability to consider SOM spatial variation and environmental influence, this paper proposes an improved method for selecting the <b>calibration</b> <b>set.</b> The proposed method combines the improved multi-variable association relationship clustering mining (MVARC) method and the Rank–Kennard–Stone (Rank-KS) method in order to synthetically consider the SOM gradient, spectral information, and environmental variables. In the proposed MVARC-R-KS method, MVARC integrates the Apriori algorithm, a density-based clustering algorithm, and the Delaunay triangulation. The MVARC method is first utilized to adaptively mine clustering distribution zones in which environmental variables exert a similar influence on soil samples. The feasibility of the MVARC method is proven by conducting an experiment on a simulated dataset. The <b>calibration</b> <b>set</b> is evenly selected from the clustering zones and the remaining zone by using the Rank-KS algorithm in order to avoid a single property in the selected <b>calibration</b> <b>set.</b> The proposed MVARC-R-KS approach is applied to select a <b>calibration</b> <b>set</b> in order to construct a VNIR prediction model of SOM content in the riparian areas of the Jianghan Plain in China. Results indicate that the <b>calibration</b> <b>set</b> selected using the MVARC-R-KS method is representative of the component concentration, spectral information, and environmental variables. The MVARC-R-KS method can also select the <b>calibration</b> <b>set</b> for constructing a VNIR model of SOM content with a relatively higher-fitting degree and accuracy by comparing it to classical <b>calibration</b> <b>set</b> selection methods...|$|E
40|$|In {{this paper}} we report the {{application}} of NMR spectroscopy and Raman spectroscopy to determine the degree of maleate substitution in maleinated starches. Five kinds of maleinated starches were investigated and <b>calibration</b> <b>sets</b> were constructed to derive linear regression equations {{that may be used}} to predict the degree of maleate substitution for starch samples with unknown amounts of chemical modification. The <b>calibration</b> <b>sets</b> reported have very high linearity (r > 0. 99) for both the NMR and Raman methods. The NMR and Raman <b>calibration</b> <b>sets</b> allow fast and nondestructive measurement of the degree of maleate substitution for different starches with little need of sample preparation. link_to_subscribed_fulltex...|$|R
40|$|In {{high-performance}} liquid chromatography, quantitative structure-retention relationships (QSRRs) {{are applied}} to model the relation between chromatographic retention and quantities derived from molecular structure of analytes. Classically {{a substantial number of}} test analytes is used to build QSRR models. This makes their application laborious and time consuming. In this work a strategy is presented to build QSRR models based on selected reduced <b>calibration</b> <b>sets.</b> The analytes in the reduced <b>calibration</b> <b>sets</b> are selected from larger sets of analytes by applying the algorithm of Kennard and Stone on the molecular descriptors used in the QSRR concerned. The strategy was applied on three QSRR models of different complexity, relating log kw or log k with either: (i) log P, the n-octanol-water partition coefficient, (ii) calculated quantum chemical indices (QCI), or (iii) descriptors from the linear solvation energy relationship (LSER). Models were developed and validated for 76 reversed-phase high-performance liquid chromatography systems. From the results we can conclude {{that it is possible to}} develop log P models suitable for the future prediction of retentions with as few as seven analytes. For the QCI and LSER models we derived the rule that three selected analytes per descriptor are sufficient. Both the dependent variable space, formed by the retention values, and the independent variable space, formed by the descriptors, are covered well by the reduced <b>calibration</b> <b>sets.</b> Finally guidelines to construct small <b>calibration</b> <b>sets</b> are formulated. © 2009 Elsevier B. V. All rights reserved...|$|R
40|$|Because {{of their}} {{chemical}} properties and multiday half lives, iodine- 124 and zirconium- 89 {{are being used}} in {{a growing number of}} PET imaging studies. Some aspects of their quantitation, however, still need attention. For (89) Zr the PET images should, in principle, be as quantitatively accurate as similarly reconstructed 18 F measurements. We found, however, that images of a 20 cm well calibration phantom containing (89) Zr underestimated the activity by approximately 10 % relative to a dose calibrator measurement (Capintec CRC- 15 R) using a published <b>calibration</b> <b>setting</b> number of 465. PET images of (124) I, in contrast, are complicated by the contribution of decays in cascade that add spurious coincident events to the PET data. When these cascade coincidences are properly accounted for, quantitatively accurate images should be possible. We found, however, that even with this correction we still encountered {{what appeared to be a}} large variability in the accuracy of the PET images when compared to dose calibrator measurements made using the <b>calibration</b> <b>setting</b> number, 570, recommended by Capintec. We derive new <b>calibration</b> <b>setting</b> numbers for (89) Zr and (124) I based on their 511 keV photon peaks as measured on an HPGe detector. The peaks were calibrated relative to an 18 F standard, the activity level of which was precisely measured in a dose calibrator under well-defined measurement conditions. When measuring (89) Zr on a Capintec CRC- 15 R we propose the use of <b>calibration</b> <b>setting</b> number 517. And for (124) I, we recommend the use of a copper filter surrounding the sample and the use of <b>calibration</b> <b>setting</b> number 494. The new dose calibrator measurement procedures we propose will result in more consistent and accurate radioactivity measurements of (89) Zr and (124) I. These and other positron emitting radionuclides can be accurately calibrated relative to 18 F based on measurements of their 511 keV peaks and knowledge of their relative positron abundances...|$|R
40|$|Multiple {{regional}} chironomid-climate calibration datasets {{are available}} to reconstruct quantitatively July air temperatures from fossil chironomid assemblages. We {{examined the relationship between}} July air temperature and the 40 most common chironomid taxa in three independent Eurasian calibration (training) sets. The estimated temperature optimum of each chironomid taxon is systematically lower (by ~ 1 - 2 °C) in a Norwegian <b>calibration</b> <b>set</b> compared to Finnish and Russian calibration sets. This result might partly be {{explained by the fact that}} the Norwegian <b>calibration</b> <b>set</b> extends further at the cold end of the temperature gradient. A difference in continentality between the Russian sites and the European sites might also contribute to this pattern. The number of taxa that show a statistically significant unimodal response to temperature is higher in the Norwegian <b>calibration</b> <b>set</b> (34 out of 40 taxa) compared to the modern Finnish (11 of 37 taxa; 3 common taxa absent) and the Russian <b>calibration</b> <b>set</b> (20 of 40 taxa), probably due to the longer temperature gradient incorporated in the Norwegian <b>calibration</b> <b>set.</b> We applied all three calibration sets to fossil chironomid assemblages from the high-latitude study site of Sokli (northeast Finland), a site with a unique series of lacustrine deposits covering (amongst others) the Holocene, part of early MIS 3 (at ~ 53 ka) and MIS 5 d-c (at ~ 110 - 95 ka) and with independent proxy-records for comparison. In the early Holocene and during MIS 5 c, the chironomid-based temperature inferences from all three inference models had similar values. Temperature reconstructions based on the Norwegian <b>calibration</b> <b>set</b> are 2 - 4 °C lower for the late Holocene, early MIS 3 and MIS 5 d than the inferred temperatures based on the other calibration sets. Although the lakes included in the Finnish <b>calibration</b> <b>set</b> are located closest to the site of Sokli, evaluation tests and a comparison with independent proxy data suggests that the Norwegian <b>calibration</b> <b>set</b> provides the most suitable analogues for reconstruction purposes for most of the fossil assemblages. Our results imply that when choosing a <b>calibration</b> <b>set</b> for quantitative climate reconstructions on glacial timescales, regional proximity of the fossil site may not be a sufficient basis, and the length of the temperature gradient of the calibration dataset and factors such as the continentality gradient covered by the <b>calibration</b> <b>set</b> must also be considered...|$|E
40|$|We {{investigated}} {{the effect of}} both the <b>calibration</b> <b>set</b> size (number of samples) and the calibration sampling strategy {{on the performance of}} vis–NIR models to predict clay content and exchangeable Ca (Ca++). We evaluated the following calibration sampling algorithms: Kenard–Stone (KSS), conditioned Latin hypercube (cLHS) and fuzzy c-means (FCMS), which are commonly used in spectroscopy and digital soil mapping. These algorithmswere tested separately using a field-scale dataset and a regional scale dataset. For each datasetwe randomly selected a validation subset and the remaining samples were used as candidates for calibration sampling. The accuracy of vis–NIRmodels of clay content and Ca++were compared {{on the basis of the}} sampling algorithms used for selecting the calibration samples. We also tested 38 different <b>calibration</b> <b>set</b> sizes varying from 10 to 380 samples. The vis–NIR models were calibrated by using the support vector regression machine (SVM) algorithm. The training root mean square error (RMSE), the normalized RMSE and the prediction RMSE were used to evaluate the sensitivity of the models to both the sampling algorithmand the <b>calibration</b> <b>set</b> size. In addition, we {{investigated the}} sample representativeness of each algorithm and we suggest a novel and simple methodology to identify an adequate <b>calibration</b> <b>set</b> size based only on the vis–NIR data (i. e. without prior knowledge of the response variables). As expected, our results showthat the error of the soil vis–NIRmodels depends on the <b>calibration</b> <b>set</b> size. When the number of calibration samples is relatively small the sampling algorithm may play an important role on the accuracy of the vis–NIRmodels. On the other hand, if the <b>calibration</b> <b>set</b> size is large enough, the samplingmethod is not a critical issue. Concerning the sample representativeness, we found for all the algorithms that the original distribution of the vis–NIR data can be better replicated by increasing the <b>calibration</b> <b>set</b> size. The results indicate that the calibration samples selected by the cLHS and by the FCMSalgorithms better replicate the original vis–NIR distribution of all the samples, in comparison to those samples selected by the KSS algorithm...|$|E
40|$|International audienceThe hyperspectral imaging {{technology}} {{is used to}} detect early-maturing pear’s effective acidity nondestructively, and effective prediction model is established. 145 pears’ hyperspectral images are obtained in the wavelength range of 400 nm- 1000 nm. Total 145 pears are separated into the <b>calibration</b> <b>set</b> (77 samples) and prediction set (68 samples). Early-maturing pear’s effective acidity partial least squares (PLS) prediction model is built in different range of spectrum band. By comparison, the range 498 nm - 971 nm was selected in using partial least squares (PLS) to build early-maturing pear’s effective acidity prediction model. The experimental results show that, PLS prediction model of early-maturing pear’s effective acidity has the best effect in this range of wavelength. The correlation coefficient R between early-maturing pear’s actual effective acidity and predicted effective acidity is 0. 9944 and 0. 9233 for <b>calibration</b> <b>set</b> and prediction set respectively, the root mean squared error of prediction samples (RMSEP) is 0. 022 and 0. 072 for <b>calibration</b> <b>set</b> and prediction set respectively...|$|E
40|$|Over {{the past}} few years, the subject of movies getting louder has {{generated}} increasing concern within the film production community. In addition, it has become commonplace for movie-goers to claim that movies are too loud. Many theatres now project films at an audio fader <b>setting</b> below the <b>calibration</b> <b>setting</b> that would match that in the dubbing theatre, presumabl...|$|R
40|$|International audienceIn {{order to}} achieve {{non-destructive}} of mature vinegar varieties, a fast discrimination method was put forward based on Visible_near infrared reflectance (NIR) spectroscopy. The FieldSpec 3 spectrometer was used for collecting 20 sample spectra data of the three kinds of mature vinegar separately. Then principal component analysis (PCA) was used to process the spectral data after pretreatment using average smoothing method and multiplicative scatter correction (MSC) method, and principal components(PCs) were selected based on accumulative reliabilities. A total of 60 mature vinegar samples were divided into <b>calibration</b> <b>sets</b> and validation <b>sets</b> randomly, the <b>calibration</b> <b>sets</b> had 45 samples and the validation sets had 15 samples. The stepwise discriminant analysis was trained with five PCs in <b>calibration</b> <b>sets</b> as the inputs,and mature vinegar varieties as the outputs. The stepwise discriminant analysis model was built for discrimination of mature vinegar variety,and the model contains 15 samples in the validation sets. The result showed that a 100 % recognition ration was achieved. The BP-ANN model for discrimination of mature vinegar varieties were built based on PCA and the stepwise discriminant analysis, then the model was tested with the 15 sample in the validation sets. The result showed that a 100 % recognition ration was achieved with the threshold predictive error ± 0. 027. It based on five principal components had a higher prediction accuracy and efficiency more than the BP neural network model. It could be concluded that PCA combined with stepwise discriminant analysis and BP-ANN was an available method for varieties recognition of mature vinegar based on NIR spectroscopy...|$|R
40|$|Human {{impact is}} a {{well-known}} confounder in pollen-based quantitative climate reconstructions as most terrestrial ecosystems have been artificially affected to varying degrees. In this paper, we use a human-induced pollen dataset (H-set) and a corresponding natural pollen dataset (N-set) to establish pollen–climate <b>calibration</b> <b>sets</b> for temperate eastern China (TEC). The two <b>calibration</b> <b>sets,</b> taking a weighted averaging partial least squares (WA-PLS) approach, are used to reconstruct past climate variables from a fossil record, which {{is located at the}} margin of the East Asian summer monsoon in north-central China and covers the late glacial Holocene from 14. 7  ka BP (thousands of years before AD  1950). Ordination results suggest that mean annual precipitation (P ann) is the main explanatory variable of both pollen composition and percentage distributions in both datasets. The P ann reconstructions, based on the two <b>calibration</b> <b>sets,</b> demonstrate consistently similar patterns and general trends, suggesting a relatively strong climate impact on the regional vegetation and pollen spectra. However, our results also indicate that the human impact may obscure climate signals derived from fossil pollen assemblages. In a test with modern climate and pollen data, the P ann influence on pollen distribution decreases in the H-set, while the human influence index (HII) rises. Moreover, the relatively strong human impact reduces woody pollen taxa abundances, particularly in the subhumid forested areas. Consequently, this shifts their model-inferred P ann optima to the arid end of the gradient compared to P ann tolerances in the natural dataset and further produces distinct deviations when the total tree pollen percentages are high (i. e. about 40...|$|R
40|$|Calibration is {{the first}} step in the {{prediction}} of concentrations from spectral measurements of chemical reaction systems. It is a well-known fact that the species in the <b>calibration</b> <b>set</b> must include those in the new set. Typically, the <b>calibration</b> <b>set</b> is constructed from nonreacting mixtures of known concentrations. In this paper, it is proposed instead to use the calibration data from reacting mixtures, thereby avoiding the independent variation of possibly highly-reactive intermediates. However, for the prediction to be correct, restrictions on the initial and inlet concentrations of the new data set must be imposed. When these restrictions cannot be met, calibration of data in reaction-variant form is proposed. The methodology is illustrated experimentally using an esterification reaction...|$|E
3000|$|... 2) {{and root}} mean square error of {{prediction}} (RMSEP) served as the statistical measures of predictive power. RMSEP values were used to measure how well the calibration model predicts the parameter of interest for a set of unknown samples excluding the <b>calibration</b> <b>set.</b>|$|E
40|$|Genome-enabled {{prediction}} provides breeders {{with the}} means {{to increase the number}} of genotypes that can be evaluated for selection. One of the major challenges in genome-enabled prediction is how to construct a training set of genotypes from a <b>calibration</b> <b>set</b> that represents the target population of genotypes, where the <b>calibration</b> <b>set</b> is composed of a training and validation set. A random sampling protocol of genotypes from the <b>calibration</b> <b>set</b> will lead to low quality coverage of the total genetic space by the training set when the <b>calibration</b> <b>set</b> contains population structure. As a consequence, predictive ability will be affected negatively, because some parts of the genotypic diversity in the target population will be under-represented in the training set, whereas other parts will be over-represented. Therefore, we propose a training set construction method that uniformly samples the genetic space spanned by the target population of genotypes, thereby increasing predictive ability. To evaluate our method, we constructed training sets alongside with the identification of corresponding genomic prediction models for four genotype panels that differed in the amount of population structure they contained (maize Flint, maize Dent, wheat, and rice). Training sets were constructed using uniform sampling, stratified-uniform sampling, stratified sampling and random sampling. We compared these methods with a method that maximizes the generalized coefficient of determination (CD). Several training set sizes were considered. We investigated four genomic prediction models: multi-locus QTL models, GBLUP models, combinations of QTL and GBLUPs, and Reproducing Kernel Hilbert Space (RKHS) models. For the maize and wheat panels, construction of the training set under uniform sampling led to a larger predictive ability than under stratified and random sampling. The results of our methods were similar to those of the CD method. For the rice panel, all training set construction methods led to similar predictive ability, a reflection of the very strong population structure in this panel...|$|E
3000|$|We are {{interested}} in examining the over-time and cross-region observed values of occupational groups and productivity in Spain, under the lens of our three occupational choices model. For this purpose, we calibrate {{the values of the}} parameters of the model with data from the Spanish economy for the years 2000 – 2005. This <b>calibration</b> <b>sets</b> the size of each occupational group at values of 6.5 [...]...|$|R
40|$|Regulatory {{agencies}} often rely on paleolimnological {{studies for}} models that predict variables pertinent to nutrient loading or to public perception. Limitations of statistical approaches often pose significant challenges. We present {{a case study}} from Florida USA that involves diatom-based inference models derived from two <b>calibration</b> <b>sets.</b> Spatial autocorrelation conclusions differed with methods and approaches, and h block cross validation was unduly pessimistic. <b>Calibration</b> <b>sets</b> and temporal sets represent fundamentally different populations. The accuracy and precision of temporal inferences for specific lakes can be affected by site-specific factors, and {{are not likely to}} be known with the certainty suggested by models. Error terms can provide a false sense of knowledge about the reliability of inferences for temporal samples. Broad error terms for limnetic total phosphorus models have little or no utility in any event. Limnetic total P models can perform poorly when applied to N-limited lakes. Transfer functions should be regarded more as qualitative indicators of past water quality rather than methods with known precision, and more emphasis should be placed on multiple lines of evidence and ecological interpretations...|$|R
40|$|A chemometric {{model for}} the {{simultaneous}} estimation of phenobarbitone and phenytoin sodium anticonvulsant tablets using the back-propagation neural network calibration has been presented. The use of calibration datasets constructed from the spectral data of pure components is proposed. The <b>calibration</b> <b>sets</b> were designed such that the concentrations were orthogonal and span the possible mixture space fairly evenly. Spectra of phenobarbitone and phenytoin sodium were recorded at several concentrations within their linear range and used to compute the calibration mixture between wavelengths 220 and 260 nm at an interval of 1 nm. The back-propagation neural network model was optimized using three different <b>sets</b> of <b>calibration</b> and monitoring data {{for the number of}} hidden sigmoid neurons. The calibration model was thoroughly evaluated at several concentration levels using spectra obtained for 95 synthetic binary mixtures prepared using orthogonal designs. The optimized model showed sufficient robustness even when the <b>calibration</b> <b>sets</b> were constructed from different sets of pure spectra of components. Although the components showed complete spectral overlap, the model could accurately estimate the drugs, with satisfactory precision and accuracy, in tablet dosage with no interference from excipients, as indicated by the recovery study results...|$|R
3000|$|... 2) {{were used}} to assess the fitting performance. The {{standard}} error of prediction (SEP) was employed to evaluate the accuracy of the established model by predicting the parameter of interest for a set of unknown samples that are different from the <b>calibration</b> <b>set.</b> The predicting coefficient of determination (R [...]...|$|E
40|$|A 440 ha paddock of Sorghum (Sorghum bicolor cv Buster and cv MR 43) was {{harvested}} at 'Well Park' in Queensland, Australia (27. 105 degrees S, 151. 345 degrees E), in May-June 2004. Prior to harvest, {{a prototype}} Cropscan 2000 H 'on-the-go' near-infrared (NIR) protein sensor designed by NIR Technology Australia ([URL] was fitted to the bubble-up auger {{of the contract}} harvester's New Holland TR 66 combine. More than 5000 readings were taken within a 282 ha sub-sample area of the paddock (approximately every 30 - 40 m). Additionally, 120 grab samples were collected from the bubble-up auger and {{the position of the}} sample 'tagged' in the yield monitor file. These samples were analysed using laboratory NIR equipment to compare with the 'on-header' unit. Unfortunately, the samples were outside the <b>calibration</b> <b>set</b> of the instrument and the results were in error. To rectify this situation, 10 of the samples were processed for protein using wet chemistry and added to the <b>calibration</b> <b>set.</b> The 120 samples were repredicted and compared to the protein sensor values. The correlation between the 'grab samples' protein values and values from the protein sensor for the same location in the field was low (R 2 = 0. 32). This may have been due to a low population in the <b>calibration</b> <b>set</b> or an offset in the protein sensor. This is being investigate...|$|E
40|$|Surface {{sediment}} {{recovered from}} 51 lakes in the Uinta Mountains of northeast Utah was analyzed for subfossil chironomid remains, and incorporated in a midge-based inference model for summer surface water temperature (SSWT). The lakes in the <b>calibration</b> <b>set</b> spanned elevation, depth, and summer surface water temperature ranges of 900 m, 12. 7 m, and 11. 3 °C, respectively. Redundancy analysis (RDA) identified four variables, SSWT, depth, specific conductivity, and Al concentration, that {{could account for}} a statistically significant amount of variance in the chironomid distribution, with SSWT accounting for the largest amount of variance. The Uinta Mountain <b>calibration</b> <b>set</b> was merged with a previously developed <b>calibration</b> <b>set</b> from the Sierra Nevada, California, {{in order to develop}} a midge-based inference model for SSWT applicable to subfossil chironomid stratigraphies from the Great Basin. A variety of statistical approaches, such as weighted averaging (WA), weighted averaging-partial least squares (WA-PLS), and partial least squares (PLS) were used to assess model performance. The best inference model for SSWT, based on a 3 -component WA-PLS approach, had robust performance statistics (r 2 jack = 0. 66, RMSEP = 1. 4 °C). The newly expanded inference model will enable more accurate estimates of late Pleistocene and Holocene thermal regimes and help address many outstanding questions relating to long-term and recent climate change in this region...|$|E
40|$|Abstract — We {{propose a}} new method for {{extrinsic}} calibration of a line-scan LIDAR with a perspective projection camera. Our method is a closed-form, minimal {{solution to the}} problem. The solution is a symbolic template found via variable elimination and the multi-polynomial Macaulay resultant. It does not require initialization, {{and can be used}} in an automatic <b>calibration</b> <b>setting</b> when paired with RANSAC and least-squares refinement. We show the efficacy of our approach through a set of simulations and a real calibration. I...|$|R
30|$|The {{weighted}} regression models with a weighting factor of 1 /x, 1 /√x, and 1 /x 2 were further constructed {{on the same}} <b>calibration</b> data <b>set.</b>|$|R
5000|$|PaRappa the Rapper Remastered {{received}} mixed or average reviews. It {{was praised}} {{for keeping the}} charm of the original game while improving on the graphical quality, but was criticised for only improving the graphics of the gameplay and not the cutscenes. Caitlin Cooke of Destructoid wrote that [...] "The remastered version does not include a <b>calibration</b> <b>setting.</b> This works very much against PaRappas favor as there’s an extremely noticeable lag throughout each of the levels, causing havoc when trying to hit the notes on time." ...|$|R
40|$|Spatially enabled sensing {{technologies}} {{are now available}} for refining traditional methods of assessing soil carbon stocks and stock changes within the landscape, taking into account spatial variability. In this study visible near infra-red spectroscopy (VNIR) was trialled as a non-destructive and cost-efficient field method for estimating soil carbon stocks in a 68. 5 hectare arable field. Soil carbon values (to 0. 3 m) at one hundred positions have been spatialised using electromagnetic (EM) survey data to develop a total soil organic carbon (SOC) mapping method. Soil carbon was estimated by (1) laboratory analysis and (2) chemometric processing of the VNIR soil spectra. To estimate the number of physical samples needed to provide an accurate <b>calibration</b> <b>set</b> for the chemometric processing of VNIR spectra, model performance was repetitively assessed using between 10 and 80 % of soil analyses for the <b>calibration</b> <b>set.</b> Our results indicate that VNIR could accurately predict SOC using only 40 % of the soil samples as a <b>calibration</b> <b>set.</b> Mean estimations over 10 simulations of the total soil carbon present to 0. 3 m depth in this paddock is 3476. 2 T for Method 1 and 3555. 73 T for Method 2. Method 2 used 60 % less soil carbon laboratory analyses, and only differs from the Method 1 result by 2. 29 %...|$|E
40|$|Chemometrics-assisted {{spectrophotometry}} for {{the determination}} of two protease inhibitors, lopinavir and ritonavir, in plasma was evaluated. A set of calibration mixtures (<b>calibration</b> <b>set)</b> was designed according to central composite design. The UV spectra obtained from the <b>calibration</b> <b>set</b> were subjected to partial least square regression (PLS- 1) to construct the prediction models for lopinavir and ritonavir in unknown samples, which were then validated in a randomly selected set of synthetic mixtures of the drugs. An optimum model was obtained in the wavelength ranges of 215 – 249 nm and 240 – 279 nm with principal components 8 for both lopinavir and ritonavir respectively. The prediction models were used to analyse the two drugs in plasma {{and the results were}} compared with those obtained by high-performance liquid chromatography (HPLC). The PLS- 1 model and the HPLC method were found to be comparable...|$|E
40|$|Genome enabled {{prediction}} provides breeders {{with the}} means {{to increase the number}} of genotypes that can be evaluated for selection. One of the major challenges in genome enabled prediction is how to construct a training set of genotypes from a <b>calibration</b> <b>set</b> that represents the target population of genotypes, where the <b>calibration</b> <b>set</b> is composed of a training and validation set. A random sampling protocol of genotypes from the <b>calibration</b> <b>set</b> will lead to low quality coverage of the total genetic space by the training set when the <b>calibration</b> <b>set</b> contains population structure. As a consequence, predictive ability will be affected negatively, because some parts of the genotypic diversity in the target population will be under represented in the training set, whereas other parts will be over represented. Therefore, we propose a training set construction method that uniformly samples the genetic space spanned by the target population of genotypes, thereby increasing predictive ability. To evaluate our method, we constructed training sets alongside with the identification of corresponding genomic prediction models for four genotype panels that differed in the amount of population structure they contained (maize Flint, maize Dent, wheat, and rice). Training sets were constructed using uniform sampling, stratified-uniform sampling, stratified sampling and random sampling. We compared these methods with a method that maximizes the generalized coefficient of determination (CD), proposed by Rincent et al. (2012). Several training set sizes were considered. We investigated four genomic prediction models: multi-locus QTL models, GBLUP models, combinations of QTLs and GBLUPs, and Reproducing Kernel Hilbert Spaces (RKHS) models. For the maize and wheat panels, construction of the training set under uniform sampling led to a larger predictive ability than under stratified and random sampling. The results of our methods were similar to those of the CD method. For the rice panel, all training set construction methods led to similar predictive ability, a reflection of the very strong population structure in this panel...|$|E
30|$|A <b>calibration</b> curve was <b>set</b> at five <b>calibration</b> {{standard}} levels.|$|R
40|$|Presented here is {{the first}} chironomid <b>calibration</b> data <b>set</b> for {{tropical}} South America. Surface sediments were collected from 59 lakes across Bolivia (15 lakes), Peru (32 lakes), and Ecuador (12 lakes) between 2004 and 2013 over an altitudinal gradient from 150 mabove sea level (a. s. l) to 4655 ma. s. l, between 0 - 17 ° S and 64 - 78 °W. The study sites cover a mean annual temperature (MAT) gradient of 25 °C. In total, 55 chironomid taxa were identified in the 59 <b>calibration</b> data <b>set</b> lakes. When used as a single explanatory variable, MAT explains 12. 9...|$|R
40|$|Pollen-based past climate {{reconstruction}} for {{regions with}} long-term human occupation is always controversial. We examined the bias {{induced by the}} human impact on vegetation in a climate reconstruction for temperate eastern China by comparing the deviations in the reconstructed results for a fossil record (Lake Gonghai, 38. 54 °N, 112. 14 °E) based on two pollen-climate <b>calibration</b> <b>sets.</b> Climatic signals in pollen assemblages are indeed obscured by human impact; however, {{the extent of the}} bias could be assessed. The reconstructed anunal precipitation values of the last 14. 7 kyr in the East Asian summer monsoon margin are given in the data set...|$|R
40|$|Chantier qualité GAGenomic {{selection}} {{refers to}} the use of genotypic information for predicting breeding values of selection candidates. A prediction formula is calibrated with the genotypes and phenotypes of reference individuals constituting the <b>calibration</b> <b>set.</b> The size and the composition of this set are essential parameters affecting the prediction reliabilities. The objective {{of this study was to}} maximize reliabilities by optimizing the <b>calibration</b> <b>set.</b> Different criteria based on the diversity or on the prediction error variance (PEV) derived from the realized additive relationship matrix-best linear unbiased predictions model (RA-BLUP) were used to select the reference individuals. For the latter, we considered the mean of the PEV of the contrasts between each selection candidate and the mean of the population (PEVmean) and the mean of the expected reliabilities of the same contrasts (CDmean). These criteria were tested with phenotypic data collected on two diversity panels of maize (Zea mays L.) genotyped with a 50 k SNPs array. In the two panels, samples chosen based on CDmean gave higher reliabilities than random samples for various <b>calibration</b> <b>set</b> sizes. CDmean also appeared superior to PEVmean, which can be explained by the fact that it takes into account the reduction of variance due to the relatedness between individuals. Selected samples were close to optimality for a wide range of trait heritabilities, which suggests that the strategy presented here can efficiently sample subsets in panels of inbred lines. A script to optimize reference samples based on CDmean is available on request...|$|E
3000|$|... values. Each {{variable}} was mean centred and {{the maximum number}} of latent variable (LV) was set to five. Four third of data sets were randomly selected as <b>calibration</b> <b>set</b> and remaining data were used for test set validation. The optimum number of LV was determined where the minimum standard error of validation (SEV) was obtained. Data were processed by Matlab R 2014 a.|$|E
40|$|Abstract. Considering that {{crystallinity}} {{is one of}} {{the important}} properties that influence the end use of cellulose nanomaterials, {{it is important that the}} former be measured accurately. Recently, a new method based on near-IR FT-Raman spectroscopy was proposed to determine cellulose I crystallinity. It was reported that in the Raman spectrum of cellulose materials, the peak intensity ratio of 380 and 1, 096 cm- 1 bands can be used to determine cellulose crystallinity. Raman crystallinities of the calibration-set Whatman CC 31 samples were correlated with the WAXS data (Segal-WAXS- 21 °; coefficient of determination R 2 = 0. 98). Average standard error calculated from replicate Raman acquisitions indicated that the Raman crystallinity model was highly reliable. In ongoing investigations, the Raman method is being applied to determine crystallinity of nanocellulose materials. Figure 1. Univariate analysis of the <b>calibration</b> <b>set</b> samples showing the correlation between <b>calibration</b> <b>set</b> crystallinity versus 380 / 1, 096 Raman intensity ratio or WAXS crystallinity [2]...|$|E
40|$|Accurate {{estimation}} of the axial position of a molecule using a single lateral image remains a challenge in fluorescent single particle tracking. Here, a principled algorithm for the Bayesian {{estimation of}} the axial position of a molecule in three-dimensional astigmatism-based particle tracking is proposed. This technique uses the data from a <b>calibration</b> image <b>set</b> to derive the position without assuming a functional form for the abberated defocusing curve. Using a <b>calibration</b> image <b>set</b> from forty 57 &#x 2009;nm beads, the axial position is calculated, and the error associated with position estimation is discussed. This method is compared to previously published algorithms...|$|R
40|$|We compute a pseudo-dataset by Monte Carlo {{simulations}} featuring important {{characteristics of}} US agriculture, {{such that the}} initial technology parameters are known, and employing widely used datasets for calibration. Then, we show the usefulness of this calibration by applying the duality theory approach to datasets bearing as sources of noise only the aggregation of technologically heterogeneous firms. Estimation recovers initial parameters with reasonable accuracy. These conclusions are expected, but the proposed <b>calibration</b> <b>sets</b> the basis for analysing the performance of duality theory in empirical work when datasets have more observed and unobserved sources of noise, as those faced by practitioners...|$|R
30|$|Step 1 : <b>Set</b> <b>calibration</b> grid, {{as shown}} in Figure 5.|$|R
