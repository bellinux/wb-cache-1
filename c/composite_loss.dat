13|90|Public
40|$|A <b>composite</b> <b>loss</b> assigns {{a penalty}} to a realvalued {{prediction}} by associating the prediction with a probability via a link function then applying a class probability estimation (CPE) loss. If {{the risk for}} a <b>composite</b> <b>loss</b> is always minimised by predicting the value associated with the true class probability the <b>composite</b> <b>loss</b> is proper. We provide a novel, explicit and complete characterisation of the convexity of any proper <b>composite</b> <b>loss</b> {{in terms of its}} link and its “weight function” associated with its proper CPE loss. ...|$|E
40|$|The damping {{characteristics}} of a viscoelastic sandwich plate, composed of a core layer of viscoelastic material and thin elastic outer layers, subjected to the inplane load are investigated. The dissipation of vibratory energy is assumed to take place due to the shear deformation of the viscoelastic layer, whose shear modulus is represented as a complex one, G* =G 1 (1 +iβ). An equation {{to be used in}} the calculation of <b>composite</b> <b>loss</b> factor of viscoelastic sandwich plate is obtained analytically. Experiments have been carried out with fixed ends sandwich plates subjected to the inplane compressive load. Good agreement has been found between the experimental and calculated values of <b>composite</b> <b>loss</b> factors of sandwich plates...|$|E
40|$|We {{consider}} <b>composite</b> <b>loss</b> {{functions for}} multiclass prediction comprising a proper (i. e., Fisherconsistent) loss over probability distributions and an inverse link function. We establish conditions for their (strong) convexity {{and explore the}} implications. We also show how the separation of concerns afforded by using this composite representation allows {{for the design of}} families of losses with the same Bayes risk. 1...|$|E
40|$|International audienceThe impulse {{response}} of a lossless resonant system, usually obtained using the finite-difference time-domain method, permits us {{to determine the}} resonant frequencies through the Fourier transform. However, the obtained spectrum has no physical meaning since the losses have not been implemented. Rather than modeling physically the losses, we propose to apply a specific time-domain window to the already simulated signal of the lossless system. This Losses window depends on a user-defined quality factor. The advantage of this postsimulation losses implementation is a capability of parametric study of <b>composite</b> <b>losses.</b> Losses of various physical origins are found for example {{in the case of}} reverberation chambers...|$|R
40|$|Relationships are {{identified}} between the thermo-oxidative stability (TOS) at 316 C {{of a wide}} variety of PMR (polymerization of monomeric reactants) addition cured polyimide resins and their corresponding graphite fiber <b>composites.</b> Weight <b>loss</b> results at 316 C confirmed the expected relationship of increasing aliphatic endcap content with decreasing TOS. Moreover, the resin TOS study also showed an unexpected linear correlation of decreasing weight loss to increasing ratio of benzylic diamine to aliphatic endcap in the range of the stoichiometries studied. Only after long term 316 C aging does the dianhydride used with the benzylic diamines become an additional factor in influencing the amount of PMR resin and <b>composite</b> weight <b>losses.</b> Also, the benzylic systems consistently showed much lower resin and <b>composite</b> weight <b>losses</b> at 316 C than the corresponding nonbenzylic norbornenyl resins and composites, except when the nonbenzylic diamine monomer does not contain a connecting group. Instead, this diamine resulted in a 316 C resin and <b>composite</b> weight <b>loss</b> that was only competitive with benzylic type diamines. Results show excellent correlation between TOS of all graphite fiber PMR composites and resins...|$|R
40|$|We present tight {{surrogate}} regret bounds for {{the class}} of proper (i. e., Fisher consistent) losses. The bounds generalise the margin-based bounds due to Bartlett et al. (2006). The proof uses Taylor’s theorem and leads to new representations for loss and regret and a simple proof of the integral representation of proper losses. We also present a different formulation of a duality result of Bregman divergences {{which leads to a}} simple demonstration of the convexity of <b>composite</b> <b>losses</b> using canonical link functions. 1...|$|R
40|$|A <b>composite</b> <b>loss</b> {{framework}} is proposed for low-rank modeling of data consisting of interesting and common values, such as excess zeros or missing values. The methodology {{is motivated by}} the generalized low-rank framework and the hurdle method which is commonly used to analyze zero-inflated counts. The model is demonstrated on a manufacturing data set and applied {{to the problem of}} missing value imputation. Comment: 14 pages, 2 figures, 2 table...|$|E
40|$|This {{research}} {{proposes a}} hierarchical aggregation approach using Data Envelopment Analysis (DEA) and Analytic Hierarchy Process (AHP) for indicators. The core {{logic of the}} proposed approach is to reflect the hierarchical structures of indicators and their relative priorities in constructing composite indicators (CIs), simultaneously. Under hierarchical structures, the indicators of similar characteristics can be grouped into sub-categories and further into categories. According to this approach, we define a domain of composite losses, i. e., a reduction in CI values, based on two sets of weights. The first set represents the weights of indicators for each Decision Making Unit (DMU) with the minimal <b>composite</b> <b>loss,</b> and the second set represents the weights of indicators bounded by AHP with the maximal <b>composite</b> <b>loss.</b> Using a parametric distance model, we explore various ranking positions for DMUs while the indicator weights obtained from a three-level DEA-based CI model shift towards the corresponding weights bounded by AHP. An illustrative example of road safety performance indicators (SPIs) {{for a set of}} European countries highlights the usefulness of the proposed approach...|$|E
40|$|The {{effects of}} space environments on damping {{materials}} and damping designs on flexible structures were investigated. The following items were examined: damping of flexible spacecraft appendages; <b>composite</b> <b>loss</b> factor (n sub s) vs. time in high vacuum for damped test beams and damping of flexible structures. The STEP experiments show inherent damping of flexible structures in space effective possible damping design configurations for space structures, effects of passively damped components {{on the system}} loss factor of flexible structures {{and the effect of}} space environment on properties of damping materials...|$|E
40|$|The {{purpose of}} this study was to {{identify}} any relationships between the thermo-oxidative stability (TOS) at 316 °C of a wide variety of PMR (polymer-ization of monomeric reactants) addition cured polyimide resins and their corresponding graphite fiber <b>composites.</b> Weight <b>loss</b> results at 316 *C confirmed the expected relationship of increasing aliphatic endcap content with decreasing TOS. More importantly, the resin TOS study also showed an unexpected linear correlation of decreasing weight loss to increasing ratio of benzylic diamine to aliphatic endcap in the range of the stoichiometries studied. Furthermore, only after long-term 316 C aging does the dianhydride used with the benzylic diamines become an additional factor in influencing the amount of PMR resin and <b>composite</b> weight <b>losses.</b> Additionally, the benzylic systems also consistently showed significantly lower resin and <b>composite</b> weight <b>losses</b> at 316 0 C than the corresponding nonbenzylic/norbornenyl resins and composites, except when the nonbenzylic diamine monomer does not contain...|$|R
40|$|The {{problem of}} bipartite ranking, where {{instances}} are labeled {{positive or negative}} and {{the goal is to}} learn a scoring function that minimizes the probability of mis-ranking a pair of positive and negative instances (or equivalently, that maximizes the area under the ROC curve), has been widely studied in recent years. A dominant theoretical and algorithmic framework for the problem has been to reduce bipartite ranking to pairwise classification; in particular, {{it is well known that}} the bipartite ranking regret can be formulated as a pairwise classification regret, which in turn can be upper bounded using usual regret bounds for classification problems. Recently, Kotlowski et al. (2011) showed regret bounds for bipartite ranking in terms of the regret associated with balanced versions of the standard (non-pairwise) logistic and exponential losses. In this paper, we show that such (non-pairwise) surrogate regret bounds for bipartite ranking can be obtained in terms of a broad class of proper (<b>composite)</b> <b>losses</b> that we term as strongly proper. Our proof technique is much simpler than that of Kotlowski et al. (2011), and relies on properties of proper (<b>composite)</b> <b>losses</b> as elucidated recently by Reid and Williamson (2010, 2011) and others. Our result yields explicit surrogate bounds (with no hidden balancing terms) in terms of a variety of strongly proper losses, including for example logistic, exponential, squared and squared hinge losses as special cases. An important consequence is that standard algorithms minimizing a (non-pairwise) strongly proper loss, such as logistic regression and boosting algorithms (assuming a universal function class and appropriate regularization), are in fact consistent for bipartite ranking; moreover, our results allow us to quantify the bipartite ranking regret in terms of the corresponding surrogate regret. We also obtain tighter surrogate bounds under certain low-noise conditions via a recent result of Clemencon and Robbiano (2011) ...|$|R
30|$|<b>Composite</b> tissue <b>loss</b> in {{extremities}} involving neurovascular structures {{has been}} a major challenge for reconstructive surgeons. Reconstruction of large defects can only be achieved with microsurgical procedures. The success of free flap operations depends on the presence of healthy recipient vessels. In cases with no suitable donor artery and vein or in which even the use of vein grafts would not be feasible, the lower limb can be salvaged with a cross-leg free flap procedure. We present a case with a large <b>composite</b> tissue <b>loss</b> that was reconstructed with cross-leg free transfer of a combined latissimus dorsi and serratus anterior muscle flap. This case indicates that this large muscle flap can survive with the cross-leg free flap method and this technique may be a viable alternative for large lower extremity defects that have no reliable recipient artery.|$|R
40|$|We {{consider}} {{the problem of}} binary class prob-ability estimation (CPE) when one class is rare compared to the other. It {{is well known that}} stan-dard algorithms such as logistic regression do not perform well in this setting as they tend to under-estimate the probability of the rare class. Com-mon fixes include under-sampling and weight-ing, together with various correction schemes. Recently, Wang & Dey (2010) suggested the use of a parametrized family of asymmetric link functions based on the generalized extreme value (GEV) distribution, which has been used for modeling rare events in statistics. The approach showed promising initial results, but combined with the logarithmic CPE loss implicitly used in their work, it results in a non-convex <b>composite</b> <b>loss</b> that is difficult to optimize. In this paper, we use tools from the theory of proper compos-ite losses (Buja et al., 2005; Reid & Williamson, 2010) to construct a canonical underlying CPE loss corresponding to the GEV link, which yields a convex proper <b>composite</b> <b>loss</b> that we call the GEV-canonical loss; this loss can be tailored to CPE settings where one class is rare, and is easily minimized using an IRLS-type algorithm similar to that used for logistic regression. Our experi-ments on both synthetic and real data suggest that the resulting algorithm – which we term GEV-canonical regression – performs well compared to common approaches such as under-sampling and weights-correction for this problem...|$|E
40|$|A {{model is}} {{developed}} {{to relate the}} energy loss factors of ultrasonic longitudinal waves propagating in the principal directions of a unidirectional graphite fiber composite to the composite constituent properties. All the constituents are assumed to behave as linear viscoelastic materials with energy dissipation properties defined by loss factors. It is found that by introducing a new constituent called the interface material, the composite and constituent properties can be brought into consistency with simple series and parallel models. An expression relating the <b>composite</b> <b>loss</b> factors to the loss factors of the constituents is derived and its coefficients are evaluated...|$|E
40|$|Hand, {{wrist and}} forearm {{injuries}} are common presentations {{to the emergency}} department. There is a huge variation of severity from small lacerations involving only skin to extensive upper limb <b>composite</b> <b>loss.</b> There is no minor injury in upper limb trauma. Even the most trivial of wounds {{may be associated with}} major tendon or nerve damage which, if missed, may have life-long functional implications for the patient. Although this review concentrates on soft tissue injury and not bony injury, {{it is not possible to}} separate the two completely. It is important to realise that all fractures have a soft tissue injury component that needs to be assessed and correctly treated. In some instances the soft tissue component is much more important than the fracture, and failure to recognise it will result in a poor outcome...|$|E
40|$|Online Convex Optimization plays a {{key role}} in large scale machine learning. Early {{approaches}} to this problem were conservative, in which the main focus was protection against the worst case scenario. But recently several algorithms have been developed for tightening the regret bounds in easy data instances such as sparsity, predictable sequences, and curved losses. In this work we unify some of these existing techniques to obtain new update rules for the cases when these easy instances occur together. First we analyse an adaptive and optimistic update rule which achieves tighter regret bound when the loss sequence is sparse and predictable. Then we explain an update rule that dynamically adapts to the curvature of the loss function and utilizes the predictable nature of the loss sequence as well. Finally we extend these results to <b>composite</b> <b>losses...</b>|$|R
40|$|<b>Composite</b> tissue <b>loss</b> in {{extremities}} involving neurovascular structures {{has been}} a major challenge for reconstructive surgeons. Reconstruction of large defects can only be achieved with microsurgical procedures. The success of free flap operations depends on the presence of healthy recipient vessels. In cases with no suitable donor artery and vein or in which even the use of vein grafts would not be feasible, the lower limb can be salvaged with a cross-leg free flap procedure. We present a case with a large <b>composite</b> tissue <b>loss</b> that was reconstructed with cross-leg free transfer of a combined latissimus dorsi and serratus anterior muscle flap. This case indicates that this large muscle flap can survive with the cross-leg free flap method and this technique may be a viable alternative for large lower extremity defects that have no reliable recipient artery...|$|R
40|$|Online {{learning}} algorithms are fast, memory-efficient, easy to implement, and {{applicable to}} many prediction problems, including classification, regression, and ranking. Several online algorithms were {{proposed in the}} past few decades, some based on additive updates, like the Perceptron, and some on multiplicative updates, like Winnow. A unified viewpoint on the design and the analysis of online algorithms is provided by online mirror descent, a general prediction strategy from which most first-order algorithms can be obtained as special cases. We generalize online mirror descent to sequences of time-varying regularizers with generic updates. Unlike standard mirror descent, our more general formulation also captures second order algorithms, algorithms for <b>composite</b> <b>losses,</b> and algorithms for adaptive filtering. Moreover, we recover, and some-times improve, known regret bounds by instantiating our analysis on specific regularizers. Finally, we show the power of our approach by deriving a new second order algorithm with a regret bound invariant with respect to arbitrary rescalings of individual features. ...|$|R
40|$|Structural Support Vector Machines (SSVMs) {{have become}} a popular tool in machine {{learning}} for predicting structured objects like parse trees, Part-of-Speech (POS) label sequences and image segments. Various efficient algorithmic techniques have been proposed for training SSVMs for large datasets. The typical SSVM formulation contains a regularizer term and a <b>composite</b> <b>loss</b> term. The loss term is usually composed of the Linear Maximum Error (LME) associated with the training examples. Other alternatives for the loss term are yet to be explored for SSVMs. We formulate a new SSVM with Linear Summed Error (LSE) loss term and propose efficient algorithms to train the new SSVM formulation using primal cutting-plane method and sequential dual coordinate descent method. Numerical experiments on benchmark datasets demonstrate that the sequential dual coordinate descent method is faster than the cutting-plane method and reaches the steady-state generalization performance faster. It is thus a useful alternative for training SSVMs when linear summed error is used...|$|E
40|$|We {{consider}} optimization of generalized performance metrics for binary classification {{by means}} of surrogate losses. We focus on a class of metrics, which are linear-fractional functions of the false positive and false negative rates (examples of which include F_β-measure, Jaccard similarity coefficient, AM measure, and many others). Our analysis concerns the following two-step procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification on the training sample. It is assumed that the surrogate loss is a strongly proper <b>composite</b> <b>loss</b> function (examples of which include logistic loss, squared-error loss, exponential loss, etc.). Then, given f, a threshold θ is tuned on a separate validation sample, by direct optimization of the target performance metric. We show that the regret of the resulting classifier (obtained from thresholding f on θ) measured {{with respect to the}} target metric is upperbounded by the regret of f measured with respect to the surrogate loss. We also extend our results to cover multilabel classification and provide regret bounds for micro- and macro-averaging measures. Our findings are further analyzed in a computational study on both synthetic and real data sets. Comment: 22 page...|$|E
40|$|We study {{losses for}} binary {{classification}} and class probability estimation {{and extend the}} understanding of them from margin losses to general composite losses which are the composition of a proper loss with a link function. We characterise when margin losses can be proper composite losses, explicitly show how to determine a symmetric loss in full from half {{of one of its}} partial losses, introduce an intrinsic parametrisation of composite binary losses and give a complete characterisation of the relationship between proper losses and ``classification calibrated'' losses. We also consider the question of the ``best'' surrogate binary loss. We introduce a precise notion of ``best'' and show there exist situations where two convex surrogate losses are incommensurable. We provide a complete explicit characterisation of the convexity of composite binary losses in terms of the link function and the weight function associated with the proper loss which make up the <b>composite</b> <b>loss.</b> This characterisation suggests new ways of ``surrogate tuning''. Finally, in an appendix we present some new algorithm-independent results on the relationship between properness, convexity and robustness to misclassification noise for binary losses and show that all convex proper losses are non-robust to misclassification noise. Comment: 38 pages, 4 figures. Submitted to JML...|$|E
40|$|International audienceThe use of glass/polyester {{composite}} materials in wind turbines is increasing {{due to their}} low cost and favorable mechanical properties. The existing knowledge about the fatigue characteristics of such composites leads to rather conservative designs which are over dimensioned and hence costly. The aim of this work {{is the development of}} an approach for the characterization of composites under cyclic loadings. An investigation is performed on the reduction of stiffness and the heat generated during the progression of damage. It is shown that even in the matrix mode failure the fatigue limit can be above the monotonic damage criterion, where the <b>composite</b> <b>losses</b> its rigidity either due to plasticity or matrix fiber separation. Thus showing that polyester resins are rather brittle in nature and brittle material fracture models can be used for modeling these composites in fatigue. However the role of fibers in initiation or arresting of the cracks is not presented in this study...|$|R
50|$|Dow Jones Industrial Average and Nasdaq <b>composite</b> trimmed <b>losses</b> by {{the close}} Tuesday after a tough session hurt by {{discouraging}} comments from Yahoo! and revived worries about the economy following a big drop in housing starts. Also pressuring markets: An apparent coup attempt in Thailand that led that country's prime minister to declare {{a state of emergency}} and prepare to abruptly leave a United Nations summit in New York. Thailand is an economic cornerstone of Southeast Asia.|$|R
40|$|Carbon/carbon (C/C) {{composites}} {{are one of}} {{the most}} important high temperature structure materials; Which are oxidized remarkably above 400 ¡䟩n oxidative atmosphere. In order to improve the oxidation resistance of C/C composites, suspension mixtures prepared by mixing B 4 C, SiC and Al 2 O 3 powders and phosphoric acid solution were used as precursors to modify the C/C composites by a novel hydrothermal treatment. The influences of the hydrothermal treatment temperature on the phase, microstructure and antiª²oxidation property of the as-modified composites were investigated. The asª²modified C/C composites were characterized by X-ray diffraction, scanning electron microscope (SEM), energy dispersive spectroscope (PDS) and X-ray photoelectron spectroscopy (XPS) techniques. Results show that the surface of the C/C composites is covered by a coating composed of molten B 2 O 3, HPO 3 and microcrystalline Al(PO 3) 3 after modified by the hydrothermal treatment, and their oxidation resistance is effectively improved in the temperature range from 120 ¡䟴o 200 ¡䬠The anti-oxidation property of the treated C/C composites is improved with increasing hydrothermal treatment temperature. The mass of the modified C/C <b>composites</b> <b>losses</b> only 2. 31 % after oxidized at 700 ¡䟩n air for 10 h. </FONT...|$|R
40|$|It {{has been}} found that the {{composites}} of carbon nanotubes (CNTs) and epoxy resin could greatly enhance damping ability while the stiffness is kept at a very high level. In this research, carbon nanotube enhanced epoxy resin is fabricated. The dynamic properties of the nanotube composites are evaluated. A testing apparatus for obtaining composite dynamic properties is set up and measurement procedures are given. Multiple groups of specimens are made for investigations. In particular, the loss factors together with dynamic stiffness are measured for the specimens with different CNT weight ratio. Experimental results show that CNT additive can provide the composite with several times higher damping as compared with pure epoxy. The composite is much stiffer than viscoelastic material (VEM) while the damping is comparable when strain is above certain level. In order to further study the damping mechanism of the CNT composite, models are developed. Composite unit cell models containing single CNT segments are built by using finite element method (FEM). Models with varying CNT orientations are considered in order to describe the behaviors of the randomly oriented CNTs inside the epoxy matrix. <b>Composite</b> <b>loss</b> factors are calculated based on the average ratio of the unit cell energy loss to the unit cell energy input. Calculated loss factors under different strain levels are compared to experimental results. With the validated model, parametric study is thereafter performed. Parameters such as CNT dimensions and CNT alignment orientation are studied. Those factors lead to higher composite damping capacity are identified. by Dai, Ruoli. "September 2007. "Adviser: Wei-Hsin Liao. Source: Dissertation Abstracts International, Volume: 69 - 08, Section: B, page: 4978. Thesis (Ph. D.) [...] Chinese University of Hong Kong, 2007. Includes bibliographical references (p. 93 - 97). Electronic reproduction. Hong Kong : Chinese University of Hong Kong, [2012] System requirements: Adobe Acrobat Reader. Available via World Wide Web. Electronic reproduction. [Ann Arbor, MI] : ProQuest Information and Learning, [200 -] System requirements: Adobe Acrobat Reader. Available via World Wide Web. Abstracts in English and Chinese. School code: 1307...|$|E
40|$|The {{use of an}} osteocutaneous free fibular graft as a {{single-stage}} reconstructive {{procedure for}} <b>composite</b> tissue <b>loss</b> is increasingly common. Detailed anatomical study in cadavers of the blood supply to the graft demonstrates cutaneous arteries arising from the peroneal artery and then passing along the posterior surface of the lateral intermuscular septum. These vessels pierce the crural fascia and then ramify to supply the skin. Knowledge of the vascular anatomy of the skin overlying the fibula {{is essential to the}} success of the graft...|$|R
40|$|A popular {{approach}} to solving multiclass learning problems {{is to reduce}} them {{to a set of}} binary classification problems through some output code matrix: the widely used one-vs-all and all-pairs methods, and the error-correcting output code methods of Dietterich and Bakiri (1995), can all be viewed as special cases of this approach. In this paper, we consider the question of statistical consis-tency of such methods. We focus on settings where the binary problems are solved by minimizing a binary surrogate loss, and derive general conditions on the binary surrogate loss under which the one-vs-all and all-pairs code matrices yield consistent algorithms with respect to the multiclass 0 - 1 loss. We then consider general multiclass learning problems defined by a general multiclass loss, and derive conditions on the output code matrix and binary surrogates under which the resulting algorithm is consistent with respect to the target multiclass loss. We also consider probabilistic code matrices, where one reduces a multiclass problem to a set of class probability labeled binary problems, and show that these can yield benefits in the sense of requiring a smaller number of bi-nary problems to achieve overall consistency. Our analysis makes interesting connections with the theory of proper <b>composite</b> <b>losses</b> (Buja et al., 2005; Reid and Williamson, 2010); these play a rol...|$|R
30|$|<b>Composite</b> tissue <b>loss</b> in {{extremities}} involving neurovascular structures {{has been}} a major challenge for reconstructive surgeons. Principles of reconstruction cascade dictate first using local and regional tissues. However, local and regional flaps may not be suitable for larger defects, and adequate fresh tissue can only be obtained with microsurgical procedures. The success of free flap operations depends on the presence of healthy recipient vessels. In cases with no suitable recipient artery and vein or in those where even the use of vein grafts would not be feasible, the lower limb could be salvaged through a cross-leg free flap procedure [1].|$|R
40|$|The {{effect of}} the {{stability}} of graphite fibers on composite properties after exposure in air at 600 F was investigated. Composites were fabricated from PMR- 15 and PMR- 2 monomer solutions, using HTS- 2 and Celion 6000 graphite fibers as the reinforcement. The effect of long-term exposure in air at 600 F on <b>composite</b> weight <b>loss</b> and mechanical properties was determined. These composites exhibited a significantly increased lifetime at that temperature compared to composites fabricated from HTS fiber sold prior to 1975. The {{effect of the}} PMR- 15 and PMR-II resin compositions on long-term composite performance at 600 F is also discussed...|$|R
40|$|Studies are {{performed}} {{to investigate the}} effect of substituting 4, 4 '-oxydianiline and 1, 1 -bis(4 -aminophenyl) - 1 -phenyl- 2, 2, 2 -trifluoroethane for the 4, 4 '-methylenedianiline in PMR polyimide matrix resin. Graphite fiber reinforced composites are fabricated from unsized Celion 6000 and PMR-polyimide matrix resins having formulated molecular weights {{in the range of}} 1500 to 2400. The composite processing characteristics are investigated and the initial room temperature and 316 C (600 F) composite mechanical properties are determined. Comparative 316 C <b>composite</b> weight <b>losses</b> and 316 C mechanical properties retention after prolonged 316 C air exposure are also determined...|$|R
40|$|Studies were {{performed}} to investigate {{the effect of the}} stability of graphite fibers on composite properties after exposure in air at 600 F. Composites were fabricated from PMR- 15 and PMR-II monomer solutions, using HTS- 2 and Celion 6000 graphite fibers as the reinforcement. The effect of long-term exposure in air at 600 F on <b>composite</b> weight <b>loss</b> and mechanical properties was determined. These composites exhibited a significantly increased lifetime at 600 F compared to composites fabricated from HTS fiber sold prior to 1975. The effect of the PMR- 15 and PMR-II resin compositions on long-term composite performance at 600 F is also discussed...|$|R
40|$|A {{mutilated}} foot as {{a result}} of traumas or resection for tumours or ulcers, is a serious physical and social handicap for the patient, because it impairs deambulation and affects his selfgovernment. The evolution of microsurgical techniques has allowed us to utilize such methods to reconstruct wide simple and <b>composite</b> <b>losses</b> of substance of the foot, usually treated conservatively or radically with amputation and prosthesization. Functional, cosmetic and social outcome has been evaluated. We evaluated 23 patients affected by cutaneous (19) and osteocutaneous (4) losses of substance of the foot (11 of rearfoot, 5 of forefoot, 4 of the sole, 1 of middlefoot, 1 of the dorsum, and 1 of the malleolus). We performed 23 microsurgical reconstructions harvesting 24 free flaps (14 radial flaps, 4 latissimus dorsi, 3 fibula, 1 scapular flap, 1 lateral arm, 1 iliac crest). Cutaneous and muscular flaps healed in 3 weeks, while osteocutaneous flaps healed in 10 to 12 weeks. Deambulation was restored in all patients but 1, within 6 months from surgery, and all patients went back to their work and social life. We observed in the early follow-up 2 cases of partial skin necrosis, which solved spontaneously and 1 case of total necrosis (overall complication = 4. 3 %). Donor area morbidity was rated as fair. Overall success rate was 95. 7 % at a mean follow-up of 3 years. Free microsurgical transfers allowed us to obtain a satisfactory and long-lasting morpho-functional restoration of wide superficial and deep losses of substance of the foot, guaranteeing the patient a fast psycho-physical and social rehabilitation...|$|R
40|$|Preservation of {{the finger}} pulp is {{important}} as <b>composite</b> tissue <b>loss</b> can potentially result in severe hand disability. However, reconstruction of finger pulp defects {{can be difficult}} for hand and reconstructive surgeons because few donor sites provide similar tissue. The ideal reconstruction provides both the good esthetic results and restored function. Existing resurfacing techniques include skin grafting, local flaps, island flaps, cross flaps, and free flaps; however, no single technique perfectly treats {{the wide variety of}} finger pulp defects. Many factors, such as patient preference, host conditions, health care system considerations, and surgical expertise, must be considered when selecting the optimal technique. Reconstruction of finger pulp defects with a great toe pulp flap (hemipulp) was first reported by Buncke and Rose. 1 Wit...|$|R
40|$|The {{variation}} of {{ultimate tensile strength}} with thermal treatment of B-Al composite materials and of boron fibers chemically removed from these composites {{in an attempt to}} determine the mechanism of the resulting strength degradation was studied. Findings indicate that thermally cycling B-Al represents a more severe condition than equivalent time at temperature. Degradation of composite tensile strength from about 1. 3 GN/m squared to as low as 0. 34 GN/m squared was observed after 3, 000 cycles to 420 C for 203 micrometers B- 1100 Al composite. In general, the 1100 Al matrix composites degraded somewhat more than the 6061 matrix material studied. Measurement of fiber strengths confirmed a <b>composite</b> strength <b>loss</b> due to the degradation of fiber strength. Microscopy indicated a highly flawed fiber surface...|$|R
40|$|Objectives: Long-term in-vivo {{posterior}} study. 6 and 12 months interim wear observation (3 D-Pro Laserscanning, SEM, USPHS scoring) of a nanotechnology composite-resin, Filtek-Supreme (3 M-ESPE) and a monomodal compact filled composite-resin, Z 100 (3 M-ESPE) versus human enamel. Methods: 18 Filtek-Supreme and 18 Z 100 restorations {{placed in}} upper or lower molars (split mouth model). BA: Single bond Adhesive (3 M-ESPE). Baseline, 6 m & 12 m replicas made in gypsum for 3 D-Pro laserscanning (Willytec, Munich), to measure <b>composite</b> volumetric <b>loss,</b> <b>composite</b> and enamel vertical loss at occlusal contact areas (OCA). Araldite epoxy replicas {{were used for}} SEM analysis (Philips, XL 20). At recall assessment was done using USPHS evaluation criteria for posterior restorations. After one year of clinical service the polish of Z 100 was significantly (p= 0. 0313) worse than Filtek-Supreme. For marginal adaptation 21 % of the Z 100 restorations and 22 % of the Filtek-Supreme restoration were scored "Bravo". SEM confirmed the 3 D-Laserscan and USPHS findings. Conclusions: The clinical wear performance of Filtek-Supreme and Z 100 after 12 months {{is comparable to the}} one of human enamel. The nanofilled composite can be considered as an acceptable universal and posterior restorative material. 3 and 5 years follow-up will show if the material is also fatigue resistant. The conditioning step and the bonding agent seem to {{play a crucial role in}} the maintenance of the marginal integrity. status: accepte...|$|R
40|$|The {{amounts of}} resin {{weight loss and}} fiber weight loss in four PMR-polyimide {{graphite}} fiber composites were calculated from the <b>composite</b> weight <b>losses</b> and the fiber/resin ratios of the composites after long term thermo-oxidative aging in 600 F air. The accelerating effect of graphite fiber on resin weight loss, compared to neat resin weight loss, indicated {{the presence of a}} deleterious resin/fiber thermo-oxidative interaction, presumably due to fiber impurities. Similarly, the decelerating effect of the protective matrix resin on fiber weight loss, compared to bare fiber weight loss, was also demonstrated. The amount of hydrazine-indigestible resin and the amount of loose surface graphite fiber that formed during 600 deg F exposure of the composites were quantitatively determined. The indigestible residual resin was also qualitatively studied by scanning electron microscopy...|$|R
