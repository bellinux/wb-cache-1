45|108|Public
25|$|This arises {{because the}} {{sampling}} {{distribution of the}} sample standard deviation follows a (scaled) <b>chi</b> <b>distribution,</b> and the correction factor is {{the mean of the}} <b>chi</b> <b>distribution.</b>|$|E
25|$|The {{absolute}} value of normalized residuals, |X - μ|/σ, has <b>chi</b> <b>distribution</b> with one degree of freedom: |X - μ|/σ ~ χ1(|X - μ|/σ).|$|E
2500|$|The <b>chi</b> <b>distribution</b> with vnbsp&=nbsp&2 is {{equivalent}} to the Rayleigh Distribution withnbsp&sigma&nbsp&=nbsp&1. [...] I.e., if , then [...] has a chi-squared distribution with parameter , degrees of freedom, equal to two (Nnbsp&=nbsp&2) ...|$|E
40|$|The {{quantiles}} of {{the central}} and non-central <b>chi</b> squared <b>distributions</b> cannot be expressed as explicit functions of the non-centrality parameter. We give in this paper an approximation of these quantiles {{in terms of the}} non-centrality parameter; this approximation is surprisingly good for the median. Quantile approximation <b>chi</b> squared <b>distribution</b> non-centrality parameter...|$|R
5000|$|Scaled inverse <b>chi</b> square <b>{{distribution}}</b> is {{a special}} case of type 5 Pearson distribution ...|$|R
5000|$|Let X be a normal(0,1) distribution, Y and Z be a <b>chi</b> square <b>distributions</b> with m and n {{degrees of}} freedom respectively. Then ...|$|R
5000|$|... <b>chi</b> <b>distribution</b> is {{a special}} case of the {{generalized}} gamma distribution or the Nakagami distribution or the noncentral <b>chi</b> <b>distribution</b> ...|$|E
5000|$|... is {{distributed}} {{according to the}} <b>chi</b> <b>distribution.</b> Accordingly, dividing by {{the mean of the}} <b>chi</b> <b>distribution</b> (scaled by the square root of n &minus; 1) yields the correction factor in the unbiased estimation of the standard deviation of the normal distribution. The <b>chi</b> <b>distribution</b> has one parameter: [...] which specifies the number of degrees of freedom (i.e. the number of [...] ).|$|E
5000|$|In {{probability}} theory and statistics, the noncentral <b>chi</b> <b>distribution</b> is a generalization of the <b>chi</b> <b>distribution.</b> If [...] are k independent, normally distributed random variables with means [...] and variances , then the statistic ...|$|E
5000|$|... {{which is}} known to have an {{asymptotic}} <b>chi</b> squared <b>distribution</b> with n − 1 degrees of freedom when the population is Poisson distributed.|$|R
5000|$|... {{has to be}} {{compared}} to critical values from a weighted sum of <b>chi</b> squared <b>distributions.</b> This can be approximated by a gamma distribution: ...|$|R
5000|$|Consider the k samples [...] to {{represent}} a single point in a k-dimensional space. The <b>chi</b> square <b>distribution</b> for k degrees of freedom will then be given by: ...|$|R
5000|$|If [...] is chi distributed: [...] then [...] is also non-central chi distributed: [...] In other words, the <b>chi</b> <b>distribution</b> is {{a special}} case of the non-central <b>chi</b> <b>distribution</b> (i.e., with a non-centrality {{parameter}} of zero).|$|E
50|$|The <b>chi</b> <b>distribution.</b>|$|E
5000|$|... is {{distributed}} {{according to the}} noncentral <b>chi</b> <b>distribution.</b> The noncentral <b>chi</b> <b>distribution</b> has two parameters: [...] which specifies the number of degrees of freedom (i.e. the number of [...] ), and [...] which {{is related to the}} mean of the random variables [...] by: ...|$|E
30|$|Took {{the value}} of the Chi square (X 2) at degrees of freedom =  1 at the desired {{confidence}} interval of 0.10 which when looked up at the <b>Chi</b> square <b>distribution</b> table yields 2.71.|$|R
30|$|We can deduce the {{corresponding}} {{distribution of the}} lead time demand X when the demand follows many continuous distributions. Consider X follows the normal distribution, the exponential <b>distribution</b> and the <b>Chi</b> square <b>distribution.</b>|$|R
50|$|It is not {{consistent}} for the sample median. In {{the case of a}} unimodal variate the ratio of the jackknife variance to the sample variance tends to be distributed as one half the square of a <b>chi</b> square <b>distribution</b> with two degrees of freedom.|$|R
5000|$|... the <b>chi</b> <b>distribution</b> in {{statistics}} ( [...] is {{the more}} frequently encountered chi-squared distribution) ...|$|E
5000|$|In {{probability}} theory and statistics, the <b>chi</b> <b>distribution</b> is a continuous probability distribution. It is {{the distribution of}} the square root of the sum of squares of independent random variables having a standard normal distribution, or equivalently, {{the distribution of the}} Euclidean distance of the random variables from the origin. The most familiar examples are the Rayleigh distribution with <b>chi</b> <b>distribution</b> with 2 degrees of freedom, and the Maxwell distribution of (normalized) molecular speeds which is a <b>chi</b> <b>distribution</b> with 3 degrees of freedom (one for each spatial coordinate). If [...] are k independent, normally distributed random variables with means [...] and standard deviations , then the statistic ...|$|E
5000|$|Let , be {{a set of}} n {{independent}} and identically distributed bivariate normal random vectors with marginal distributions , correlation , and mean vector and covariance matrixwith [...] positive definite. DefineThen the joint distribution of U, V is central or noncentral bivariate <b>chi</b> <b>distribution</b> with n degrees of freedom.If either or both [...] or [...] the distribution is a noncentral bivariate <b>chi</b> <b>distribution.</b>|$|E
30|$|With the <b>Chi</b> square <b>distribution</b> as the {{limiting}} distribution, it is shown that 2 NΔH is Chi square distributed. Hence, the Chi square statistic may {{be applied to}} assess if the fitted parametric distribution {{is close to the}} POME-based distribution (i.e., the reference distribution of random variable).|$|R
5000|$|When {{the random}} {{variable}} is normally distributed, a minor correction exists {{to eliminate the}} bias. To derive the correction, note that for normally distributed X, Cochran's theorem implies that the square of [...] has a <b>chi</b> square <b>distribution</b> with n − 1 degrees of freedom. Consequently, ...|$|R
40|$|National Natural Science Foundation of China [11171230, 11231010]For {{complete}} {{observation and}} p-dimensional parameter theta defined by an estimation equation, empirical likelihood method of construction of confidence region {{is based on}} the asymptotic <b>chi</b> (p) (2) <b>distribution</b> of - 2 log(EL ratio). For right censored lifetime data with covariables, however, it is shown in literature that - 2 log(EL ratio) converges weakly to a scaled <b>chi</b> (p) (2) <b>distribution,</b> where the scale parameter is a function of unknown asymptotic covariance matrix. The construction of confidence region requires estimation of this scale parameter. In this paper, by using influence functions in the estimating equation, we show that - 2 log(EL ratio) converges weakly to a standard <b>chi</b> (p) (2) <b>distribution</b> and hence eliminates the procedure of estimating the scale parameter...|$|R
50|$|The Euclidean norm of {{a multivariate}} {{normally}} distributed random vector follows a noncentral <b>chi</b> <b>distribution.</b>|$|E
5000|$|The pdf of the noncentral <b>chi</b> <b>distribution</b> is a {{solution}} to the following differential equation: ...|$|E
5000|$|A noncentral <b>chi</b> <b>distribution</b> with 2 {{degrees of}} freedom is {{equivalent}} to a Rice distribution with [...]|$|E
40|$|For testing {{goodness}} of fit it is very popular to use either the chi square statistic or G statistics (information divergence). Asymptotically both are chi square distributed so an obvious question is {{which of the two}} statistics that has a distribution that is closest to the <b>chi</b> square <b>distribution.</b> Surprisingly, when there is only one degree of freedom it seems like the distribution of information divergence is much better approximated by a <b>chi</b> square <b>distribution</b> than the <b>chi</b> square statistic. For random variables we introduce a new transformation that transform several important distributions into new random variables that are almost Gaussian. For the binomial distributions and the Poisson distributions we formulate a general conjecture about how close their transform are to the Gaussian. The conjecture is proved for Poisson distributions. Comment: 5 pages, accepted for presentation at ISIT 201...|$|R
40|$|A {{variable}} X follows <b>chi</b> square <b>distribution</b> {{and another}} variable Y follows gamma distribution, then Z = f(x,y) follows chi square mixture of gamma distribution. In this study, Chi-square mixture of Gamma distribution {{has been defined}} and determines mean, variance, skewness and kurtosis of the distribution. This distribution is always positively skewed and leptokurtic for any value of the parameters...|$|R
40|$|In this paper, {{we apply}} {{empirical}} likelihood method to inference for the regression parameters in the partial functional linear regression models based on B spline. We {{prove that the}} empirical log likelihood ratio for the regression parameters converges in law to a weighted sum of independent <b>chi</b> square <b>distributions</b> and run simulations to assess the finite sample performance of our method...|$|R
5000|$|... (The 2-norm of [...] {{standard}} normally distributed variables is a <b>chi</b> <b>distribution</b> with [...] {{degrees of}} freedom) ...|$|E
5000|$|If [...] then [...] has a noncentral <b>chi</b> <b>distribution</b> {{with two}} {{degrees of freedom}} and noncentrality {{parameter}} [...]|$|E
5000|$|<b>Chi</b> <b>distribution,</b> the pdf of the 2-norm (or Euclidean norm) of {{a multivariate}} {{normally}} distributed vector (centered at zero).|$|E
40|$|In {{this paper}} limit theorems for closed queuing {{networks}} with excess of servers are formulated and proved. First theorem is {{a variant of}} the central limit theorem and is proved using classical results of V. I. Romanovskiy for discrete Markov chains. Second theorem considers a convergence to <b>chi</b> square <b>distribution.</b> These theorems are mainly based on an assumption of servers excess in queuing nodes...|$|R
5000|$|... where [...] is the [...] {{percentile}} of the <b>chi</b> squared <b>distribution</b> with v {{degrees of}} freedom, n {{is the number}} of observations of inter-arrival times in the sample, and x-bar is the sample average. A simple approximation to the exact interval endpoints can be derived using a normal approximation to the [...] distribution. This approximation gives the following values for a 95% confidence interval: ...|$|R
3000|$|Chi-square test of {{independence}} {{is one of}} the statistical measures that tests the linear and non-linear association between variables. This test helps to determine whether variables are independent of each other or whether there is pattern of dependency between variables. Formally, chi square test {{of independence}} determine whether the observed pattern between the variables is strong enough to show that the two variables are dependent on each other, or by considering all possible combinations of variables events and testing for the independence of each pair of these events. If the probability of occurrence of the different possible values of one variable depend on which category of another variable occurs, then the two variables are dependent on each other. Chi-square variable have a continuous distribution obtained by the sum of the squares of a set of normally distributed variables. Chi-square distribution is a rightly skewed distribution with lower limit at 0 and declines as χ ^ 2 increases to the right with most of values {{near the center of the}} distribution. Since, theoretical <b>distribution</b> of <b>chi</b> square <b>distribution</b> is a continuous <b>distribution,</b> and the <b>chi</b> square statistic have discrete <b>distribution,</b> <b>chi</b> square statistic is approximated by the theoretical <b>chi</b> square <b>distribution</b> for reasonably large sample size or for expected number of cases exceed 5 in most cells of the cross classification table. The wildly used rule on expected cases are less than 1 and no more than 20 [...]...|$|R
