2|17|Public
50|$|The PROSITE {{notation}} {{uses the}} IUPAC one-letter codes and {{conforms to the}} above description with the exception that a <b>concatenation</b> <b>symbol,</b> '', is used between pattern elements, but it is often dropped between letters of the pattern alphabet.|$|E
5000|$|C# handles brace {{notation}} differently. A string is {{a primitive}} type that returns a char when encountered with brace notation:String var = [...] "Hello World";char h = var0;char e = var1;String hehe = h.ToString (...) + e.ToString (...) //string [...] "he"hehe += hehe; //string [...] "hehe"To change the char type to a string in C#, use the method ToString (...) [...] This allows joining individual characters {{with the addition}} symbol + which acts as a <b>concatenation</b> <b>symbol</b> when dealing with strings.|$|E
5000|$|Quasi-quotation is {{introduced}} as shorthand {{to capture the}} fact that what the formula expresses isnt precisely quotation, but instead something about the <b>concatenation</b> of <b>symbols.</b> Our replacement for rule 2 using quasi-quotation looks like this: ...|$|R
40|$|AbstractIn this {{tutorial}} paper, {{we consider}} various classes of automata generated by simple rewrite transition systems. These classes {{are defined by}} two natural hierarchies, one given by interpreting <b>concatenation</b> of <b>symbols</b> in the rewrite system as sequential composition, and the other by interpreting concatenation as parallel composition. In this way we provide natural definitions for commutative (parallel) context-free automata, multiset (parallel, or random access, push-down) automata, and Petri nets...|$|R
40|$|Deterministic regular {{expressions}} {{are widely}} used in XML processing. For instance, all regular expressions in DTDs and XML Schemas are required to be deterministic. In this paper we show that determinism of a regular expression e can be tested in linear time. The best known algorithms, based on the Glushkov automaton, require O(σ|e|) time, where σ {{is the number of}} distinct symbols in e. We further show that matching a word w against an expression e can be achieved in combined linear time O(|e | + |w|), {{for a wide range of}} deterministic regular expressions: (i) star-free (for multiple input words), (ii) bounded-occurrence, i. e., expressions in which each symbol appears a bounded number of times, and (iii) bounded plus-depth, i. e., expressions in which the nesting depth of alternating plus (union) and <b>concatenation</b> <b>symbols</b> is bounded. Our algorithms use a new structural decomposition of the parse tree of e. For matching arbitrary deterministic regular expressions we present an O(|e | + |w | log log |e|) time algorithm...|$|R
40|$|Relation grammars are {{introduced}} {{as a powerful}} formalism for specifying the syntax of visual languages and, more generally, of multi-dimensional languages. Textual languages use only the implicit relation of sequential <b>concatenation</b> of <b>symbols.</b> The proposed extension relax this limitation and allows the introduction of any number of relations. By analogy with textual grammars, relation grammars {{make it easier to}} recognize the purpose of the lexical analysis phase and that of the syntactic one for parsing multi-dimensional structures...|$|R
5000|$|In Joy, {{the meaning}} {{function}} is a homomorphism from the syntactic monoid onto the semantic monoid. That is, the syntactic relation of <b>concatenation</b> of <b>symbols</b> maps {{directly onto the}} semantic relation of composition of functions. It is a homomorphism rather than an isomorphism, because it is onto but not one-to-one; that is, no symbol {{has more than one}} meaning, but some sequences of symbols have the same meaning (e.g. [...] "dup +" [...] and [...] "2 *").|$|R
40|$|AbstractIn this paper, we {{consider}} various classes of (infinite-state) automata generated by simple rewrite transition systems. These classes {{are defined by}} two natural hierarchies, one given by interpreting <b>concatenation</b> of <b>symbols</b> in the rewrite system as sequential composition, and the other by interpreting concatenation as parallel composition. In this way, we provide natural definitions for commutative (parallel) context-free automata, multiset (parallel, or random access, pushdown) automata, and Petri nets. We provide example automata which demonstrate the strictness of this hierarchy. In particular, we provide a proof of an earlier conjecture by Moller: that multiset automata form a proper subset of Petri nets. This result contrasts with the result of Caucal for the analogous question in the sequential case where the hierarchy collapses...|$|R
40|$|Relation grammars are {{introduced}} {{as a possible}} general framework for specifying the syntax of visual languages and,more in general, of multi-dimensional languages. Relation grammars are an extension of traditional textual languages. Textual languages use relations like "on the left" which are implicitly expressed by the sequential <b>concatenation</b> of terminal <b>symbols</b> in a sentence. The proposed extension releases such limitation and allows the introduction of any number of relations. By their analogy with textual grammars, relation grammars make easier to recognize {{the purpose of the}} lexical analysis phase and that of the syntactic one for parsing multidimensional structures...|$|R
40|$|Concatenation is the {{adjoining}} (juxtaposition) of two patterns {{to form a}} larger one. There are two forms of pattern concatenation: horizontal, in which patterns are adjoined at their vertical edges, and horizontal, in which patterns are adjoined at their horizontal edges. We’ll indicate horizontal and vertical <b>concatenation</b> by the <b>symbols</b> and, respectively. In order for concatenation to be possible, {{the adjoining}} edges must be of the same length [1]: for the horizontal concatenation of patterns P and Q, η(P) = η(Q) for the vertical concatenation of patterns P and Q, ω(P) = ω(Q) Figures 1 and 2 show examples of horizontal and vertical concatenation. P...|$|R
40|$|Background: The {{language}} faculty {{is probably}} the most distinctive feature of our species, and endows us with a unique ability to exchange highly structured information. In written language, information is encoded by the <b>concatenation</b> of basic <b>symbols</b> under grammatical and semantic constraints. As is also the case in other natural information carriers, the resulting symbolic sequences show a delicate balance between order and disorder. That balance is determined by the interplay between the diversity of symbols and by their specific ordering in the sequences. Here we used entropy to quantify the contribution of different organizational levels to the overall statistical structure of language. Methodology/Principal Findings: We computed a relative entropy measure to quantify the degree of ordering in word sequences from languages belonging to several linguistic families. While a direct estimation of the overall entropy of language yielded values that varied for the different families considered, the relative entropy quantifying word ordering presented an almost constant value for all those families. Conclusions/Significance: Our results indicate that despite the differences in the structure and vocabulary of the language...|$|R
40|$|The {{language}} faculty {{is probably}} the most distinctive feature of our species, and endows us with a unique ability to exchange highly structured information. In written language, information is encoded by the <b>concatenation</b> of basic <b>symbols</b> under grammatical and semantic constraints. As is also the case in other natural information carriers, the resulting symbolic sequences show a delicate balance between order and disorder. That balance is determined by the interplay between the diversity of symbols and by their specific ordering in the sequences. Here we used entropy to quantify the contribution of different organizational levels to the overall statistical structure of language. We computed a relative entropy measure to quantify the degree of ordering in word sequences from languages belonging to several linguistic families. While a direct estimation of the overall entropy of language yielded values that varied for the different families considered, the relative entropy quantifying word ordering presented an almost constant value for all those families. Our results indicate that despite the differences in the structure and vocabulary of the languages analyzed, the impact of word ordering in the structure of language is a statistical linguistic universal...|$|R
40|$|We prove a theorem {{stating that}} any {{semantics}} can be encoded as a compositional semantics, which means that, essentially, the standard definition of compositionality is formally vacuous, ” says Zadrozny (1994 : 329). We disagree. Consider the following very simple language L, {{that consists of}} only five strings. It is generated by a grammar with only three symbols (A, B, C) in its alphabet and one syntactic operation (concatenation). 1 We explicitly indicate this syntactic <b>concatenation</b> by the <b>symbol</b> •. The language L consists of just the strings A, B, C, C•A, C•B. The semantics for L is given by a meaning function, m. We will not bother to state specifically what the meanings are for the various expressions of L, but will just say what are the conditions on the meaning which determine that the semantics is non-compositional: Each of the five strings in the language has a meaning; furthermore (1) a. m(A) = m(B) b. m(C•A) ≠ m(C•B) Even though we have not said what the meanings of the various expressions of L are, we have required that any such specific semantics must be non-compositional because the meaning of C•...|$|R
40|$|Streaming string {{transducers}} [1] define (partial) functions from input strings {{to output}} strings. A streaming string transducer makes a single {{pass through the}} input string and uses a finite set of variables that range over strings from the output alphabet. At every step, the transducer processes an input symbol, and updates all the variables in parallel using assignments whose right-hand-sides are <b>concatenations</b> of output <b>symbols</b> and variables with the restriction that a variable can be used at most once in a right-hand-side expression. It {{has been shown that}} streaming string transducers operating on strings over infinite data domains are of interest in algorithmic verification of list-processing programs, as they lead to Pspace decision procedures for checking pre/post conditions and for checking semantic equivalence, for a well-defined class of heap-manipulating programs. In order to understand the theoretical expressiveness of streaming transducers, we focus on streaming transducers processing strings over finite alphabets, given the existence of a robust and well-studied class of “regular ” transductions for this case. Such regular transductions can be defined either by two-way deterministic finite-state transducers, or using a logical MSO-based characterization. Our main result is that the expressiveness of streaming string transducers coincides exactly with this class of regular transductions. ...|$|R
40|$|Abstract. Pattern {{discovery}} {{is used for}} determining, in a blind way, subsequences characterizing a given sequence or set of sequences. It is ap-plied in genome and proteome analysis for discovering interesting biose-quences which are usually very short {{when compared to the}} length of the analyzed sequence. Abstraction of subsequences, that is grouping similar subsequences and representing them in a compact way as patterns, seems particularly useful in the field of pattern discovery in order to stress sim-ilarities among interesting subsequences. In this paper we propose a set of techniques for pattern discovery which makes use of abstraction. We define a data structure, the k-trie, which is an enriched and truncated suffix trie, for collecting and counting subsequences of length at most k. We propose an on-line algorithm for building a k-trie in linear time. We associate the chi-square score to the subsequences represented in the tree in order to estimate their ”interest”. By analyzing the properties of the score w. r. t. <b>symbol</b> <b>concatenation</b> and string abstraction, we derive a method for collecting the most interesting subsequences in an automatic way. Besides, we abstract a set of subsequences of the same length into a set of rigid patterns. Such abstraction may be represented by a tree corresponding to the prefix automaton associated to the set of patterns. We propose to use such trees for concisely representing the most inter-esting subsequences, for searching patterns and for comparing biological sequences...|$|R
40|$|We are {{questioning}} the classical metrical {{approach of the}} rhythmic phenomena incounting-out and nursery rhymes. According to the generative metrical model, aphonological structure is constructed by <b>concatenation</b> of <b>symbols</b> on a deepphonological level. Further rules driven transformations apply till the surfacingphonetics output. The problem appears {{when we consider the}} relationship betweenmetrics and verses. In this model the rhythmical alignment is strict and adisplacement of the rhythm relative to the textual structure (the verse) is not possible- prosodic and textual frontiers (rhymes and assonance) are coinciding. The classical approach will consider strong and weak metrical positions as functionally equivalents. Conflicts are resolved by adding empty positions or extra-metrical, not surfacing beats, which is a very questionable way to patch the theory when it fails to account of the data in a natural way. In addition it complicates thelearnability of the structures from the surface data. A good example for the problems inherent in the classical approach are the 3 beats counting-out rhymes, like in the French Am stram gram or the Italian An gbin go. Onthe underlying level they are represented as a malformed 4 -beat structure. There is another approach derived from the musical practice. Consider a conductorof an orchestra, counting the beats. He will count only the strong positions: X X X X,but never Xo Xo Xo Xo. Thatʼs because in musical representation weak and strongbeats are not doing sense without the whole rhythm. The cognitive status of therhythm is different here. It is not dependent of the symbols (or constituents), and thelevel of representation is the one of an autonomous rhythmical curve, a kind of waveor oscillator. According to the dynamic account proposed by Goldsmith and Larson (1992), thenLaks (1997) the rhythm level is autonomous and is the product of such phenomenalike direction, limits and impulsion resolution. Simple connectionist-like networks areused to model the rhythmical curve. Dynamic Computational Nets (DCN), are alsoused for modeling the syllable and the stress domain as they provide a natural andlearnable alternative to the constituents based metrics. We are presenting the first results of a DCN network model of the metrics ofcounting-out rhymes in French, Italian, Russian and Bulgarian. Emphasis is put onthe learning of the network parameters (leftward, rightward connections, initial and final activation/inhibition) for different rhythmic types...|$|R
40|$|We {{initiate}} a complexity theoretic {{study of the}} language based graph reachability problem (L-REACH) : Fix a language L. Given a graph whose edges are labeled with alphabet symbols of the language L and two special vertices s and t, test if there is path P from s to t in the graph such that the <b>concatenation</b> of the <b>symbols</b> seen from s to t in the path P forms a string in the language L. We study variants of this problem with different graph classes and different language classes and obtain complexity theoretic characterizations for all of them. Our main results are the following: 1. Restricting the language using formal language theory we show that the complexity of L-REACH increases {{with the power of}} the formal language class. We show that there is a regular language for which the L-REACH is NL-complete even for undirected graphs. In the case of linear languages, the complexity of L-REACH does not go beyond the complexity of L itself. Further, there is a deterministic context-free language L for which L-DAGREACH is LogCFL-complete. 2. We use L-REACH as a lens to study structural complexity. In this direction we show that there is a language A in TC 0 for which A-DAGREACH is NP-complete. Using this we show that P vs NP question is equivalent to P vs DAGREACH- 1 (P) question. This leads to the intriguing possibility that by proving DAGREACH- 1 (P) is contained in some subclass of P, we can prove an upward translation of separation of complexity classes. Note that we do not know a way to upward translate the separation of complexity classes. Comment: 14 pages, 4 figures, Published in Fundamenta Informatica...|$|R
40|$|C be the {{corresponding}} Huffman code that has 26 codewords {c 1, c 2, [...] ., c 26 } with average codeword length 4. 15573. The respective lengths of the codewords are given by {` 1, ` 2, [...] ., ` 26 }. According to P, a <b>concatenation</b> of 1000 <b>symbols</b> randomly generated from A is Huffman encoded into a bitstream x of length M and x is further encoded into a bitstream y of length N by a binary (2, 1, 6) convolutional code with octal generator sequence 554 and 744. Then, y is BPSK modulated and sent over an AWGN channel. Let r = (r 1, r 2, [...] ., rN) denote the received bitstream. This work assumes that no bits are deleted by the channel, {{and that the}} side information N is known at the receiver. The transmitted bitstream y or its corresponding bitstream x can be represented as a path in a symbol-level trellis. For each node (l,s) in the trellis, l denotes a position (level) in the bitstream x following a valid codeword [1] and s denotes the current register state of the binary convolutional encoder. The codeword, that presents a symbol, or its convolutionally encoded bitstream labels each branch in the trellis. Let SN denote the set of all valid bitstreams of length N formed by the outputs of the convolutional encoder for sequences of codewords in C. For maximum a posteriori (MAP) decoding, a bitstream y ̂ ∈ SN needs to be selected such that Pr(r|ŷ) Pr(ŷ) ≥ Pr(r|y) Pr(y) ⇔ N∑ j= 1 (hj ⊕ ŷj) |φj | − ln Pr(ŷ) ≤ N∑ j= 1 (hj ⊕ yj) |φj | − ln Pr(y) (1) for all y ∈ SN, where hj 4 = 1, if φj < 0 0, otherwise and φj 4 = ln Pr(rj | 0) Pr(rj | 1). Under the memoryless source and channel assumptions, for branch labeled by yil =...|$|R

