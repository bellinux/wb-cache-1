9|146|Public
40|$|In this thesis, a {{class of}} {{clustered}} censored distributions are proposed in various financial modelling processes. In particular, the proposed distribution can accommodate many stylized (observed) phenomena across different stock markets, especially those with price limits. One main attractive characteristics of the proposed distribution {{is that it can}} capture the clustered behaviour of the data over certain continuous interval (while the traditional <b>censored</b> <b>distribution</b> can only allow the clusters to be on the bounds). The clustered <b>censored</b> <b>distribution</b> is developed and presented, to some extent, in a general way {{so that it can be}} transformed into other well-known distributions, such as the classical Normal distribution, one- (or two-) sided truncated distribution, one- (or two-) sided <b>censored</b> <b>distribution,</b> etc. The clustered <b>censored</b> <b>distribution</b> is further designed into some well-known financial modelling structures, such as Generalized Autoregressive Conditional Heteroskedasticity (GARCH, Bollerslev (1986)) process. We also investigate the potential applications of the proposed models in this thesis to risk management. Overall, there are three main chapters in the thesis. Chapter 1 introduces the fundamental theory and properties of the proposed clustered <b>censored</b> <b>distribution.</b> As a starting point, Normality is mainly considered in this chapter. Built on Chapter 1, Chapter 2 designs a GARCH process with the cluster censored Normal distribution (referred as GARCHCCN). The model performance is investigated via Monte Carlo experiments and empirical data. The risk implication is also discussed in Chapter 2. Chapter 3 consists of two dimensions of the extensions. Sections 3. 1 - 3. 4 extend the model using clustered censored heavy tailed distributions, such as Student-t and Generalized Error Distribution (GED), for a better performance in capturing the tail behaviour. Section 3. 5 examines the dynamic spillover effects under the proposed model framework. There are 14 supporting appendices (A-N) mainly for proofs, tables and figures...|$|E
40|$|By {{introducing}} random vectors described <b>censored</b> <b>distribution</b> system uncertainty, and {{optimize the}} performance of the probability-weighted index, we propose a new robust controller design method. The results are conservative low, taking into account the robust stability and robust performance, and controller performance between the nominal case and worst-case probability of getting a compromise to achieve an integrated design of the entire parameter plane. Simulation results show the effectiveness of this method...|$|E
30|$|As an {{alternative}} to maximum likelihood estimation, {{it is possible to}} estimate the <b>censored</b> <b>distribution</b> by matching PWMs. The main advantage of using PWMs is that these moments are more robust than conventional moments with respect to sampling variability. Closely related to PWMs are L moments, where sample L moments can be defined indirectly as functions of probability weighted moments. Owing to their robustness, fitting statistical distributions by matching PWMs/L moments to data is usually preferable to matching conventional moments.|$|E
40|$|Abstract Background The {{analysis}} of time-to-event {{data can be}} complicated by competing risks, which are events that alter the probability of, or completely preclude the occurrence of an event of interest. This is distinct from censoring, which merely prevents us from observing the time at which the event of interest occurs. However, the <b>censoring</b> <b>distribution</b> plays {{a vital role in}} the proportional subdistribution hazards model, a commonly used method for regression {{analysis of}} time-to-event data in the presence of competing risks. Methods We present the equations that underlie the proportional subdistribution hazards model to highlight {{the way in which the}} <b>censoring</b> <b>distribution</b> is included in its estimation via risk set weights. By simulating competing risk data under a proportional subdistribution hazards model with different patterns of censoring, we examine the properties of the estimates from such a model when the <b>censoring</b> <b>distribution</b> is misspecified. We use an example from stem cell transplantation in multiple myeloma to illustrate the issue in real data. Results Models that correctly specified the <b>censoring</b> <b>distribution</b> performed better than those that did not, giving lower bias and variance in the estimate of the subdistribution hazard ratio. In particular, when the covariate of interest does not affect the <b>censoring</b> <b>distribution</b> but is used in calculating risk set weights, estimates from the model based on these weights may not reflect the correct likelihood structure and therefore may have suboptimal performance. Conclusions The estimation of the <b>censoring</b> <b>distribution</b> can affect the accuracy and conclusions of a competing risks analysis, so it is important that this issue is considered carefully when analysing time-to-event data in the presence of competing risks...|$|R
40|$|The {{so called}} pseudo-observations in {{survival}} analysis were introduced by recent studies that reviewed this method when estimating different parameters using regressions models (Andersen and Perme, Stat. Meth. Med. Res., 2010) {{with the condition}} that the <b>censoring</b> <b>distribution</b> is independent from covariates. If censoring depends on covariates, the method based on pseudo-observations requires modeling of the <b>censoring</b> <b>distribution,</b> {{which leads to the}} construction of alternative estimators based on censoring probability weighting. This master thesis will present the proposal of Andersen and Perme and [...] by means of Monte Carlo simulation [...] will also study its robustness if the model for the <b>censoring</b> <b>distribution</b> is misspecified. Two alternative estimators will be explained and used for the study of robustness of the method: the Cumulative Incidence Function and the Restricted Mean Lifetime...|$|R
40|$|This note {{investigates the}} {{behavior}} of stochastic dominance tests of <b>censored</b> <b>distributions</b> which are dependent on nuisance parameters. In particular, we consider finite mixture distributions that are subject to exogenous censoring. To deal with this potential problem, critical values of the proposed tests statistics are calculated using a parametric bootstrap. The tests are then applied to compare differences between distributions of incomplete employment spells with different levels of censoring obtained from Canadian General Social Survey data. The size of the proposed test statistics is computed using fitted GSS data. Stochastic Dominance Tests, Parametric Bootstrap, <b>Censored</b> <b>Distributions,</b> Finite Mixtures...|$|R
40|$|To measure income {{inequality}} with right-censored (top-coded) data, we propose multiple-imputation methods for estimation and inference. Censored observations are multiply imputed using draws from a flexible parametric model fitted to the <b>censored</b> <b>distribution,</b> yielding a partially synthetic data set from which point and variance estimates {{can be derived}} using complete-data methods and appropriate combination formulae. The methods are illustrated using US Current Population Survey data and the generalized beta of the second kind distribution as the imputation model. With Current Population Survey internal data, we find few statistically significant differences in {{income inequality}} for pairs of years between 1995 and 2004. We also show that using Current Population Survey public use data with cell mean imputations may lead to incorrect inferences. Multiply-imputed public use data provide an intermediate solution...|$|E
40|$|Abstract. The {{experimental}} treatments analysed in {{this paper}} are simple in {{that there is a}} unique Nash equilibrium resulting in each player having a dominant strategy. However, the data show quite clearly that subjects do not always choose this strategy. In fact, when this dominant strategy is not a “focal ” outcome it does not even describe the average decision adequately. It is shown that average individual decisions are best described by a decision error model based on a <b>censored</b> <b>distribution</b> as opposed to the truncate regression model which is typically used in similar studies. Moreover it is shown that in the treatments where the dominant strategy is not “focal ” dynamics are important with average subject decisions initially corresponding to the “focal ” outcome and then adjusting towards the Nash prediction. Overall, 66. 7 % of subjects are consistent with Payoff Maximization, 27. 8 % are consistent with an alternate preference maximization and 5. 6 % are random. (JEL C 72, C 92, D 70...|$|E
40|$|The {{experimental}} treatments analysed in {{this paper}} are simple in {{that there is a}} unique Nash equilibrium resulting in each player having a dominant strategy. However, the data show quite clearly that subjects do not always choose this strategy. In fact, when this dominant strategy is not a “focal” outcome it does not even describe the average decision adequately. It is shown that average individual decisions are best described by a decision error model based on a <b>censored</b> <b>distribution</b> as opposed to the truncate regression model which is typically used in similar studies. Moreover it is shown that in the treatments where the dominant strategy is not “focal” dynamics are important with average subject decisions initially corresponding to the “focal” outcome and then adjusting towards the Nash prediction. Overall, 66. 7 % of subjects are consistent with Payoff Maximization, 27. 8 % are consistent with an alternate preference maximization and 5. 6 % are random. ...|$|E
40|$|Methods {{accounting}} for competing risks in time-to-event problems are becoming common in mainstream statistical analyses. Standard approaches include those based on log-rank type tests [1] and cumulative incidence regression [2]. These approaches {{are based on}} weighting competing events by the <b>censoring</b> <b>distribution.</b> The usual cumulative incidence regression uses weights based on the pooled <b>censoring</b> <b>distribution.</b> However, {{the impact of the}} pattern of events and censoring in these approaches is still unclear. We examine two aspects of this problem: the amount of competing risk present in a proportional hazards model, and the pattern of censoring between groups in the presence of competing risks. Methods We investigated the behaviour of the estimate of treatmen...|$|R
40|$|Abstract: When {{data are}} complete, the {{estimation}} of the conditional variance function in a heteroscedastic non-parametric regression model has been studied by various authors. In this paper, we consider the same problem under random censorship. We propose two methods for estimating the conditional variance. One is the synthetic-data-based direct estimator {{and the other is}} the synthetic-residual-based estimator. The basic idea is to apply the synthetic-data method and a local linear regression to synthetic data or squared synthetic residuals. We establish the results of asymptotic normality for both estimators. Further, we demonstrate that, using synthetic data, without knowing the regression function and the <b>censoring</b> <b>distribution,</b> the synthetic-residual-based estimator can estimate the conditional variance asymptotically as well as if the regression and the <b>censoring</b> <b>distribution</b> were given. This implies that the synthetic-residual-based estimator is ecient and regression-adaptive for estimating the conditiona...|$|R
40|$|Geskus (2011, Biometrics, 67, 39 - 49) studied {{estimation}} of the Fine-Gray model for the cumulative incidence function with left truncated right censored competing risks data. The limiting distribution for an estimator base on weighting inversely using weights involving estimates of the joint distribution of the truncation and censoring times was derived via classical martingale theory with variance estimation based on martingale results. In this note, we demonstrate that martingale theory is not applicable and that other theoretical arguments, like those in Fine and Gray (1999), are needed to rigorously establish the asymptotic properties of the estimators and to construct valid variance estimators. For inverse probability of censoring weighted estimators, the common wisdom is that martingale theory fails because of {{estimation of}} the <b>censoring</b> <b>distribution</b> in the weights. For the Fine-Gray model, alternative theoretical developments are needed even with a known <b>censoring</b> <b>distribution...</b>|$|R
40|$|I {{estimate}} the wage elasticity {{of working in}} the day labor market in rural Malawi using panel data from a unique field experiment. One third of adults in rural areas in Malawi participate in the casual wage labor market, and the government recently committed $ 40 million in a public sector employment scheme. Creating day labor jobs is also a prominent policy tool for governments in other developing countries seeking to simultaneously reduce poverty and promote infrastructure development. Despite {{the importance of this}} sector to individuals and governments, the existing evidence about the elasticity of labor supply in developing countries is scarce and often poorly identified. My estimates are from a field experiment in which 529 adults from ten different villages are offered a day’s work once per week for 12 consecutive weeks. Each village faces a different wage each week; wages range from MK 30 ($US 0. 21) to MK 140 ($US 1. 00) per day. I observe whether or not each individual works at each wage. The experimental design provides exogenous variation in wages, allows me to observe the full distribution of wage offers rather than the <b>censored</b> <b>distribution</b> of accepted wages...|$|E
40|$|The R package spate {{implements}} {{methodology for}} modeling of large space-time data sets. A spatio-temporal Gaussian process is defined through a stochastic partial differential equation (SPDE) which is solved using spectral methods. In {{contrast to the}} traditional geostatistical way of relying on the covariance function, the spectral SPDE approach is computationally tractable and provides a realistic space-time parametrization. This package aims at providing tools for simulating and modeling of spatio-temporal processes using an SPDE based approach. The package contains functions for obtaining parametrizations, such as propagator or innovation covariance matrices, of the spatio-temporal model. This allows for building customized hierarchical Bayesian models using the SPDE based model at the process stage. The functions of the package then provide computationally efficient algorithms needed for doing inference with the hierarchical model. Furthermore, an adaptive Markov chain Monte Carlo (MCMC) algorithm implemented in the package {{can be used as}} an algorithm for doing inference without any additional modeling. This function is flexible and allows for application specific customizing. The MCMC algorithm supports data that follow a Gaussian or a <b>censored</b> <b>distribution</b> with point mass at zero. Spatio-temporal covariates can be included in the model through a regression term...|$|E
40|$|I use panel {{data from}} a unique field {{experiment}} to estimate the wage elasticity of working in the day labor market in rural Malawi. Once a week for 12 consecutive weeks, I make job offers to a pre-defined sample of 529 adults. The wage varies each week, ranging from MK 30 ($US 0. 21) to MK 140 ($US 1. 00) for a day’s work. This approach provides exogenous variation in wages, allows me to observe the full distribution of wage offers rather than the <b>censored</b> <b>distribution</b> of accepted wages, and permits the inclusion of time and village or time and individual fixed effects. I estimate that the elasticity of employment is between 0. 15 and 0. 17, with {{no significant differences between}} men and women. I use auxiliary {{data from a}} nationally representative survey to confirm that equal elasticities for men and women is typical of the Malawian labor market during the agricultural off-season, {{the time of year when}} my experiment takes place. I collapse my data into a censored cross section that mimics data used in the previous literature to demonstrate that my low point estimates of the elasticity employment are due to my improved identification strategy, rather than reflecting inherent differences between Malawi and other developing countries. My results reject backward-bending labor supply curves for men or women, and suggest that labor supply is highly inflexibl...|$|E
40|$|After {{expressing the}} Fisher {{information}} in randomly censored data {{in terms of}} hazard rates, we examine the loss of Fisher information under the Koziol-Green random censoring model. Because the same parameter enters both the survival and <b>censoring</b> <b>distributions</b> in this model, the censored data may contain more Fisher information than the uncensored data. Hazard rate Koziol-Green model Loss of Fisher information...|$|R
40|$|We propose two density estimators of the {{survival}} {{distribution in the}} setting of the Koziol-Green random-censoring model. The estimators are obtained by maximum-penalized-likelihood methods, and we provide an algorithm for their numerical evaluation. We establish the strong consistency of the estimators in the Hellinger metric, the L(p) -norms, p = 1, 2,-infinity, and a Sobolev norm, under mild conditions on the underlying survival density and the <b>censoring</b> <b>distribution.</b> status: publishe...|$|R
40|$|AbstractThe general {{asymptotic}} {{order of}} magnitude is determined for the maximal deviation of the multivariate product-limit estimate from the estimated survival function on Rk. This order depends on the joint behavior of the <b>censoring</b> and <b>censored</b> <b>distributions</b> in a well-defined way. Corresponding to specific joint behaviors, several lim sup results are deduced generalizing everything that is known in the univariate case. The results are also extended for the variable censoring model...|$|R
40|$|Epidemiology {{research}} often {{entails the}} analysis of failure times subject to grouping. In large cohorts interval grouping also offers a feasible choice of data reduction to actually facilitate {{an analysis of the}} data. Based on an underlying Cox proportional hazards model for the exact failure times one may deduce a grouped data version of this model which may then be used to analyse the data. The model bears a lot of resemblance to a generalized linear model, yet {{due to the nature of}} data one also needs to incorporate censoring. In the case of non-trivial censoring this precludes model checking procedures based on ordinary residuals as calculation of these requires knowledge of the <b>censoring</b> <b>distribution.</b> In this paper, we represent interval grouped data in a dynamical way using a counting process approach. This enables us to identify martingale residuals which can be computed without knowledge of the <b>censoring</b> <b>distribution.</b> We use these residuals to construct graphical as well as numerical model checking procedures. An example from epidemiology is provided. Copyright 2007 Board of the Foundation of the Scandinavian Journal of Statistics [...] ...|$|R
40|$|This thesis {{explores the}} issue of how the level of {{censoring}} affects the performance of estimators under departures from an assumed exponential survival distribution. The motivation for this work is a simulation study by Emerson (1981) which suggests that under Weibull departures from exponentiality, validity of exponential confidence intervals for the median survival time improves as censoring increases. Chapter 1 describes survival analysis and robustness, and reviews some relevant literature on both topics. Each of the following chapters deals with a different method of estimation and in each chapter, we find the asymptotic coverage probability of an exponential-based interval for a percentile of a local alternative to the exponential distribution. Chapter 2 is on maximum likelihood estimation. Under mild conditions, the exponential maximum likelihood estimator of a percentile is asymptotically normal. Asymptotic theory suggests that if the <b>censoring</b> <b>distribution</b> converges weakly to point mass at zero, and if the departure from exponentiality is independent of the <b>censoring</b> <b>distribution,</b> as is true in the Weibull case, then the asymptotic coverage probability converges to the expected coverage probability under exponentiality...|$|R
40|$|In {{order to}} {{determine}} an optimum sales strategy for a property {{it is useful to}} estimate the distribution of bids which will be received for the property. The more accurate the estimate of the distribution, the higher the expected return will be from following the optimal strategy. This paper presents a technique for estimating the parameters of that distribution based on order statistics. It also describes how a posted list price might affect the sale price data used in this estimation technique, and how the technique can be modified to deal with this type of <b>censored</b> data. bid <b>distributions,</b> order statistics, <b>censored</b> <b>distributions,</b> asset pricing...|$|R
40|$|The {{evaluation}} of center‐specific outcomes is often through survival analysis methods. Such evaluations must account {{for differences in}} the distribution of patient characteristics across centers. In the context of censored event times, it is also important that the measure chosen to evaluate centers not be influenced by imbalances in the center‐specific <b>censoring</b> <b>distributions.</b> The practice of using center indicators in a hazard regression model is often invalid, inconvenient, or undesirable to carry out. We propose a semiparametric version of the standardized rate ratio (SRR) useful for the {{evaluation of}} centers with respect to a right‐censored event time. The SRR for center j can be interpreted as the ratio of the expected number of deaths in the total population (if the total population were in fact subject to the center j mortality hazard) to the observed number of events. The proposed measure is not affected by differences in center‐specific covariate or <b>censoring</b> <b>distributions.</b> Asymptotic properties of the proposed estimators are derived, with finite‐sample properties examined through simulation studies. The proposed methods are applied to national kidney transplant data. Copyright © 2014 John Wiley & Sons, Ltd...|$|R
40|$|The general {{asymptotic}} {{order of}} magnitude is determined for the maximal deviation of the multivariate product-limit estimate from the estimated survival function on Rk. This order depends on the joint behavior of the <b>censoring</b> and <b>censored</b> <b>distributions</b> in a well-defined way. Corresponding to specific joint behaviors, several lim sup results are deduced generalizing everything that is known in the univariate case. The results are also extended for the variable censoring model. Multivariate censored data multivariate product-limit estimator the rate of strong uniform consistency...|$|R
40|$|A {{class of}} tests is {{considered}} for testing equality of quantiles (of a specified order) of K ([greater-or-equal, slanted] 2) continuous populations when the observations {{are subject to}} random right-censorship. The tests {{may be viewed as}} a generalization of a class of tests considered by Sen (1962) to the case of right-censored data. The proposed tests are useful when the <b>censoring</b> <b>distributions</b> are unequal and do not require the scale or the shape parameters of the underlying populations to be either known or equal. Homogeneity of quantiles global alternatives unequal right-censorship...|$|R
40|$|A noniterative {{method of}} {{estimation}} is presented in a simple linear regression model where the independent variable (covariate) assumes only {{a finite number of}} values and the dependent variable (response) is randomly right <b>censored.</b> The <b>censoring</b> <b>distribution</b> may depend on the covariate values. The efficiency of our estimator is compared with another noniterative estimator in the literature using simulations. The asymptotic normality of the estimators of the regression parameters are established. In addition, the distribution of estimator of the asymptotic variance is obtained. Kaplan-Meier estimator Asymptotic normality and right censored data...|$|R
40|$|Cataloged from PDF {{version of}} article. In most {{reliability}} studies involving censoring, one assumes that censoring probabilities are unknown. We derive a nonparametric estimator {{for the survival}} function when information regarding censoring frequency is available. The estimator is constructed by adjusting the Nelson–Aalen estimator to incorporate censoring information. Our results indicate significant improvements can be achieved if available information regarding censoring is used. We compare this model to the Koziol–Green model, which is also based on a form of proportional hazards for the lifetime and <b>censoring</b> <b>distributions.</b> Two examples of survival data help to illustrate {{the differences in the}} estimation techniques...|$|R
40|$|This paper models {{expected}} future {{values of}} Gaussian stochastic {{processes that are}} bounded by reflecting barriers. Such expectations are of course crucial to any model with forward looking agents. The approach is illustrated by applying it to an exchange rate target zone. By adopting a distributional approach, the formal analysis can be both simple and somewhat elegant. In doing so, we show that the first moments of folded and <b>censored</b> <b>distributions</b> are related in a surprisingly neat way. The setting is discrete-time. though where appropriate we extend the analysis to the continuous-time analogue of reflected Brownian motion...|$|R
40|$|We {{consider}} a two-period airline yield management problem where customers may act strategically. Specifically, we {{allow for the}} possibility that a customer may decide to defer purchase in the hope that a ticket cheaper than those currently on offer will become available. We also allow {{for the possibility that}} some customers will buy a more expensive ticket if the cheaper tickets are not available. We show how to find optimal booking limits in the presence of such strategic customer behavior. We also explicitly incorporate the fact that, once a booking limit has been reached, demand <b>distributions</b> are now <b>censored</b> <b>distributions...</b>|$|R
40|$|A {{central limit theorem}} {{is given}} for functionals of the Kaplan [...] Meier {{estimator}} when the <b>censoring</b> <b>distributions</b> are possibly different or discontinuous. In the i. i. d. case only one easily interpretable and simple integrability condition is needed. This condition reduces to the usual condition for the Lindeberg [...] Lévy theorem {{when there is no}} censoring; it is also necessary in certain other situations. The weak convergence of the corresponding processes is also established. The simple proofs and conditions result from the martingale method of Gill (1983), an extension of an identity of Shorack and Wellner (1986) and a delicate treatment of the remainder terms. ...|$|R
40|$|Abstract: In this paper, we are {{considered}} {{with the problem}} of identifying the minimum effective dose (MED) in a dose-response study with randomly right-censored survival data, where the MED is defined to be the smallest dose level producing a survival function higher than that does the zero-dose control. A closed testing procedures based on the versatile generalized weighted Kaplan-Meier (GWKM, Shen and Cai (2001)) statistics is then suggested. The comparative results of a Monte Carlo error rate and power/bias study for small sample sizes with a variety of survival and <b>censoring</b> <b>distributions</b> are then presented and discussed. Finally, the prostatic cancer data in (Byar and Corle (1977)) is illustrated...|$|R
40|$|In the Koziol [...] Green {{proportional}} hazards model {{one assumes}} that the lifetime distribution F and the <b>censoring</b> <b>distribution</b> G satisfy 1 [...] G = (1 [...] F) [beta]. Let Fn denote the nonparametric MLE of F. We show that for any integrable function, [integral operator] dFn [...] > [integral operator] dF w. p. 1. This result may be applied to yield consistency of many estimators. In a small sample simulation study it is demonstrated that [integral operator] dFn outperforms [integral operator] dn, where n is the Kaplan [...] Meier estimate of F. Koziol [...] Green {{proportional hazards model}} random censorship nonparametric MLE consistency...|$|R
40|$|Survival {{analysis}} {{is a popular}} area of statistics dealing with time-to-event data. A special characteristic of survival data {{is the presence of}} censoring. Censoring occurs when the survival time is only partially known. In medical studies, censoring can be caused by patients dropping out of the study before their disease event occurs. This dissertation focuses on the analysis of interval-censored data, where the failure time is only known to belong to some interval of observation times. One problem researchers face when analyzing survival data is how to handle the <b>censoring</b> <b>distribution.</b> This is an important consideration because sometimes a patient's survival time is related to the time they drop out of the study. It is often assumed that these two times are unrelated, so special methods need to be developed when they are dependent. Part of this dissertation investigates the effectiveness of methods developed for interval-censored data with dependent censoring when the censoring is actually independent. The results of these simulation studies can provide guidelines for deciding between models when facing a practical problem where one is unsure about the dependence of the <b>censoring</b> <b>distribution.</b> Another important problem seen in survival {{analysis is}} variable selection. For example, doctors might want to identify a set of diagnostic tests or measurements that can predict patient survival. We propose an imputation approach for variable selection of interval-censored data that utilizes penalized likelihood procedures. This work is significant because researchers currently do not have many tools to select important variables related to the survival time for interval-censored data...|$|R
40|$|Indirect {{censoring}} {{is defined}} as the effect on observed variables of censoring on unobserved variables. Methods of testing for indirect censoring are discussed, and exemplified, using a bivariate Farlie-Gumbel-Morgenstern <b>distribution.</b> Indirect <b>censoring</b> Farlie-Gumbel-Morgenstern <b>distribution</b> likelihood ratio tests order statistics moments...|$|R
40|$|To {{apply the}} method {{proposed}} in Section 3. 2 we need estimated {{values for the}} error variance. To obtain estimates we can rely on an asymptotic representation, proposed by Lo and Singh (1986), decomposing F ̂ (k) i (t) − F (k) i (t) as an average of i. i. d. terms and a lower order remainder term rik(t), where F (k) i is the continuous failure time distribution function for subjects in cluster i with xij = k. Let G be the <b>censoring</b> <b>distribution,</b> 1 −Hik(s) = { 1 − F (k) i (s) }{ 1 − G(s) } and Huik(s) = P (Tij ≤ s, δij = 1 |xij = k) = ∫...|$|R
40|$|The {{problem of}} testing for {{differences}} between two groups {{with respect to}} multiple competing risk time-to-event endpoints is considered A class of two-sample test is proposed for comparing the subdistribution of {{a particular type of}} failures. The test is based on comparing the weighted average of subdistribution functions without making any assumption on the nature of dependence among the risks. The weight function has been chosen so that the test is distribution-free in the sense that asymptotically valid test can be performed without assumption regarding the underlying survival and <b>censoring</b> <b>distribution.</b> Both theoretical result and simulation evidence show that the proposed method attains the nominal level. We also apply the test to real data...|$|R
40|$|A {{method for}} {{estimating}} {{the ranks of}} the underlying uncensored observations in a censored data set is proposed. The derived ranks are used to extend the use of the rank transform method to the censored matched pairs and the censored k-sample problems. The derived procedure for the censored matched pairs problem is new and consists of performing a paired-t test on the defined ranks. The procedure for the k-sample problem consists of performing a one-way ANOVA F-test on the derived ranks. This is essentially identical to a statistic proposed by Peto and Peto (1972). The asymptotic power of this procedure is derived and multiple comparison procedures based on it are proposed. The robustness of this test and multiple comparison procedures to departures from the assumption of equal <b>censoring</b> <b>distributions</b> is also established. ...|$|R
