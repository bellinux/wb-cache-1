12|26|Public
50|$|Inserting {{elements}} can be {{done through}} oXygen's XML refactoring commands to insert an element at the current <b>cursor</b> <b>location.</b> Even if XML tags are set to be non-visible, an indication for an empty element is always displayed using that element's name.|$|E
5000|$|Emacs {{operates}} on data structures called buffers containing text with additional attributes; every buffer maintains its own point (<b>cursor</b> <b>location)</b> and mark (another location, delimiting the selected region {{together with the}} point), {{the name of the}} file it is visiting (if applicable) and the set of active modes (exactly one major mode and any number of minor modes), which control editor behaviour through variables.Elisp code can be executed interactively through named commands, which can be bound to key presses or accessed by name; some commands evaluate arbitrary Elisp code from buffers (e.g. [...] or [...] ).|$|E
50|$|A {{text editor}} written or {{customized}} {{for a specific}} use can determine what the user is editing and assist the user, often by completing programming terms and showing tooltips with relevant documentation. Many text editors for software developers include source code syntax highlighting and automatic indentation to make programs easier to read and write. Programming editors often let the user select {{the name of an}} include file, function or variable, then jump to its definition. Some also allow for easy navigation back to the original section of code by storing the initial <b>cursor</b> <b>location</b> or by displaying the requested definition in a popup window or temporary buffer. Some editors implement this ability themselves, but often an auxiliary utility like ctags is used to locate the definitions.|$|E
5000|$|In {{this text}} {{navigation}} mode the ‘cursor’, often {{depicted as a}} blinking vertical line, appears within the text on-screen. The user can then navigate throughout the text by using the arrow navigation keys to cause the cursor to move; typically changing the <b>cursor’s</b> <b>location</b> in increments of character position horizontally and of text line vertically.|$|R
50|$|The Liberator {{controls}} {{consist of}} a trackball, fire button, and shield button. The player controls a coordinated attack from four star ships {{at the corners of}} the screen. The primary target of the attack are enemy bases on a rotating planet {{in the center of the}} screen. The trackball is used to move a cross-shaped cursor. The fire button fires a missile at the <b>cursor's</b> <b>location</b> from your closest ship. The shield button is used to activate force fields around the ships. The shield can only take four hits each round, and the count is shared between all ships.|$|R
40|$|Suppose, {{you want}} to {{implement}} a structured editor for some term type, so that the user can navigate through a given term and perform edit actions on subterms. In this case you are immediately faced {{with the problem of}} how to keep track of the cursor movements and the user's edits in a reasonably efficient manner. In a previous pearl G.  Huet introduced a simple data structure, the Zipper, that addresses this problem. A drawback of the Zipper is that the type of <b>cursor</b> <b>locations</b> depends on the structure of the term type, that is, each term type gives rise to a different type of locations (unless you are working in an untyped environment). In this pearl we present an alternative data structure, the Web, that serves the same purpose but that is parametric in the underlying term type...|$|R
40|$|International audienceThis article {{presents}} ControlTree, a relevant technique {{to select a}} node {{is a very large}} node-link representation using a continuous interaction. The node-link representation is dynamic and driven by the <b>cursor</b> <b>location</b> to optimize screen space and to ease the selections. ControlTree uses a snapping mechanism and adapts the OrthoZoom technique to offer an alternative to common "point-and-click" techniques. We also present a preliminary theoretical evaluation showing that ControlTree is a promising technique...|$|E
40|$|Cursor {{snapping}} is {{a standard}} method for providing precise pointing in direct manipulation graphical interfaces. In this paper, we introduce image snapping, a variant of cursor snapping that works in image-based programs such as paint systems. Image snapping moves the <b>cursor</b> <b>location</b> to nearby features in the image, such as edges. It is implemented by using gradient descent on blurred versions of feature maps made from the images. Interaction techniques using cursor snapping for image segmentation and curve tracing are presente...|$|E
40|$|Abstract: The more {{complicated}} web resources exist, the more professional web browsing technologies should be inno-vated. This paper illustrates a concept {{for how to}} extract a web page semantic content and automatically follow the <b>cursor</b> <b>location</b> to organize the likely-words from a sentence for data intelligence. Such a web browsing concept could be implemented {{with a couple of}} cross-browser techniques. We believe this concept will be popular with any other miscellaneous form in the future browsers. However, this concept will be another im-portant step for human-computer interaction, especially, for minimizing the time expense and maintaining the likely keywords library during further web surfing utilization. ...|$|E
40|$|Introduction Say, {{you want}} to {{implement}} a structured editor for some term type, so that the user can navigate through a given term and perform edit actions on subterms. In this case you are immediately faced {{with the problem of}} how to keep track of the cursor movements and the user's edits in a reasonably ecient manner. In a previous pearl G. Huet (1997) introduced a simple data structure, the Zipper, that addresses this problem|we will explain the Zipper briey in Sec. 2. A drawback of the Zipper is that the type of <b>cursor</b> <b>locations</b> depends on the structure of the term type, that is, each term type gives rise to a dierent type of locations (unless you are working in an untyped environment). In this pearl we present an alternative data structure, the Web, that serves the same purpose but that is parametric in the underlying term type. Sec. 3 - 6 are devoted to the new data structure. Before we unravel the Zipper and explore the Web, let us rs...|$|R
40|$|Introduction Suppose, {{you want}} to {{implement}} a structured editor for some term type, so that the user can navigate through a given term and perform edit actions on subterms. In this case you are immediately faced {{with the problem of}} how to keep track of the cursor movements and the user's edits in a reasonably ecient manner. In a previous pearl G. Huet (1997) introduced a simple data structure, the Zipper, that addresses this problem|we will explain the Zipper briey in Sec. 2. A drawback of the Zipper is that the type of <b>cursor</b> <b>locations</b> depends on the structure of the term type, that is, each term type gives rise to a dierent type of locations (unless you are working in an untyped environment). In this pearl we present an alternative data structure, the Web, that serves the same purpose but that is parametric in the underlying term type. Sec. 3 - 6 are devoted to the new data structure. Before we unravel the Zipper and explore the Web, let us rst give a taste of their use. The fo...|$|R
40|$|Selections {{are often}} carried out using {{toolbars}} that are located {{far away from}} the <b>location</b> of the <b>cursor.</b> To reduce the time to make these selections, researchers have proposed in-place toolbars such as Toolglasses or popup palettes. Even though in-place toolbars have been known for a long time, there are factors influencing their performance that have not been investigated. To explore the subtleties of different designs for in-place toolbars, we implemented and compared three approaches: warping the cursor to the toolbar, having the toolbar pop up over the cursor, and showing the toolbar on the trackpad itself to allow direct touch. Our study showed that all three new techniques were faster than traditional static toolbars, but also uncovered important differences between the three in-place versions. Participants spent significantly less time in the direct-touch trackpad, and warping the <b>cursor’s</b> <b>location</b> caused a time-consuming attentional shift. These results provide {{a better understanding of how}} small changes to in-place toolbar techniques can affect performance. KEYWORDS: In-place toolbars, targeting time, direct input...|$|R
40|$|This {{research}} conducted {{to create a}} control of computer mouse cursor for users with hand disabilities. Input for the control system is taken by 1. 3 MP webcam with average frame rate is 10 fps. Controlling the <b>cursor</b> <b>location</b> is done by realtime face detection using the haarcascade method, and controlling clicking activities carried out by blink detection using SURF. The experiments involving some applications on OS Window 7. The {{results show that the}} application of the haarcascade method to function properly for purposes of allocating the mouse cursor, and mouse click events can be used successfully for click activity are not bound by time restrictions...|$|E
40|$|We {{present a}} novel manipulandum for {{understanding}} the sensorimotor processes involved in object grasping. We have developed a closed-loop loop prosthetic hand, with 2 degrees of control and 32 channels of vibrotactile feedback of fingertip forces and finger positions s. In order to understand this model sensorimotor circuit we first tackle two sub sub-problems: problems: (Q 1) Do we integrate artificial al sensory feedback (vibrotactile) with our other modalities (vision, proprioception) in a statistically optimal manner based on sensory uncertainty? We run subjects through a pursuit tracking task with noisy visual and vibrotactile cues to <b>cursor</b> <b>location,</b> and describe the resulting trajectories with a Kalman filter model; and (Q 2) Are grasp trajectories and temporal force profiles a predictable function of the actuation commands that control the hand and the available feedback? We run subjects through a new tracking task where the grasp size and force on an object are modulated, and compare the resulting trajectories to those predicted by the optimal feedback control (OFC) framework...|$|E
40|$|Abstract: Drag-and-pop and drag-and-pick are {{interaction}} techniques designed for users of pen- and touch-operated display systems. They provide users {{with access to}} screen content {{that would otherwise be}} impossible or hard to reach, e. g., because it is located behind a bezel or far away from the user. Drag-and-pop is an exten-sion of traditional drag-and-drop. As the user starts dragging an icon towards some target icon, drag-and-pop responds by temporarily moving potential target icons towards the user’s current <b>cursor</b> <b>location,</b> thereby allow-ing the user to interact with these icons using comparably small hand movements. Drag-and-Pick extends the drag-and-pop interaction style such that it allows activating icons, e. g., to open folders or launch applications. In this paper, we report the results of a user study comparing drag-and-pop with traditional drag-and-drop on a 15 ’ (4. 50 m) wide interactive display wall. Participants where able to file icons up to 3. 7 times faster when using the drag-and-pop interface...|$|E
40|$|The {{issue of}} how the Euclidean {{properties}} of space are represented in the nervous system is a main focus {{in the study of}} visual perception, but is equally relevant to motor learning. The goal of our experiments was to investigate how the properties of space guide the remapping of motor coordination. Subjects wore an instrumented data glove that recorded the finger motions. Signals generated by the glove operated a remotely-controlled endpoint: a cursor on a computer monitor. The subjects were instructed to execute movements of this endpoint with controlled motions of the fingers. This required inverting a highly redundant map from fingers to cursor motions. We found that 1) after training with visual feedback of the final error (but not of the ongoing cursor motion), subjects learned to map <b>cursor</b> <b>locations</b> into configurations of the fingers; 2) extended practice of movement led to more rectilinear cursor movement, a trend facilitated by training under continuous visual feedback of cursor motions; 3) with practice, subjects reduced motion in the degrees of freedom that did not contribute to the movements of the cursor; 4) with practice, subjects reduced variability of both cursor and hand movements...|$|R
5000|$|Emacspeak {{achieves}} its integration {{by being}} written largely in Emacs Lisp using [...] "advice", enabling it to literally be a wrapper around most functions that change or otherwise modify the display. Auditorily, verbalizations are pre-emptible, and common actions like opening a menu or closing a file have a brief sound {{associated with that}} particular action; it also immediately verbalizes all insertions of characters, and attempts to speak {{as much of the}} context sentences around the <b>cursor's</b> present <b>location</b> as possible.|$|R
50|$|Cursorjacking is a UI {{redressing}} {{technique to}} change the <b>cursor</b> from the <b>location</b> the user perceives, discovered in 2010 by Eddy Bordi, a researcher at Vulnerability.fr, Marcus Niemietz demonstrated this with a custom cursor icon, and in 2012 Mario Heiderich by hiding the cursor.|$|R
40|$|We {{developed}} the three-dimensional visualization software, Tonal Interface to MacroMolecules or TIMMol, for studying atomic coordinates of protein structures. Key features include audio tones indicating x, y, z location, {{identification of the}} <b>cursor</b> <b>location</b> in one-dimensional and three-dimensional space, textual output {{that can be easily}} linked to speech or Braille output, and the ability to scroll along the main chain backbone of a protein structure. This program was initially designed for visually impaired users, and it already has shown its effectiveness in helping a blind researcher study X-ray crystal structure data. Subsequently, TIMMol has been enhanced with a graphical display to act as a bridge to ease communication between sighted and visually impaired users as well as to serve users with spatial visualization difficulties. We performed a pilot study to assess the efficacy of the program in conveying three-dimensional information about proteins with and without graphical output to a general scientific audience. Attitudes regarding using TIMMol were assessed using Rasmol, a common visualization package, for comparison. With the use of text and tones exclusively, a majority of users were able to identify specific secondary structure elements, three-dimensional relationships among atoms, and atoms coordinating a ligand. In addition, a majority of users saw benefits in using TIMMol and would recommend it to those having difficulty with standard tools...|$|E
40|$|Figure 1 : Sample use of UIMarks in a {{drag-and-drop}} situation. While dragging an icon (A), {{the user}} enters the UIMarks mode, points at a previously marked location using the bubble cursor technique (B), leaves the mode (C) and drops the icon (D). Here, the {{activation of the}} mark not only moved the cursor but also created a temporary mark at the initial <b>cursor</b> <b>location.</b> The user thus simply has to enter the mode again (E), point at the new mark (F) and leave the mode (G) to return there. This paper reports on the design and evaluation of UIMarks, a system that lets users specify on-screen targets and associated actions {{by means of a}} graphical marking language. UIMarks supplements traditional pointing by providing an alternative mode in which users can quickly activate these marks. Associated actions can range from basic pointing facilitation to complex sequences possibly involving user interaction: one can leave a mark on a palette to make it more reachable, but the mark can also be configured to wait for a click and then automatically move the pointer back to its original location, for example. The system has been implemented on two different platforms, Metisse and OS X. We compared it to traditional pointing on a set of elementary and composite tasks in an abstract setting. Although pure pointing was not improved, the programmable automation supported by the system proved very effective. ACM Classification: H. 5. 2 [Information interfaces and presentation]: User interfaces- Graphical user interfaces...|$|E
40|$|We {{present a}} new {{non-blocking}} doubly-linked list implementation for an asynchronous shared-memory system. It {{is the first}} such implementation for which an upper bound on amortized time complexity has been proved. In our implementation, operations access the list via cursors. Each cursor is associated with an item in the list and is local to a process. The implementation supports two update operations, insertBefore and delete, and two move operations, moveRight and moveLeft. An insertBefore(c, x) operation inserts an item x into the list immediately before the <b>cursor</b> c’s <b>location.</b> A delete(c) operation removes the item at the <b>cursor</b> c’s <b>location</b> and sets the cursor to the next item in the list. The move operations move the cursor one position to the right or left. The update operations use single-word Compare&Swap instructions. The move operations only read shared memory and never change {{the state of the}} data structure. If all update operations modify different parts of the list, they run completely concurrently. Let ċ(op) be the maximum number of active cursors at any one time during the operation op. The amortized complexity of each update operation op is O(ċ(op)) and each move operation is O(1). We have written a detailed correctness proof and amortized analysis of our implementation. ...|$|R
50|$|In many text {{processing}} programs, such as web browsers or word processors, clicking on text moves the <b>cursor</b> to that <b>location.</b> Clicking {{and holding the}} left button will allow users to highlight the selected text enabling the user with more options to edit or use the text.|$|R
5000|$|Up to nine files can {{be opened}} for editing {{at one time}} in {{separate}} [...] "windows" [...] that allow quick copy-and-paste among several files. Two files may be opened on the same screen for easy comparison of changes; a XyWrite command will do the comparison automatically, putting the <b>cursor</b> on the <b>location</b> at which the two files first differ (from which the user can {{move to the next}} difference).|$|R
5000|$|The {{shape of}} the cursor is {{restricted}} to a rectangle the full width of the character box, and filled with the foreground color of the character at the <b>cursor's</b> current <b>location.</b> Its height and position may be arbitrary within a character box;. [...] The EGA and many VGA clones allowed a split-box cursor (appearing as two rectangles, one {{at the top of}} the character box and one at the bottom), by setting the end of the cursor before the start, however if this is done on the original VGA the cursor is completely hidden instead. [...] The VGA standard does not provide a way to alter the blink rate, although common workarounds involve hiding the cursor and using a normal character glyph to provide a so-called software cursor.|$|R
40|$|To behave adaptively {{in complex}} and dynamic environments, one must link {{perception}} and action to satisfy internal states, {{a process known}} as response selection (RS). A largely unexplored topic in the study of RS is how interstimulus and interresponse similarity affect performance. To examine this issue, we manipulated stimulus similarity by using colors that were either similar or dissimilar and manipulated response similarity by having participants move a mouse <b>cursor</b> to <b>locations</b> that were either close together or far apart. Stimulus and response similarity produced an interaction such that the mouse trajectory showed the greatest curvature when both were similar, a result obtained under task conditions emphasizing speed and conditions emphasizing accuracy. These findings are inconsistent with symbolic look-up accounts of RS but are consistent with central codes incorporating metrical properties of both stimuli and responses...|$|R
40|$|This paper {{demonstrates}} the clinical {{application of a}} multiplanar imaging system, which simultaneously acquires enface (C-scan) OCT and corresponding confocal ophthalmoscopic images along with cross-sectional (B-scan) OCT at <b>cursor</b> designated <b>locations</b> on the confocal image. Advantages of the simultaneous OCT/confocal acquisition {{as well as the}} challenges of interpreting the C-scan OCT images are discussed. Variations in tissue inclination with respect to the coherence wave surface alters the sampling of structures within the depth in the retina, producing novel slice orientations which are often challenging to interpret. We evaluate {{for the first time the}} utility of C-scan OCT for a variety of pathologies including exudative ARMD, macular hole, central serous retinopathy, diabetic retinopathy, polypoidal choroidal vasculopathy and macular pucker. Several remarkable observations of new aspects of clinical anatomy were noted. The versatility of selective capture of C-scan OCT images and B-scan OCT images at precise points on the confocal image affords the clinician a more complete and interactive tool for 3 D imaging of retinal pathology...|$|R
40|$|A {{versatile}} multifunction package, POLYSITE, {{developed for}} Goddard's Land Analysis System, is described which simplifies {{the process of}} interactively selecting and correcting the sites used to study Landsat TM and MSS images. Image switching between the zoomed and nonzoomed image, color and shape <b>cursor</b> change and <b>location</b> display, and bit plane erase or color change, are global functions which are active at all times. Local functions possibly include manipulation of intensive study areas, new site definition, mensuration, and new image copying. The program is illustrated with {{the example of a}} full TM maser scene of metropolitan Washington, DC...|$|R
40|$|This {{research}} {{is aimed at}} designing and implementing a human computer interface system that tracks {{the direction of the}} human gaze. The motion and direction of the iris is used to drive the interface by positioning the mouse <b>cursor</b> accordingly. The <b>location</b> of the iris is done in batch mode. This implies that the frames are stored in a permanent storage device (hard disk, USB drive etc) and are retrieved one by one. Each of the frames is processed thus finding the location of the iris and thereby placing the mouse cursor accordingly. Such a system that detects the iris position from still images provides an alternate input modality to facilitate computer users with severe disabilities...|$|R
5000|$|InfoWorld in May 1986 {{stated that}} [...] "we can see why" [...] Apple opposed the Laser 128's {{importation}} to the United States. It stated that {{other than the}} keyboard feel, the computer's external features (the expansion slot, numeric keypad, and Centronics port) improved on the IIc. Given {{the high degree of}} compatibility and a price less than half that of the IIc, the magazine concluded that the Laser 128 [...] "is a real bargain". Writing that [...] "it's cheap and it works", inCider in December 1986 stated that the Laser 128 [...] "deserved a look from anyone considering a Commodore. Or, to be blunt, anyone considering an Apple IIc". The magazine also disliked the keyboard's feel and called the computer [...] "homely", but concluded that [...] "The Laser is a remarkably compatible, competent performer. The Apple market isn't known for hardware bargains, but it has one now". BYTE in January 1987 preferred the Laser 128's keyboard, including the keypad and <b>cursor</b> keys' <b>locations,</b> to that of the Apple IIc and approved of the documentation's quality. Despite describing the software incompatibility issues as [...] "disappointing" [...] the magazine concluded that its [...] "technical issues are relatively minor", and that its low price made the computer [...] "perfect for someone looking for a second computer or an inexpensive first computer that runs the largest pool of software available today".|$|R
50|$|Many {{more control}} {{characters}} take parameters: {{one or more}} characters that follow are used solely for their bit value as a parameter {{and not as a}} control code. VDU 19 handles palette remap; the following five bytes represent the palette entry, the desired colour and three reserve bytes. VDU 31 locates the text <b>cursor</b> to the <b>location</b> held in the following two bytes. VDU 17 sets the text colour and 18 the graphics colour. VDU 25 uses the succeeding five bytes to move the graphics cursor and plot solid and dashed lines, dots and filled triangles, the documented extent of graphics in MOS 0 and 1. The first byte is the command code, followed by the x and y co-ordinates as two byte pairs. Other graphic functions such as horizontal line fill bounded by a given colour were available by use of undocumented or poorly documented command codes.|$|R
40|$|The {{conflict}} between vision and proprioception {{has been proposed}} to explain why healthy subjects perform worse than propriocep-tively deafferented patients in conditions with optical displacement, e. g. novel mirror drawing. It is not known which brain processes depend upon the successful integration of visual and proprioceptive information and are therefore impaired when these modalities disagree. With fMRI in healthy subjects we compared brain activity across two conditions with similar visual and proprioceptive stimulation and similar task demands that differed by the congru-ence of movement showed by the two modalities. Subjects felt the passive movement of the right index finger on a rectangular field and watched a cursor moving on a computer screen. <b>Cursor</b> and finger <b>locations</b> either mapped onto each other (congruent condi-tion) or did not (incongruent condition). Monitoring incongruent compared with congruent movement activated the premotor area bilaterally and the right temporoparietal junction. These brain areas have previously been associated with shifts in the attended location in the visual space. These findings suggest an interaction between vision and proprioception in orienting to spatial locations...|$|R
40|$|The current {{dissertation}} proposes three manners {{in which}} findings about the neuroscience of decision-making can inform traditional questions in economics that historically {{has been investigated}} using choice data alone, and without delineating the mechanism of choice. The first chapter investigates the origins of {{a critical component of}} both economic and perceptual decision-making under uncertainty: the belief formation process. Most research has studied belief formation in economic and perceptual decision-making in isolation. One reason for this separate treatment may be the assumption that there are distinct psychological mechanisms that underlie belief formation in economic and perceptual decisions. An alternative theory is that there exists a common mechanism that governs belief formation in both domains. Here,we test this alternative theory by combining a novel computational modeling technique with two well-known experimental paradigms. I estimate a drift-diffusion model (DDM) and provide an analytical method to decode prior beliefs from DDM parameters. Subjects in our experiment exhibit strong extrapolative beliefs in both paradigms. In line with the common mechanism hypothesis, we find that a single computational model explains belief formation in both tasks, and that individual differences in belief formation are correlated across tasks. These results suggest that extrapolative beliefs in economic decision-making may stem from low-level automatic processes that also play a role in perceptual decision-making, and therefore might be difficult to suppress. The second chapter investigates the role of the sex steroid hormone testosterone as a biological mediator that translates environmental changes into shifts in cognition, that influence decision-making. Correlational studies have linked testosterone with aggression and disorders associated with poor impulse control, but corresponding mechanisms are poorly understood and {{there is no evidence of}} causality. Building on a dual-process framework, I identify a mechanism for testosterone’s behavioral effects in humans: reducing cognitive reflection. In the largest testosterone administration study to date, 243 men received either testosterone or placebo and took the Cognitive Reflection Test (CRT) that estimated their capacity to override incorrect intuitive judgments with deliberate correct responses. Testosterone administration reduced CRT scores. The effect was robust to controlling for age, mood, math skills, treatment expectancy, and 14 other hormones. The effects were enhanced in subjects with high cortisol and estradiol levels. These findings suggest a unified mechanism underlying testosterone’s varied behavioral effects in humans and provide novel, clear, and testable predictions. In the third chapter, I study dynamic unstructured bargaining with deadlines and one-sided private information about the amount available to share (the “pie size"). Using mechanism design theory, I show that given the players’ incentives, the equilibrium incidence of bargaining failures (“strikes”) should increase with the pie size, and I derive a condition under which strikes are efficient. In our setting, no equilibrium satisfies both equality and efficiency in all pie sizes. I derive two equilibria that resolve the trade-off between equality and efficiency by either favoring equality or favoring efficiency. Using a novel experimental paradigm, I confirm that strike incidence is decreasing in the pie size. Subjects reach equal splits in small pie games (in which strikes are efficient), while most payoffs are close to either the efficient or the equal equilibrium prediction when the pie is large. I employ a machine learning approach to show that bargaining process features recorded early in the game improve out of sample prediction of disagreements at the deadline. The process feature predictions are as accurate as predictions from pie sizes only, and adding process and pie data together improve predictions even more. As process data can be much richer than the series of <b>cursor</b> <b>locations</b> that we have used (for example, by including skin conductance, pupil dilation or facial expressions), better inference of outcome variables is likely feasible. Thus, if a policy maker or a mediator can access an independent measure of private information, an arbitration mechanism may allow boosting efficiency by taking this measurement into account. </p...|$|R
40|$|The Canada Centre for Remote Sensing (CCRS) has two DAEDALUS {{analog line}} {{scanners}} in the CCRS aircraft. The spacial resolution is 2. 5 milliradians for the 8 to 14 u meter sensor and 1. 7 milliradians for the 3 to 5 u meter sensor. Each has black body references for quantitative data processing. The scanner analog video and sync data are recorded on wide band FM Group I 1 amplifiers on a MINCOM tape. The record speed is 30 IPS for 2. 5 milliradian resolution and 60 IPS for 1. 7 milliradian resolution due to upper {{cut off frequency}} of the FM Group I 1 amplifiers. The hardware data recovery system developed by CCRS provides either Universal Imagery Format digital computer compatible tape or continuous strip colour film with quantitative temperature colour assignments. The scanner analog video data is digitized on an 8 bit analog to digital converter. The digitization of black bodies and video are controlled by the scanner sync track. The film is produced on a CCRS built film recorder. The video data can be digitized in three modes. First in a constant A/D mode where the sampling frequency is selectable. To remove panoramic distortion two fixed modes of non-linear A/D are provided using a Binary Rate Multiplier control. The 2. 5 milliradian resolution data is digitized to 1024 pixels per scan line with a nadir frequency of 120 KHz. The 1. 7 milliradian resolution data is digitized to 2048 pixels per per scan line with a nadir frequency of 240 KHz. The user can process CCTs interactively on-line on a colour video display or colour film products may be provided. The interactive software includes a <b>cursor</b> area <b>location</b> which uses the black body references to provide quantitative temperature reading together with {{the area in the}} cursor. The most recent interactive software provides a colour density slicing for displayed images. The temperature slicing is in. 5 degree increments with a maximum of 24 increments available. Colour film has provided users with information for land use and moisture content. The system has also been successfully used for determining heat loss from central heating system piping complexes as well as building roof heat loss areas...|$|R
40|$|Abstract — Prior {{work has}} shown that neural {{activity}} from the primate brain can maneuver a computer cursor to specified visual targets. This cursor movement can take over a second, longer than the time for an arm reach to the same location. We asked if this acquisition time could be reduced, thereby {{increasing the number of}} targets that could be hit per second. We implemented a system that positions a prosthetic <b>cursor</b> at discrete <b>locations,</b> based on pre-movement neural activity in rhesus monkeys. Using a delayed center-out reaching task with several different target layouts, neural activity was simultaneously recorded from an electrode array implanted in the dorsal pre-motor cortex. We designed a target prediction algorithm based on maximum-likelihood models (using Gaussian or Poisson distributions) to decode the upcoming reach target in real-time. During cursor trials, the algorithm predicted the most likely reach target using 50 - 275 ms of delay activity starting at least 150 ms after target onset. If the target prediction was correct, a cursor was positioned and the monkey received a reward. The performance of the system was evaluated based on the accuracy of decoded targets and speed at which targets were decoded, both of which were consolidated with an information theoretic analysis. The maximum average sustained rate of target acquisition was 4. 3 targets per second obtained with a 2 target layout and 50 ms of delay activity. The maximum information transfer rate calculated for the system was 6. 5 bps obtained with an 8 target layout and 100 ms of delay activity...|$|R
25|$|Further {{advances}} in computing led to greater advancements in interactive computer graphics. In 1959, the TX-2 computer was developed at MIT's Lincoln Laboratory. The TX-2 integrated {{a number of}} new man-machine interfaces. A light pen could be used to draw sketches on the computer using Ivan Sutherland's revolutionary Sketchpad software. Using a light pen, Sketchpad allowed one to draw simple shapes on the computer screen, save them and even recall them later. The light pen itself had a small photoelectric cell in its tip. This cell emitted an electronic pulse whenever it was placed {{in front of a computer}} screen and the screen's electron gun fired directly at it. By simply timing the electronic pulse with the current location of the electron gun, it was easy to pinpoint exactly where the pen was on the screen at any given moment. Once that was determined, the computer could then draw a <b>cursor</b> at that <b>location.</b> Sutherland seemed to find the perfect solution for many of the graphics problems he faced. Even today, many standards of computer graphics interfaces got their start with this early Sketchpad program. One example of this is in drawing constraints. If one wants to draw a square for example, they do not have to worry about drawing four lines perfectly to form the edges of the box. One can simply specify that they want to draw a box, and then specify the location and size of the box. The software will then construct a perfect box, with the right dimensions and at the right location. Another example is that Sutherland's software modeled objects - not just a picture of objects. In other words, with a model of a car, one could change the size of the tires without affecting the rest of the car. It could stretch the body of car without deforming the tires.|$|R
40|$|It {{has been}} {{reported}} that the brain combines egocentric and allocentric information to update object positions after an intervening movement. Studies typically use discrete updating tasks (i. e., comparing pre- to post-movement target representations). Such approaches, however, cannot reveal how the brain would weigh the information in these reference frames during the intervening motion. A reasonable assumption is that objects with stable position over time {{would be more likely to}} be considered as a reliable allocentric landmark. But inferring whether an object is stable in space while the observer is moving involves attributing perceived changes in location to either the object's or the observer's displacement. Here, we tested this causal inference hypothesis by designing a continuous whole-body motion updating task. At the beginning of a trial, a target was presented for 500 ms, within a large visual frame. As soon as the target disappeared, participants were asked to move a <b>cursor</b> to this <b>location</b> by controlling a linear-guide mounted on the vestibular sled on which they were seated. Participants were translated sideways as soon as their reaching movement started, and they had to maintain the cursor on the remembered target location in space while being moved. During the sled motion, the frame would move with a velocity proportional to that of the sled (gain ranging from - 0. 7 to 0. 7). Participants' responses showed a systematic bias in the direction of the frame displacement, one that increased with the difference between the frame and the sled velocity for small differences, but was decreasing for large differences. This bias pattern provides evidence for humans exploiting a dynamic Bayesian inference process with two causal structures to mediate the dynamic integration of allocentric and egocentric information in spatial updating. Meeting abstract presented at VSS 2017...|$|R
