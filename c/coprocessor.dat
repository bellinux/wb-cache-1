1423|523|Public
5|$|Robotron: 2084 {{features}} monaural {{sound and}} raster graphics on a 19-inch CRT monitor. It uses a Motorola 6809 {{central processing unit}} that operates at 1MHz. To produce multiple sounds on a single audio channel, the game uses a priority scheme to generate sounds in order of importance. A custom graphics coprocessor—which operates as a blitter chip—generates the on-screen objects and visual effects. The <b>coprocessor</b> increases the transfer speed of memory, which allows the game to simultaneously animate {{a large number of}} objects.|$|E
5|$|There {{have been}} seven {{versions}} of the iPad. The first generation established design precedents, some of which, such as the home button placement, have persisted through all models. The 2nd-generation iPad (iPad 2) introduced a new thinner design, a dual-core Apple A5 processor, and VGA front-facing and 720p rear-facing cameras designed for FaceTime video calling. The third generation added a Retina Display, the new Apple A5X processor with a quad-core graphics processor, a 5-megapixel camera, HD 1080p video recording, voice dictation, and 4G (LTE). The fourth generation added the Apple A6X processor and replaced the 30-pin connector with an all-digital Lightning connector. The iPad Air added the Apple A7 processor and the Apple M7 motion <b>coprocessor,</b> and reduced the thickness {{for the first time}} since the iPad 2. The iPad Air 2 added the Apple A8X processor, the Apple M8 motion <b>coprocessor,</b> an 8-megapixel camera, and the Touch ID fingerprint sensor; and further reduced the thickness. The iPad introduced in 2017 added the Apple A9 processor, while sacrificing some of the improvements the iPad Air 2 introduced in exchange for a lower launch price.|$|E
5|$|Both models {{include an}} Apple A8 system-on-chip, and an M8 motion co-processor—an update of the M7 chip from the iPhone 5s. The primary {{difference}} between the M8 and the original M7 <b>coprocessor</b> is that the M8 also includes a barometer to measure altitude changes. Phil Schiller touted that the A8 chip would provide, {{in comparison to the}} 5s, a 25% increase in CPU performance, a 50% increase in graphics performance, and less heat output. Early hands-on reports suggested that the A8's GPU performance might indeed break away from previous generations doubling of performance at each yearly release, scoring 21204.26 in Base mark X compared to 20253.80, 10973.36 and 5034.75 on respectively the 5s, 5 and 4s.|$|E
40|$|As chip {{designers}} {{face the}} prospect of increasingly dark silicon, there is increased interest in incorporating energy-efficient specialized <b>coprocessors</b> into general-purpose designs. For specialization to be a viable means of leveraging dark silicon, it must provide energy savings over the majority of execution for large, diverse workloads, and this will require deploying <b>coprocessors</b> in large numbers. Recent work has shown that automatically-generated application-specific <b>coprocessors</b> can greatly improve energy efficiency, {{but it is not clear}} that current techniques will scale to coprocessor-dominated architec-tures (CoDAs) with hundreds or thousands of <b>coprocessors.</b> We show that scaling CoDAs to include very large numbers of <b>coprocessors</b> is challenging because of the energy cost of interconnects, the memory system, and leakage. These overheads grow with the number of <b>coprocessors</b> and, left unchecked, will squander the energy gains that <b>coprocessors</b> can provide. The paper presents a detailed study of energy costs across a wide range of tiled CoDA designs and shows that careful choice of cache configuration, tile size, coarse-grain power management, and transistor implementation can limit the growth of these overheads. For multi-threaded workloads, designers must also take care to avoid excessive contention for <b>coprocessors,</b> which can significantly increase energy consumption. The results suggest that, for CoDAs that target larger workloads, amortizing shared overheads via multithreading can provide u...|$|R
50|$|During {{the era of}} 8- and 16-bit desktop {{computers}} another common source of floating-point <b>coprocessors</b> was Weitek. These <b>coprocessors</b> had a different instruction set from the Intel <b>coprocessors,</b> and used a different socket, which not all motherboards supported. The Weitek processors did not provide transcendental mathematics functions (for example, trigonometric functions) like the Intel x87 family, and required specific software libraries to support their functions.|$|R
40|$|The Dyad {{project at}} Carnegie Mellon University is using {{physically}} secure <b>coprocessors</b> to achieve new protocols and systems addressing {{a number of}} perplexing security problems. These <b>coprocessors</b> can be produced as boards or integrated circuit chips and can be directly inserted in standard workstations or PC-style computers. This paper presents a set of security problems and easily implementable solutions that exploit the power of physically secure coprocessors: (1) protecting the integrity of publicly accessible workstations, (2) tamper-proof accounting/audit trails, (3) copy protection, and (4) electronic currency without centralized servers. We outline the architectural requirements {{for the use of}} secure <b>coprocessors.</b> 1 Introduction and Motivation The Dyad project at Carnegie Mellon University is using physically secure <b>coprocessors</b> to achieve new protocols and systems addressing a number of perplexing security problems. These <b>coprocessors</b> can be produced as boards or integrated [...] ...|$|R
25|$|In other cases, chip {{designers}} only integrate hardware {{using the}} <b>coprocessor</b> mechanism. For example, an image processing engine {{might be a}} small ARM7TDMI core combined with a <b>coprocessor</b> that has specialised operations to support {{a specific set of}} HDTV transcoding primitives.|$|E
25|$|The {{processors}} {{are available}} {{in a variety of}} speeds including 8 and 16MHz configurations, producing 2,100 and 4,376Dhrystones each. These processors have no floating-point unit, {{and it is difficult to}} implement an FPU <b>coprocessor</b> (MC68881/2) with one because the EC series lacks necessary <b>coprocessor</b> instructions.|$|E
25|$|In ARM-based machines, {{peripheral}} {{devices are}} usually {{attached to the}} processor by mapping their physical registers into ARM memory space, into the <b>coprocessor</b> space, or by connecting to another device (a bus) that in turn attaches to the processor. <b>Coprocessor</b> accesses have lower latency, so some peripherals—for example, an XScale interrupt controller—are accessible in both ways: through memory and through coprocessors.|$|E
50|$|The Apple M-series <b>coprocessors</b> are motion <b>coprocessors</b> used by Apple Inc. {{in their}} mobile devices. First {{released}} in 2013, their {{function is to}} collect sensor data from integrated accelerometers, gyroscopes and compasses and offload the collecting and processing of sensor data from the main central processing unit (CPU).|$|R
50|$|Companies {{that have}} {{designed}} or manufactured floating point units {{compatible with the}} Intel 8087 or later models include AMD (287, 387, 486DX, 5x86, K5, K6, K7, K8), Chips and Technologies (the Super MATH <b>coprocessors),</b> Cyrix (the FasMath, Cx87SLC, Cx87DLC, etc., 6x86, Cyrix MII), Fujitsu (early Pentium Mobile etc.), Harris Semiconductor (manufactured 80387 and 486DX processors), IBM (various 387 and 486 designs), IDT (the WinChip, C3, C7, Nano, etc.), IIT (the 2C87, 3C87, etc.), LC Technology (the Green MATH <b>coprocessors),</b> National Semiconductor (the Geode GX1, Geode GXm, etc.), NexGen (the Nx587), Rise Technology (the mP6), ST Microelectronics (manufactured 486DX, 5x86, etc.), Texas Instruments (manufactured 486DX processors etc.), Transmeta (the TM5600 and TM5800), ULSI (the Math·Co <b>coprocessors),</b> VIA (the C3, C7, and Nano, etc.), and Xtend (the 83S87SX-25 and other <b>coprocessors).</b>|$|R
50|$|As of 2013, these {{used the}} Xeon Phi <b>coprocessors.</b>|$|R
25|$|A floating-point unit (FPU, colloquially a math <b>coprocessor)</b> {{is a part}} of a {{computer}} system specially designed to carry out operations on floating-point numbers.|$|E
25|$|Some {{devices such}} as the ARM Cortex-A8 have a cut-down VFPLite module instead of a full VFP module, and require roughly ten times more clock cycles per float operation. Pre-ARMv8 {{architecture}} implemented floating-point/SIMD with the <b>coprocessor</b> interface. Other floating-point and/or SIMD units found in ARM-based processors using the <b>coprocessor</b> interface include FPA, FPE, iwMMXt, {{some of which were}} implemented in software by trapping but could have been implemented in hardware. They provide some of the same functionality as VFP but are not opcode-compatible with it.|$|E
25|$|MIPS III added a {{supervisor}} privilege level {{in between the}} existing kernel and user privilege levels. This feature only affected the implementation-defined System Control Processor (<b>Coprocessor</b> 0).|$|E
5000|$|Support for {{multiple}} external <b>coprocessors</b> through an accelerated communication interface ...|$|R
40|$|This paper {{presents}} a structured application design trajectory to transform media-processing applications— modeled as Kahn process network—into {{a set of}} functionspecific hardware units called <b>coprocessors.</b> The proposed design trajectory focuses on identifying hardwareimplementable computation kernels that are common for a predetermined set of applications. The design trajectory is exercised in a case study that maps MPEG video decoding and encoding applications onto a set of <b>coprocessors</b> in a heterogeneous multiprocessor architecture. The resulting set of <b>coprocessors</b> can simultaneously perform both encoding and decoding functions for multiple MPEG- 2 streams in an estimated 4 mm 2 (excluding memory) in 0. 18 µ technology 1...|$|R
5000|$|A {{pre-production}} {{configuration of}} Stampede {{was listed as}} the 7th fastest supercomputer on the November 2012 Top500 list with a delivered performance of 2660 TFlops. Because the system was still being assembled, the submitted benchmark was run using 1875 nodes with Xeon Phi <b>coprocessors</b> and 3900 nodes without Xeon Phi <b>coprocessors.</b> [...] For the June 2013 Top500 list, the benchmark was re-run using 6006 nodes (all with Xeon Phi <b>coprocessors),</b> delivering 5168 TFlops and moving the system up to 6th place. The benchmark was not re-run for the November 2013 Top500 list and Stampede dropped back to the 7th position.|$|R
25|$|Adapteva epiphany is {{targeted}} as a <b>coprocessor,</b> featuring a network on a chip scratchpad memory model, {{suitable for a}} dataflow programming model, which should be suitable for many machine learning tasks.|$|E
25|$|MIPS III {{removed the}} <b>Coprocessor</b> 3 (CP3) support instructions, and reused its opcodes {{for the new}} doubleword instructions. The {{remaining}} coprocessors gained instructions to move doublewords between <b>coprocessor</b> registers and the GPRs. The floating general registers (FGRs) were extended to 64 bits and the requirement for instructions to use even-numbered register only was removed. This is incompatible with earlier versions of the architecture; {{a bit in the}} floating-point control/status register is used to operate the MIPS III floating-point unit (FPU) in a MIPS I- and II-compatible mode. The floating-point control registers were not extended for compatibility. The only new floating-point instructions added were those to copy doublewords between the CPU and FPU convert single- and double-precision floating-point numbers into doubleword integers and vice versa.|$|E
25|$|In {{particular}} hardware abstraction {{does not}} involve abstracting the instruction set, which generally falls under the wider concept of portability. Abstracting the instruction set, when necessary (such as for handling the several revisions to the x86 instruction set, or emulating a missing math <b>coprocessor),</b> is performed by the kernel, or via hardware virtualization.|$|E
40|$|Principles of {{representation}} of a class of trigonometric functions by specialized <b>coprocessors.</b> The work is aimed at development of techniques of accelerated computation of trigonometrical functions and structures of <b>coprocessors</b> for their realization. Bitable-algorithmic technique of accelerated calculation of trigonometric functions, digital analog and analog-digital versions of structures of <b>coprocessors</b> for calculating trigonometric functions are developed. The developed technique and structures of <b>coprocessors</b> for calculating trigonometric functions {{made it possible to}} increase substantially the operational efficiency of the simulation complex. The bitable-algorithmic technique of accelerated calculation of trigonometric functions, as well as the principle of application of approximate relations are implemented. The time of calculation of the functions is reduced, the computational process of the trigonometric functions as a whole is simplified. The field of application covers computational systems used on simulationof robotic systems and aircraft control systemsAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The main {{topic of}} this thesis is the {{implementation}} and subsequent optimization of high performance applications on {{a cluster of}} Intel Xeon Phi <b>coprocessors.</b> Using two approaches to solve the N-Body problem, the possibilities of the program execution on a cluster of processors, <b>coprocessors</b> or both device types have been demonstrated. Two particular versions of the N-Body problem have been chosen - the naive and Barnes-hut. Both problems have been implemented and optimized. For better comparison of the achieved results, we only considered achieved acceleration against single node runs using processors only. In {{the case of the}} naive version a 15 -fold increase has been achieved when using combination of processors and <b>coprocessors</b> on 8 computational nodes. The performance in this case was 9 TFLOP/s. Based on the obtained results we concluded {{the advantages and disadvantages of}} the program execution in the distributed environments using processors, <b>coprocessors</b> or both...|$|R
50|$|On August 19, 2012, Adapteva posted some {{specifications}} {{and information}} about Epiphany multi-core <b>coprocessors.</b>|$|R
25|$|As a {{sophisticated}} computer for its day (Amiga used 25 DMA channels and a <b>coprocessor),</b> Sassenrath {{decided to create}} a preemptive multitasking operating system within a microkernel design. This was a novel approach for 1983 when other personal computer operating systems were single tasking such as MS-DOS (1981) and the Macintosh (1984).|$|E
25|$|Both device {{variants}} {{also contain}} a new iteration of Apple's motion <b>coprocessor,</b> the M10. Unlike previous iPhone models, internal storage options for iPhone 7 begin at 32GB instead of 16GB, and max out at 256GB. iPhone 7 Plus offers 3GB of RAM, {{more than any}} other previous iPhone; the 4.7-inch iPhone 7 has 2GB.|$|E
25|$|Channel {{architecture}} avoids {{this problem}} by using a separate, independent, low-cost processor. Channel processors are simple, but self-contained, with minimal logic and sufficient on-board scratchpad memory (working storage) to handle I/O tasks. They are typically not powerful or flexible enough {{to be used as}} a computer on their own and can be construed as a form of <b>coprocessor.</b>|$|E
5000|$|Official {{support for}} <b>coprocessors</b> via HTX slots and vacant CPU sockets through HyperTransport: Torrenza initiative.|$|R
5000|$|Virginia Tech, Advanced Research Computing (ARC) - Blue-Ridge Supercomputer (2011) {{featuring}} Intel Xeon Phi <b>coprocessors</b> ...|$|R
30|$|Heterogeneous {{embedded}} systems combine {{the peculiarities of}} traditional {{embedded systems}} (little available memory and exotic architectures among others) with the complexity of having many processors of different architectures on the same board. Usually, some processors {{are referred to as}} masters as they are the main cores, typically running a high-level OS (HLOS) like Linux, and offloading work to some <b>coprocessors</b> (slaves). Even though some <b>coprocessors</b> could run an HLOS [1], we assume in this paper that they are used as bare-metal units, as this brings the most compelling challenges. This is a reasonable assumption since those <b>coprocessors</b> are mostly used to perform very specific tasks and should not be disturbed by any other processes.|$|R
25|$|As part of {{the overall}} plan for the SNES, rather than include an {{expensive}} CPU that would still become obsolete in a few years, the hardware designers made it easy to interface special <b>coprocessor</b> chips to the console, just like the MMC chips used for most NES games. This is most often characterized by 16 additional pins on the cartridge card edge.|$|E
25|$|The {{instruction}} {{set for the}} floating point <b>coprocessor</b> also had several instructions added to it. An IEEE 754-compliant floating-point square root instruction was added. It supported both single- and double-precision operands. A set of instructions that converted single- and double-precision floating-point numbers to 32-bit words were added. These complemented the existing conversion instructions by allowing the IEEE rounding mode to be specified by the instruction instead of the Floating Point Control and Status Register.|$|E
25|$|MIPS is a modular {{architecture}} supporting {{up to four}} coprocessors (CP0/1/2/3). In MIPS terminology, CP0 is the System Control <b>Coprocessor</b> (an {{essential part of the}} processor that is implementation-defined in MIPS IV), CP1 is an optional floating-point unit (FPU) and CP2/3 are optional implementation-defined coprocessors (MIPS III removed CP3 and reused its opcodes for other purposes). For example, in the PlayStation video game console, CP2 is the Geometry Transformation Engine (GTE), which accelerates the processing of geometry in 3D computer graphics.|$|E
40|$|The paper {{demonstrates}} the optimization of the execution en-vironment of a hybrid OpenMP+MPI {{computational fluid dynamics}} code (shallow water equation solver) on a cluster enabled with Intel Xeon Phi <b>coprocessors.</b> The discussion includes: 1. Controlling the number and affinity of OpenMP threads to optimize access to memory bandwidth; 2. Tuning the inter-operation of OpenMP and MPI to partition the problem for better data locality; 3. Ordering the MPI ranks {{in a way that}} directs some of the traffic into faster communication channels; 4. Using efficient peer-to-peer communication between Xeon Phi <b>coprocessors</b> based on the InfiniBand fabric. With tuning, the application has 90 % percent efficiency of par-allel scaling up to 8 Intel Xeon Phi <b>coprocessors</b> in 2 comput...|$|R
40|$|Biological Information Signal Processor (BISP) is {{computing}} system analyzing data on deoxyribonucleic acid (DNA) sequences for molecular genetic analysis. Includes <b>coprocessors,</b> specialized microprocessors complementing {{present and future}} computers by performing rapidly most-time-consuming DNA-sequence-analyzing functions, establishing relationships (alignments) between both global sequences and defining patterns in multiple sequences. Also includes state-of-art software and data-base systems on both conventional and parallel computer systems to augment analytical abilities of developmental <b>coprocessors...</b>|$|R
50|$|In 1991, S3 Graphics {{introduced}} the S3 86C911, which its designers {{named after the}} Porsche 911 as an implication of the performance increase it promised. The 86C911 spawned a host of imitators: by 1995, all major PC graphics chip makers had added 2D acceleration support to their chips. By this time, fixed-function Windows accelerators had surpassed expensive general-purpose graphics <b>coprocessors</b> in Windows performance, and these <b>coprocessors</b> faded away from the PC market.|$|R
