32|1447|Public
50|$|Persistent Rice adaptation, using a Rice <b>coding</b> <b>parameter</b> {{derivation}} for {{entropy coding}} that has memory that persists across transform coefficient sub-block boundaries.|$|E
5000|$|ECMA-407 {{specifies}} {{the base}} S5 encoder and decoder {{in terms of}} configuration data, downmix, inverse <b>coding</b> <b>parameter</b> data and upmix. In addition it provides reference and guidance on how to incorporate further components to form a scalable multichannel coding system for audio data compression.|$|E
30|$|In future work, we {{will extend}} this {{approach}} to other <b>coding</b> <b>parameter</b> configurations that take transmission effects and user environments into consideration. Moreover, we will also explore ways to reduce computational complexity.|$|E
3000|$|... value, and the LP based <b>code</b> <b>parameter</b> {{optimization}} are all {{included in}} a single repeat-until loop. This indicates that the <b>code</b> <b>parameters</b> are also changed in the EBSA framework.|$|R
3000|$|... [...]. This {{designed}} {{family has}} more flexible <b>code</b> <b>parameters</b> {{when compared to}} the family of Hamming <b>codes</b> having the <b>parameters</b> [...]...|$|R
3000|$|... [...])=l). Thus, {{the value}} of the rank {{deficiency}} depends on <b>code</b> <b>parameters</b> (k and n). Indeed, only two consecutive rank deficiencies are necessary to determine all <b>code</b> <b>parameters.</b> The <b>code</b> word length n can be determined by the difference between two values of l corresponding to two consecutive rank deficiencies of R [...]...|$|R
40|$|We {{present a}} new method for {{lossless}} image compression that gives compression comparable to JPEG lossless mode with {{about five times}} the speed. Our method, called FELICS, {{is based on a}} novel use of two neighboring pixels for both prediction and error modeling. For coding we use single bits, adjusted binary codes, and Golomb or Rice codes. For the latter we present and analyze a provably good method for estimating the single <b>coding</b> <b>parameter...</b>|$|E
40|$|Electronic travel aids (ETAs) can {{potentially}} increase {{the safety and}} comfort of blind users by detecting and displaying obstacles outside {{the range of the}} white cane. In a series of experiments, we aim to balance the amount of information displayed and the comprehensibility of the information taking into account the risk of information overload. In Experiment 1, we investigate perception of compound signals displayed on a tactile vest while walking. The results confirm that the threat of information overload is clear and present. Tactile coding parameters that are sufficiently discriminable in isolation may not be so in compound signals and while walking and using the white cane. Horizontal tactor location is a strong <b>coding</b> <b>parameter,</b> and temporal pattern is the preferred secondary <b>coding</b> <b>parameter.</b> Vertical location is also possible as <b>coding</b> <b>parameter</b> but it requires additional tactors and makes the display hardware more complex and expensive and less user friendly. In Experiment 2, we investigate how we can off-load the tactile modality by mitigating part of the information to an auditory display. Off-loading the tactile modality through auditory presentation is possible, but this off-loading is limited and may result in a new threat of auditory overload. In addition, taxing the auditory channel may in turn interfere with other auditory cues from the environment. In Experiment 3, we off-load the tactile sense by reducing the amount of displayed information using several filter rules. The resulting design was evaluated in Experiment 4 with visually impaired users. Although they acknowledge the potential of the display, the added of the ETA as a whole also depends on its sensor and object recognition capabilities. We recommend to use not more than two coding parameters in a tactile compound message and apply filter rules {{to reduce the amount of}} obstacles to be displayed in an obstacle avoidance ETA...|$|E
40|$|Basic {{characteristics}} of digital data transmission systems described include the physical communication links, {{the notion of}} bandwidth, FCC regulations, and performance measurements such as bit rates, bit error probabilities, throughputs, and delays. The error probability performance and spectral {{characteristics of}} various modulation/demodulation techniques commonly used or proposed for use in radio and satellite communication links are summarized. Forward error correction with block or convolutional codes is also discussed along with the important <b>coding</b> <b>parameter,</b> channel cutoff rate...|$|E
30|$|The {{overhead}} {{reduces the}} efficiency of the design (overall code rate) especially when designing for large <b>code</b> <b>parameters.</b> However, as the packets size increases, the efficiency improves. Therefore, the design is applicable to packets of any size provided that they are not very small. For moderate <b>code</b> <b>parameters,</b> packets of few hundred bits (all network standards requires even more than this) are good enough that will not affect {{the efficiency of}} the code very much. For large <b>code</b> <b>parameters,</b> the efficiency can be improved by increasing the packet size and/or by utilizing the mentioned ways of reducing the overhead.|$|R
5000|$|... error <b>code</b> (<b>{{parameter}}</b> 1, parameter 2, parameter 3, parameter 4) error name ...|$|R
5000|$|Small {{memory dump}} {{contains}} various info {{such as the}} stop <b>code,</b> <b>parameters,</b> list of loaded device drivers, etc.|$|R
3000|$|... (x) is {{a factor}} of the {{codeword}} polynomial, {{it is just the}} mean value of the probabilities that the syndromes equal to zero. The true probability should be obtained by calculating the probability that all syndromes equal to zero. But as shown in section 3.2, the probability that all syndromes equal to zero is determined by the degree of the corresponding minimal polynomial for incorrect <b>coding</b> <b>parameter</b> estimations, the probability distribution is not uniform. But we use the mean value of P [...]...|$|E
40|$|International Telemetering Conference Proceedings / November 14 - 16, 1978 / Hyatt House Hotel, Los Angeles, CaliforniaThe {{performance}} of two coded communication systems is compared. The {{first one is}} obtained when the system modulation is coherent PSK. The second system results when the modulation is noncoherent FSK. The <b>coding</b> <b>parameter</b> adopted to evaluate the system performance is the cut-off rate. A second parameter called coded throughput {{is derived from the}} cut-off rate and utilized to effectively compare the {{performance of}} the two coded systems under consideration...|$|E
40|$|Abstract This paper {{represents}} a new hand shape representationtechnique that characterises the finger-only topology of the hand, by adapting an existing technique from speech signalprocessing. From a moving hand sequence, the tracking algorithm determines {{the centre of}} the largest convex subsetof the hand, using a combination of pattern matching and condensation algorithms. A hand shape feature representsthe topological formation of the finger-only regions of the hand using a Linear Predictive <b>Coding</b> <b>parameter</b> set calledcepstral coefficients. Experimental results demonstrate the effectiveness of detecting the shape feature from motion se-quences...|$|E
40|$|The recent {{growth in}} {{personal}} wireless communication devices {{being used for}} image transmission, have poised a challenge to protect this data against loss over mobile radio channels. The paper addresses this problem investigating error protection schemes {{in the context of}} JPEG 2000 compressed imagery. More particularly, the results reported in this paper provide coding guidelines concerning the selection of appropriate Turbo <b>code</b> <b>parameters</b> along with JPEG 2000 <b>coding</b> <b>parameters</b> mentioned in [2]. 1...|$|R
40|$|We assign binary and ternary error-correcting {{codes to}} the data of {{syntactic}} structures of world languages and we study the distribution of code points {{in the space of}} <b>code</b> <b>parameters.</b> We show that, while most codes populate the lower region approximating a superposition of Thomae functions, there is a substantial presence of codes above the Gilbert-Varshamov bound and even above the asymptotic bound and the Plotkin bound. We investigate the dynamics induced on the space of <b>code</b> <b>parameters</b> by spin glass models of language change, and show that, in the presence of entailment relations between syntactic parameters the dynamics can sometimes improve the code. For large sets of languages and syntactic data, one can gain information on the spin glass dynamics from the induced dynamics in the space of <b>code</b> <b>parameters.</b> Comment: 14 pages, LaTeX, 12 png figure...|$|R
3000|$|... • Following the {{approach}} of [22], we use Bernstein’s inequality and Bennett’s inequality to upper bound the false-positive and false-negative error probability, respectively. From these bounds, we derive conditions on the <b>code</b> <b>parameters</b> (<b>code</b> length, cutoff, threshold) such that the error probabilities are sufficiently low.|$|R
40|$|Highly {{scalable}} {{video compression}} based on invertible motion adaptive lifting transforms {{has emerged as}} a promising area in im-age processing research and an important component in interactive multimedia technology. However, within this feed-forward frame-work, the potential for coding efficiency improvement and its im-pact on random accessibility still has not been carefully assessed. In this paper, we compare the merits of several three-dimensional context coding strategies from an information-theoretic perspec-tive. The variation in random access cost in response to <b>coding</b> <b>parameter</b> adjustments is analyzed, for a variety of spatial and tem-poral configurations. 1...|$|E
40|$|This paper {{represents}} a new hand shape representation technique that characterises the finger-only topology of the hand, by adapting an existing technique from speech signal processing. From a moving hand sequence, the tracking algorithm determines {{the centre of}} the largest convex subset of the hand, using a combination of pattern matching and condensation algorithms. A hand shape feature represents the topological formation of the finger-only regions of the hand using a Linear Predictive <b>Coding</b> <b>parameter</b> set called cepstral coefficients. Experimental results demonstrate the effectiveness of detecting the shape feature from motion sequences. ...|$|E
40|$|A low-complexity circuit for on-sensor {{compression}} is presented. The proposed circuit achieves complexity savings {{by combining}} a single-slope analog-to-digital converter with a Golomb-Rice entropy encoder and by implementing a low-complexity adaptation rule. The adaptation rule monitors the output codewords and minimizes their length by incrementing or decrementing {{the value of}} the Golomb-Rice <b>coding</b> <b>parameter</b> k. Its hardware implementation is one order of magnitude lower than existing adaptive algorithms. The compression circuit has been fabricated using a 0. 35 micrometers CMOS technology and occupies an area of 0. 0918 mm 2. Test measurements confirm the validity of the desig...|$|E
3000|$|... ● The {{transfer}} speed between CEC and VM cannot be neglected, {{especially if the}} internet connection is slower and large data sets must be transmitted (e.g., input data, <b>code,</b> <b>parameter).</b>|$|R
40|$|Multiple {{description}} {{motion compensation}} (MDMC) is a multiple description video coding scheme that has shown good error resilience performance. MDMC enables one to vary <b>coding</b> <b>parameters</b> {{according to the}} desired trade-off between coding efficiency and error resilience. To fully utilize this advantage, one needs to establish a set of models, relating the rate, encoder distortion, and the end-to-end distortion after transmission, with the encoder parameters and channel parameters. Using these models, one can find the optimal <b>coding</b> <b>parameters</b> for given channel parameters and rate (or distortion) constraints. In this paper, we formulate and validate the rate and encoder distortion models...|$|R
3000|$|... is also determined, {{which reduces}} the {{broadcast}} phase design to optimization of the EW RLC <b>code</b> <b>parameter</b> Γ(BS)(ξ) {{such that the}} average received video quality D is maximized after the target system delay T.|$|R
30|$|Here, the {{rate-distortion}} (RD) {{performance of}} the proposed SI generation methods along with a coding time comparison is presented. We also present the RD {{performance of the}} spatial scalable coder and compare it to conventional coding. Such a coder is based in previous studies for optimal <b>coding</b> <b>parameter</b> selection [27] and correlated statistic estimation [28]. The results of the temporal scalable coder in the transform domain are known, and normally outperform simple intracoding, but underperforms zero-motion vector coding, depending on the sequence [29]. The entire tests were implemented using the state-of-the-art standard H. 264 /AVC as the conventional codec.|$|E
30|$|Some prior work towards more {{efficient}} subjective testing exists. It {{has been proposed}} {{that in some cases}} a range of values for a single video <b>coding</b> <b>parameter</b> can be searched for a quality maximum by setting up an interactive control (e.g., a slider) and allowing subjects to adjust it at will until a maximal level of video quality is perceived [10]. One might seek to extend this to multiple parameters, in which case subjects could be facing very difficult and lengthy tasks. GAST naturally searches multiple dimensions while test subjects interact with the same simple univariate PC or ACR test protocol.|$|E
40|$|In {{order to}} apply UWB {{technology}} to a communication system, channel measurement {{and analysis of}} UWB signals in the 3. 1 ~ 10. 6 GHz frequency-band become necessary. This paper presents the propagation measurement results for the devices based on the Direct Sequence Ultra Wideband (DS-UWB) technology, which includes the open-space channel, emulated conditions for channels inside an aircraft, as well as measurements inside a large aircraft. The measurements and performance evaluations focus on the BER vs. power level, data-rate, <b>coding</b> <b>parameter</b> and range. The set of collected parameters from our experiment results {{may be used to}} develop realistic models for a range of UWB channel...|$|E
3000|$|In this article, we {{proposed}} a parameters’ optimization scheme in order to eliminate uncertainties when selecting <b>coding</b> <b>parameters.</b> Compare with existing methods, our approach builds a relationship map of the quantization parameter QP [...]...|$|R
40|$|A {{method of}} blind {{recognition}} of the <b>coding</b> <b>parameters</b> for binary Bose-Chaudhuri-Hocquenghem (BCH) codes is proposed in this paper. We consider an intelligent communication receiver which can blindly recognize the <b>coding</b> <b>parameters</b> of the received data stream. The only knowledge is that the stream is encoded using binary BCH codes, while the <b>coding</b> <b>parameters</b> are unknown. The problem can be addressed on {{the context of the}} non-cooperative communications or adaptive coding and modulations (ACM) for cognitive radio networks. The recognition processing includes two major procedures: code length estimation and generator polynomial reconstruction. A hard decision method has been proposed in a previous literature. In this paper we propose the recognition approach in soft decision situations with Binary-Phase-Shift-Key modulations and Additive-White-Gaussian-Noise (AWGN) channels. The code length is estimated by maximizing the root information dispersion entropy function. And then we search for the code roots to reconstruct the primitive and generator polynomials. By utilizing the soft output of the channel, the recognition performance is improved and the simulations show the efficiency of the proposed algorithm...|$|R
40|$|In {{this paper}} we propose the {{application}} of a new transform-based coding method[1] in conjunction with Golomb-Rice () codes to lower significantly the complexity, which can be used in various applications, e. g. the Multiple Description coding[2]. The theoretical evaluations predict no important loss in compression performance, while the complexity is considerably reduced. Since codes are very fast and well suited for exponentially decaying distributions, they were implemented during the last decade in image and audio compressors. In all these schemes, the selection of the <b>code</b> <b>parameter</b> is performed presuming Laplacian distribution of prediction errors. We derive the selection method for the <b>code</b> <b>parameter</b> also for the case of Gaussian inputs. 1...|$|R
40|$|In {{order to}} get {{accurately}} the coding characteristics of current basic unit, a novel adaptive coding characteristic prediction scheme called texture-complexity estimation is proposed. Through adaptive linear texture-complexity and overhead prediction model as well as optimum bits allocation scheme, we can obtain current basic unit <b>coding</b> <b>parameter</b> such as texture-complexity, overhead bits count and texture bits budget, and then the quantization parameter can be directly calculated. Simulation {{results show that the}} H. 264 encoder, using the proposed rate control algorithm, achieves a visual quality improvement up to 0. 388 dB, meets better with target bit rates and produces more flat bit-rate curve than that using the H. 264 previous rate control method (JVT-G 012) ...|$|E
40|$|Much {{attention}} has been paid to the problem of optimally utilizing resources such as spectrum, power and time in order to achieve the best video delivery quality in wireless communications system, due to the fueling demand for such applications. In this work, we present a joint source coding and data adaptation scheme for downlink video transmission in a multi-user wireless network. We formulate a rate-distortion optimization problem, where the source coding and data rate are jointly designed according to the changing channel conditions. In addition, transmissions ofvideo packets are optimally scheduled through exploiting the multi-user diversity. We solve the problem using abackward stochastic dynamical programming approach, and the simulation results have shown the advantage of the joint selection of source <b>coding</b> <b>parameter</b> and transmission rate coupled with optimal packet scheduling. 1...|$|E
30|$|The {{paradigm}} shift of network design from performance-centric to constraint-centric {{has called for}} new signal processing techniques to deal with various aspects of resource-constrained communication and networking. In this paper, we consider the computational constraints of a multimedia communication system and propose a video adaptation mechanism for live video streaming of multiple channels. The video adaptation mechanism includes three salient features. First, it adjusts the computational resource of the streaming server block by block to provide a fine control of the encoding complexity. Second, {{as far as we}} know, it is the first mechanism to allocate the computational resource to multiple channels. Third, it utilizes a complexity-distortion model to determine the optimal <b>coding</b> <b>parameter</b> values to achieve global optimization. These techniques constitute the basic building blocks for a successful application of wireless and Internet video to digital home, surveillance, IPTV, and online games.|$|E
30|$|In this section, {{we discuss}} some {{specific}} cases {{for the design}} of erasure codes proposed in this paper. We demonstrate the PLR reduction capability of these codes through analytical calculations and simulation results for different <b>code</b> <b>parameters.</b>|$|R
5000|$|The ATR {{starts with}} a header of 32 bits {{organized}} into 4 bytes, denoted H1 to H4. H1 codes the protocol (with [...] and [...] being invalid), H2 <b>codes</b> <b>parameters</b> of the protocol. Little more is standardized.|$|R
40|$|We {{demonstrate}} propagation {{rules of}} subsystem code constructions by extending, shortening and combining given subsystem codes. Given an [[n,k,r,d]]_q subsystem code, we drive new subsystem <b>codes</b> with <b>parameters</b> [[n+ 1,k,r,≥ d]]_q, [[n- 1,k+ 1,r,≥ d- 1]]_q, [[n,k- 1,r+ 1,d]]_q. The interested readers shall consult our companion papers for {{upper and lower}} bounds on subsystem <b>codes</b> <b>parameters,</b> and introduction, trading dimensions, families, and references on subsystem codes [1][2][3] and references therein. Comment: Private comments are welcom...|$|R
