4|7|Public
40|$|Abstract. This paper {{proposes a}} Domotic OSGi Gateway (DOG) able to expose {{different}} domotic networks as a single, technology neutral, home automation system. The {{adoption of a}} standard framework such as OSGi, and of sophisticated modeling techniques stemming from the Semantic Web research community, allows DOG to go beyond simple automation and to support reasoning-based intelligence inside home environments. By exploiting the DogOnt ontology for automatic device generalization, syntactic and semantic <b>command</b> <b>validation,</b> and internetwork scenario definition, DOG provides the building blocks for evolving current, isolated, home automation plants into so-called Intelligent Domotic Environments, where heterogeneous devices and domotic systems are coordinated to behave as a single, intelligent, proactive system. The paper introduces the DOG architecture by looking at functionalities provided by each of its components and by describing features that exploit ontology-modeling. ...|$|E
40|$|This paper moves a {{first step}} towards the {{creation}} of Intelligent Domotic Environments (IDE) in real-life home-living. A new Domotic OSGi Gateway (DOG) is presented, able to manage different domotic networks as a single, technology neutral, home automation system. The adoption of a standard framework such as OSGi, and of sophisticated modeling techniques stemming from the Semantic Web research community, allows DOG to go beyond simple automation and to support reasoning-based intelligence inside home environments. By exploiting automatic device generalization, syntactic and semantic <b>command</b> <b>validation,</b> and internetwork scenario definition, DOG provides the building blocks for supporting the evolution of current, isolated, home automation plants into IDEs, where heterogeneous devices and domotic systems are coordinated to behave as a single, intelligent, proactive system. The paper introduces the DOG architecture and the underlying ontology modeling. A case study is also illustrated, where DOG controls a laboratory reconstruction of a simple domotic environmen...|$|E
40|$|Abstract — This paper moves a {{first step}} towards the {{creation}} of Intelligent Domotic Environments (IDE) in real-life home-living. A new Domotic OSGi Gateway (DOG) is presented, able to manage different domotic networks as a single, technology neutral, home automation system. The adoption of a standard framework such as OSGi, and of sophisticated modeling techniques stemming from the Semantic Web research community, allows DOG to go beyond simple automation and to support reasoning-based intelligence inside home environments. By exploiting automatic device generalization, syntactic and semantic <b>command</b> <b>validation,</b> and inter-network scenario definition, DOG provides the building blocks for supporting the evolution of current, isolated, home automation plants into IDEs, where heterogeneous devices and domotic systems are coordinated to behave as a single, intelligent, proactive system. The paper introduces the DOG architecture and the underlying ontology modeling. A case study is also illustrated, where DOG controls a laboratory reconstruction of a simple domotic environment 1. Index Terms — System architectures, integration and modeling, Ubiquitous computing, Rule-based processing, Knowledge modeling...|$|E
50|$|YAML {{is purely}} a data {{representation}} language and thus has no executable <b>commands.</b> While <b>validation</b> and safe parsing is inherently possible in any data language, implementation {{is such a}} notorious pitfall that YAML's lack of an associated command language may be a relative security benefit.|$|R
40|$|Software {{added to}} {{compiler}} for automated test system for Space Shuttle decreases computer run errors by providing offline validation of engineering units used system <b>command</b> programs. <b>Validation</b> procedures are general, though originally written for GOAL, a free-form language that accepts "English-like" statements, {{and may be}} adapted to other programming languages...|$|R
40|$|Abstract. In {{recent years}} {{videogame}} companies {{have recognized the}} role of player engagement as {{a major factor in}} user experience and enjoyment. This en-couraged a greater investment in new types of game controllers such as the WiiMote™, Rock Band ™ instruments and the Kinect™. However, the native software of these controllers was not originally designed to be used in other game applications. This work addresses this issue by building a middleware framework, which maps body poses or voice commands to actions in any game. This not only warrants a more natural and customized user-experience but it al-so defines an interoperable virtual controller. In this version of the framework, body poses and voice commands are respectively recognized through the Ki-nect’s built-in cameras and microphones. The acquired data is then translated into the native interaction scheme in real time using a lightweight method based on spatial restrictions. The system is also prepared to use Nintendo’s Wiimote ™ as an auxiliary and unobtrusive gamepad for physically or verbally impractical <b>commands.</b> System <b>validation</b> was performed by analyzing the per-formance of certain tasks and examining user reports. Both confirmed this ap-proach as a practical and alluring alternative to the game’s native interaction scheme. In sum, this framework provides a game-controlling tool that is totally customizable and very flexible, thus expanding the market of game consumers...|$|R
40|$|The {{initiation}} of the (German-) nationally funded control center for manned spaceflight operations {{triggered by the}} invitation of President Reagan to ESA, Japan, and Canada in 1984 to join the International Space Station Freedom Program is recalled. The requirements for a Manned Space-Laboratories Control Center (MSCC) as defined {{at the beginning of}} the planning and construction process in 1987 and the resulting modifications during the various programmatic scenario changes on NASA and ESA side between 1987 and now are presented. The validity of the original requirements with respect to the current scenario, which asks for a logical evolution from the execution of the D- 2 mission in January 1993 via the European Columbus Precursor flights (in particular the E- 1 mission) towards Columbus Attached Laboratory (APM) -operations by the end of this century are discussed. The resulting tasks of the MSCC for the various missions, the current configuration, and the ensuing operations concept leading from a more centralized concept for D- 2 towards a decentralized payload operations concept for the APM and the implications with respect to European and International interfaces are presented. The planned Columbus MSCC facility architecture and its expected modifications introduced by the ESA Ministerial Conference in Munich (Nov. 1991) and follow-on discussions are briefly addressed. The last chapter outlines the planned services to be provided by the MSCC to the decentralized User (experimenter) community. Issues like decentralized mission planning on executional level, <b>command</b> <b>validation,</b> data flow coordination, archiving services, and telescience capabilities are highlighted from a MSCC point of view...|$|E
40|$|One of Stata’s great {{strengths}} is {{its data}} management abilities. When either building or sharing datasets, {{some of the}} most time-consuming activities are validating the data and writing documentation for the data. Much of this futility could be avoided if datasets were self-contained, i. e., if they could validate themselves. I will show how to achieve this goal within Stata. I will demonstrate a package of <b>commands</b> for attaching <b>validation</b> rules to the variables themselves, via characteristics, along with commands for running error checks and marking suspicious observations in the dataset. The validation system is flexible enough that simple checks continue to work even if variable names change or if the data are reshaped, and it is rich enough that validation may depend on other variables in the dataset. Since the validation is at the variable level, the self-validation also works if variables are recombined with data from other datasets. With these tools, Stata’s datasets can become truly self-contained. ...|$|R
40|$|The {{bachelor}} thesis {{deals with}} extension of data extractor of public contracts gained from server Tenders Electronic Daily. The thesis covers a modularized extractor 10 {{new types of}} public contract notices. The data is retrieved from XML by using transformation scenario and they are extracted to RDF/XML data format. The extension is realized on TED-XML and META-XML formats of published data. The work also expands and creates independent library of functions. The library is documented. To ensure {{the accuracy of the}} extracted data in terms of syntax and also used ontologies there are used <b>validation</b> tools. For <b>command</b> line syntax <b>validation</b> Jena Apache Riot and for testing the correctness of output in terms of use Public Contracts Ontology RDFUnit testing tool. The contribution of this work is the practical part, allowing you to convert semi-structured data from the Journal of procurement of EU Member States into a fully structured data. Enhanced extractor allows you to extract data from the notices type F 04 - F 09 and F 15 - F 18...|$|R
40|$|The {{motivation}} {{for the present study}} is derived from the fact that time mangaement {{is an integral part of}} good engineering practice. The present study investigated the quantification of the required computation time using two nonlinear and harmonically excited oscillators (Pendulum and Duffing) as case studies. Simulations with personal computer were effected for Runge-Kutta schemes (RK 2, RK 3, RK 4, RK 5, RK 5 M) and one blend (RKB) over thirty five thousand and ten excitation periods consisting the unsteady and steady solutions. The need for validation of the developed FORTRAN 90 codes by comparing Poincare results with their conterpart from the literature informed the choice of simulation parameters. However, the simulation time was monitored at three lengths of excitation period (15000, 25000 and 35000) using the current time subroutine call <b>command.</b> The <b>validation</b> Poincaré results obtained for all the schemes including RKB compare well with the counterpart available in the literature for both Pendulum and Duffing. The actual computation time increases with increasing order of scheme, but suffered a decrease for the blended scheme. The diffencerence in computation time required between RK 5 and RK 5 M is negligible for all studied cases. The actual computational time for Duffing (5 - 33 seconds) remain consistently higher for corresponding Pendulum (3 - 23 seconds) with difference (2 - 10 seconds). Interestingly, the quantitative difference between the corresponding normalised computation time for systems and schemes is insignificant. It is insensitive to systems and schemes and formed a simple average ratio { (1. 0) : (1. 5) : (2. 0) : (3. 1) : (3. 1) : (2. 4) } for RK 2, RK 3, RK 4, RK 5, RK 5 M and RKB respectively. It is concluded that the end justified the means provided that computation accuracy is assured using the higher order scheme (with higher computational time ratio) ...|$|R

