3|10000|Public
40|$|In this paper, a {{proposal}} for OLSR protocol based upon <b>Boltzmann</b> <b>learning</b> <b>algorithm</b> is made. The main focus is to tune OLSR by using <b>Boltzmann</b> <b>learning</b> <b>algorithm.</b> The proposed work deals with the standardized OLSR routing protocol, {{to make it more}} reliable, more energy efficient and more adaptable to the rapidly changing network topology and infrastructure. This article therefore provides a simple mechanism for dynamic adoption of mobile nodes based on <b>Boltzmann</b> <b>learning</b> <b>algorithm</b> with OLSR. Then the paper provides a mathematical proof how Boltzmann Learning can be used in MANETs using OLSR...|$|E
40|$|The Boltzmann {{machine is}} a {{nonlinear}} network of stochastic binary processing units that interact pairwise through symmetric connection strengths. In a third-order Boltzmann machine, triples of units interact through symmetric conjunctive interactions. The <b>Boltzmann</b> <b>learning</b> <b>algorithm</b> is generalized to higher-order interactions. The rate of learning for internal representations in a higher-order Boltzmann machine should be {{much faster than}} for a second-order Boltzmann machine based on pairwise interactions...|$|E
40|$|Learning to {{recognize}} mirror, rotational and translational symmetries {{is a difficult}} problem for massively-parallel network models. These symmetries cannot be learned by first-order perceptrons or Hopfield networks, which have no means for incorporating additional adaptive units that are hidden from the input and output layers. We demonstrate that the <b>Boltzmann</b> <b>learning</b> <b>algorithm</b> is capable of finding sets of weights which turn hidden units into useful higher-order feature detectors capable of solving symmetry problems. 1...|$|E
40|$|We {{investigate}} {{the use of}} Boltzmann machines in semi-supervised classification. We treat the labeled/unlabeled dataset as a Markov random field, and derive a <b>Boltzmann</b> machine <b>learning</b> <b>algorithm</b> for it to learn the feature weights, label noise and labels for unlabeled data all at once. We present some Markov chain Monte Carlo methods needed for learning, and discuss the need to regularize model parameters. Preliminary experimental results are presented...|$|R
40|$|This paper {{develops}} a <b>Boltzmann</b> <b>learning</b> enhanced genetic <b>algorithm</b> for L∞ norm based system identification and model reduction for robust control applications. Using this technique, both a globally optimised nominal model and an error bounding function for additive and multiplicative uncertainties can be obtained. It can {{also offer a}} tighter L∞ error bound and is applicable to both continuous and discrete-time systems...|$|R
40|$|It is {{currently}} believed that {{artificial neural network}} models may {{form the basis for}} inte 1 ligent computational devices. The Boltzmann Machine belongs to the class of recursive artificial neural networks and uses a supervised <b>learning</b> <b>algorithm</b> to <b>learn</b> the mapping between input vectors and desired outputs. This study examines the parameters that influence the performance of the <b>Boltzmann</b> Machine <b>learning</b> <b>algorithm.</b> Improving the performance of the algorithm {{through the use of a}} naïve mean field theory approximation is also examined. The study was initiated to examine the hypothesis that the <b>Boltzmann</b> Machine <b>learning</b> <b>algorithm,</b> when used with the mean field approximation, is an efficient, reliable, and flexible model of machine learning. An empirical analysis of the performance of the algorithm supports this hypothesis. The performance of the algorithm is investigated by applying it to training the Boltzmann Machine, and its mean field approximation, the exclusive-Or function. Simulation results suggest that the mean field theory approximation learns faster than the Boltzmann Machine, and shows better stability. The size of the network and the learning rate were found to have considerable impact upon the performance of the algorithm, especially in the case of the mean field theory approximation. A comparison is made with the feed forward back propagation paradigm and it is found that the back propagation network learns the exclusive-Or function eight times faster than the mean field approximation. However, the mean field approximation demonstrated better reliability and stability. Because the mean field approximation is local and asynchronous it has an advantage over back propagation with regard to a parallel implementation. The mean field approximation is domain independent and structurally flexible. These features make the network suitable for use with a structural adaption algorithm, allowing the network to modify its architecture in response to the external environment...|$|R
40|$|A novel type of {{an optical}} neurochip with {{learning}} capability and memory function is reported. The neurochip is a three dimensional {{optoelectronic integrated circuit}} consisting of a light emitting diode array and a variable sensitivity photodetector (VSPD) array. The principle of operation and the fundamental characteristics are described. By using the fabricated optical neurochip with 32 neurons and 32 Θ 32 synapses, experiments of on-chip learning based on the backpropagation and <b>Boltzmann</b> machine <b>learning</b> <b>algorithms</b> have successfully been demonstrated. INTRODUCTION Optoelectronics is expected {{to play an important}} role in hardware implementation of neural networks because of its innate parallelism, high-density interconnection, and direct image processing abilities [1]. This summary describes an optical learning chip with variable synaptic interconnections developed in our laboratory. This chip enables to perform on-chip learning by using an internal analog memory function. Firs [...] ...|$|R
40|$|International audienceThis paper {{proposes a}} {{modification}} to the restricted <b>Boltzmann</b> machine (RBM) <b>learning</b> <b>algorithm</b> to incorporate inductive biases. These latent activation biases are ideal solutions of the latent activity {{and may be}} designed either by modeling neural phenomenon or inductive principles of the task. In this paper, we design activation biases for sparseness and selectivity based on the activation distributions of biological neurons. With this model, one can manipulate the selectivity of individual hidden units and the sparsity of population codes. The biased RBM yields a filter bank of Gabor-like filters when trained on natural images, while modeling handwritten digits results in filters with stroke-like features. We quantitatively verify that the latent representations assume {{the properties of the}} activation biases. We further demonstrate that RBMs biased with selectivity and sparsity can significantly outperform standard RBMs for discriminative tasks...|$|R
40|$|In {{this thesis}} we asses the {{consistency}} and convexity of the parameter inference in <b>Boltzmann</b> machine <b>learning</b> <b>algorithms</b> based on gradient ascent on the likelihood surface. We {{do this by}} rst developing standard tools for generating equillibrium data drawn from a Boltzmann distribution, as well as analytically exact algorithms for inferring the parameters of restricted and semi-restricted Boltzmann machine architctures. After testing, and showing, the functionality of our algorithms, we assess how dierent network properties eect the inferrence quality of restricted Boltzmann machines. Subsequently, we look closer at the likelihood function itself, {{in an attempt to}} uncover more rigid details about its curvature, and the nature of its convexity. As we present results of our investigation, we discuss the ndings, before suggesting possible future directions to take, improvements to make and aspects to further investigate. We conclude that the standard, analytically exact restricted Boltzmann machine algorithm is convex up to certain permutations of the parameters, when initialized within reasonable ranges of parameter values, and given that the strength of connectivity in the underlying model is within a specied range. Additionaly, for strengths of connectivity, the distribution of Hessian eigenvalues of the likelihood function, as a funtion of the distance to a peak, may be stable both within and across network sizes. </p...|$|R
40|$|International audienceMotivation: Graphical {{models are}} often {{employed}} to interpret patterns of correlations observed in data through {{a network of}} interactions between the variables. Recently, Ising/Potts models, also known as Markov random fields, have been productively applied to diverse problems in biology, including the prediction of structural contacts from protein sequence data and the description of neural activity patterns. However, inference of such models is a challenging computational problem that cannot be solved exactly. Here, we describe the adaptive cluster expansion (ACE) method to quickly and accurately infer Ising or Potts models based on correlation data. ACE avoids overfitting by constructing a sparse network of interactions sufficient to reproduce the observed correlation data within the statistical error expected due to finite sampling. When convergence of the ACE algorithm is slow, we combine it with a <b>Boltzmann</b> Machine <b>Learning</b> <b>algorithm</b> (BML). We illustrate this method {{on a variety of}} biological and artificial datasets and compare it to state-of-the-art approximate methods such as Gaussian and pseudo-likelihood inference. Results: We show that ACE accurately reproduces the true parameters of the underlying model when they are known, and yields accurate statistical descriptions of both biological and artificial data. Models inferred by ACE more accurately describe the statistics of the data, including both the constrained low-order correlations and unconstrained higher-order correlations, compared to those obtained by faster Gaussian and pseudo-likelihood methods. These alternative approaches can recover the structure of the interaction network but typically not the correct strength of interactions, resulting in less accurate generative models...|$|R
40|$|<b>Boltzmann</b> <b>learning</b> {{underlies}} {{an artificial}} neural network model known as the Boltzmann machine that extends and improves upon the Hopfield network model. Boltzmann machine model uses stochastic binary units and allows {{for the existence of}} hidden units to represent latent variables. When subjected to reducing noise via simulated annealing and allowing uphill steps via Metropolis algorithm, the training algorithm increases the chances that, at thermal equilibrium, the network settles on the best distribution of parameters. The existence of equilibrium distribution for an asynchronous Boltzmann machine is analyzed with respect to temperature. Two families of <b>learning</b> <b>algorithms,</b> which correspond to two different approaches to compute the statistics required for learning, are presented. The <b>learning</b> <b>algorithms</b> based only on stochastic approximations are traditionally slow. When variational approximations of the free energy are used, like the mean field approximation or the Bethe approximation, the performance of learning improves considerably. The principal contribution of the present study is to provide, from a rigorous mathematical perspective, a unified framework for these two families of <b>learning</b> <b>algorithms</b> in asynchronous <b>Boltzmann</b> machines...|$|R
40|$|One of the {{delights of}} the field of neural or connectionist {{networks}} is the great diversity of perspectives from which these nets can be profitably studied. Biological and cognitive perspectives are important among these, but in this book we focus on mathematical perspectives, from w hich these netw orks appear as purely formal systems. Throughout the history of the neural networks field, broadly construed, major turning points have been marked by developments of a primarily mathematical nature: consider how the field was changed forever by the work of McCulloch and Pitts, Rosenblatt, Minsky and Papert, Grossberg, Kohonen, Hopfield, the development of the <b>Boltzmann</b> and back-propagation <b>learning</b> <b>algorithms,</b> and many other equally important formal advances. Mathematical perspectives have been central to the field from its inception. To say w e are limiting ourselves in this book to mathematical perspectives is not at all to say that we are operating within narrow boundaries. For even the purely mathematical perspectives on neural networks constitute an extremely rich and diverse class: neural networks are collections of Boolean gates, collections of analog gates, evolving dynamical systems, stochastic process es, models of stochastic process es, function approximators, Bayesian probabilistic models, information-theoretic analyzers, statistical parameter estimators—just to sample the perspec tives represented in this book alone...|$|R
40|$|We {{introduce}} {{a large family}} of Boltzmann machines that can be trained using standard gradient descent. The networks can have one or more layers of hidden units, with tree-like connectivity. We show how to implement the supervised <b>learning</b> <b>algorithm</b> for these <b>Boltzmann</b> machines exactly, without resort to simulated or mean-field annealing. The stochastic averages that yield the gradients in weight space are computed by the technique of decimation. We present results {{on the problems of}} N-bit parity and the detection of hidden symmetries. 1 Introduction Boltzmann machines (Ackley, Hinton, & Sejnowski, 1985) have several compelling virtues. Unlike simple perceptrons, they can solve problems that are not linearly separable. The learning rule, simple and locally based, lends itself to massive parallelism. The theory of <b>Boltzmann</b> <b>learning,</b> moreover, has a solid foundation in statistical mechanics. Unfortunately, Boltzmann machines [...] - as originally conceived [...] -also have some serious drawbacks [...] ...|$|R
40|$|We {{present a}} new <b>learning</b> <b>algorithm</b> for <b>Boltzmann</b> {{machines}} that contain {{many layers of}} hidden variables. Data-dependent expectations are estimated using a variational approximation that tends {{to focus on a}} single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two quite different techniques for estimating the two types of expectation that enter into the gradient of the log-likelihood makes it practical to <b>learn</b> <b>Boltzmann</b> machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer “pre-training ” phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and NORB datasets showing that deep <b>Boltzmann</b> machines <b>learn</b> good generative models and perform well on handwritten digit and visual object recognition tasks. ...|$|R
40|$|Deep Boltzmann {{machines}} are in principle powerful models for extracting the hierarchical structure of data. Unfortunately, attempts to train layers jointly (without greedy layer-wise pretraining) {{have been largely}} unsuccessful. We propose a modification of the <b>learning</b> <b>algorithm</b> that initially recenters {{the output of the}} activation functions to zero. This modification leads to a better conditioned Hessian and thus makes learning easier. We test the algorithm on real data and demonstrate that our suggestion, the centered deep <b>Boltzmann</b> machine, <b>learns</b> a hierarchy of increasingly abstract representations and a better generative model of data...|$|R
40|$|Exact <b>Boltzmann</b> <b>learning</b> {{can be done}} {{in certain}} {{restricted}} networks by the technique of decimation. We have enlarged the set of decimatable Boltzmann machines by introducing a new and more general decimation rule. We have compared solutions of a probability density estimation problem with decimatable Boltzmann machines to the results obtained by Gibbs sampling in unrestricted (non-decimatable) Boltzmann machines. 1 Introduction Boltzmann machines [3] have been the first stochastical neural networks for which a <b>learning</b> <b>algorithm</b> [1] has been defined. This learning rule is based upon local interactions of nodes. Generally, their calculation is intractable in the number of hidden nodes. However, Gibbs sampling with simulated annealing can estimate them sufficiently precise. Many efforts have been made since then to overcome the [...] - even for modern computers [...] - comparatively slow Gibbs sampling of a Boltzmann machine. One especially interesting Sekr. FR 5 - 9, Franklinstr. 28 - 29, 10587 [...] ...|$|R
40|$|A {{stability}} {{criterion for}} dynamic parameter adaptation is given. In {{the case of}} the learning rate of backpropagation, a class of stable algorithms is presented and studied, including a convergence proof. 1 INTRODUCTION All but a few <b>learning</b> <b>algorithms</b> employ one or more parameters that control the quality of learning. Backpropagation has its learning rate and momentum parameter; <b>Boltzmann</b> <b>learning</b> uses a simulated annealing schedule; Kohonen learning a learning rate and a decay parameter; genetic algorithms probabilities, etc. The investigator always has to set the parameters to specific values when trying to solve a certain problem. Traditionally, the metaproblem of adjusting the parameters is solved by relying on a set of well-tested values of other problems or an intensive search for good parameter regions by restarting the experiment with different values. In this situation, a great deal of expertise and/or time for experiment design is required (as well as a huge amount of compu [...] ...|$|R
40|$|We study {{historical}} {{dynamics of}} joint equilibrium distribution of stock returns in the U. S. stock market using the Boltzmann distribution model being parametrized by external fields and pairwise couplings. Within <b>Boltzmann</b> <b>learning</b> framework for statistical inference, we analyze historical {{behavior of the}} parameters inferred using exact and approximate <b>learning</b> <b>algorithms.</b> Since the model and inference methods require use of binary variables, effect of this mapping of continuous returns to the discrete domain is studied. The presented analysis shows that binarization preserves market correlation structure. Properties of distributions of external fields and couplings as well as industry sector clustering structure are studied for different historical dates and moving window sizes. We found that a heavy positive tail {{in the distribution of}} couplings is responsible for the sparse market clustering structure. We also show that discrepancies between the model parameters might be used as a precursor of financial instabilities. Comment: 15 pages, 17 figures, 1 tabl...|$|R
40|$|We {{propose a}} {{statistical}} mechanical {{framework for the}} modeling of discrete time series. Maximum likelihood estimation is done via <b>Boltzmann</b> <b>learning</b> in one-dimensional networks with tied weights. We call these networks Boltzmann chains and show that they contain hidden Markov models (HMMs) as a special case. Our framework also motivates new architectures that address partic-ular shortcomings of HMMs. We look at two such architectures: parallel chains that model feature sets with disparate time scales, and looped networks that model long-term dependencies between hidden states. For these networks, we show how to implement the <b>Boltzmann</b> <b>learning</b> rule exactly, in polynomial time, without resort to simulated or mean-field annealing. The necessary com-putations are done by exact decimation procedures from statistical mechanics. ...|$|R
40|$|AbstractA clear need exists within {{artificial}} intelligence for flexible systems capable of modifying their own knowledge bases. A common formalism {{can be used}} to describe two seemingly different models: the <b>Boltzmann</b> machine connectionist <b>learning</b> model and the Bayes network model for probabilistic reasoning. The <b>learning</b> <b>algorithm</b> for <b>Boltzmann</b> machines can be adapted to a general algorithm for adjusting conditional probabilities on the links in a Bayes network. It is hypothesized that the formal approach outlined here holds promise for unifying symbolic and subsymbolic levels of reasoning...|$|R
40|$|This pape. r {{shows that}} {{contrastive}} Hebbian, the algorithm used in mean field learning, {{can be applied}} to any continuous Hopfield model. This implies that non-logistic activation functions as well as self connections are allowed. Contrary to previous approaches, the <b>learning</b> <b>algorithm</b> is derived without considering it a mean field approximation to <b>Boltzmann</b> machine <b>learning.</b> The paper includes a discussion of the conditions under which the function that contrastive Hebbian mini~ mizes can be considered a proper error function, and an analysis of five different training regimes. An appendix provides complete demonstrations and specific instructions on how to implement contrastive Hebbian learning in interactive activation and competition models (a convenient version of the continuous Hopfield model). ...|$|R
5000|$|... #Subtitle level 3: Ensemble <b>learning</b> <b>algorithms</b> (supervised meta-algorithms for {{combining}} multiple <b>learning</b> <b>algorithms</b> together) ...|$|R
30|$|As a result, {{ensemble}} <b>learning</b> <b>algorithms</b> adapt {{much better}} to concept drift than incremental <b>learning</b> <b>algorithms.</b>|$|R
40|$|The {{convergence}} of online <b>learning</b> <b>algorithms</b> is analyzed using {{the tools of}} the stochastic approximation theory, and proved under very weak conditions. A general framework for online <b>learning</b> <b>algorithms</b> is first presented. This framework encompasses the most common online <b>learning</b> <b>algorithms</b> in use today, as illustrated by several examples. The stochastic approximation theory then provides general results describing the {{convergence of}} all these <b>learning</b> <b>algorithms</b> at once...|$|R
40|$|Removing or {{filtering}} outliers and mislabeled instances {{prior to}} training a <b>learning</b> <b>algorithm</b> {{has been shown}} to increase classification accuracy. A popular approach for handling outliers and mislabeled instances is to remove any instance that is misclassified by a <b>learning</b> <b>algorithm.</b> However, an examination of which <b>learning</b> <b>algorithms</b> to use for filtering as well as their effects on multiple <b>learning</b> <b>algorithms</b> over a large set of data sets has not been done. Previous work has generally been limited due to the large computational requirements to run such an experiment, and, thus, the examination has generally been limited to <b>learning</b> <b>algorithms</b> that are computationally inexpensive and using a small number of data sets. In this paper, we examine 9 <b>learning</b> <b>algorithms</b> as filtering algorithms as well as examining the effects of filtering in the 9 chosen <b>learning</b> <b>algorithms</b> on a set of 54 data sets. In addition to using each <b>learning</b> <b>algorithm</b> individually as a filter, we also use the set of <b>learning</b> <b>algorithms</b> as an ensemble filter and use an adaptive algorithm that selects a subset of the <b>learning</b> <b>algorithms</b> for filtering for a specific task and <b>learning</b> <b>algorithm.</b> We find that for most cases, using an ensemble of <b>learning</b> <b>algorithms</b> for filtering produces the greatest increase in classification accuracy. We also compare filtering with a majority voting ensemble. The voting ensemble significantly outperforms filtering unless there are high amounts of noise present in the data set. Additionally, we find that a majority voting ensemble is robust to noise as filtering with a voting ensemble does not increase the classification accuracy of the voting ensemble. Comment: 29 pages, 3 Figures, 20 Table...|$|R
5000|$|If we {{know that}} [...] then [...] is called proper <b>learning</b> <b>algorithm,</b> {{otherwise}} is called improper <b>learning</b> <b>algorithm.</b>|$|R
40|$|Abstract. We analyze {{completely}} the convergence {{speed of the}} batch <b>learning</b> <b>algorithm,</b> and compare its speed {{to that of the}} memoryless <b>learning</b> <b>algorithm</b> and of <b>learning</b> with memory (as analyzed in [KR 2001 b]). We show that the batch <b>learning</b> <b>algorithm</b> is never worse than the memoryless <b>learning</b> <b>algorithm</b> (at least asymptotically). Its performance vis-a-vis learning with full memory is less clearcut, and depends on certain probabilistic assumptions...|$|R
40|$|In {{this paper}} we present {{applications}} of different machine <b>learning</b> <b>algorithms</b> in aquaculture. Machine <b>learning</b> <b>algorithms</b> <b>learn</b> models from historical data. In aquaculture historical data are obtained from farm practices, yields, and environmental data sources. Associations between these different variables {{can be obtained}} by applying machine <b>learning</b> <b>algorithms</b> to historical data. In this paper we present applications of different machine <b>learning</b> <b>algorithms</b> in aquaculture applications. Comment: 2 page...|$|R
40|$|We analyze {{completely}} the convergence {{speed of the}} batch <b>learning</b> <b>algorithm,</b> and compare its speed {{to that of the}} memoryless <b>learning</b> <b>algorithm</b> and of <b>learning</b> with memory. We show that the batch <b>learning</b> <b>algorithm</b> is never worse than the memoryless <b>learning</b> <b>algorithm</b> (at least asymptotically). Its performance vis-a-vis learning with full memory is less clearcut, and depends on certain probabilistic assumptions. Comment: Supercedes a part of cs. LG/ 010703...|$|R
40|$|LIBOL is an {{open-source}} {{machine learning}} library {{that consists of}} a family of classical and state-of-the-art online <b>learning</b> <b>algorithms</b> for large-scale machine learning and data mining research. It includes two categories of online learning methods: regular linear online <b>learning</b> <b>algorithms</b> and kernel-based online <b>learning</b> <b>algorithms...</b>|$|R
40|$|We {{propose a}} {{new view of}} active <b>learning</b> <b>algorithms</b> as optimization. We show that many online active <b>learning</b> <b>algorithms</b> {{can be viewed as}} {{stochastic}} gradient descent on non-convex objective functions. Variations of some of these algorithms and objective functions have been previously proposed without noting this connection. We also point out a connection between the standard min-margin offline active <b>learning</b> <b>algorithm</b> and non-convex losses. Finally, we discuss and show empirically how viewing active learning as non-convex loss minimization helps explain two previously observed phenomena: certain active <b>learning</b> <b>algorithms</b> achieve better generalization error than passive <b>learning</b> <b>algorithms</b> on certain data sets (Schohn and Cohn, 2000; Bordes et al., 2005) and on other data sets many active <b>learning</b> <b>algorithms</b> are prone to local minima (Schütze et al., 2006). ...|$|R
40|$|This paper {{presents}} {{work which}} extends previous corpus-based work on training Machine <b>Learning</b> <b>Algorithms</b> to perform Prepositional Phrase attachment. Besides recreating others' experiments {{to see how}} algorithms' performance changes {{with the number of}} training examples and using n-fold cross-validation to produce more accurate error rates, we implemented our own vanilla Machine <b>Learning</b> <b>Algorithms</b> as a comparison. We also had people perform exactly the same task as the Machine <b>Learning</b> <b>Algorithms</b> to indicate whether the way forward lies in improving Machine <b>Learning</b> <b>Algorithms</b> or in improving the data sets used to train Machine <b>Learning</b> <b>Algorithms.</b> The results from all these experiments feed into our other work transforming the Penn TreeBank into a more useful resource for training Machine <b>Learning</b> <b>Algorithms</b> to do Prepositional Phrase attachment...|$|R
40|$|We {{present a}} new <b>learning</b> <b>algorithm</b> for <b>Boltzmann</b> Machines that contain {{many layers of}} hidden variables. Data-dependent {{statistics}} are estimated using a variational approximation that tends {{to focus on a}} single mode, and data-independent statistics are estimated using persistent Markov chains. The use of two quite different techniques for estimating the two types of statistic that enter into the gradient of the log likelihood makes it practical to <b>learn</b> <b>Boltzmann</b> Machines with multiple hidden layers and millions of parameters. The learning can be made more efficient by using a layer-by-layer "pre-training" phase that initializes the weights sensibly. The pre-training also allows the variational inference to be initialized sensibly with a single bottom-up pass. We present results on the MNIST and NORB datasets showing that Deep <b>Boltzmann</b> Machines <b>learn</b> very good generative models of hand-written digits and 3 -D objects. We also show that the features discovered by Deep Boltzmann Machines are a very effective way to initialize the hidden layers of feed-forward neural nets which are then discriminatively fine-tuned...|$|R
40|$|In {{this paper}} a robust <b>learning</b> <b>algorithm</b> of the radial?basis {{adaptive}} fuzzy?wavelet?neural network based on R. Welsh criterion is proposed. Proposed <b>learning</b> <b>algorithm</b> allows signals processing under significant noise level and under outliers. The experiment results are confirmed {{the effectiveness of}} proposed robust <b>learning</b> <b>algorithm.</b> ? ?????? ?????????? ????????? ???????? ???????? ?????????-???????? ?????????? ?????-???????-????????? ???? ?? ???? ???????? ?. ?????. ???????????? ???????? ???????? ????????? ???????????? ??????? ??? ???????? ???????????? ?????, ? ????? ??? ??????? ???????? ? ??????? ??????????. ?????????? ???????????? ???????????? ????????????? ????????????? ?????????? ????????? ????????...|$|R
40|$|No {{standard}} <b>learning</b> <b>algorithm</b> {{exists for}} training neural networks with step activation function. In this work we use Genetic Programming (GP) to discover supervised <b>learning</b> <b>algorithms</b> which can train neural networks using step function. A new <b>learning</b> <b>algorithm</b> {{has been discovered}} and {{has been shown to}} provide good performances...|$|R
40|$|In {{this paper}} an {{outliers}} resistant <b>learning</b> <b>algorithm</b> for the radial-basis-fuzzy-wavelet-neural network based on R. Welsh criterion is proposed. Suggested <b>learning</b> <b>algorithm</b> under consideration allows the signals processing in presence of significant noise level and outliers. The robust <b>learning</b> <b>algorithm</b> efficiency is investigated and {{confirmed by the}} number of experiments including medical applications...|$|R
