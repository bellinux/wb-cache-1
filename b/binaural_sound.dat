159|91|Public
5000|$|... #Caption: Neumann KU100 {{microphone}} used {{to record}} <b>binaural</b> <b>sound</b> ...|$|E
5000|$|... 2012 Dr. Chesky - Dr. Cheskys Sensational, Fantastic, And Simply Amazing <b>Binaural</b> <b>Sound</b> Show ...|$|E
50|$|The Bells is a 1979 album by Lou Reed, {{released}} through Arista Records. It {{is recorded}} in <b>binaural</b> <b>sound.</b>|$|E
40|$|To date {{a number}} of studies have shown that {{receptive}} field shapes of early sensory neurons can be reproduced by optimizing coding efficiency of natural stimulus ensembles. A still unresolved question is whether the efficient coding hypothesis explains formation of neurons which explicitly represent environmental features of different functional importance. This paper proposes that the spatial selectivity of higher auditory neurons emerges as a direct consequence of learning efficient codes for natural <b>binaural</b> <b>sounds.</b> Firstly, it is demonstrated that a linear efficient coding transform - Independent Component Analysis (ICA) trained on spectrograms of naturalistic simulated <b>binaural</b> <b>sounds</b> extracts spatial information present in the signal. A simple hierarchical ICA extension allowing for decoding of sound position is proposed. Furthermore, it is shown that units revealing spatial selectivity can be learned from a binaural recording of a natural auditory scene. In both cases a relatively small subpopulation of learned spectrogram features suffices to perform accurate sound localization. Representation of the auditory space is therefore learned in a purely unsupervised way by maximizing the coding efficiency and without any task-specific constraints. This results imply that efficient coding is a useful strategy for learning structures which allow for making behaviorally vital inferences about the environment. Comment: 22 pages, 9 figure...|$|R
40|$|Traditionally 3 D sound {{generation}} {{involves the}} use of multiple speakers that are strategically placed, and have appropriate lags in the sounds emanating from them. Using Head Related Transfer Functions (HRTFs), a realistic <b>binaural</b> <b>sounds</b> can be generated using a pair of headphones. This work describes that how a single channel audio can be transformed into binaural (left / right channels) using HRTFs. The implementation has been performed on a C 6713 DSK Texas Instrumentation (TI) kit. Current sound specialization systems use HRTFs, represented by the corresponding impuls...|$|R
40|$|ABSTRACT: Dummy {{heads are}} {{prerequisite}} for binaural recordings. Only with binaural recording or synthesis technology the full spatial information of sound events can be kept. Appropriate reproduction systems of <b>binaural</b> <b>sounds</b> are another important and interesting {{field of research}} and development. The application of binaural technology reaches from professional audio to home entertainment and games. However, more “serious ” applications like measurements of hearing aids and development of virtual reality systems are to be considered, too. In this presentation {{the historical development of}} dummy heads (artificial heads) is briefly described, the commercial products and their applications presented. Finally, research projects are discussed for improving the quality of binaural technology and for further extension of dummy head applications...|$|R
50|$|The Jecklin Disk is a {{refinement}} of the baffled microphone technique for stereo initially described by Alan Blumlein in his 1931 patent on <b>binaural</b> <b>sound.</b>|$|E
50|$|In 2016, Gray made a large artistic leap by {{changing}} labels to record an album produced with <b>binaural</b> <b>sound.</b> Stripped (Chesky Records, 2016) marked the singer's first {{steps into the}} world of audiophile recordings.|$|E
50|$|Subsequently, artists Sophie Mallett and Marie Toseland created 'a live <b>binaural</b> <b>sound</b> work' {{composed}} of ASMR triggers, broadcast by Resonance FM, the listings for which advised {{the audience to}} 'listen with headphones for the full sensory effect'.|$|E
50|$|Psychoacoustics is the {{scientific}} study of how humans respond to what they hear. At the heart of audio engineering are listeners who are the final arbitrator as to whether an audio design is successful, such as whether a <b>binaural</b> recording <b>sounds</b> immersive.|$|R
40|$|IWAENC 2005 : International Workshop on Acoustic Echo and Noise Control, September 12 - 15, 2005, Eindhoven, The Netherlands. High-fidelity blind source {{separation}} (BSS) using Single-Input Multiple-Output (SIMO) -model-based Independent Component Analysis (SIMO-ICA) is {{now being}} studied by the authors. This paper describes a comparison of two types of SIMO-ICAs with different constrains and the conventional methods, and gives explicit discussion on {{the sensitivity of the}} parameters settings in the methods. In order to discuss the difference, the source-separation experiments using the mixed <b>binaural</b> <b>sounds</b> are carried out under the same real acoustic conditions. The experiment results reveal that SIMO-ICA-IG outperforms SIMO-ICA-LS and the conventional methods, and the parameter setting in SIMO-ICAIG does not depend on the source signals’ properties compared with that of SIMO-ICA-LS...|$|R
40|$|This article {{presents}} {{an overview of}} the problems involved in modeling the phase in analysis/synthesis of voiced sounds. A number of informal experiments for monaural sounds are presented, demonstrating the problems and possible improvements to these kinds of systems. Furthermore, a number of psycho-acoustic experiments are presented, for assessing the importance of phase information regarding the spatial qualities of synthesized <b>sounds.</b> <b>Binaural</b> recorded <b>sounds</b> are synthesized using additive analysis/synthesis with and without phase information. The phase information is used in the synthesis to preserve the characteristics of the waveform. The experiments show the importance of phase when dealing with localization of voiced instruments...|$|R
5000|$|Later {{that same}} year, Bell Labs also {{demonstrated}} <b>binaural</b> <b>sound,</b> at the Chicago World's Fair in 1933 using a dummy with microphones instead of ears, [...] The two signals were sent out over separate AM station bands.|$|E
50|$|In 2014, France Télévisions {{asked him}} to direct a concert {{conducted}} by John Eliot Gardiner (Monteverdi's Vespers) at the Chapelle royale of Versailles, {{one of the first}} concert filmed in multicameras live in 4K (UHD) and <b>binaural</b> <b>sound.</b>|$|E
5000|$|ExtraTERRORestrial Alien Encounter (often {{abbreviated}} Alien Encounter) was a [...] "theater-in-the-round" [...] {{attraction in}} the Tomorrowland {{section of the}} Magic Kingdom theme park at Walt Disney World Resort. It was a darkly humorous science-fiction experience that used <b>binaural</b> <b>sound</b> to achieve many of its effects.|$|E
50|$|DTS Headphone:X reproduces 12 {{channels}} of <b>binaural</b> surround <b>sound</b> using any pair of stereo headphones. The head related transfer function is developed by DTS and includes compensation for room cues such as reflection and delay by mapping the acoustic {{characteristic of the}} original mixing studio, or other professional audio lab as a reference.|$|R
40|$|ICASSP 2004 : IEEE International Conference on Acoustics, Speech, and Signal Processing, May 17 - 21, 2004, Quebec, Canada. High-fidelity blind {{audio signal}} {{separation}} is addressed, adopting the extended ICA algorithm, single-input multiple-output (SIMO) -model-based ICA. The SIMO-ICA consists of multiple ICA parts and a fidelity controller, and each ICA runs in parallel under fidelity {{control of the}} entire separation system. SIMO-ICA can separate the mixed signals, not into monaural source signals, but into SIMO-model-based signals from independent sources as {{they are at the}} microphones. Thus, the separated signals of the SIMO-ICA can maintain the spatial qualities of each sound source. We apply the SIMO-ICA to the problem of blind separation of mixed <b>binaural</b> <b>sounds,</b> including the effect of the head-related transfer function (HRTF). Experimental results reveal that the performance of the proposed SIMO-ICA is superior to that of the conventional ICA-based method, and the separated signals of SIMO-ICA maintain the spatial qualities of each sound source...|$|R
40|$|Astrocytes of {{hippocampus}} contribute in {{the learning}} performance. Entrainment of gamma waves can improve learning performance by improving the neurons to astrocytes communication. The {{aim of this study}} was to evaluate the effect of binaural entrainment of 2000 - 2040 Hz and 2000 - 2090 Hz on Glial Fibrillary Acidic Protein (GFAP) expression in astrocytes of the CA 1 region of rat hippocampus during operant learning conditions. Twenty male Wistar rats aged 4 - 6 weeks with body weight 100 - 150 g were devided into 4 groups. Group I was given <b>binaural</b> <b>sounds</b> entrainment at 2000 - 2040 Hz without learning test. Group II was given entrainment as performed in Group I followed by a learning test. Group III was given <b>binaural</b> <b>sounds</b> entrainment at 2000 - 2090 followed by a learning test. Group IV was not given entrainment nor learning test. The entrainment was performed for 30 minutes everyday for 12 days and the learning test was performed for 10 minutes everyday for 12 days. The GFAP expression was examined imminohistochemically. Astrocytes processes and astrocytes histoscore were also calculated. The results showed that the number of the GFAP-positive astrocytes in Group I (70. 96 ± 4. 86), II (69. 76 ± 3. 07) and III (63. 10 ± 5. 85) were significantly higher than Control (47. 33 ± 1. 33) (p< 0. 05). The number of the processes astrocytes in Group I (47. 64 ± 3. 87), II (60. 66 ± 2. 07) and III (54. 17 ± 6. 38) was significantly higher than Control (30. 87 ± 2. 69) (p< 0. 05). Moreover, the number of the processes astrocytes in Group II was significantly higher than Group I (p= 0. 016). The astrocytes histoscore index in the Group II (115. 58 ± 14. 13) and III (78. 32 ± 22. 23) were significantly higher than Group I (28. 79 ± 9. 61) and Control (16. 05 ± 1. 64) (p< 0. 05). In conclusion, the binaural entrainment of 2000 - 2040 Hz and 2000 - 2090 Hz increase GFAP expression of astrocytes in Cornu Ammonus 1 (CA 1) region of rat hippocampus during operant learning conditioning...|$|R
5000|$|Alan Blumlein {{carried out}} his {{research}} into <b>binaural</b> <b>sound</b> and stereophonic gramophone recording here. [...] "Trains at Hayes Station" [...] (1935) and [...] "Walking & Talking" [...] are two notable films Blumlein shot to demonstrate stereo sound on film. These films are {{held at the}} Hayes EMI archive.|$|E
50|$|ZBS did a 1984-85 radio series, The Cabinet of Dr. Fritz, later {{releasing}} some {{shows in}} the series on cassettes and CDs. These productions were recorded binaurally using a Neumann Ku81 Kunstkopf microphone. ZBS also produced a widely acclaimed dramatization of Stephen King's The Mist recording in <b>binaural</b> <b>sound.</b>|$|E
5000|$|Live: Take No Prisoners was {{recorded}} during {{the series of}} albums where Reed employed {{the use of a}} binaural recording setup, using a dummy head with microphones in each ear. The back cover of the album notes: [...] "Produced by Lou Reed for Sister Ray Enterprises LTD. This is a <b>binaural</b> <b>sound</b> recording." ...|$|E
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. 3 D <b>binaural</b> <b>sounds</b> play an {{important}} role in the development of navigational systems for the blind people. The use of generic HRTFs in virtual auditory displays significantly affects the acoustic spatial resolution and the listener’s ability to make localization judgments regarding the sound sources situated inside the cone of confusion. The aim of this paper is to investigate whether haptic-auditory feedback based training can enhance sound localization performance, front-back discrimination and the navigational skills of the visually impaired people. In our experiments, we assessed the sound localization performance of nine visually impaired subjects before and after a series of haptic-auditory training procedures aimed to enhance the perception of 3 D sounds. The results of our tests demonstrate that our subjects succeeded to improve their sound localization performance, reduced the incidence of angular precision and reversal errors and became able to build an effective spatial representation map of the acoustic environment...|$|R
40|$|We report {{evidence}} for a context- and not stimulus-dependent functional asymmetry in {{the left and right}} human auditory midbrain, thalamus, and cortex in response to monaural sounds. Neural activity elicited by left- and right-ear stimulation was measured simultaneously in the cochlear nuclei, inferior colliculi (ICs), medial geniculate bodies (MGBs), and auditory cortices (ACs) in 2 functional magnetic resonance imaging experiments. In experiment 1, pulsed noise was presented monaurally to either ear, or binaurally, simulating a moving sound source. In experiment 2, only monaural sounds were presented. The results show a modulation of the neural responses to monaural sounds by the presence of <b>binaural</b> <b>sounds</b> at a time scale of tens of seconds: In the absence of binaural stimulation, the left and right ICs, MGBs, and ACs responded stronger to stimulation of the contralateral ear. When blocks of binaural stimuli were interspersed in the sound sequence, the contralateral preference vanished in those structures in the right hemisphere. The resulting hemispheric asymmetry was similar to the asymmetry demonstrated for spatial sound processing. Taken together, the data demonstrate that functional asymmetries in auditory processing are modulated by context. The observed long time constant suggests that this effect results from a "top-down" mechanism...|$|R
40|$|Background: While human {{auditory}} cortex {{is known}} to contain tonotopically organized auditory cortical fields (ACFs), {{little is known about}} how processing in these fields is modulated by other acoustic features or by attention. Methodology/Principal Findings: We used functional magnetic resonance imaging (fMRI) and population-based cortical surface analysis to characterize the tonotopic organization of human auditory cortex and analyze the influence of tone intensity, ear of delivery, scanner background noise, and intermodal selective attention on auditory cortex activations. Medial auditory cortex surrounding Heschl’s gyrus showed large sensory (unattended) activations with two mirror-symmetric tonotopic fields similar to those observed in non-human primates. Sensory responses in medial regions had symmetrical distributions with respect to the left and right hemispheres, were enlarged for tones of increased intensity, and were enhanced when sparse image acquisition reduced scanner acoustic noise. Spatial distribution analysis suggested that changes in tone intensity shifted activation within isofrequency bands. Activations to monaural tones were enhanced over the hemisphere contralateral to stimulation, where they produced activations similar to those produced by <b>binaural</b> <b>sounds.</b> Lateral regions of auditory cortex showed small sensory responses that were larger in the right than left hemisphere, lacked tonotopic organization, and were uninfluenced by acoustic parameters. Sensory responses in both medial and latera...|$|R
50|$|In 1990, Chesky Records {{released}} its Jazz Sampler & Audiophile Test Compact Disc, {{with the first}} nine tracks devoted to music and the remaining twenty devoted to listening and technical tests for headphones and loud speakers. Other test discs include Dr. Chesky's Sensational, Fantastic, and Simply Amazing <b>Binaural</b> <b>Sound</b> Show and the Ultimate Demo Disc.|$|E
5000|$|Based on {{previous}} <b>binaural</b> <b>sound</b> localization methods, a hierarchical fuzzy {{artificial neural network}} system combines interaural time difference(ITD-based) and interaural intensity difference(IID-based) sound localization methods for higher accuracy {{that is similar to}} that of humans. Hierarchical Fuzzy Artificial Neural Networks [...] were used with the goal of the same sound localization accuracy as human ears.|$|E
50|$|Linear {{reasoning}} {{functions of}} language such as grammar and word production are often lateralized {{to the left}} hemisphere of the brain. In contrast, holistic reasoning functions of language such as intonation and emphasis are often lateralized to the right hemisphere of the brain. Other integrative functions such as intuitive or heuristic arithmetic, <b>binaural</b> <b>sound</b> localization, etc. {{seem to be more}} bilaterally controlled.|$|E
40|$|The {{development}} of noise reduction algorithms for hearing aids HA is not longer only {{related to the}} improvement of signal to noise ratio, {{but also to the}} quality of hearing, e. g., binaural aspects of hearing. This is very important for the recognition of the localization of sound sources but also for an improved speech intelligibility in noisy situations due to spatial release from masking effects. New design and signal processing algorithms for binaural HA’s need to be tested and validated in different acoustical scenarios. As it is too laborious and time consuming to perform sufficient numbers of perceptual evaluations in different rooms with different acoustical parameters, advanced acoustic modeling of different virtual acoustical environments might be needed. Virtual acoustics in our research relates to the convolution of the measured or simulated binaural signals head related transfer functions - HRTF’s with the impulse response generated from a computer model of a room using ODEON® software to simulate <b>binaural</b> <b>sounds.</b> This study investigates the usage of virtual acoustics in the framework of developing algorithms for binaural hearing aids. It evaluates and quantifies the fidelity of binaural signals generated by commercially available virtual acoustics software with respect to the localization of sound and speech intelligibility in different acoustical scenarios. status: publishe...|$|R
50|$|Channels, objects, and HOA {{components}} {{may be used}} {{to transmit}} immersive sound as well as mono, stereo, or surround sound. The MPEG-H 3D Audio decoder renders the bitstream to a number of standard speaker configurations as well as to misplaced speakers. <b>Binaural</b> rendering of <b>sound</b> for headphone listening is also supported.|$|R
5000|$|Cook is {{sometimes}} said [...] to have intended only {{to show the}} quality of his recording and molding process at an audio fair, with the added feature of <b>binaural</b> (i.e., stereophonic) <b>sound</b> to get attention. The overwhelming response led him to produce and sell his equipment and to produce records.|$|R
50|$|The work of Myriam Van Imschoot {{has been}} {{presented}} by Sculpture International Rotterdam (The Netherlands), Nodar <b>Binaural</b> <b>Sound</b> Center, Rumpsti-Pumsti (Musik), MUU Galeria, Playground Stuk (Leuven, Belgium), Jan Van Eyck Academie (Maastricht, The Netherlands), Kaaitheater (Brussels, Belgium), Vooruit (Ghent, Belgium), Kunstencentrum Buda (Kortrijk, Belgium), Museo Reina Sofia (Madrid, Spain), De Player, Operdagen Rotterdam (The Netherlands), Pact Zollverein, Techno Park Studios, Campo, Kiasma Theater (Helsinki, Finland).|$|E
50|$|The {{attraction}} includes much of {{the technology}} and sets from its predecessor, the ExtraTERRORestrial Alien Encounter, including the comical alien Skippy in the preshow area. The 39-inch Audio-Animatronic Stitch figure built by Imagineering reportedly {{is one of the}} most complex creations of its size. Other special effects include <b>binaural</b> <b>sound,</b> simulated laser cannons and a pungent smell (that of a chili dog, which lampoons the rule about bringing food and drink into the theater).|$|E
50|$|The Hierarchical Fuzzy Artificial Neural Networks Approach sound {{localization}} {{system was}} modelled on biologically <b>binaural</b> <b>sound</b> localization. Some primitive animals with two ears and small brains can perceive 3D space and process sounds, although {{the process is}} not fully understood. Some animals experience difficulty in 3D sound location due to small head size. Additionally, the wavelength of communication sound may be much larger than their head diameter, {{as is the case}} with frogs.|$|E
40|$|The present paper aims to {{describe}} the work carried out inside the ARGUS project to design and develop a software tool that manages heterogeneous cartographical datasets in order to offer personalized routing services. The project is focused on guiding {{blind and visually impaired}} in urban and rural environments with the help of <b>binaural</b> <b>sounds.</b> The navigation algorithm in the ARGUS smartphone application relies on GPX tracks containing the path to follow and informative points of interest along the path. These GPX files, previously recorded or created on demand, are downloaded from the remote service platform where the Multilayer Information Management System is hosted. This module handles, on one hand, crowdsourced data from OpenStreetMap and ARGUS users and, on the other hand, cartography from individual city providers. Moreover the system defines a set of spatial attributes to categorize the most relevant and signifcant types of urban elements for the target user group, which are represented as geographical point or lines, enabling users to decide which type of objects have a positive effect such as tactile pavements, negative or neutral effect during the trace of a path. This user specified aproach affect the route finding by changing the routing weights. Different levels of visual impairment and skills from one user to another, as well as personal preferences, make this module a decisive configurable abstraction layer for the route calculation module...|$|R
40|$|Indoors and {{in nature}} alike, the {{auditory}} scenes that we perceive unfold in reverberant environments. In a reverberant sound field, reflected acoustic waves reach the listener from all directions, {{interfering with the}} direct sound and distorting the <b>binaural</b> cues for <b>sound</b> localization such as interaural time and level differences (ITD and ILD). I...|$|R
40|$|Internal {{models of}} regularities {{in the world}} serve to {{facilitate}} perception as redundant input can be predicted and neural resources conserved for that which is new or unexpected. In the auditory system, this is reflected in an evoked potential component known as mismatch negativity (MMN). MMN is elicited by the violation of an established regularity to signal the inaccuracy of the current model and direct resources to the unexpected event. Prevailing accounts suggest that MMN amplitude will increase with stability in regularity; however, observations of first-impression bias contradict stability effects. If tones rotate probabilities as a rare deviant (p=. 125) and common standard (p=. 875), MMN elicited to the initial deviant tone reaches maximal amplitude faster than MMN to the first standard when later encountered as deviant—a differential pattern that persists throughout rotations. Sensory inference is therefore biased by longer-term contextual information beyond local probability statistics. Using the same multicontext sequence structure, we examined whether this bias generalizes to MMN elicited by spatial sound cues using monaural sounds (n= 19, right first deviant and n= 22, left first deviant) and <b>binaural</b> <b>sounds</b> (n= 19, right first deviant). The characteristic differential modulation of MMN to the two tones was observed in two of three groups, providing partial support for the generalization of first-impression bias to spatially deviant sounds. We discuss possible explanations for its absence when the initial deviant was delivered monaurally to the right ear. [Final citation details to be advised...|$|R
