0|88|Public
40|$|This paper {{describes}} a <b>backtracking</b> <b>strategy</b> for an incremental deterministic transitionbased parser for HPSG. The method could theoretically be implemented {{on any other}} transition-based parser with some adjustments. In this paper, the algorithm is evaluated on CuteForce, an efficient deterministic shiftreduce HPSG parser. The <b>backtracking</b> <b>strategy</b> may serve to improve existing parsers, or to assess if a deterministic parser would benefit from <b>backtracking</b> as a <b>strategy</b> to improve parsing. ...|$|R
40|$|This thesis {{addresses}} {{the problem of}} <b>backtracking</b> <b>strategies</b> in test generation. First, a methodology which uses status of absolute dominators {{as a means for}} causing backtracking during the test generation process is presented. Then, different heuristics that force the test generation to execute the backtracking procedure are investigated. Experiments which generated test patterns for over 30, 000 faults have been used to evaluate these heuristics. According to the experimental results, we recommend a new <b>backtracking</b> <b>strategy</b> that has the best performance among the six strategies explored in this thesis...|$|R
40|$|AbstractCurrent Web {{technologies}} {{provide the}} basis for publishing and composing large number of Web Services which are char–acterized by functional, non-functional, and transactional properties. Although the research community has proposed several approaches to effciently solve problems as service selection and composition, some of these solutions may be incomplete, i. e., they may fail producing a solution when solutions exist. In this paper we propose a non-chronological <b>backtracking</b> <b>strategy</b> which is implemented in a state-of-the-art composition algorithm named PT-SAM, and complete–ness is achieved in the context of transactional web service composition. Empirical results suggest that the proposed approach may overcome the chronological <b>backtracking</b> <b>strategy</b> by up one order of magnitude...|$|R
30|$|Herre van Oostendorp & Sonal Aggarwal, [36] {{propose a}} new {{cognitive}} model based on path adequacy and <b>backtracking</b> <b>strategies,</b> also recognizing the semantics of pictures. The effectiveness of support {{based on the}} new model could be proven in a multi-tasking experiment with cognitively demanding situations.|$|R
40|$|This paper {{proposes a}} general {{framework}} for implementing <b>backtrack</b> search <b>strategies</b> in Propositional Satisfiability (SAT) algorithms, that {{is referred to}} as unrestricted backtracking. Different organizations of unrestricted backtracking yield well-known <b>backtrack</b> search <b>strategies.</b> Moreover, this general framework allows devising new <b>backtracking</b> <b>strategies.</b> For example, we propose a stochastic systematic search algorithm for SAT, that randomizes both the variable selection and the backtracking steps of the algorithm. In addition, we illustrate how unrestricted backtracking can be used to develop informed search restart strategies, that only eliminate variable selections that are deemed relevant for the set of conflicts identified prior to each search restart. Finally, experimental results provide empirical evidence that different organizations of unrestricted backtracking can result in competitive approaches for solving hard real-world instances of SAT...|$|R
25|$|Any search {{strategy}} {{can be used}} to search this space. Prolog uses a sequential, last-in-first-out, <b>backtracking</b> <b>strategy,</b> in which only one alternative and one sub-goal is considered at a time. Other search strategies, such as parallel search, intelligent backtracking, or best-first search to find an optimal solution, are also possible.|$|R
40|$|Extending {{functional}} Lisp with McCarthy's nondeterministic operator AMB {{yields a}} language which can concisely express search problems. Dependency-directed backtracking {{is a powerful}} search strategy. We describe a non-deterministic Lisp dialect called SCHEMER and show that it can provide automatic dependency-directed backtracking. The resulting language provides a convenient interface to this efficient <b>backtracking</b> <b>strategy...</b>|$|R
40|$|The {{past few}} decades saw great {{improvements}} {{in the performance of}} satisfiability (SAT) solvers. In this thesis, we discuss the state-of-the-art techniques used in building an efficient SAT solver. Modern SAT solvers are mainly constituted by the following components: decision heuristics, Boolean constraint propagation, conflict analysis, restart, clause deletion and preprocessing. Various algorithms and implementations in each component will be discussed and analyzed. Then we propose a new <b>backtracking</b> <b>strategy,</b> partial <b>backtracking,</b> which can be easily implemented in SAT solvers. It is essentially an extension of the <b>backtracking</b> <b>strategy</b> used in most SAT solvers. With partial backtracking, the solver consecutively amends the variable assignments instead of discarding them completely so that it does not backtrack as many levels as the classic strategy does after analyzing a conflict. We implemented this strategy in our solver Nigma and the experiments show that the solver benefits from this adjustment...|$|R
40|$|International audienceIn {{this work}} we {{introduce}} a new method for solving nonsmooth equations with simple constraints. The method {{is based on the}} inexact and quasi-Newton approaches with <b>backtracking</b> <b>strategy.</b> Some conditions are given that ensure global superlinear convergence to a solution of the equation. Moreover, we propose a nonmonotone scheme of algorithm. Both versions of algorithm was constructed for the Lipschitz constinuous equations...|$|R
40|$|In this paper, we {{describe}} {{a variant of}} the inexact Newton method for solving nonlinear systems of equations. We define a nonmonotone inexact Newton step and a nonmonotone <b>backtracking</b> <b>strategy.</b> For this nonmonotone inexact Newton scheme, we present the convergence theorems. Finally, we show how we can apply these strategies to the inexact Newton interior-point method and we present some numerical examples...|$|R
40|$|Search {{algorithms}} {{are often}} categorized by their node expansion strategy. One option is the depth-first <b>strategy,</b> a simple <b>backtracking</b> <b>strategy</b> that traverses the search {{space in the}} order in which successor nodes are generated. An alternative is the best-first strategy, which was designed to make it possible to use domain-specific heuristic information. By exploring promising parts of the search space first, best-first algorithms are usually more efficient than depth-first algorithms...|$|R
40|$|We {{present and}} analyse a <b>backtracking</b> <b>strategy</b> {{for a general}} Fast Iterative Shrinkage/Thresholding Algorithm which has been {{recently}} proposed in (Chambolle, Pock, 2016) for strongly convex objective functions. Differently from classical Armijo-type line searching, our backtracking rule allows for local increasing and decreasing of the descent step size (i. e. proximal parameter) along the iterations. For such strategy accelerated convergence rates are proved and numerical results are shown for some exemplar imaging problems...|$|R
40|$|Constraint {{inference}} engine {{as the core}} part of constraint logic programming system comprises variable set, temporary container and constraint filter and {{inference engine}} and adopts branching strategy, exploration <b>strategy</b> and node <b>backtracking</b> <b>strategy</b> to complete the inference task. This study introduces variable event to reduce the triggering times of constraint filter and analyzes the trigger probability of inference engine. The experiments show that variable event setting can enhance the efficiency of constraint inference engine...|$|R
3000|$|In {{this section}} {{we return to}} the first aim of this article, which in {{particularly}} extends our previous conference publication (at WIMS 14, [24]): to investigate whether taking into account path adequacy and <b>backtracking</b> <b>strategies</b> next to the semantics of pictures lead to better model performance. For that purpose we will compare and contrast the two models CoLiDeS[*]+[*]Pic and CoLiDeS++Pic. Does inclusion of information from past selections and backtracking have any impact on the model’s performance? [...]...|$|R
3000|$|Recently, more {{sophisticated}} greedy algorithms have been developed, such as Analysis Subspace Pursuit (ASP) and Analysis Compressive Sampling Matching Pursuit (ACoSaMP) [12, 19]. They employ the <b>backtracking</b> <b>strategy</b> and offer strong theoretical guarantees. ASP and ACoSaMP with a candidate set size of 2 l[*]−[*]p have good performance on reconstructing the signal when l {{is close to}} d, but they require more measurements for an exact reconstruction with an increasing level of cosparsity. ASP and ACoSaMP with a candidate set size of l provide a comparable reconstruction quality {{to that of the}} l [...]...|$|R
40|$|PRholog is an {{experimental}} extension of logic programming with strategic conditional transformation rules, combining Prolog with Rholog calculus. The rules perform nondeterministic transformations on hedges. Queries may have several results {{that can be}} explored on <b>backtracking.</b> <b>Strategies</b> provide a control on rule applications in a declarative way. With strategy combinators, the user can construct more complex strategies from simpler ones. Matching with four different kinds of variables provides a flexible mechanism of selecting (sub) terms during execution. We give an overview on programming with strategies in PRholog and demonstrate how rewriting strategies can be expressed...|$|R
40|$|Abstract. Abstract:- One of {{the most}} severe problem due to softwaredevelopment is to {{guarantee}} {{that there are no}} contradictions and no incompletion within a certain requirement specification. We did a new approach how to handle this problem, because we are especially engaged in fuzzy controllers in real-time Systems. The presented method is limited to rule bases as a part of fuzzy systems. The fundamental idea is to calculate all possible rules within a rule base automatically, and afterwards, reduce the number of rules with <b>backtracking</b> <b>strategies</b> and contradiction checks. Additionally, an analysis of rules by a human expert can be done...|$|R
40|$|This paper {{addresses}} {{the problem of}} mitigating the order e#ects in incremental learning, a phenomenon observed when di#erent ordered sequences of observations lead to di#erent results. A modification of an ILP incremental learning system, {{with the aim of}} making it order-independent, is presented. A <b>backtracking</b> <b>strategy</b> on theories is incorporated in its refinement operators, which causes a change of its refinement strategy and reflects the human behavior during the learning process. A modality to restore a previous theory, in order to backtrack on a previous knowledge level, is presented. Experiments validate the approach in terms of computational cost and predictive accuracy...|$|R
40|$|This paper {{presents}} some {{variants of}} the inexact Newton method for solving systems of nonlinear equations defined by locally Lipschitzian functions. These methods use variants of Newton's iteration {{in association with}} Krylov subspace methods for solving the Jacobian linear systems. Global convergence of the proposed algorithms is established under a nonmonotonic <b>backtracking</b> <b>strategy.</b> The local convergence based on the assumptions of semismoothness and BD-regularity at the solution is characterized, {{and the way to}} choose an inexact forcing sequence that preserves the rapid convergence of the proposed methods is also indicated. Numerical examples are given to show the practical viability of these approaches. Department of Applied Mathematic...|$|R
40|$|This paper {{describes}} a powerful inexact matching algorithm {{that has been}} applied with success to high-level 3 D-object representations in a 3 D object recognition system. In a promising way, the algorithm combines several approaches proposed {{in the last couple}} of years: an extension to the <b>backtrack</b> <b>strategies</b> for inexact matching of attributed relational subgraphs, error-correction isomorphism, determination of local attribute similarity and global transformation fitting, features which are efficiently used for search-tree pruning. The algorithm was tested successfully in a series of experiments involving scenes with single and multiple objects. Index terms: 3 D-object recognition, scene analysis, inexact subgraph matching, machine vision 1...|$|R
40|$|To {{determine}} the effects of text messaging on driving performance, all available experimental studies that measured driving performance were identified through a variety of database searches and <b>backtracking</b> <b>strategies,</b> and analyzed using standard research synthesis methods. Fourteen studies with a total of 519 participants were coded and analyzed. Methodology, independent and dependent variables, and statistical analyses varied widely across studies, but conclusions were clear and convergent. Reaction time, crashes, longitudinal and lateral control, eye movements, hazard detection and subjective workload measures indicate significant decrements in driving performance while reading and typing text messages. The importance of the results for further policy development and methodological reporting is briefly introduced...|$|R
3000|$|... est {{components}} in the temporarily estimated signal (calculated in Step 4 in Algorithm 1), are used to form the cosupport. Then, we approximate the signal and update the measurement residual of the current iteration with this cosupport. The <b>backtracking</b> <b>strategy</b> [12, 19], which {{can be described as}} not only selecting rows that match the current residual signal better from the candidate set in each iteration but also excluding the other rows from the cosupport, provides the basis for constructing a more accurate cosupport and obtaining a smaller measurement residual. Here, index(Ωx_temp,q) [...] is reserved for sharing in the backward process. An efficient mechanism is required for stage switching when each stage finishes till l [...]...|$|R
40|$|This report {{describes}} licensing-structure parsing (LS-parsing), a {{computational model}} of human parsing. LS-parsing corresponds to human parsing at three points: (1) {{the order in}} which the LS parser builds nodes is psychologically more accurate than the orders in which either LL or LR parsers build nodes, (2) the LS parser's preferences in resolving local ambiguities are preferable to Frazier's strategies on both empirical and theoretical grounds, and O) the <b>backtracking</b> <b>strategies</b> the parser uses when it has made an error at an earlier choice point model the distinction between weak and strong garden paths [...] strong garden paths being irrecoverable, weak garden paths causing psychological diffculo,, but not preventing recovery of the correct structur...|$|R
40|$|Channel {{management}} in cellular systems involves the initial allocation {{of a set}} of nominal channels to each cell and the assignment of channels to each incoming call. In this paper, we focus on the design of heuristic algorithms for the allocation of nominal channels. We first generalize the concept of compact pattern for cellular systems with irregular cell sizes. Then we explore a combined use of compact pattern and greedy allocation methods called hybrid allocation. The K-optimal variations and <b>backtracking</b> <b>strategies</b> are studied for their effectiveness in homing towards optimality. In a 49 cell network example, it is found that the hybrid allocation with backtracking can increase the system's traffic-carrying capacity by 38 % at 2 % blocking when compared to the uniform channel allocation. link_to_subscribed_fulltex...|$|R
30|$|On {{the basis}} of OMP, Needell and Tropp {{proposed}} compressive sampling matching pursuit (CoSaMP) [15] algorithm. In contrast to the OMP algorithm, CoSaMP algorithm selects two K optimal-related atoms simultaneously then discards K atoms selected before the next iteration. The CoSaMP algorithm is robust noise because of its <b>backtracking</b> <b>strategy</b> for atom selection. A similar atom selection strategy is available between CoSaMP algorithm and subspace pursuit (SP) algorithm [16]. For a better reconstruction result, Needell and Vershynin introduced the regularization constraint to the atom selection strategy of regularized orthogonal matching pursuit (ROMP) algorithm, which selects K optimal-related atoms, then reselect atoms from the previous selected K atom based on the regularization constraint [17]. However, these reconstruction algorithms need to know signal sparsity in advance, which is extremely hard to obtain in practice. Therefore, the practical application of these reconstruction algorithms is not as successful as the theoretical research.|$|R
40|$|A general {{language}} for specifying resource allocation in Scheduling problems is presented. TRAPS is a superclass of the RAPS (Resource Allocation Problem Specification) language {{developed by the}} authors [31]. TRAPS enables the specification of a scheduling problem by adding built in time operators, on top of existing terms for resources, activities, allocation rules and constraints. In this way TRAPS provides a convenient knowledge acquisition tool. The language syntax is powerful and allows the specification of rules and constraints which are difficult to formulate with traditional approaches, and it also supports the specification of various control and <b>backtracking</b> <b>strategies.</b> The generalized inference engine that runs compiled TRAPS programs is enhanced to provide all needed operations for a typical PERT/CPM calculations on a schedule. This engine acts as an expert system shell and is called ESRA (Expert System for Resource Allocation). The performance of TRAPS combined [...] ...|$|R
50|$|ALF was {{designed}} to be genuine integration of both programming paradigms, and thus any functional expression {{can be used in a}} goal literal and arbitrary predicates can occur in conditions of equations. ALF's operational semantics is based on the resolution rule to solve literals and narrowing to evaluate functional expressions. In order to reduce the number of possible narrowing steps, a leftmost-innermost basic narrowing strategy is used which, it is claimed, can be efficiently implemented. Terms are simplified by rewriting before a narrowing step is applied and equations are rejected if the two sides have different constructors at the top. Rewriting and rejection are supposed to result in a large reduction of the search tree and produce an operational semantics that is more efficient than Prolog's resolution strategy. Similarly to Prolog, ALF uses a <b>backtracking</b> <b>strategy</b> corresponding to a depth-first search in the derivation tree.|$|R
40|$|Agents {{that exist}} in an {{environment}} that changes over time, and are able {{to take into account the}} temporal nature of experience, are commonly called incremental learners. It is widely known that incremental learning systems suffer from order effects, a phenomenon observed when differently ordered sequences of examples lead to different results. The goal of this paper is presenting INTHELEXback, an order-independent evolution of the incremental learning system INTHELEX. A <b>backtracking</b> <b>strategy</b> is incorporated in its refinement operators, which causes a change in its refinement strategy and reflects the human behavior during the learning process. It consists in remembering the different versions of the learned theory across modifications due to new evidence. In this way the system can backtrack on a previous knowledge level when it discovers to have made a wrong choice. Experiments on an artificial dataset validate the approach in terms of computational cost and predictive accuracy...|$|R
40|$|Given the intractability of domain-independent planning, {{learning}} effective search control {{knowledge is}} vitally important. One way of learning search control knowledge {{is to use}} explanation based learning (EBL) methods. This paper aims to analyze and understand the factors influencing the effectiveness of EBL. We present an EBL framework for UCPOP, a partial order planner, {{and use it to}} systematically analyze the effect of (i) expressive action representations (ii) domain specific failure theories and (iii) sophisticated <b>backtracking</b> <b>strategies</b> on the utility of EBL. Through empirical studies, we demonstrate that expressive action representations allow for more explicit domain representations which in turn increase the ability of EBL to learn from analytical failures, and obviate the need for domain specific failure theories. We also explore the strong affinity between dependency directed backtracking and EBL in planning. 1 Introduction Given the exponential worst case complexity of d [...] ...|$|R
40|$|In {{this work}} we study the {{numerical}} solution of nonlinear systems arising from stabilized FEM discretizations of Navier-Stokes equations. This {{is a very}} challenging problem and often inexact Newton solvers present severe difficulties to converge. Then, they must be wrapped into a globalization strategy. We consider the classical backtracking procedure, a subspace trust-region strategy and an hybrid approach. This latter strategy is proposed {{with the aim of}} improve the robustness of backtracking and it is obtained combining the backtracking procedure and the elliptical subspace trust-region strategy. Under standard assumptions, we prove global and fast convergence of the inexact Newton methods embedded in this new strategy {{as well as in the}} subspace trust-region procedure. Computational results on classical CFD benchmarks are performed. Comparisons among the classical <b>backtracking</b> <b>strategy,</b> the elliptical subspace trust-region approach and the hybrid procedure are presented. Our numerical experiments show the effectiveness of the proposed hybrid technique...|$|R
40|$|Search {{algorithms}} {{are often}} categorized by their node expansion strategy. One option is the depth-first <b>strategy,</b> a simple <b>backtracking</b> <b>strategy</b> that traverses the search {{space in the}} order in which successor nodes are generated. An alternative is the best-first strategy, which was designed to make it possible to use domain-specific heuristic information. By exploring promising parts of the search space first, best-first algorithms are usually more efficient than depth-first algorithms. In programs that play minimax games such as chess and checkers, the efficiency of the search is of crucial importance. Given the success of best-first algorithms in other domains, one would expect them to be used for minimax games too. However, all high-performance game-playing programs are based on a depth-first algorithm. This study takes a closer look at a depth-first algorithm, Alpha-Beta, and a best-first algorithm, SSS*. The prevailing opinion on these algorithms is that SSS* offers the potential [...] ...|$|R
5000|$|Thus, the <b>backtracking</b> {{line search}} <b>strategy</b> {{starts with a}} {{relatively}} large step size, and repeatedly shrinks it by a factor [...] until the Armijo-Goldstein condition is fulfilled.|$|R
40|$|Many {{problems}} in computer science, especially in Artificial Intelligence, {{can be represented}} as constraint satisfaction problems (CSP). For example, scene labeling in computer vision involves testing possible interpretation of objects against relation rules. Other constraint satisfaction {{problems in}}clude theorem proving, scheduling, expert systems. These problems are typically NP-Complete because they require extensive searches {{to find a solution}} and the basic search algorithm is the naive <b>Backtracking</b> <b>strategy.</b> In order to improve its performances different approaches have been explored: filtering strategies, heuristics for search algorithms, decomposition methods. Although parallelization seems to be a good candidate to obtain further practical improvements the research in this direction is fewly developed. In this paper we explore the benefit of a domain decomposition strategy for parallel CSP resolution. Mainly we solve in parallel the different subproblems resulting from the decomposition step on a shared memory architecture with an OpenMP library. All the experiments were realized with the Sillicon Graphics Origin 2000 parallel machine...|$|R
40|$|Given a set cal P {{of points}} in the Euclidean plane and two triangulations of cal P, the flip {{distance}} between these two triangulations is the minimum number of flips required to transform one triangulation into the other. The Parameterized Flip Distance problem is to decide if the flip distance between two given triangulations is equal to a given integer k. The previous best FPT algorithm runs in time O^*(kcdot c^k) (cleq 2 times 14 ^ 11), where each step has fourteen possible choices, {{and the length of}} the action sequence is bounded by 11 k. By applying the <b>backtracking</b> <b>strategy</b> and analyzing the underlying property of the flip sequence, each step of our algorithm has only five possible choices. Based on an auxiliary graph G, we prove that the length of the action sequence for our algorithm is bounded by 2 |G|. As a result, we present an FPT algorithm running in time O^*(kcdot 32 ^k) ...|$|R
40|$|Pepl, {{parameter}} estimation in Prolog, is an {{implementation of the}} failure adjusted maximisation algorithm (FAM) [4] for Stochastic Logic Programs (Slps) [6, 7]. SLPs extend logic programming by arithmetic labels on clausal definitions. They have well characterised log linear semantics and <b>backtracking</b> <b>strategies</b> [5, 3]. The FAM algorithm was introduced as an extension to the Expectation-Maximization (EM) algorithm and account for failed derivation paths in SLPs [4]. It provides a closed-form for computing the parameter weights within EM’s iterative maximization approach. The algorithm {{has been shown to}} work for normalised SLPs, [4], and is in practice applicable to a wide class of programs. The failure adjusted aspect of the algorithm has also been incorporated in the PRISM system [8]. Pepl is implemented in Prolog and is available as open source. Stochastic clauses are term expanded to standard Prolog ones. Unique identifiers and a path argument are added to the transformation of stochastic clauses. These are used to identify the path of each derivation. In addition failure paths ar...|$|R
40|$|ABSTRACT: The Virgilio {{software}} {{system is a}} general purpose exploration tool for large collections of complex structured data. It generates visualisations {{of the results of}} a query to a database by the help of virtual reality objects, embedded into predefined virtual reality scenarios. This document describes the design, specification, and implementation of the Metaphor Definition Tool. This component of the Virgilio {{software system}} has to identify the most suitable virtual worlds for representing the result of a query. This is achieved by considering the metaphor definition task as a general constraint satisfaction problem. The logical formalism adopted to describe interrelationships among the involved objects corresponds to that of the Prolog programming language, in order to take advantage from its built in <b>backtracking</b> <b>strategy.</b> This paper presents the overall Virgilio architecture, provides a brief introduction to the concept of metaphor and its use within the Virgilio environment, contains a description of the MDT as well as a description of the repositories, and explains how to integrate the MDT into the whole system. Two complex mappin...|$|R
