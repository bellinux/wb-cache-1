607|250|Public
5|$|Binary search trees lend {{themselves}} to fast searching in external memory stored in hard disks, as binary search trees can effectively be structured in filesystems. The <b>B-tree</b> generalizes this method of tree organization; B-trees are frequently used to organize long-term storage such as databases and filesystems.|$|E
5|$|There are {{numerous}} variations of binary search. In particular, fractional cascading speeds up binary {{searches for the}} same value in multiple arrays, efficiently solving a series of search problems in computational geometry and numerous other fields. Exponential search extends binary search to unbounded lists. The binary search tree and <b>B-tree</b> data structures are based on binary search.|$|E
25|$|In addition, a <b>B-tree</b> {{minimizes}} waste {{by making}} sure the interior nodes are at least half full. A <b>B-tree</b> can handle an arbitrary number of insertions and deletions.|$|E
40|$|Two {{modifications}} of <b>B-trees</b> are described, simple prefix <b>B-trees</b> and prefix <b>B-trees.</b> Both store only parts of keys, namely prefixes, {{in the index}} part of a B*-tree. In simple prefix <b>B-trees</b> those prefixes are selected carefully to minimize their length. In prefix <b>B-trees</b> the pre-fixes need not he fully stored, but are reconstructed as the tree is searched. Prefix <b>B-trees</b> are designed to combine some {{of the advantages of}} <b>B-trees,</b> digital search trees, and key compres-sion techniques while reducing the processing overhead of compression techniques...|$|R
40|$|The O-tree is an {{indexing}} mechanism {{closely related to}} <b>B-trees</b> and Prefix <b>B-trees.</b> In this paper we derive the expected storage overhead of O-Trees under the standard Bernoulli model of randomness, compare the results with the expected overhead of <b>B-trees</b> and Prefix <b>B-trees</b> under the same conditions, and assess the expected relative improvements...|$|R
40|$|The use of <b>B-trees</b> for {{achieving}} good performance for updates and retrievals in databases is well-known. Many excellent implementations of <b>B-trees</b> are available as well. However {{it is difficult}} to find <b>B-trees</b> that are easily configured and deployed into experimental systems. We undertake an implementation of <b>B-trees</b> from scratch that specifically addresses configurability and deployablility issue. An XML file is used to store as well as document information such as page formats of the nodes of the <b>B-trees</b> and details about the nature of records and keys. The behavior of the tree is encapsulated by commands for creation of <b>B-trees,</b> insertions of records in the tree, and make retrievals via the tree. The XML based configuration together with commands make the deployment and functionality of the tree completely clear and straightforward...|$|R
25|$|In applications, it is {{frequently}} useful {{to build a}} <b>B-tree</b> to represent a large existing collection of data and then update it incrementally using standard <b>B-tree</b> operations. In this case, {{the most efficient way}} to construct the initial <b>B-tree</b> is not to insert every element in the initial collection successively, but instead to construct the initial set of leaf nodes directly from the input, then build the internal nodes from these. This approach to <b>B-tree</b> construction is called bulkloading. Initially, every leaf but the last one has one extra element, which will be used to build the internal nodes.|$|E
25|$|A <b>B-tree</b> {{of depth}} n+1 can hold about U {{times as many}} items as a <b>B-tree</b> of depth n, {{but the cost of}} search, insert, and delete {{operations}} grows with the depth of the tree. As with any balanced tree, the cost grows much more slowly than the number of elements.|$|E
25|$|There are two popular {{strategies}} for deletion from a <b>B-tree.</b>|$|E
40|$|ABSTRACT The O-tree is an {{indexing}} mechanism {{closely related to}} <b>B-trees</b> and Prefix <b>B-trees.</b> In this paper we derive the expected storage overhead of O-Trees under the standard Bernoulli model of randomness, compare the results with the expected overhead of Btrees and Prefix <b>B-trees</b> under the same conditions, and assess the expected relative improvements...|$|R
50|$|<b>B-trees</b> are generalizations of {{binary search}} trees {{in that they}} can have a {{variable}} number of subtrees at each node. While child-nodes have a pre-defined range, they will not necessarily be filled with data, meaning <b>B-trees</b> can potentially waste some space. The advantage is that <b>B-trees</b> {{do not need to be}} re-balanced as frequently as other self-balancing trees.|$|R
5000|$|Where {{they differ}} is on {{insertion}}s, deletions and updates. An insertion in a Fractal Tree index takes [...] whereas <b>B-trees</b> require [...] Thus, Fractal Tree indexes are faster than <b>B-trees</b> {{by a factor}} of [...] Since [...] can be quite large, this yields a potential two-order-of-magnitude improvement in worst-case insertion times, which is observed in practice. Both <b>B-trees</b> and Fractal Tree indexes can perform insertions faster in the best case. For example, if keys are inserted in sequential order, both data structures achieve a [...] I/Os per insertion. Thus, because the best and worst cases of <b>B-trees</b> differ so widely, whereas Fractal Tree indexes are always near their best case, the actual speedup that Fractal Tree indexes achieve over <b>B-trees</b> depends on the details of the workload.|$|R
25|$|The term <b>B-tree</b> may {{refer to}} a {{specific}} design or it may {{refer to a}} general class of designs. In the narrow sense, a <b>B-tree</b> stores keys in its internal nodes but need not store those keys in the records at the leaves. The general class includes variations such as the B+ tree and the B* tree.|$|E
25|$|Let h be {{the height}} of the classic <b>B-tree.</b> Let n > 0 be the number of entries in the tree. Let m be the maximum number of {{children}} a node can have. Each node can have at most m−1 keys.|$|E
25|$|Different {{kinds of}} data {{structures}} are suited to {{different kinds of}} applications, and some are highly specialized to specific tasks. For example, databases use <b>B-tree</b> indexes for small percentages of data retrieval and compilers and databases use dynamic hash tables as look up tables.|$|E
40|$|In {{this paper}} we explore the use of weak <b>B-trees</b> to {{represent}} sorted lists. In weak <b>B-trees</b> each node has at least a and at most b sons where 2 a<b. We analyse the worst case cost of sequences of insertions and deletions in weak <b>B-trees.</b> This leads to a new data structure (level-linked weak <b>B-trees)</b> for representing sorted lists when the access pattern exhibits a (time-varying) locality of reference. Our structure is substantially simpler than the one proposed in [7], yet it has many of its properties. Our structure {{is as simple as}} the one proposed in [5], but our structure can treat arbitrary sequences of insertions and deletions whilst theirs can only treat non-interacting insertions and deletions. We also show that weak <b>B-trees</b> support concurrent operations in an efficient way...|$|R
5000|$|... 2-3-4 {{trees are}} <b>B-trees</b> of order 4; like <b>B-trees</b> in general, they can search, insert and delete in O(log n) time. One {{property}} of a 2-3-4 tree {{is that all}} external nodes are at the same depth.|$|R
30|$|Since the {{outsourced}} ciphertexts are indistinguishable, encrypted <b>B-Trees</b> {{can be used}} {{to protect}} attributes against D&BKQ-attackers that have access to the outsourced data as well as background knowledge on the data and the queries (cf. Figure 3). However, since encrypted <b>B-Trees</b> do not provide access confidentiality, they are not suited to provide protection against a Q&BKD-attacker that has background knowledge of the data and can monitor queries/modifications. Once an attacker can observe queries or modifications, they are not only able to distinguish ciphertexts, but can also infer the order of the ciphertexts due to the <b>B-Tree’s</b> ordered structure [23]. Thus, if queries or modifications that target specific records can be observed, encrypted <b>B-Trees</b> can only provide security guarantees against Q&NBK-attackers that have no background knowledge.|$|R
25|$|A <b>B-tree</b> is kept {{balanced}} by requiring that all leaf nodes {{be at the}} same depth. This depth will increase slowly as elements {{are added to the}} tree, but an increase in the overall depth is infrequent, and results in all leaf nodes being one more node farther away from the root.|$|E
25|$|Internal nodes are all nodes {{except for}} leaf nodes and the root node. They are usually {{represented}} as an ordered set of elements and child pointers. Every internal node contains {{a maximum of}} U children and a minimum of L children. Thus, the number of elements is always 1 less {{than the number of}} child pointers (the number of elements is between L−1 and U−1). U must be either 2L or 2L−1; therefore each internal node is at least half full. The relationship between U and L implies that two half-full nodes can be joined to make a legal node, and one full node can be split into two legal nodes (if there’s room to push one element up into the parent). These properties make it possible to delete and insert new values into a <b>B-tree</b> and adjust the tree to preserve the <b>B-tree</b> properties.|$|E
25|$|Each {{internal}} node of a <b>B-tree</b> {{contains a}} number of keys. The keys act as separation values which divide its subtrees. For example, if an internal node has 3 child nodes (or subtrees) then it must have 2 keys: a1 and a2. All values in the leftmost subtree will be less than a1, all values in the middle subtree will be between a1 and a2, and all values in the rightmost subtree will be greater than a2.|$|E
40|$|<b>B-trees</b> {{have been}} {{ubiquitous}} in database management systems for several decades, {{and they are}} used in other storage systems as well. Their basic structure and basic operations are well and widely understood including search, insertion, and deletion. Concurrency control of operations in <b>B-trees,</b> however, {{is perceived as a}} difficult subject with many subtleties and special cases. The purpose of this survey is to clarify, simplify, and structure the topic of concurrency control in <b>B-trees</b> by dividing it into two sub-topics and exploring each of them in depth. ...|$|R
40|$|Gupta, Lee and Wong {{described}} algorithms {{for generating}} 2 - 3 trees and <b>B-trees</b> with a given number of nodes and left as open problems whether algorithms exist that generate them in lexicographic order, {{and whether it}} is possible to generate 2 - 3 trees (GLW) or <b>B-Trees</b> (GLW 1) in constant average delay, exclusive of the output. In this thesis, we propose solutions to the open problems in both (GLW) and (GLW 1). The main results of this thesis are: introducing a new notation of <b>B-Trees</b> which provides lexicographic order and a proof that (GLW) and (GLW 1) algorithms do have a constant average delay (thus solving two open problems posed by Gupta, Lee and Wong). A new algorithm for generating 2 - 3 trees, with a given number of nodes, in lexicographic order is also presented. This algorithm is an improvement over (GLW) in terms of time complexity and storage. An algorithm for lexicographic generation of <b>B-Trees</b> with a given number of leaves is described. Finally new algorithms for coding and decoding <b>B-Trees</b> sequentially are described...|$|R
50|$|<b>B-trees</b> grow at {{the root}} and not at the leaves.|$|R
25|$|For {{physical}} storage of a table, its rows {{are divided into}} a series of partitions (numbered 1 to n). The partition size is user defined; by default all rows are in a single partition. A table is split into multiple partitions in order to spread a database over a computer cluster. Rows in each partition are stored in either <b>B-tree</b> or heap structure. If the table has an associated, clustered index to allow fast retrieval of rows, the rows are stored in-order according to their index values, with a <b>B-tree</b> providing the index. The data is in the leaf node of the leaves, and other nodes storing the index values for the leaf data reachable from the respective nodes. If the index is non-clustered, the rows are not sorted according to the index keys. An indexed view has the same storage structure as an indexed table. A table without a clustered index is stored in an unordered heap structure. However, the table may have non-clustered indices to allow fast retrieval of rows. In some situations the heap structure has performance advantages over the clustered structure. Both heaps and B-trees can span multiple allocation units.|$|E
25|$|In B-trees, {{internal}} (non-leaf) nodes {{can have}} a variable number of child nodes within some pre-defined range. When data is inserted or removed from a node, its number of child nodes changes. In {{order to maintain the}} pre-defined range, internal nodes may be joined or split. Because a range of child nodes is permitted, B-trees do not need re-balancing as frequently as other self-balancing search trees, but may waste some space, since nodes are not entirely full. The lower and upper bounds on the number of child nodes are typically fixed for a particular implementation. For example, in a 2-3 <b>B-tree</b> (often simply referred to as a 2-3 tree), each internal node may have only 2 or 3 child nodes.|$|E
25|$|TOPS-20 (and {{possibly}} TENEX) used a 0 to 2 level {{tree that}} has similarities to a <b>B-tree.</b> A disk block was 512 36-bit words. If the file {{fit in a}} 512 (29) word block, then the file directory would point to that physical disk block. If the file fit in 218 words, then the directory would point to an aux index; the 512 words of that index would either be NULL (the block isn't allocated) or point to the physical address of the block. If the file fit in 227 words, then the directory would point to a block holding an aux-aux index; each entry would either be NULL or point to an aux index. Consequently, the physical disk block for a 227 word file could be located in two disk reads and read on the third.|$|E
2500|$|The {{literature}} on <b>B-trees</b> is not uniform in its terminology [...]|$|R
25|$|Some {{balanced}} trees store values only at leaf nodes, and {{use different}} kinds of nodes for leaf nodes and internal nodes. <b>B-trees</b> keep values in every node in the tree, and may use the same structure for all nodes. However, since leaf nodes never have children, the <b>B-trees</b> benefit from improved performance if they use a specialized structure.|$|R
50|$|Fractal Tree {{indexing}} {{technology is}} {{a new approach to}} indexing that replaces <b>B-trees.</b>|$|R
500|$|Some SQL {{products}} do not index keys containing NULLs. For instance, PostgreSQL [...] versions {{prior to}} 8.3 did not, with the documentation for a <b>B-tree</b> index stating that ...|$|E
500|$|An early {{result in}} this {{direction}} was provided by [...] using the cell probe model of computation (an artificial model in which the complexity of an algorithm is measured only {{by the number of}} memory accesses it performs). Building on their work, [...] described two data structures, the Q-heap and the atomic heap, that are implementable on a random access machine. The Q-heap is a bit-parallel version of a binary trie, and allows both priority queue operations and successor and predecessor queries to be performed in constant time for sets of [...] items, where [...] is the size of the precomputed tables needed to implement the data structure. The atomic heap is a <b>B-tree</b> in which each tree node is represented as a Q-heap; it allows constant time priority queue operations (and therefore sorting) for sets of [...] items.|$|E
2500|$|It can {{be shown}} (by {{induction}} for example) that a <b>B-tree</b> of height h with all its nodes completely filled has n= m'h+11 entries. Hence, the best case height of a <b>B-tree</b> is: ...|$|E
5000|$|Efficient use of <b>B-trees</b> {{to achieve}} high {{performance}} even with very large directories.|$|R
50|$|For {{moderate}} {{volumes of}} values, insertions and deletions in a colored binary tree are faster compared to <b>B-trees</b> because colored trees don't attempt {{to maximize the}} fill factor of each horizontal cluster of nodes (only the minimum fill factor is guaranteed in colored binary trees, {{limiting the number of}} splits or junctions of clusters). <b>B-trees</b> will be faster for performing rotations (because rotations will frequently occur within the same cluster rather than with multiple separate nodes in a colored binary tree). For storing large volumes, however, <b>B-trees</b> will be much faster as they will be more compact by grouping several children in the same cluster where they can be accessed locally.|$|R
50|$|Guibas et al.introduced ﬁnger search trees, by {{building}} upon <b>B-trees.</b> The original version supports ﬁnger searches in O(log d) time, where d {{is the number}} of elements between the ﬁnger and the search target. Updates take O(1) time, when only O(1) moveable ﬁngers are maintained. Moving a ﬁnger p positions requires O(log p) time. Huddleston and Mehlhorn refined this idea as level-linked <b>B-trees.</b>|$|R
