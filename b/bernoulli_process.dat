302|159|Public
5|$|A {{classic example}} of a random walk {{is known as the}} simple random walk, which is a {{stochastic}} process in discrete time with the integers as the state space, and is based on a <b>Bernoulli</b> <b>process,</b> where each iid Bernoulli variable takes either the value positive one or negative one. In other words, the simple random walk takes place on the integers, and its value increases by one with probability, say, , or decreases by negative one with probability , so index set of this random walk is the natural numbers, while its state space is the integers. If the , this random walk is called a symmetric random walk.|$|E
25|$|From any <b>Bernoulli</b> <b>process</b> one may derive a <b>Bernoulli</b> <b>process</b> with pnbsp&=nbsp&1/2 by the von Neumann extractor, the {{earliest}} randomness extractor, which actually extracts uniform randomness.|$|E
25|$|In other words, a <b>Bernoulli</b> <b>process</b> is a {{sequence}} of independent identically distributed Bernoulli trials.|$|E
40|$|A {{computationally}} {{efficient algorithm}} for characterizing the superposition process of N heterogeneous and independent Interrupted <b>Bernoulli</b> <b>Processes</b> is introduced. The algorithm is {{then used to}} analyze a statistical multiplexer with finite buffer. Finally, numerical examples highlighting the algorithm accuracy are given. ...|$|R
40|$|One of {{a number}} of <b>Bernoulli</b> <b>processes</b> is {{selected}} at each {{of a number}} of stages. A success at stage i is worth [alpha]i and the problem is to maximize the expected payoff before the first failure. Results of Berry and Viscusi (1981) are generalized. In particular, we show that there is always an optimal strategy that uses a single process exclusively and indefinitely whenever the arms are independent and the discount sequence ([alpha] 1, [alpha] 2, [...] .) is superregular. There is not always a similar {{reduction in the number of}} strategies when the discount sequence is not superregular. Many-armed bandits sequential decisions gambling with discounting <b>Bernoulli</b> <b>processes</b> single-arm strategies stay-on-a-winner rule...|$|R
5000|$|Specifically, {{suppose that}} there are two random, {{independent}} bit streams called stochastic numbers (i.e. <b>Bernoulli</b> <b>processes),</b> where the probability of a one in the first stream is , and the probability in the second stream is [...] We can take the logical AND of the two streams.|$|R
25|$|To {{conclude}} the formal definition, a <b>Bernoulli</b> <b>process</b> is then {{given by the}} probability triple , as defined above.|$|E
25|$|The term Bernoulli {{sequence}} {{is often used}} informally {{to refer to a}} realization of a <b>Bernoulli</b> <b>process.</b>|$|E
25|$|Consider {{tossing a}} coin with known, not {{necessarily}} fair, probabilities of coming up heads or tails; {{this can be}} modelled as a <b>Bernoulli</b> <b>process.</b>|$|E
40|$|Abstract—We {{consider}} {{two related}} problems of estimating properties {{of a collection}} of point processes: estimating the multiset of parameters of continuous-time Poisson processes based on their activities {{over a period of time}} t, and estimating the multiset of activity probabilities of discrete-time <b>Bernoulli</b> <b>processes</b> based on their activities over n time instants. For both problems, it is sufficient to consider the observations’ profile—the multiset of activity counts, regardless of their process identities. We consider the profile maximum likelihood (PML) esti-mator that finds the parameter multiset maximizing the profile’s likelihood, and establish some of its competitive performance guarantees. For Poisson processes, if any estimator approximates the parameter multiset to within distance with error probability δ, then PML approximates the multiset to within distance 2 with error probability at most δ · e 4 t·S, where S is the sum of the Poisson parameters, and the same result holds for <b>Bernoulli</b> <b>processes.</b> In particular, for the L 1 distance metric, we relate the problems to the long-studied distribution-estimation problem and apply recent results to show that the PML estimator has error probability e−(t·S) 0. 9 for Poisson processes whenever the number of processes is k = O(tS log(tS)), and show a similar result for <b>Bernoulli</b> <b>processes.</b> We also show experimental results where the EM algorithm is used to compute the PML. I...|$|R
40|$|Abstract. In {{this paper}} we {{investigate}} the statistics of large waiting times (with {{respect to the}} total waiting time) for <b>Bernoulli</b> <b>processes.</b> We deter-mine the corresponding rate functions explicitly and prove a large deviations asymptotic. By this we have estabished a large deviation principle for which the rate function is not the Legendre transform of some free energy function...|$|R
40|$|In this article, recent {{progress}} on ML-randomness {{with respect to}} conditional probabilities is reviewed. In particular a new result of conditional randomness with respect to mutually singular probabilities are shown, which is a generalization of Hanssen's result (2010) for <b>Bernoulli</b> <b>processes.</b> Comment: Presented at Probability Symposium RIMS (2016 Dec.), and Ergodic theory and related area (Tsukuba Univ. 2016 Nov. ...|$|R
25|$|If {{the process}} is infinite, then from any point the future trials {{constitute}} a <b>Bernoulli</b> <b>process</b> identical to the whole process, the fresh-start property.|$|E
25|$|This {{value is}} the Bernoulli entropy of a <b>Bernoulli</b> <b>process.</b> Here, H stands for entropy; do not confuse {{it with the}} same symbol H {{standing}} for heads.|$|E
25|$|For {{the special}} case where r is an integer, the {{negative}} binomial distribution {{is known as the}} Pascal distribution. It is the probability distribution of a certain number of failures and successes in a series of independent and identically distributed Bernoulli trials. For knbsp&+nbsp&r Bernoulli trials with success probability p, the negative binomial gives the probability of k successes and r failures, with a failure on the last trial. In other words, the {{negative binomial distribution}} is the probability distribution of the number of successes before the rth failure in a <b>Bernoulli</b> <b>process,</b> with probability p of successes on each trial. A <b>Bernoulli</b> <b>process</b> is a discrete time process, and so the number of trials, failures, and successes are integers.|$|E
40|$|In {{this paper}} we {{investigate}} the statistics of large waiting times (with {{respect to the}} total waiting time) for <b>Bernoulli</b> <b>processes.</b> We determine the corresponding rate functions explicitly and prove a large deviations asymptotic. By this we have estabished a large deviation principle for which the rate function is not the Legendre transform of some free energy function. Comment: 11 pages, 3 figure...|$|R
40|$|Timothy Williamson {{has claimed}} {{to prove that}} {{regularity}} must fail even in a nonstandard setting, with a counterexample based on tossing a fair coin infinitely many times. I argue that Williamson’s argument is mistaken, and that a corrected version shows {{that it is not}} regularity which fails in the non-standard setting but a fundamental property of shifts in <b>Bernoulli</b> <b>processes...</b>|$|R
40|$|Abstract. We present three {{methods to}} {{construct}} majorizing measures in various settings. These methods {{are based on}} direct constructions of increasing sequences of partitions through a simple exhaustion procedure {{rather than on the}} construction of well separated ultrametric subspaces. The first scheme of construction provides a simple unified proof of the Majorizing Measure Theorem for Gaussian processes and of the following fact. If A, B are balanced convex sets in a vector space, and if A is sufficiently convex, a control of the covering numbers N(A, εB) for all ε> 0 implies the (a priori stronger) existence of a majorizing measure on A provided with the distance induced by B. This establishes, apparently for the first time, a clear link between geometry and majorizing measures, and generalizes the earlier results on majorizing measures on ellipsoids in Hilbert space, that were obtained by specific methods. Much {{of the rest of the}} paper is concerned with the structure of bounded <b>Bernoulli</b> (=Radmacher) <b>processes.</b> The main conjecture on their structure is reformulated in several ways, that are shown to be equivalent, and to be equivalent to the existence of certain majorizing measures. Two schemes of construction of majorizing measures related to this problem are presented. One allows to describe <b>Bernoulli</b> <b>processes</b> when the index set, provided with the supremum norm, is sufficiently small. The other allows to prove a weak form of the main conjecture. This result, while not sufficient to characterize boundedness of <b>Bernoulli</b> <b>processes,</b> allows to prove the remarkable fact that for any continuous operator T from C(K) to E, the Rademacher cotype- 2 constant of T is controlled by the maximum of the Gaussian cotype- 2 constant of T and of its (2, 1) -summing norm. It is also proved, as a consequence of one of the main inequalities on <b>Bernoulli</b> <b>processes,</b> that in a Banach space E of dimension n, at most n log n log log n vectors suffices to compute the Rademacher cotype 2 constant of E within a universal constant...|$|R
25|$|A Bernoulli {{scheme is}} a special case of a Markov chain where the {{transition}} probability matrix has identical rows, {{which means that the}} next state is even independent of the current state (in addition to being independent of the past states). A Bernoulli scheme with only two possible states is known as a <b>Bernoulli</b> <b>process.</b>|$|E
500|$|The <b>Bernoulli</b> <b>process,</b> {{which can}} serve as a {{mathematical}} model for flipping a biased coin, is possibly the first stochastic process to have been studied. The process is [...] a sequence of independent Bernoulli trials, which are named after Jackob Bernoulli who used them to study games of chance, including probability problems proposed and studied earlier by Christiaan Hugens. Bernoulli's work, including the <b>Bernoulli</b> <b>process,</b> were published in his book Ars Conjectandi in 1713.|$|E
500|$|One of the {{simplest}} stochastic processes is the <b>Bernoulli</b> <b>process,</b> which is a sequence of independent and identically distributed (iid) random variables, where each random variable takes either the value one with probability, say, [...] and value zero with probability [...] This process can be likened to somebody flipping a coin, where the probability of obtaining a head is [...] and its value is one, while {{the value of a}} tail is zero. In other words, a <b>Bernoulli</b> <b>process</b> is a sequence of iid Bernoulli random variables, where each coin flip is a Bernoulli trial.|$|E
40|$|What {{constitutes}} jointly Poisson processes {{remains an}} unresolved issue. This report reviews {{the current state}} of the theory and indicates how the accepted but unproven model equals that resulting from the small time-interval limit of jointly <b>Bernoulli</b> <b>processes.</b> One intriguing consequence of these models is that jointly Poisson processes can only be positively correlated as measured by the correlation coefficient defined by cumulants of the probability generating functional. ...|$|R
40|$|<b>Bernoulli</b> {{selecting}} <b>processes</b> {{are generally}} considered as valuable analytical tools for making decisions in many disciplines of particular {{theoretical and practical}} importance. The present paper concentrates on the formulation, investigation and actuarial applications of a stochastic model describing a <b>Bernoulli</b> selecting <b>process.</b> It is shown that the formulated stochastic model can substantially support the applicability of such a selecting process for making insurance decisions incorporating significant elements of proactivity. Actuarial Decision, Stochastic Model, Risk...|$|R
40|$|AbstractWe {{consider}} {{the problem of}} the determination of the largest modulus of a root of a complex polynomial P. We obtain lower and upper bounds using properties of appropriate linear recurrent sequences associated with P. This allows giving the absolute value of a dominant root as the limit as in <b>Bernoulli’s</b> <b>process.</b> We finally discuss a rule of Jacobi in his refinement of Bernoulli’s method. Relevant examples are obtained through pari and maple procedures...|$|R
2500|$|A <b>Bernoulli</b> <b>process</b> is {{a finite}} or {{infinite}} sequence of {{independent random variables}} X1,X2,X3,..., such that ...|$|E
2500|$|In {{probability}} and statistics, a <b>Bernoulli</b> <b>process</b> is {{a finite}} or infinite sequence of binary random variables, {{so it is}} a discrete-time stochastic process that takes only two values, canonically 0 and1. The component Bernoulli variables X'i are identically distributed and independent. [...] Prosaically, a <b>Bernoulli</b> <b>process</b> is a repeated coin flipping, possibly with an unfair coin (but with consistent unfairness). [...] Every variable X'i in the sequence is associated with a Bernoulli trial or experiment. They all have the same Bernoulli distribution. Much of what can be said about the <b>Bernoulli</b> <b>process</b> can also be generalized to more than two outcomes (such as the process for a six-sided die); this generalization is known as the Bernoulli scheme.|$|E
2500|$|... for {{any given}} random {{variable}} [...] out of the infinite sequence of Bernoulli trials that compose the <b>Bernoulli</b> <b>process.</b>|$|E
3000|$|... (t) {{represents}} {{the number of}} packet arrivals at time t and is a <b>Bernoulli</b> stationary <b>process</b> with finite mean E[X [...]...|$|R
40|$|The book {{develops}} modern {{methods and}} in particular the "generic chaining" to bound stochastic processes. This methods allows in particular to get optimal bounds for Gaussian and <b>Bernoulli</b> <b>processes.</b> Applications are given to stable processes, infinitely divisible processes, matching theorems, the convergence of random Fourier series, of orthogonal series, and to functional analysis. The complete solution of a number of classical problems is given in complete detail, and an ambitious program for future research is laid out...|$|R
40|$|A {{computationally}} {{efficient algorithm}} for characterizing the superposition process of heterogeneous and independent Interrupted <b>Bernoulli</b> <b>Processes</b> is introduced. The algorithm is {{then used to}} analyze a statistical multiplexer with finite buffer. Numerical examples highlighting the algorithm accuracy are given. We use the analysis to validate the equivalent capacity and heavy traffic approximation methods which are popular methods for call admission control in an ATM network. We also show the algorithmcan be used to handle the case of homogeneous sporadic on/off sources...|$|R
2500|$|John von Neumann posed {{a curious}} {{question}} about the Bernoulli process: is it ever possible that a given process is isomorphic to another, {{in the sense of}} the isomorphism of dynamical systems? The question [...] long defied analysis, but was finally and completely answered with the Ornstein isomorphism theorem. [...] This breakthrough resulted in the understanding that the <b>Bernoulli</b> <b>process</b> is unique and universal; in a certain sense, it is the single most random process possible; nothing is 'more' random than the <b>Bernoulli</b> <b>process</b> (although one must be careful with this informal statement; certainly, systems that are mixing are, in a certain sense, 'stronger' than the <b>Bernoulli</b> <b>process,</b> which is merely ergodic but not mixing. However, such processes do not consist of independent random variables: indeed, many purely deterministic, non-random systems can be mixing).|$|E
2500|$|Suppose a <b>Bernoulli</b> <b>process</b> {{formally}} {{defined as}} a single random variable (see preceding section). For every infinite sequence x of coin flips, there is a sequence of integers ...|$|E
2500|$|The <b>Bernoulli</b> <b>process</b> {{can also}} be {{understood}} to be a dynamical system, specifically, a measure-preserving dynamical system. [...] This arises {{because there is a}} natural translation symmetry on the (two-sided) product space [...] given by the shift operator ...|$|E
40|$|We {{propose a}} decode-forward {{protocol}} for streaming over a relay network using sequential random tree codes. An achievable bound on the end-to-end error performance is derived. The bound is parameterised {{by the number}} of errors occuring at the relay, which is the sum of correlated <b>Bernoulli</b> <b>processes.</b> The bound is useful for determining the achievable delay-exponent as well as for designing finite-delay relaying schemes. For a wide range of conjectured correlation models, the proposed scheme can achieve the delay-exponent of full source-relay cooperation. ...|$|R
40|$|This report {{considers}} a fairly general model of constrained queuing networks {{that allows us}} to represent both MMBP (Markov Modulated <b>Bernoulli</b> <b>Processes)</b> arrivals and time-varying service constraints. We derive a set of sufficient conditions for throughput optimality of scheduling policies that encompass and generalize all the previously obtained results in the field. This leads to the definition of new classes of (non diagonal) throughput optimal scheduling policies. We prove the stability of queues by extending the traditional Lyapunov drift criteria methodology...|$|R
40|$|International audienceThis paper {{presents}} a distributed state filtering strategy for large scale network controlled systems. The distributed state filtering scheme is obtained {{by considering the}} interconnection signals between subsystems as intermittent unknown inputs and by applying on each subsystem {{a modified version of}} the unknown input Kalman filter restricted, in its original version, to the treatment of permanent unknown inputs. The stochastic stability conditions of the filter are established from an upper bound of the mean prediction error covariance matrix and independent <b>Bernoulli</b> <b>processes</b> for the data exchange rates between subsystems...|$|R
