23|10000|Public
2500|$|Although <b>both</b> <b>models</b> <b>have</b> <b>similar</b> assumptions, {{they have}} very {{different}} implications: ...|$|E
50|$|<b>Both</b> <b>models</b> <b>have</b> <b>similar</b> requirements, such as trip {{planners}} {{to construct}} optimal trip chains, and technical and business relationships with transport service providers, (i.e. a taxi booking/payment API and e-ticketing, QR codes on urban buses and metros, etc.).|$|E
30|$|At {{the bottom}} of the channel, <b>both</b> <b>models</b> <b>have</b> <b>similar</b> {{electrical}} field distribution.|$|E
5000|$|After discontinuing the Eagle brand in 1998, Chrysler was {{planning}} to expand the Plymouth line {{with a number of}} unique models before the corporation's merger with Daimler-Benz AG. The first model was the Plymouth Prowler, a hot rod-styled sports car. The PT Cruiser was to have been the second. <b>Both</b> <b>models</b> <b>had</b> <b>similar</b> front-end styling, suggesting Chrysler intended a retro styling theme for the Plymouth brand. At the time of Daimler's takeover of Chrysler, Plymouth <b>had</b> no <b>models</b> besides the Prowler not also offered in similar version by Dodge.|$|R
30|$|The {{real time}} {{susceptibility}} to shallow landslides has been assessed by Montrasio et al. (2011) for Emilion Apennine in north Italy. They compared SLIP (shallow Landslide Instability Prediction) and TRIGRS (Transient Rainfall Infiltration and Grid based Slope Stability) models of landslide susceptibility analysis in GIS (Geographical Information System) environment. The {{results of the}} study indicates that <b>both</b> the <b>models</b> <b>have</b> <b>similar</b> predictive capability.|$|R
40|$|The clinical, morphologic, histochemical, and {{biochemical}} {{features of}} GM 1 -gangliosidosis in two canine models, English Springer Spaniel (ESS) and Portuguese Water Dog (PWD), have been compared. The disease onset, its clinical course, and survival {{period of the}} affected dogs were similar in <b>both</b> <b>models.</b> Skeletal dysplasia was noted radiographically at 2 months of age, whereas at 4 1 / 2 months of age there was progressive neurologic impairment. However, dwarfism and coarse facial features were seen only in ESS. <b>Both</b> <b>models</b> <b>had</b> <b>similar</b> deficiency in activity of lysosomal beta-galactosidase, but possessed a normal protein activator for GM 1 -beta-galactosidase. <b>Both</b> <b>models</b> stored GM 1 -ganglioside, asialo-GM 1, and oligosaccharides in brain. Furthermore, only the PWD stored glycoproteins containing polylactosaminoglycans in visceral organs, and neither model stored them in the brain. Morphologically, <b>both</b> <b>models</b> demonstrated similar storage material in multiple tissues and cell types. The ultrastructure of the storage material was cell-type specific and identical in <b>both</b> <b>models.</b> However, some differences in the lectin staining pattern were noted. Our clinical, biochemical, and histochemical findings indicate that PWD and ESS may represent two different mutations of the beta-galactosidase gene. Moreover, the authors conclude that it is difficult, and inappropriate, to apply the human classification of GM 1 -gangliosidosis (i. e. infantile, juvenile, and adult forms) to these canine models...|$|R
30|$|Comparing {{errors in}} detail based on NN types, {{we find that}} using {{techniques}} like adding the momentum rate to the classic gradient descent method did not improve the performance. <b>Both</b> <b>models</b> <b>have</b> <b>similar</b> performance, and it is notable that the R 2 values in the models are very close and high for both one- and two-step-ahead predictions. Comparing errors based on data types (univariate and multivariate) shows that using spatial attributes {{in addition to the}} temporal ones improves the performance.|$|E
40|$|The {{transport}} {{characteristics of}} particulate contaminants in a displacement ventilated room containing a seated thermal manikin were investigated, using the Eulerian-Eulerian {{model and the}} Eulerian-Lagrangian model, respectively. Numerical results of airflow field, particle trajectories and particle concentration were compared and analysed. It was found that when the same inter-phase interaction mechanisms are considered, the <b>both</b> <b>models</b> <b>have</b> <b>similar</b> predictive capacities {{in terms of the}} velocity and temperature fields. However, the Eulerian-Eulerian model, which requires less computational cost, gives a direct prediction to the particle concentration while the Eulerian-Lagrangian model needs an additional post-processing procedure to estimate the particle concentration, which makes its accuracy of concentration prediction subjected to the stability of the post-processing procedure...|$|E
40|$|Abstract. Various {{interacting}} lattice path {{models of}} polymer collapse in two dimensions demonstrate different critical behaviours. This difference has been {{without a clear}} explanation. The collapse transition has been variously seen {{to be in the}} Duplantier-Saleur θ-point university class (specific heat cusp), the interacting trail class (specific heat divergence) or even first-order. Here we study via Monte Carlo simulation a generalisation of the Duplantier-Saleur model on the honeycomb lattice and also a generalisation of the so-called vertex-interacting self-avoiding walk model (configurations are actually restricted trails known as grooves) on the triangular lattice. Crucially for both models we have three and two body interactions explicitly and differentially weighted. We show that <b>both</b> <b>models</b> <b>have</b> <b>similar</b> phase diagrams when considered in these larger two-parameter spaces. They demonstrate regions for which the collapse transition is first-order for high three body interactions and regions where the collapse is in the Duplantier-Saleur θ-point university class. We conjecture a higher order multiple critical point separating these two types of collapse. 1...|$|E
50|$|Alongside the SC-8850, Roland {{released}} the Roland ED SC-8820, an inexpensive cut-down {{version of the}} MIDI module, smaller than the 8850. Both sound canvases could be rackmounted alongside each other.The Roland SC-8820 model lacks the large LCD screen and extended controls of the SC-8850. Some sounds are different {{in comparison to the}} 8850, but has a map that is compatible with the 8850. <b>Both</b> <b>models</b> <b>have</b> external appearance <b>similar</b> to Roland's older models.|$|R
40|$|Title The Analysis of Structure Change on East Java Economic Year 1997 2007. (Researcher: Diki Mardiansah, Supervisor: Dra. Dwi Susilowati, MM, Co-Supervisor: Dra. Sudarti, M. Si.) The {{research}} has purpose {{to find out}} change of economic structure in East Java province. The method used in this research is descriptive statistical analysis and Chow Breakpoint Test. <b>Both</b> of <b>models</b> <b>have</b> <b>similar</b> goal to find out general review about region economic and economic structure {{and to find out}} change of structure at the region economic. From test resulted was obtained East Java economic structure period 1997 - 2007, indicated change of economic structure presented by sector change become tertiary sector. During 1997 2007, contribution of primary sector to East Java PDRB 20, 80...|$|R
40|$|AbstractIn this paper, {{impact of}} {{meteorology}} {{derived from the}} Weather, Research and Forecasting (WRF) – Non–hydrostatic Mesoscale Model (NMM) and WRF–Advanced Research WRF (ARW) meteorological models on the Community Multiscale Air Quality (CMAQ) simulations for ozone and its related precursors has been comparatively evaluated over the eastern United States using surface network (AIRNow) data and over the Texas area with the intensive observations obtained by NOAA aircraft P– 3 flights and ship during the 2006 TexAQS/GoMACCS campaign. The NMM–CMAQ and ARW–CMAQ models were run {{on the basis of}} their original grid structures of the meteorological models. The results at the AIRNow surface sites showed that the model performance for ARW–CMAQ and NMM–CMAQ models was similar and reasonable for the high maximum 8 –hr O 3 concentration range (> 40 ppbv) with slightly better performance for ARW–CMAQ [the normalized mean bias (NMB) values of ARW–CMAQ and NMM–CMAQ are 8. 1 and 9. 4 %, respectively]. The results of the evaluation using aircraft observations over the Houston–Galveston–Brazoria and Dallas metropolitan areas revealed that <b>both</b> <b>models</b> <b>had</b> <b>similar</b> performances for different chemical species (O 3, CO, PAN, NO 2, NO, NOX, HNO 3, NOY and ethylene) as <b>both</b> <b>models</b> use the same chemical mechanism and emissions. <b>Both</b> <b>models</b> reproduced the vertical variation patterns of the observed air temperature and water vapor well with the slightly lower values for the ARW–CMAQ model. The evaluation results with ship observations over the Gulf of Mexico showed that <b>both</b> <b>models</b> captured, with a good deal of accuracy, the temporal variations and broad synoptic change seen in the observed O 3, NOY, CO and O 3 +NO 2 with the mean NMB value < 25 % most of the time...|$|R
40|$|Accelerating Chaplygin gas {{combined}} with the decelerating braneworld Dvali-Gabadadze-Porrati (DGP) model can produce an overall accelerated expansion {{of the order of}} magnitude seen. <b>Both</b> <b>models</b> <b>have</b> <b>similar</b> asymptotic properties at early and late cosmic times, and are characterized by a length scale. Taking the length scales to be proportional one obtains a combined model with three free parameters, one more than the LCDM model, which fits supernovae data equally well. We further constrain it by the CMB shift parameter, and by requiring that the model yields a longer age of the Universe than that of the oldest star HE 1523 - 0901, t * = 13. 4 ± 0. 8 (stat) ± 1. 8 (syst). In contrast to generalized DGP and Chaplygin gas models, this is a genuine alternative to the cosmological constant model because it does not reduce to it in any limit of the parameter space. Comment: 11 pages, 4 figure...|$|E
40|$|The {{interaction}} between a power {{system and a}} wind-farm can be studied using either a simplified 'aggregated' or a complex 'detailed' model. The detailed-model results compare well with the actual, therefore, provided that <b>both</b> <b>models</b> <b>have</b> <b>similar</b> dynamic characteristics, the aggregated model provides a rapid and cost-effective way of representing large wind-farms in power system dynamic studies. A brief overview of windfarm aggregation methods is given and their application in power systems analysis is discussed. Aggregation techniques are then applied to a wind-farm with thirty wind turbines. It is shown that the aggregation of the swing equation and equivalent representation of network and generator impedances {{can be used for}} aggregated representation of fixed speed wind turbines. A similar approach applied to the d- and q- axis controller of a doubly-fed induction generator (DFIG) failed initially to provide satisfactory dynamic characteristics with the aggregated model. Consequently, a simple method was used to scale the rotor currents of the controller, so the dynamic characteristics with DFIGs became acceptable...|$|E
40|$|Sensitization is {{an example}} of {{malfunctioning}} of the nociceptive pathway in either the peripheral or central nervous system. Using quantitative sensory testing, one can only infer sensitization, but not determine the defective subsystem. The states of the subsystems may be characterized using computational modeling together with experimental data. Here, we develop a neurophysiologically plausible model replicating experimental observations from a psychophysical human subject study. We study the effects of single temporal stimulus parameters on detection thresholds corresponding to a 0. 5 detection probability. To model peripheral activation and central processing, we adapt a stochastic drift-diffusion model and a probabilistic hazard model to our experimental setting without reaction times. We retain six lumped parameters in both models characterizing peripheral and central mechanisms. <b>Both</b> <b>models</b> <b>have</b> <b>similar</b> psychophysical functions, but the hazard model is computationally more efficient. The model-based effects of temporal stimulus parameters on detection thresholds are consistent with those from human subject data...|$|E
40|$|Hip {{fractures}} commonly {{result in}} permanent disability, institutionalization or death in elderly. Existing hip-fracture predicting tools are underused in clinical practice, {{partly due to}} their lack of intuitive interpretation. By use of a graphical layer, Bayesian network models could increase the attractiveness of fracture prediction tools. Our aim was to study the potential contribution of a causal Bayesian network in this clinical setting. A logistic regression was performed as a standard control approach to check the robustness of the causal Bayesian network approach. EPIDOS is a multicenter study, conducted in an ambulatory care setting in five French cities between 1992 and 1996 and updated in 2010. The study included 7598 women aged 75 years or older, in which fractures were assessed quarterly during 4 years. A causal Bayesian network and a logistic regression were performed on EPIDOS data to describe major variables involved in hip fractures occurrences. <b>Both</b> <b>models</b> <b>had</b> <b>similar</b> association estimations and predictive performances. They detected gait speed and mineral bone density as variables the most involved in the fracture process. The causal Bayesian network showed that gait speed and bone mineral density were directly connected to fracture and seem to mediate the influence {{of all the other}} variables included in our model. The logistic regression approach detected multiple interactions involving psychotropic drug use, age and bone mineral density. Both approaches retrieved similar variables as predictors of hip fractures. However, Bayesian network highlighted the whole web of relation between the variables involved in the analysis, suggesting a possible mechanism leading to hip fracture. According to the latter results, intervention focusing concomitantly on gait speed and bone mineral density may be necessary for an optimal prevention of hip fracture occurrence in elderly people...|$|R
40|$|The puropuse of {{this thesis}} was {{to study and}} compare a {{simulation}} model and a reference model of the Delay Tolerant Network architecture. The simulation model was created during a previous thesis at Luleå university of technology by Henrik Eriksson and Patrik Jönsson. When tested, {{it was discovered that}} neither model were complete. They both lacked certain features. The simulation model did not behave in a very good way when the custody transfer feature was disabled and the reference <b>model</b> did not <b>have</b> the custody transfer feature at all. Therefore <b>both</b> <b>models</b> were modified during this thesis. After the modification were done, a number of different tests were run on <b>both</b> <b>models.</b> These tests generated data which were used to produce graphs. These graphs were used to compare the behaviour of the models. They showed that <b>both</b> <b>models</b> <b>had</b> a <b>similar</b> behaviour which indicated that the simulation model is a good choice for testing different networks with the bundling protocol. Validerat; 20101217 (root...|$|R
40|$|Many {{background}} error correlation (BEC) {{models in}} data assimilation are for-mulated {{in terms of}} a positive-definite smoothing operator B which simulates the action of correlation matrix on a vector in state space. To estimate the ef-ficiency of such approach, numerical experiments with the Gaussian and spline models B = exp(Vi/V); Bm = (l — J have been conducted. Here I is the identity operator and v is the diffusion tensor, whose spatial variability is derived from the forecast field and m is the spline approximation order. Performance of these BEC representations are compared in the frame-work of numerical experiments with real 3 dVar data assimilation into the Navy Coastal Ocean model (NCOM) in the Western TVopical Pacific. It is shown that <b>both</b> BEC <b>models</b> <b>have</b> <b>similar</b> forecast skills over a two-month time period, whereas the second-order spline model is several times more efficient compu-tationally if the cost function is minimized in the state space...|$|R
40|$|This paper {{integrates}} {{a theory}} of equilibrium unemployment into a monetary model with nominal price rigidities. The model is used to study the dynamic response of the economy to a monetary policy shock. The labor market displays search and matching frictions and bargaining over real wages and hours of work. Search frictions generate unemployment in equilibrium. Wage bargaining introduces a microfounded real wage rigidity. First, I study a Nash bargaining model. Then, I develop an alternative bargaining model, which I refer to as right-to-manage bargaining. <b>Both</b> <b>models</b> <b>have</b> <b>similar</b> predictions in terms of real wage dynamics: bargaining significantly reduces the volatility of the real wage. But they have different implications for inflation dynamics: under right-to-manage, the real wage rigidity also results in smaller fluctuations of inflation. These {{findings are consistent with}} recent evidence suggesting that real wages and inflation only vary by a moderate amount in response to a monetary shock. Finally, the model can explain important features of labor-market fluctuations. In particular, a monetary expansion leads to a rise in job creation and to a hump-shaped decline in unemployment. ...|$|E
40|$|Various {{interacting}} lattice path {{models of}} polymer collapse in two dimensions demonstrate different critical behaviours. This difference has been {{without a clear}} explanation. The collapse transition has been variously seen {{to be in the}} Duplantier-Saleur θ-point university class (specific heat cusp), the interacting trail class (specific heat divergence) or even first-order. Here we study via Monte Carlo simulation a generalisation of the Duplantier-Saleur model on the honeycomb lattice and also a generalisation of the so-called vertex-interacting self-avoiding walk model (configurations are actually restricted trails known as grooves) on the triangular lattice. Crucially for both models we have three and two body interactions explicitly and differentially weighted. We show that <b>both</b> <b>models</b> <b>have</b> <b>similar</b> phase diagrams when considered in these larger two-parameter spaces. They demonstrate regions for which the collapse transition is first-order for high three body interactions and regions where the collapse is in the Duplantier-Saleur θ-point university class. We conjecture a higher order multiple critical point separating these two types of collapse. Comment: 17 pages, 20 figure...|$|E
30|$|The 2007 Niigata-ken Chuetsu-oki {{earthquake}} generated strong ground motions in Kashiwazaki and Kariwa, {{where the}} world largest nuclear power plant was in operation. Due {{to the complexity of}} the aftershock distribution, activation of the northwest-dipping fault and/or the southeast-dipping fault is proposed. To explore the fault geometry and source process of the earthquake, we performed multi-time window linear waveform inversions for both the fault planes from near-fault strong motion data. A fault plane model of 30 km in length by 24 km in width was set to cover the region of aftershock distribution within 24 h of the mainshock. Both inverted slip models provided moment magnitudes of 6.7 with a small asperity near the rupture starting point, and a large asperity approximately 10 km southwest of the rupture initiation, which is located in the region of relatively sparse aftershock distribution. Both the small and large asperities are located near the intersection between the two conjugate fault plane models, and the asperities of <b>both</b> <b>models</b> <b>have</b> <b>similar</b> radiation patterns. Therefore, the difference of the residuals between the observed and synthetic waveforms for both models was not significant, indicating {{that it is difficult to}} conclude which fault is the rupture.|$|E
40|$|Abstract Background An {{important}} public health {{goal is to}} decrease the prevalence of key behavioural risk factors, such as tobacco use and obesity. Survey information is often available at the regional level, but heterogeneity within large geographic regions cannot be assessed. Advanced spatial analysis techniques are demonstrated to produce sensible micro area estimates of behavioural risk factors that enable identification of areas with high prevalence. Methods A spatial Bayesian hierarchical model was used to estimate the micro area prevalence of current smoking and excess bodyweight for the Erie-St. Clair region in southwestern Ontario. Estimates were mapped {{for male and female}} respondents of five cycles of the Canadian Community Health Survey (CCHS). The micro areas were 2006 Census Dissemination Areas, with an average population of 400 – 700 people. Two individual-level models were specified: one controlled for survey cycle and age group (model 1), and one controlled for survey cycle, age group and micro area median household income (model 2). Post-stratification was used to derive micro area behavioural risk factor estimates weighted to the population structure. SaTScan analyses were conducted on the granular, postal-code level CCHS data to corroborate findings of elevated prevalence. Results Current smoking was elevated in two urban areas for both sexes (Sarnia and Windsor), and an additional small community (Chatham) for males only. Areas of excess bodyweight were prevalent in an urban core (Windsor) among males, but not females. Precision of the posterior post-stratified current smoking estimates was improved in model 2, as indicated by narrower credible intervals and a lower coefficient of variation. For excess bodyweight, <b>both</b> <b>models</b> <b>had</b> <b>similar</b> precision. Aggregation of the micro area estimates to CCHS design-based estimates validated the findings. Conclusions This is among the first studies to apply a full Bayesian model to complex sample survey data to identify micro areas with variation in risk factor prevalence, accounting for spatial correlation and other covariates. Application of micro area analysis techniques helps define areas for public health planning, and may be informative to surveillance and research modeling of relevant chronic disease outcomes...|$|R
40|$|We {{consider}} supersymmetric {{models in}} which sneutrinos are viable dark matter candidates. These are either simple {{extensions of the}} Minimal Supersymmetric Standard Model with additional singlet superfields, such as the inverse or linear seesaw, or a model with an additional U(1) group. All of these models can accomodate the observed small neutrino masses and large mixings. We investigate the properties of sneutrinos as dark matter candidates in these scenarios. We check for phenomenological bounds, such as correct relic abundance, consistency with direct detection cross section limits and laboratory constraints, among others lepton flavour violating (LFV) charged lepton decays. While inverse and linear seesaw lead to different results for LFV, <b>both</b> <b>models</b> <b>have</b> very <b>similar</b> dark matter phenomenology, consistent with all experimental bounds. The extended gauge model shows some additional and peculiar features due {{to the presence of}} an extra gauge boson Z' and an additional light Higgs. Specifically, we point out that for sneutrino LSPs there is a strong constraint on the mass of the Z' due to the experimental bounds on the direct detection scattering cross section...|$|R
40|$|ABSTRACT Using {{the annual}} data of Iran’s economy from 1981 - 2012, this study {{examines}} Wagner’s law and the Keynesian hypothesis {{about the relationship between}} the real government expenditure and the real GDP. In this regard, this paper investigated the relationship between the total government expenditure, the GDP and the relationship between government educational expenditure and GDP using bivariate and multivariate models. The multivariate model is used to reduce the specified error issues that has not been considered in many studies. The co-integration was examined using the auto regressive distributive lag method (ARDL) of both long-term and short-term relationships. In making the estimations of the Wagner’s view, the variables: real GDP, capital stock and labor force stock respectively, had a positive, a negative, and a positive impact on total government expenditure and the long-term relationship is true in this regard. Additionally, in the estimation of Keynesian model, the educational expenditures, unlike real expenditures of government, had a long-term relationship. In addition, the variable, capital, in <b>both</b> <b>models</b> <b>had</b> a <b>similar</b> effect on the real GDP, and the labor force coefficient {{in the presence of the}} total expenditures and educational expenditures were negative and positive respectively...|$|R
40|$|This work {{presents}} a computational modelling study of CaSiO 3 glass, with {{the aims of}} examining the local atomic environment of Ca, {{the interpretation of the}} Ca-Ca distribution, and the influence of network topology. One model was constructed using the molecular dynamics method and has a broad Q(n) distribution, whereas another model was constructed using the reverse Monte Carlo method to control network topology and has a narrow Qn distribution. Both models have average Ca-O coordination with N = 6. 3 and modal distance R = 2. 40 angstrom, which are in fair agreement with previous experimental results. In both models the majority of bridging oxygens are also coordinated to Ca. Hence nonbridging oxygens by themselves are not sufficient to define the interface between network former and network modifier regions. Despite having different Q(n) distributions, <b>both</b> <b>models</b> <b>have</b> <b>similar</b> x-ray diffraction structure factor and Ca-Ca distribution, and these are in fair agreement with experimental results. Hence strong effects due to network topology are not exhibited. The Ca-Ca distribution is not similar to that in wollastonite and {{there is no evidence of}} layer like ordering of CaON polyhedra, in contradiction to a previous interpretatio...|$|E
40|$|Abstract: Sammel and Ryan (1996) {{developed}} a latent variable model {{that allows for}} covariate effects on multiple continuous outcomes. While the approach provides an effective tool for data reduction and global test for covariate effects, it makes strong assumptions about the covariance among the outcomes. In addition, some parameters are common to both the mean and variance suggesting that robustness could be a problem. This manuscript evaluates model misspecification on tests of exposure effects derived from the latent variable model. We develop a robust score test which is valid under misspecified variance assumptions and compare it to one based on Generalized Estimating Equations (GEE) (Liang and Zeger (1986)), under varying assumptions on the true model. <b>Both</b> <b>models</b> <b>have</b> <b>similar</b> loss in power under variance misspecification while the estimated global effect of the covariate is more biased towards the null for the GEE model than the LV model. As the variance/scale of the outcomes increases, {{the performance of the}} LV model improves. As for asymptotic comparisons, test performance depends upon the amount of variability and correlation among the outcomes. The LV model test is superior when the data are highly correlated, ρ> 0. 3, and with large variance. When uncorrelated outcomes are incorporated, the GEE model is superior, except when only the correlated outcomes are impacted by the exposure. Key words and phrases: Factor analysis, generalized estimating equations, global tests. 1...|$|E
40|$|Two {{knockout}} mouse {{models for the}} autism candidate gene Neurobeachin (Nbea) have been generated independently. Although <b>both</b> <b>models</b> <b>have</b> <b>similar</b> phenotypes, one striking difference is the dwarf phenotype observed in the heterozygous configuration of the GH 240 B model that is generated by the serendipitous insertion of a promoterless human growth hormone (hGH) genomic fragment in the Nbea gene. In order to elucidate this discrepancy, the dwarfism present in this Nbea mouse model was investigated in detail. The growth deficiency in Nbea+/ 2 mice coincided with an increased percentage of fat mass {{and a decrease in}} bone mineral density. Low but detectable levels of hGH were detected in the pituitary and hypothalamus of Nbea+/ 2 mice but not in liver, hippocampus nor in serum. As a consequence, several members of the mouse growth hormone (mGH) signaling cascade showed altered mRNA levels, including a reduction in growth hormone-releasing hormone mRNA in the hypothalamus. Moreover, somatotrope cells were less numerous in the pituitary of Nbea+/ 2 mice and both contained and secreted significantly less mGH resulting in reduced levels of circulating insulin-like growth factor 1. These findings demonstrate that the random integration of the hGH transgene in this mouse model has not only inactivated Nbea but has also resulted in the tissue-specific expression of hGH causing a negativ...|$|E
40|$|Two {{models of}} the neocortex are {{developed}} to study normal and pathologic neuronal activity. One model contains {{a detailed description of}} a neocortical microcolumn represented by 656 neurons, including superficial and deep pyramidal cells, four types of inhibitory neurons, and realistic synaptic contacts. Simulations show that neurons of a given type exhibit similar, synchronized behavior in this detailed model. This observation is captured by a population model that describes the activity of large neuronal populations with two differential equations with two delays. <b>Both</b> <b>models</b> appear to <b>have</b> <b>similar</b> sensitivity to variations of total network excitation. Analysis of the population model reveals the presence of multistability, which was also observed in various simulations of the detailed model...|$|R
40|$|The Galileo SSI camera {{acquired}} {{high resolution}} (< 100 m/pixel) stereoimages in Galymede's Galileo Regio and Uruk Sulcus during the encounters in June (G 1) and September (G 2) 1996. The images were taken at similar solar illumination and from camera positions separated enough for good stereo conditions. We performed a photogrammetric {{analysis of these}} image data and derived Digital Terrain Models and orthophotos (rectified images). The obtained terrain models cover an area of 22 km x 30 km (Uruk Sulcus) and 63 km x 102 km (Galileo Regio), and have spatial resolutions of 200 m/pixel and 300 m/pixel, respectively. The resolution is {{by a factor of}} three poorer than the resolution of the images, due to limitations of the digital image correlation approach. We used patch sizes (correlation windows) of 15 pixels to cope with strong compression artifacts in the G 2 -images. <b>Both</b> terrain <b>models</b> <b>have</b> <b>similar</b> characteristic height ranges on the order of 1 km. Heights are relative heights becuase ground control information was not available. The Uruk Sulcus terrain shows distinct large-scale grooves and ridges aligned with visible dark and bright surface lineaments. This strong correlation of elevation with material brightness may hold information on the processes that have formed this terrain type and needs to be further explored...|$|R
40|$|Airmanship is {{considered}} important for aviators. Kern describes {{a model that}} provides a theoretical structure of airmanship, based on research conducted in the USA. Kern states that the fundamental principles of airmanship are: "skill, proficiency and the discipline to apply them in a safe and efficient manner". In addition, there are six areas of critical expertise, which are shown as pillars of knowledge: self, team, aircraft, environment, risk and mission. According to Kern it is {{the combination of the}} basic principles with expert knowledge that enables an aviator to maintain situational awareness and exercise good judgement in decision making, and thus display good airmanship. Ebbage and Spencer present a simplified model of airmanship with three main factors: discipline, control and judgement. Discipline includes self-improvement, vigilance, co-operation and confidence. Judgement covers situational awareness, problem solving, mental workload and foresight, while control refers to flying skills, automation skills, information management, navigation and communication skills. This model specifies broader skill sets than the Kern <b>model.</b> <b>Both</b> <b>models</b> <b>have</b> a <b>similar</b> emphasis on discipline. Ebbage and Spencer consider the foundations of airmanship to be the underlying knowledge, skills and attitudes and that these should be included in any flight training program. The current research addresses whether Australian aviators consider airmanship to include similar concepts to Kern's model and whether there are any additional themes specific to the Australian industry...|$|R
40|$|The {{purpose of}} this econometric {{analysis}} is to model the concentration of particle number emissions from a hybrid diesel-electric bus in terms of operating characteristics. Important aspects {{of this study are}} that particle number concentrations are modeled instead of particle mass, and the emissions are recorded using on-board instrumentation in real-world driving conditions. The operating characteristics included in the final models are two engine parameters: fuel rate and engine speed and two vehicle parameters: velocity and acceleration. The emissions data possess properties that frequently cause problems in regression analysis: nonstationarity, multicollinearity, heteroscedasticity, and autocorrelation. Methods for overcoming and/or minimizing the effects of these properties are implemented. The Newey-West autocorrelation consistent covariance estimator is implemented using ordinary least squares (OLS) to produce a model that accounts for heteroscedasticity and autocorrelation, without requiring assumptions to be made about the structure of the model disturbances. A first-order autoregressive process is used with feasible generalized least squares as a comparative model. <b>Both</b> <b>models</b> <b>have</b> <b>similar</b> coefficients, fit and predictive capability. However the models are specific in scope to typical freeway driving conditions. In future studies, the researchers anticipate applying econometric analysis to model particle number emissions among different routes, bus technologies, aftertreatments, and atmospheric conditions. This research was sponsored in part by the Joint Highway Research Advisory Council of the University of Connecticut and the Connecticut Department of Transportation through Project 05 - 9...|$|E
40|$|International audienceModeling studies {{addressing}} {{daily to}} interannual coastal evolution typically relate shoreline change with waves, currents and sediment transport through complex processes and feedbacks. For wave-dominated environments, the main driver (waves) {{is controlled by}} the regional atmospheric circulation. Here a simple weather regime-driven shoreline model is developed for a 15 -year shoreline dataset (2000 – 2014) collected at Truc Vert beach, Bay of Biscay, SW France. In all, 16 weather regimes (four per season) are considered. The centroids and occurrences are computed using the ERA- 40 and ERA-Interim reanalyses, applying k-means and EOF methods to the anomalies of the 500 -hPa geopotential height over the North Atlantic Basin. The weather regime-driven shoreline model explains 70 % of the observed interannual shoreline variability. The application of a proven wave-driven equilibrium shoreline model to the same period shows that <b>both</b> <b>models</b> <b>have</b> <b>similar</b> skills at the interannual scale. Relation between the weather regimes and the wave climate in the Bay of Biscay is investigated and the primary weather regimes impacting shoreline change are identified. For instance, the winter zonal regime characterized by a strengthening of the pressure gradient between the Iceland low and the Azores high is associated with high-energy wave conditions and is found to drive an increase in the shoreline erosion rate. The study demonstrates the predictability of interannual shoreline change from a limited number of weather regimes, which opens new perspectives for shoreline change modeling and encourages long-term shoreline monitoring programs...|$|E
40|$|Background: Numerous {{studies have}} {{investigated}} the impact of smoke-free laws on health outcomes. Large differences in estimates are in part attributable to how the long-term trend is modelled. However, the choice of appropriate trend is not always straightforward. We explore these complexities {{in an analysis of}} myocardial infarction (MI) mortality in England before and after the introduction of smoke-free legislation in July 2007. Methods: Weekly rates of MI mortality among men aged 40 + between July 2002 and December 2010 were analysed using quasi-Poisson generalised additive models. We explore two ways of modelling the long-term trend: (1) a parametric approach, where we fix the shape of the trend, and (2) a penalised spline approach, in which we allow the model to decide on the shape of the trend. Results: While <b>both</b> <b>models</b> <b>have</b> <b>similar</b> measures of fit and near identical fitted values, they have different interpretations of the legislation effect. The parametric approach estimates a significant immediate reduction in mortality rate of 13. 7 % (95 % CI: 7. 5, 19. 5), whereas the penalised spline approach estimates a non-significant reduction of 2 % (95 % CI:- 0. 9, 4. 8). After considering the implications of the models, evidence from sensitivity analyses and other studies, we conclude that the second model is to be preferred. Conclusions: When there is a strong long-term trend and the intervention of interest also varies over time, it is difficult for models to separate out the two components. Our recommendations will help further studies determine the best way of modelling their data...|$|E
40|$|Structural {{responses}} {{obtained with}} finite element simulations normally {{differ from those}} measured on physical prototypes. In the case of monolithic structures, {{the differences between the}} simulated and measured responses are mainly caused by inaccuracies in the geometry and material behavior. The present work focuses on evaluating the impact of using a high-fidelity representation of the actual geometry on the differences between measured and computed resonant frequencies and mode shapes. This paper presents a study that was performed on a cast-iron lantern housing of a gear box. In a first step, the resonant frequencies and modes shapes of the test structure were measured using impact testing. Next, optical scanning and photogrammetric techniques were used to obtain a 3 D virtual point cloud model which accurately describes the surface of the lantern housing. This point cloud was then used to generate a 3 D solid finite element model representing the as-built geometry of the housing. To evaluate the impact of using the actual geometry on the correlation and model updating results, two FE-models were used: an FE-model derived from the measured geometry and an FE-model derived from the CAD model of the lantern housing. <b>Both</b> <b>models</b> <b>have</b> a <b>similar</b> mesh density and mesh quality. These two models were first correlated with the measured modal data and then updated. The geometry appeared to {{have a significant impact on}} both the correlation and updating results. ...|$|R
40|$|Calibration and {{validation}} of hydrological models for simulating stream flow {{can usually be}} a promising procedure for future sustainable watershed development. Therefore, development of hydrological models with attributed capabilities is vital to explore the models. Recently, arid climate regions are facing critical water resource problems due to elevated water scarcity. The main objective {{of this research is}} to compare the Soil and Water Assessment Tool (SWAT), a knowledge driven by semi-distributed hydrological model, with the Modular Neural Network (MNN), a data driven technique, in predicting the daily flow in arid and large scale. Development of SWAT required digital elevation map, hydro-meteorological data, land use map, and soil maps; whilst, the MNN only needed hydro-meteorological data. For <b>both</b> <b>models,</b> a sensitivity analysis that included both calibration {{and validation}} with individual uncertainty evaluation methods was carried out. Generally, results for relative errors such as Nash-Sutcliffe, coefficient of determination and percent of bias favored the SWAT for the validation period. Not only that, the absolute error criteria such as root mean square error, mean square error and mean relative error obtained were close to zero for the SWAT as well within the same period. The mean absolute error for <b>both</b> <b>models</b> was similar during the validation period. Results of the uncertainty evaluation were in satisfactory range. <b>Both</b> <b>models</b> <b>had</b> given <b>similar</b> trend for flow prediction during the validation period. Results of box plot, according to 50 % (median) of daily flow, showed that <b>both</b> <b>models</b> <b>had</b> respectively overestimated (MNN) and underestimated (SWAT) the daily flow during validation period. Evaluation on runoff volume for each year showed that <b>both</b> <b>models</b> <b>had</b> a one-year underestimation and three-year overestimation in the same period. However, the overestimation of MNN was more obvious. As a conclusion, this study showed that <b>both</b> <b>models</b> <b>have</b> promising prediction performance for daily flow in a large scale watershed with arid climat...|$|R
40|$|Experimental {{studies on}} {{allergic}} asthma {{are limited by}} {{the high cost of}} the administrated allergens. In this study we tested the allergic potency of low fat milk as a cheap substitute to the widely used standard allergen, ovalbumin (OVA). BALB/c female mice (4  weeks old) were sensitized intraperitoneally with low fat milk/or OVA followed by intranasal challenge with the two allergens on days 28 and 29. At day 31, serum, bronchoalveolar lavage fluid (BALF), and lungs were harvested. Mice of the low fat milk model showed infiltration of eosinophils, macrophages, lymphocytes, and neutrophils in BALF comparable to that of the OVA <b>model.</b> <b>Both</b> allergic protocols led to the production of similar numbers of Th 2 cells and induced comparable expression of Th 2 cytokine (IL- 13) as evident by real time PCR for IL- 13 and GATA 3 (Th 2 transcription factor) and confirmed by immunofluorescence for Th 2 surface markers (T 1 /ST 2). In addition, <b>both</b> mouse <b>models</b> <b>had</b> <b>similar</b> elevated levels of allergen specific antibody, IgG 1 and IgE. Notably, HE, PAS, and LUNA stained lung sections from low fat milk treated mice had higher average pathological scores as compared to OVA treated mice. In conclusion, this study suggests that the low fat milk-induced inflammation showed hallmarks of allergic airway inflammatory model such as eosinophilic influx in BALF, increased numbers of Th 2 cells, augmented expression of IL- 13, elevated levels of circulatory IgG 1 and IgE, signs of robust pulmonary inflammation, and most importantly it is a cheap and promising model for studying acute allergic airway inflammation and acute asthma...|$|R
