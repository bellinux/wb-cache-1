15|62|Public
5000|$|... de:Memory Address Register und Memory Buffer Register#Memory <b>Buffer</b> <b>Register</b> ...|$|E
50|$|In {{cases where}} the {{parallel}} outputs should not change during the serial loading process, it is desirable to use a latched or buffered output. In a latched shift register (such as the 74595) the serial data is first loaded into an internal <b>buffer</b> <b>register,</b> then upon receipt of a load signal {{the state of the}} <b>buffer</b> <b>register</b> is copied into a set of output registers. In general, the practical application of the serial-in/parallel-out shift register is to convert data from serial format on a single wire to parallel format on multiple wires.|$|E
5000|$|A two-way {{register}} {{that holds}} data fetched from memory (and {{ready for the}} CPU to process) or data waiting to be stored in memory. (This {{is also known as}} the memory <b>buffer</b> <b>register</b> (MBR).) ...|$|E
40|$|This paper {{considers}} the rate optimal VLSI {{design of a}} re-cursive data flow graph (DFG). Previous research on rate optimal scheduling is not directly applicable to VLSI de-sign. We propose a technique that inserts <b>buffer</b> <b>registers</b> to allow overlapped rate optimal implementation of VLSI. We illustrate that nonoverlapped schedules can be implemented by a simpler control path but with a larger unfolding factor, if exists, than overlapped schedules. ...|$|R
5000|$|Larger {{number of}} memory sockets which use <b>registered</b> (<b>buffered)</b> modules ...|$|R
30|$|The “RAMStick” {{class has}} several {{attributes}} relevant to power consumption estimation: voltage reflects the supply voltage {{under which the}} memory module operates which is highly dependent on the type (e.g. DDR 1, DDR 2, DDR 3, etc.), whereas size and frequency indicate respectively the size (in GB) and frequency (in MHz) of the memory, vendor denotes the manufacturer (e.g. KINGSTON, HYNIX, etc.), bufferType shows the type of the memory module in terms of buffer technology (e.g. fully <b>buffered,</b> <b>buffered,</b> <b>registered,</b> and unbuffered). It is worthwhile to mention that values of all the above-mentioned attributes are provided by the manufacturer’s data sheet.|$|R
50|$|The Memory Data Register (MDR) or Memory <b>Buffer</b> <b>Register</b> (MBR) is the {{register}} of a computer's control unit {{that contains the}} data to be stored in the computer storage (e.g. RAM), or the data after a fetch from the computer storage. It acts like a buffer and holds anything that is copied from the memory ready for the processor to use it.|$|E
5000|$|The {{electronics}} of a basic PDP-8 CPU {{has only}} four 12-bit registers: the accumulator, program counter, memory-buffer register, and memory-address register. To save money, these {{were designed to}} serve multiple purposes {{at different points in}} the operating cycle. For example, the memory <b>buffer</b> <b>register</b> provides arithmetic operands, is part of the instruction register, and stores data to rewrite the core memory. (This restores the core data destroyed by the read.) ...|$|E
50|$|A memory <b>buffer</b> <b>{{register}}</b> (MBR) is {{the register}} in a computer's processor, or central processing unit, CPU, that stores the data being transferred {{to and from}} the immediate access store. It contains the copy of designated memory locations specified by the memory address register. It acts as a buffer allowing the processor and memory units to act independently without being affected by minor differences in operation. A data item will be copied to the MBR ready for use at the next clock cycle, when it can be either used by the processor for reading or writing or stored in main memory after being written.|$|E
50|$|The 82497 Cache Controller {{implements}} the MESI write-back {{protocol for}} full multiprocessing support. Dual ported <b>buffers</b> and <b>registers</b> allow the 82497 to concurrently handle CPU bus, memory bus, and internal cache operation for maximum performance.|$|R
40|$|Abstract- This paper enumerates low power, {{high speed}} {{designed}} circuits like 5 T TSPC D-Flip Flop and 4 T Schmitt trigger having less number of transistors. As the transistors used have small area and low power consumption, {{they can be}} used in various applications like digital VLSI clocking system, <b>buffers,</b> <b>registers,</b> microprocessors, etc. So the leakage current of these devices will increase significantly with the shrinking of semiconductor process technologies. The most straight forward and effective method for reducing standby leakage is power-gating. In this Multithreshold Voltage Based CMOS (MTCMOS) technique is used as a power gating method to optimize power and delay in the circuits...|$|R
40|$|This paper enumerates low power, {{high speed}} design of Flip-Flops having less number of {{transistors}} {{and only one}} transistor being clocked by short pulse train which is true single phase clocking (TSPC) Flip-Flop. As transistors used have small area and low power consumption, {{they can be used}} in various applications like digital VLSI clocking system, <b>buffers,</b> <b>registers,</b> microprocessors etc. The Flip-Flops are analyzed at 90 nm, 70 nm and 50 nm technologies. As the technology is scaled down, the leakage power increases, which is reduced by using MTCMOS technique. The designed Flip-Flops and Latches are compared in terms of power consumption, propagation delays and power dissipation product using DSCH and Microwind tools...|$|R
5000|$|Von Neumann’s {{machine design}} uses a RISC (Reduced {{instruction}} set computing) architecture, {{which means the}} instruction set uses a total of 21 instructions to perform all tasks. (This {{is in contrast to}} CISC, complex instruction set computing, instruction sets which have more instructions from which to choose.) With von Neumann architecture, main memory along with the accumulator (the register that holds the result of logical operations) are the two memories that are addressed. Operations can be carried out as simple arithmetic (these are performed by the ALU and include addition, subtraction, multiplication and division), conditional branches (these are more commonly seen now as [...] statements or [...] loops. The branches serve as [...] statements), and logical moves between the different components of the machine, i.e., a move from the accumulator to memory or vice versa. Von Neumann architecture accepts fractions and instructions as data types. Finally, as the von Neumann architecture is a simple one, its register management is also simple. The architecture uses a set of seven registers to manipulate and interpret fetched data and instructions. These registers include the [...] "IR" [...] (instruction register), [...] "IBR" [...] (instruction <b>buffer</b> <b>register),</b> [...] "MQ" [...] (multiplier quotient register), [...] "MAR" [...] (memory address register), and [...] "MDR" [...] (memory data register)." [...] The architecture also uses a program counter ("PC") to keep track of where in the program the machine is.|$|E
40|$|The {{assembly}} comprises {{a circuit}} for detecting errors in data supplied {{by at least}} one of the blocks of the assembly. When an error has been detected, the assembly is decontaminated by one circuit for backup and reconstitution of past states of a latch associated to a block. The backup and reconstitution circuit comprises a multiplexer and <b>buffer</b> <b>register.</b> The multiplexer comprises a first input directly connected to the output of the latch and a second input connected to this output via the <b>buffer</b> <b>register.</b> A control circuit controls the <b>buffer</b> <b>register</b> and the multiplexer so as to activate the <b>buffer</b> <b>register</b> writing function and connect the output of the multiplexer to its first input at each cycle, during a normal operation phase, and to read enable the <b>buffer</b> <b>register</b> and connect the multiplexer output to its second input during predetermined cycles of a decontamination phase...|$|E
40|$|The {{assembly}} {{drawings of the}} receiver unit are presented for the data compression/error correction digital test system. Equipment specifications are given for the various receiver parts, including the TV input <b>buffer</b> <b>register,</b> delta demodulator, TV sync generator, memory devices, and data storage devices...|$|E
40|$|The 74 ALVT 162823 18 -bit bus {{interface}} register {{is designed}} to eliminate the extra packages required to <b>buffer</b> existing <b>registers</b> and provide extra data width for wider data or address paths of buses carrying parity. The 74 ALVT 162823 has two 9 -bit wide <b>buffered</b> <b>registers</b> with clock enable (nCE) and master reset (nMR) which are ideal for parity bus interfacing in high microprogrammed systems. The registers are fully edge-triggered. The state of each D input, one set-up time before the LOW-to-HIGH clock transition is transferred to the corresponding Q output of the flip-flop. The 74 ALVT 162823 is designed with 30 Ω series resistance in both the pull-up and pull-down output structures. This design reduces line noise in applications such as memory address drivers, clock drivers, and bus receivers or transmitters. ■ Two sets of high speed parallel registers with positive edge-triggered D-type flip-flops ■ 5 V I/O compatible ■ Ideal where high speed, light loading or increased fan-in are required with MOS microprocessors ■ Bus hold data inputs {{eliminate the need for}} external pull-up resistors to hold unused inputs ■ Live insertion and extraction permitted ■ Power-up 3 -state ■ Power-up reset ■ Output capability: + 12 mA to − 12 mA ■ Outputs include series resistance of 30 Ω making external termination resistors unnecessary ■ Latch-up protection: ◆ JESD 78 : exceeds 500 mA ■ ESD protection...|$|R
5000|$|The chomski {{language}} uses {{many ideas}} taken from sed, the Unix stream editor. For example, sed includes two virtual variables or data buffers, {{known as the}} [...] "pattern space" [...] and the [...] "hold space". These two variables constitute an extremely simple virtual machine. In the Chomski language this virtual machine has been augmented with several new <b>buffers</b> or <b>registers</b> along {{with a number of}} commands to manipulate these buffers.|$|R
40|$|International audienceIn today's {{embedded}} systems, {{memory hierarchy}} is rapidly becoming {{a major factor}} in terms of power, performance and area. This is especially true for embedded multimedia applications using temporary multi-dimensional arrays that are typically used to store intermediate results during multimedia processing. In this paper, we propose a new technique that optimizes the use of the cache and the registers. It consists in combining <b>buffer</b> and <b>register</b> allocation {{to reduce the size of}} the temporary arrays. Firstly we use the concept of live data to replace each array by a buffer of lower size. Then we replace references to these <b>buffers</b> by <b>registers.</b> The <b>buffer</b> allocation step keeps only useful data in memory and the register allocation step allows taking advantage of data reuse in internal loops. Codes considered in this paper are multimedia applications structured as a sequence of loop nests. The experiments are made on Unix environment and on the StepNP simulator (MPSoC platform of STMicroelctronics). They show that our technique yields significant reduction of the number of data cache and TLB misses...|$|R
40|$|We {{present an}} {{algorithm}} to schedule basic blocks of vector three-addressinstructions. This algorithm is suited {{for a special}} class of vector processors containing a <b>buffer</b> (<b>register</b> file) which may be partitioned arbitrarily into vector registers by the user. The algorithm computes the best ratio of vector register spilling to strip mining, taking the vector length and the buffer size into consideration, {{as well as several}} machine parameters of the target architecture. We apply the algorithm to groups of vector instructions within a basic block that are quasiscalar, i. e. all vectors occurring in the group must have one fixed length L...|$|E
40|$|AbstractThis {{work is a}} {{complementary}} part for what we proposed in [1]. In this paper, an undergraduate design experience for special purpose 4 -bit microprocessor using the skills learned from digital logic design and Microprocessors courses is presented. The experience started in [1] by designing the ALU using the hardware printed circuit board and we are following it by completing the design by the instruction set architecture and the microprogram code. Our microprocessor contains – {{in addition to the}} ALU- six registers: A 4 -bit accumulator register, Flag register that holds only zero (Z) and carry (C) flags, Program counter register (PC), Memory address register (MAR), Instruction register (IR), and <b>Buffer</b> <b>Register.</b> All programs and data are stored in the 1 k RAM...|$|E
40|$|A digital {{controller}} for controlling {{the operation of}} a folding machine enables automatic folding of a desired number of sheets responsive to entry of that number into a selector. The controller includes three decade counter stages for corresponding rows of units, tens and hundreds push buttons. Each stage including a decimal-to-BCD encoder, a <b>buffer</b> <b>register,</b> and a digital or binary counter. The BCD representation of the selected count for each digit is loaded into the respective decade down counters. Pulses generated by a sensor and associated circuitry are used to decrease the count in the decade counters. When {{the content of the}} decade counter reaches either 0 or 1, a solenoid control valve is actuated which interrupts operation of the machine. A repeat switch, when actuated, prevents clearing of the buffer registers so that multiple groups of the same number of sheets can be folded without reentering the number into the selector...|$|E
40|$|Part 8 : Sidechannel AnalysisInternational audienceMemory {{disclosure}} attacks, such as cold-boot {{attacks and}} DMA attacks, allow attackers to access all memory contents, therefore introduce great threats to plaintext sensitive data in memory. Register-based and cache-based schemes {{have been used}} to implement RSA securely, at the expense of decreased performance. In this paper, we propose another concept named <b>register</b> <b>buffer,</b> which makes use of all available registers as secure data buffer, no matter scalar registers or vector registers. The plaintext sensitive data only appear in <b>register</b> <b>buffer.</b> Based on this concept, we finish a security implementation of 2048 -bit RSA called RegRSA, to defeat against memory disclosure attacks. The 1024 -bit Montgomery multiplication in RegRSA runs entirely in <b>register</b> <b>buffer,</b> by performing computations using scalar instructions and registers, maintaining intermediate variables in vector registers. Due to the size limitation of <b>register</b> <b>buffer,</b> several variables out of Montgomery multiplications are spilled into memory. RegRSA encrypts these variables with AES before saving in memory. Furthermore, RegRSA employs a windowing method and the CRT speed-up to accelerate RSA, and minimizes the data exchange between registers and memory to reduce the workload of AES encryption/decryption. The evaluation on Intel Haswell i 7 - 4770 R shows that, the performance of RegRSA achieves a factor of 0. 74 compared to the regular RSA implementation in OpenSSL and is much greater than PRIME, the existing register-based scheme for 2048 -bit RSA. Moreover, RegRSA allows multiple instances to run on a multi-core CPU simultaneously, which makes it more practical for the real-world applications...|$|R
5000|$|MU5 and ICL 2900 Series. Hybrid stack and {{accumulator}} machines. The accumulator <b>register</b> <b>buffered</b> {{the memory}} stack's top data value. Variants of load and store opcodes controlled when that register was spilled {{to the memory}} stack or reloaded from there.|$|R
40|$|The System/ 360 Model 91 central {{processing}} unit provides internal computational performance one to two orders of magnitude {{greater than that of}} the IBM 7090 Data Processing System through a combination of advancements in machine organization, circuit design, and hardware packaging. The circuits employed will switch at speeds of less than 3 nsec, and the circuit environment is such that delay is approximately 5 nsec per circuit level. Organizationally, primary emphasis is placed on (1) alleviating the disparity between storage time and circuit speed, and (2) the development of high speed floating-point arithmetic algorithms. This paper deals mainly with item (1) of the organization. A design is described which improves the ratio of storage bandwidth and access time to cycle time through the use of storage interleaving and CPU <b>buffer</b> <b>registers.</b> It is shown that history recording (the retention of complete instruction loops in the CPU) reduces the need to exercise storage, and that sophisticated employment of buffering techniques has reduced the effective access time. The system is organized so that execution hardware is separated from the instruction unit; the resulting smaller, semiautonomous “packages” improve intra-area communication...|$|R
40|$|We {{investigate}} the memory system performance of several algorithms for transposing an # N matrix in-place, where N is large. Specifically, we {{investigate the}} relative {{contributions of the}} data cache, the translation lookaside <b>buffer,</b> <b>register</b> tiling, and the array layout function to the overall running time of the algorithms. We use various memory models to capture and analyze the effect of various facets of cache memory architecture that guide {{the choice of a}} particular algorithm, and attempt to experimentally validate the predictions of the model. Our major conclusions are as follows: limited associativity in the mapping from main memory addresses to cache sets can significantly degrade running time; the limited number of TLB entries can easily lead to thrashing; the fanciest optimal algorithms are not competitive on real machines even at fairly large problem sizes unless cache miss penalties are quite high; low-level performance tuning "hacks", such as register tiling and array [...] ...|$|E
40|$|Reducing power {{dissipation}} {{is the ultimate}} objective {{in the world of}} VLSI circuit design. Conventional logic dissipates more power by losing bits of information whereas reversibility recovers bit loss from the unique input-output mapping. Thus reversible logic has become immensely popular research area and its applications have spread in various technologies. In this paper we have proposed the compact design of reversible circuits for a data acquisition and storage system. The design comprises with a compact reversible analog-to- digital converter and a reversible address register. In the way of designing this data acquisition and storage system we have proposed a reversible J-K flip-flop with asynchronous inputs, a reversible D flipflop and a reversible three state <b>buffer</b> <b>register.</b> All the reversible designs individually have less number of gates, garbage outputs and quantum cost compared with the existing ones and have outperformed those described in the literature. Moreover we have proposed some lower bounds for designing these reversible components of the compact data acquisition and storage system...|$|E
40|$|CIRCUIT DESIGN We now {{consider}} the abstract circuit representation of Gordon's Computer. A {{diagram of the}} basic implementation is shown in Figure 3. From the implementation representation in Figure 3 {{we can see that}} the following elements {{have been added to the}} datapath, in order for it to function: A memory address register (MAR) of 13 bits, an instruction register (IR), an argument register (ARG), and a <b>buffer</b> <b>register</b> (BUF), all of 16 bits. All components of the datapath, and the memory, are connected by a 16 -bit bus, though this is not properly part of the state of the datapath. The controller is seen to consist of a microprogram counter (MPC), and a microprogram memory (ROM) consisting of 32 words of 30 bits each, together with a decoder. 5. 1 Controller: Informal Description Each 30 -bit microprogram word consists of four fields: a three-bit test field; two five-bit next address fields, A and B; and a 17 -bit control field. The control field is used to direct the operation of da [...] ...|$|E
40|$|The turbo {{coprocessor}} (TCP) is a programmable peripheral for decoding IS 2000 / 3 GPP turbo codes, {{that are}} {{integrated into the}} Texas Instruments (TI) TMS 320 C 6416 digital signal processor. The TCP is controlled via memory-mapped control <b>registers</b> and data <b>buffers.</b> Control <b>registers</b> can be accessed directly by the CPU, whereas data buffers are typically accessed using the EDMA controller. This application report describes {{the relationship between the}} theory of turbo decoding and TCP implementation, outlines TCP programming procedures, and provides examples that demonstrate how to program TCPs for typica...|$|R
50|$|Latency {{oriented}} processors expend {{a substantial}} chip area on sophisticated control structures like branch prediction, data forwarding, re-order <b>buffer,</b> large <b>register</b> files and caches in each processor. These structures help reduce operational latency and memory-access time per instruction, and make results available {{as soon as}} possible. Throughput oriented architectures on the other hand, usually have a multitude of processors with much smaller caches and simpler control logic. This helps to efficiently utilize the memory bandwidth and increase total the number of total number of execution units on the same chip area.|$|R
50|$|The 82497 Cache Controller {{implements}} the MESI write-back {{protocol for}} full multiprocessing support. Dual ported <b>buffers</b> and <b>registers</b> allow the 82497 to concurrently handle CPU bus, memory bus, and internal cache operation for maximum performance. The 82492 is a customized high performance SRAM that supports 32-, 64-, and 128-bit wide memory bus widths, 16-, 32-, and 64-byte line sizes, and optional sectoring. The data path between the CPU bus {{and the memory}} bus is separated by the 82492, allowing the CPU bus to handshake synchronously, asynchronously, or with a strobed protocol, and allowing concurrent CPU bus and memory bus operations.|$|R
40|$|Kalman filter {{relies heavily}} on perfect {{knowledge}} of sensor readings, used to compute the {{minimum mean square error}} estimate of the system state. However in reality, unavailability of output data might occur due to factors including sensor faults and failures, confined memory spaces of <b>buffer</b> <b>registers</b> and congestion of communication channels. Therefore investigations on the effectiveness of Kalman filtering in the case of imperfect data have, since the last decade, been an interesting yet challenging research topic. The prevailed methodology employed in the state estimation for imperfect data is the open loop estimation wherein the measurement update step is skipped during data loss time. This method has several shortcomings such as high divergence rate, not regaining its steady states after the data is resumed, etc. This thesis proposes a novel approach, which is found efficient for both stationary and nonstationary processes, for the above scenario, based on linear prediction schemes. Utilising the concept of linear prediction, the missing data (output signal) is reconstructed through modified linear prediction schemes. This signal is then employed in Kalman filtering at the measurement update step. To reduce the computational cost in the large matrix inversions, a modified Levinson-Durbin algorithm is employed. It is shown that the proposed scheme offers promising results in the event of loss of observations and exhibits the general properties of conventional Kalman filters. To demonstrate the effectiveness of the proposed scheme, a rigid body spacecraft case study subject to measurement loss has been considered...|$|R
30|$|The “.id” {{field in}} (7) {{represents}} the ordering {{position of a}} node within the array. The pn and cn fields denotes respectively the number of predecessors of op {{and the number of}} concurrent operations using the same unit resource as op and which are indexed less than its index. The formula is scaled by the number of <b>registers</b> (<b>buffers</b> size “.bs”) that are required by op.|$|R
30|$|However, picoJava {{implements}} a 64 -word stack <b>buffer</b> as discrete <b>registers.</b> Spill {{and fill}} of that stack buffer is performed in background by the hardware. Therefore, the stack buffer closely {{interacts with the}} data cache. The interference between the folding unit, the instruction buffer, the instruction cache, the stack buffer, the data cache, and the memory interface causes complications in modeling picoJava for WCET analysis.|$|R
40|$|AbstractSeveral local data buffers are {{proposed}} and measurements are presented for {{variations of the}} Warren–abstract–machine (WAM) architecture for PROLOG. First, literature {{in this area is}} reviewed. Choice-point buffers, stack buffers, split-stack <b>buffers,</b> multiple <b>register</b> sets, copyback caches, and “smart” caches are then examined. Evaluation parameters such as stack reference depth and reset depth are defined, and measurements are presented motivating the local-memory designs. A memory-trace-driven simulator was used to collect miss- and traffic-ratio statistics for the local memories. Statistics collected from four benchmark programs indicate that small (< 1024 words) conventional local memories perform quite well because of the WAM's high locality. The data-memory performance results are equally valid for native code and reduced-instruction-set implementations of PROLOG...|$|R
40|$|In this paper, {{we propose}} an {{efficient}} architecture for the adaptive deblocking filter in H. 264 /AVC video coding standard. We use eight forwarding shift register arrays (of which each contains 4 × 4 8 -bit shift registers) with two transposing operations and two filter units to support simultaneous processing of the {{horizontal and vertical}} filtering. The proposed architecture is called “Pipeline <b>Buffer</b> Shift <b>Register</b> (PBSR). ” As a result, the performance of PBSR is 22. 5 % faster than the advanced architecture of the previous proposal. Moreover, the number of total memory references is reduced to 37 % and 75 % respectively compared to the basic and advanced architectures of the previous proposals...|$|R
50|$|The SIPO (Serial Input, Parallel Output) block {{typically}} has a {{receive clock}} output, {{a set of}} data output lines and output data latches. The receive clock may have been recovered from the data by the serial clock recovery technique. However, SerDes which do not transmit a clock use reference clock to lock the PLL to the correct Tx frequency, avoiding low harmonic frequencies present in the data stream. The SIPO block then divides the incoming clock down to the parallel rate. Implementations typically have two registers connected as a double <b>buffer.</b> One <b>register</b> is used to clock in the serial stream, {{and the other is}} used to hold the data for the slower, parallel side.|$|R
