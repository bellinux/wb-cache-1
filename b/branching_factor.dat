354|176|Public
25|$|In three dimensions, the perturbative series {{from the}} field theory is an {{expansion}} in a coupling constant λ which is not particularly small. The effective size of the coupling at the fixed point is one over the <b>branching</b> <b>factor</b> of the particle paths, so the expansion parameter is about 1/3. In two dimensions, the perturbative expansion parameter is 2/3.|$|E
2500|$|Good {{heuristics}} {{are those}} with low effective <b>branching</b> <b>factor</b> (the optimal being [...] ).|$|E
2500|$|A rough {{estimate}} {{of the number of}} nodes in the game tree can be obtained as an exponential function of the average <b>branching</b> <b>factor</b> and the average number of plies in a game thus: b'd where d is the ply depth and b is the <b>branching</b> <b>factor.</b> [...] In Hex, the average <b>branching</b> <b>factor</b> {{is a function of the}} ply depth. It has been stated that the average <b>branching</b> <b>factor</b> is about 100; that implies an average ply depth of 43 (there will be 121 open spaces on the board when the first player is to make his first move, and 79 when he is to make his 22nd move, the 43rd ply - the average number of open spaces, i.e. <b>branching</b> <b>factor,</b> during the game is (121+120+...+79)/43=100). [...] Therefore, the game tree size has an upper bound of approximately 10043 = 1086.. [...] The bound includes some number of illegal positions due to playing on when there is a complete chain for one player or the other, as well as excludes legal positions for games longer than 43 ply. [...] Another researcher obtained a state space estimate of 1057 and a game tree size of 1098 using an upper limit of 50 plies for the game. This compares to 10123 node game tree size of chess.|$|E
5000|$|Like most AI game playing programs, {{the default}} engine plays poorly in games with large <b>branching</b> <b>factors,</b> such as shogi.|$|R
40|$|In {{contrast}} to previous competitions, where {{the problems were}} goal-based, the 2011 International Probabilistic Planning Competition (IPPC- 2011) emphasized finite-horizon reward maximization problems with large <b>branching</b> <b>factors.</b> These MDPs modeled more realistic planning scenarios and presented challenges to the previous state-of-the-art planners (e. g., those from IPPC- 2008), which were primarily based on domain determinization — a technique more suited to goal-oriented MDPs with small <b>branching</b> <b>factors.</b> Moreover, large <b>branching</b> <b>factors</b> render the existing implementations of RTDP- and LAO ∗-style algorithms inefficient as well. In this paper we present GLUTTON, our planner at IPPC- 2011 that performed well on these challenging MDPs. The main algorithm used by GLUTTON is LR 2 TDP, an LRTDPbased optimal algorithm for finite-horizon problems centered around the novel idea of reverse iterative deepening. We detail LR 2 TDP itself {{as well as a}} series of optimizations included in GLUTTON that help LR 2 TDP achieve competitive performance on difficult problems with large <b>branching</b> <b>factors</b> — subsampling the transition function, separating out natural dynamics, caching transition function samples, and others. Experiments show that GLUTTON and PROST, the IPPC- 2011 winner, have complementary strengths, with GLUTTON demonstrating superior performance on problems with few high-reward terminal states...|$|R
3000|$|... codewords, where B is the <b>branch</b> <b>factor</b> and L is the depth. Then, a query image q is {{represented}} by a bag of N [...]...|$|R
2500|$|It is hard even to {{estimate}} the game-tree complexity, but for some games a reasonable lower bound can be given by raising the game's average <b>branching</b> <b>factor</b> {{to the power of}} the number of plies in an average game, or: ...|$|E
2500|$|The {{heuristic}} function {{has a major}} {{effect on}} the practical performance of A* search, since a good heuristic allows A* to prune away many of the [...] nodes that an uninformed search would expand. Its quality can be {{expressed in terms of}} the effective <b>branching</b> <b>factor</b> , which can be determined empirically for a problem instance by measuring the number of nodes expanded, , and the depth of the solution, then solving ...|$|E
2500|$|With an (average or constant) <b>branching</b> <b>factor</b> of b, and {{a search}} depth of d plies, {{the maximum number}} of leaf node {{positions}} evaluated (when the move ordering is [...] ) is O(b*b*...*b) = O(b'd) – the same as a simple minimax search. If the move ordering for the search is optimal (meaning the best moves are always searched first), the number of leaf node positions evaluated is about O(b*1*b*1*...*b) for odd depth and O(b*1*b*1*...*1) for even depth, or [...] In the latter case, where the ply of a search is even, the effective <b>branching</b> <b>factor</b> is reduced to its square root, or, equivalently, the search can go twice as deep with the same amount of computation. The explanation of b*1*b*1*... is that all the first player's moves must be studied to find the best one, but for each, only the best second player's move is needed to refute all but the first (and best) first player move—alpha–beta ensures no other second player moves need be considered. When nodes are ordered at random, ...|$|E
50|$|Higher <b>branching</b> <b>factors</b> make {{algorithms}} {{that follow}} every branch at every node, such as exhaustive brute force searches, computationally more expensive {{due to the}} exponentially increasing number of nodes, leading to combinatorial explosion.|$|R
5000|$|These differing <b>branching</b> <b>factors</b> {{imply that}} a {{computer}} which can search {{to a depth}} of eight turns for each player in chess, can only search about three turns deep for each player in Arimaa: ...|$|R
40|$|We {{introduce}} {{and analyze}} {{a method to}} reduce the search cost in tries. Traditional trie structures use <b>branching</b> <b>factors</b> at the nodes that are either fixed or {{a function of the}} number of elements. Instead, we let the distribution of the elements guide the choice of <b>branching</b> <b>factors.</b> This is accomplished in a strikingly simple way: in a binary trie, the i highest complete levels are replaced by a single node of degree 2 i; the compression is repeated in the subtries. This structure, the level-compressed trie, inherits the good properties of binary tries with respect to neighbour and range searches, while the external path length is significantly decreased. It also has the advantage of being easy to implement. Our analysis shows that the expected depth of a stored element is Θ (log Λ n) for uniformly distributed data...|$|R
2500|$|The time {{complexity}} of A* {{depends on the}} heuristic. In the worst case of an unbounded search space, the number of nodes expanded is exponential in {{the depth of the}} solution (the shortest path) : , where [...] is the <b>branching</b> <b>factor</b> (the average number of successors per state). This assumes that a goal state exists at all, and is reachable from the start state; if it is not, and the state space is infinite, the algorithm will not terminate.|$|E
2500|$|Usually, {{the number}} of keys is chosen to vary between [...] and , where [...] is the minimum number of keys, and [...] is the minimum degree or <b>branching</b> <b>factor</b> of the tree. In practice, the keys take up the most space in a node. The factor of 2 will {{guarantee}} that nodes can be split or combined. If an internal node has [...] keys, then adding a key to that node {{can be accomplished by}} splitting the hypothetical [...] key node into two [...] key nodes and moving the key that {{would have been in the}} middle to the parent node. Each split node has the required minimum number of keys. Similarly, if an internal node and its neighbor each have [...] keys, then a key may be deleted from the internal node by combining it with its neighbor. Deleting the key would make the internal node have [...] keys; joining the neighbor would add [...] keys plus one more key brought down from the neighbor's parent. The result is an entirely full node of [...] keys.|$|E
5000|$|For example, if the <b>branching</b> <b>factor</b> is 10, {{then there}} will be 10 nodes one level down from the current position, 102 (or 100) nodes two levels down, 103 (or 1,000) nodes three levels down, and so on. The higher the <b>branching</b> <b>factor,</b> the faster this [...] "explosion" [...] occurs. The <b>branching</b> <b>factor</b> can be cut down by a pruning algorithm.|$|E
40|$|This paper proposes Monte Carlo Action Programming, a {{programming}} language framework for autonomous systems that act in large probabilistic state spaces with high <b>branching</b> <b>factors.</b> It comprises formal syntax and semantics of a nondeterministic action {{programming language}}. The language is interpreted stochastically via Monte Carlo Tree Search. Effectiveness of the approach is shown empirically...|$|R
40|$|Many problems, {{such as the}} sliding-tile puzzles, {{generate}} search trees where different nodes {{have different}} numbers of children, in this case depending on {{the position of the}} blank. We show how to calculate the asymptotic <b>branching</b> <b>factors</b> of such problems, and how to efficiently compute the exact numbers of nodes at a given depth. This information is important for determining the complexity of various search algorithms on these problems. In addition to the sliding-tile puzzles, we also apply our technique to Rubik's Cube. While our techniques are fairly straightforward, the literature is full of incorrect <b>branching</b> <b>factors</b> for these problems, and the errors in several incorrect methods are fairly subtle. Introduction Many AI search algorithms, such as depth-first search (DFS), depth-first iterative-deepening (DFID), and Iterative-Deepening-A* (IDA*) (Korf 1985) search a problem-space tree. While most problem spaces are in fact graphs with cycles, detecting these cycles in general req [...] ...|$|R
40|$|We propose XQGen, a stand-alone, algebra-based XPath {{generator}} to aid {{engineers in}} testing {{and improving the}} design of XML query engines. XQGen takes an XML schema sketch and user configurations, such as number of queries, query types, duplication <b>factors,</b> and <b>branching</b> <b>factors</b> as input, and generates a set of queries that comform to the schema and configurations. In addition, given a set of labelpaths as workload input, XQGen is capable of generating query sets that honor the workload...|$|R
5000|$|In computing, tree data structures, {{and game}} theory, the <b>branching</b> <b>factor</b> {{is the number}} of {{children}} at each node, the outdegree. If this value is not uniform, an average <b>branching</b> <b>factor</b> can be calculated.|$|E
5000|$|The {{higher the}} <b>branching</b> <b>factor,</b> {{the lower the}} {{overhead}} of repeatedly expanded states, but even when the <b>branching</b> <b>factor</b> is 2, iterative deepening search only takes about {{twice as long as}} a complete breadth-first search. This means that the time complexity of iterative deepening is still [...]|$|E
5000|$|Consider {{the cost}} of an {{insertion}}. Each message gets flushed [...] times, and {{the cost of}} a flush is [...] Therefore, {{the cost of an}} insertion is [...] Finally, note that the <b>branching</b> <b>factor</b> can vary, but for any <b>branching</b> <b>factor</b> , the cost of a flush is , thereby providing a smooth tradeoff between search cost, which depends on the depth of the search tree, and therefore the <b>branching</b> <b>factor,</b> versus the insertion time, which depends on the depth of the tree but more sensitively {{on the size of the}} buffer flushes.|$|E
40|$|In {{this paper}} we prove a {{functional}} limit theorem for the weighted {{profile of a}} $b$-ary tree. For the proof we use classical martingales connected to branching Markov processes and a generalized version of the profile-polynomial martingale. By embedding, choosing weights and a <b>branch</b> <b>factor</b> in a right way, we finally rediscover the profiles of some well-known discrete time trees. Comment: Published in at [URL] the Annals of Applied Probability ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
40|$|Amazons is {{a perfect}} {{information}} board game with simple rules and large <b>branching</b> <b>factors.</b> Two players alternately move chess queen-like pieces and block squares on a 10 × 10 playing field. The player who makes the last move wins. Amazons endgames usually decompose into independent subgames. Therefore, the game is a natural testbed for combinatorial game theory. It was known that determining the winner of simple generalized Amazons endgames is NP-equivalent. This paper presents two proofs for the PSPACEcompleteness of the generalized version of the full game. ...|$|R
40|$|Exciting {{research}} {{looking at}} early events in arbuscular mycorrhizal symbioses has shown how the fungus and plant get together. Kohki Akiyama et al. {{have demonstrated that}} strigolactones in root exudates are fungal germ tube <b>branching</b> <b>factors,</b> and Arnaud Besserer et al. found that these compounds rapidly induce fungal mitochondrial activity. Andrea Genre et al. have shown that subsequent development of appressoria on host roots induces construction of a transient prepenetration apparatus inside epidermal cells that is reminiscent of nodulation infection. Sally E. Smith, Susan J. Barker and Yong-Guan Zhu[URL]...|$|R
5000|$|For example, in chess, if a [...] "node" [...] is {{considered}} to be a legal position, the average <b>branching</b> <b>factor</b> has been said to be about 35. This means that, on average, a player has about 35 legal moves at his disposal at each turn. By comparison, the <b>branching</b> <b>factor</b> for the game Go is 250.|$|E
5000|$|Good {{heuristics}} {{are those}} with low effective <b>branching</b> <b>factor</b> (the optimal being [...] ).|$|E
5000|$|A rough {{estimate}} {{of the number of}} nodes in the game tree can be obtained as an exponential function of the average <b>branching</b> <b>factor</b> and the average number of plies in a game thus: bd where d is the ply depth and b is the <b>branching</b> <b>factor.</b> In Hex, the average <b>branching</b> <b>factor</b> {{is a function of the}} ply depth. It has been stated that the average <b>branching</b> <b>factor</b> is about 100; that implies an average ply depth of 43 (there will be 121 open spaces on the board when the first player is to make his first move, and 79 when he is to make his 22nd move, the 43rd ply - the average number of open spaces, i.e. <b>branching</b> <b>factor,</b> during the game is (121+120+...+79)/43=100). Therefore, the game tree size has an upper bound of approximately 10043 = 1086. [...] The bound includes some number of illegal positions due to playing on when there is a complete chain for one player or the other, as well as excludes legal positions for games longer than 43 ply. Another researcher obtained a state space estimate of 1057 and a game tree size of 1098 using an upper limit of 50 plies for the game. This compares to 10123 node game tree size of chess.|$|E
40|$|We {{present a}} {{comparative}} delay analysis of tree-based reliable multicast protocols {{and show the}} influence of varying sending rates, group sizes, packet loss probabilities and <b>branching</b> <b>factors</b> of the control tree. Besides the average delivery delay we consider the delay to reliably deliver all packets and the round trip delay. The former two examines the delay between generation of a packet at the sender and correct reception at a randomly chosen receiver or all receivers, respectively. The latter is the delay between generation of a packet at the sender and reception of all acknowledgement packets at the sender...|$|R
40|$|Many search {{problems}} are commonly solved with combinatoric algorithms that unnecessarily duplicate and serialize work at considerable computational expense. There are techniques available that can eliminate redundant computations and perform remaining operations concurrently, effectively reducing the <b>branching</b> <b>factors</b> of these algorithms. This thesis applies these techniques {{to the problem}} of parsing natural language. The result is an efficient programming language that can reduce some of the expense associated with principle-based parsing and other search problems. The language is used to implement various natural language parsers, and the improvements are compared to those that result from implementing more deterministic theories of language processing...|$|R
40|$|AbstractHex is a {{beautiful}} game with simple rules and a strategic complexity {{comparable to that of}} Chess and Go. The massive game-tree search techniques developed mostly for Chess and successfully used for Checkers {{and a number of other}} games, become less useful for games with large <b>branching</b> <b>factors</b> like Hex and Go. In this paper, we describe deduction rules, which are used to calculate values of complex Hex positions recursively starting from the simplest ones. We explain how this approach is implemented in HEXY—the strongest Hex-playing computer program, the Gold medallist of the 5 th Computer Olympiad in London, August 2000...|$|R
5000|$|... #Caption: The {{unsustainable}} exponential {{progression of}} a classic pyramid scheme (here with a <b>branching</b> <b>factor</b> of 6) ...|$|E
50|$|When brute-force searching {{is applied}} to Arimaa, {{the depth of the}} search is limited by the huge number of options each player has on each turn. Computationally, the number of options a player has {{available}} to them governs the number of different paths play can go down. This is known as the <b>branching</b> <b>factor.</b> The average <b>branching</b> <b>factor</b> in a game of Chess is about 35, whereas in Arimaa it is about 17,000.|$|E
50|$|These {{approaches}} {{attempt to}} mitigate {{the problems of the}} game of Go having a high <b>branching</b> <b>factor</b> and numerous other difficulties.|$|E
40|$|This article tests {{a multidimensional}} {{model of the}} {{marketing}} and sales organizational interface, based on a previous one tested for European companies (Homburg et al., 2008), in a specific taxonomical configuration: a brand focused professional multinational, in three successful Latin American <b>branches.</b> <b>Factor</b> reliability and hypotheses were studied through a confirmatory factor analysis. Results show {{the existence of a}} positive relationship between formalization, joint planning, teamwork, information sharing, trust and interface quality. Interface quality and business performance show also a positive relationship. This empirical study contributes to the knowledge of the organizational enhancement of interactions in emerging market...|$|R
40|$|Qanats in {{northern}} Xinjiang of China provide valuable information for agriculturists and anthropologists who seek fundamental {{understanding of the}} distribution of qanat water supply systems with regard to water resource utilization, the development of oasis agriculture, and eventually climate change. Only the tops of qanat shafts (TQSs), indicating the course of the qanats, can be observed from space, and their circular archaeological traces can also be seen in very high resolution imagery in Google Earth. The small size of the TQSs, vast search regions, and degraded features make manually extracting them from remote sensing images difficult and costly. This paper proposes an automated TQS extraction method that adopts mathematical morphological processing methods before an edge detecting module is used in the circular Hough transform approach. The accuracy assessment criteria for the proposed method include: (i) extraction percentage (E) = 95. 9 %, <b>branch</b> <b>factor</b> (B) = 0 and quality percentage (Q) = 95. 9 % in Site 1; and (ii) extraction percentage (E) = 83. 4 %, <b>branch</b> <b>factor</b> (B) = 0. 058 and quality percentage (Q) = 79. 5 % in Site 2. Compared with the standard circular Hough transform, the quality percentages (Q) of our proposed method were improved to 95. 9 % and 79. 5 % from 86. 3 % and 65. 8 % in test sites 1 and 2, respectively. The results demonstrate that wide-area discovery and mapping can be performed much more effectively based on our proposed method...|$|R
40|$|Hex is a {{beautiful}} game with simple rules and a strategic complexity {{comparable to that of}} Chess and Go. The massive game-tree search techniques developed mostly for Chess and successfully used for Checkers {{and a number of other}} games, become less useful for games with large <b>branching</b> <b>factors</b> like Hex and Go. In this paper, we describe deduction rules, which are used to calculate values of complex Hex positions recursively starting from the simplest ones. We explain how this approach is implemented in HEXY [...] -the strongest Hex-playing computer program, the Gold medallist of the 5 th Computer Olympiad in London, August 2000. 2001 Elsevier Science B. V. All rights reserved...|$|R
