6|65|Public
40|$|A {{non-linear}} pendulum {{model is}} developed {{to represent the}} motion of a sloshing fluid in real time. The forces imposed by the sloshing fluid are identified using multiphase RANS CFD simulations and subsequently included in the pendulum sloshing model. The pendulum sloshing model was used to simulate sloshing induced by linear and angular motions at and near resonance. Good agreement between the CFD data and the pendulum sloshing model was observed. A <b>blind</b> <b>simulation</b> with multiple surge excitation components is carried out and the pendulum sloshing model agrees with the RANS CFD result. Typically, the computational time of the pendulum is approximately 1 / 700 th of real time. KEY WORDS: Sloshing; multiphase; CFD; Simplified sloshin...|$|E
40|$|A new {{approach}} to transparent embedding of data into digital images is proposed. It provides {{a high rate of}} the embedded data and is robust to common and some intentional distortions. The developed technique employs properties of the singular value decomposition (SVD) of a digital image. According to these properties each singular value (SV) specifies the luminance of the SVD image layer, whereas the respective pair of singular vectors specifies image geometry. Therefore slight variations of SVs cannot affect the visual perception of the cover image. The proposed approach is based on embedding a bit of data through slight modifications of SVs of a small block of the segmented covers. The approach is robust because it supposes to embed extra data into low bands of covers in a distributed way. The size of small blocks is used as an attribute to achieve a tradeoff between the embedded data rate and robustness. An advantage of the approach is that it is <b>blind.</b> <b>Simulation</b> has proved its robustness to JPEG up to 40 %. The approach can be used both for hidden communication and watermarking...|$|E
40|$|In {{the late}} phase of Molten Core Concrete Interaction (MCCI) the {{ablation}} rate becomes {{low and the}} gas flow rate issued from the concrete decomposition is reduced. Moreover the oxide phase becomes lighter than the metal phase due to {{the addition of the}} light oxide from the concrete. A large density difference and a low gas flow rate ensure that a stratified configuration will occur. The stratified configuration has then {{to be taken into account}} in the MCCI simulation tools. Only few experimental programs were conducted with stratified pools; among them the BETA tests were performed at FZK with a large test matrix. The COMET-L 2 and L 3 experiments were recently conducted at FZK in a stratified configuration. In the frame of SARNET WP 11. 2 a benchmark was organised in order to compare the MCCI code results regarding these experiments. COMET-L 2 was used for a post-test simulation and after that COMET-L 3 was used as a <b>blind</b> <b>simulation.</b> The participants and codes were AREVA with COSACO, CEA with TOLBIAC-ICB, EDF wit...|$|E
3000|$|... 0), which {{represents}} the effect of rapid spectral decay at high frequencies, site amplifications in the Kyushu region and the stress drop of the mainshock. Then, the ground-motion simulations were performed and compared with the observations at all stations. Simulated PGA values were also compared with ground-motion prediction equations (GMPEs) suggested by Boore et al. (2014). Finally, we performed <b>blind</b> <b>simulations</b> for Kumamoto Castle and Minami Aso village based on our validated model, where engineered structures suffered severe damages but without ground-motion records.|$|R
40|$|In {{this paper}} we present {{results from the}} Mapping Dark Matter {{competition}} that expressed the weak lensing shape measurement task in its simplest form {{and as a result}} attracted over 700 submissions in 2 months and a factor of 3 improvement in shape measurement accuracy on high signal to noise galaxies, over previously published results, and a factor 10 improvement over methods tested on constant shear <b>blind</b> <b>simulations.</b> We also review weak lensing shape measurement challenges, including the Shear TEsting Programmes (STEP 1 and STEP 2) and the GRavitational lEnsing Accuracy Testing competitions (GREAT 08 and GREAT 10) ...|$|R
40|$|In many heat devices {{designers}} and operators meet {{the problem of}} low efficiency of combustion and restricted emission standards. This process should be improved to maximize its efficiency and satisfy additional requirements as, for example, uniform temperature fieldin combustion chamber, low noise level or very low NOx emission. These requirements are satisfied by homogeneous combustion. Such combustion method is particularly attractive for the steel or glass industry or power industry based in particular on natural gas. In this paper factors, which have the biggest influence on performance of flameless combustion, are discussed, among others: momentum of fuel and oxidizer, composition of the mixture, {{the temperature of the}} inlet gases. Additionally, <b>blind</b> <b>simulations</b> of combustion in a combustion chamber of a furnace are run to assess how high is the influence of these factors individually. Numerical simulations are performed in a CFD code AVL Fire. The detailed chemical kinetics mechanism GRI-mech 3. 0 is used for combustion calculations. Calculations results are correlated with experimental data. <b>Blind</b> <b>simulations</b> and experiment provide similar level of NOX emission (~ 6 - 8 ppm). Experiments showed that the effect of the addition of ethylene to fuel on emissions of NOX, CO, THC is not significant. Similarly, numerical simulations predict that influence of ethylene is negligible. CO, THC and CO 2 were on a stable level across all cases. NOX emissions increases when mass flow of air and fuel increases due to higher heat release in the same volume, what results in higher temperature of combustion products. When temperature of fuel increases NOX level decreases...|$|R
40|$|The {{document}} {{deals with}} the description of results obtained by two Relap 5 /mod 2 code versions in the pre-test <b>blind</b> <b>simulation</b> of an experiment performed in the VVER (water cooled- Water Moderated Energy Reactor) experimental simulator PMK-NVH installed at the Budapest Atomic Energy Research Institute in Hungary. The Relap is the well-known computer code developed at Idaho National Laboratory in US: the code is in use at UNIPI since more than a decade. The PMK-NVH loop is an Integral Test Facility (ITF) simulating with reduced height, full pressure, modulated linear power a Russian (Gidropress) type VVER- 440. The concerned test was selected by International Atomic Energy Agency (IAEA) as Standard Problem Exercise 2 (SPE 2). The document describes {{the results of the}} pre-test calculation submitted (by UNIPI) to Hungary before the execution of the test. This is called blind pre-test analysis: the comparison of about 40 calculated time trends with measured data (once the experiment is performed: {{this is part of the}} SPE documentation issued as IAEA report) allows an objective evaluation of the capabilities of the computer code and of the code user team in predicting the scenario of an accident. This is relevant for demonstrating the capabilities in evaluating safety margins of existing NPP, with main reference to VVER (present case) ...|$|E
40|$|During {{volcanic}} crises, volcanologists {{estimate the}} impact of possible imminent eruptions usually through deterministic modeling {{of the effects of}} one or a few preestablished scenarios. Despite such an approach may bring an important information to the decision makers, the sole use of deterministic scenarios does not allow scientists to properly take into consideration all uncertainties, and it cannot be used to assess quantitatively the risk because the latter unavoidably requires a probabilistic approach. We present a model based on the concept of Bayesian event tree (hereinafter named BET_VH_ST, standing for Bayesian event tree for short-term volcanic hazard), for short-term near-real-time probabilistic volcanic hazard analysis formulated for any potential hazardous phenomenon accompanying an eruption. The specific goal of BET_VH_ST is to produce a quantitative assessment of the probability of exceedance of any potential level of intensity for a given volcanic hazard due to eruptions within restricted time windows (hours to days) in any area surrounding the volcano, accounting for all natural and epistemic uncertainties. BET_VH_ST properly assesses the conditional probability at each level of the event tree accounting for any relevant information derived from the monitoring system, theoretical models, and the past history of the volcano, propagating any relevant epistemic uncertainty underlying these assessments. As an application example of the model, we apply BET_VH_ST to assess short-term volcanic hazard related to tephra loading during Major Emergency Simulation Exercise, a major exercise at Mount Vesuvius that took place from 19 to 23 October 2006, consisting in a <b>blind</b> <b>simulation</b> of Vesuvius reactivation, from the early warning phase up to the final eruption, including the evacuation of a sample of about 2000 people from the area at risk. The results show that BET_VH_ST is able to produce short-term forecasts of {{the impact of}} tephra fall during a rapidly evolving crisis, accurately accounting for and propagating all uncertainties and enabling rational decision making under uncertainty...|$|E
40|$|The LIGO-Virgo {{network of}} kilometer-scale laser {{interferometric}} gravitational-wave detectors reached a major milestone with the successful operation of LIGO's fifth (S 5) and Virgo's first (VSR 1) science runs during 2005 - 2007. This thesis presents several {{issues related to}} gravitational-wave transient detection {{from the perspective of}} the joint all-sky, un-triggered burst search over S 5 /VSR 1 data. Existing searches for gravitational-wave bursts must deal with the presence of non-Gaussian noise transients which populate the data over the majority of sensitive signal space. These events may be confused with true signals, and are the current limiting factor in search sensitivity and detection confidence for any real event. The first part of this thesis focuses on the development of tools to identify, monitor and characterize these instrumental disturbances in LIGO and Virgo data. An automated procedure is developed and applied to the S 5 /VSR 1 search in order to safely remove noise transients from the analysis without sacrificing sensitivity by making use of the wealth of auxiliary information recorded by the detectors. The second part of this thesis focuses on the interpretation of outlier events in the context of a non-Gaussian, non-stationary background. An extensive follow-up procedure for candidate gravitational-wave events is developed and applied to a single burst outlier from the S 5 /VSR 1 search, later revealed to be a <b>blind</b> <b>simulation</b> injected into the instruments. While the follow-up procedure correctly finds no reason to reject the candidate as a possible gravitational wave, it highlights the difficulty in making a confident detection for signals with similar waveform morphology to common instrumental disturbances. The follow-up also deals with the problem of objectively defining the significance of a single outlier event in the context of many semi-disjoint individual searches. To address this, a likelihood-ratio based unified ranking is developed and tested against the original procedures of the S 5 /VSR 1 burst search. The new ranking shows a factor of four improvement in the statistical significance of the outlier event, and a 12 % reduction using fixed thresholds and 38 % reduction using a loudest event statistic for a rate upper limit on a mock signal population. by Lindy L. BlackburnThesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Physics, 2010. Cataloged from PDF version of thesis. Includes bibliographical references (p. 193 - 201) ...|$|E
40|$|We {{present the}} {{observational}} {{results of an}} L' and M band Adaptive Optics (AO) imaging survey of 54 nearby, sunlike stars for extrasolar planets, carried out using the Clio camera on the MMT. We have concentrated more strongly than all other planet imaging surveys to date on very nearby F, G, and K stars, prioritizing stellar proximity higher than youth. Ours is also the first survey to include extensive observations in the M band, which supplement the primary L' observations. Models predict much better planet/star flux ratios at the L' and M bands than at more commonly used shorter wavelengths (i. e. the H band). We have carried out extensive <b>blind</b> <b>simulations</b> with fake planets inserted into the raw data to verify our sensitivity, and to establish a definitive relationship between source significance in σ and survey completeness. We find 97...|$|R
40|$|External heat {{transfer}} predictions are performed for two-dimensional turbine blade cascades. The Reynolds averaged Navier-Stokes equations with algebraic (Baldwin-Lomax) and two-equation (low-Re k Γ ffl) turbulence closures are solved with an explicit Runge-Kutta time-marching finite volume method. Comparisons with measurement for subsonic and transonic cascades show good agreement in some cases, but also reveals problems with transition prediction and turbulence modeling. Stability, grid independence and {{problems in the}} stagnation point region are investigated. <b>Blind</b> <b>simulations</b> of a supersonic cascade are included to demonstrate the methods capability in handling this type of flows. Nomenclature cp Specific heat [J=kgK] C ffl 1, C ffl 2, C¯, oe k, oe ffl Turbulence model constants [] D Turbulence model term [J=kgs] E Turbulence model term [J=kgs 2] e 0 Total energy [J=kg] f 1, f 2, f¯ Damping functions [] k Turbulent kinetic energy [J=kg] l e Local equilibrium le [...] ...|$|R
40|$|An {{evacuation}} {{model validation}} data-set collected {{as part of}} the EU FP 7 project SAFEGUARD is presented. The data was collected from a cruise ship operated by Royal Caribbean International (CS). The trial was a semi-unannounced assembly trial conducted at sea and involved some 2500 passengers. The trial took place at an unspecified time however, passengers were aware that on their voyage an assembly exercise would take place. The validation data-set consists of passenger; response times, starting locations, end locations and arrival times in the assembly stations. The validation data were collected using a novel data acquisition system consisting of ship-mounted beacons, each emitting unique Infra-Red (IR) signals and IR data logging tags worn by each passenger. The results from <b>blind</b> <b>simulations</b> using maritimeEXODUS for the assembly trial are presented and compared with the measured data. Three objective measures are proposed to assess the goodness of fit between the predicted model data and the measured data...|$|R
40|$|This paper {{deals with}} the dust {{mobilization}} in fusion facilities, in which the plasma disruptions induce an erosion of small particles causing external releases if accidents occur. In the ITER safety guidelines the administrative limits of 200 kg carbon, 100 kg beryllium and 100 kg tungsten inside the VV have been fixed to avoid the population evacuation in case of accident. The conservative assumption to mobilize all these dusts is adopted in the accident analyses. To support a less conservative hypothesis some experiments have been performed inside the STARDUST facility (ENEA Frascati laboratories, Italy). The ECART code {{has been used for}} <b>blind</b> <b>simulations</b> to validate the dust transport model implemented. The results match satisfactorily the experiments. The dusts used were carbon, stainless steel, tungsten and a mixed dust (C, SS, W). The experiments represent a LOVA due to a small or a large air leak through two different VV ports. The measured mobilization rate ranges from 0. 03...|$|R
40|$|This study aims to {{encourage}} a wider usage of daylighting design features in office buildings. The two major outputs are a dynamic, RADIANCE-based daylight simulation method and a manual lighting control model. The former method predicts the annual daylight availability in arbitrary buildings with complicated facade geometries and advanced shading devices such as external venetian <b>blinds.</b> <b>Simulation</b> results have been compared to conventional daylight simulation method s and to illuminance measurements in a full scale test-bed under more than 10, 000 sky conditions. The manual lighting control model considers occupant behavior to predict the temporary status of manually operated artificial lighting and blind systems. The model combines simulated indoor illuminance and occupancy profiles with probabilistic switching patterns to predict the electric energy demand for artificial lighting in a work place. The switching patterns have been derived from a literature review of past field studies and a monitoring pilot study in an office building in Southern Germany...|$|R
40|$|Two {{evacuation}} {{model validation}} data-sets collected {{as part of}} the EU FP 7 project SAFEGUARD are presented. The data was collected from a RO-PAX ferry operated by ColorLine (RP 1) and a cruise ship operated by Royal Caribbean (CS). The trials were semi-unannounced assembly trials at sea and involved some 1349 and 2500 passengers respectively. The trials took place at an unspecified time however, passengers were aware that on their voyage an assembly exercise would take place. The validation data-sets consist of passenger; response times, starting locations, end locations and arrival times in the assembly stations. The validation data were collected using a novel data acquisition system consisting of ship-mounted beacons, each emitting unique Infra-Red (IR) signals and IR data logging tags worn by each passenger. The results from <b>blind</b> <b>simulations</b> using maritimeEXODUS for these assembly trials are presented and compared with the measured data. Three objective measures are proposed to assess the goodness of fit between the predicted model data and the measured data...|$|R
40|$|The International Atomic Energy Agency Coordinated Research Project, "Benchmark Analyses of an EBR-II Shutdown Heat Removal Test" is in {{the third}} year of its {{four-year}} term. Nineteen participants representing eleven countries have simulated two of the most severe transients performed during the Shutdown Heat Removal Tests program conducted at Argonne's Experimental Breeder Reactor II. Benchmark specifications were created for these two transients, enabling project participants to develop computer models of the core and primary heat transport system, and simulate both transients. In phase 1 of the project, <b>blind</b> <b>simulations</b> were performed and then evaluated against recorded data. During phase 2, participants have refined their models to address areas where the phase 1 simulations did not predict the experimental data as well as desired. This paper describes the progress that has been made to date in phase 2 in improving on the earlier simulations and presents the direction of planned work {{for the remainder of the}} project...|$|R
30|$|We {{have found}} {{excellent}} agreement between our model and available empirical clinical {{data for the}} drug combination studied here. To support the kinetic model at a molecular level, we built an atomistic three-dimensional model of the ligands interacting with the metabolic enzyme and elucidated the binding modes of paclitaxel and doxorubicin within CYP 3 A 4. <b>Blind</b> docking <b>simulations</b> provided estimates of the corresponding binding energies. The paper is concluded with clinical implications for {{the administration of the}} two drugs in combination.|$|R
40|$|Stop-and-go decision-directed (S&G-DD) {{equalization}} is {{the most}} primitive blind equalization (BE) method for the cancelling of intersymbol-interference in data communication systems. Recently, this scheme {{has been applied to}} complex-valued multilayer feedforward neural network, giving robust results with a lower mean-square error at the expense of slow convergence. To overcome this problem, in this work, a fast converging recursive least squares (RLS) -based complex-valued backpropagation learning algorithm is derived for S&G-DD <b>blind</b> equalization. <b>Simulation</b> results show the effectiveness of the proposed algorithm in terms of initial convergence...|$|R
40|$|A {{modified}} MMSE receiver for multicarrier DS-CDMA {{operating in}} fading, multipath radio channels is presented. This structure is compu-tationally efficient when the channel is rapidly time-varying. Subspace concepts are applied in a proposed <b>blind</b> implementation and <b>simulations</b> {{show that the}} new receiver can produce enhanced performance...|$|R
40|$|Abstract: In this paper, {{the problem}} of {{minimizing}} energy consumption of a building zone under pre-assigned multi-variable comfort conditions and changing energy rate is addressed. The solution {{involves the use of}} a parameterized multi-variable Nonlinear Model Predictive Control (NMPC) that manages the actuation of heating/cooling, ventilation, lighting and <b>blinds</b> devices. <b>Simulations</b> of the resulting closed-loop in winter and summer seasons under varying rate profile are proposed to assess its efficiency. Moreover, a sensitivity analysis is conducted to show how the comfort level assignment impacts the level of energy consumption...|$|R
40|$|This paper {{presents}} {{a novel approach}} for speech extraction by a combined subband independent component analysis and neural memory. In the approach, probabilistic neural networks followed by the subband independent component analysis processing units are used for the neural memory to identify firstly the speaker and then compensate for the `side-effects', i. e., the scaling and the permutation disorder, {{both of which are}} particularly problematic for subband <b>blind</b> extraction. <b>Simulation</b> study shows that the combined scheme can effectively extract the speech signal of interest from the instantaneous/delayed mixtures, in comparison with the conventional subband/fullband approaches...|$|R
30|$|A saturable multi-compartment {{pharmacokinetic}} {{model for}} the multidrug treatment of cancer using paclitaxel and doxorubicin in a combination is developed. The model’s kinetic equations are then solved using standard numerical methods for solving systems of nonlinear differential equations. The parameters were adjusted by fitting to available clinical data. In addition, we studied the interaction of each drug with the metabolic enzyme CYP 3 A 4 through <b>blind</b> docking <b>simulations</b> to demonstrate that these drugs compete for the same metabolic enzyme and to show their molecular mode of binding. This provides a molecular-level justification for the introduction of interaction terms in the kinetic model.|$|R
40|$|SSP 2009 : IEEE/SP 15 th Workshop on Statistical Signal Processing, August 31 - September 3, 2009, Cardiff, UK. This paper {{presents}} a new frequency domain blind signal extraction (FD-BSE) method for {{the extraction of}} a target speech in presence of diffuse background noise. This is a fast alternative to frequency domain blind signal separation (FD-BSS) for hands-free speech interface. Like the FD-BSS approach, the speech signal is enhanced by using a nonlinear filter to suppress the noise estimated by the <b>blind</b> method. <b>Simulation</b> results in a realistic environment show {{the effectiveness of the}} proposed method...|$|R
30|$|Below {{is a short}} {{description}} of the pharmacokinetic model mentioned above. The model focuses on the interactions of paclitaxel and doxorubicin with a common metabolic enzyme for the two compounds. To gain further understanding of these interactions at the molecular level, we performed a <b>blind</b> docking <b>simulation</b> protocol, which was employed to predict the binding sites, modes of binding and binding energies of the two drugs to the CYP 3 A 4 metabolic enzyme. This was intended to explain at a molecular level why these two drugs affect each other’s pharmacokinetic profiles. Below is {{a description of the}} modeling techniques used both for pharmacokinetic analysis and molecular dynamics simulations of the two drugs, paclitaxel and doxorubicin.|$|R
40|$|The paper {{presents}} the results of the CFD inter-comparison exercise SBEP-V 3, performed within the activity InsHyde, internal project of the HySafe network of excellence, in the framework of evaluating the capability of various CFD tools and modelling approaches in predicting the short and long term mixing and distribution of hydrogen releases in confined spaces. The experiment simulated was INERIS-TEST- 6 C, performed within the InsHyde project by INERIS, consisting of a 1 g/s vertical hydrogen release for 240 s from an orifice of 20 mm diameter into a rectangular room (garage) of dimensions 3. 78 × 7. 2 × 2. 88 m in width, length and height respectively. Two small openings {{at the bottom of the}} front side of the room assured constant pressure conditions. During the test hydrogen concentration time histories were measured at 12 positions in the room, for a period up to 5160 s after the end of release, covering both the release and the subsequent diffusion phases. The benchmark was organized in two phases. The first phase consisted of <b>blind</b> <b>simulations</b> performed prior to the execution of the tests. The second phase consisted of post-calculations performed after the tests were concluded and the experimental results made available. The participation in the benchmark was high: 12 different organizations (2 non-HySafe partners), 10 different CFD codes and 8 different turbulence models. Large variation in predicted results was found in the first phase of the benchmark, between the various modelling approaches. This was attributed mainly to differences in turbulence models and numerical accuracy options (time/space resolution and discretization schemes). During the second phase of the benchmark the variation between predicted results was reduced...|$|R
40|$|This paper {{addresses}} {{the problem of}} separating a cyclostationary source from linear mixtures. It first shows that if the cyclic frequencies {{of the source of}} interest are known and {{different from those of the}} interfering sources, perfect source separation can be achieved using the proposed separation criterion. Then an algorithm is derived to perform the <b>blind</b> source separation. <b>Simulation</b> results demonstrate the validity of the proposed algorithm<br /...|$|R
40|$|Abstract—This paper aims {{at finding}} an {{algorithm}} featuring good estimation performance and easy hardware implementation for tracking airborne target hidden in blind Doppler. Incorporating the current statistical model which {{is effective in}} dealing with the maneuvering motions that most blind Doppler issues are caused, a current statistical model particle filter (CSM-PF) is presented in this paper for tracking airborne targets hidden in <b>blind</b> Doppler. <b>Simulation</b> results demonstrate that the proposed CSM-PF shows similar performance with the interacting multiple model particle filter (IMM-PF) in terms of tracking accuracy and track continuity, but it avoids the difficulty of model selection for maneuvering targets. In addition, when hardware implementation is considered, the proposed CSM-PF has lower processing latency, fewer resource utilization and lower hardware complexity than the IMM-PF. 1...|$|R
40|$|Abstract. Paraunitary filter {{banks are}} {{important}} for several signal processing tasks, including coding, multichannel deconvolution and equalization, adaptive beamforming, and subspace processing. In this paper, we consider the task of adapting the impulse response of a multichannel paraunitary filter bank via gradient ascent or descent on a chosen cost function. Our methods are spatio-temporal generalizations of gradient techniques on the Grassmann and Stiefel manifolds, and we prove that they inherently maintain the paraunitariness of the multichannel adaptive system over time. We then discuss the necessary practical approximations, modifications, and simplifications of the methods for solving two relevant signal processing tasks: (i) spatio-temporal subspace analysis and (ii) multichannel <b>blind</b> deconvolution. <b>Simulations</b> indicate that our methods can provide simple, useful solutions to these important problems...|$|R
40|$|Careful {{selection}} of step size parameters is often necessary to obtain good performance from gradient-based adaptive algorithms for decorrelation and source separation tasks. In this paper, we provide {{an overview of}} methods for the on-line calculation of step size parameters for these systems. A particular emphasis is placed on gradient adaptive step sizes for a class of natural gradient algorithms for decorrelation and <b>blind</b> source separation. <b>Simulations</b> verifying their useful behaviors are provided. 1...|$|R
40|$|Background In {{this paper}} the {{interactions}} between paclitaxel, doxorubicin and the metabolic enzyme CYP 3 A 4 are studied using computational models. The obtained results are {{compared with those of}} available clinical data sets. Analysis of the drug-enzyme interactions leads to a recommendation of an optimized paclitaxel-doxorubicin drug regime for chemotherapy treatment. Methods A saturable multi-compartment pharmacokinetic model for the multidrug treatment of cancer using paclitaxel and doxorubicin in a combination is developed. The model’s kinetic equations are then solved using standard numerical methods for solving systems of nonlinear differential equations. The parameters were adjusted by fitting to available clinical data. In addition, we studied the interaction of each drug with the metabolic enzyme CYP 3 A 4 through <b>blind</b> docking <b>simulations</b> to demonstrate that these drugs compete for the same metabolic enzyme and to show their molecular mode of binding. This provides a molecular-level justification for the introduction of interaction terms in the kinetic model. Results Using docking simulations we compared the relative binding affinities for the metabolic enzyme of the two chemotherapy drugs. Since paclitaxel binds more strongly to CYP 3 A 4 than doxorubicin, an explanation is given why doxorubicin has no apparent influence upon paclitaxel, while paclitaxel has a profound effect upon doxorubicin. Finally, we studied different time sequences of paclitaxel and doxorubicin concentrations and calculated their AUCs. Conclusions We have found excellent agreement between our model and available empirical clinical data for the drug combination studied here. To support the kinetic model at a molecular level, we built an atomistic three-dimensional model of the ligands interacting with the metabolic enzyme and elucidated the binding modes of paclitaxel and doxorubicin within CYP 3 A 4. <b>Blind</b> docking <b>simulations</b> provided estimates of the corresponding binding energies. The paper is concluded with clinical implications for the administration of the two drugs in combination...|$|R
40|$|International audienceThe paper {{presents}} the results of the CFD inter-comparison exercise SBEP-V 3, performed within the activity InsHyde, internal project of the HYSAFE network of excellence, in the framework of evaluating the capability of various CFD tools and modeling approaches in predicting the physical phenomena associated to the short and long term mixing and distribution of hydrogen releases in confined spaces. The experiment simulated was INERIS-TEST- 6 C, performed within the InsHyde project by INERIS, consisting of a 1 g/s vertical hydrogen release for 240 s from an orifice of 20 mm diameter into a rectangu ar room (garage) of dimensions 3. 78 x 7. 2 x 2. 88 m in width, length and height respectively. Two small openings at the front and bottom side of the room assured constant pressure conditions. During the test hydrogen concentration time histories were measured at 12 positions in the room, for a period up to 5160 s after the end of release, covering both the release and the subsequent diffusion phases. The benchmark was organized in two phases. The first phase consisted of <b>blind</b> <b>simulations</b> performed prior to the execution of the tests. The second phase consisted of post-calculations performed after the tests were concluded and the experimental results made available. The participation in the benchmark was high: 12 different organizations (2 non-HYSAFE partners) 10 different CFD codes and 8 different turbulence models. Large variation in predicted results was found in {{the first phase of the}} benchmark, between the various modeling approaches. This was attributed mainly to differences in turbulence models and numerical accuracy options (time/space resolution and discretization schemes). During the second phase of the benchmark the variation between predicted results was reduced...|$|R
40|$|This paper {{presents}} {{a method for}} the efficient realistic shading of cumulus clouds. Our approach consists in taking advantage of all the a priori knowledge {{on the characteristics of}} such objects and on the light effects that are known to occur, thus avoiding a time consuming (<b>blind)</b> physical <b>simulation</b> of multiple scattering through volumes. This paper only focuses on cloud shading. It does not deal with the modeling and animation of the cloud's shape, or with sky models. The features we take into account are the illumination, including the effects of the inter-reflections and of the environment, and the cloud's corona behavior, especially when illuminated from the back. We show some results obtained with our preliminary implementation, illustrating these features. All the images are ray-traced in about 1 minute on a SGI O 2...|$|R
40|$|AbstractWe have {{developed}} a new combined approach for ab initio protein structure prediction. The protein conformation {{is described as a}} lattice chain connecting Cα atoms, with attached Cβ atoms and side-chain centers of mass. The model force field includes various short-range and long-range knowledge-based potentials derived from a statistical analysis of the regularities of protein structures. The combination of these energy terms is optimized through the maximization of correlation for 30 × 60, 000 decoys between the root mean square deviation (RMSD) to native and energies, as well as the energy gap between native and the decoy ensemble. To accelerate the conformational search, a newly developed parallel hyperbolic sampling algorithm with a composite movement set is used in the Monte Carlo simulation processes. We exploit this strategy to successfully fold 41 / 100 small proteins (36 ∼ 120 residues) with predicted structures having a RMSD from native below 6. 5 Å in the top five cluster centroids. To fold larger-size proteins as well as to improve the folding yield of small proteins, we incorporate into the basic force field side-chain contact predictions from our threading program PROSPECTOR where homologous proteins were excluded from the data base. With these threading-based restraints, the program can fold 83 / 125 test proteins (36 ∼ 174 residues) with structures having a RMSD to native below 6. 5 Å in the top five cluster centroids. This shows the significant improvement of folding by using predicted tertiary restraints, especially when the accuracy of side-chain contact prediction is > 20 %. For native fold selection, we introduce quantities dependent on the cluster density and the combination of energy and free energy, which show a higher discriminative power to select the native structure than the previously used cluster energy or cluster size, and which can be used in native structure identification in <b>blind</b> <b>simulations.</b> These procedures are readily automated and are being implemented on a genomic scale...|$|R
40|$|Yantai UniversitySensor {{scheduling}} problem in infrared LEO constellation by bearing-only location is studied {{to ensure its}} continuous tracking and parallel processing multitask. Firstly, the problem is defined in detail, and a mathematical model is presented. Secondly, an adaptive multitask programming on probabilistic selection algorithm(AMPPSA) is proposed, which utilizes trend catching, random selection and clone variation to keep from sub optimizing and applies heuristic rules to avoid <b>blind</b> searching. Finally, <b>simulations</b> show that the algorithm fits to sensor management of multi-objective optimization in infrared LEO constellation. © 2010 IEEE...|$|R
40|$|Abstract—We {{present in}} this paper a non-orthogonal algo-rithm for the {{approximate}} joint diagonalization {{of a set of}} matrices. It is an iterative algorithm, using relaxation technique applied on the rows of the diagonalizer. The performances of our algorithm are compared with usual standard algorithms using <b>blind</b> sources separation <b>simulations</b> results. We show that the improvement in estimating the separating matrix can be wreaked when the level noise in the mixture is significant, the length of observed sequences is sufficiently large and when the mixing matrix is not an orthogonal matrix or just about. I...|$|R
40|$|In certain digital {{communication}} systems, {{such as those}} us-ing Tomlinson-Harashima precoding and signal shaping, the received symbols are not equiprobable; rather, symbols with more energy are less likely. It is shown that in such scenar-ios the performance of standard carrier phase estimators is severely degraded. Using a discrete Gaussian model for the symbol probability distribution, we present the likelihood function for phase estimation, {{as well as an}} approximate Maximum Likelihood <b>blind</b> phase estimator. <b>Simulation</b> re-sults show that the proposed estimate is much more robust to non-equiprobable symbol distributions than standard ones...|$|R
