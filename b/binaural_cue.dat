58|288|Public
40|$|We {{propose a}} new multi-microphone noise {{reduction}} technique for <b>binaural</b> <b>cue</b> {{preservation of the}} desired source and the interferers. This method {{is based on the}} linearly constrained minimum variance (LCMV) framework, where the constraints are used for the <b>binaural</b> <b>cue</b> preservation of the desired source and of multiple interferers. In this framework there is a trade-off between noise reduction and <b>binaural</b> <b>cue</b> preservation. The more constraints the LCMV uses for preserving binaural cues, the less degrees of freedom can be used for noise suppression. The recently presented binaural LCMV (BLCMV) method and the optimal BLCMV (OBLCMV) method require two constraints per interferer and introduce an additional interference rejection parameter. This unnecessarily reduces the degrees of freedom, available for noise reduction, and negatively influences the trade-off between noise reduction and <b>binaural</b> <b>cue</b> preservation. With the proposed method, <b>binaural</b> <b>cue</b> preservation is obtained using just a single constraint per interferer without the need of an interference rejection parameter. The proposed method can simultaneously achieve noise reduction and perfect <b>binaural</b> <b>cue</b> preservation of {{more than twice as many}} interferers as the BLCMV, while the OBLCMV can preserve the binaural cues of only one interferer. Accepted Author ManuscriptCircuits and System...|$|E
40|$|Perceptual {{parameters}} ICLD, ICTD and ICC has a {{very important}} practical significance, so {{the use of these}} parameters, the researchers propose parameters based on FFT frequency domain <b>binaural</b> <b>cue</b> coding method to achieve a better stereo encoding quality. Compared with the FFT, modulation spliced transform (Modulated Lapped Transform, MLT) has an energy concentration, facilitating the removal of the characteristics of inter-blocking effect. Therefore, this article will be applied to <b>binaural</b> <b>cue</b> coding MLT transform them, to achieve a <b>binaural</b> <b>cue</b> coding method based MLT transfor...|$|E
40|$|In {{this paper}} we propose a new {{binaural}} beamforming technique which {{can be seen as a}} relaxation of the linearly constrained minimum variance (LCMV) framework. The proposed method can achieve simultaneous noise reduction and exact <b>binaural</b> <b>cue</b> preservation of the target source, similar to the binaural minimum variance distortionless response (BMVDR) method. However, unlike BMVDR, the proposed method is also able to preserve the binaural cues of multiple interferers to a certain predefined accuracy. Specifically, it is able to control the trade-off between noise reduction and <b>binaural</b> <b>cue</b> preservation of the interferers by using a separate trade-off parameter per interferer. Moreover, we provide a robust way of selecting these trade-off parameters in such a way that the preservation accuracy for the binaural cues of the interferers is always better than the corresponding ones of the BMVDR. The relaxation of the constraints in the proposed method achieves approximate <b>binaural</b> <b>cue</b> preservation of more interferers than other previously presented LCMV-based binaural beamforming methods that use strict equality constraints...|$|E
50|$|<b>Binaural</b> <b>cues</b> are {{generated}} by the difference in hearing between {{the left and right}} ears. These differences include the interaural time difference (ITD) and the interaural intensity difference (IID). <b>Binaural</b> <b>cues</b> are used mostly for horizontal localization.|$|R
40|$|Abstract—In {{this paper}} the mixing vector (MV) in the {{statistical}} mixing model {{is compared to}} the <b>binaural</b> <b>cues</b> represented by in-teraural level and phase differences (ILD and IPD). It is shown that the MV distributions are quite distinct while binaural models overlap when the sources are close to each other. On the other hand, the <b>binaural</b> <b>cues</b> are more robust to high reverberation than MV models. According to this complementary behavior we intro-duce a new robust algorithm for stereo speech separation which considers both additive and convolutive noise signals to model the MV and <b>binaural</b> <b>cues</b> in parallel and estimate probabilistic time-frequency masks. The contribution of each cue to the final decision is also adjusted by weighting the log-likelihoods of the cues em-pirically. Furthermore, the permutation problem of the frequency domain blind source separation (BSS) is addressed by initializing the MVs based on <b>binaural</b> <b>cues.</b> Experiments are performed sys-tematically on determined and underdetermined speech mixtures in five rooms with various acoustic properties including anechoic, highly reverberant, and spatially-diffuse noise conditions. The re-sults in terms of signal-to-distortion-ratio (SDR) confirm the ben-efits of integrating the MV and <b>binaural</b> <b>cues,</b> as compared with two state-of-the-art baseline algorithms which only use MV or the <b>binaural</b> <b>cues.</b> Index Terms—Blind source separation, computational auditory scene analysis, reverberation, time-frequency masking. I...|$|R
40|$|In {{this paper}} the mixing vector (MV) in the {{statistical}} mixing model {{is compared to}} the <b>binaural</b> <b>cues</b> represented by interaural level and phase differences (ILD and IPD). It is shown that the MV distributions are quite distinct while binaural models overlap when the sources are close to each other. On the other hand, the <b>binaural</b> <b>cues</b> are more robust to high reverberation than MV models. According to this complementary behavior we introduce a new robust algorithm for stereo speech separation which considers both additive and convolutive noise signals to model the MV and <b>binaural</b> <b>cues</b> in parallel and estimate probabilistic time-frequency masks. The contribution of each cue to the final decision is also adjusted by weighting the log-likelihoods of the cues empirically. Furthermore, the permutation problem of the frequency domain blind source separation (BSS) is addressed by initializing the MVs based on <b>binaural</b> <b>cues.</b> Experiments are performed systematically on determined and underdetermined speech mixtures in five rooms with various acoustic properties including anechoic, highly reverberant, and spatially-diffuse noise conditions. The results in terms of signal-to-distortion-ratio (SDR) confirm the benefits of integrating the MV and <b>binaural</b> <b>cues,</b> as compared with two state-of-the-art baseline algorithms which only use MV or the <b>binaural</b> <b>cues...</b>|$|R
30|$|<b>Binaural</b> <b>cue</b> {{preservation}} {{is one of}} {{the main}} quality factors that need to be considered in addition to noise reduction and speech preservation in binaural speech enhancement. Preserving the binaural cues of the speech signal, particularly ILD and ITD, helps the listener to localize the desired speaker more precisely.|$|E
30|$|We first {{analyze the}} {{localization}} principle of binaural hearing {{and give a}} spatial hearing model on the physical and physiological layers. Then we propose a <b>Binaural</b> <b>Cue</b> Physiological Perception Model (BCPPM) based on binaural hearing. Finally using binaural frequency-domain perception property, we give a formula to compute the quantity of spatial information and numerical results of spatial information estimation of real-world stereo audio signals.|$|E
30|$|This paper {{presents}} a novel algorithm {{to estimate the}} interchannel time difference by using the nonuniform discrete Fourier transform. The frequency bins can be adjusted as requested by integrating this algorithm with the <b>binaural</b> <b>cue</b> coding approach. Consequently, the decoded audio image width is improved compared to the traditional DFT-based method. On the other hand, the sound quality is not deteriorated by adding this algorithm module in the BCC scheme.|$|E
40|$|Psychoacoustics is the {{scientific}} study of sound perception. Within this field, Virtual Reality is a technique that uses two synthesis speakers to simulate a sine tone coming from anywhere in open space. Using this method it is possible to independently control specific <b>binaural</b> <b>cues</b> in a free-field environment. This study analyzes listener responses to these controlled sine tones to investigate the relative importance of certain <b>binaural</b> <b>cues</b> at different frequencies...|$|R
3000|$|The resolutions or {{quantization}} {{steps of}} the <b>binaural</b> <b>cues</b> (Figure 12) can be determined by JND experiments. Denote by [...]...|$|R
40|$|EUSIPCO 2012 : The 20 th European Signal Processing Conference, August 27 - 31, 2012, Bucharest, RomaniaIn this paper, {{we address}} some {{variations}} of the sourcelocalization-preserved MMSE STSA estimator used for binaural hearing aids. In our previous work, the soundlocalization-preserved MMSE STSA estimator with ICAbased noise estimation has been proposed. However, this conventional method {{is based on an}} approximated optimization criterion and does not use <b>binaural</b> <b>cues,</b> resulting in poor noise reduction performance. To solve this problem, we propose two methods: a multichannel MMSE STSA estimator with explicit <b>binaural</b> <b>cues,</b> and a sound-localizationpreserved generalized MMSE STSA estimator with different speech priors for the left and right channels as implicit <b>binaural</b> <b>cues.</b> From the results of objective and subjective evaluation, we confirm that the noise reduction performance is improved using the proposed method...|$|R
40|$|Binaural {{hearing aids}} use {{microphone}} signals from both {{left and right}} hearing aid to generate an output signal for each ear. The microphone signals can be processed by a procedure based on speech distortion weighted multichannel wiener filtering (SDW-MWF) to achieve significant noise reduction in a speech + noise scenario. In binaural procedures, it is also desirable to preserve binaural cues, in particular the interaural time difference (ITD) and interaural level difference (ILD), which are used to localize sounds. It {{has been shown in}} previous work that the binaural SDW-MWF procedure only preserves these binaural cues for the desired speech source, but distorts the noise binaural cues. Two extensions of the binaural SDW-MWF have therefore been proposed to improve the <b>binaural</b> <b>cue</b> preservation, namely the MWF with partial noise estimation (MWF-) and MWF with interaural transfer function extension (MWF-ITF). In this paper, the <b>binaural</b> <b>cue</b> preservation of these extensions is analyzed theoretically and tested based on objective performance measures. Both extensions are able to preserve binaural cues for the speech and noise sources, while still achieving significant noise reduction performance. status: publishe...|$|E
40|$|This paper {{describes}} the <b>binaural</b> <b>cue</b> preservation of a noise reduc-tion algorithm for bilateral hearing aids, namely the multichannel Wiener filter with interaural transfer function extension (MWF-ITF). An extra term {{is added to}} the cost function to preserve the binaural cues of both the speech and noise component of a signal at the cost of some noise reduction. This paper combines the theoretical anal-ysis with objective binaural performance measures and a perceptual evaluation. Index Terms — hearing aids, binaural hearing, noise reduction, adaptive filter, localization 1...|$|E
40|$|To {{evaluate}} {{all aspects}} of binaural signal processing algorithms, an objective measure of how they affect spatial perception is required. We are developing such a measure using a data-driven approach based on virtual acoustics and models of binaural signal processing of the auditory system. We present {{a brief overview of}} the methods and models that we use to study spatial perception. We discuss the binaural cues of realistic signals in more detail, and demonstrate the importance of interaural coherence as a <b>binaural</b> <b>cue.</b> We conclude with an outlook on our future work...|$|E
40|$|Abstract [...] We {{study the}} problem of audio source {{separation}} from stereo-channel microphones in a room acoustic environment. Instead of using the whole <b>binaural</b> <b>cues</b> as done in DUET (Degenerate Unmixing Estimation Technique) -type methods, we propose a technique that selects a reliable subset of <b>binaural</b> <b>cues</b> by examining the phase determinacy and the sparse source conditions. We conduct experiments with a simulated room acoustic environment and show a significant performance gain of the proposed technique over the DUET-type methods. I...|$|R
40|$|Despite many {{considerable}} technical {{advances in}} the field of hearing aids and cochlear implants, people using auditory prostheses still have major problems with speech understanding in the presence of interfering sounds and with directional hearing. Both abilities are dependent on sound stream segregation in real-world listening environments. In this paper, two timely and important issues related to sound stream segregation in auditory prostheses are addressed, namely, the coding of monaural and <b>binaural</b> <b>cues.</b> Several state-of-the-art signal processing algorithms used in cochlear implants (CIs) and in hearing aids (HAs) are introduced. A review is given of some recent proposals to improve temporal coding in monaural CIs, and of recent work to improve the transmission of <b>binaural</b> <b>cues</b> in both HAs, CIs, and combined acoustic and electric hearing (bimodal hearing). The ultimate aim is to improve speech and music perception, and, additionally, the preservation of <b>binaural</b> <b>cues</b> to preserve directional hearing. status: publishe...|$|R
30|$|In audio compression, {{irrelevancy}} removing {{is mainly}} on the physical and physiological layers. In the following, we discuss the representation of <b>binaural</b> <b>cues</b> on the two layers—BCPPM.|$|R
30|$|The {{bilateral}} gain functions G_i = 1 - ϕ _n_in_i/ϕ _y_iy_i with i∈l,r and the binaural cue-preserving MMSE filter in (10) {{are compared}} {{in terms of}} <b>binaural</b> <b>cue</b> preservation. Here, the ILD and ITD are estimated according to [65] using the shadow-filtered clean signal. It {{should be noted that}} only frequency ranges higher than 1.5 kHz and lower than 1.5 kHz are considered for the computation of the ILD and ITD, respectively. The ambient noise is the isotropic diffuse noise generated by the algorithm in [62] with the 2 D coherence model at 0 dB SNR.|$|E
40|$|In {{this paper}} a {{theoretical}} {{analysis of the}} <b>binaural</b> <b>cue</b> preserva-tion of the multi-channel Wiener filter (MWF) is performed. We will prove {{that in the case}} of a single speech source the MWF perfectly preserves the binaural cues of the speech component, but changes the binaural cues of the noise component to the cues of the speech component. In addition, we show that by extend-ing the MWF cost function with terms related to the interaural transfer function it is possible to preserve the binaural cues of both the speech and the noise component, without considerably reducing the noise reduction performance. 1...|$|E
30|$|Since 1990, {{joint stereo coding}} {{algorithm}} has been widely used in the two-channel audio coding. Various techniques {{have been developed for}} compressing stereo or multichannel audio signals. Recently, the ISO/MPEG standardization group has published a new audio standard, that is, MPEG Surround, which is a feature-rich open standard compression technique for multichannel audio signals [1]. MPEG Surround coding can be regarded as an enhancement of the joint stereo coding and an extension of BCC [[2, 5]]. BCC exploits <b>binaural</b> <b>cue</b> parameters for capturing the spatial image of multichannel audio and enables low-bit-rate transmission by transmitting mono signals plus side information in relation to binaural perception.|$|E
40|$|Abstract—A {{fundamental}} {{task for}} a robotic audition system is sound source localization. This paper addresses the local-ization {{problem in a}} robotic humanoid context, providing a novel learning algorithm that uses <b>binaural</b> <b>cues</b> to determine the sound source’s position. Sound signals are extracted from a humanoid robot’s ears. <b>Binaural</b> <b>cues</b> are then computed to provide inputs for a neural network. The neural network uses pixel coordinates of a sound source in a camera image as outputs. This learning approach provides good localization performances as it reaches very small errors for azimuth and elevation angles estimates...|$|R
30|$|To {{overcome}} {{the limitations of}} single-channel systems, various multi-channel techniques have been developed, including the minimum variance distortionless response (MVDR) [7] and the multi-channel Wiener filter (MWF) with constraints [8 – 12]. The MVDR is a widely used spatial filter in multi-channel systems that minimizes output power under the constraint that the desired signal is not affected [7]. On the other hand, the MWF provides an optimal solution for broadband noise reduction from a {{minimum mean square error}} (MMSE) perspective. Speech-distortion-weighted MWF (SDW-MWF) has been introduced to control speech distortion and noise reduction [8]. Algorithms such as SDW-MWF and MVDR preserve speech <b>binaural</b> <b>cues,</b> but distort noise <b>binaural</b> <b>cues</b> [10]. Therefore, extensions for preserving the <b>binaural</b> <b>cues</b> of directional sources using additional cost functions or linear constraints have been proposed [10, 11]. As a result, another extension to preserve interaural coherence (IC) has been proposed [12] as part of a study of spatially isotropic noise, the spatial characteristic of which is represented by IC.|$|R
40|$|Relaxed {{implantation}} criteria {{resulting from}} the success of cochlear implants (CI’s) {{over the years as}} a treatment for severe hearing impairment lead to more and more CI users who still have residual hearing in the non-implanted ear. The combination of a CI and a hearing aid is often called bimodal stimulation. Although the fitting of a hearing aid (HA) in the ear contralateral to the CI can lead to binaural benefits and improves speech understanding in quiet, bimodal listeners still perform poor in sound localization and speech understanding in noisy surroundings. In localization of sound sources <b>binaural</b> <b>cues</b> such as the interaural time difference (ITD) and interaural level difference (ILD) play an important role. The ability to perceive <b>binaural</b> <b>cues</b> is also strongly related to understanding a target speaker in a noisy environment. <b>Binaural</b> <b>cues</b> are not optimally present in the sound transmitted to the auditory system mainly due to independent fitting of the devices, lack of synchronization between the devices and several processing steps in the CI speech processing. Current research focuses on the development of binaural processing strategies to improve the transmission and perception of <b>binaural</b> <b>cues</b> in bimodal stimulation. Latest results show benefit from synchronized temporal envelope modulations in the electrical signal on the perception of ITD in vowel stimuli with bimodal stimulation. status: publishe...|$|R
40|$|International audienceLow-bit-rate {{parametric}} audio coding for multichannel audio {{is mainly}} based on <b>Binaural</b> <b>Cue</b> Coding (BCC). In this paper {{we show that}} the Unified Domain Representation (UDR) of multichannel audio, recently introduced, is equivalent to BCC scheme. We also discuss another method, called multichannel audio upmix, which classically converts existing two-channel stereo to five-channel audio. More precisely, we focus on existing PCA-based upmix method. Starting from PCA approach, we propose a general model that may be applied both to parametric representation of multichannel audio signals and upmix methods. Moreover, we apply the analysis results to propose a new low-bit-rate parametric audio coding method based on frequency subbands PCA processing...|$|E
40|$|For over a century, the duplex {{theory has}} guided our {{understanding}} of human sound localization in the horizontal plane. According to this theory, the auditory system uses interaural time differences (ITDs) and interaural level differences (ILDs) to localize low-frequency and high-frequency sounds, respectively. Whilst this theory successfully accounts for the localization of tones by humans, some species show very different behaviour. Ferrets are widely used for studying both clinical and fundamental aspects of spatial hearing, {{but it is not}} known whether the duplex theory applies to this species or, if so, to what extent the frequency range over which each <b>binaural</b> <b>cue</b> is used depends on acoustical or neurophysiological factors. To address these issues, we trained ferrets to lateralize tones presented over earphones and found that the frequency dependence of ITD and ILD sensitivity broadly paralleled that observed in humans. Compared with humans, however, the transition between ITD and ILD sensitivity was shifted toward higher frequencies. We found that the frequency dependence of ITD sensitivity in ferrets can partially be accounted for by acoustical factors, although neurophysiological mechanisms are also likely to be involved. Moreover, we show that <b>binaural</b> <b>cue</b> sensitivity can be shaped by experience, as training ferrets on a 1 -kHz ILD task resulted in significant improvements in thresholds that were specific to the trained cue and frequency. Our results provide new insights into the factors limiting the use of different sound localization cues and highlight the importance of sensory experience in shaping the underlying neural mechanisms...|$|E
40|$|EX Multi-channel audio {{recording}} and reproduction systems involve {{large amounts of}} data, which requires efficient audio coders for storage and transmission. <b>Binaural</b> <b>Cue</b> Coding (BCC) introduces a solution to provide spatial audio rendering at low data rate, by representing the multi-channel audio signals as one ’sum ’ channel and additional spatially relevant information. This information is based on analysis of perceptually relevant binaural cues, Interaural Level Difference (ILD) and Interaural Time Difference (ITD). This thesis discusses the psychoacoustics fundamentals related to spatial hearing employed by BCC. Implementation of BCC analyzer using a Gammatone Filter Bank is described and all aspects of BCC analyzer and synthesizer with a low-complexity scheme based on DFT is explained. The performance of the schemes are evaluated by an informal subjective test. ...|$|E
30|$|In this section, we {{introduce}} the proposed noise PSD estimator based on eigenvalue of input covariance matrix. After that, approximation {{of the proposed}} estimator based on interaural <b>binaural</b> <b>cues</b> is presented.|$|R
30|$|In each sub-channel, {{there are}} {{intrinsic}} channel noises (resolution of spatial hearing), and among sub-channels, there are interchannel interferences (interaction of <b>binaural</b> <b>cues).</b> Then {{there is an}} effective noise for each sub-channel.|$|R
5000|$|When {{the head}} is stationary, the <b>binaural</b> <b>cues</b> for lateral sound {{localization}} (interaural time difference and interaural level difference) do not give information about {{the location of a}} sound in the median plane. Identical ITDs and ILDs can be produced by sounds at eye level or at any elevation, as long as the lateral direction is constant. However, if {{the head is}} rotated, the ITD and ILD change dynamically, and those changes are different for sounds at different elevations. For example, if an eye-level sound source is straight ahead and the head turns to the left, the sound becomes louder (and arrives sooner) at the right ear than at the left. But if the sound source is directly overhead, there will be no change in the ITD and ILD as the head turns. Intermediate elevations will produce intermediate degrees of change, and if the presentation of <b>binaural</b> <b>cues</b> to the two ears during head movement is reversed, the sound will be heard behind the listener. [...] Hans Wallach [...] artificially altered a sound’s <b>binaural</b> <b>cues</b> during movements of the head. Although the sound was objectively placed at eye level, the dynamic changes to ITD and ILD as the head rotated were those that would be produced if the sound source had been elevated. In this situation, the sound was heard at the synthesized elevation. The fact that the sound sources objectively remained at eye level prevented monaural cues from specifying the elevation, showing that it was the dynamic change in the <b>binaural</b> <b>cues</b> during head movement that allowed the sound to be correctly localized in the vertical dimension. The head movements need not be actively produced; accurate vertical localization occurred in a similar setup when the head rotation was produced passively, by seating the blindfolded subject in a rotating chair. As long as the dynamic changes in <b>binaural</b> <b>cues</b> accompanied a perceived head rotation, the synthesized elevation was perceived.|$|R
40|$|This paper {{outlines}} {{the development of}} a crosscorrelation algorithm and a spiking neural network (SNN) for sound localisation based on real sound recorded in a noisy and dynamic environment by a mobile robot. The SNN architecture aims to simulate the sound localisation ability of the mammalian auditory pathways by exploiting the <b>binaural</b> <b>cue</b> of interaural time difference (ITD). The medial superior olive was the inspiration for the SNN architecture which required the integration of an encoding layer which produced biologically realistic spike trains, a model of the bushy cells found in the cochlear nucleus and a supervised learning algorithm. The experimental results demonstrate that biologically inspired sound localisation achieved using a SNN can compare favourably to the more classical technique of cross-correlation...|$|E
40|$|In {{this paper}} a novel speech {{enhancement}} algorithm for binaural dereverberation is proposed. It {{is based on}} a multichannel Wiener filter approach, which is optimized for the application to digital hear-ing aids and binaural telephony headsets. This is mainly done by two different modifications. First, an optimized model for the bin-aural coherence which takes the shadowing effects of the head into account. Second, a binaural input-output structure which does not affect the most important binaural cues, i. e., interaural time differ-ence (ITD) and interaural level difference (ILD), and hence, keeps the localization ability. Evaluations with measured binaural room impulse responses (BRIR) show that this approach is capable of re-ducing reverberation especially in highly reverberant environments. Index Terms — Binaural, dereverberation, <b>binaural</b> <b>cue</b> preser-vation, coherence, speech enhancement 1...|$|E
30|$|In {{an effort}} to {{efficiently}} represent multi-channel audio, spatial audio coding (SAC) has been studied extensively {{during the last decade}} [1 – 4]. Among SAC schemes, parametric stereo (PS) [5] drew keen attention due to its simple but effective way of representing stereo audio. PS presents stereo audio as a downmixed mono, together with relevant spatial parameters. Past researches indicate that PS can provide stable stereo quality at bit rates of a few kbps for spatial parameters [5]. After being combined with <b>binaural</b> <b>cue</b> coding (BCC) [6], PS was expanded to multi-channel applications, so that it was adopted in MPEG Surround as a stereo tool [7 – 10]. PS was also included in HE-AACv 2 [9] and the recently developed unified speech and audio coding (USAC) [10] standards.|$|E
30|$|The {{main goal}} of this paper has been to {{investigate}} the effect of quantization errors on the binaural GSC. Several extensions to the basic theme can be followed. Topics for future work include studying the effect of reverberation and ambient diffuse noise {{on the performance of}} the beamformer. <b>Binaural</b> localization <b>cues</b> such as interaural time and level differences have been shown to contribute towards speech intelligibility. Future work could analyze the effect of quantization errors on these <b>binaural</b> <b>cues.</b>|$|R
30|$|We have {{developed}} the <b>Binaural</b> <b>Cues</b> Physiological Perceptual Model (BCPPM) to measure the perceptible information, or Spatial Perceptual Entropy (SPE), in multichannel audio signals and have given a lower bitrate bound in multimedia communications {{for this type of}} contents. BCPPM models the physical and physiological processing of human spatial hearing into a parallel of lossy communication subchannels with inter-subchannel interference, and SPE is the overall channel capacity. Each of these subchannels carries ITD, ILD, or IC with addictive noises, resulted from intrinsic noises of <b>binaural</b> <b>cues</b> perception and interferences among the cues within the same CB. Experiments on stereo signals of different types have confirmed that SPE is compatible with the spatial parameter bitrate and spatial impression in SAC.|$|R
40|$|Abstract The {{purpose of}} this project is to desig a systematical method {{in order to measure}} human {{directionality}} ability in horizontal plane with a single sound source. A completely virtual auditory model has been created in Matlab. The project consists of modeling <b>binaural</b> <b>cues,</b> designing digital filters, designing a test workbench, measuring listener's directionality and analyzing the data. The head related transfer function (HRTF) is computed by calculating the two most important <b>binaural</b> <b>cues,</b> interaural level difference (ILD) and interaural time difference (ITD). The platform is made in Matlab and all results have been shown by plots produced from Matlab code. The directionality test has been done with real human subjects and the results have been analyzed and presented...|$|R
