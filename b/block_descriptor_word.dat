0|146|Public
3000|$|Therefore, {{the final}} <b>block</b> <b>descriptor</b> is a 128 (or any other number that is chosen)-element vector, and it {{corresponds}} to the X (L [...]...|$|R
30|$|The rest of {{the article}} is {{organized}} as follows: Section 2 describes the block detection method while Section 3 explains {{the creation of the}} <b>block</b> <b>descriptor</b> using a novel algorithm called SDASE. Section 4 presents the SVM and the algorithm to train them. Section 5 contains the evaluation and the experimental results of the text-extraction technique, and finally, the conclusions are drawn in Section 6.|$|R
50|$|Gender is denoted in two ways. Prefixes can {{be added}} to {{indicate}} gender of living creatures, or distinct words are used for female and male counterparts. Plurals are marked on animate nouns by adding plural suffixes. Plurals can be noted on inanimate nouns by using a <b>descriptor</b> <b>word</b> to provide details about the noun, but cannot themselves be changed to represent pluralization.|$|R
40|$|ESM system {{consists}} of antenna head unit, receiver processor and display system the parameters measured instantaneously for tactical purposes. Receiver measures all parameters {{pulse by pulse}} and provides the data in digital form. Parameters are organized in pulse <b>descriptor</b> <b>words</b> (PDW). PDW is to be generated in PD Generator. pd generator pulse width, pulse repetition frequency, signal strength, antenna scan period, direction of arrival and all these parameters are organized in 128 bit format...|$|R
40|$|The Translate Address {{diagnostic}} pages use {{the defect}} list formats {{defined in the}} FORMAT UNIT command. However, they don’t always use them for “defects ”- non-defective addresses can be translated. The definitions of the defect descriptors are unclear, particularly the <b>block</b> <b>descriptors,</b> and were broken even more during an SBC- 2 editing session. Although possibly corrected in sbc 2 r 14, the wording still needs careful review. SCSI- 2 wording FORMAT UNIT: Each <b>block</b> format defect <b>descriptor</b> (see table 113) specifies a four-byte defective block address that contains the defect. READ DEFECT DATA: NOTE 1 - NOTE 110 The use of the block format is not recommended. There is no universal model that sensibly defines {{the meaning of the}} logical block address of a defect. In the usual case, a defect that has been reassigned no longer has a logical <b>block</b> address. Defect <b>descriptors</b> returned in the block format are vendor-specific. SBC- 1 wording...|$|R
30|$|This article {{proposes a}} new {{bottom-up}} method which detects and extracts homogeneous text in document images indifferent to font types and size by using connected components {{analysis for the}} object detection, document structure elements (DSE) to construct a descriptor and SVM to tag the appropriate objects as text. The proposed technique {{has the ability to}} adapt to the peculiarities of each document images database since the features are adjustable. It provides also the ability to increase or decrease text localization speed by the manipulation of the <b>block</b> <b>descriptor</b> length. A preliminary version of this work has been presented in [23].|$|R
40|$|Instruction {{delivery}} {{is a critical}} component for wide-issue, high-frequency processors since its bandwidth and accuracy place an upper limit on performance. The processor front-end accuracy and bandwidth are limited by instruction-cache misses, multicycle instruction-cache accesses, and target or direction mispredictions for control-flow operations. This paper presents a block-aware instruction set (BLISS) that allows software to assist with front-end challenges. BLISS defines basic <b>block</b> <b>descriptors</b> that are stored separately from the actual instructions in a program. We show that BLISS allows for a decoupled front-end that tolerates instruction-cache latency, facilitates instruction prefetching, and leads to higher prediction accuracy...|$|R
40|$|Code {{size and}} energy {{consumption}} are critical design concerns for embedded processors as they determine {{the cost of}} the overall system. Techniques such as reduced length instruction sets lead to significant code size savings but also introduce performance and energy consumption impediments such as additional dynamic instructions or decompression latency. In this paper, we show that a blockaware instruction set (BLISS) which stores basic <b>block</b> <b>descriptors</b> in addition to and separately from the actual instructions in the program allows embedded processors to achieve significant improvements in all three metrics: reduced code size and improved performance and lower energy consumption. ...|$|R
5000|$|In ARMv6, a new page {{table entry}} format was introduced; it {{includes}} an [...] "execute never" [...] bit. For ARMv8-A, VMSAv8-64 <b>block</b> and page <b>descriptors,</b> and VMSAv8-32 long-descriptor <b>block</b> and page <b>descriptors,</b> for stage 1 translations have [...] "execute never" [...] bits for both privileged and unprivileged modes and <b>block</b> and page <b>descriptors</b> for page 2 translations {{have a single}} [...] "execute never" [...] bit; VMSAv8-32 short-descriptor translation table descriptors at level 1 have [...] "execute never" [...] bits for both privileged and unprivileged mode and at level 2 have a single [...] "execute never" [...] bit.|$|R
50|$|Each block group {{contains}} {{a copy of}} the superblock and <b>block</b> group <b>descriptor</b> table, and all block groups contain a block bitmap, an inode bitmap, an inode table, and finally the actual data blocks.|$|R
40|$|Abstract. This work {{presents}} a neural network for the retrieval of images from text queries. The proposed network {{is composed of}} two main modules: the first one extracts a global picture representation from local <b>block</b> <b>descriptors</b> while the second one aims at solving the retrieval problem from the extracted representation. Both modules are trained jointly to minimize a loss related to the retrieval performance. This approach is shown to be advantageous when compared to previous models relying on unsupervised feature extraction: average precision over Corel queries reaches 26. 2 % for our model, which should be compared to 21. 6 % for PAMIR, the best alternative. ...|$|R
40|$|The {{front-end}} in superscalar processors must deliver high application {{performance in}} an energy-effective manner. Impediments such as multi-cycle instruction accesses, instruction-cache misses, and mispredictions reduce performance by 48 % and increase energy consumption by 21 %. This paper presents a block-aware instruction set architecture (BLISS) that defines basic <b>block</b> <b>descriptors</b> {{in addition to}} the actual instructions in a program. BLISS allows for a decoupled front-end that reduces the time and energy spent on misspeculated instructions. It also allows for accurate instruction prefetching and energy efficient instruction access. A BLISS-based front-end leads to 14 % IPC, 16 % total energy, and 83 % energydelay-squared product improvements for wide-issue processors...|$|R
5000|$|Model Futures OWL Editor (Free) Able to {{work with}} very large OWL files (e.g. Cyc) and has {{extensive}} import and export capabilities (inc. UML, Thesaurus <b>Descriptor,</b> MS <b>Word,</b> CA ERwin Data Modeler, CSV, etc.) ...|$|R
3000|$|... e). In {{order to}} achieve a better {{invariance}} to noise, it is also useful to contrast-normalize the local responses before using them. This {{can be done by}} accumulating a measurement of local histogram energy over larger spatial regions, named blocks, and using the results to normalize all of the cells in the <b>block.</b> The normalized <b>descriptor</b> <b>blocks</b> will represent the HOG descriptor.|$|R
40|$|Eighty {{patients}} with a diagnosis of either rheumatoid arthritis, localised osteoarthritis, or generalised osteoarthritis {{were asked to describe}} their pain by selecting words from a standardised list of pain <b>descriptors.</b> <b>Words</b> on this list were taken from the sensory class of pain descriptors found in the McGill pain questionnaire. Discriminant analysis was used to identify distinctive characteristics for each of these pain syndromes. On the basis of this analysis verbal responses for each patient were classified into one of the three diagnostic categories. Correct classification occurred in 65 % of cases. An estimate of the technique's performance in prospective validation was derived by a split sample approach...|$|R
40|$|We propose {{an action}} {{classification}} algorithm which uses Locality-constrained Linear Coding (LLC) to capture discriminative information of human body variations in each spatio-temporal subsequence {{of a video}} sequence. Our proposed method divides the input video into equally spaced overlapping spatio-temporal subsequences, {{each of which is}} decomposed into blocks and then cells. We use the Histogram of Oriented Gradient (HOG 3 D) feature to encode the information in each cell. We justify the use of LLC for encoding the <b>block</b> <b>descriptor</b> by demonstrating its superiority over Sparse Coding (SC). Our sequence de-scriptor is obtained via a logistic regression classifier with L 2 regularization. We evaluate and compare our algorithm with ten state-of-the-art algorithms on five benchmar...|$|R
40|$|ESM (Electronics support measure) systems {{intercept}} radar emissions {{which are}} within the operating frequency range of the system. ESM System consists of Antennas, Front End Receiver, Receiver subsystem, Processor subsystem and Display subsystem. Antennas intercepts the RF signals which are given to Front end receiver. The Front End Receiver gives amplified RF and detected video outputs. Amplified RF output is given to DIFM unit which measures the frequency. Video output of Front End Receiver {{is connected to the}} receiver subsystem. The receiver subsystem measures the parameters such as Pulse width, Pulse repetition frequency and Amplitude of the on pulse by pulse basis. It also timestamps the received signal by generating the time of arrival(TOA) parameter. The measured frequency from DIFM Receiver is also routed to receiver subsystem. The above mentioned measured parameters are interleaved into 128 bit <b>word</b> called Pulse <b>descriptor</b> <b>word</b> (PDW). This project Pulse <b>Descriptor</b> <b>Word</b> Simulator aims at developing a simulator which can be used to test the processor in the absence of Receiver hardware. This simulates the 128 bit PD Word along with the required control signals which will be generated by the receiver card ESM Processor. The 128 bit PD Word is organized as four 32 bit words. Two address bits are used to indicate the word address. A strobe is to be provided to indicate the presence of each word. The simulator is being planned to be developed using Xilinx ISE 10. 1 and the simulated results are to be demonstrated on modelsim simulator...|$|R
5000|$|To retrieve, {{obtain the}} <b>descriptor</b> <b>block</b> or blocks {{and for each}} {{contained}} set of size , do the following: ...|$|R
40|$|As signal spectra become dense, {{the task}} of {{tracking}} and identifying radars becomes increasingly cumbersome. The variety of radars in modern theaters of war compound the task due to simultaneous operation. Real-time processing of large data sets prove difficult for sequential systems, and the parallelism of Field Programmable Gate Arrays (FPGAs) becomes an attractive option. To mitigate the increasing complexity of this task, this design proposes an FPGA architecture to produce pulse <b>descriptor</b> <b>words</b> (PDW) for up to eight independent radio frequency signals {{that can be used}} in near-real-time processing. Focusing on digital hardware techniques and modular design allow for flexibility to target specific signal aspects such as carrier frequency (F), signal amplitude (A), time of arrival (TOA), and pulse width (PW) ...|$|R
50|$|<b>Descriptors</b> {{describe}} data <b>blocks.</b> Each <b>descriptor</b> {{contains a}} 20-bit address field referencing the data block. Each block has a length which {{is stored in}} the descriptor, also 20 bits. The size of the data is also given, being 4-, 6-, 8- or 48-bit data in a three bit field.|$|R
30|$|In {{order to}} {{evaluate}} the proposed technique, we utilize the Document Image Database from the University of Oulu. First, we provide the correlation of the descriptor length with the success rate of the proposed method and we reach the conclusion that 128 elements is enough {{for the detection of}} the text blocks satisfactory. Moreover, the descriptor length can be increased or decreased accordingly to the computational constrains. In addition to that, we provide the run time of the proposed method with regard to the descriptor length. Then, we add noise to the Document Image Database and calculate the new <b>block</b> <b>descriptor</b> so as to demonstrate its flexibility. The results are very close to the original image documents. Finally, we assessed the efficiency of the SDASE text-extraction algorithm against other text-extraction techniques and it performed better.|$|R
40|$|Abstract. Instruction {{delivery}} {{is a critical}} component for wide-issue processors since its bandwidth and accuracy place an upper limit on performance. The processor front-end accuracy and bandwidth are limited by instruction cache misses, multi-cycle instruction cache accesses, and target or direction mispredictions for control-flow operations. This paper introduces a block-aware ISA (BLISS) that helps accurate instruction delivery by defining basic <b>block</b> <b>descriptors</b> in addition to and separate from the actual instructions in a program. We show that BLISS allows for a decoupled front-end that tolerates cache latency and allows for higher speculation accuracy. This translates to a 20 % IPC and 14 % energy improvements over conventional front-ends. We also demonstrate that a BLISS-based front-end outperforms by 13 % decoupled front-ends that detect fetched blocks dynamically in hardware, without any information from the ISA. ...|$|R
40|$|Abstract—We propose {{an action}} {{classification}} algorithm which uses Locality-constrained Linear Coding (LLC) to capture dis-criminative information of human body variations in each spatio-temporal subsequence {{of a video}} sequence. Our proposed method divides the input video into equally spaced overlapping spatio-temporal subsequences, {{each of which is}} decomposed into blocks and then cells. We use the Histogram of Oriented Gradient (HOG 3 D) feature to encode the information in each cell. We justify the use of LLC for encoding the <b>block</b> <b>descriptor</b> by demonstrating its superiority over Sparse Coding (SC). Our sequence descriptor is obtained via a logistic regression classifier with L 2 regularization. We evaluate and compare our algorithm with ten state-of-the-art algorithms on five benchmark datasets. Experimental results show that, on average, our algorithm gives better accuracy than these ten algorithms. I...|$|R
5000|$|In SCSI {{standards}} for transferring data between computers and peripheral devices, often computer storage, commands are sent in a Command <b>Descriptor</b> <b>Block</b> (CDB).|$|R
30|$|Workplace {{well-being}} (WWB) {{was measured}} using Warr’s (1990) affective well-being scales to assess the affective components of WWB, and the Michigan Organizational Assessment Questionnaire (MOAQ; Cammann et al. 1979) to measure the cognitive component of WWB. Warr’s affective well-being scales contain 12 <b>descriptor</b> <b>words</b> that measure both positive affect (PA; 6 items) and negative affect (NA; 6 items) across a continuum of emotional arousal (e.g., “cheerful” and “contented” for high and low arousal PA, respectively; “worried” and “depressed” for high and low arousal NA, respectively). Participants indicate {{the frequency with which}} they experience each of the emotions at work on a 6 -point scale (1  = never, 6  = all of the time). In the current sample, internal consistency was high (PA: 6 items, α =  0.94; NA: 6 items, α =  0.92).|$|R
30|$|Depending on the documents, {{there are}} several {{features}} that can be automatically extracted to generate content descriptors. For a document with textual content, text indexing {{can be viewed as}} the extraction of <b>descriptors</b> (<b>words)</b> which are organized in specialized structures for retrieval. The analysis of image or video generates feature representations that will be referred to as low-level descriptors. For example, color analysis generates descriptors such as DominantColor, ColorStructure, and ScalableColor descriptors [18]. Similarly, texture analysis generates descriptors such as HomogeneousTexture and EdgeHistogram [18]. These low-level descriptors consist predominantly of vectorial data. The DominantColor descriptor, for example, consists of an RGB-tuple, and the color histogram descriptors are vectors of 128 or 256 values. The entire set of descriptors {{can be viewed as a}} vectorial space, called feature space, that can have hundreds or thousands of dimensions. Searching in feature spaces requires the use of custom-designed similarity metrics [19] and indexes.|$|R
40|$|American college {{students}} (N= 46) {{were asked to}} assign grades {{to a series of}} words and phrases used in describing college work. The variables of sex. GPA and cognitive/semantic consistency were correlated with 30 <b>descriptor</b> <b>words.</b> The results revealed that the first canonical root was significant. Using regression to explore individual patterns, it was found that all three independent variables of sex, self-reported grade point average, and cognitive/semantic consistency affected the grades thought {{to be associated with the}} descriptors. Males perceived the wood "poor " to be significantly more positive than did females. Higher grade point averages led to a more positive evaluation of the words "graduate quality. " Finally, "poor, " "outstanding, " and "passing " were all more favorably rated by those who exhibited greater cognitive/semantic consistency. What is abundantly clear from these data is that the words used to describe achievement in a college classroom are subjec...|$|R
50|$|As for the results, the C-HOG and R-HOG <b>block</b> <b>{{descriptors}}</b> perform comparably, {{with the}} C-HOG descriptors maintaining a slight {{advantage in the}} detection miss rate at fixed false positive rates across both data sets. On the MIT set, the C-HOG and R-HOG descriptors produced a detection miss rate of essentially zero at a 10&minus;4 false positive rate. On the INRIA set, the C-HOG and R-HOG descriptors produced a detection miss rate of roughly 0.1 at a 10&minus;4 false positive rate. The generalized Haar wavelets represent the next highest performing approach: they produced roughly a 0.01 miss rate at a 10&minus;4 false positive rate on the MIT set, and roughly a 0.3 miss rate on the INRIA set. The PCA-SIFT descriptors and shape context descriptors both performed fairly poorly on both data sets. Both methods produced a miss rate of 0.1 at a 10&minus;4 false positive rate on the MIT set and nearly a miss rate of 0.5 at a 10&minus;4 false positive rate on the INRIA set.|$|R
40|$|This {{document}} {{provides a}} text proposal for {{implementation of a}} new Read Diagnostics Parameters ELS as proposed by 13 - 030 v 2. 12 - 208 v 2 was accepted for incorporation in FC-LS- 3 on 08 / 05 / 2013 in Chicago. This document, 13 - 438 v 0, was accepted for incorporation in Austin on 12 / 03 / 13 and replaces document 12 - 208 v 2. This proposal provides corrections and enhancements to 12 - 208 v 2 indicated with change recording. The proposed changes are to: a) Correct {{the size of the}} LESB in the Link Error Status <b>Block</b> <b>descriptor</b> b) Use PN_Port instead of VN_Port when referring to phy type. c) Add “not valid ” indicator in the SFP Diagnostics descriptor for implementations that {{do not have access to}} that information. Note to Editor: Add the following text as a reference under 2. 4 Other Reference...|$|R
40|$|A {{computer}} model of some classes of verbal behaviour is described. The general {{characteristic of the}} classes is that the subjects emit discrete verbal units but not continuous discourse. The concept of a word store {{is defined as a}} stochastic information retrieval system, implemented {{in the form of a}} network of stochastically interacting nodes. The word store is assumed to be a parallel processor which operates in conjunction with a serial processor in the human organism. The application of the model to word association, response sequences, learning processes, and satiation effects is discussed. The main data structure and functions of the computer program are described with some examples given in the POP- 2 programming language. It is shown that the word store model fits qualitatively many of the phenomena in verbal behaviour, and an example of a quantitative comparison is shown. <b>Descriptors</b> <b>Words,</b> memory organisation, retrieval, association, verbal behaviour, {{computer model}}, stochastic, network...|$|R
40|$|Patients with {{mucopolysaccharidosis}} (MPS), and Morquio A syndrome (MPS IVA) in particular, often report substantial pain burden. MOR- 008 was a randomized, double-blind, {{pilot study}} assessing {{the safety and}} efficacy, including impact on patient-reported pain, of 52 weeks of treatment with elosulfase alfa (at a dose of 2. 0 or 4. 0 mg/kg/week) in patients with Morquio A syndrome (≥ 7 years old). Assessment of pain at baseline revealed that patients (N = 25) had a mean number of pain locations of 5. 7, mean pain intensity score of 4. 6 (indicative of medium pain), and a mean number of selected pain descriptors of 7. 4 words. Treatment with elosulfase alfa improved subjective pain score (reduced to 3. 2), pain locations (reduced by a mean of 1 location), and pain <b>descriptor</b> <b>words</b> (reduced to 4. 9 words) over 1 year (52 weeks), suggesting that elosulfase alfa can reduce pain in some patients with Morquio A...|$|R
40|$|Many modern {{programming}} environments use tag bits at runtime {{to distinguish}} objects of different types. This is particularly common in systems with garbage collection, since the garbage collector {{must be able}} to distinguish pointers from non-pointers, and to learn the length of records pointed to. The use of tag bits leads to inefficiency. In addition to the obvious space overhead (tag bits and record descriptors occupy memory space), there is a time overhead: tag bits must be stripped off of data before arithmetic operations are performed, and re-attached to the data when it is stored into memory. This takes either extra instructions at runtime, or special tag-handling hardware, or both. This paper shows how the use of tag bits, record <b>descriptor</b> <b>words,</b> explicit type parameters, and the like can be avoided in languages (like ML) with static polymorphic typechecking. Though a form of tag will still be required for user-defined variant records, all other type information [...] ...|$|R
5000|$|Regardless of organization, the {{physical}} structure of each record {{is essentially the}} same, and is uniform throughout the data set. This is specified in the DCB [...] parameter. [...] means that the records are of fixed length, specified via the [...] parameter, and [...] specifies a variable-length record. V records when stored on media are prefixed by a Record <b>Descriptor</b> <b>Word</b> (RDW) containing the integer length of the record in bytes. With [...] and , multiple logical records are grouped together into a single physical block on tape or disk. FB and VB are , and , respectively. The [...] parameter specifies the maximum length of the block. [...] could be also specified, meaning , meaning all the blocks except the last one were required to be in full [...] length. , or , means a logical record could be spanned across two or more blocks, with flags in the RDW indicating whether a record segment is continued into the next block and/or was continued from the previous one.|$|R
30|$|The {{histogram}} {{consists of}} evenly spaced orientation bins accumulating the weighted votes of gradient magnitude of each pixel {{belonging to the}} cell. Additionally, the cells are grouped into blocks, and for each block, all cell histograms are normalized. The blocks are overlapping, so the same cell can be differently normalized in several <b>blocks.</b> The <b>descriptor</b> is calculated using all overlapping blocks from the image detection window.|$|R
50|$|Many {{computer}} files have a defined structure such as fixed length records {{with the data}} divided into records that are the same length. Structured data might have records of different lengths but each record is prefixed with a RDW (Record <b>Descriptor</b> <b>Word)</b> that indicates the length of that data {{as well as other}} attributes. JBOB data has no structure. Records are defined by the presence of characters in the data. For example, a report might have hundreds of records (or lines) but the length of each record is defined by the presence of a Carriage Return (and/or Line Feed). Mainframe computers have traditionally dealt with structured data but unstructured (JBOB) data is much more common in PC environments. The critical difference is that it is difficult, if not impossible, to advance to say, the 100th record without examining every character of the 99 records that precede it. With fixed length records, it is possible to calculate the exact position of a particular record. Even with variable length records, the length of each record is given so navigation is easier.|$|R
40|$|Abstract – A {{compressed}} domain color-based image indexing {{method that}} avoids overheads associated with full decompression and color space transformation by {{operating in the}} YCbCr space has been presented. The proposed method performs a hard segmentation of the color space into predefined clusters based on perceptual similarity. A three dimensional color descriptor is generated by extracting the average intensity value of the Y, Cb and Cr components for each 8 X 8 DCT <b>block.</b> Each <b>blocks</b> <b>descriptor</b> is subsequently allocated to its corresponding cluster, whose centroid is updated using a weighted mean. The similarity measure is evaluated using a compact four dimensional feature vector from each cluster, which consists of the quantized centroid co-ordinates and the percentage contribution to the image composition by the cluster. Retrieval is performed by comparing the feature attributes of the clusters having significant membership in the query image, to those with the database images; the obtained matches are then integrated to evaluate the final ranking. The experimental results of the proposed model on a database of 7380 images are reported. Index Terms – Color indexing, compressed domain, content based retrieval, DCT. I...|$|R
