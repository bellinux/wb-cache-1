2983|1|Public
25|$|Various <b>branch-and-bound</b> algorithms, {{which can}} be used to process TSPs {{containing}} 40–60 cities.|$|E
25|$|Great {{progress}} {{was made in the}} late 1970s and 1980, when Grötschel, Padberg, Rinaldi and others managed to exactly solve instances with up to 2392 cities, using cutting planes and <b>branch-and-bound.</b>|$|E
2500|$|Implementations of <b>branch-and-bound</b> and problem-specific cut {{generation}} (branch-and-cut); this is {{the method}} of choice for solving large instances. This approach holds the current record, solving an instance with 85,900 cities, see [...]|$|E
5000|$|... {{forward-backward}} {{greedy search}} and exact methods using <b>branch-and-bound</b> techniques, ...|$|E
50|$|Other {{libraries}} implement search methods like <b>branch-and-bound,</b> repair-based search, limited discrepancy search.|$|E
5000|$|Various <b>branch-and-bound</b> algorithms, {{which can}} be used to process TSPs {{containing}} 40-60 cities.|$|E
5000|$|Branch-and-cut, {{a hybrid}} between <b>branch-and-bound</b> and the cutting plane methods {{that is used}} {{extensively}} for solving integer linear programs.|$|E
50|$|The {{combinatorial}} problems above are, in fact, mixed 0-1 {{linear programming}} {{problems that can}} be solved by using <b>branch-and-bound</b> algorithms.|$|E
5000|$|When f is {{nonlinear}} the set inversion {{problem can}} be solved [...] using interval analysis combined with a <b>branch-and-bound</b> algorithm.|$|E
50|$|Hybrids {{of these}} DCOP {{algorithms}} also exist. BnB-Adopt, for example, changes the search strategy of Adopt from best-first search to depth-first <b>branch-and-bound</b> search.|$|E
5000|$|Combined with a <b>branch-and-bound</b> {{algorithm}} such as SIVIA (Set Inversion Via Interval Analysis), the q-relaxedintersection of m subsets of [...] can be computed.|$|E
50|$|GLPK {{uses the}} revised simplex method and the primal-dual {{interior}} point method for non-integer {{problems and the}} <b>branch-and-bound</b> algorithm together with Gomory's mixed integer cuts for (mixed) integer problems.|$|E
50|$|Great {{progress}} {{was made in the}} late 1970s and 1980, when Grötschel, Padberg, Rinaldi and others managed to exactly solve instances with up to 2392 cities, using cutting planes and <b>branch-and-bound.</b>|$|E
5000|$|Implementations of <b>branch-and-bound</b> and problem-specific cut {{generation}} (branch-and-cut); this is {{the method}} of choice for solving large instances. This approach holds the current record, solving an instance with 85,900 cities, see [...]|$|E
50|$|Super-linear speedups {{can also}} occur in {{parallel}} implementations of <b>branch-and-bound</b> for optimization: {{the processing of}} one node by one processor may affect the work other processors need {{to do for the}} other nodes.|$|E
50|$|In Boolean algebra, Petrick's method (also {{known as}} the <b>branch-and-bound</b> method) is a {{technique}} described by Stanley R. Petrick (1931-2006) in 1956 for determining all minimum sum-of-products solutions from a prime implicant chart. Petrick's method is very tedious for large charts, but {{it is easy to}} implement on a computer.|$|E
5000|$|The {{special case}} of {{optimizing}} egalitarian welfare with additive utilities is called [...] "the Santa Claus problem". [...] The problem is still NP-hard and cannot be approximated within a factor > 1/2, {{but there is}} an [...] approximation and a more complicated [...] approximation.See also [...] for a <b>branch-and-bound</b> algorithm for two partners.|$|E
5000|$|This method runs a <b>branch-and-bound</b> {{algorithm}} on [...] problems, where [...] is {{the number}} of variables. Each such problem is the subproblem obtained by dropping a sequence of variables [...] from the original problem, along with the constraints containing them. After the problem on variables [...] is solved, its optimal cost can be used as an upper bound while solving the other problems, ...|$|E
50|$|DCOP {{algorithms}} can {{be classified}} according to the search strategy (best-first search or depth-first <b>branch-and-bound</b> search), the synchronization among agents (synchronous or asynchronous), the communication among agents (point-to-point with neighbors in the constraint graph or broadcast) and the main communication topology (chain or tree).ADOPT, for example, uses best-first search, asynchronous synchronization, point-to-point communication between neighboring agents in the constraint graph and a constraint tree as main communication topology.|$|E
50|$|For example, {{a linear}} {{programming}} relaxation of an integer programming problem removes the integrality constraint and so allows non-integer rational solutions. A Lagrangian relaxation of a complicated problem in combinatorial optimization penalizes violations of some constraints, allowing an easier relaxed {{problem to be}} solved. Relaxation techniques complement or supplement branch and bound algorithms of combinatorial optimization; linear programming and Lagrangian relaxations are used to obtain bounds in <b>branch-and-bound</b> algorithms for integer programming.|$|E
5000|$|Greedy {{algorithms}} can {{be characterized}} as being 'short sighted', and also as 'non-recoverable'. They are ideal only for problems which have 'optimal substructure'. Despite this, for many simple problems (e.g. giving change), the best suited algorithms are greedy algorithms. It is important, however, to note that the greedy algorithm {{can be used as a}} selection algorithm to prioritize options within a search, or <b>branch-and-bound</b> algorithm. There are a few variations to the greedy algorithm: ...|$|E
5000|$|This {{algorithm}} {{introduces a}} tree {{structure for the}} motif candidates and uses a <b>branch-and-bound</b> algorithm to reduce the search space. Let S = {s1, s2, …, sn} be a given set of input strings.PMSprune follows the same strategy as PMS0: For every l-mer y in s1, it generates the set of neighbors of y and, for each of them, checks {{whether this is a}} motif or not. Some key steps in the algorithm are: ...|$|E
50|$|The GK {{algorithm}} {{discovers the}} {{whole set of}} mappings of a given query graph to the network in two major steps. It starts with the computation of symmetry-breaking conditions of the query graph. Next, {{by means of a}} <b>branch-and-bound</b> method, the algorithm tries to find every possible mapping from the query graph to the network that meets the associated symmetry-breaking conditions. An example of the usage of symmetry-breaking conditions in GK algorithm is demonstrated in figure.|$|E
5000|$|Couenne is an {{implementation}} of a <b>branch-and-bound</b> where every subproblem is solved by constructing a linear programming relaxation to obtain a lower bound. Branching may occur at both continuous and integer variables, which is necessary in global optimization problems. It requires the input to be specified in A Mathematical Programming Language (AMPL) [...]nl format, {{so as to be}} used from AMPL, and writes as an output a file [...]sol containing the best solution found until that moment (if the optimization is interrupted) or the global optimum if it completes without interruption.|$|E
5000|$|<b>Branch-and-bound</b> {{may also}} be a base of various heuristics. For example, one may wish to stop {{branching}} when the gap between the upper and lower bounds becomes smaller than a certain threshold. This is used when the solution is [...] "good enough for practical purposes" [...] and can greatly reduce the computations required. This type of solution is particularly applicable when the cost function used is noisy or is the result of statistical estimates and so is not known precisely but rather only known to lie within a range of values with a specific probability.|$|E
5000|$|The {{goal of a}} <b>branch-and-bound</b> {{algorithm}} {{is to find a}} value [...] that maximizes or minimizes the value of a real-valued function , called an objective function, among some set [...] of admissible, or candidate solutions. The set [...] is called the search space, or feasible region. The rest of this section assumes that minimization of [...] is desired; this assumption comes without loss of generality, since one can find the maximum value of [...] by finding the minimum of [...] A B&B algorithm operates according to two principles: ...|$|E
5000|$|Feature {{selection}} algorithms {{attempt to}} directly prune out redundant or irrelevant features. A general introduction to feature selection which summarizes approaches and challenges, has been given. The complexity of feature-selection is, {{because of its}} non-monotonous character, an optimization problem where given a total of [...] features the powerset consisting of all [...] subsets of features need to be explored. The <b>Branch-and-Bound</b> algorithm does reduce this complexity but is intractable for medium to large values {{of the number of}} available features [...] For a large-scale comparison of feature-selection algorithms see [...]|$|E
50|$|Mallba is {{a library}} for {{combinatorial}} optimizations supporting exact, heuristic and hybrid search strategies. Each strategy is implemented in Mallba as a generic skeleton {{which can be}} used by providing the required code. On the exact search algorithms Mallba provides <b>branch-and-bound</b> and dynamic-optimization skeletons. For local search heuristics Mallba supports: hill climbing, metropolis, simulated annealing, and tabu search; and also population based heuristics derived from evolutionary algorithms such as genetic algorithms, evolution strategy, and others (CHC). The hybrid skeletons combine strategies, such as: GASA, a mixture of genetic algorithm andsimulated annealing, and CHCCES which combines CHC and ES.|$|E
50|$|Branch {{and bound}} (BB or B&B) is an {{algorithm}} design paradigm for discrete and combinatorial optimization problems. A <b>branch-and-bound</b> algorithm {{consists of a}} systematic enumeration of candidate solutions by means of state space search: the set of candidate solutions is thought of as forming a rooted tree with the full set at the root. The algorithm explores branches of this tree, which represent subsets of the solution set. Before enumerating the candidate solutions of a branch, the branch is checked against upper and lower estimated bounds on the optimal solution, and is discarded if it cannot produce a better solution than the best one found so far by the algorithm.|$|E
50|$|SLD {{resolution}} is non-deterministic {{in the sense}} that it does not determine the search strategy for exploring the search tree. Prolog searches the tree depth-first, one branch at a time, using backtracking when it encounters a failure node. Depth-first search is very efficient in its use of computing resources, but is incomplete if the search space contains infinite branches and the search strategy searches these in preference to finite branches: the computation does not terminate. Other search strategies, including breadth-first, best-first, and <b>branch-and-bound</b> search are also possible. Moreover, the search can be carried out sequentially, one node at a time, or in parallel, many nodes simultaneously.|$|E
50|$|Branch {{and bound}} (BB, B&B, or BnB) is an {{algorithm}} design paradigm for discrete and combinatorial optimization problems, {{as well as}} mathematical optimization. A <b>branch-and-bound</b> algorithm consists of a systematic enumeration of candidate solutions by means of state space search: the set of candidate solutions is thought of as forming a rooted tree with the full set at the root. The algorithm explores branches of this tree, which represent subsets of the solution set. Before enumerating the candidate solutions of a branch, the branch is checked against upper and lower estimated bounds on the optimal solution, and is discarded if it cannot produce a better solution than the best one found so far by the algorithm.|$|E
50|$|In {{addition}} to being an accomplished athlete, Johnson is well respected {{in the field of}} operations management. After receiving his PhD from the Graduate School of Management at UCLA in 1973, Johnson joined the faculty of the University of Otago in New Zealand, and was promoted to the dean of commerce from 1976 to 1979. In 1980, Johnson went on to be an associate professor at the UCLA Anderson School of Business, and an associate professor of operations management at the University of Michigan School of Business Administration. His research interests include assembly-line balancing and management, project management, <b>branch-and-bound</b> methods, facility layout, and flexible manufacturing systems. Johnson's work has been published in Management Science, Decision Sciences, and the International Journal of Production Research.|$|E
5000|$|Maximum parsimony is an {{intuitive}} and simple criterion, {{and it is}} popular for this reason. However, although {{it is easy to}} score a phylogenetic tree (by counting the number of character-state changes), there is no algorithm to quickly generate the most-parsimonious tree. Instead, the most-parsimonious tree must be found in [...] "tree space" [...] (i.e., amongst all possible trees). For a small number of taxa (i.e., fewer than nine) it is possible to do an exhaustive search, in which every possible tree is scored, and the best one is selected. For nine to twenty taxa, it will generally be preferable to use <b>branch-and-bound,</b> which is also guaranteed to return the best tree. For greater numbers of taxa, a heuristic search must be performed.|$|E
50|$|Cutting {{planes were}} {{proposed}} by Ralph Gomory in the 1950s {{as a method}} for solving integer programming and mixed-integer programming problems. However most experts, including Gomory himself, considered them to be impractical due to numerical instability, as well as ineffective because many rounds of cuts were needed to make progress towards the solution. Things turned around when in the mid-1990s Gérard Cornuéjols and co-workers showed them to be very effective in combination with <b>branch-and-bound</b> (called branch-and-cut) and ways to overcome numerical instabilities. Nowadays, all commercial MILP solvers use Gomory cuts {{in one way or}} another. Gomory cuts are very efficiently generated from a simplex tableau, whereas many other types of cuts are either expensive or even NP-hard to separate. Among other general cuts for MILP, most notably lift-and-project dominates Gomory cuts.|$|E
50|$|Quadknap is {{an exact}} <b>branch-and-bound</b> {{algorithm}} raised by Caprara et al., where upper bounds are computed by considering a Lagrangian relaxation which approximate a difficult problem by a simpler problem and penalizes violations of constraints using Lagrange multiplier to impost a cost on violations. Quadknap releases the integer requirement when computing the upper bounds. Suboptimal Lagrangian multipliers {{are derived from}} sub-gradient optimization and provide a convenient reformulation of the problem. This algorithm is quite efficient since Lagrangian multipliers are stable, and suitable data structures are adopted to compute a tight upper bound in linear expected time {{in the number of}} variables. This algorithm was reported to generate exact solutions of instances with up to 400 binary variables, i.e., significantly larger than those solvable by other approaches. The code was written C language and available online.|$|E
3000|$|Novel {{formulations}} using <b>branch-and-bound.</b> Based on the pick-l algorithm, {{we propose}} a <b>branch-and-bound</b> tree search approach to compute tighter bounds {{or even the}} exact value of α [...]...|$|E
