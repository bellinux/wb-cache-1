179|917|Public
25|$|If both {{endpoints}} are unknown, {{then the}} sample range is a <b>biased</b> <b>estimator</b> {{for the population}} range, but correcting as for maximum above yields the UMVU estimator.|$|E
2500|$|However, we {{can achieve}} a lower mean squared error using a <b>biased</b> <b>{{estimator}}.</b> The estimator ...|$|E
2500|$|In other words, [...] is an {{unbiased}} estimator {{of the first}} moment. If {{we assume that the}} mean [...] lies in the interval , then Arg will be a (<b>biased)</b> <b>estimator</b> of the mean [...]|$|E
40|$|Some <b>biased</b> <b>estimators</b> {{have been}} {{suggested}} {{as a means of}} improving the accuracy of parameter estimates in a regression model when multicollinearity exists. The rationale for using <b>biased</b> <b>estimators</b> instead of unbiased estimators when multicollinearity exists is given in this paper. A summary for a list of <b>biased</b> <b>estimators</b> is also given in this paper...|$|R
5000|$|... #Subtitle level 3: Bound on the {{variance}} of <b>biased</b> <b>estimators</b> ...|$|R
5000|$|... the MVUE {{minimizes}} MSE among unbiased estimators. In {{some cases}} <b>biased</b> <b>estimators</b> have lower MSE {{because they have}} a smaller variance than does any unbiased estimator; see <b>estimator</b> <b>bias.</b>|$|R
2500|$|Given a sub-set {{of samples}} from a population, the sample excess {{kurtosis}} above is a <b>biased</b> <b>estimator</b> {{of the population}} excess kurtosis. An alternative estimator of the population excess kurtosis is defined as follows: ...|$|E
2500|$|It's trivial {{to have a}} small {{variance}} − an [...] "estimator" [...] that {{is constant}} has a variance of zero. But from the above equation {{we find that the}} mean squared error of a <b>biased</b> <b>estimator</b> is bounded by ...|$|E
2500|$|If {{only the}} top {{endpoint}} is unknown, the sample maximum is a <b>biased</b> <b>estimator</b> for the population maximum, but the unbiased estimator [...] (where m is the sample maximum and k is the sample size) is the UMVU estimator; see German tank problem for details.|$|E
40|$|The {{transformation}} kernel density estimator of Ruppert and Cline (1994) achieves bias {{of order}} h 4 (as the bandwidth h→ 0), {{an improvement over}} the order h 2 bias associated with the basic kernel density estimator. Hössjer and Ruppert (1994) use Taylor series expansions to build {{a bridge between the}} two, displaying an infinite sequence of O(h 4) <b>bias</b> <b>estimators</b> in the process. In this paper, we extend the work of Hössjer and Ruppert (i) by investigating three other natural Taylor series expansions, and (ii) by applying the approach to two other O(h 4) <b>bias</b> <b>estimators,</b> namely the variable bandwidth and multiplicative bias correction methods. Several further infinite sequences of O(h 4) <b>bias</b> <b>estimators</b> result...|$|R
40|$|Abstract in 1964 Nagar and Kakwani {{analysis}} {{the results}} of the first and second moment that proposed by Theil and Goldberger 1961 derive the <b>bias</b> <b>estimators</b> and second moment matrix of mixed model estimators consider with the order of magnitude criteria derived <b>biased</b> <b>estimators</b> to order that refer to big O in probability where begin the number of observations. In this paper we derive mixed seemingly unrelated regression equations SURE by combining the prior information and sample information in a single model derive the <b>bias</b> <b>estimator</b> to order and the moment matrix to order by using the methodology of Nagars expansion for the moment of <b>estimator.</b> the <b>bias</b> has been derived conceder the normality distribution assumption of the random disturbances...|$|R
25|$|The Cramér–Rao bound {{can also}} be used to bound the {{variance}} of <b>biased</b> <b>estimators</b> of given <b>bias.</b> In some cases, a biased approach can result in both a variance and a mean squared error that are below the unbiased Cramér–Rao lower bound; see <b>estimator</b> <b>bias.</b>|$|R
2500|$|The James–Stein {{estimator}} is a <b>biased</b> <b>estimator</b> of {{the mean}} of Gaussian random vectors. It can be shown that the James–Stein estimator dominates the [...] "ordinary" [...] least squares approach, i.e., it has lower mean squared error. It is the best-known example of Stein's phenomenon.|$|E
2500|$|... {{will be an}} {{unbiased}} estimator of [...] and solving the equation [...] for [...] will yield a (<b>biased)</b> <b>estimator</b> of [...] In analogy to the linear case, {{the solution to the}} equation [...] will yield the maximum likelihood estimate of [...] and both will be equal in the limit of large N. For approximate solution to [...] refer to von Mises–Fisher distribution.|$|E
2500|$|As {{explained}} above, while s2 is an {{unbiased estimator}} {{for the population}} variance, s is still a <b>biased</b> <b>estimator</b> for the population standard deviation, though markedly less biased than the uncorrected sample standard deviation. This estimator is commonly used and generally known simply as the [...] "sample standard deviation". The bias may still be large for small samples (N less than 10). As sample size increases, the amount of bias decreases. We obtain more information {{and the difference between}} [...] and [...] becomes smaller.|$|E
40|$|The {{problem of}} {{accommodating}} unknown sensor bias is considered {{in a direct}} model reference adaptive control (MRAC) setting for state tracking using state feedback. Sensor faults can occur during operation, and if the biased state measurements are directly used with a standard MRAC control law, neither closed-loop signal boundedness, nor asymptotic tracking can be guaranteed and the resulting tracking errors may be unbounded or unacceptably large. A modified MRAC law is proposed, which combines a <b>bias</b> <b>estimator</b> with control gain adaptation, and it is shown that signal boundedness can be accomplished, although the tracking error may not go to zero. Further, for the case wherein an asymptotically stable sensor <b>bias</b> <b>estimator</b> is available, an MRAC control law is proposed to accomplish asymptotic tracking and signal boundedness. Such a sensor <b>bias</b> <b>estimator</b> can be designed if additional sensor measurements are available, as illustrated for the case wherein bias {{is present in the}} rate gyro and airspeed measurements. Numerical example results are presented to illustrate each of the schemes...|$|R
40|$|Metode Jackknife dapat digunakan untuk mereduksi <b>bias</b> suatu <b>{{estimator}}.</b> Untuk mengetahui keefektifan dari estimator Jackknife order satu dan estimator Jackknife order dua sebagai pereduksi bias dapat dilihat dari sifat-sifatnya. Ciri-ciri <b>bias</b> <b>estimator</b> terfetak pada suku-suku <b>bias</b> dari <b>estimator</b> yang asli. Kemudian bias dari Jackknife order dua dibandingkan dengan <b>bias</b> <b>estimator</b> yang asli dan juga dibandingkan dengan bias Jackknife order satu. Dari perbandingan ini dapat dilihat untuk keadaan tertentu Jackknife order dua lebih efektif daripada Jackknife order satu maupun terhadap estimator aslinya. Jackknife method {{can be used}} to bias reduction. To {{investigates the}} effectiveness of the first and second order Jackknife estimators,as tools for bias reduction, we must look from the characterized. The <b>biases</b> of <b>estimators</b> are characterized in terms of the <b>bias</b> original <b>estimator.</b> Then <b>biases</b> of the two <b>estimators</b> are compared, <b>biases</b> second order Jackknife are compared with biases first order Jackknife and biases second order Jackknife compared with bias of the original estimator. From this comparison we can see that second order Jackknife more effectif than first order Jackknife or the original estimator. L. This document is Undip Institutional Repository Collection. The author(s) or copyright owner(s) agree that UNDIP-IR may, without changing the content, translate the submission to any medium or kormat for the purpose of preservation. The author(s) or copyright owner(s) also agree that UNDIP-IR may keep more than one copy of this submission for purpose of security, back-up and preservation: ([URL]) ...|$|R
40|$|Abstract—The problem {{considered}} {{in this letter}} is to bound the performance of estimators of a deterministic parameter which satisfies given constraints. Specifically, previous work on the constrained Cramér–Rao bound (CRB) is generalized to include singular Fisher information matrices and <b>biased</b> <b>estimators.</b> A necessary and sufficient condition {{for the existence of}} a finite CRB is obtained. A closed form for an estimator achieving the CRB, if one exists, is also provided, as well as a necessary and sufficient condition for the existence of such an estimator. It is shown that <b>biased</b> <b>estimators</b> achieving the CRB can be constructed in situations for which no unbiased technique exists. Index Terms—Constrained estimation, Cramér–Rao bound, pa-rameter estimation...|$|R
2500|$|The {{difference}} between s2 and [...] becomes negligibly small for large ns. In finite samples however, the motivation behind {{the use of}} s2 {{is that it is}} an unbiased estimator of the underlying parameter σ2, whereas [...] is biased. Also, by the Lehmann–Scheffé theorem the estimator s2 is uniformly minimum variance unbiased (UMVU), which makes it the [...] "best" [...] estimator among all unbiased ones. However it can be shown that the <b>biased</b> <b>estimator</b> [...] is [...] "better" [...] than the s2 in terms of the mean squared error (MSE) criterion. In finite samples both s2 and [...] have scaled chi-squared distribution with [...] degrees of freedom: ...|$|E
2500|$|This is a {{consistent}} estimator (it converges in probability {{to the population}} value {{as the number of}} samples goes to infinity), and is the maximum-likelihood estimate when the population is normally distributed. However, this is a <b>biased</b> <b>estimator,</b> as the estimates are generally too low. The bias decreases as sample size grows, dropping off as 1/N, and thus is most significant for small or moderate sample sizes; for [...] the bias is below 1%. Thus for very large sample sizes, the uncorrected sample standard deviation is generally acceptable. This estimator also has a uniformly smaller mean squared error than the corrected sample standard deviation.|$|E
50|$|All else being equal, an {{unbiased}} estimator {{is preferable to}} a <b>biased</b> <b>estimator,</b> but in practice all else is not equal, and biased estimators are frequently used, generally with small bias. When a <b>biased</b> <b>estimator</b> is used, bounds of the bias are calculated. A <b>biased</b> <b>estimator</b> {{may be used for}} various reasons: because an {{unbiased estimator}} does not exist without further assumptions about a population or is difficult to compute (as in unbiased estimation of standard deviation); because an estimator is median-unbiased but not mean-unbiased (or the reverse); because a <b>biased</b> <b>estimator</b> reduces some loss function (particularly mean squared error) compared with unbiased estimators (notably in shrinkage estimators); or because in some cases being unbiased is too strong a condition, and the only unbiased estimators are not useful. Further, mean-unbiasedness is not preserved under non-linear transformations, though median-unbiasedness is (see effect of transformations); for example, the sample variance is an unbiased estimator for the population variance, but its square root, the sample standard deviation, is a <b>biased</b> <b>estimator</b> for the population standard deviation. These are all illustrated below.|$|E
40|$|In July, 2005 Deep Impact {{successfully}} impacted comet Tempel- 1 and imaged {{the crater}} evolution. To achieve this, an onboard autonomous navigation system had {{to estimate the}} trajectory and maneuver the Impactor spacecraft into the comet's path. A similar system, operating on the Flyby spacecraft, calculated the impact location for imaging. At the heart of each autonomous navigation system is the attitude and gyro <b>bias</b> <b>estimator</b> using star trackers and gyros. The encounter geometry and timing placed stringent demands on attitude bias magnitude and drift calling for sequenced tuning of the respective filters. This paper describes the attitude and gyro <b>bias</b> <b>estimator</b> algorithms, the estimator flight performance and particular challenges overcome by the team leading up to a spectacular encounter...|$|R
50|$|One {{potential}} problem with count-min sketches {{is that they}} are <b>biased</b> <b>estimators</b> of the true frequency of events: they may overestimate, but never underestimate the true count in a point query. At least two suggested improvements to the sketch operations have been proposed to tackle this problem.|$|R
40|$|This paper studies <b>estimators</b> for the <b>bias</b> in {{estimated}} cross-sectional survey item totals due to attrition nonresponse weighting {{within a}} longitudinal survey. Adjustments for between-sample longitudinal nonresponse are made either by adjustment cells or by logistic regression. The <b>bias</b> <b>estimators</b> studied were first proposed by Bailey (2004) {{in connection with}} the Census Bureau’s Survey of Income and Program Participation (SIPP), but are generalized here to include longitudinal survey items, and formulas and estimators for their design-based variances are given in terms of joint inclusion probabilities. In practice, variance estimates for the <b>bias</b> <b>estimators</b> are obtained, in the SIPP setting where PSU samples are drawn as balanced half-sample replicates, using either balanced replication methods or a formula of Ernst, Huggins and Grill (1986). The methods are illustrated using crosssectional item data from the SIPP 1996 panel...|$|R
5000|$|A less <b>biased</b> <b>estimator</b> of the {{variance}} explained in the population is &omega;2 ...|$|E
5000|$|However, we {{can achieve}} a lower mean squared error using a <b>biased</b> <b>{{estimator}}.</b> The estimator ...|$|E
5000|$|The {{statistic}} [...] is a <b>biased</b> <b>estimator</b> of [...] Under {{independence of}} X and Y ...|$|E
40|$|Nature and {{complexity}} of models • Problems with data–guided model selection • Need for a monotonic model selection process • <b>Biased</b> <b>estimators</b> (shrinkage) • How does one choose a penalty? • Can the data tell us the optimum penalty? • Advantages of penalized estimation • Achieving parsimony by approximating the “best” mode...|$|R
40|$|An {{optimization}} problem {{which provides a}} new characterization for ridge regression is discussed. A variant of this {{optimization problem}} leads to a new family of <b>biased</b> <b>estimators</b> that includes the Stein estimation method and principal components regression as particular cases. The whole approach is illustrated {{on the basis of}} real data sets. ...|$|R
5000|$|The <b>biased</b> {{weighted}} <b>estimator</b> {{of variance}} {{can be shown}} to be: ...|$|R
5000|$|... {{which is}} simply the sample {{covariance}} matrix. This is a <b>biased</b> <b>estimator</b> whose expectation is ...|$|E
5000|$|... {{will be an}} {{unbiased}} estimator of , and [...] will be a (<b>biased)</b> <b>estimator</b> of [...]|$|E
5000|$|... {{will be an}} {{unbiased}} estimator of e&minus;&sigma;2, and ln(1/Re2) will be a (<b>biased)</b> <b>estimator</b> of &sigma;2 ...|$|E
40|$|Brix and {{apparent}} purity {{are well known}} to be <b>biased</b> <b>estimators</b> of dry solids and true purity respectively, particularly on lower purity streams. Correlations which estimate dry solids from brix {{and apparent}} purity and estimate true purity also from brix and apparent purity are presented. The suitability of these correlations is evaluated {{in the light of}} available historical data...|$|R
40|$|This study empirically {{investigated}} bootstrap bias estimation in {{the area}} of structural equation modeling (SEM). Three correctly specified SEM models were used under four different sample size conditions. Monte Carlo experiments were carried out to generate the criteria against which bootstrap bias estimation should be judged. For SEM fit indices, bias estimates from the bootstrap and Monte Carlo experiments were quite comparable in most cases. It is noted that bias was constrained in one direction in the Monte Carlo experiments because of the perfect fit of the true SEM models. For the SEM loadings and coefficients, the difference between bootstrap and Monte Carlo bias estimations was very small, and the distributions of the <b>bias</b> <b>estimators</b> from "the two experiments were quite similar. For the SEM variances/covariances, the comparison of the <b>bias</b> <b>estimator</b> distributions from the two experiments indicated that bootstrap bias estimation could be considered adequate. Because the study involve...|$|R
40|$|We are {{interested}} in the derivation of the distributional properties of a weighted log-excesses estimator of a positive tail index "&ggr;". One of the main objectives of such an estimator is the accommodation of the dominant component of asymptotic bias, together with the maintenance of the asymptotic variance of the maximum likelihood estimator of "&ggr;", under a strict Pareto model. We consider the external estimation not only of a second-order shape parameter "ρ" but also of a second-order scale parameter "&bgr;". This will enable us to reduce the asymptotic variance of the final estimators under consideration, compared with second-order reduced <b>bias</b> <b>estimators</b> that are already available in the literature. The second-order reduced <b>bias</b> <b>estimators</b> that are considered are also studied for finite samples, through Monte Carlo techniques, as well as applied to real data in the field of finance. Copyright 2008 Royal Statistical Society. ...|$|R
