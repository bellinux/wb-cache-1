9|0|Public
50|$|<b>Balisage</b> is also {{an annual}} conference on XML and related markup technologies.|$|E
5000|$|August 2008, xmlsh, an XML {{pipeline}} {{language was}} announced at <b>Balisage</b> 2008 ...|$|E
5000|$|Traitement de l'information -- Systèmes bureautiques -- Langage normalisé de <b>balisage</b> généralisé (SGML) ...|$|E
50|$|<b>Balisage</b> is, most {{commonly}} in military applications, {{the use of}} dim lighting to enable navigation while not giving away one's position to the enemy.|$|E
50|$|Kay is {{the author}} of the book XSLT: Programmer's Reference by Wrox Press and several other books and papers on {{software}} engineering. He lives and works in Reading, England and is a member of the XML Guild and a regular speaker at the XML Summer School in Oxford and <b>Balisage</b> Markup conference.|$|E
40|$|Atlas has title: Memoir {{upon the}} lighting, {{beaconage}} and buoyage of {{the coasts of}} France, by M. Léonce Reynaud [...] . Pub. by order of [...] . M. Armand Béhic, minister of agriculture, commerce, and public works. Plates [...] . Translation of chapters 1 and 2 of part I, and a section of chapter 2 of part II of the author's Mémoire sur l'éclairage et le <b>balisage</b> des côtes de France, 1864. Mode of access: Internet...|$|E
40|$|How can DOE, NNSA, and Y- 12 best {{handle the}} {{integration}} of information from diverse sources, and what will best ensure that legacy data will survive changes in computing systems for the future? Although there is no simple answer, {{it is becoming increasingly}} clear throughout the information-management industry that a key component of both preservation and integration of information is the adoption of standardized data formats. The most notable standardized format is XML, to which almost all data is now migrating. XML is derived from SGML, as is HTML, the common language of the World Wide Web. XML is becoming increasingly important as part of the Y- 12 data infrastructure. Y- 12 is implementing a new generation of XML-based publishing systems. Y- 12 already has been supporting projects at DOE Headquarters, such as the Guidance Streamlining Initiative (GSI) that will result in the storage of classification guidance in XML. Y- 12 collects some test data in XML as the result of Electronic Data Capture (EDC), and XML data is also used in Engineering Releases. I am participating in a series of projects sponsored by the PRIDE initiative that include the capture of dimensional certification and other similar records in XML, the creation of XML formats for Electronic Data Capture, and the creation of Quality Evaluation Reports in XML. In support of DOE&#x 27;s use of SGML, XML, HTML, Topic Maps, and related standards, I served 1985 - 2007 as chairman of the international committee responsible for SGML and standards derived from it, ISO/IEC JTC 1 /SC 34 (SC 34) and its predecessor organizations; I continue to belong to the committee. During the August 2010 trip, I co-chaired the conference <b>Balisage</b> 2010...|$|E
40|$|International audienceThe paper {{provides}} an overview of and an update on the on-going proposal to create a component within the TEI architecture. It elicits the conceptual background of having stand-off annotations embedded within a TEI document and the consequences in terms of primary source preservation, multiple annotation views and possible exporting of annotation content into autonomous TEI documents. It demonstrates the various types of possible use cases ranging from manual annotation to fully automatized information extraction processes and show the importance of implementing, right from the onset, the possibility to use any kind of internal or external vocabulary for representing annotation bodies (e. g. to deal with structural or conceptual annotations). An important prospect here is that the construct could lead to a simplified development of TEI-aware online services such as Named Entity Recognisers. We relate to on-going initiatives and show the necessity to align with the Web Annotation Data Model (W 3 C) {{as well as with the}} recent introduction of the element for speech transcription (as part of the work carried out in the ISO standard 24624) as an elementary annotation crystal in the sense of Romary and Wegstein (2012). In this context we tackle the issue of implicitness in the representation of annotations and open the debate related to the trade-off between having a terse vs. highly flexible model. We end up by illustrating the application that is already made of the current proposal in various projects related to data mining or scientific information, and in particular to the representation of annotated scholarly content. Further materials•Minutes of the January 2014 meeting: [URL] TEI GitHub ticket: [URL] •The standOff proposal on GitHub: [URL] (branch AnnArbor) ReferencesBański Piotr (2010). Why TEI standoff annotation doesn’t quite work: and why you might want to use it nevertheless. In Proceedings of Balisage: The Markup Conference, 2010. Vol. 5 of <b>Balisage</b> Series on Markup Technologies ISO/DIS 24624 Language resource management [...] Transcription of spoken languagePose Javier, Patrice Lopez and Laurent Romary (2014). A Generic Formalism for Encoding Stand-off annotations in TEI. 2014. Romary Laurent (2015). TEI challenges in an accelerating digital world. DiXiT Convention week, Sep 2015, The Hague, Netherlands. 2015,. Romary Laurent and Werner Wegstein (2012), « Consistent Modeling of Heterogeneous Lexical Structures », Journal of the Text Encoding Initiative [Online], Issue 3 | November 2012, Online since 15 October 2012, connection on 12 May 2016. URL : [URL]; DOI : 10. 4000 /jtei. 540 (section about Crystals : [URL] Annotation Data Model, W 3 C, [URL]...|$|E
40|$|The aim of {{this paper}} is to analyse the reasons and the {{consequences}} of the use of a base-witness for the collation, in relation with the major textual scholarship traditions. Using a base-witness means collating each witness against the same one, i. e. the base. We shall focus on collation practices, and in particular on digital collation; three classes of algorithms have been used for this purpose: pairwise alignment, progressive multiple alignment and non-progressive multiple alignment. The results obtained using these different procedures will be shown and compared. In line with recent contributions (among which Sculley and Pasanek; Burdick et al., 101; Pierazzo, 110), this paper argues that the use of digital techniques should come with a critical understanding of the mechanisms informing those techniques, in order to better choose among them and to demystify the feeling of objectivity and truth coming from the result of a computational process; engaging on explicit ground with the digital side of Digital Humanities in general, and digital collation in particular, eventually means recognizing and promoting the interpretative nature of any investigation in the Humanities. Bibliography Andrews, Tara. “Digital Techniques for Critical Edition. ” In Armenian Philology in the Modern Era: From Manuscript to Digital Text, Ed. V. Calzolari and M. E. Stone. Leiden: Brill, 2014. Burdick, Anne, Johanna Drucker, Peter Lunenfeld, Todd Presner, and Jeffrey Schnapp. Digital_Humanities. Cambridge, MA: The MIT Press, 2012. Dekker, Ronald Haentjens, Dirk van Hulle, Gregor Middell, Vincent Neyt, and Joris van Zundert. “Computer-Supported Collation of Modern Manuscripts: CollateX and the Beckett Digital Manuscript Project. ” Digital Scholarship in the Humanities 30, no. 3 (September 1, 2015) : 452 – 70. Dekker, Ronald Haentjens, and Gregor Middell. “Computer-Supported Collation with CollateX”. 2011. Froger, Jacques. La Critique des textes et son automatisation, Dunod 1968. Pierazzo, Elena. Digital Scholarly Editing: Theories, Models and Methods. Ashgate, 2015. Robinson, Peter. “Collate 2, and the design for its successor: CollateXML (now, CollateX) ”, 2007. Schmidt, Desmond Allan. “Merging Multi-Version Texts: A General Solution to the Overlap Problem. ” In Proceedings of Balisage: The Markup Conference 2009, Vol. vol. 3. <b>Balisage</b> Series on Markup Technologies. Montréal, Canada, August 11 - 14, 2009, 2009. Schmidt, Desmond, and Robert Colomb. “A Data Structure for Representing Multi-Version Texts Online. ” Int. J. Hum. -Comput. Stud. 67, no. 6 (June 2009) : 497 – 514. Sculley, D., and Bradley M. Pasanek. ‘Meaning and Mining: The Impact of Implicit Assumptions in Data Mining for the Humanities’. Literary and Linguistic Computing 23, no. 4 (1 December 2008) : 409 – 24. Spencer, Matthew, and Christopher J. Howe. “Collating Texts Using Progressive Multiple Alignment. ” Computers and the Humanities 38, no. 3 (2004) : 253 – 70...|$|E

