103|41|Public
25|$|All three {{cameras were}} CCDs {{manufactured}} by Eastman Kodak Company, and were {{controlled by the}} rover's CPU. They all had auto-exposure and capabilities for handling <b>bad</b> <b>pixels,</b> and the image parameters (exposure time, compression used, etc.) {{were included in the}} transmitted images as part of the image header. The rover could compress the front cameras' images using the block truncation coding (BTC) algorithm, but it could only do the same for the back camera's images if the colour information was discarded. The cameras' optical resolution was sufficient to resolve 0.6cm details across a 0.65m range.|$|E
500|$|On September 29, 2006 (sol [...] ), MRO {{took its}} first high {{resolution}} image from its science orbit. This image {{is said to}} resolve items as small as 90cm (3feet) in diameter. On October 6, NASA released detailed pictures from the MRO of Victoria crater along with the Opportunity rover on the rim above it. In November, problems began to surface {{in the operation of}} two MRO spacecraft instruments. A stepping mechanism in the Mars Climate Sounder (MCS) skipped on multiple occasions resulting in a field of view that is slightly out of position. By December normal operations of the instrument was suspended, although a mitigation strategy allows the instrument to continue making most of its intended observations. Also, an increase in noise and resulting <b>bad</b> <b>pixels</b> has been observed in several CCDs of the High Resolution Imaging Science Experiment (HiRISE). Operation of this camera with a longer warm-up time has alleviated the issue. However, the cause is still unknown and may return.|$|E
50|$|All three {{cameras were}} CCDs {{manufactured}} by Eastman Kodak Company, and were {{controlled by the}} rover's CPU. They all had auto-exposure and capabilities for handling <b>bad</b> <b>pixels,</b> and the image parameters (exposure time, compression used, etc.) {{were included in the}} transmitted images as part of the image header. The rover could compress the front cameras' images using the block truncation coding (BTC) algorithm, but it could only do the same for the back camera's images if the colour information was discarded. The cameras' optical resolution was sufficient to resolve 0.6 cm details across a 0.65 m range.|$|E
40|$|AbstractOne of the {{important}} factors which influence the imaging of IRFPA array is the quantity and distribution of <b>bad</b> <b>pixel.</b> Based on the features of infrared image, response characteristics of IRFAP's <b>bad</b> <b>pixel</b> and the corelation of adjacen cy pixel, this paper put forward a new method to detect <b>bad</b> <b>pixel.</b> The experimental result has proved that this metho d not only can actualize the detection of IRFPA <b>bad</b> <b>pixel,</b> but has many advantages like real time <b>bad</b> <b>pixel</b> detection,low rate of miss detection and fast detection etc. Also this algorithm is easy to be implemented by hardware...|$|R
40|$|Abstract. Infrared {{focal plane}} array (IRFPA) <b>bad</b> <b>pixel</b> {{correction}} as a prevalent problem is widely used in complex conditions. Therefore, scene-based adaptive iteration <b>bad</b> <b>pixel</b> dynamic correction algorithm is proposed and explored. Adaptive filtering <b>bad</b> <b>pixel</b> detection algorithm is to record the intensity of an image and replace {{the intensity of the}} image filtered by a locally acting adaptive filter. Using the intensity of the unfiltered and filtered image to determined the <b>bad</b> <b>pixel</b> which regarded as image noise. By the improved Nagao filtering <b>bad</b> <b>pixel</b> compensation algorithm, filtering sub-windows with the same pixel amount whose patterns are decided by the texture analysis can obtain stronger directivity. Thus, the image boundary pixels do not reappear as flicking dot during the quick scene changes, and the rich scene details are preserved...|$|R
40|$|On-orbit {{sensitivity}} curves for all echelle modes {{were derived}} for post- servicing mis-sion 4 data using {{observations of the}} DA white dwarf G 191 -B 2 B. Additionally, new echelle ripple tables and grating dependent <b>bad</b> <b>pixel</b> tables were created for the FUV and NUV MAMA. We review the procedures used to derive the adopted throughputs and implement them in the pipeline {{as well as the}} motivation for the modification of th...|$|R
5000|$|As predicted, {{over the}} course of its mission the WFPC2 {{experienced}} degradation of the CCDs, resulting in defective ("hot") pixels. The telescope's operators perform monthly calibration tests to catalog these; with the WFPC's aperture closed a number of long exposures are taken, and pixels which differ significantly from near black are flagged. To avoid false positives caused by cosmic rays tripping a given pixel, the output of different calibration shots are compared. Pixels which are consistently [...] "hot" [...] are recorded, and astronomers who analyse raw WFPC2 images receive a list of these pixels. Typically astronomers adjust their photo-processing software to ignore these <b>bad</b> <b>pixels.</b>|$|E
50|$|Due to {{a problem}} with cheap {{capacitors}} (an industry-wide issue in the early 1990s), sound failure is a frequent problem with the TurboExpress, sometimes even in new systems. The screen used in the TurboExpress was another source for problems, though it was {{state of the art}} when it was released. The LCD technology used was still fairly new and the rate of pixel failure was very high. Brand-new TurboExpress systems often had several <b>bad</b> <b>pixels.</b> Text is also difficult or impossible to read in certain circumstances, as many times fonts were written to be seen on a television screen, not on a small LCD screen. As a result, certain RPGs and adventure games can be difficult to play on the unit.|$|E
5000|$|On September 29, 2006 (sol [...] ), MRO {{took its}} first high {{resolution}} image from its science orbit. This image {{is said to}} resolve items as small as 90 cm (3 feet) in diameter. On October 6, NASA released detailed pictures from the MRO of Victoria crater along with the Opportunity rover on the rim above it. In November, problems began to surface {{in the operation of}} two MRO spacecraft instruments. A stepping mechanism in the Mars Climate Sounder (MCS) skipped on multiple occasions resulting in a field of view that is slightly out of position. By December normal operations of the instrument was suspended, although a mitigation strategy allows the instrument to continue making most of its intended observations. Also, an increase in noise and resulting <b>bad</b> <b>pixels</b> has been observed in several CCDs of the High Resolution Imaging Science Experiment (HiRISE). Operation of this camera with a longer warm-up time has alleviated the issue. However, the cause is still unknown and may return.|$|E
40|$|The {{results are}} {{presented}} of the examination and testing of a commercial CCD camera designed for use by amateur astronomers and university astronomy laboratory courses. The characteristics of the CCD chip are presented in graphical and tabular form. Individual and averaged bias frames are discussed. Dark frames were taken and counts are presented {{as a function of}} time. Flat field and other images were used to identify and locate <b>bad</b> <b>pixel</b> columns as well as pixels which vary significantly from the mean pixel sensitivity...|$|R
30|$|In recent years, {{convolutional}} {{neural networks}} (CNN) {{have become very}} popular in solving various computer vision problems, and stereo matching is not an exception. In 2015, Stereo Matching by training a Convolutional Neural Network to Compare Image Patches (MC-CNN) [12] {{was one of the}} first methods utilising CNN and achieving <b>bad</b> <b>pixel</b> percentages lower than 7 %. This algorithm has two network architectures (one optimised for speed (FST), other for accuracy (ACRT)). MC-CNN uses CNN for matching cost computation, and matching is performed using Semi-Global Matching from SGM. The success of MC-CNN has led to the adoption of CNN in modern stereo matching algorithms.|$|R
30|$|Block {{matching}} (BM) is {{a classical}} and very simple stereo matching algorithm. Image blocks from two stereo images are compared using Summed Absolute Difference (SAD) error criterion and full scanline search for finding optimal block displacement. Full scanline search used in BM produces {{a lot of}} errors especially in untextured areas. This is usually addressed by running image pre-filters that remove untextured areas and adding matched pixel uniqueness criterion. Even with these measures, results produced by BM are sparse and have high <b>bad</b> <b>pixel</b> percentage, i.e. 25.27 %. BM can be easily parallelised due to its simplicity [5], but results of CUDA implementation are not submitted in Middlebury and KITTI datasets. Our algorithm is similar to BM in that we are also performing a full scanline search.|$|R
30|$|First, the {{threshold}} for <b>bad</b> <b>pixels</b> {{is different in}} Middlebury and KITTI datasets. For Middlebury dataset pixels whose disparity error is more than 4  pixels are considered <b>bad</b> <b>pixels</b> (same threshold as that used to evaluate our algorithms). Whereas, in the KITTI dataset, <b>bad</b> <b>pixels</b> have disparity error of more than 3  pixels. Therefore, the percentage of <b>bad</b> <b>pixels</b> should be higher in KITTI dataset if two algorithms have identical performance.|$|E
30|$|Average {{error of}} <b>bad</b> <b>pixels</b> per image. The average {{disparity}} value error of pixels {{that have been}} classified as <b>bad</b> <b>pixels.</b>|$|E
30|$|Our {{algorithm}} {{provides a}} range of configurations that are suitable for different real-time applications. It is capable of maintaining up to 70  FPS for Q resolution images and 22  FPS for H resolution images. Weight function and algorithm parameters can be chosen such that the desired processing time and accuracy is achieved. This paper contains detailed experimental results of seven variations of Cyclops 2. Evaluated variations had high percentage of <b>bad</b> <b>pixels.</b> The percentage of <b>bad</b> <b>pixels</b> {{is directly related to}} the bad pixel threshold (set to 4  pixels in this paper). In situations where speed is more critical than accuracy, this threshold could be set to a larger value resulting in smaller percentage of <b>bad</b> <b>pixels.</b> Further algorithm improvements can be done by implementing additional pre-processing stages that filter out untextured regions. Such approach could reduce the percentage of <b>bad</b> <b>pixels</b> but would also increase the percentage of invalid pixels.|$|E
40|$|We {{present a}} new method of {{interpolation}} for the pixel brightness estimation in astronomical images. Our new method {{is simple and}} easily implementable. We show the comparison of this method with the widely used linear interpolation and other interpolation algorithms using 1000 astronomical images obtained from the Sloan Digital Sky Survey. The comparison shows that our method improves <b>bad</b> <b>pixel</b> brightness estimation with four times lower mean error than the presently most popular linear interpolation, and performs {{better than any other}} examined method. The presented idea is flexible and can be also applied to present and future interpolation methods. The proposed method is especially useful for large sky surveys image reduction but can be also applied to single image correction...|$|R
40|$|This {{report is}} {{the first of a series}} that {{describes}} the quantitative data analysis and the results obtained with ARNICA at the TIRGO during the commissioning of the camera (November 1992 [...] June 1993). The series of reports is based on broad-band data acquired in nineteen nights at the telescope (11 nights in December/January, 4 nights in February, and 4 nights in March), as well as data from laboratory tests. Presented here in the first report are the techniques used to characterize the detector and the derived parameters. In particular, we analyze detector performance in terms of: 1) conversion factor or gain; 2) read noise; 3) dark current; 4) non-linearity and its correction; and 5) cosmetic quality and the correction for <b>bad</b> <b>pixel...</b>|$|R
3000|$|... in (17) {{were set}} to 20, 10, and 10, respectively. The kernel size S and the {{variance}} σ 2 in (20) and (23) {{were set to}} 5 × 5 and 4, respectively. No pre-processes were performed on the input BP-LDR image, but pre-processes such as <b>bad</b> <b>pixel</b> correction [22] and Gr-Gb imbalance correction [23] can improve the HDR result according {{to the quality of}} the imaging sensor. For better visualization, we showed the results in RGB images rather than in Bayer patterned images. All the input BP-LDR images were post-processed by the edge-preserving color interpolation [24], white balancing, color correction, and gamma correction. For the resulting BP-HDR images, an additional tone-mapping algorithm [25] was used to compress the dynamic range, which visualizes the HDR image information on a low dynamic range display.|$|R
3000|$|Referring to Section 2.2, embed {{the data}} (including P, T, and the <b>bad</b> <b>pixels</b> in position) into E to {{generate}} E [...]...|$|E
40|$|Abstract- Hyperion {{images are}} {{currently}} processed to level 1 a (from level 0 or raw data). These level 1 a images are files of radiometrically corrected data in units of either watts/(sr × micron × m 2) × 40 for VNIR bands or watts/(sr × micron × m 2) × 80 for SWIR bands. Each distributed Hyperion level 1 a im-age tape contains a log file, called “(EO- 1 identifier). fix. log”, that reports the bad or corrupted pixels (called known <b>bad</b> <b>pixels)</b> found during the pre-flight checking, and details {{how they were}} fixed. All <b>bad</b> <b>pixels</b> should be corrected in a level 1 a image. However, <b>bad</b> <b>pixels</b> are still evident. In addition, there are dark vertical stripes in the image that are not reported in the log file. In this paper, we introduce a method to detect and correct the <b>bad</b> <b>pixels</b> and vertical stripes (we will refer to these occurrences as abnormal pixels). Images from the Greater Victoria Watershed and other EVEOSD test sites are used to determine how stationary {{the locations of the}} abnormal pixels are. After abnormal pixel correction a Hyperion image is ready for geometric correction, atmospheric correction, and further analysis...|$|E
3000|$|Percentage of <b>bad</b> <b>pixels</b> whose {{disparity}} {{error is}} greater than 4.0  pixels. The provided measure is the average percentage of <b>bad</b> <b>pixels</b> per image. As already mentioned in introduction, the methods {{presented in this paper}} concentrate on optimising algorithm processing time at a cost of higher percentage of errors. This is reflected in the choice of higher than default bad pixel threshold (4.0  pixels instead of 2.0  pixels default of Middlebury dataset) which is more suitable in obstacle avoidance scenario; [...]...|$|E
40|$|An image {{processor}} is discussed that combines {{many types of}} image enhancement onto a single compact electronics card. The current enhancements include <b>bad</b> <b>pixel</b> compensation, focal plane array non-uniformity correction, several stages of contrast enhancement, feature sharpening, superresolution, and image motion stabilization. Though there are certainly better algorithms for particular applications, this mixture of algorithms reliably enables the system to substantially improve image quality for a large variety of sensors, platforms, and imaging geometries. The card design hosted an FPGA and microprocessor facilitated rapid development by allowing many complicated algorithm elements to be quickly coded in C, with the FPGA providing horsepower for simpler but more computationally intensive elements. Examples show the quality improvement gained by compensating for image degradations including camera motion, atmospheric turbulence induced blur, focal plane imperfections, camera pixel density, and noise...|$|R
40|$|In the {{framework}} of the APEX (Airborne Prism Experiment) pushbroom imaging spectrometer, a complete processing and archiving facility (PAF) is developed. The PAF not only includes imaging spectrometer data processing up to physical units, but also geometric and atmospheric correction for each scene, as well as calibration datainput. The PAF software includes an Internet based web-server and provides interfaces to data users as well as instrument operators and programmers. The software design, the tools and its life cycle is discussed aswell. Further we will discuss particular instrument requirements (resampling, <b>bad</b> <b>pixel</b> treatment,etc. in view of the operation of the PAF as well as their consequences on the product quality. Finally we will discuss a combined approach for geometric and atmospheric correction including BRDF (or view angle) related effects...|$|R
40|$|Abstract—An {{active pixel}} sensor (APS) with two-dimen-sional winner-take-all (WTA) {{detection}} is presented. This system-on-a-chip employs adaptive spatial filtering of the pro-cessed image, with <b>bad</b> <b>pixel</b> elimination and false alarm reduction {{in case of}} a missing object. The circuit has a unique ability of adaptive spatial filtering that allows removal of the background from the image, one stage before it is transferred to the WTA de-tection circuit. A test chip of a 64 64 array has been implemented in 0. 5 - m CMOS technology, has a 49 % fill factor, is operated by a 3. 3 -V supply, and dissipates 36 mW at video rate. System architecture and operation are discussed and measurements from the prototype chip are presented. Index Terms—Active pixel sensor (APS), CMOS, filter, image processing, pattern recognition, spatial filtering, very large scale integration (VLSI), winner-take-all (WTA). I...|$|R
3000|$|... − 1], labeled {{as a bad}} pixel. The <b>bad</b> <b>pixels</b> in {{position}} will be saved and embedded with the payload to indicate the expandable locations.|$|E
40|$|In {{depth map}} {{generation}} algorithms, parameters settings to yield an accurate disparity map estimation are usually chosen empirically or based on un planned experiments [...] Algorithms' performance is measured {{based on the}} distance of the algorithm results vs. the Ground Truth by Middlebury's standards [...] This work shows a systematic statistical approach including exploratory data analyses on over 14000 images and designs of experiments using 31 depth maps to measure the relative inf uence of the parameters and to fine-tune them {{based on the number of}} <b>bad</b> <b>pixels</b> [...] The implemented methodology improves the performance of adaptive weight based dense depth map algorithms [...] As a result, the algorithm improves from 16. 78 % to 14. 48 % <b>bad</b> <b>pixels</b> using a classical exploratory data analysis of over 14000 existing images, while using designs of computer experiments with 31 runs yielded an even better performance by lowering <b>bad</b> <b>pixels</b> from 16. 78 % to 13...|$|E
30|$|Cyclops 2 {{has been}} {{evaluated}} on two NVIDIA Jetson boards, namely TK 1 and TX 1. Training image sets from Middlebury dataset {{were used in}} all experiments. We only used Q and H resolution images because Jetson boards did not have sufficient resources to process F resolution images. The performance of our algorithm was compared with that of SGBM, {{one of the most}} popular stereo matching algorithms. We chose SGBM because it had a publicly available GPU implementation. Four metrics were used to evaluate the algorithms, namely computation time, percentage of <b>bad</b> <b>pixels,</b> percentage of invalid pixels and average error of <b>bad</b> <b>pixels.</b>|$|E
40|$|Depth maps {{captured}} by the range imaging sensors such as ToF (time of flight) camera and Kinect are stuck with limited spatial resolution and varieties of noises, which {{makes it difficult to}} be directly applied to 3 D scene analysis. In this paper, we address these issues via an extended weighted mode filter (EWMF). In view of the impressive feature of the noise-aware filter in noise suppression, the proposed method synergistically combines standard weighted mode filter (WMF) and the noise aware filter to achieve a better noise suppression performance. Different from conventional filtering-based methods with a fixed support window, a refined adaptive support window (RASW) is designed. The proposed filter with RASW can well capture local structure details better. Experimental results demonstrate that the proposed method outperforms several state-of-the-art super-resolution techniques in terms of <b>bad</b> <b>pixel</b> rate and root mean square error...|$|R
5000|$|Waters {{was born}} and raised in West Germany (which later became Germany after reunification) before {{relocating}} to England to attend university. Waters graduated with a Bachelor of Arts with honours in film and drama. She is fluent in both languages. As well as wrestling, Waters had a small career in film, directing the British independent film Welcome To Hell and acting in Utopian Pictures' Tough Justice as Tara Hunt [...] and as [...] "Stripper #1" [...] in TVyouno.com film 24 Hours in Las Vegas, Zoe in Go Green, Valerie in <b>Bad</b> <b>Pixel</b> and as the Serpent Queen in the 2012 film Amanda and the Guardian, which was never released. Waters also appears, along with Shelly Martinez, in the music video for [...] "Miss Outta Control" [...] by Electrolightz. Her biggest influence in the wrestling world is Kevin Nash.|$|R
30|$|Starting {{from the}} idea that the perceptual quality of {{rendered}} view will depend more on the amount of geometrical distortions than on the number of <b>bad</b> depth <b>pixels,</b> we suggest to give preference to areas where the change between ground truth depth and compressed depth is more abrupt. Such changes are expected to cause perceptually high geometrical distortions.|$|R
3000|$|Find the <b>bad</b> <b>pixels</b> in {{position}} {{by using an}} embedding testing operation. The embedding testing step {{is similar to that}} in [14, 15]. Each bad pixel consumes 25 bits of payload to indicate the embedding position; [...]...|$|E
40|$|As today's {{digital cameras}} contain {{millions}} of image sensors, {{it is highly}} probable that the image sensors will contain a few defective pixels due to errors in the fabrication process. While these <b>bad</b> <b>pixels</b> would normally be mapped out in the manufacturing process, more defective pixels, known as hot pixels, could appear over time with camera usage. Since some hot pixels can still function at normal settings, they need not be permanently mapped out because they will only appear on a long exposure and/or at high ISO settings. In this paper, we apply an adaptive order-statistics multi-shell filter within CFA demosaicking to filter out only <b>bad</b> <b>pixels</b> whilst preserving {{the rest of the}} image. The CFA image containing <b>bad</b> <b>pixels</b> is first demosaicked to produce a full colour image. The adaptive filter is then only applied to the actual sensor pixels within the colour image for bad pixel correction. Demosaicking is then re-applied at those bad pixel locations to produce the final full colour image free of defective pixels. It has been shown that our proposed method outperforms a separate process of CFA demosaicking followed by bad pixel removal...|$|E
40|$|In {{depth map}} generation, the {{settings}} of the algorithm parameters to yield an accurate disparity estimation are usually chosen empirically or based on unplanned experiments [...] A structured statistical approach including classical and exploratory data analyses on over 14000 images {{to measure the}} relative influence of the parameters allows their tuning {{based on the number}} of <b>bad</b> <b>pixels</b> [...] The implemented methodology improves the performance of dense depth map algorithms [...] As a result of the statistical based tuning, the algorithm improves from 16. 78 % to 14. 48 % <b>bad</b> <b>pixels</b> rising 7 spots as per the Middlebury Stereo Evaluation Ranking Table [...] The performance is measured based on the distance of the algorithm results vs. the Ground Truth by Middlebury [...] Future work aims to achieve the tuning by using significantly smaller data sets on fractional factorial and response surface design of experiment...|$|E
3000|$|Average dark frames: {{we first}} acquire a {{sequence}} of frames when no light is present, and compute the average and standard deviation of each pixel and readout block. We set a binary threshold to define <b>bad</b> (noisy) <b>pixels</b> or <b>bad</b> (noisy) ADC channels, when the standard deviation is above a threshold or if the standard deviation is equal to 0; [...]...|$|R
40|$|Abstract. In {{the last}} few months a number of {{improvements}} to the STIS pipeline calibration have been developed and implemented, which include the following. We have released new low order flat files for use with the G 140 L observations. These flats should reduce uncertainties of the extracted flux with position from 12 % to 2 %. To better reflect the change with time in the overall shape of the NUV MAMA dark current, new dark reference files were created for different epochs. To further improve the dark subtraction, these darks are also scaled using an improved algorithm, which takes into account long term changes in the behavior of the NUV MAMA dark current. Additional improvements which have been implemented are described in the posters by Stys et al., Valenti et al., Davies et al. and Lindler et al. Future improvements include background smoothing for low signal spectroscopic data, and updating the Pixel-to-Pixel flat library and the current CCD <b>bad</b> <b>pixel</b> table. 1. New Low Order Flat Image File for G 140...|$|R
40|$|We {{present the}} {{spectral}} atlas of sources observed in low resolution with the Infrared Spectrograph {{on board the}} Spitzer Space Telescope. More than 11, 000 distinct sources were extracted using a dedicated algorithm based on the SMART software with an optimal extraction (AdOpt package). These correspond to all 13, 000 low resolution observations of fixed objects (both single source and cluster observations). The pipeline includes image cleaning, individual exposure combination, and background subtraction. A particular attention is given to <b>bad</b> <b>pixel</b> and outlier rejection at the image and spectra levels. Most sources are spatially unresolved so that optimal extraction reaches the highest possible signal-to-noise ratio. For all sources, an alternative extraction is also provided that accounts {{for all of the}} source flux within the aperture. CASSIS provides publishable quality spectra through an online database together with several important diagnostics, such as the source spatial extent and a quantitative measure of detection level. Ancillary data such as available spectroscopic redshifts are also provided. The database interface will eventually provide various ways to interact with the spectra, such as on-the-fly measurements of spectral features or comparisons among spectra. Comment: Accepted for publication in ApJ Supplement Serie...|$|R
