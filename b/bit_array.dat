87|114|Public
500|$|For {{approximate}} results, Bloom filters, another probabilistic {{data structure}} based on hashing, store {{a set of}} keys by encoding the keys using a <b>bit</b> <b>array</b> and multiple hash functions. Bloom filters are much more space-efficient than bit arrays in most cases and not much slower: with [...] hash functions, membership queries require only [...] time. However, Bloom filters suffer from false positives.|$|E
500|$|A related {{problem to}} search is set membership. Any {{algorithm}} that does lookup, like binary search, {{can also be}} used for set membership. There are other algorithms that are more specifically suited for set membership. [...] A <b>bit</b> <b>array</b> is the simplest, useful when the range of keys is limited; it is very fast, requiring only [...] time. [...] The Judy1 type of Judy array handles 64-bit keys efficiently.|$|E
2500|$|Apart from serialization, {{the terms}} bit endianness and bit-level endianness are seldom used, as {{computer}} architectures where each individual bit {{has a unique}} address are rare. Individual bits or bit fields are accessed via their numerical value or, in high-level programming languages, assigned names, the effects of which, however, may be machine dependent or lack software portability. The natural numbering is that the arithmetic left shift 1<<n yields a mask for the bit of position n, a rule which exhibits the machine's (byte) endianness at least if [...] e.g. if used for indexing a sufficiently large <b>bit</b> <b>array.</b> Other numberings do occur in various documentations.|$|E
5000|$|However, <b>bit</b> <b>arrays</b> aren't the {{solution}} to everything. In particular: ...|$|R
50|$|Another {{application}} of <b>bit</b> <b>arrays</b> is the Bloom filter, a probabilistic set data structure that can store large sets {{in a small}} space {{in exchange for a}} small probability of error. It is also possible to build probabilistic hash tables based on <b>bit</b> <b>arrays</b> that accept either false positives or false negatives.|$|R
40|$|We {{propose a}} {{learning}} method with feature selection for Locality-Sensitive Hashing. Locality-Sensitive Hashing converts feature vectors into <b>bit</b> <b>arrays.</b> These <b>bit</b> <b>arrays</b> {{can be used}} to perform similarity searches and personal authentication. The proposed method uses <b>bit</b> <b>arrays</b> longer than those used in the end for similarity and other searches and by learning selects the bits that will be used. We demonstrated this method can effectively perform optimization for cases such as fingerprint images with a large number of labels and extremely few data that share the same labels, as well as verifying that it is also effective for natural images, handwritten digits, and speech features. Comment: 9 pages, 6 figures, 3 table...|$|R
50|$|A <b>bit</b> <b>array</b> (also {{known as}} bit map , bit set, bit string, or bit vector) is an array data {{structure}} that compactly stores bits. It {{can be used}} to implement a simple set data structure. A <b>bit</b> <b>array</b> is effective at exploiting bit-level parallelism in hardware to perform operations quickly. A typical <b>bit</b> <b>array</b> stores kw bits, where w is the number of bits in the unit of storage, such as a byte or word, and k is some nonnegative integer. If w does not divide the number of bits to be stored, some space is wasted due to internal fragmentation.|$|E
50|$|A {{larger number}} of bits can be {{accommodated}} in a given space by varying the throw of the different elements {{as well as their}} area. This can achieve a magnitude or more of area improvement for a given bit depth. One could fit a 13 <b>bit</b> <b>array</b> into a square foot, or a 16 <b>bit</b> <b>array</b> into 4 sq ft.|$|E
5000|$|The bitap {{algorithm}} for exact string searching, in full generality, {{looks like}} this in pseudocode: algorithm bitap_search(text : string, pattern : string) returns string m := length(pattern) [...] if m == 0 return text [...] /* Initialize the <b>bit</b> <b>array</b> R. */ R := new arraym+1 of bit, initially all 0 R0 = 1 [...] for i = 0; i < length(text); i += 1: /* Update the <b>bit</b> <b>array.</b> */ [...] for k = m; k >= 1; k -= 1: Rk = Rk-1 & (texti == patternk-1) [...] if Rm: [...] return (text+i - m) + 1 [...] return nil ...|$|E
5000|$|<b>Bit</b> <b>arrays,</b> {{despite their}} simplicity, {{have a number}} of marked {{advantages}} over other data structures for the same problems: ...|$|R
5000|$|In Perl, strings {{can be used}} as {{expandable}} <b>bit</b> <b>arrays.</b> They can {{be manipulated}} using the usual bitwise operators (...) , and individual bits can be tested and set using the vec function.|$|R
5000|$|Given two <b>bit</b> <b>arrays</b> of {{the same}} size {{representing}} sets, we can compute their union, intersection, and set-theoretic difference using n/w simple bit operations each (2n/w for difference), as well as the complement of either: ...|$|R
50|$|In computing, a bitmap is {{a mapping}} from some domain (for example, {{a range of}} integers) to bits, that is, values which are zero or one. It is also called a <b>bit</b> <b>array</b> or bitmap index.|$|E
5000|$|When {{using an}} array of bytes to {{represent}} a set of bits, i.e., a <b>bit</b> <b>array</b> or bitset, the index of the byte in the array associated with a bit [...] can be calculated using division: ...|$|E
5000|$|If we wish {{to iterate}} through the bits of a <b>bit</b> <b>array,</b> {{we can do this}} {{efficiently}} using a doubly nested loop that loops through each word, one at a time. Only n/w memory accesses are required: ...|$|E
50|$|Because {{of their}} compactness, <b>bit</b> <b>arrays</b> {{have a number}} of {{applications}} in areas where space or efficiency is at a premium. Most commonly, they are used to represent a simple group of boolean flags or an ordered sequence of boolean values.|$|R
5000|$|Although Standard ML has {{no support}} for <b>bit</b> <b>arrays,</b> Standard ML of New Jersey has an extension, the [...] structure, in its SML/NJ Library. It is not fixed {{in size and}} {{supports}} set operations and bit operations, including, unusually, shift operations.|$|R
5000|$|The D {{programming}} language provides <b>bit</b> <b>arrays</b> in its standard library, Phobos, in [...] As in C++, the [...] operator does not return a reference, since individual bits {{are not directly}} addressable on most hardware, but instead returns a [...]|$|R
50|$|A fully tokenized, <b>bit</b> <b>array</b> encoded and {{compressed}} database, {{data storage}} is column-oriented using domains across schemas/tables {{rather than as}} rows of data within tables. This results in an optimized platform for data analytics and data mining, although not suitable for transaction processing.|$|E
5000|$|A <b>bit</b> <b>array</b> {{can be used}} to {{implement}} a priority queue. In this context, find first set (ffs) is useful in implementing the [...] "pop" [...] or [...] "pull highest priority element" [...] operation efficiently. The Linux kernel real-time scheduler internally uses [...] for this purpose.|$|E
50|$|The find {{first set}} or find first one {{operation}} identifies the index or {{position of the}} 1-bit with the smallest index in an array, and has widespread hardware support (for arrays not larger than a word) and efficient algorithms for its computation. When a priority queue is stored in a <b>bit</b> <b>array,</b> find first one {{can be used to}} identify the highest priority element in the queue. To expand a word-size find first one to longer arrays, one can find the first nonzero word and then run find first one on that word. The related operations find first zero, count leading zeros, count leading ones, count trailing zeros, count trailing ones, and log base 2 (see find first set) can also be extended to a <b>bit</b> <b>array</b> in a straightforward manner.|$|E
5000|$|Without compression, {{they are}} {{wasteful}} set data structures for sparse sets (those with few elements {{compared to their}} range) in both time and space. For such applications, compressed <b>bit</b> <b>arrays,</b> Judy arrays, tries, or even Bloom filters should be considered instead.|$|R
50|$|<b>Bit</b> <b>arrays</b> can be {{used for}} the {{allocation}} of memory pages, inodes, disk sectors, etc. In such cases, the term bitmap may be used. However, this term is frequently used to refer to raster images, which may use multiple bits per pixel.|$|R
50|$|<b>Bit</b> <b>arrays</b> {{are used}} for {{priority}} queues, where the bit at index k is set {{if and only if}} k is in the queue; this data structure is used, for example, by the Linux kernel, and benefits strongly from a find-first-zero operation in hardware.|$|R
5000|$|One of {{the strongest}} reasons for using bitmap indexes is that the {{intermediate}} results produced from them are also bitmaps and can be efficiently reused in further operations to answer more complex queries. Many programming languages support this as a <b>bit</b> <b>array</b> data structure. For example, Java has the [...] class.|$|E
50|$|Other popular {{methods include}} arrays. In {{particular}} {{a subset of}} the integers 1..n can be implemented efficiently as an n-bit <b>bit</b> <b>array,</b> which also support very efficient union and intersection operations. A Bloom map implements a set probabilistically, using a very compact representation but risking a small chance of false positives on queries.|$|E
5000|$|Haskell {{likewise}} currently lacks standard {{support for}} bitwise operations, but both GHC and Hugs provide a [...] module with assorted bitwise functions and operators, including shift and rotate operations and an [...] "unboxed" [...] array over boolean values {{may be used}} to model a <b>Bit</b> <b>array,</b> although this lacks support from the former module.|$|E
50|$|<b>Bit</b> <b>arrays</b> and the {{operations}} on them {{are also important}} for constructing succinct data structures, which use close to the minimum possible space. In this context, operations like finding the nth 1 bit or {{counting the number of}} 1 bits up to a certain position become important.|$|R
50|$|<b>Bit</b> <b>arrays</b> {{are also}} a useful {{abstraction}} for examining streams of compressed data, which often contain elements that occupy portions of bytes or are not byte-aligned. For example, the compressed Huffman coding representation of a single 8-bit character can be anywhere from 1 to 255 bits long.|$|R
5000|$|Data {{registers}} {{can hold}} numeric {{values such as}} integer and, in some architectures, floating-point values, as well as characters, small <b>bit</b> <b>arrays</b> and other data. In some older and low end CPUs, a special data register, known as the accumulator, is used implicitly for many operations.|$|R
50|$|A {{bit field}} is {{distinguished}} from a <b>bit</b> <b>array</b> {{in that the}} latter is used to store a large set of bits indexed by integers and is often wider than any integral type supported by the language. Bit fields, on the other hand, typically fit within a machine word, and the denotation of bits is independent of their numerical index.|$|E
5000|$|For {{approximate}} results, Bloom filters, another probabilistic {{data structure}} based on hashing, store {{a set of}} keys by encoding the keys using a <b>bit</b> <b>array</b> and multiple hash functions. Bloom filters are much more space-efficient than bitarrays in most cases and not much slower: with [...] hash functions, membership queries require only [...] time. However, Bloom filters suffer from false positives.|$|E
5000|$|A related {{problem to}} search is set membership. Any {{algorithm}} that does lookup, like binary search, {{can also be}} used for set membership. There are other algorithms that are more specifically suited for set membership. A <b>bit</b> <b>array</b> is the simplest, useful when the range of keys is limited; it is very fast, requiring only [...] time. The Judy1 type of Judy array handles 64-bit keys efficiently.|$|E
50|$|Find {{first set}} and related {{operations}} {{can be extended}} to arbitrarily large <b>bit</b> <b>arrays</b> in a straightforward manner by starting {{at one end and}} proceeding until a word that is not all-zero (for ffs/ctz/clz) or not all-one (for ffz/clo/cto) is encountered. A tree data structure that recursively uses bitmaps to track which words are nonzero can accelerate this.|$|R
40|$|It {{has become}} clear that large {{embedded}} configurable memory arrays will be essential in future FPGAs. Embedded arrays provide high-density high-speed implementations of the storage parts of circuits. Unfortunately, they require the FPGA vendor to partition the device into memory and logic resources at manufacture-time. This leads to a waste of chip area for customers that do not use all of the storage provided. This chip area need not be wasted, and can in fact be used very efficiently, if the arrays are configured as large multi-output ROMs, and used to implement logic. In this paper, we investigate how {{the architecture of the}} FPGA embedded arrays affects their ability to implement logic. Specifically, we focus on architectures which contain more than one size of memory array. We show that these heterogeneous architectures result in significantly denser implementations of logic than architectures with only one size of memory array. We also show that the best heterogeneous architecture contains both 2048 <b>bit</b> <b>arrays</b> and 128 <b>bit</b> <b>arrays.</b> ...|$|R
40|$|Optical {{recording}} and luminescence readout of novel covalently linked photochrome/luminophore supramolecular complexes {{has been demonstrated}} by near-field scanning optical microscopy (NSOM). Localized UV irradiation of these complexes dispersed in polymeric matrices resulted in photoinduced state switching and a concomitant increase in emission intensity. Subsequent luminescence imaging showed well-resolved luminescent data <b>bit</b> <b>arrays</b> with good signal-to-noise ratios. Spatially resolved emission spectra of the luminescent data bits confirmed the switching mechanism...|$|R
