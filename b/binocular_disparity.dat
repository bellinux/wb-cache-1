666|118|Public
500|$|One of {{the most}} {{influential}} early contributions was a 1959 paper titled What the frog's eye tells the frog's brain: the paper examined the visual responses of neurons in the retina and optic tectum of frogs, and {{came to the conclusion that}} some neurons in the tectum of the frog are wired to combine elementary responses in a way that makes them function as [...] "bug perceivers". A few years later David Hubel and Torsten Wiesel discovered cells in the primary visual cortex of monkeys that become active when sharp edges move across specific points in the field of view—a discovery for which they won a Nobel Prize. Follow-up studies in higher-order visual areas found cells that detect <b>binocular</b> <b>disparity,</b> color, movement, and aspects of shape, with areas located at increasing distances from the primary visual cortex showing increasingly complex responses. Other investigations of brain areas unrelated to vision have revealed cells with a wide variety of response correlates, some related to memory, some to abstract types of cognition such as space.|$|E
50|$|<b>Binocular</b> <b>disparity</b> {{refers to}} the {{difference}} in image location of an object seen by {{the left and right}} eyes, resulting from the eyes’ horizontal separation (parallax). The brain uses <b>binocular</b> <b>disparity</b> to extract depth information from the two-dimensional retinal images in stereopsis. In computer vision, <b>binocular</b> <b>disparity</b> {{refers to the}} difference in coordinates of similar features within two stereo images.|$|E
50|$|<b>Binocular</b> <b>disparity</b> {{can also}} be derived from simple geometry.|$|E
40|$|AbstractIn {{the natural}} world, a {{binocular}} discrepancy of luminance can signal a glossy surface. Using a spatial forced choice task, we have measured {{the ability of}} subjects to detect <b>binocular</b> luminance <b>disparities.</b> We show that the detection of <b>binocular</b> luminance <b>disparity</b> shares several basic psychophysical features with the detection of surface properties such as lightness and chromaticity: an approximation to Weber’s Law, spatial summation, temporal summation, and a deterioration with increasing eccentricity. We also discuss whether color-deficient subjects could derive reliable information about chromaticity from the <b>binocular</b> <b>disparities</b> of luminance induced by a monocularly worn color filter...|$|R
40|$|The hollow-face {{illusion}} is {{a well-known}} example of depth inversion occurring with a real object under {{a wide variety of}} viewing conditions (Gregory 1970). The key, unanswered, question remainsöwhy? Despite the availability of unambiguous cues to relative depth, for example <b>binocular</b> <b>disparities</b> and motion parallax, coupled with explicit knowledg...|$|R
5000|$|Stereopsis (from the Greek στερεο- [...] meaning [...] "solid", and [...] opsis, [...] "appearance, sight") is a {{term that}} is most often {{used to refer to}} the {{perception}} of depth and 3-dimensional structure obtained on the basis of visual information deriving from two eyes by individuals with normally developed binocular vision. Because the eyes of humans, and many animals, are located at different lateral positions on the head, binocular vision results in two slightly different images projected to the retinas of the eyes. The differences are mainly in the relative horizontal position of objects in the two images. These positional differences are referred to as horizontal disparities or, more generally, <b>binocular</b> <b>disparities.</b> Disparities are processed in the visual cortex of the brain to yield depth perception. While <b>binocular</b> <b>disparities</b> are naturally present when viewing a real 3-dimensional scene with two eyes, they can also be simulated by artificially presenting two different images separately to each eye using a method called stereoscopy. The perception of depth in such cases is also referred to as [...] "stereoscopic depth".|$|R
5000|$|... #Caption: Figure 1. Definition of <b>binocular</b> <b>disparity</b> (far and near).|$|E
50|$|Autostereograms {{are similar}} to normal stereograms except they are viewed without a {{stereoscope}}. A stereoscope presents 2D images of the same object from slightly different angles to the left eye and the right eye, allowing us to reconstruct the original object via <b>binocular</b> <b>disparity.</b> When viewed with the proper vergence, an autostereogram does the same, the <b>binocular</b> <b>disparity</b> existing in adjacent parts of the repeating 2D patterns.|$|E
50|$|The term cyclopean stimuli {{refers to}} a form of visual stimuli that is defined by <b>binocular</b> <b>disparity</b> alone. It was named after the one-eyed Cyclops of Homer’s Odyssey by Bela Julesz. Julesz was a Hungarian radar engineer. He thought that {{stereopsis}} might help to discover hidden objects, this might be useful to find camouflaged objects. The important aspect of this research was that Julesz showed using random dot stereograms (RDSs) that disparity is sufficient for stereopsis, where Charles Wheatstone had only shown that <b>binocular</b> <b>disparity</b> was necessary for stereopsis. Ironically, the Cyclops {{would not have been able}} to see a cyclopean stimulus, because having only one eye, he would not have been able to perceive binocular depth cues such as <b>binocular</b> <b>disparity.</b>|$|E
40|$|Slant {{perception}} was studied under viewing conditions that combined horizontal-size, vertical-size, and overall-size <b>binocular</b> <b>disparities</b> with motion and static image conditions. For both motion and static conditions, results indicated similar effects of size disparity on perceived slants of disparity and zero-disparity stimuli. Implications for binocular {{head mounted display}} (HMD) systems are considered...|$|R
40|$|We {{propose a}} {{computational}} scheme for uncalibrated reconstruction of scene structure up to a relief transformation from <b>binocular</b> <b>disparities.</b> This scheme, {{which we call}} regional disparity correction (RDC), is motivated both by computational considerations and by psychophysical observations regarding human stereoscopic depth perception. We describe an implementation of RDC, and demonstrate its performance experimentally. As an example of applications of RDC, we show {{how it can be}} used to align a three-dimensional object model with an uncalibrated disparity field. Keywords: stereo, disparity, uncalibrated reconstruction, relief transformation, human vision, model alignment 1 Introduction <b>Binocular</b> <b>disparities,</b> i. e., the slightly different views captured by two eyes or cameras, can convey important information about the three-dimensional structure of the scene. In machine vision, the classical approach is to combine disparities with precise camera calibration information in order to r [...] ...|$|R
40|$|This paper {{considers}} {{the hypothesis that}} systems learning aspects of visual perception may benefit {{from the use of}} suitably designed developmental progressions during training. We report the results of simulations in which three different artificial neural network models were trained to detect <b>binocular</b> <b>disparities</b> in pairs of visual images. Two of the models were developmental models {{in the sense that the}} nature of their training input changed during the course of training (either a coarse-scale-to-multiscale progression or a one-scale-to-multiscale progression). The third model was a non-developmental model in the sense that its training input remained constant during the training period. The simulation results show that the two developmental models consistently outperformed the non-developmental model. We conclude that developmental sequences during training can be useful to systems learning to detect <b>binocular</b> <b>disparities.</b> The idea that developmental progressions can aid visual learning is a viable hypothesis in need of future study...|$|R
5000|$|MT {{was shown}} to be {{organized}} in direction columns. [...] DeAngelis argued that MT neurons were also organized based on their tuning for <b>binocular</b> <b>disparity.</b>|$|E
50|$|In {{computer}} vision, <b>binocular</b> <b>disparity</b> {{is calculated}} from stereo images {{taken from a}} set of stereo cameras. The variable distance between these cameras, called the baseline, can affect the disparity of a specific point on their respective image plane. As the baseline increases, the disparity increases due to the greater angle needed to align the sight on the point. However, in computer vision, <b>binocular</b> <b>disparity</b> is referenced as coordinate differences of the point between {{the right and left}} images instead of a visual angle. The units are usually measured in pixels.|$|E
5000|$|Support {{for many}} image formats, using OpenImageIO, {{including}} multi-layer OpenEXR. Additional image layers {{can be used}} to store several color layers, or for non-color information such as depth, optical flow, <b>binocular</b> <b>disparity,</b> or masks.|$|E
50|$|Up to {{a certain}} extent, <b>binocular</b> <b>disparities</b> can be {{compensated}} for by adjustments of the visual system. If, however, defects of binocular vision are too great - for example if they would require the visual system to adapt to overly large horizontal, vertical, torsional or aniseikonic deviations - the eyes tend to avoid binocular vision, ultimately causing or worsening a condition of strabismus.|$|R
40|$|Our {{two eyes}} receive {{different}} views of a visual scene, and the resulting <b>binocular</b> <b>disparities</b> enable us to reconstruct its three-dimensional layout. However, the visual environment is also rich in monocular depth cues. We examined the resulting percept when observers view {{a scene in which}} there are large conflicts between the surface slant signaled by <b>binocular</b> <b>disparities</b> and the slant signaled by monocular perspective. For a range of disparity-perspective cue conflicts, many observers experience bistability: They are able to perceive two distinct slants and to flip between the two percepts in a controlled way. We present a Bayesian model that describes the quantitative aspects of perceived slant {{on the basis of the}} likelihoods of both perspective and disparity slant information combined with prior assumptions about the shape and orientation of objects in the scene. Our Bayesian approach can be regarded as an overarching framework that allows researchers to study all cue integration aspects - including perceptual decisions - in a unified manner...|$|R
40|$|Obtaining exact depth from <b>binocular</b> <b>disparities</b> is hard if camera {{calibration}} is needed. We {{will show}} that qualitative depth information {{can be obtained from}} stereo disparities with almost no computations and with no prior knowledge (or computation) of camera parameters. We derive two expressions that order all matched points in the images in two distinct depth-consistent ways from image coordinates only. One is a tilt-related order...|$|R
50|$|It {{can give}} {{stereopsis}} in which <b>binocular</b> <b>disparity</b> (or parallax) {{provided by the}} two eyes' different positions on the head gives precise depth perception. This also allows a creature to break the camouflage of another creature.|$|E
50|$|Holographic {{display is}} a display {{technology}} {{that has the}} ability to provide all four eye mechanism: <b>binocular</b> <b>disparity,</b> motion parallax, accommodation and convergence. The 3D objects can be viewed without wearing any special glasses and no visual fatigue will be caused to human eyes.|$|E
50|$|Stereo vision uses {{triangulation}} {{based on}} epipolar geometry to determine distance to an object. More specifically, <b>binocular</b> <b>disparity</b> {{is the process}} of relating the depth of an object to its change in position when viewed from a different camera, given the relative position of each camera is known.|$|E
40|$|Stimuli {{with small}} <b>binocular</b> <b>disparities</b> {{are seen as}} single, despite their differing visual {{directions}} for the two eyes. Such stimuli also yield stereopsis, but stereopsis and single vision can be dissociated. The occurrence of binocular single vision depends {{not only on the}} disparities of individual stimulus elements, but also on the geometrical relation of different parts of the pattern presented to each eye. A pair of vertical bars with opposite <b>binocular</b> <b>disparities</b> is seen as single if the pair is moderately widely spaced but not if it is narrow. Vertical alignment and identity in length of such bars also increase the occurrence of double vision. It is argued that these effects reflect the extraction of features of the monocular patterns, with these detected monocular features determining the binocular percept. Single and double vision of bars differing in orientation can be similarly analysed. The occurrence of relatively elaborate processing of monocular signals does not exclude the possibility that binocular interaction can occur between signals that have not been so processed. Multiple sites or types of binocular interaction are likely...|$|R
40|$|A {{computational}} {{theory and}} neural architecture for determining image affine flow and <b>binocular</b> affine <b>disparity</b> is presented. The computation of image affine flow is formulated {{as a system}} of linear equations, and the computation of <b>binocular</b> affine <b>disparity</b> is formulated as a dynamical system defined on the parameter space of a Lie subgroup of the two dimensional affine Lie group. The proposed neural architecture includes a set of neurons called the Lie-germs which function as the Lie-derivative operators, a set of simple cells with dynamical receptive fields, a set of intrinsic neurons that can affine transform the receptive fields of simple cells, and an analog circuit for determining affine parameters. The result of computer simulations of the proposed neural architecture for <b>binocular</b> affine <b>disparity</b> is also presented in this paper...|$|R
40|$|A {{fundamental}} {{problem in the}} study of spatial perception concerns whether and how vision might acquire information about the metric structure of surfaces inthree-dimensionaLspacefrom motion and from stereopsis. Theoretical analyses have indicated that stereoscopic perceptions of metric relations in depth require additional information about egocentric viewing distance; and recent experiments by James Todd and his colleagues have indicated that vision acquires only afline but notmetric structure from motion—that is, spatial relations ambiguouswith regard to scale in depth. The {{purpose of the present study}} was to determine whether the metric shape ofplanar stereoscopic forms might be perceived from congruence underplanar rotation. In Experiment 1, observers discriminated between similar planar shapes (ellipses) rotating in a plane with varying slant from the frontal-parallel plane. Experimental conditions varied the presence versus absence of <b>binocular</b> <b>disparities,</b> magnification of the disparity scale, and moving versus stationary patterns. Shape discriminations were accurate in all conditions withmovingpatterns and were near chance in conditions with stationary patterns; neither-the- presence nor the magnification of <b>binocular</b> <b>disparities</b> had any reliable effect. In Experiment 2, accuracy decreased as the range of rotation decreased from 800 to 100. In Experiment 3, small deviations from planarity of the motio...|$|R
50|$|In vision, <b>binocular</b> <b>disparity</b> is {{term that}} {{describes}} the difference between two retinal images. This disparity serves {{as the basis for}} stereopsis, {{one of the most important}} depth cues in human sight. In Campus' video, however, the two disparate images are mixed on a single monitor, rendering stereoscopic perception of the image impossible.|$|E
5000|$|<b>Binocular</b> <b>disparity</b> {{forms the}} premise for a sketch {{from the film}} Wayne's World in which Wayne, who is lying in bed as Tia Carrere's character, Cassandra, perches above him, compares the {{respective}} images from his left and right eyes while noting which is which by saying [...] "Camera 1 ... Camera 2 ... Camera 1 ... Camera 2." ...|$|E
5000|$|Binocular neurons are neurons in {{the visual}} system that assist in the {{creation}} of stereopsis from <b>binocular</b> <b>disparity.</b> They have been found in the primary visual cortex where the initial stage of binocular convergence begins. [...] Binocular neurons receive inputs from both the right and left eyes and integrate the signals together to create a perception of depth.|$|E
40|$|Investigators {{debate the}} extent to which neural populations use {{pair-wise}} and higher-order statistical dependencies among neural responses to represent information about a visual stimulus. To study this issue, three statistical decoders were used to extract the information in the responses of model neurons about the <b>binocular</b> <b>disparities</b> present in simulated pairs of left-eye and right-eye images: (1) the full joint probability de-coder considered all possible statistical relations among neural responses as potentially important; (2) the dependence tree decoder also consid-ered all possible relations as potentially important, but it approximated high-order statistical correlations using a computationally tractable pro-cedure; and (3) the independent response decoder, which assumed that neural responses are statistically independent, meaning that all correla-tions should be zero and thus can be ignored. Simulation results indicate that high-order correlations among model neuron responses contain sig-nificant information about <b>binocular</b> <b>disparities</b> and that the amount of this high-order information increases rapidly as a function of neural pop-ulation size. Furthermore, the results highlight the potential importance of the dependence tree decoder to neuroscientists as a powerful but still practical way of approximating high-order correlations among neural re-sponses. ...|$|R
40|$|ARE {{two eyes}} needed for judging {{direction}} of self-motion? Traditional analyses {{stress that the}} pattern of optic flow in one eye is sufficient 1 – 5. The main difficulty is {{how to deal with}} the eye or head rotation. Extraretinal signals help 6 – 8, but humans can also discount the effect of rotation purely on the basis of monocular flow 6, 7, 9 – 12 provided the scene contains depth 6, 9, 10. Depth differences give rise to changing <b>binocular</b> <b>disparities</b> when the observer moves. These disparities are ignored in monocular theories of judgements of heading. Using computer generated displays, we investigated whether stereoscopic presentation improves heading judgements for conditions that pose problems to the monocular observer. We found that adding disparities to simulated ego-motion through a cloud of dots made heading judgements up to four times more tolerant to motion noise. The same improvement was found when the disparities specify the initial distances throughout the motion sequence. We conclude that <b>binocular</b> <b>disparities</b> improve judgements of heading by imposing a depth order on the elements of the scene, not because they provide additional information on the elements' motion in depth...|$|R
40|$|In {{a typical}} Head Mounted Display (HMD), the {{distance}} between the lens and the display screen is fixed. When viewing stereoscopic images presented on a HMD with different <b>binocular</b> <b>disparities,</b> viewers are forced to perform vergence without appropriate eye accommodation. This posts an un-natural demand on viewers' eyes. This paper reports the successful development of a HMD with computer-controlled lens focuses and the results of an experiment conducted to study the benefits of appropriate lens focus adjustment on the time taken for viewers to converge a pair of left and right binocular images into a single stereoscopic image. 3 D letters were presented with <b>binocular</b> <b>disparities</b> appropriate to a virtual depth of 40 cm. Two lens focus adjustments were used: 40 cm and infinity. The order of presenting the two lens focus conditions was randomized. Data from ten participants with five repetitions indicate that the participants took significantly less time to converge the left and right images when the lens focus matched with the virtual depth of the images (p< 0. 0001, ANOVA). The effects of repetitions, participants, and their interactions with the main effects of lens focus are presented...|$|R
50|$|Human {{eyes are}} {{horizontally}} separated by about 50-75 mm (interpupillary distance) depending on each individual. Thus, each eye {{has a slightly}} different {{view of the world}} around. This can be easily seen when alternately closing one eye while looking at a vertical edge. The <b>binocular</b> <b>disparity</b> can be observed from apparent horizontal shift of the vertical edge between both views.|$|E
50|$|In {{bottom-up}} factors, eye guidance can {{be affected}} by the local contrast or salience of features in an image (Itti & Koch, 2000). An example of this would be an area with a large difference in luminance (Parkhurst et al., 2002), a greater density of edges (Mannan, Ruddock & Wooding, 1996) or <b>binocular</b> <b>disparity</b> determining the distance of different objects on the scene (Jansen et al., 2009).|$|E
50|$|In the 1970s, Gabriel Liebermann {{discovered}} that a scratch {{in the shape of}} a circular arc produces glints whose motion is approximately consistent with <b>binocular</b> <b>disparity.</b> His 1980 artwork World Brain is made of CNC-machined semi-circular arcs that produce a holographic effect. The phenomenon was independently discovered in the 1990s by William Beaty who popularized a method of making hand-drawn holograms using a compass (drafting). This has come to be known as scratch holography.|$|E
40|$|Not only <b>binocular</b> {{perspective}} <b>disparity,</b> {{but also}} many secondary binocular and monocular sensory phenomena, {{contribute to the}} human sensation of depth. <b>Binocular</b> perspective <b>disparity</b> is notable as the strongest depth perception factor. However means for creating it artificially from flat image pairs are notorious for inducing physical and mental stresses, e. g., "virtual reality sickness". Aiming to deliver a less stressful "kinder gentler stereo (KGS) ", we systematically examine the secondary phenomena and their synergistic combination {{with each other and}} with <b>binocular</b> perspective <b>disparity.</b> By KGS we mean a stereo capture, rendering, and display paradigm without cue conflicts, without eyewear, without viewing zones, with negligible "lock-in" time to perceive the image in depth, and with a normal appearance for stereo-deficient viewers. To achieve KGS we employ optical and digital image processing steps that introduce distortions contrary to strict "geometrical correctness" of binoc [...] ...|$|R
40|$|Reliable depth {{perception}} {{is essential for}} successfully guiding ones hand toward objects. <b>Binocular</b> <b>disparities</b> are often {{considered to be the}} primary source of metric information about depth. Moreover, as the hand approaches the object, errors in initial depth judgments give rise to relative disparities {{that could be used to}} correct the movement. In the present study we examine whether people can quickly adjust their movements on the basis of information from <b>binocular</b> <b>disparities.</b> It only takes 110 - 150 ms to correct a hand's movement if the object toward which the hand is moving is suddenly displaced. It takes about the same time to adjust the way one moves a computer mouse, and thereby correct the cursor's movement, if the target is displaced on the screen. If arm movements are to be adjusted on the basis of relative disparities it is vital that the response to such information is also this fast, because the information itself only becomes available when the hand comes near the object. We examined cursor movements, rather than hand movements, because this makes it easier to control the visual information that the subjects can use. Subjects sat 80 cm from a computer screen and quickly moved a cursor to a target by moving the mouse. The cursor moved in a horizontal plane at eye level, in the same direction as the mouse. Shutter spectacles were used to present the cursor and target at the desired depths. Once the cursor reached the target the latter disappeared and a new one appeared elsewhere. On some trials the target jumped 15 cm in depth while the cursor was moving toward it. It took subjects more than 200 ms to respond to this displacement. When the experiment was repeated with the targets 8 cm below eye height, so that a movement in depth gave rise to a small vertical movement on the screen, the response was much faster. Thus <b>binocular</b> <b>disparities</b> are unlikely to be important for guiding the hand toward objects unless we move rather slowly...|$|R
50|$|Current {{research}} in visual neuroscience and psychophysics is investigating how microsaccades relate to fixation correction, control of <b>binocular</b> fixation <b>disparity</b> and attentional shifts. Recent {{research has found}} a direct correlation between illusory motion and microsaccades.|$|R
