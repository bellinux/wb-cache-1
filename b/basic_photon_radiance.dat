0|34|Public
5000|$|The {{relationship}} between <b>photon</b> <b>radiance,</b> L, (in units of photons per square metre per second per steradian) and I (in units of rayleighs) is ...|$|R
40|$|Analytical {{expressions}} for the <b>photon</b> <b>radiance</b> and its derivative in {{the spectral}} band from 400 to 700 microns {{are presented in}} a graphic form {{as a function of}} temperature for the cryogenic temperatures from 1 to 8 K. The temperature dependence of <b>photon</b> <b>radiance</b> and its derivative have been applied to a background-limited telescope to determine the temperature tolerances. It is concluded that the application of the background-limited telescope operation concept to the telescope operational requirements results in a reduction in the telescope temperature, i. e., an increase in temperatures for the most components, and a prolonged telescope facility lifetime...|$|R
50|$|The {{number of}} photons {{observed}} per unit time is the photon flux. The photon flux per unit area is the photon irradiance if the photons are incident on a surface, or photon exitance if the emission of photons from a broad-area source is being considered. The flux per unit solid angle is the photon intensity. The flux per unit source area per unit solid angle is <b>photon</b> <b>radiance.</b> SI units for these quantities are summarized in the table below.|$|R
50|$|The {{spaceship}} {{starts with}} a <b>basic</b> <b>photon</b> cannon and air-to-ground bombs. Both of these weapons can fire continuously without a need for pause. The photon cannon can be upgraded five times {{for up to five}} streams of photons by collecting P upgrades. Additionally, the exhaust of the ship {{can be used as a}} weapon.|$|R
40|$|A {{detailed}} Monte-Carlo code {{has been}} developed from basic principles that simulates {{almost all of the}} <b>basic</b> <b>photon</b> and charged particle interactions. The code is used to derive the response functions of a high energy photon detector to incident beams of photons of various energies. The detector response matrice(DRM) s are calculated using this code. Deconvolution of an artificially generated spectrum is presented...|$|R
5000|$|Current {{technical}} {{criticisms of}} the idea of [...] "foam plasma pressure" [...] focus on unclassified analysis from similar high energy physics fields that indicate that the pressure produced by such a plasma would only be a small multiplier of the <b>basic</b> <b>photon</b> pressure within the radiation case, and also that the known foam materials intrinsically have a very low absorption efficiency of the gamma ray and X-ray radiation from the primary. Most of the energy produced would be absorbed by either the walls of the radiation case or the tamper around the secondary. Analyzing the effects of that absorbed energy led to the third mechanism: ablation.|$|R
40|$|Entanglement between macroscopically {{populated}} {{states can}} easily be created by combining a single photon and a bright coherent state on a beam-splitter. Motivated by the simplicity of this technique, we report on a method using displacement operations in the phase space and <b>basic</b> <b>photon</b> detections to reveal such an entanglement. We demonstrate through preliminary experimental results, that this eminently feasible approach provides an attractive way for exploring entanglement at various scales, ranging from one to a thousand photons. This offers an instructive viewpoint to gain insight into the reasons that {{make it hard to}} observe quantum features in our macroscopic world. Comment: 6 pages, 10 figures. v 2 : Updated version. The corresponding experiment is reported in arXiv: 1212. 3710. See also arXiv: 1306. 084...|$|R
40|$|Several {{approaches}} to imaging hard X-rays emitted from solar flares {{have been proposed}} or are planned for the nineties including the spatial modulation collimator (SMC) and the rotating modulation collimator (RMC). A survey of current solar flare theoretical literature indicates the desirability of spatial resolutions down to 1 arcsecond, field of views greater than the full solar disk (i. e., 32 arcminutes), and temporal resolutions down to 1 second. Although the sun typically provides relatively high flux levels, the requirement for 1 second temporal resolution raises {{the question as to}} the viability of Fourier telescopes subject to the aforementioned constraints. A <b>basic</b> <b>photon</b> counting, Monte Carlo 'end-to-end' model telescope was employed using the Astronomical Image Processing System (AIPS) for image reconstruction. The resulting solar flare hard X-ray images compared against typical observations indicated that both telescopes show promise for the future...|$|R
40|$|The photon map {{technique}} for global illumination does not specifically address animated scenes. In particular, prior work has not considered {{the problem of}} temporal sampling (motion blur) while using the photon map. In this paper we examine several approaches for simulating motion blur with the photon map. In particular we show that a distribution of photons in time combined with the standard <b>photon</b> map <b>radiance</b> estimate is incorrect, and we introduce a simple generalization that correctly handles photons distributed in both time and space. Our results demonstrate that this time dependent photon map extension allows fast and correct estimates of motion-blurred illumination including motion-blurred caustics. 1...|$|R
40|$|Game {{theory is}} a well {{established}} branch of mathematics whose formalism has a vast range of applications from the social sciences, biology, to economics. Motivated by quantum information science, {{there has been a}} leap in the formulation of novel game strategies that lead to new (quantum Nash) equilibrium points whereby players in some classical games are always outperformed if sharing and processing joint information ruled by the laws of quantum physics is allowed. We show that, for a bipartite non zero-sum game, input local quantum correlations, and separable states in particular, suffice to achieve an advantage over any strategy that uses classical resources, thus dispensing with quantum nonlocality, entanglement, or even discord between the players' input states. This highlights the remarkable key role played by pure quantum coherence at powering some protocols. Finally, we propose an experiment that uses separable states and <b>basic</b> <b>photon</b> interferometry to demonstrate the locally-correlated quantum advantage. Comment: 10 pages, 7 figure...|$|R
50|$|In {{the first}} lecture, which {{acts as a}} gentle lead-in {{to the subject of}} quantum electrodynamics, Feynman {{describes}} the <b>basic</b> properties of <b>photons.</b> He discusses how to measure the probability that a photon will reflect or transmit through a partially reflective piece of glass.|$|R
5000|$|The step size, s, is the {{distance}} the photon packet travels between interaction sites. There {{are a variety}} of methods for step size selection. Below is a <b>basic</b> form of <b>photon</b> step size selection (derived using the inverse distribution method and the Beer - Lambert law) from which we use for our homogeneous model: ...|$|R
40|$|In this paper, {{we present}} a {{physical}} validation of global illumination algorithms based on measurements from a simple experimental setup. The validation methodology emphasizes tractability and error minimization. To this end, we discuss {{issues such as the}} acquisition and accurate simulation of material bidirectional reflection distribution functions (BRDFs) and the light source distribution, as well as error analysis. In addition, {{we present a}} nearest-neighbor resampling technique for BRDFs and a simple method for extracting the light source distribution from digitized high dynamic range (HDR) images. Finally, we compare the measurements to a forward and backward raytracing solution (<b>photon</b> map and <b>RADIANCE,</b> respectively) in a set of case studies...|$|R
40|$|Dose {{inhomogeneity}} {{in treatment}} planning can be compensated using physical wedges. Enhanced dynamic wedges (EDW) were introduced by Varian to over-come {{some of the}} shortcomings of physical wedges. The objectives {{of this study were}} to measure EDW output factors for 6 MV and 20 MV photon energies for a Varian 2300 CD. Secondly, to review the literature in terms of published enhanced dynamic wedge output factors (EDWOF) for different Varian models and thereby add credence to the case of the validity of reference databases. The enhanced dynamic wedge output factors were measured for the Varian 2300 CD for both 6 MV and 20 MV photon energies. Twelve papers with published EDWOF for different Varian linac models were found in the literature. Comparing our results with the published mean, we found an excellent agreement for 6 MV EDWOF, with the percentage differences ranging from 0. 01 % to 0. 57 %, with a mean of 0. 03 %. The coefficient of variation of published EDWOF ranged from 0. 17 % to 0. 85 % and 0. 1 % to 0. 9 % for the for 6 MV and 18 MV photon energies, respectively. This paper provides the first published EDWOF for 20 MV photon energy. In addition, we have provided the first compendium of EDWOFs for different Varian linac models. The consistency of value across models and institution provide further support that a standard dataset of <b>basic</b> <b>photon</b> and electron dosimetry could be established as a guide for future commissioning, beam modeling, and quality assurance purposes. PACS numbers: 87. 50, 87. 5...|$|R
40|$|Until very {{recently}} Single Photon Avalanche Diodes (SPAD), which yield high detection efficiency in the visible spectrum, provided poor timing performance. This paper {{will review the}} current state of the SPAD technology and review new SPAD developments that provide: sub 50 ps-timing resolution, are stable with count rate, and yield high detection efficiency. Examples will be provided; comparing timing resolution of PMT’s and solid-state photon counting modules, effect of count rate on timing resolution, thus illustrating the stability of these newly developed SPAD’s. In addition, the paper will review the <b>basics</b> of <b>photon</b> counting using SPAD’s and illustrate how these SPAD’s are used in Time-Correlated Single Photon Counting (TCSPC) and the results from these experiments...|$|R
40|$|Our {{investigation}} into the spatial blur in optical recording consisted of a joint Monte Carlo simulation of photon scatter and absorption in cortical tissue and a diffractive optics model of the macroscope. The full details of our system have been presented elsewhere (1). Here we review the most relevant details of the system, and describe our quantitative analysis of cortical orientation maps. Monte Carlo Methods Monte Carlo techniques are the primary method for modeling the behavior of light in biological tissue. They were first applied in this context to modeling the interaction of laser light with tissue in medical applications {{for the assessment of}} damage during clinical laser ablation (2). The term Monte Carlo (3) refers to the use of a stochastic simulation to model physical processes. It is well understood and widely deployed. However, since the tissue ablation literature assumes the existence of a tightly collimated laser beam, and the current application requires examination of individual photon paths, we wrote a custom version of the <b>basic</b> <b>photon</b> scattering and absorption model in the MATLAB development environment (MathWorks, Natick, MA). Tissue optical Parameters There are four fundamental optical parameters required to accurately model photon propagation in a turbid medium such as visual cortex. These are the coefficient of absorption, µa, the coefficient of scatter, µs, the index of refraction, n, and the anisotropy constant, g. These parameters, except for the index of refraction, are significantly different in different types of tissue, and the model must account for this by using parameter values measured empirically for gray and white matter in the cerebral cortex. In this simulation, the optica...|$|R
5000|$|Noise is {{a random}} {{variation}} of image density, visible as grain in film and pixel level variations in digital images. It {{arises from the}} effects of <b>basic</b> physics— the <b>photon</b> nature of light and the thermal energy of heat— inside image sensors. Typical noise reduction (NR) software reduces the visibility of noise by smoothing the image, excluding areas near contrast boundaries. This technique works well, but it can obscure fine, low contrast detail.|$|R
40|$|This course {{serves as}} a {{practical}} guide to photon maps. Any reader who can implement a ray tracer {{should be able to}} add an efficient implementation of photon maps to his or her ray tracer after attending this course and reading the course notes. There are many reasons to augment a ray tracer with photon maps. Photon maps makes it possible to efficiently compute global illumination including caustics, diffuse color bleeding, and participating media. Photon maps can be used in scenes containing many complex objects of general type (i. e. the method is not restricted to tessellated models). The method is capable of handling advanced material descriptions based on a mixture of specular, diffuse, and non-diffuse components. Furthermore, the method is easy to implement and experiment with. This course is structured as a half day course. We will therefore assume that the participants have knowledge of global illumination algorithms (in particular ray tracing), material models, and radiometric terms such as radiance and flux. We will discuss in detail photon tracing, the photon map data structure, the <b>photon</b> map <b>radiance</b> estimate, and rendering techniques based on photon maps. We will emphasize the techniques for efficient computation throughout the presentation. Finally, we will present several examples of scenes rendered with photon maps and explain the important aspects that we considered when rendering each scene. Lecturer...|$|R
40|$|This slide {{presentation}} {{reviews the}} radiometric performance model for Airborne Visible/Infrared Imaging Spectrometer (AVIRIS). This model allows for an {{estimation of the}} signal throughput and noise properties of AVIRIS for the components. This understanding can point to areas for improvements of the components [...] The {{signal to noise ratio}} properties may be estimated. An accurate radiometric performance model is essential for the use of existing instruments and the design of new instruments. Included in the presentation is a design view and a picture of the AVIRIS instrument. There is discussion of the signal, the signal area solid angle product, aspects of area solid angle time, the idealized radiometer photon calculation and noise both instrument read and photon counting noise. Graphs of signal throughput efficiency, input <b>radiance,</b> <b>photons</b> at the detector, signal e-, noise e- and the signal to noise ratio are presented...|$|R
50|$|Monte Carlo {{simulations}} of photon transport, though time consuming, will accurately predict photon {{behavior in a}} scattering medium. The assumptions involved in characterizing photon behavior with the diffusion equation generate inaccuracies. Generally, the diffusion approximation is less accurate as the absorption coefficient μa increases and the scattering coefficient μs decreases.For a photon beam incident on a medium of limited depth, error due to the diffusion approximation is most prominent within one transport mean free path of the location of <b>photon</b> incidence (where <b>radiance</b> is not yet isotropic) (Figure 3).Among the steps in describing a pencil beam incident on a semi-infinite medium with the diffusion equation, converting the medium from anisotropic to isotropic (step 1) (Figure 4) and converting the beam to a source (step 2) (Figure 5) generate more error than converting from a single source {{to a pair of}} image sources (step 3) (Figure 6). Step 2 generates the most significant error.|$|R
40|$|Krolik (1989) {{pointed out}} that {{frequency}} redistribution due to scattering {{is more important than}} cosmological expansion in determining the Ly-alpha frequency profile during cosmological recombination, and that its effects substantially modify the rate of recombination. Although the first statement is true, the second statement is not: a <b>basic</b> symmetry of <b>photon</b> scattering leads to identical cancellations which almost completely erase the effects of both coherent and incoherent scattering. Only a small correction due to atomic recoil alters the line profile from the prediction of pure cosmological expansion, so that the pace of cosmological recombination can be well approximated by ignoring Ly-alpha scattering...|$|R
40|$|It is {{difficult}} to render caustic patterns at interactive frame rates. This paper introduces new rendering techniques that relax current constraints, allowing scenes with moving, non-rigid scene objects, rigid caustic objects, and rotating directional light sources to be rendered in real-time with GPU hardware acceleration. Because our algorithm estimates the intensity and the direction of caustic light, rendering of non-Lambertian surfaces is supported. Previous caustics algorithms have separated the problem into pre-rendering and rendering phases, storing intermediate results in data structures such as <b>photon</b> maps or <b>radiance</b> transfer functions. Our central idea is to use specially parameterized spot lights, called caustic spot lights (CSLs), as the intermediate representation of a twophase algorithm. CSLs are flexible enough that a small number can approximate the light leaving a caustic object, yet simple enough {{that they can be}} efficiently evaluated by a pixel shader program during accelerated rendering. We extend our approach to support changing lighting direction by further dividing the pre-rendering phase into per-scene and per-frame components: the per-frame phase computes frame-specific CSLs by interpolating between CSLs that were pre-computed with differing light directions...|$|R
40|$|AbstractNon-spherical {{particles}} in the atmosphere absorb and scatter solar radiation. They change the polarization state of solar radiation depending on their shape, size, chemical composition and orientation. To quantify polarization effects, a new three-dimensional (3 D) vector radiative transfer model, SPARTA (Solver for Polarized Atmospheric Radiative Transfer Applications) is introduced and validated against benchmark results. SPARTA employs the statistical forward Monte Carlo technique for efficient column-response pixel-based radiance calculations including polarization for 3 D inhomogeneous cloudless and cloudy atmospheres. A sensitivity study {{has been carried out}} and exemplarily results are presented for two lidar-based mineral dust fields. The scattering and absorption properties of the dust particles have been computed for spheroids and irregular shaped particles. Polarized radiance fields in two-dimensional (2 D) and one-dimensional (1 D) inhomogeneous Saharan dust fields have been calculated at 532 nm wavelength. The domain-averaged results of the normalized reflected radiance are almost identical for the 1 D and 2 D modes. In the areas with large spatial gradient in optical thickness with expected significant horizontal <b>photon</b> transport, the <b>radiance</b> fields of the 2 D mode differ by about ± 12 % for the first Stokes component (radiance, I) and ± 8 % for the second Stokes component (linear polarization, Q) from the fields of the 1 D mode...|$|R
40|$|Every GRB model {{where the}} {{progenitor}} {{is assumed to}} be a highly relativistic hadronic jet whose pions, muons and electron pair secondaries are feeding the gamma jets engine, necessarily (except for very fine-tuned cases) leads to a high average neutrino over <b>photon</b> radiant exposure (<b>radiance),</b> a ratio well above unity, though the present observed average IceCube neutrino radiance is at most comparable to the gamma in the GRB one. Therefore no hadronic GRB, fireball or hadronic thin precessing jet, escaping exploding star in tunneled or penetrarting beam, can fit the actual observations. A new model is shown here, based on a purely electronic progenitor jet, fed by neutrons (and relics) stripped from a neutron star (NS) by tidal forces of a black hole or NS companion, showering into a gamma jet. Such thin precessing spinning jets explain unsolved puzzles such as the existence of the X-ray precursor in many GRBs. The present pure electron jet model, disentangling gamma and (absent) neutrinos, explains naturally why there is no gamma GRB correlates with any simultaneous TeV IceCube astrophysical neutrinos. Rare unstable NS companion stages while feeding the jet may lead to an explosion simulating a SN event. Recent IceCube- 160731 A highest energy muon neutrino event with absent X-gamma traces confirms the present model expectations. Comment: 9 pages, 6 Figure...|$|R
40|$|We {{present and}} discuss {{perspectives}} on developing advanced quantum optical circuits monolithically integrated in the lithium niobate platform. A set of <b>basic</b> components comprising <b>photon</b> pair sources based on parametric down conversion (PDC), passive routing elements and active electro-optically controllable switches and polarisation converters are constituent {{parts of a}} toolbox which {{is the basis for}} a broad range of diverse quantum circuits. We discuss {{the state of the art}} of these components and present models that properly describe their performance in quantum circuits. As a demonstration of the applicability of these models we consider as an example an on-chip two-photon interference circuit comprising a PDC section for photon pair generation followed by an actively controllable modified Mach-Zehnder structure for detecting Hong-Ou-Mandel (HOM) interference. The performance of such a chip is simulated theoretically by taking even imperfections in the properties of the individual components into account...|$|R
40|$|Photon {{strength}} functions quantities, which describe deexcitation of nucleus by emiting {{gamma rays}} within statistical {{model of the}} nucleus. Information about these quantities can be gained from study of two-step gamma cascades. The thesis is focused on processing of experimental data from measurement of these cascades in 162 Dy nucleus. Data were acquired using experimental set-up istalled on the research reactor in Řež near Prague. In the experiment the 161 Dy targed was bombarded by thermal neutrons. Following gamma deexcitation of 162 Dy nucleus was measured by coincident spectrometer composed of two semi-conductor detectors. The aim of the thesis is to perform energy and efficiency calibration and to process experimental data into the form of two-step gamma cascades spectra. In adition, a comparsion of the two-step cascades spectra with the outcome of simulations of a few <b>basic</b> models of <b>photon</b> strength functions is made...|$|R
40|$|Aim: {{the study}} of the {{physical}} effect of the local dose increasing in biological tissue at the gadolinium-containing drug under the influence of X-ray radiation. Material and Methods. Experimental and three independent numerical methods are obtained distribution of the absorbed dose in tissue-equivalent phantom containing a model of the tumor with a given concentration of gadolinium. Results. The presence of a gadolinium-containing drug in the biological tissue (1 % Gd by weight) leads to a local increase of an absorbed dose up to 2 times under the influence of X-ray radiation. The difference in the results obtained calculated and experimental methods does not exceed 12 %. Conclusion. The results of the study confirmed the <b>basic</b> theoretical background <b>photon</b> capture therapy, as well as the legal use of methods of mathematic modeling of the process of forming radiation in biological tissue, necessary for dosimetric photon capture therapy planning...|$|R
40|$|Aims: We {{investigate}} photon quenching in compact non-thermal sources. This involves photon-photon annihilation and lepton {{synchrotron radiation}} {{in a network}} that can become non-linear. As a result the gamma-ray luminosity of a source cannot exceed a critical limit that depends only on the radius of the source and on the magnetic field. Methods: We perform analytic and numerical calculations that verify previous results and extend them so that the <b>basic</b> properties of <b>photon</b> quenching are investigated. Results: We apply the above to the 2006 TeV observations of quasar 3 C 279 and obtain the parameter space of allowed values for the radius of the emitting source, its magnetic field strength and the Doppler factor of the flow. We argue that the TeV observations favour either a modest Doppler factor and a low magnetic field or a high Doppler factor and a high magnetic field. Comment: 10 pages, 12 figures, accepted for publication in Astronomy and Astrophysic...|$|R
40|$|The {{study of}} photon {{interaction}} with different composite materials {{has become a}} topic of prime importance for radiation physicists. Some parameters of dosimetric interest are the mass attenuation coefficient, effective atomic number, and electron density; these help in the <b>basic</b> understanding of <b>photon</b> interactions with composite materials. The photon interaction parameters such as mass attenuation coefficient (μ/ρ), effective atomic number (Z eff), and effective electron density (N el) must be identical for the phantom material and their tissue. In the present study, we have evaluated the photon interaction parameters such as (μ/ρ), Z eff and N el of 13 lung tissue substitutes. The variations of these parameters of lung tissue substitutes with photon energy are graphically represented. The photon interaction parameters of lung tissue substitutes are {{compared with that of}} lung tissue. The variation of photon interaction parameters of the studied lung tissue substitutes is similar that of the lung. Logically, it can be shown that Alderson lung is good substitute for lung than the other substitutes...|$|R
30|$|As we know, HgCdTe (MCT) ternary {{compound}} {{is one of}} the <b>basic</b> semiconductors for <b>photon</b> detectors from NWIR to LWIR spectral range [16] that can absorb IR radiation over a broad range of wavelengths due to a change in the bandgap from 0 to 1.6  eV related to the change in the composition. The ability to detect sub-terahertz radiation by MCT-based structures is also discussed [17, 18]. Commonly used method for the fabrication of the IR devices based on MCT {{ternary compound}} is an ion implantation. An implant, getting into the epitaxial layer, initiates an active restructuring of the defect structure of MCT, which changes the epilayer carrier type. As a result, n-on-p (boron-implanted) [19] and p-on-n (arsenic-implanted) [20] photodiodes are fabricated. At the same time, {{it is well known that}} ion implantation induces mechanical stress in MCT layers, which is a matter of paramount importance for solid-state devices, and has been exploited to improve their electrical and optical properties. It was shown that implantation-induced stress is an important factor influencing the depth of p-n junctions in MCT-based structures [21].|$|R
40|$|Annual {{simulation}} is {{a significant}} indicator of a daylight redirecting component's per- formance, since it accounts for seasonal variations in daylight availability {{as well as the}} system's response under such conditions. This study details the simulation of a representative redirecting component using a 3 D forward raytracing technique to assess its annual daylighting performance. We streamline and largely automate this work ow with the EvalDRC tool, a Python script whichimplements a simulation frontend based on the <b>Radiance</b> <b>photon</b> map, coupled to a postprocessing and evaluation backend. The redirecting component selected for our case study combines retroreflection with redirection and is designed for optimal daylight availability over the entire year without the need for adjustment. The lamella profile can be mounted in a forward and reversed configuration to combine retroreflection with redirection in the lower resp. upper portions of the fenestration. We evaluate our simulations visually and numerically as high dynamic range (HDR) renderings and a spatial daylight autonomy (sDA) metric based on climate based sky distributions for Geneva, Switzerland. Our case study satisfies the sDA requirement that 55 % of the workplane receives an illuminance exceeding 300 lux during 50 % or more of the occupancy hours for a whole year. In addition, we propose the msDA, a detailed monthly breakdown of the sDA, for which the criteria are specifically met in the months March{September, while a minimum of 32 % is predicted for December. Our results demonstrate the effectiveness of photon mapping for this application, and that the simulation accurately predicts the redirecting component's expected seasonal behaviour for multiple solar angles and sky configurations. This applies in particular to complex redirecting systems which cannot be reliably simulated with a backward raytracer at reasonable computational cost...|$|R
40|$|The {{radiative}} transfer equation (RTE) is a mathematical description of radiative {{gains and losses}} experienced by a propagating electromagnetic wave in a participating medium. Except for an isotropic lossless vacuum, all other volumes {{have the potential to}} scatter, absorb and emit radiant energy. Of these possible events, the global scattering term is the greatest obstacle between a {{radiative transfer}} problem and its solution. Historically, the RTE has been solved using a host of analytical approximations and numerical methods. Typical solution models exploit plane-parallel assumptions where it is assumed that optical properties may vary vertically with depth, but have an infinite horizontal extent. For more complicated scenarios that include pronounced 3 D variability, a Monte Carlo statistical approach to the radiative transfer solution is often utilized. This statistical approach has been integrated within the Digital Imaging and Remote Sensing Image Generation (DIRSIG) model in the form of photon mapping. Photon mapping provides a probabilistic solution to the in-scattered radiance problem, by employing a two-pass technique that first populates a photon map based on a Monte Carlo solution to the global scattering term, and then later uses this map to reconstruct the in-scattered radiance distribution during a traditional raytracing pass. As with any computational solution, the actual implementation of the technique requires assumptions, simplifications and integration within a cohesive rendering model. Moreover, the realistic simulation of any environment requires several other radiometric solutions that are not directly related to the <b>photon</b> mapped in-scattered <b>radiance.</b> This research attempts to validate raytraced and photon mapped contributions to sensor reaching radiance that can be expected in typical littoral environments, including boundary interface, medium and submerged or floating object effects. This is accomplished by comparing DIRSIG modeled results to those predicted analytically, by comparison to other numerical models, and by comparison to observed field phenomenology. When appropriate, first-order estimates of a computational solution 2 ̆ 7 s ability to render a given phenomenon are provided, including any variance or bias that may result {{as a function of the}} user-specified solution configuration...|$|R
40|$|Today {{electronic}} portal imaging devices (EPID's) {{are used}} primarily to verify patient positioning. They have, however, also the potential as 2 D-dosimeters {{and could be}} used as such for transit dosimetry or dose reconstruction. It has been proven that such devices, especially liquid filled ionization chambers, have a stable dose response relationship which can be described in terms of the physical properties of the EPID and the pulsed linac radiation. For absolute dosimetry however, an accurate method of calibration to an absolute dose is needed. In this work, we concentrate on calibration against dose in a homogeneous water phantom. Using a Monte Carlo model of the detector we calculated dose spread kernels in units of absolute dose per incident energy fluence and compared them to calculated dose spread kernels in water at different depths. The energy of the incident pencil beams varied between 0. 5 and 18 MeV. At the depth of dose maximum in water for a 6 MV beam (1. 5 cm) and for a 18 MV beam (3. 0 cm) we observed large absolute differences between water and detector dose above an incident energy of 4 MeV but only small relative differences in the most frequent energy range of the beam energy spectra. It is shown that for a 6 MV beam the absolute reference dose measured at 1. 5 cm water depth differs from the absolute detector dose by 3. 8 %. At depth 1. 2 cm in water, however, the relative dose differences are almost constant between 2 and 6 MeV. The effects of changes in the energy spectrum of the beam on the dose responses in water and in the detector are also investigated. We show that differences larger than 2 % can occur for different beam qualities of the incident photon beam behind water slabs of different thicknesses. It is therefore concluded that for high-precision dosimetry such effects have to be taken into account. Nevertheless, the precise information about the dose response of the detector provided in this Monte Carlo study forms the basis of extracting directly the <b>basic</b> radiometric quantities <b>photon</b> fluence and photon energy fluence from the detector's signal using a deconvolution algorithm. The results are therefore promising for future application in absolute transit dosimetry and absolute dose reconstruction...|$|R
40|$|Causality {{dictates}} that all physical media must be dispersive. (We will call a medium dispersive if its refractive index varies with frequency.) Ordinarily, strong dispersion is accompanied either by strong absorption or strong gain. However, {{over the past}} 15 years several groups have demonstrated {{that it is possible}} to have media that are both strongly dispersive and roughly transparent for some finite bandwidth. In these media, group and phase velocities may differ from each other by many orders of magnitude and even by sign. Relationships and intuitive models that are satisfactory when it is reasonable to neglect dispersion may then fail dramatically. In this dissertation we analyze three such cases of failure. Before looking at the specific cases, we review some basic ideas relating to dispersion. We review some of the geometric meanings of group velocity, touch on the relationship between group velocity and causality, and give some examples of techniques by which the group velocity may be manipulated. We describe the interplay between group velocity and energy density for non-absorbing dispersive media. We discuss the ideas of temporary absorption and emission as dictated by an instantaneous spectrum. We then apply these concepts in three specific areas. First, non-dispersive formulations for the momentum of light in a medium must be adjusted to account for dispersion. For over 100 years, there has been a gradual discussion of the proper form for the per-photon momentum. Two forms, each of which has experimental relevance in a 'dispersionless' medium, are the Abraham momentum, and the Minkowski momentum. If ω is the angular frequency, n is the refractive index, ħ is Planck's constant, and c is the speed of light, then these reduce in a dispersionless medium to per-photon momenta of ħω/(nc), and nħω/c respectively. A simple generalization of the two momenta to dispersive media entails multiplying each per-photon momentum by n/n_g, where n_g is the group refractive index. The resulting forms are experimentally relevant for the case of the Abraham momentum, but not for the Minkowski momentum. We show how dispersion modulates the displacement of a sphere embedded in a dispersive medium by a pulse. Second, pulse transformation in a nonstationary medium is modulated by the presence of dispersion. Dispersion may enhance or mitigate the frequency response of a pulse to a changing refractive index, and if dispersion changes with time, the pulse bandwidth must change in a compensatory fashion. We introduce an explicit description of the kinetics of dispersive nonstationary inhomogeneous media. Using this description, we show how the group velocity can modulate the frequency response to a change in the refractive index and how Doppler shifts may become large in a dispersive medium as the velocity of the Doppler shifting surface approaches the group velocity. We explain a simple way to use existing technology to either compress or decompress a given pulse, changing its bandwidth and spatial extent by several orders of magnitude while otherwise preserving its envelope shape. We then introduce a dynamic descriptions of two simple media [...] one dispersive and one nondispersive. We compare the transformation of <b>basic</b> quantities like <b>photon</b> number, momentum density, and frequency by a temporal change in the refractive index in a specific non-dispersive medium to those wrought by a temporal change in the group refractive index in a specific dispersive medium. The differences between the media are fundamental and emphasize the salience of dispersion in the study of nonstationary media. Finally, we note that the nature of a single optical cavity quasimode depends on intracavity dispersion. We show that the quantum field noise associated with a single cavity mode may be modulated by dispersion. For a well-chosen mode in a high-Q cavity, this can amount to either an increase or a decrease in total vacuum field energy by several orders of magnitude. We focus on the "white light cavity", showing that the quantum noise of an ideal white light cavity diverges as the cavity finesse improves. Los Alamos National Laboratory Laboratory Directed Research and Development ProgramOptical Science and EngineeringDoctoralUniversity of New Mexico. Dept. of Physics & AstronomyDeutsch, Ivan H. Milonni, Peter W. Prasad, SudhakarSheik-Bahae, Mansoo...|$|R

