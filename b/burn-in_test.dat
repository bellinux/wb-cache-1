19|36|Public
5000|$|Test {{engineers}} can have different expertise which {{depends on what}} test process they are more familiar with (although many test engineers have full familiarity from the PCB level processes like ICT, JTAG, and AXI) to PCBA and system level processes like board functional test (BFT or FT), <b>burn-in</b> <b>test,</b> system level test (ST). Some of the processes used in manufacturing where a test engineer is needed are: ...|$|E
40|$|Increase in {{leakage current}} with {{technology}} scaling {{has been a}} major problem for IC technology. This problem becomes more crucial during <b>burn-in</b> <b>test</b> where stressed voltage and temperature are applied. Due to presence of a positive feedback between major components of leakage and temperature in CMOS circuits, excessive leakage may lead to thermal runaway and yield loss during burnin test. This paper describes a novel integrated leakage control system to ensure thermal stability during <b>burn-in</b> <b>test</b> {{for a wide range of}} ambient temperatures and process variations. 1...|$|E
40|$|<b>Burn-in</b> <b>test</b> is a {{manufacturing}} procedure implemented {{to identify and}} eliminate units with infant mortality before they are shipped to the customers. The traditional <b>burn-in</b> <b>test,</b> collecting event data over {{a short period of}} time, is rather inefficient. This problem can be solved if there is a suitable quality characteristic (QC) whose degradation over time can be related to the lifetime of the product. Optimal burn-in policies have been discussed in the literature assuming that the underlying degradation path follows a Wiener process or a gamma process. However, the degradation paths of many products may be more appropriately modeled by an inverse Gaussian process which exhibits a monotone increasing pattern. Here, motivated by the numerous merits of the inverse Gaussian process, we first propose a mixed inverse Gaussian process to describe the degradation paths of the products. Next, we present a decision rule for classifying a unit as typical or weak. A cost model is used to determine the optimal burn-in duration and the optimal cut-off level. A simulation study is carried out to illustrate the proposed procedure. Department of Applied Mathematic...|$|E
50|$|The {{compound}} is used {{in larger}} quantities in several electronic applications, such as liquid <b>burn-in,</b> <b>testing,</b> environmental stress screening and vapor phase soldering processes {{as well as an}} indicator fluid in leak testing and as a heat transfer fluid for thermal shock testing.|$|R
50|$|The scanner (Figure 2) is used {{to connect}} {{multiple}} inputs to a single output in sequential order. Only one relay is closed at any one time. In its most basic form, relay closure proceeds from the first channel to the last, but some scanner systems allow skipping channels. Typical scanner switching applications include component <b>burn-in</b> <b>testing,</b> monitoring time and temperature drift in circuits, and taking data on system variables like temperature, pressure, flow, etc.|$|R
40|$|Semiconductor device {{junction}} {{temperatures are}} maintained within datasheet specified limits to avoid failure in power converters. <b>Burn-in</b> <b>tests</b> {{are used to}} ensure this. In inverters, thermal time constants can be large and <b>burn-in</b> <b>tests</b> are required to be performed over long durations of time. At higher power levels, besides increased production cost, the testing requires sources and loads that can handle high power. In this study, a novel method to test a high power three-phase grid-connected inverter is proposed. The method {{eliminates the need for}} high power sources and loads. Only energy corresponding to the losses is consumed. The test is done by circulating rated current within the three legs of the inverter. All the phase legs being loaded, the method can be used to test the inverter in both cases of a common or independent cooling arrangement for the inverter phase legs. Further, the method can be used with different inverter configurations - three- or four-wire and for different pulse width modulation (PWM) techniques. The method has been experimentally validated on a 24 kVA inverter for a four-wire configuration that uses sine-triangle PWM and a three-wire configuration that uses conventional space vector PWM...|$|R
40|$|Power {{converters}} <b>burn-in</b> <b>test</b> consumes {{large amount}} of energy, which increases the cost of testing, and certification, in medium and high power application. A simple test configuration to test a PWM rectifier induction motor drive, using a Doubly Fed Induction Machine (DFIM) to circulate power back to the grid for <b>burn-in</b> <b>test</b> is presented. The test configuration makes use of only one power electronic converter, which is the converter to be tested. The test method ensures soft synchronization of DFIM and Squirrel Cage Induction Machine (SCIM). A simple volt per hertz control of the drive is sufficient for conducting the test. To synchronize the DFIM with SCIM, the rotor terminal voltage of DFIM is measured and used {{as an indication of}} speed mismatch between DFIM and SCIM. The synchronization is done when the DFIM rotor voltage is at its minimum. Analysis of the DFIM characteristics confirms that such a test can be effectively performed with smooth start up and loading of the test setup. After synchronization is obtained, the speed command to SCIM is changed in order to load the setup in motoring or regenerative mode of operation. The experimental results are presented that validates the proposed test method...|$|E
40|$|For {{more than}} three decades, {{aggressive}} scaling of transistor dimensions {{has been successful in}} achieving higher performance and increased functionality in CMOS IC technology. However, the increasing contribution of leakage power has been a major problem. Moreover, due to higher and non-uniform die temperatures caused by increasing power consumption, thermal aware circuit design has become essential in order to improve the robustness and thermal stability of circuits. Furthermore, as the process parameters (such as channel length, width, oxide thickness, number and location of dopant atoms) suffer large fluctuations due to limitations in the fabrication process and shrinking device geometries in scaled technologies, the robustness of circuits has degraded significantly. As a result, process variation aware circuit design has become crucial to improve parametric yield. ^ In this research, we first address <b>burn-in</b> <b>test</b> where increased voltages and temperatures are applied to weed out defective devices. Due to the strong temperature dependence of leakage, leakage control during burn-in is required for thermal stability and thermal runaway prevention. We developed two circuit design techniques that ensure thermal stability during <b>burn-in</b> <b>test</b> under process parameter variations. ^ Second, a detailed thermal analysis is performed on the performance, robustness and stability of embedded cache memories (such as SRAM and eDRAM). ^ Finally, two process variation sensors are developed in order to characterize local random process variations for improved yield and process optimization. By utilizing sub-threshold region of operation, both sensors feature ultra-low power and high sensitivity without the need for any bias circuitry. ...|$|E
40|$|Includes bibliographical {{references}} (page 29) Field Programmable Gate Array (FPGA) {{technology has}} introduced and opened new domains in electrical and engineering field {{due to its}} performance, reliability, flexibility, long-term maintenance, cost, and time to market. FPGAs have been utilized across most industries such as commercial, military, aerospace, and medical devices. The objective of this project is to establish an automated dynamic test platform to test Xilinx reprogrammable Virtex- 4 FPGAs while the FPGA is being stressed (under 125 degree C temperature). This temperature stress test is called <b>burn-in</b> <b>test.</b> Most FPGA resources e. g. CLBs, Block-RAM, DSP??? are exhaustively tested. The main goal of <b>burn-in</b> <b>test</b> is to detect defective components at {{the early stages of}} their usage by stressing the chips at high voltage and temperatures while the FPGA is powered and performing its customized functions. The unit under test (UUT) is placed inside a chamber while test-vectors are applied through a serial communication (RS- 232) to the FPGA board. The test response is compared with an expected golden-copy of the response by an automated software platform. The may lead to detection of possible discrepancy (fault) between the chip on the FPGA board and the expected response (Gold Copy), and associated error in the FPGA is stored into an XML/Database system to generate further report. In this project, all the information is stored in XML (Extensible Markup Language) file format due to benefit such as ability to communicate between different systems, clear defined set of standards, forming a tree structure where it start at the root and branches to the leaves and to the lowest level of the tree. This attribute makes it possible to divide and break hardware specification into smaller pieces of information while keeping track of a logical relationship of all pieces...|$|E
5000|$|... 2012.11, Alliance Fiber Optic Products, Inc. {{introduced}} {{a line of}} MPO Fiber Optic Loopback Assemblies for <b>burn-in</b> and <b>testing</b> transmitter capability and receiver sensitivity of MPO network components and systems.|$|R
40|$|The quality {{assurance}} system for semi-industrial production scale of multichip hybrid circuits is presented. The hybrids are parts of the silicon strip detector modules of the Semiconductor Tracker (SCT) of the forthcoming ATLAS detector. The edcap hybrid houses the readout and data transmission ASICs, providing the full functionality needed for binary readout of double-sided silicon strip detector modules. The hybrids are assembled in the industry using pretested components. The full {{quality assurance}} testing, including visual inspection, electrical <b>testing</b> and <b>burn-in</b> <b>tests,</b> is performed in the institutes of the SCT collaboration. The testing procedures and test results are presented. I...|$|R
40|$|Currently, the ALICE DCS {{project is}} supervising {{equipment}} {{installed in the}} ALICE experiment site at CERN. Hence, {{the aim of this}} project was to provide a test bench in the DCS lab, where a real equipment and software tools will be deployed. Using this test bench, test procedures which exercise the devices under the test in a configurable way and provide logging and trending of the acquired data were implemented. The setup was devised using the ALICE software framework and Siemens SCADA system WINCC OA, providing the same functionality as the systems installed in ALICE, and will be used for the commissioning of the new software and hardware, <b>burn-in</b> <b>tests</b> of new modules and log-term stability tests of ALICE hardware...|$|R
40|$|Abstract- We {{propose a}} novel method that {{exploits}} BTI to partially offset variation and thus improve SRAM Vmin and yield. We show correlation between a bitcell’s power-up {{state and its}} static noise margin. By applying stress with periodic re-power-up, device mismatch can be compensated by BTI induced changes. The proposed method has no extra design and area cost. It can be applied during <b>burn-in</b> <b>test</b> to offset manufacturing variation and/or used during the lifetime of the chip to offset variation from real-time aging and hence continue to improve the margins. Simulations in 45 nm show that write, read, and hold Vmin at 6 σ can be reduced by 128, 75, and 91 mV, respectively. Measurements from a 16 Kb 45 nm SRAM demonstrate the improvement of Vmin and yield...|$|E
40|$|Homogeneous manycore {{systems that}} contain {{a large number}} of {{structurally}} identical cores are emerging for tera-scale computation. To ensure the required quality and reliability of such complex integrated circuits before supplying them to final users, extensive manufacturing tests need to be conducted and the associated test cost can account for a great share of the total production cost. By introducing spare cores on-chip, the <b>burn-in</b> <b>test</b> time can be shortened and the defect coverage requirements for core tests can be also relaxed, without sacrificing quality of the shipped products. The above test cost reduction is likely to exceed/compensate the manufacturing cost of the extra cores, thus reducing the total production cost of manycore systems. We develop novel analytical models that capture the above tradeoff in this paper and we verify the effectiveness of the proposed test economics model for hypothetical manycore systems with various configurations. ...|$|E
40|$|The LHCb {{experiment}} has {{a dedicated}} vertex detector (VELO) {{to measure the}} particle's tracks close to the interaction point. This paper describes the main steps of the quality assurance tests performed during assembly, reception and installation of the LHCb VELO modules. Visual in-spection, electrical tests, thermal tests and metrology measurements were made. A <b>burn-in</b> <b>test</b> of the modules was performed in a vacuum environment {{similar to that of}} the LHCb experiment. The signal to noise of the sensors was estimated to be 20. 4 3. 0 for R sensors and 22. 4 3 0 for Φ sensors. The modules were tested up to 350 V and the leakage current of the modules did not exceed 20 µA at any stage of the testing. Only 0. 6 % of channels were found to be noisy or not fully functional. The acceptable operating pressures of the modules in vacuum was also evaluated...|$|E
40|$|Abstract- Dynamic <b>burn-in</b> <b>testing</b> is an {{integral}} component of any test plan that seeks to produce reliable integrated circuits. Despite its importance in ensuring the reliability of semiconductors, burn-in {{has been a major}} contributor to overall test cost and turnaround time. In this work we discuss the application of advanced Boolean satisfiability (SAT) techniques to generate a set of vectors or input stimuli that increases the nodal activity in the circuit and hence the elevation of its temperature. The vectors are designed to uniformly stress all parts of the circuit. Additionally, we present a SAT-based methodology where weak nodes can selectively be targeted for high switching activity in an effort to detect potential failures. Finally, SAT-based solvers are compared against generic Integer Linear Programming (ILP) solvers when handling the vector generation problem...|$|R
50|$|Reliability {{testing is}} common in the Photonics industry. Examples of {{reliability}} tests of lasers are life <b>test</b> and <b>burn-in.</b> These <b>tests</b> consist of the highly accelerated ageing, under controlled conditions, {{of a group of}} lasers. The data collected from these life tests are used to predict laser life expectancy under the intended operating characteristics.|$|R
40|$|Motivated by two real-life examples, {{this article}} {{develops}} a burn-in planning framework with competing risks. Existing approaches to planning <b>burn-in</b> <b>tests</b> {{are confined to}} a single failure mode {{based on the assumption}} that this failure mode is subject to infant mortality. Considering the prevalence of competing risks and the high reliability of modern products, our framework differentiates between normal and infant mortality failure modes and recommends degradation-based burn-in approaches. This framework is employed to guide the burn-in planning for an electronic device subject to both a degradation- threshold failure, which is an infant mortality mode and can be modeled by a gamma process with random effect, and a catastrophic mode, which is normal and can be represented with a conventional reliability model. Three degradation-based burn-in models are built and the optimal cutoff degradation levels are derived. Their validity is demonstrated by an electronic device example. We also propose three approaches to deal with uncertainty due to parameter estimation. Algorithmic details and proofs are provided in supplementary material online. 漏 2012 American Statistical Association and the American Society for Quality...|$|R
40|$|Yield and {{reliability}} are two factors affecting {{the profitability of}} semiconductor manufacturing. High-temperature burn-in and extreme-voltage stress tests are two current industrial standard methods {{to speed up the}} deterioration of electronic devices and weed-out infant mortality. Extreme-voltage stress test aims at enhancing both quality {{and reliability}} without performance the high-cost <b>burn-in</b> <b>test</b> process. Our recent stress tests of analog/mixed–signal CMOS ICs for gate-oxide reliability enhance. This paper presents a control flow model for analog CMOS circuits and uses it to develop a circuit partition scheme. A practically large analog circuit can be partitioned into many smaller sub-circuits so that the developed stress vector generator and stressability analyzer can conformably handle in term of computational complexity. In addition, a structure-based stress vector generation process is also developed. Stress vectors are generated based on the circuit topological structure without performing circuit simulations. The performance improvement proposed in this study can significantly reduce the computational complexity so that the developed stress test system can handle practically large analog CMOS circuits...|$|E
40|$|Abstract—The {{employment}} {{of a large}} number of structurally identical cores on a single silicon die is generally regarded as a promising solution for tera-scale computation, known as manycore chips. To ensure the product quality of such complex integrated circuits before shipping them to final users, extensive manufacturing tests are necessary and the associated test cost can account for a large share of the total production cost. By introducing spare cores on-chip, the <b>burn-in</b> <b>test</b> time can be shortened and the defect coverage requirements for core tests can be also relaxed, without sacrificing quality of the shipped products. If the above test cost reduction exceeds the manufacturing cost of the extra cores, the total production cost of manycore chips can be reduced. In this paper, we develop novel analytical models to study the above tradeoff and we verify the effectiveness of the proposed test economics model for hypothetical manycore chips with various configurations. Index Terms—Analytical model, manycore chip, product quality test economics. I...|$|E
40|$|This paper {{describes}} {{the problem of}} increasing the reliability of electronic components (EC) used for the fabrication of high-tech products. Two main ways of solving the problem are considered based on analysis of published data. One approach is rejection of EC at the input control using special testing methods combined with <b>burn-in</b> <b>test</b> program. This testing reveals components with “hidden defects”, counterfeit parts and components with incompatible construction materials with {{both internal and external}} service conditions. The other approach considers the feature of creating EC with nanoscale parameters. In this case the modular principle is applied for the design of devices that allows significantly reducing the loads on single elements and malfunction of a discrete module causes its disconnection from the scheme followed by reconfiguration of the EC structure. We show that in general the problem of increasing reliability is a complex task related to developing an optimum structure of IC elements, informed choice of materials, testing and optimization of circuit solutions...|$|E
40|$|The {{paper is}} {{concerned}} with the design & construction of a regenerative load that redirects the electrical energy used for testing back to the grid instead of wasting it as heat. Manufacturers of DC supply equipment, such as DC power supplies and battery management units, apply <b>burn-in</b> <b>testing</b> at full load for 24 hours to detect early failures and reliability issues. The power drawn during full-load testing of DC supply equipment is normally dissipated into heat through resistive loads. The regenerative load has a very wide input voltage range to be able to test various models of DC supply equipment. The regenerative load consists of an efficient wide input voltage range DC-DC converter and a grid-connected inverter. This system will allow the energy drawn from the equipment under test to be fed back to the grid. The only energy consumed corresponds to the losses within the system. Bajada New Energy Ltd., CD Power Saving Co. Ltd., Energy Investment Co. Ltd., Solar Engineering Ltd. & Solar Solutions Ltd. peer-reviewe...|$|R
40|$|The paper {{presents}} {{the design of}} an active load for electronic welding machines. The active load’s main purpose {{is to reduce the}} amount of electrical energy that is wasted during the welding equipment <b>burn-in</b> <b>tests,</b> allowing a large fraction of it to be re-circulated through the utility grid. The converter needs to operate with low input voltages, typically a few tens of Volts, and high input currents, up to 250 Amperes. In addition, it has to guarantee galvanic isolation and a relatively large step-up ratio, so as to allow active power injection into the grid. To comply with these requirements, a multi stage solution is devised. The paper discusses the design choices, the sizing procedure and the control strategy of the more critical converter component, i. e. the stepup, front-end stage. This is represented by a six phase interleaved boost converter, operating in discontinuous conduction mode (DCM). To demonstrate the validity of the implemented solutions, experimental results from a full power prototype of the dc-dc converter are provided...|$|R
40|$|The {{excellent}} {{dielectric properties}} of saturated fluorocarbons have allowed {{their use in}} direct immersion liquid cooling of electronics, including supercomputers and as heat transfer media in vapour phase soldering and <b>burn-in</b> <b>testing</b> of electronics. Their high density, UV transparency, non-flammability, non-toxicity and radiation tolerance have led to their use as liquid and gas radiator media for RICH detectors in numerous particle physics experiments. Systems to circulate and purify saturated fluorocarbon Cherenkov radiator vapours often rely on thermodynamic evaporation-condensation cycles {{similar to those used}} in refrigeration. Their use as evaporative refrigerants was pioneered for the ATLAS silicon tracker, and they are now also used as evaporative coolants in ALICE and TOTEM and as liquid coolants in ATLAS and CMS. Ultrasonic techniques for vapour phase analysis of fluorocarbon mixtures - developed for the SLAC SLD barrel CRID radiator during the 1980 s as an alternative to UV refractometry are again under development for the ATLAS tracker evaporative cooling system. Examples of fluorocarbon circulation systems, together with purification and analysis techniques for these versatile fluids are mentioned...|$|R
40|$|Includes bibliographical {{references}} (leaf 40) Association of Xilinx {{with the}} Aerospace and Defense Community has been long. Xilinx have come-up with products that combine commercial grade to space grade, radiation tolerant FPGAs, Aerospace &Defense focused intellectual property (IP) for applications ranging from image processing to waveform generation, and advanced technology such as partial reconfiguration for software defined radios. Challenges for introducing FPGA's in Space: To achieve high performance and integration without incurring the costs, risk, and long development times of ASICs, FPGA's provides a most reasonable alternative. To implement hardware changes {{late in the}} design cycle and ensuring reliable operation in high radiation environment, several techniques {{have been developed to}} help in predicting the reliability of these devices. As a result, these FPGA chips are subjected to different kinds of tests to find the efficiency of the internal logic and the immunity to different effects in adverse environments. One of these tests performed is the dynamic <b>burn-in</b> <b>test</b> to find out defects in these chips at the early life of their usage. The idea is to stress these chips at high voltages and temperatures (around l 25 ???C) while powered on and configured to perform ce 1 iain functions to extract inefficient parts within a specific time. The objective of this project is to design and implement a dynamic <b>burn-in</b> <b>test</b> platform that can qualify Xilinx Virtex 4 LX- 200 FPGA for aerospace and defense use. This test will be used to weed out infant m 01 iality due to manufacturing defects. In this system, the unit under test (UUT FPGA) is tested under high temperature by placing it in an oven at 125 ???C while it is powered on and configured to perform certain pre-defined tasks. Burn In is the process by which components of a system is stressed before being assembled in a final top level system. Burn in will detect components that may fail by accelerating the bathtub curve of component reliability. Components that pass burn in can then be placed or assembled into a larger system. Hence thereby we can test the FPGA dynamically...|$|E
40|$|The burn-in {{can be used}} {{to reduce}} {{warranty}} costs, particularly for products with an initially high failure rate that are sold under warranty. Because previous studies seldom account for burn-in error factors, this study consider such factors in our model to obtain an optimal burn-in time that corresponds more closely with reality. This study focuses on a <b>burn-in</b> <b>test</b> carried out on SDRAM products for the purpose of obtaining reliability and optimal burn-in time and test costs. This study will analyze and validate the data acquired from a life test to determine the types of distributions. The empirical analysis results of this study show that the lifetime of SDRAM products conforms to a Weibull distribution. If the lifetime of an SDRAM product is estimated under such a distribution, a cumulative failure of about 6799 ppm is acquired when the product is operated for one year under normal conditions which is much higher than goal of 100 ppm; thus for the SDRAM products used in this study, the execution of a burn-in is necessary...|$|E
40|$|Simulated {{electrostatic}} discharges (ESD) {{according to the}} human body model (HBM) and the charged device model (CDM) were compared {{in their ability to}} reproduce a leakage degradation observed in the field. Only CDM successfully reproduced the electrical and the physical failure signature in the input inverter of the active circuitry. A homebuilt CDM-tester was used to degrade a significant number of input pins for a reliability or latency study. An experimental investigation of the impact of this degradation on reliability showed that the degraded devices are latently damaged. They have input leakage currents still within specification, but show a highly increased sensitivity to electrical overstress and to ESD stress according to the human body model with a 100 per cent correlation to the CDM degradation. A standard <b>burn-in</b> <b>test</b> showed that they can cause early failures. The degradation is caused by a damage in the gate oxide of an input transistor, and the latent failure is caused by a 'breakdown' of the damaged oxide. Latency was shown to appear systematically...|$|E
40|$|Abstract- The growing {{size and}} {{complexity}} of VLSI circuits have made quality and reliability requirements increasingly stringent. The work {{presented in this paper}} investigates the application of Boolean Satisfiability (SAT) -based techniques to address two distinct VLSI testing activities, namely, test vector generation to excite stuck-open faults in CMOS circuits, and test vector generation for dynamic <b>burn-in</b> <b>testing.</b> The presence of a stuck-open fault renders an otherwise combinational logic gate sequential, therefore causing a malfunction of the integrated circuit. On the other hand, burn-in screening has been an integral part of semiconductors manufacturing to assure that reliability goals are achieved. The purpose of this type of testing is to apply to the device under test a set of input patterns which maximizes the circuits nodal activity, and by so doing causing an increase in its power dissipation that leads to device failures like electromigration and hot-carrier degradation at an early stage of the device operation. The search for input or test patterns to either excite a stuckopen fault, or to maximize the activity in the circuit is an NPcomplete problem. In this work, we discuss the applicability of SAT methodologies in tackling these two testing problems. W...|$|R
40|$|The growing {{size and}} {{complexity}} of VLSI circuits have made quality and reliability requirements increasingly stringent. The work {{presented in this paper}} investigates the application of Boolean Satisfiability (SAT) -based techniques to address two distinct VLSI testing activities, namely, test vector generation to excite stuck-open faults in CMOS circuits, and test vector generation for dynamic <b>burn-in</b> <b>testing.</b> The presence of a stuck-open fault renders an otherwise combinational logic gate sequential, therefore causing a malfunction of the integrated circuit.  On the other hand, burn-in screening has been an integral part of semiconductors manufacturing to assure that reliability goals are achieved. The purpose of this type of testing is to apply to the device under test a set of input patterns which maximizes the circuits nodal activity, and by so doing causing an increase in its power dissipation that leads to device failures like electromigration and hot-carrier degradation at an early stage of the device operation. The search for input or test patterns to either excite a stuck open fault, or to maximize the activity in the circuit is an NP-complete problem. In this work, we discuss the applicability of SAT methodologies in tackling these two testing problems. We experiment with SAT and Integer Linear Programming (ILP) solvers to compute solution sets for these two testing activities. </div...|$|R
40|$|Abstract: The paper {{gives an}} {{overview}} of the present situation in the domain, the front line in the battle for the best products. After a short introduction, the main problems arisen in reliability evaluation of monolithic integrated circuits, the evaluation itself and some new points of view concerning the dynamic life <b>testing,</b> screening and <b>burn-in,</b> accelerated <b>tests,</b> physics of failure of plastic encapsulated microcircuits (PEM) and process reliability are presented. Key words: Accelerated tests, best reliability of products, dynamic life <b>testing</b> and <b>burn-in,</b> evaluation of monolithic integrated circuits, physics of failure of PEM. ...|$|R
40|$|Parameter {{variations}} have a {{great impact}} on maximum clock frequency. Designers set a processor’s clock frequency to allow for the worst-case critical-path delay plus a safety margin. This process, known as guardbanding, is necessary because delays are not constant: Variations in process, voltage, temperature, and input values (PVTI) all contribute to the worstcase critical-path delay. To ensure correctness, designers must sum up the circuit-related worst-case delay and a safety margin for each PVTI element and then include this PVTIrelated delay in the worst-case delay calculation. PVTI-related variability increases with technology scaling, especially beyond 90 nm, so safety margins are becoming an important path delay component. 1 That is, designers must make the clock cycle time much longer than actual delays to guarantee correctness. Increased variability in the newer process technologies also has a serious cost implication: Companies must discard more low-per-formance parts, which increases costs and decreases total revenues. Moreover, PVTI variations are chiefly responsible for leakage current fluctuations, which can vary by as much as a factor of 20 across dies. 1 In the future, excessive leakage currents and resulting extreme temperatures could phase out the standard <b>burn-in</b> <b>test,</b> necessitating alternative approaches to identifying infant mortality in manufactured processors. 2 Thus, by affecting yield, increasing variability is becoming a reliability concern. The 2004 International Technology Roadmap for Semiconductor...|$|E
40|$|Mechanical load {{tests are}} a commonly-performed stress test where {{pressure}} {{is applied to}} the front and back sides of solar panels. In this paper we review the motivation for load tests and the different ways of performing them. We then discuss emerging durability concerns and ways in which the load tests can be modified and/or enhanced by combining them with other characterization methods. In particular, we present data from a new tool where the loads are applied by using vacuum and air pressure from the rear side of the panels, thus leaving the front side available for EL and IV characterization with the panels in the bent state. Tightly closed cracks in the cells can be temporarily opened by such a test, thus enabling a prediction of panel degradation in the field were these cracks to open up over time. Based on this predictive crack opening test, we introduce the concept of using a quick load test on each panel in the factory as a quality control tool and potentially as a type of <b>burn-in</b> <b>test</b> to initiate cracks that would certainly form early on during a panel's field life. We examine the stresses seen by the cells under panel load through Finite Element Modeling and demonstrate the importance of constraining the panel motion during testing as it will be constrained when mounted in the field...|$|E
40|$|Field Programmable Gate Arrays (FPGA) {{have played}} {{increasingly}} {{important roles in}} military and aerospace applications. Xilinx SRAM-based FPGAs have been extensively used in commercial applications. They have been used less frequently in space flight applications due to their susceptibility to single-event upsets. Reliability of these devices in space applications is a concern {{that has not been}} addressed. The objective of this project is to design a fully programmable hardware/software platform that allows (but is not limited to) comprehensive static/dynamic <b>burn-in</b> <b>test</b> of Virtex-II 3000 FPGAs, at speed test and SEU test. Conventional methods test very few discrete AC parameters (primarily switching) of a given integrated circuit. This approach will test any possible configuration of the FPGA and any associated performance parameters. It allows complete or partial re-programming of the FPGA and verification of the program by using read back followed by dynamic test. Designers have full control over which functional elements of the FPGA to stress. They can completely simulate all possible types of configurations/functions. Another benefit of this platform is that it allows collecting information on elevation of the junction temperature as a function of gate utilization, operating frequency and functionality. A software tool has been implemented to demonstrate the various features of the system. The software consists of three major parts: the parallel interface driver, main system procedure and a graphical user interface (GUI) ...|$|E
40|$|Large {{temperature}} gradients exacerbate {{various types of}} defects including early-life failures and delay faults. Efficient detection of these defects requires that <b>burn-in</b> and <b>test</b> for delay faults, respectively, are performed when {{temperature gradients}} with proper magnitudes are enforced on an Integrated Circuit (IC). This issue {{is much more important}} for 3 -D stacked ICs (3 -D SICs) compared with 2 -D ICs because of the larger temperature gradients in 3 -D SICs. In this paper, two methods to efficiently enforce the specified temperature gradients on the IC, for <b>burn-in</b> and delay-fault <b>test,</b> are proposed. The specified temperature gradients are enforced by applying high-power stimuli to the cores of the IC under test through the test access mechanism. Therefore, no external heating mechanism is required. The tests, high power stimuli, and cooling intervals are scheduled together based on temperature simulations so that the desired temperature gradients are rapidly enforced. The schedule generation is guided by functions derived from a set of thermal equations. The experimental results demonstrate the efficiency of the proposed methods...|$|R
40|$|We {{report the}} results of tests of 12880 Very Front End (VFE) readout cards for {{the barrel of the}} CMS {{electromagnetic}} calorimeter. A thorough test sequence was applied to each card including power-on <b>test,</b> <b>burn-in</b> and final calibration. Cards failing the tests were at the few per mille level. The results prove the very high quality of the VFE cards...|$|R
40|$|On the Compact Muon Solenoid (CMS) experimentat the Large Hadron Collider (LHC) at the CERN laboratory, {{the drift}} tube {{chambers}} {{are responsible for}} muon detection and precise momentum measurement. In this paper the first level of the read out electronics for these drift tube chambers is described. These drift tube chambers will be located inside the muon barrel detector in the so-called minicrates (MCs), attached to the chambers. The read out boards (ROBs) are {{the main component of}} this first level data acquisition system, and they are responsible for the time digitalization related to Level 1 Accept (L 1 A) trigger of the incoming signals from the front-end electronics, followed by a consequent data merging to the next stages of the data acquisition system. ROBs' architecture and functionality have been exhaustively tested, as well as their capability of operation beyond the expected environmental conditions inside the CMS detector. Due to the satisfactory results obtained, final production of ROBs and their assembly in the MCs has already started. A total amount of 250 MCs and approximately 1500 ROBs are being produced and tested thoroughly at CIEMAT (Spain). One set of <b>tests,</b> the <b>burn-in</b> <b>tests,</b> will guarantee ten years of limited maintenance operation. An overview of the system and a summary of the different results of the tests performed on ROBs and MCs will be presented. They include acceptance tests for the production chain as well as several validation tests that insure proper operation of the ROBs beyond the CMS detector conditions...|$|R
