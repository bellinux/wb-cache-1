71|228|Public
5|$|Integer {{powers of}} 2 are {{important}} in computer science. The positive integer powers 2n give the number of possible values for an n-bit integer binary number, e.g. 28 = 256 different values for 1byte. For a given number the binary number system denotes {{on one side of}} the <b>binary</b> <b>point</b> all the positive integer powers of 2, that are contained in the integer part of this number, and the negative powers to the other side of the <b>binary</b> <b>point</b> represent the fractional part. This system is consistently used to represent numbers in computers for hardware reasons.|$|E
2500|$|When this {{is stored}} in memory using the IEEE 754 encoding, this becomes the significand [...] The significand is assumed to have a <b>binary</b> <b>point</b> {{to the right of}} the leftmost bit. So, the binary {{representation}} of π is calculated from left-to-right as follows: ...|$|E
2500|$|The term {{floating}} point {{refers to the}} fact that a number's radix point (decimal point, or, more commonly in computers, <b>binary</b> <b>point)</b> can [...] "float"; that is, it can be placed anywhere relative to the significant digits of the number. This position is indicated as the exponent component, and thus the floating-point representation {{can be thought of as}} a kind of scientific notation.|$|E
50|$|<b>Binary</b> <b>points</b> {{obey the}} {{mathematical}} laws of exponentiation.|$|R
5000|$|Arithmetic unit: <b>Binary</b> {{floating}} <b>point,</b> 22 bit, add, subtract, multiply, divide, {{square root}} ...|$|R
5000|$|... #Caption: <b>Binary</b> boiling <b>point</b> {{diagram of}} two {{hypothetical}} only weakly interacting components without an azeotrope ...|$|R
2500|$|In the {{following}} table, [...] "s" [...] {{is the value}} of the sign bit (0 means positive, 1 means negative), [...] "e" [...] {{is the value of}} the exponent field interpreted as a positive integer, and [...] "m" [...] is the significand interpreted as a positive binary number where the <b>binary</b> <b>point</b> is located between bits 63 and 62. [...] The [...] "m" [...] field is the combination of the integer and fraction parts in the above diagram.|$|E
2500|$|Internally, the EDSAC used two's complement, binary numbers. [...] Numbers {{were either}} 17 bits (one word) or 35 bits (two words) long. [...] Unusually, the {{multiplier}} {{was designed to}} treat numbers as fixed-point fractions in the range −1 ≤ x < 1, i.e. the <b>binary</b> <b>point</b> was immediately {{to the right of}} the sign. [...] The accumulator could hold 71 bits, including the sign, allowing two long (35-bit) numbers to be multiplied without losing any precision.|$|E
2500|$|The {{reason that}} the dyadic {{transformation}} is also called the bit-shift map is that when [...] is written in binary notation, the map moves the <b>binary</b> <b>point</b> one place to the right (and if the bit {{to the left of}} the <b>binary</b> <b>point</b> has become a [...] "1", this [...] "1" [...] is changed to a [...] "0"). [...] A cycle of length 3, for example, occurs if an iterate has a 3-bit repeating sequence in its binary expansion (which is not also a one-bit repeating sequence): 001, 010, 100, 110, 101, or 011. The iterate 001001001... maps into 010010010..., which maps into 100100100..., which in turn maps into the original 001001001...; so this is a 3-cycle of the bit shift map. [...] And the other three binary-expansion repeating sequences give the 3-cycle 110110110... → 101101101... → 011011011... → 110110110.... Either of these 3-cycles can be converted to fraction form: for example, the first-given 3-cycle can be written as 1/7 → 2/7 → 4/7 → 1/7. [...] Using the above translation from the bit-shift map to the [...] logistic map gives the corresponding logistic cycle [...]611260467... → [...]950484434... → [...]188255099... → [...]611260467... We could similarly translate the other bit-shift 3-cycle into its corresponding logistic cycle. [...] Likewise, cycles of any length [...] can be found in the bit-shift map and then translated into the corresponding logistic cycles.|$|E
50|$|A turn can be {{subdivided}} in {{many different}} ways: into half turns, quarter turns, centiturns, milliturns, <b>binary</b> angles, <b>points</b> etc.|$|R
5000|$|Another {{perspective}} on the canonical codewords {{is that they are}} the digits past the radix <b>point</b> (<b>binary</b> decimal <b>point)</b> in a <b>binary</b> representation of a certain series. Specifically, suppose the lengths of the codewords are l1 ... ln. Then the canonical codeword for symbol i is the first li binary digits past the radix <b>point</b> in the <b>binary</b> representation of ...|$|R
5000|$|Guard digits {{are also}} used in {{floating}} point operations in most computer systems. Given [...] we have to line up the <b>binary</b> <b>points.</b> This means we must add an extra digit to the first operand—a guard digit. This gives us [...] Performing this operation gives us [...] or [...] Without using a guard digit we have , yielding [...] or [...] This gives us a relative error of 1. Therefore, we can see how important guard digits can be.|$|R
5000|$|The name {{bit shift}} map arises because, if {{the value of}} an iterate is written in binary notation, the next iterate is {{obtained}} by shifting the <b>binary</b> <b>point</b> one bit to the right, and if the bit {{to the left of the}} new <b>binary</b> <b>point</b> is a [...] "one", replacing it with a zero.|$|E
50|$|Using binary {{scientific}} notation, {{this will}} place the <b>binary</b> <b>point</b> at 1B16.|$|E
5000|$|The {{fraction}} is 100011 (looking to {{the right}} of the <b>binary</b> <b>point)</b> ...|$|E
25|$|The Z1 computer, {{which was}} {{designed}} and built by Konrad Zuse between 1935 and 1938, used Boolean logic and <b>binary</b> floating <b>point</b> numbers.|$|R
50|$|Unlike in 854, 754r {{requires}} correctly rounded base conversion between decimal and <b>binary</b> floating <b>point</b> {{within a}} range which {{depends on the}} format.|$|R
5000|$|Numeric {{variables}} {{have only}} one type, a <b>binary</b> floating <b>point</b> implementation. Each numeric variable consumes 5 bytes of memory and {{can be in the}} range from -1E+38 up to 1E+37 ...|$|R
5000|$|The {{fraction}} is 0 (looking to {{the right}} of <b>binary</b> <b>point</b> in 1.0 is all zeros) ...|$|E
5000|$|... with vk,j,m {{denoting}} the m-th digit {{after the}} <b>binary</b> <b>point</b> {{of the direction}} number vk,j = (0.vk,j,1vk,j,2...)2.|$|E
5000|$|The true significand {{includes}} 23 fraction bits to {{the right}} of the <b>binary</b> <b>point</b> and an implicit leading bit (to the left of the <b>binary</b> <b>point)</b> with value 1, unless the exponent is stored with all zeros. Thus only 23 fraction bits of the significand appear in the memory format, but the total precision is 24 bits (equivalent to log10(224) ≈ 7.225 decimal digits). The bits are laid out as follows: ...|$|E
25|$|Fixed-point {{representation}} uses integer hardware operations {{controlled by}} a software implementation of a specific convention about {{the location of the}} <b>binary</b> or decimal <b>point,</b> for example, 6 bits or digits from the right. The hardware to manipulate these representations is less costly than floating point, and {{it can be used to}} perform normal integer operations, too. <b>Binary</b> fixed <b>point</b> is usually used in special-purpose applications on embedded processors that can only do integer arithmetic, but decimal fixed point is common in commercial applications.|$|R
5000|$|... #Caption: [...] A {{schematic}} for {{the determination}} of melting <b>point</b> <b>binary</b> phase diagrams from thermal microscopy.|$|R
50|$|Each core has six RISC-like {{execution}} units, {{including two}} integer units, two load-store units, one <b>binary</b> floating <b>point</b> unit and one decimal floating point unit. The z196 chip can decode three instructions and execute five operations {{in a single}} clock cycle.|$|R
5000|$|Convert {{the number}} to {{floating}} point {{as if it were}} an integer, in other words remove the <b>binary</b> <b>point</b> ...|$|E
5000|$|The {{fraction}} is 0 (looking to {{the right}} of the <b>binary</b> <b>point</b> in 1.0 is all 0 = 000...0) ...|$|E
5000|$|The {{fraction}} is 1 (looking to {{the right}} of <b>binary</b> <b>point</b> in 1.1 is a single 1 = x1) ...|$|E
40|$|This paper {{uses the}} image of the garden as a tool to explore the {{complementarity}} of imagery {{in the work of the}} siblings Jorge Luis Borges (1899 – 1986) and Norah Borges (1901 – 1998). It extends the largely biographical reading of their complementarity by interrogating the degree to which their work adheres to the light / dark <b>binary</b> <b>pointed</b> to by Emir Rodríguez Monegal. The image of the garden is traced throughout the early work of both siblings. Alongside the biographical details of their childhood, the wider use of the image is considered in order to demonstrate the inefficacy of a limited approach to the works of either of the Borges siblings. </p...|$|R
40|$|This {{document}} {{describes a}} novel approach to finding localised clusters in spatially distributed, <b>binary</b> labelled <b>point</b> data. The frequentist spatial scan statistic, in-troduced by Martin Kulldorff in 1995, was developed into a Bayesian spatial scan statistic for areal data by Daniel Neill, circa 2006, where computationally expensive Monte Carlo testing is replaced {{by the use of}} historical data and expert judgement. Following Neill’s approach, I present here my derivation of a Bayesian spatial scan statistic for <b>binary</b> labelled <b>point</b> data. I have also developed a method for replac-ing historic data with expert judgement, by using a prior probability distribution of relative risk. Please note this document describes work in progress, and content may be subject to revision. ...|$|R
50|$|MS BASIC for Macintosh was a dialect of Microsoft BASIC for Macintosh. It {{was one of}} {{the first}} Microsoft BASIC {{variants}} to have optional line numbering, predating QuickBASIC. It was provided in two versions, one with standard <b>binary</b> floating <b>point</b> and another with decimal arithmetic.|$|R
5000|$|... n is {{the number}} of bits used to {{designate}} the fractional portion of the number, i.e. the number of bits {{to the right of the}} <b>binary</b> <b>point.</b> (If n = 0, the Q numbers are integers — the degenerate case).|$|E
5000|$|The term {{floating}} point {{refers to the}} fact that a number's radix point (decimal point, or, more commonly in computers, <b>binary</b> <b>point)</b> can [...] "float"; that is, it can be placed anywhere relative to the significant digits of the number. This position is indicated as the exponent component, and thus the floating-point representation {{can be thought of as}} a kind of scientific notation.|$|E
50|$|Internally, the EDSAC used two's complement, binary numbers. Numbers {{were either}} 17 bits (one word) or 35 bits (two words) long. Unusually, the {{multiplier}} {{was designed to}} treat numbers as fixed-point fractions in the range −1 ≤ x < 1, i.e. the <b>binary</b> <b>point</b> was immediately {{to the right of}} the sign. The accumulator could hold 71 bits, including the sign, allowing two long (35-bit) numbers to be multiplied without losing any precision.|$|E
40|$|We {{examine the}} {{algorithmic}} tractability of NP-hard combinatorial feature selection problems {{in terms of}} parameterized complexity theory. In combinatorial feature selection, one seeks to discard dimensions from high-dimensional data such that the resulting instances fulfill a desired property. In parameterized complexity analysis, one seeks to identify relevant problem-specific quantities and tries to determine their influence on the computational complexity of the considered problem. In this paper, for various combinatorial feature selection problems, we identify parameterizations and reveal to what extent these govern computational complexity. We provide tractability as well as intractability results; for example, we show that the Distinct Vectors problem on <b>binary</b> <b>points</b> is polynomial-time solvable if each pair of points differs in at most three dimensions, whereas it is NP-hard otherwise...|$|R
25|$|As JavaScript has unusual {{limitations}} – such as no explicit integer type, only double-precision <b>binary</b> floating <b>point</b> – languages that compile to JavaScript and do {{not take}} care to use the integer-converting shift and bitwise logical operators may have slightly different behavior than in other environments.|$|R
40|$|We {{expand on}} {{a result of}} Barvinok and Hartigan to derive {{asymptotic}} formulas {{for the number of}} integer and <b>binary</b> integer <b>points</b> in a wide class of multi-index k_ 1 × k_ 2 × [...] . × k_ν transportation polytopes. A simple closed form approximation is given as the k_js go to infinity. Comment: 38 page...|$|R
