1701|10000|Public
25|$|Stage2 {{begins with}} a self-hosting (<b>bootstrapped)</b> toolchain for the target system, which is then used to compile all other core userland {{software}} for the target.|$|E
25|$|ALGOL 68RS(RS) from RSRE was a {{portable}} compiler system written in ALGOL 68RS (<b>bootstrapped</b> from ALGOL 68R), and implemented {{on a variety}} of systems including the ICL 2900/Series 39, Multics and DEC VAX/VMS. The language was based on the Revised Report, but with similar subset restrictions to ALGOL 68R. This compiler survives {{in the form of an}} Algol68-to-C compiler.|$|E
25|$|Development on Pugs, {{the first}} high-traction implementation, began in 2005, {{and there have}} been {{multiple}} Perl 6 implementation projects. Rakudo Perl 6 is based on NQP (Not Quite Perl) and can use MoarVM or the Java Virtual Machine as a runtime environment, and releases a new version every month; in July 2010, the project released the first Rakudo Star distribution, a useful and usable collection of a Perl 6 implementation and related materials. Larry Wall maintains a reference grammar known as STD.pm6, written in Perl 6 and <b>bootstrapped</b> with Perl 5.|$|E
40|$|This paper surveys <b>bootstrap</b> and Monte Carlo {{methods for}} testing {{hypotheses}} in econometrics. Several {{different ways of}} computing <b>bootstrap</b> P values are discussed, including the double <b>bootstrap</b> and the fast double <b>bootstrap.</b> It is emphasized {{that there are many}} different procedures for generating <b>bootstrap</b> samples for regression models and other types of model. As an illustration, a simulation experiment examines the performance of several methods of <b>bootstrapping</b> the supF test for structural change with an unknown break point. <b>bootstrap</b> test, supF test, wild <b>bootstrap,</b> pairs <b>bootstrap,</b> moving block <b>bootstrap,</b> residual <b>bootstrap,</b> <b>bootstrap</b> P value...|$|R
40|$|A {{modified}} <b>bootstrap</b> {{procedure is}} proposed. It {{is based on}} the outlier <b>bootstrap</b> sample concept introduced by Muñoz-García et al. (1997). The consistency of the modified <b>bootstrap</b> distribution estimator and of the modified <b>bootstrap</b> variance estimator is established for Féchet differentiable statistical functionals. The modified <b>bootstrap</b> variance estimator requires less stringent conditions for its consistency than the ordinary <b>bootstrap</b> variance estimator. <b>Bootstrap</b> Outlier <b>bootstrap</b> sample Distribution estimation Variance estimation Fréchet differentiability Consistency...|$|R
40|$|We show that, {{compared}} to the classical <b>bootstrap,</b> the modified <b>bootstrap</b> provides faster consistency rates for the <b>bootstrap</b> distribution of U-quantiles. This shows that the modified <b>bootstrap</b> is useful, not only {{in cases where the}} classical <b>bootstrap</b> fails, but also in situations where it is valid. Consistency rates Modified <b>bootstrap</b> Quantiles...|$|R
25|$|Since the {{beginning}} of computer networks, {{there has been a}} persistent need for client systems which can boot appropriate software images, with appropriate configuration parameters, both retrieved at boot time from one or more network servers. This goal requires a client to use a set of pre-boot services, based on industry standard network protocols. Additionally, the Network Bootstrap Program (NBP) which is initially downloaded and run must be built using a client firmware layer (at the device to be <b>bootstrapped</b> via PXE) providing a hardware independent standardized way to interact with the surrounding network booting environment. In this case the availability and subjection to standards are a key factor required to guarantee the network boot process system interoperability.|$|E
2500|$|As in {{the early}} {{development}} days with RogueRemover, Malwarebytes thrives on community feedback. It runs two sub-forums complementing the main forum, known as [...] "False positives" [...] and [...] "Malware contribution", with the false positives being reported allowing the company to update its database within just hours, and the Malware contribution allowing for them to quickly report what is missing and download it. Kleczynski had been quoted as saying, [...] "We still try to work like a <b>bootstrapped</b> company. We'd rather build products that our customers buy rather than we sell to them something they may not need.” ...|$|E
50|$|The <b>Bootstrapped</b> {{initiative}} is now also offered to <b>bootstrapped</b> companies at their events in Brooklyn {{where they are}} known as The Round.|$|E
40|$|The fast double <b>bootstrap,</b> or FDB, is a {{procedure}} for calculating <b>bootstrap</b> P values {{that is much}} more computationally efficient than the double <b>bootstrap</b> itself. In many cases, it can provide more accurate results than ordinary <b>bootstrap</b> tests. For the fast double <b>bootstrap</b> to be valid, the test statistic must be asymptotically independent of the random parts of the <b>bootstrap</b> data generating process. This paper presents simulation evidence {{on the performance of}} FDB tests in three cases of interest to econometricians. One of the cases involves both symmetric and equal-tail <b>bootstrap</b> tests, which, interestingly, can have quite different power properties. Another highlights the importance of imposing the null hypothesis on the <b>bootstrap</b> DGP. <b>bootstrap</b> test, serial correlation, ARCH errors, weak instruments, double <b>bootstrap,</b> fast double <b>bootstrap,</b> FDB...|$|R
40|$|The {{asymptotic}} refinements {{attributable to}} the block <b>bootstrap</b> for time series are not as large {{as those of the}} nonparametric iid <b>bootstrap</b> or the parametric <b>bootstrap.</b> One reason is that the independence between the blocks in the block <b>bootstrap</b> sample does not mimic the dependence structure of the original sample. This is the join-point problem. In this paper, we propose a method of solving this problem. The idea is not to alter the block <b>bootstrap.</b> Instead, we alter the original sample statistics to which the block <b>bootstrap</b> is applied. We introduce block statistics that possess join-point features that {{are similar to those of}} the block <b>bootstrap</b> versions of these statistics. We refer to the application of the block <b>bootstrap</b> to block statistics as the block-block <b>bootstrap.</b> The asymptotic refinements of the block-block <b>bootstrap</b> are shown to be greater than those obtained with the block <b>bootstrap</b> and close to those obtained with the nonparametric iid <b>bootstrap</b> and parametric <b>bootstrap.</b> Asymptotics, Block <b>bootstrap,</b> Block statistics, Edgeworth expansion, Extremum estimator, Generalized method of moments estimator, Maximum likelihood estimator, t statistic, Test of over-identifying restrictions...|$|R
40|$|The double <b>bootstrap</b> {{provides}} {{a useful tool for}} <b>bootstrapping</b> approximately pivotal quantities by using an "inner" <b>bootstrap</b> loop to estimate the variance. When the estimators are computationally intensive, the double <b>bootstrap</b> may become infeasible. We propose the use of a new variance estimator for the nonparametric <b>bootstrap</b> which effectively removes the requirement to perform the inner loop of the double <b>bootstrap.</b> Simulation results indicate that the proposed estimator produce bootstrap-t confidence intervals with coverage accuracy which replicates the coverage accuracy for the standard double <b>bootstrap.</b> Bootstrap-t; confidence intervals; influence function; non-parametric <b>bootstrap...</b>|$|R
50|$|An example: <b>bootstrapped</b> current source.|$|E
50|$|Milkroundabout {{have helped}} 10-20 <b>bootstrapped</b> {{companies}} at each event in London and Edinburgh since 2011 {{and of the}} 138 <b>Bootstrapped</b> companies supported in their infancy, they {{have gone on to}} raise $91,968,400 in investment. These include UK success stories Citymapper, Constant Commerce and Osper.|$|E
50|$|From {{the date}} of its incorporation, JustOrbit has been <b>bootstrapped.</b>|$|E
50|$|<b>Bootstrapping</b> is a {{term used}} in {{language}} acquisition {{in the field of}} linguistics. It refers to the idea that human beings are born innately equipped with a mental faculty that forms the basis of language, and that allows children to effortlessly acquire language. As a process, <b>bootstrapping</b> can be divided into different domains, according to whether it involves semantic <b>bootstrapping,</b> syntactic <b>bootstrapping,</b> prosodic <b>bootstrapping,</b> or pragmatic <b>bootstrapping.</b>|$|R
40|$|International audienceIn {{regression}} models, appropriate <b>bootstrap</b> {{methods for}} inference robust to heteroskedasticity of unknown form are the wild <b>bootstrap</b> and the pairs <b>bootstrap.</b> The finite sample {{performance of a}} heteroskedastic-robust test is investigated with Monte Carlo experiments. The simulation results suggest that one specific version of the wild <b>bootstrap</b> outperforms the other versions of the wild <b>bootstrap</b> and of the pairs <b>bootstrap.</b> It {{is the only one}} for which the <b>bootstrap</b> test gives always better results than the asymptotic test...|$|R
40|$|Although it {{is common}} to refer to “the <b>bootstrap,</b> ” there are {{actually}} a great many different <b>bootstrap</b> methods {{that can be used in}} econometrics. We emphasize the use of <b>bootstrap</b> methods for inference, particularly hypothesis testing, and we also discuss <b>bootstrap</b> confidence intervals. There are important cases in which <b>bootstrap</b> inference tends to be more accurate than asymptotic inference. However, it is not always easy to generate <b>bootstrap</b> samples in a way that makes <b>bootstrap</b> inference even asymptotically valid...|$|R
5000|$|Can be <b>bootstrapped</b> {{from other}} PHP {{applications}} or command-line scripts ...|$|E
50|$|It is <b>bootstrapped</b> by the founders, Monish Shah and Malhar Gala.|$|E
5000|$|... where [...] {{denotes the}} [...] {{percentile}} of the <b>bootstrapped</b> coefficients [...]|$|E
40|$|There {{are many}} <b>bootstrap</b> methods {{that can be}} used for econometric analysis. In certain circumstances, such as {{regression}} models with independent and identically distributed error terms, appropriately chosen <b>bootstrap</b> methods generally work very well. However, there are many other cases, such as regression models with dependent errors, in which <b>bootstrap</b> methods do not always work well. This paper discusses a large number of <b>bootstrap</b> methods that can be useful in econometrics. Applications to hypothesis testing are emphasized, and simulation results are presented for a few illustrative cases. <b>bootstrap,</b> Monte Carlo test, wild <b>bootstrap,</b> sieve <b>bootstrap,</b> moving block <b>bootstrap...</b>|$|R
40|$|It is {{well known}} that Efron's <b>bootstrap</b> can fail in {{settings}} where the data are heavy tailed and when regularity conditions do not hold. Naturally this applies to weighted <b>bootstrap</b> schemes such as the Bayesian <b>bootstrap.</b> To deal with this, we introduce a Bayesian <b>bootstrap</b> analogue of the m out of n <b>bootstrap.</b> This <b>bootstrap</b> differs from traditional m out of n <b>bootstraps</b> in that all n observations are used in the <b>bootstrap</b> test statistic. Moreover, the method is relatively robust to the selection of m. We establish consistency for the new <b>bootstrap</b> and examine its other useful properties including a connection to the Dirichlet process. Several examples illustrating consistency in settings where the Efron <b>bootstrap</b> fails are given. Further generalizations are suggested. (c) 2008 Elsevier B. V. All rights reserved...|$|R
50|$|Histograms of the <b>bootstrap</b> {{distribution}} and the smooth <b>bootstrap</b> distribution appear below. The <b>bootstrap</b> {{distribution of the}} sample-median has {{only a small number}} of values. The smoothed <b>bootstrap</b> distribution has a richer support.|$|R
5000|$|Language {{definition}} languages - these {{language are}} implemented with themselves, i.e. <b>bootstrapped</b> ...|$|E
50|$|The {{compiler}} {{was written}} in ALGOL 68, <b>bootstrapped</b> initially using the ALGOL 68R compiler.|$|E
50|$|Juju has two {{components:}} a client and a bootstrap node. Currently clients exist for Ubuntu, CentOS, Mac and Windows. After installing the client, {{one or more}} environments can be <b>bootstrapped.</b> Juju environments can be <b>bootstrapped</b> on many clouds: Amazon Web Services, HP Cloud Services, Microsoft Azure, OpenStack, etc. By creating a Juju Provider, additional cloud environments can be supported. Juju can also be <b>bootstrapped</b> on bare-metal servers. Large deployments can use Canonical's Metal as a Service. Small deployments can use the manual provider, which allows any SSH Ubuntu machine to be converted into a Juju-managed machine. Juju can also be installed on a local Ubuntu machine via LXC operating system-level virtualization and the local provider.|$|E
5000|$|Percentile <b>Bootstrap.</b> The {{percentile}} <b>bootstrap</b> proceeds in {{a similar}} way to the basic <b>bootstrap,</b> using percentiles of the <b>bootstrap</b> distribution, but with a different formula (note the inversion of the left and right quantiles!): ...|$|R
40|$|Abstract: The article {{proposes a}} {{computationally}} efficient procedure for bias adjustment in the iterated <b>bootstrap.</b> The new technique replaces {{the need for}} successive levels of <b>bootstrap</b> resampling by proposing an approximation for the double <b>bootstrap</b> “calibrating coefficient ” using only one draw from the second level probability distribution. Extensive Monte Carlo evidence suggest that the proposed approximation performs better than the ordinary <b>bootstrap</b> bias correction. The article evaluates {{the usefulness of the}} <b>bootstrap</b> and fast <b>bootstrap</b> in reducing the bias of generalized method of moments estimators under weak instruments. In identified models, this fast <b>bootstrap</b> bias correction leads to estimators with lower variance than those based on the double <b>bootstrap.</b> The proposed fast iterated <b>bootstrap</b> performs better than the double <b>bootstrap</b> in all scenarios and especially when the model has the weakest instrument relevance and the highest degree of endogeneity. However, when the estimators have no finite moments and the instruments are weak, the <b>bootstrap</b> does not work well and iterating it makes things worse...|$|R
40|$|Efron (1979) {{introduced}} the <b>bootstrap</b> method for independent data but it cannot be easily applied to spatial data {{because of their}} dependency. For spatial data that are correlated {{in terms of their}} locations in the underlying space the moving block <b>bootstrap</b> method is usually used to estimate the precision measures of the estimators. The precision of the moving block <b>bootstrap</b> estimators is related to the block size which is difficult to select. In the moving block <b>bootstrap</b> method also the variance estimator is underestimated. In this paper, first the semi-parametric <b>bootstrap</b> is used to estimate the precision measures of estimators in spatial data analysis. In the semi-parametric <b>bootstrap</b> method, we use the estimation of the spatial correlation structure. Then, we compare the semi-parametric <b>bootstrap</b> with a moving block <b>bootstrap</b> for variance estimation of estimators in a simulation study. Finally, we use the semi-parametric <b>bootstrap</b> to analyze the coal-ash data. Moving block <b>bootstrap</b> Semi-parametric <b>bootstrap</b> Plug-in kriging Monte Carlo simulation Coal-ash data...|$|R
50|$|RUWT?! {{was founded}} in 2006, {{launched}} publicly in 2007, and was <b>bootstrapped</b> by Phillip, its sole employee.|$|E
50|$|Salarium was <b>bootstrapped</b> {{until it}} {{received}} its {{first round of}} investment in 2014 by Seedstars World (SSW).|$|E
50|$|In 2002, Thelen {{founded and}} <b>bootstrapped</b> a startup company, Big Fish Games with $10,000 {{of his own}} seed capital.|$|E
40|$|In this paper, we {{introduce}} an idea {{we refer}} to as sufficient <b>bootstrapping,</b> {{which is based on}} retaining only distinct individual responses, and also develop a theoretical framework for the techniques. We demonstrate through numerical illustrations that the proposed sufficient <b>bootstrapping</b> may be better than the conventional <b>bootstrapping</b> in certain situations. The expected gain by the sufficient <b>bootstrapping</b> has been computed for small and large sample sizes. The relative efficiency shows that there could be significant gain by the sufficient <b>bootstrapping</b> and it could reduce computational burden. Variance expressions for both the conventional and sufficient <b>bootstrapping</b> sample means are derived. Here the word "sufficient" is being used {{in the sense that it}} is "sufficient to take just one of any duplicated items in the <b>bootstrap</b> sample" and is not tightly connected to sufficiency in terms of any likelihood perspective. R code for comparing <b>bootstrapping</b> and sufficient <b>bootstrapping</b> are provided. A huge scope of further studies is suggested. <b>Bootstrapping</b> Sufficient <b>bootstrapping</b> Estimation of mean Resampling Distinct units...|$|R
40|$|This paper {{provides}} bounds on {{the errors}} in coverage probabilities of maximum likelihood-based, percentile-t, parametric <b>bootstrap</b> confidence intervals for Markov time series processes. These bounds {{show that the}} parametric <b>bootstrap</b> for Markov time series provides higher-order improvements (over confidence intervals based on first order asymptotics) that are comparable to those obtained by the parametric and nonparametric <b>bootstrap</b> for iid data and are better than those obtained by the block <b>bootstrap</b> for time series. Additional results are given for Wald-based confidence regions. The paper also shows that k-step parametric <b>bootstrap</b> confidence intervals achieve the same higher-order improvements as the standard parametric <b>bootstrap</b> for Markov processes. The k-step <b>bootstrap</b> confidence intervals are computationally attractive. They circumvent the need to compute a nonlinear optimization for each simulated <b>bootstrap</b> sample. The latter is necessary to implement the standard parametric <b>bootstrap</b> when the maximum likelihood estimator solves a nonlinear optimization problem. Asymptotics, Edgeworth expansion, Gauss-Newton, k-step <b>bootstrap,</b> maximum likelihood estimator, Newton-Raphson, parametric <b>bootstrap,</b> t statistic...|$|R
40|$|A {{functional}} law for an I(1) {{sample data}} {{version of the}} continuous-path block <b>bootstrap</b> of Paparoditis and Politis (2001) is given. The results provide an alternative demonstration that continuous-path block <b>bootstrap</b> unit root tests are consistent under the null. Asymptotic theory, Block <b>bootstrap,</b> <b>Bootstrap,</b> Brownian motion, Continuous path <b>bootstrap,</b> Embedding, Unit root...|$|R
