927|20|Public
5|$|The hook (α) {{angle is}} a {{parameter}} {{of the material}} being cut. For steel, it is between 15 and 20° and for cast iron it is between 6 and 8°. The <b>back-off</b> (γ) provides clearance for the teeth so that they don't rub on the workpiece; it is usually between 1 and 3°.|$|E
25|$|Because Jules Verne was {{the first}} ATV, several on-orbit {{demonstration}} tests were performed in order to confirm that {{it was able to}} safely approach and dock with the ISS. After launch, the ATV spent three weeks in free flight. It successfully underwent Collision Avoidance Manoeuvre (CAM) tests on 13 March and 14 March, ensuring that the CAM could be conducted as a last <b>back-off</b> mechanism should all other systems fail during the docking manoeuvre.|$|E
2500|$|In {{practice}} {{it is necessary}} to smooth the probability distributions by also assigning non-zero probabilities to unseen words or n-grams. [...] The reason is that models derived directly from the n-gram frequency counts have severe problems when confronted with any n-grams that have not explicitly been seen before – the zero-frequency problem. [...] Various smoothing methods are used, from simple [...] "add-one" [...] (Laplace) smoothing (assign a count of 1 to unseen n-grams; see Rule of succession) to more sophisticated models, such as Good–Turing discounting or <b>back-off</b> models. [...] Some of these methods are equivalent to assigning a prior distribution to the probabilities of the n-grams and using Bayesian inference to compute the resulting posterior n-gram probabilities. [...] However, the more sophisticated smoothing models were typically not derived in this fashion, but instead through independent considerations.|$|E
30|$|Traditional <b>back-off's</b> success {{probability}} degrades {{with increasing}} number of nodes.|$|R
40|$|Modern {{wireless}} communication systems use spectrally efficient modulation schemes to reach {{high data rate}} transmission. These schemes are generally involved with signals with high peak-to-average power ratio (PAPR). Moreover, the development of next generation {{wireless communication}} systems requires the power amplifiers to operate over a wide frequency band or multiple frequency bands to support different applications. These wide-band and multi-band solutions will lead to reductions in both the size and cost of the whole system. This dissertation presents several advanced power amplifier solutions to provide wide-band and multi-band operations with efficiency improvement at power <b>back-offs...</b>|$|R
40|$|Spectrally {{efficient}} {{wireless communication}} standards impose stringent linearity specifications, {{which would require}} traditional IQ transmitters to operate with <b>back-offed</b> and power inefficient linear RF power amplifiers (PAs). In order to overcome such a significant limitation, alternative architectures have been proposed, as those based on the Envelope Elimination and Restoration (EER) technique. In this paper, a UHF polar transmitter is presented, combining switching and linear stages in the envelope amplifier as to achieve both great bandwidth and high efficiency, when drain modulating a GaN HEMT class E RF PA. Several tests, using EDGE, TETRA, and WCDMA standards have been performed with good results...|$|R
5000|$|Once {{the free}} {{point of a}} stuck pipe string is determined, the stringshot <b>back-off</b> service {{can be used to}} remove the free portion from the well. The string-shot is a metal rod wrapped in {{explosive}} primer cord. The <b>back-off</b> procedure applies left-hand torque to the stuck pipe string. The CCL is used to help position the string shot at the predetermined pipe joint, and then the string shot is detonated. [...] The explosion produces a similar effect as an intense hammer blow and allows the joint to be unscrewed at the proper connection. Several factors such as pipe size, weight and condition, <b>back-off</b> depth, mud or borehole fluid weight and well temperature are carefully considered when making up the proper string-shot assembly.|$|E
50|$|Like N-gram models, {{smoothing}} {{techniques are}} necessary in parameter estimation. In particular, generalized <b>back-off</b> {{is used in}} training an FLM.|$|E
5000|$|For example, user A and user B both try {{to access}} a quiet link {{at the same}} time. Since they detect a {{collision}}, user A waits for a random time between 0 and 1 time units and so does user B. Let's say user A chooses a lower <b>back-off</b> time. User A then begins to use the link and B allows it to finish sending its frame. If user A still has more to send, then user A and user B will cause another data collision. A will once again choose a random <b>back-off</b> time between 0 and 1, but user B will choose a <b>back-off</b> time between 0 and 3 - because this is his second time colliding in a row. Chances are A will [...] "win" [...] this one again. If this continues, A will most likely win all the collision battles, and after 16 collisions (the number of tries before a user backs down {{for an extended period}} of time), user A will have [...] "captured" [...] the channel.|$|E
40|$|AbstractIn this paper, an {{analytic}} model is present {{for evaluating the}} MAC layer Collision Probability and mean delay at wireless nodes using the Distributed Coordination Function of IEEE 802. 11 MAC Model. This model is valid for finite loads and can account for arbitrary arrival patterns, packet size distributions and number of nodes. Each node is modeled as a discrete time M/G/ 1 queue and impact of packet collisions, the resulting <b>back-offs</b> {{as well as the}} packet size distribution. We analyze this Model for different number of nodes in any network. The impact of arrival pattern on collision probability and delay is also analyzed...|$|R
40|$|We {{present a}} Chinese word {{segmentation}} system {{submitted to the}} first task on CLP 2012 <b>back-offs.</b> Our segmenter is built using a conditional random field sequence model. We set {{the combination of a}} few annotated micro blogs and People Daily corpus as the training data. We encode special words detected by rules and information extracted from unlabeled data into features. These features are used to improve our model’s performance. We also derive a micro blog specified lexicon from auto-analyzed data and use lexicon related features to assist the model. When testing on the sample data of this task, these features result in 1. 8 % improvement over the baseline model. Finally, our model achieves F-score of 94. 07 % on the bakeoff’s test set. ...|$|R
30|$|Measurement {{results in}} Figure 5 {{show that the}} CMSA-CA {{mechanism}} of the IEEE 802.11 g standard effectively tackles homogeneous interference present on the same channel. Despite the slight variations in the throughput values in Figure 5 a, {{the order of the}} achieved throughput is preserved for increasing the interference power sensed at the receiver. The variations are the result of non-deterministic spectral competition between the interfering link and the link under test which is introduced by the random <b>back-offs</b> in the DCF algorithm of IEEE 802.11 standards [24]. Figure 5 a also shows the dependency of the throughput to the interference TxRate. At lower TxRates, transmission of a fixed length packet lasts longer, causing the spectrum to be shared inefficiently between the interference link and the LUT (also reported in [25]). This dependency will be more elaborately studied and modeled in Section 3.4.|$|R
50|$|Molded in Low Density Polyethylene, Polyseal cone liners form to {{the inside}} of the bottle neck {{providing}} a leakproof seal which guards against <b>back-off</b> and product evaporation. Excellent for use with acid products and essential oils, these closures are recommended for use on glass bottles only.|$|E
50|$|Essentially, {{this means}} that if the n-gram has been seen more than k times in training, the {{conditional}} probability of a word given its history {{is proportional to the}} maximum likelihood estimate of that n-gram. Otherwise, the conditional probability is equal to the <b>back-off</b> conditional probability of the (n &minus; 1)-gram.|$|E
5000|$|Giannakis and {{collaborators}} developed several significant {{innovations in}} multi-carrier modulation. One important development {{was the use}} of zero-padding instead of a cyclic prefix. Using a zero-prefix has advantages in the application to multi-band OFDM in ultra wideband because it extends the coverage range by avoiding power <b>back-off</b> at the transmitter.|$|E
40|$|OFDM signals {{suffer from}} a large peak to average power ratio, which {{requires}} large power <b>back-offs</b> in the transmit and receive chains. This paper presents a digital postprocessing method that mitigates clipping by the analog-to-digital converter (ADC) in the receiver. Clipped peaks cause spurious signals on empty subcarriers, {{which can be used}} to eliminate clipping artifacts and to recover the original signal. Simulations show that a significant reduction of 3 dB in the headroom of the A/D converter (ADC) is possible, when an elaborate MMSE clip correction algorithm is used. A simple algorithm still allows for 1 dB reduction of the headroom. As the ADC is consuming an ever increasing fraction of the total receiver power, the results are believed to be relevant for low-power design of OFDM receivers, for instance to prolong battery life of laptops and other portable WLAN devices...|$|R
3000|$|Motivated by {{the above}} example, we {{strongly}} advocate the channel width adaptable network architecture. Briefly speaking, {{the advantages of}} channel width adaptation are two-fold. On one hand, we can distribute the traffic as evenly as possible across the spectrum in a fine granularity to achieve channel load balance. On the other hand, in a scenario with many interfering links, by [...] "creating" [...] more small-width orthogonal channels, we can greatly reduce the phenomena of contention and collision, and therefore improve throughput {{as a result of}} fewer <b>back-offs</b> and reduced interference. Another motivation for the channel width adaptable network architecture is the recent open spectrum effort [7] made by the spectrum regulation authority such as FCC. Because of the variable widths of [...] "white space" [...] unoccupied by licensed users, we believe channel width adaptation will {{become one of the most}} important functions for cognitive radio networks in future open spectrum environment.|$|R
40|$|In a multi-carrier {{non-linear}} {{satellite communication}} channel, inter-symbol interference (ISI) and adjacent channel interference (ACI) occur {{due to the}} non-linear power amplifier aboard the satellite. In order to prevent a too high performance degradation, large input <b>back-offs</b> (IBO) are generally considered. However, if all carriers are issued from the same ground station, pre-distortion of the whole transmitted signal can be a better solution to achieve higher power efficiency aboard the satellite and/or spectral efficiency. The relation between the symbols transmitted on the channel and the received symbols is tricky for a multi-carrier system, as it involves several symbol flows. Few approaches have been proposed yet to provide an efficient algorithm with reasonable complexity in such context. In this paper, we will derive a sub-optimum algorithm for the pre-distortion of a multi-carrier non-linear satellite channel which offers a good trade-off between performance and complexity. info:eu-repo/semantics/publishe...|$|R
50|$|System files used by {{applications}} must {{be protected}} {{in order to ensure}} the integrity and stability of the application. Using source code repositories with version control, extensive testing, production <b>back-off</b> plans, and appropriate access to program code are some effective measures {{that can be used to}} protect an application's files.|$|E
5000|$|The {{ability of}} one node {{to capture the}} entire medium is {{decreased}} {{as the number of}} nodes increases. This is because as the number of nodes increases, there is a higher probability that one of the [...] "other" [...] nodes will have a lower <b>back-off</b> time than the capturing node.|$|E
50|$|The hook (α) {{angle is}} a {{parameter}} {{of the material}} being cut. For steel, it is between 15 and 20° and for cast iron it is between 6 and 8°. The <b>back-off</b> (γ) provides clearance for the teeth so that they don't rub on the workpiece; it is usually between 1 and 3°.|$|E
40|$|This paper {{addresses}} the tradeoff between energy consumption and localization {{performance in a}} mobile sensor network application. The focus is on augmenting GPS location with more energy-efficient location sensors to bound position estimate uncertainty in order to prolong node lifetime. We use empirical GPS and radio contact data from a largescale animal tracking deployment to model node mobility, GPS and radio performance. These models are used to explore duty cycling strategies for maintaining position uncertainty within specified bounds. We then explore the benefits of using short-range radio contact logging alongside GPS as an energy-inexpensive means of lowering uncertainty while the GPS is off, and we propose a versatile contact logging strategy that relies on RSSI ranging and GPS lock <b>back-offs</b> for reducing the node energy consumption relative to GPS duty cycling. Results show that our strategy can cut the node energy consumption by half while meeting application specific positioning criteria...|$|R
40|$|Abstract. Performance {{evaluation}} and comparison of multi-carrier code {{division multiple access}} (MC-CDMA) system model for different spreading sequences at the presence of Saleh and Rapp model of high power amplifier (HPA) is investigated. Nonlinear amplification introduces degradation of bit error performance and destroys the orthogonality among subcarriers. In order to avoid perfor-mance degradation without requiring extremely large <b>back-offs</b> in the transmitter amplifier, it becomes convenient to use nonlinear multi-user detection techniques at the re-ceiver side. In order to illustrate this fact, microstatistic multi-user receiver (MSF-MUD) and conventional minimum mean square error receiver (MMSE-MUD) are considered and mutually compared. The results of our analyses based on computer simulations will show very clearly, that the application of nonlinear MSF-MUD in combination with Golay codes can provide significantly better results than the other tested spreading codes and receivers. Besides this fact, a failure of Walsh codes especially at the Saleh model of HPA will be outlined by using constellation diagram...|$|R
40|$|Abstract—Video {{telephony}} {{has recently}} gained its momentum and is widely adopted by end-consumers. But {{there have been}} very few studies on the network impacts of video calls and the user Quality-of-Experience (QoE) under different network conditions. In this paper, we study the rate control and video quality of Skype video calls. We first measure the behaviors of Skype video calls on a controlled network testbed. By varying packet loss rate, propagation delay and available network bandwidth, we observe how Skype adjusts its sending rate, FEC redundancy, video rate and frame rate. We find that Skype is robust against mild packet losses and propagation delays, and can efficiently utilize the available network bandwidth. We also find that Skype employs an overly aggressive FEC protection strategy. Based on the measurement results, we develop rate control model, FEC model, and video quality model for Skype. Extrapolating from the models, we conduct numerical analysis to study the network impacts of Skype. We demonstrate that user <b>back-offs</b> upon quality degradation serve as an effective user-level rate control scheme. We also show that Skype video calls are indeed TCPfriendly and respond to congestion quickly when the network is overloaded. I...|$|R
5000|$|Katz <b>back-off</b> is a {{generative}} n-gram {{language model}} that estimates the conditional {{probability of a}} word given its history in the n-gram. It accomplishes this estimation by [...] "backing-off" [...] to models with smaller histories under certain conditions. By doing so, the model with the most reliable information about a given history is used to provide the better results.|$|E
5000|$|Note: Vasileseu et al. {{implementation}} {{considers a}} <b>back-off</b> strategy for words {{not covered by}} the algorithm, consisting of the most frequent sense defined in WordNet. This means that words for which all their possible meanings lead to zero overlap with current context or with other word definitions are by default assigned sense number one in WordNet." ...|$|E
50|$|A {{negative}} {{side effect of}} the capture effect would be the idle time created due to stations backing off. Once one station is finished transmitting on the medium, large idle times are present because all other stations were continually backing off. In some instances, <b>back-off</b> can occur {{for so long that}} some stations actually discard packets because maximum attempt limits have been reached.|$|E
30|$|Many {{existing}} works {{have been proposed}} to address the congestion misjudgement issue in wireless TCP. Packet losses due to route breaks in ad hoc wireless networks have been noticed in [3 – 8]. TCP-F in [3] is proposed to feed back the route break information to the source. On receiving the feedback, the source then freezes the sending window and suspends sending packets. The contention in the shared medium is another reason that causes packet losses. It is shown in [9] that link layer drops due to medium contention are the first sign for network overload. Link-layer random early dropping (LRED) and adaptive pacing are then proposed in [9] to stabilize the TCP window size around the best size, where LRED tunes up the link-layer dropping probability according to channel conditions and adaptive pacing extends the range of link-layer contention coordination. Rather than <b>back-offing</b> an additional packet transmission time in [9], the cross-layer TCP pacing in [10] adjusts the contention window to improve throughput. Backward end-to-end acknowledgement (ACK) transmissions also involves in the contention with forward data transmissions for the network resources. Compressing ACKs is another means to improve TCP throughput. The reference [11] proposed to minimize the number of ACK packets by delaying ACK packets according to the channel condition, thus mitigating channel contention and improve TCP’s throughput.|$|R
40|$|International audienceGPS is a {{commonly}} used and convenient technology for determining absolute position in outdoor environments, but its {{high power consumption}} leads to rapid battery depletion in mobile devices. An obvious solution is to duty cycle the GPS module, which prolongs the device lifetime {{at the cost of}} increased position uncertainty while the GPS is off. This paper addresses the tradeoff between energy consumption and localization performance in a mobile sensor network application. The focus is on augmenting GPS location with more energy- efficient location sensors to bound position estimate uncertainty while GPS is off. Empirical GPS and radio contact data from a large-scale animal tracking deployment is used to model node mobility, radio performance and GPS. Because GPS takes a considerable, and variable, time after powering up before it delivers a good position measurement, we model the GPS behaviour through empirical measurements of two GPS modules. These models are then used to explore duty cycling strategies for maintaining position uncertainty within specified bounds. We then explore the benefits of using short-range radio contact logging alongside GPS as an energy-inexpensive means of lowering uncertainty while the GPS is off, and we propose strategies that use RSSI ranging and GPS <b>back-offs</b> to further reduce energy consumption. Results show that our combined strategies can cut node energy consumption by one third while still meeting application-specific positioning criteria...|$|R
30|$|A further {{observation}} is that, when {{the amount of}} offered traffic to the network reaches a certain level (mean data session arrival rate of 15 – 16 sessions/s in our scenario), the performance difference between the SON functions becomes minimal. This is because, in the end, the total network capacity remains fixed and limited. The SON solutions allow load balancing between the LTE and WLAN systems and use network resources more efficiently. However, once both systems are highly loaded at the same time, ANS SON can only offer minimal help. Different solutions {{would be required to}} address this situation such as enabling additional capacity for the existing network or by means of a denser deployment of LTE small cells and APs. Thus, larger gains can be found at lower and medium load levels, where ANS SON has more freedom to operate. On the other hand, the 10 th percentile throughput is still sensitive to differences in SON schemes, even at very high load situations, particularly for the case of LTE LC. By providing protection against congestion limited to the LTE network, at high offered load levels, LTE LC based ANS pushes too much traffic to be served by WLAN. This causes WLAN throughput performance to suffer drastically due to the MAC design which is based on contention-based random access and suffers from inevitable collisions and <b>back-offs.</b>|$|R
50|$|Unlike 10BASE-T, 100BASE-T and 1000BASE-T PHYs, {{providing}} a single rate of 10, 100, or 1000 Mbit/s respectively, 2BASE-TL link rate can vary, {{depending on the}} copper media characteristics (such as length, wire diameter or gauge, number of pairs if the link is aggregated, amount of crosstalk between the pairs, etc.), desired link parameters (such as desired SNR margin, Power <b>Back-Off,</b> etc.), and regional spectral limitations.|$|E
50|$|Because Jules Verne was {{the first}} ATV, several on-orbit {{demonstration}} tests were performed in order to confirm that {{it was able to}} safely approach and dock with the ISS. After launch, the ATV spent three weeks in free flight. It successfully underwent Collision Avoidance Manoeuvre (CAM) tests on 13 March and 14 March, ensuring that the CAM could be conducted as a last <b>back-off</b> mechanism should all other systems fail during the docking manoeuvre.|$|E
50|$|Additional <b>back-off</b> {{algorithms}} {{have been}} developed and researched to improve performance. The basic principle {{is based on the}} use of sequencing techniques where each node in the wireless network maintains a counter which limits the number attempts to {{less than or equal to}} the sequence number or use wireless channel states to control the access probabilities so that a node with a good channel state has a higher probability of contention success. This reduces the number of collisions.|$|E
40|$|GPS is a {{commonly}} used and convenient technology for determining absolute position in outdoor environments, but its {{high power consumption}} leads to rapid battery depletion in mobile devices. An obvious solution is to duty cycle the GPS module, which prolongs the device lifetime {{at the cost of}} increased position uncertainty while the GPS is off. This article addresses the trade-off between energy consumption and localization performance in a mobile sensor network application. The focus is on augmenting GPS location with more energy-efficient location sensors to bound position estimate uncertainty while GPS is off. Empirical GPS and radio contact data from a large-scale animal tracking deployment is used to model node mobility, radio performance, and GPS. Because GPS takes a considerable, and variable, time after powering up before it delivers a good position measurement, we model the GPS behaviour through empirical measurements of two GPS modules. These models are then used to explore duty cycling strategies for maintaining position uncertainty within specified bounds. We then explore the benefits of using short-range radio contact logging alongside GPS as an energy-inexpensive means of lowering uncertainty while the GPS is off, and we propose strategies that use RSSI ranging and GPS <b>back-offs</b> to further reduce energy consumption. Results show that our combined strategies can cut node energy consumption by one third while still meeting application-specific positioning criteria...|$|R
40|$|OFDM (Orthogonal Frequency Division multiplexing) {{has several}} {{properties}} which {{make it an}} attractive modulation scheme for high speed transmission. One marjor difficulty, however, is its high peak-to-average-power ratio (PAPR). If a class A power amplifier is used, a 5 MHz OFDM signal should be <b>back-offed</b> to an unacceptable level which gives an average power efficiency of about 5 %. To reduce the PAPR, many baseband techniques have been proposed. However, even these techniques are applied, a linear power amplifier is still required and the power efficiency cannot be improved too much. Instead of attempting to reduce peak-to-average power ratio, a power amplifier linearization technique called Envelope Elimination and Restoration (EER) is adopted in this project to amplify the OFDM signal. System simulation was done on a 5 MHz OFDM radio system {{to find out the}} required parameters of the EER PA. A 5 MHz bandwidth switching mode power converter, which is applied to linearize RF power amplifier, has also been designed using delta modulation with 500 MHz sampling frequency. The power converter was fabricated using AMS 0. 8 μm BiCMOS process. The measured maximum power efficiency is 80 % and the maximum harmonic distortion is about - 35 dBc. The power converter is used to linearize a nonlinear RF power amplifier which operates in 1. 8 GHz to 2 GHz. The measurement results show that the EER power amplifier successfully linearizes the nonlinear power amplifier by reducing the maximum harmonic distortion to less than - 30 dBc and raising the efficiency from 15 % to 35 % at 22 dBm output power...|$|R
40|$|Over {{the last}} 10 years, Wireless Sensor Networks (WSNs) have evolved as a hot {{interdisciplinary}} research area. What {{started as a}} concept of ubiquitous computing with the initial assumptions of low-cost and low power sensing, has now progressed {{to the development of}} new wireless sensing applications supported by the advancement of computing devices. Similarly, a vast number of said applications have also emerged with varying Quality of Service (QoS) requirements. It is our argument that the current approach whereby {{there is a need to}} customise protocols for individual applications contributes to the slow uptake WSN in the real world. Likewise, we believe that generalised solutions are not always appropriate and while tailor-made solutions are costly. Therefore, we advocate that protocols that understand the notion of a classification of WSN applications can be a potential solution to this problem; in that the tailoring pertains to the type of application or their behaviour classes. Hence, we present the design of a classification-based cross-layer WSN stack that considers Dual-Mode Periodic Data Collection and Event- Driven Monitoring (D-PEDM) applications. In this thesis, we first derive the D-PEDM protocol configuration parameters through thorough analysis of the QoS requirements, physical constraints, and resource constraints of D-PEDM applications. Once the DPEDM protocol configuration parameters are derived, we design an Emergent Broadcast Slot (EBS) scheme, as well as Medium Access Control (YA-MAC) and efficient Priority Based Routing (PBR) protocols. We evaluate each protocol individually as well as an integrated cross-layer stack using the WSN standard test-beds. Further, we show how an Adaptive Rate Control (ARC) protocol can be used with these types of applications. More specifically we introduce the EBS synchronisation scheme that efficiently handles control messages (broadcast messages) in Duty-Cycled Multi-hop (DCM) networks by integrating routing and application broadcast messages together. This approach minimises the overhead caused by control messages that results in improved application level throughput. Additionally, EBS enables efficient decentralised sleep-awake coordination among neighbourhood nodes that improves the power usage in battery-powered sensor devices up to 5 - 6 times. To meet the latency requirements of the D-PEDM applications, YA-MAC provides support to handle unicast messages in an asynchronous manner that not only reduces the event traffic latency but also reduces contention in the network. To further improve the latency and reliabilities of bursty event traffic; PBR uses a priority queuing mechanism and traffic differentiation schemes. In the traffic differentiation scheme, PBR gives priority to event traffic and diverts non-priority traffic away from the event traffic path to alternative random paths. This favours the QoS of event traffic in many ways: first, it reduces the contention in the event traffic path resulting in less collisions and fewer <b>back-offs</b> at MAC layer, which in turn significantly improves end-to-end event traffic latency (by 10 ms per hop). Additionally, the MAC layers reduced numbers of <b>back-offs</b> inherently reduces re-transmissions by 70 % thereby reducing the energy consumption by 2 / 3. Furthermore, PBR increases the probability of event data reaching the Sink/Base-station as compared to that of when both event and non-event share same paths. The D-PEDM cross-layer stack, which includes EBS, YA-MAC, and PBR, achieves 80 % application level throughput while operating in less than 10 % duty-cycle in presence of relatively high unicast data traffic. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
