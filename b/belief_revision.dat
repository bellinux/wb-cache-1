1170|57|Public
25|$|Epistemology and <b>belief</b> <b>revision.</b> Paraconsistent logic {{has been}} {{proposed}} {{as a means of}} reasoning with and revising inconsistent theories and belief systems.|$|E
25|$|Likened to a Bayesian network, an HTM {{comprises}} {{a collection}} of nodes that are arranged in a tree-shaped hierarchy. Each node in the hierarchy discovers an array of causes in the input patterns and temporal sequences it receives. A Bayesian <b>belief</b> <b>revision</b> algorithm is used to propagate feed-forward and feedback beliefs from child to parent nodes and vice versa. However, the analogy to Bayesian networks is limited, because HTMs can be self-trained (such that each node has an unambiguous family relationship), cope with time-sensitive data, and grant mechanisms for covert attention.|$|E
50|$|Systems {{specifically}} implementing <b>belief</b> <b>revision</b> are: Immortal, SATEN, and BReLS. Two systems {{including a}} <b>belief</b> <b>revision</b> feature are SNePS and Cyc. Truth maintenance systems {{are used in}} Artificial Intelligence to implement <b>belief</b> <b>revision.</b>|$|E
30|$|<b>Beliefs</b> <b>revision</b> {{is not a}} local {{operation}} and {{requires a lot of}} work also because the revision feedbacks also on other Ks and on the reliability of the sources. Have I to discredit a source? Can I do that? How much revision and integration work would this require.|$|R
40|$|This paper {{discusses}} {{the strengths and}} weaknesses of non-monotonic-offers in alternating-offer bargaining protocol. It is commonly assumed that bargainers submit monotonic offers over time, which correspond to their <b>belief</b> <b>revisions.</b> However, through formal analysis and simulations, we are able to show that nonmonotonic-offers protocols can generate higher average surplus and lower breakdown rate compared to monotonic-offers protocols. 1...|$|R
40|$|We {{revisit the}} problem of {{revising}} probabilistic beliefs using uncertain evidence, and report results on four major issues relating to this problem: How to specify uncertain evidence? How to revise a distribution? Should, and do, iterated <b>belief</b> <b>revisions</b> commute? And how to provide guarantees {{on the amount of}} belief change induced by a revision? Our discussion is focused on two main methods for probabilistic revision: Jeffrey's rule of probability kinematics and Pearl's method of virtual evidence, where we analyze and unify these methods {{from the perspective of the}} questions posed above. ...|$|R
50|$|<b>Belief</b> <b>revision</b> is {{the process}} of {{changing}} beliefs to take into account a new piece of information. The logical formalization of <b>belief</b> <b>revision</b> is researched in philosophy, in databases, and in artificial intelligence for the design of rational agents.|$|E
50|$|<b>Belief</b> <b>revision</b> is {{the process}} of {{changing}} beliefs to accommodate a new belief that might be inconsistent with the old ones. In the assumption that the new belief is correct, some of the old ones have to be retracted in order to maintain consistency. This retraction in response to an addition of a new belief makes any logic for <b>belief</b> <b>revision</b> to be non-monotonic. The <b>belief</b> <b>revision</b> approach is alternative to paraconsistent logics, which tolerate inconsistency rather than attempting to remove it.|$|E
5000|$|Hannes Leitgeb (<b>belief</b> <b>revision,</b> probability, Bayesianism, etc.) ...|$|E
40|$|AbstractWe {{revisit the}} problem of {{revising}} probabilistic beliefs using uncertain evidence, and report results on several major issues relating to this problem: how should one specify uncertain evidence? How should one revise a probability distribution? How should one interpret informal evidential statements? Should, and do, iterated <b>belief</b> <b>revisions</b> commute? And what guarantees can be offered {{on the amount of}} belief change induced by a particular revision? Our discussion is focused on two main methods for probabilistic revision: Jeffrey's rule of probability kinematics and Pearl's method of virtual evidence, where we analyze and unify these methods {{from the perspective of the}} questions posed above...|$|R
40|$|Bilattice-based {{triangle}} {{provides an}} elegant algebraic structure for reasoning with vague and uncertain information. But {{the truth and}} knowledge ordering of intervals in bilattice-based triangle can not handle repetitive <b>belief</b> <b>revisions</b> which is an essential characteristic of nonmonotonic reasoning. Moreover the ordering induced over the intervals by the bilattice-based triangle is not sometimes intuitive. In this work, we construct an alternative algebraic structure, namely preorder-based triangle and we formulate proper logical connectives for this. It is also demonstrated that Preorder-based triangle serves {{to be a better}} alternative to the bilattice-based triangle for reasoning in application areas, that involve nonmonotonic fuzzy reasoning with uncertain information...|$|R
40|$|Abstract. Representation {{of belief}} states is an {{important}} issue for knowledge based systems. In this paper, we develop a matrix representation for ordered belief states and show that <b>belief</b> reasoning, <b>revision</b> and fusion can all be interpreted as operations of matrix algebra. Thus, the matrix representation can serve as the basis of algebraic semantics for belief logic...|$|R
5000|$|Hans Rott (<b>belief</b> <b>revision,</b> nonmonotonic logic, {{rational}} choice) ...|$|E
5000|$|Alexandru Baltag (dynamic-epistemic logic, {{probabilistic}} logics, <b>belief</b> <b>revision</b> etc.) ...|$|E
5000|$|John Collins Columbia, Philosophy (<b>belief</b> <b>revision,</b> causal {{decision}} theory) ...|$|E
40|$|This paper {{describes}} how we simulate a dialog aimed at resolving conflicts between an Instructing and an Executing Agent in explanation text planning. We describe {{how the two}} agents are modelled. We then illustrate the algorithm which, starting from {{the discovery of a}} conflict and proceeding through a set of negotiated <b>belief</b> <b>revisions,</b> brings to solve the conflict or to conclude that it cannot be solved. An example in the domain of drug prescription is provided. 1. INTRODUCTION In this paper we consider a particular case of collaborative activity, where an Instructing Agent (IA) has to explain to an Executing Agent (EA) how to perform an action. However, IA's and EA's views about whether to talk about a specific subject can be in conflict: IA might consider irrelevant or inappropriate to talk about subjects which, on the contrary, EA finds interesting, or the inverse. To solve this conflict, the two agents should be able to initiate a dialogue aimed at understanding the reasons of t [...] ...|$|R
40|$|This study {{measures}} the economic consequences of information security activities, in general, {{and more specifically}} {{the market value of}} disclosures of information security activities. Since information security activities are primarily non-revenue generating, management tends to view them as the cost-of-doing-business, with no impact on firm value. Furthermore, managers are reluctant to share the details, because that {{they do not want to}} attract the attention of hackers. However, voluntary disclosures of information security can help reduce information asymmetry, which leads to <b>belief</b> <b>revisions</b> by investors, and hence corrects the misspecifications (if any) of the firm’s market value. In other words, voluntary disclosures of security activities are signaling mechanisms. The objective of this dissertation is to develop a taxonomy of disclosures of information security activities, and empirically test the value relevance of such disclosures. Based on a sample of 1, 637 disclosing firms, the empirical results provide support for the argument that voluntary disclosures of information security activities are value-relevant. Industry-wide analyses support the disclosure taxonomy developed, and highlight that firms which are technology an...|$|R
40|$|Abstract — The {{knowledge}} {{that must be}} acquired by machine learning systems which try to mimic common sense, as exhibited by humans, is inherently incomplete, redundant or even contradictory. Thus, the main characteristics of common sense is nonmonotonicity, which is introduced by exceptions to general rules, redundancy, which is introduced by continuous <b>belief</b> <b>revisions</b> and ambiguity, which is introduced by conflicting information. Incorporating common sense into artificial intelligent systems {{plays an important role}} in their development. In all cases presented in the literature, common sense is investigated within the context of artificial reasoning systems. In this paper, we examine common sense within the context of a machine learning system which, of course, is also capable for reasoning. More specifically, we present how the proposed NRL system can handle nonmonotonicity, redundancy and ambiguity, in a consistent manner. NRL is based on a hybrid machine learning system capable of acquiring symbolic knowledge of a domain, refining it using a set of classified examples along with Connectionist learning techniques and, finally, extracting comprehensible symbolic information. Moreover, we present how NRL can be used in classification, as a data mining task. Copyright c ○ 2004...|$|R
5000|$|Isaac Levi Columbia, Philosophy (<b>belief</b> <b>revision,</b> {{decision}} theory, probability) ...|$|E
5000|$|James Hawthorne (confirmation theory, {{inductive}} logic, <b>belief</b> <b>revision,</b> nonmonotonic logic) ...|$|E
5000|$|Sven Ove Hansson (risk, {{decision}} theory, <b>belief</b> <b>revision,</b> deontic logic) ...|$|E
40|$|In Hart and Kurz (1983), {{stability}} and formation of coalition structures {{has been investigated}} in a noncooperative framework in which the strategy of each player is the coalition he wishes to join. However, given a strategy profile, the coalition structure formed is not unequivocally determined. In order to solve this problem, they proposed two rules of coalition structure formation: the γ and the δ models. In this paper we look at evolutionary games arising from the γ model for situations in which each player can choose mixed strategies and has vague expectations about the formation rule of the coalitions in which is not involved; players determine at every instant their strategies and we study how, for every player, subjective beliefs {{on the set of}} coalition structures evolve coherently to the strategic choices. Coherency is regarded as a viability constraint for the differential inclusions describing the evolutionary game. Therefore, we investigate viability properties of the constraints and characterize velocities of pairs belief/strategies which guarantee that coherency of beliefs is always satisfied. Finally, among many coherent <b>belief</b> <b>revisions</b> (evolutions), we investigate those characterized by minimal change and provide existence results. ...|$|R
40|$|We {{propose a}} new {{relevance}} sensitive model for representing and revising belief structures, which {{relies on a}} notion of partial language splitting and tolerates some amount of inconsistency while retaining classical logic. The model preserves an agent's ability to answer queries in a coherent way using Belnap's four-valued logic. Axioms analogous to the AGM axioms hold for this new model. The distinction between implicit and explicit beliefs is represented and psychologically plausible, computationally tractable procedures for query answering and <b>belief</b> base <b>revision</b> are obtained...|$|R
40|$|We {{examine how}} {{investor}} preferences and beliefs affect trading {{in relation to}} past gains and losses. The probability of selling {{as a function of}} profit is V-shaped; at short holding periods, investors are more likely to sell big losers than small ones. There is little evidence of an upward jump in selling at zero profits. These findings provide no clear indication that realization preference explains trading. Furthermore, the disposition effect is not driven by a simple direct preference for selling a stock by virtue of having a gain versus a loss. Trading based on <b>belief</b> <b>revisions</b> can potentially explain these findings. (JEL G 11, G 12, G 14) What makes individual investors trade, and how do they trade in relation to their past gains and losses? Several studies have examined aspects of these fundamental questions by testing whether the probability of selling (or of buying additional shares) differs depending on whether the investor experienced a previous gain versus a loss. For example, the literature on the disposition effect reports that investors are more likely to sell winners than losers. A leading explanation that has been offered is that investors are reluctant to realize their losses, either because of a direct disutility from doing so (which we cal...|$|R
50|$|There {{are related}} (and {{slightly}} competing) systems of reasoning that are newer than systems of defeasible reasoning, e.g., <b>belief</b> <b>revision</b> and dynamic logic. The dialogue logics of Charles Hamblin and Jim Mackenzie, and their colleagues, {{can also be}} tied closely to defeasible reasoning. <b>Belief</b> <b>revision</b> is a non-constructive specification of the desiderata with which, or constraints according to which, epistemic change takes place. Dynamic logic is related mainly because, like paraconsistent logic, the reordering of premises can change the set of justified conclusions. Dialogue logics introduce an adversary, but are like <b>belief</b> <b>revision</b> theories in their adherence to deductively consistent states of belief.|$|E
5000|$|Kevin T. Kelly, Carnegie Mellon, Philosophy (computational epistemology, <b>belief</b> <b>revision,</b> etc.) ...|$|E
50|$|The {{following}} models use belief propagation or <b>belief</b> <b>revision</b> in singly connected Bayesian networks.|$|E
30|$|The free {{circulation}} of contents is facilitating users attention to critical matter {{such as the}} financial crisis {{as well as any}} political argument. However, in this work we show that unsubstantiated rumors are pervasive in online social media and they might affect users <b>belief</b> formation and <b>revision.</b>|$|R
40|$|We {{introduce}} {{a number of}} contraction operations {{that allow us to}} preserve more information in the process of <b>belief</b> contraction and <b>revision</b> of our epistemic states. One of them, choice contraction, will be argued to characterise basic (in) dependence relations among propositions belonging to the epistemic state...|$|R
40|$|In {{this paper}} we {{investigate}} how to model legal abrogation and annulment in Defeasible Logic. We examine some options that embed in this setting, and similar rule-based systems, ideas from <b>belief</b> and base <b>revision.</b> In both cases, our conclusion is negative, which suggests {{to adopt a}} different logical model...|$|R
5000|$|... a {{sensory input}} is {{received}} by the <b>belief</b> <b>revision</b> function and agent's beliefs are altered ...|$|E
5000|$|The problem about <b>belief</b> <b>revision</b> that is {{the most}} studied {{from the point of view}} of {{computational}} complexity is that of query answering in the propositional case. This is the problem of establishing whether a formula follows from the result of a revision, that is, , where , , and [...] are propositional formulae. More generally, query answering is the problem of telling whether a formula is entailed by the result of a <b>belief</b> <b>revision,</b> which could be update, merging, revision, iterated revision, etc. Another problem that has received some attention is that of model checking, that is, checking whether a model satisfies the result of a <b>belief</b> <b>revision.</b> A related question is whether such result can be represented in space polynomial in that of its arguments.|$|E
5000|$|Horacio Arló-Costa, Carnegie Mellon, Philosophy (Bayesian epistemology, epistemic logic, <b>belief</b> <b>revision,</b> conditionals, {{rational}} choice, normative {{and behavioral}} decision theory) ...|$|E
40|$|In {{this paper}} we study the {{dynamics}} of belief from an agent-oriented, semantics-based point of view. In a formal framework used to specify and to reason about formal agents, we dene actions that model three well- known changes of belief, viz. expansions, contractions, and revisions. We treat these belief changes as full- edged actions by dening both the op- portunity for and result of these actions, {{and the ability of}} agents to apply these belief-changing actions. In dening the result of the contraction ac- tion we introduce the concept of selection functions. These are special functions that select a subset of the set of states that is {{to be added to the}} set of doxastic alternatives of an agent, thereby contracting its set of beliefs. The action that models <b>belief</b> <b>revisions</b> is dened as the sequen- tial composition of a contraction and an expansion. We show that these belief-changing actions are dened in an intuitively acceptable, reasonable way by proving that the G?ardenfors postulates for belief changes are val- idated. The ability of agents to apply belief-changing actions is dened in terms of their knowledge and belief. These denitions are such that actions that an agent is capable of performing lead to desired states of aairs. The resulting framework provides an intuitively acceptable yet simple formalization of expansions, contractions and revisions as actions in a dynamic/epistemic, agent-oriented framework...|$|R
40|$|Abstract. In {{this paper}} we {{investigate}} how to represent and reason about legal abrogations and annulments in Defeasible Logic. We examine some options that embed in this setting, and in similar rule-based systems, ideas from <b>belief</b> and base <b>revision.</b> In both cases, our conclusion is negative, which suggests {{to adopt a}} different logical model. This model expresses temporal aspects of legal rules, and distinguishes between two main timelines, one internal to a given temporal version of the legal system, and another relative to how the legal system evolves over time. Accordingly, we propose a temporal extension of Defeasible Logic suitable to express this model and to capture abrogation and annulment. We show that the proposed framework overcomes the difficulties discussed in regard to <b>belief</b> and base <b>revision,</b> and is sufficiently flexible to represent many of the subtleties characterizing legal abrogations and annulments. ...|$|R
40|$|We present three {{approaches}} to <b>belief</b> base <b>revision,</b> which are examined {{also in the}} {{case in which the}} sentences in the base are partitioned between those which can and those which cannot be changed; the approaches are shown to be semantically equivalent. A new approach is then presented, based on the modification of individual rules, instead of deletion. The resulting base is semantically equivalent to that generated by the other approaches, {{in the sense that it}} has the same models, but the rule part alone has less models, that is, is subjected to a smaller change...|$|R
