896|448|Public
25|$|To {{choose a}} {{value for n}} in an n-gram model, it is {{necessary}} to find the right trade off between the stability of the estimate against its appropriateness. This means that trigram (i.e. triplets of words) is a common choice with large training corpora (millions of words), whereas a <b>bigram</b> is often used with smaller ones.|$|E
500|$|... as {{the word}} 'the' and the word 'cat' appear once each in the candidate, and {{the total number of}} words is two. The {{modified}} <b>bigram</b> precision would be [...] as the <b>bigram,</b> [...] "the cat" [...] appears once in the candidate. It has been pointed out that precision is usually twinned with recall to overcome this problem , as the unigram recall of this example would be [...] or [...] The problem being that as there are multiple reference translations, a bad translation could easily have an inflated recall, such as a translation which consisted of all the words in each of the references.|$|E
2500|$|Linear {{interpolation}} (e.g., {{taking the}} weighted {{mean of the}} unigram, <b>bigram,</b> and trigram) ...|$|E
40|$|We outline an {{implementation}} of Viterbi beam search that incorporates layered <b>bigrams.</b> Layered <b>bigrams</b> are class <b>bigrams</b> {{in which some}} nodes are themselves <b>bigrams,</b> resulting in a recursive structure. The implementation is in C ++ and involves a hierarchy of classes. The paper outlines the main concepts and the corresponding C ++ classes...|$|R
50|$|Head word <b>bigrams</b> are gappy <b>bigrams</b> with an {{explicit}} dependency relationship.|$|R
5000|$|... where nt is {{the number}} of {{character}} <b>bigrams</b> found in both strings, nx {{is the number}} of <b>bigrams</b> in string x and ny {{is the number of}} <b>bigrams</b> in string y. For example, to calculate the similarity between: ...|$|R
2500|$|The cipher {{materials}} {{captured on}} U-505 included the special [...] "coordinate" [...] code, the regular and officer Enigma settings for June 1944, the current short weather codebook, the short signal codebook, and <b>bigram</b> tables due {{to come into}} effect in July and August respectively.|$|E
2500|$|Eve {{could use}} {{frequency}} analysis {{to help solve}} the message along the following lines: counts of the letters in the cryptogram show that I {{is the most common}} single letter, XL most common <b>bigram,</b> and XLI is the most common trigram. e is the most common letter in the English language, th is the most common <b>bigram,</b> and the is the most common trigram. This strongly suggests that X~t, L~h and [...] I~e. The second most common letter in the cryptogram is E; since the first and second most frequent letters in the English language, e and t are accounted for, Eve guesses that E~a, the third most frequent letter. Tentatively making these assumptions, the following partial decrypted message is obtained.|$|E
2500|$|Note that in {{a simple}} n-gram {{language}} model, {{the probability of a}} word, conditioned on some number of previous words (one word in a <b>bigram</b> model, two words in a trigram model, etc.) can be described as following a categorical distribution (often imprecisely called a [...] "multinomial distribution").|$|E
50|$|Gappy <b>bigrams</b> or {{skipping}} <b>bigrams</b> are word pairs {{which allow}} gaps (perhaps avoiding connecting words, or allowing some simulation of dependencies, as in a dependency grammar).|$|R
30|$|Considering the {{successful}} n-grams {{based on research}} found in literature [1, 4, 29, 30], we decided to utilize an n-grams model as our baseline with three scenarios: only unigrams, only <b>bigrams,</b> and unigrams combined with <b>bigrams.</b>|$|R
30|$|The indexes of {{accuracy}} considering only unigrams and <b>bigrams</b> were 83.89 and 83.77 %, respectively. Combining unigrams and <b>bigrams</b> through a {{multiple linear regression}} model, the index was 83.95 % {{and that of the}} human evaluators was 84.93 %.|$|R
2500|$|The {{material}} from U-505 {{arrived at the}} decryption establishment at Bletchley Park on 20 June 1944. While the Allies were able to break most Enigma settings by intense cryptanalysis (including heavy use of the electromechanical [...] "bombes"), having the Enigma settings for the U-boats {{saved a lot of}} work and time, which could be applied to other keys. The settings break was only valid until the end of June and therefore had an extremely limited outcome on the eventual cracking of the Enigma code, but having the weather and short signal codebooks and <b>bigram</b> tables made the work easier.|$|E
2500|$|Letter frequencies, like word frequencies, tend to vary, both by {{writer and}} by subject. One cannot {{write an essay}} about x-rays without using {{frequent}} Xs, and the essay will have an idiosyncratic letter frequency if the essay is about the frequent use of x-rays to treat zebras in Qatar. Different authors have habits which can be reflected {{in their use of}} letters. Hemingway's writing style, for example, is visibly different from [...] Faulkner's. Letter, <b>bigram,</b> trigram, word frequencies, word length, and sentence length can be calculated for specific authors, and used to prove or disprove authorship of texts, even for authors whose styles are not so divergent.|$|E
50|$|A <b>bigram</b> or digram is a {{sequence}} of two adjacent elements from a string of tokens, which are typically letters, syllables, or words. A <b>bigram</b> is an n-gram for n=2. The frequency distribution of every <b>bigram</b> in a string is commonly used for simple statistical analysis of text in many applications, including in computational linguistics, cryptography, speech recognition, and so on.|$|E
30|$|Our LSA model preprocesses {{the answers}} using unigrams and <b>bigrams</b> of words: it codes {{the rows of}} the initial matrix based on the occurrences of unigrams (or <b>bigrams)</b> and the columns show the answers; the {{reference}} answer is in the first column.|$|R
30|$|This {{study had}} four main objectives: {{to create a}} model of co-occurrence of unigrams and <b>bigrams,</b> to combine <b>bigrams</b> and LSA, to adjust the LSA scores {{based on the number}} of words per answer, and to compare LSA-attributed score {{distribution}} with that of human evaluators.|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceThis paper {{describes}} {{a method for}} detectingvimpossible <b>bigrams</b> using a vocabulary of V elements. The idea is to discard all the ungrammatical events to expect an improvement of the language model. We extract the impossible <b>bigrams</b> by using automatic rules. The biclass associations which are ungrammatical are detected and all the corresponding <b>bigrams</b> are analyzed and set as possible or impossible events, we also decided to manage {{for each of the}} retrieved rule an exception list...|$|R
5000|$|For example, if the <b>bigram</b> [...] "on the" [...] is {{correctly}} matched, it {{will receive}} lower weight than the correct matching of <b>bigram</b> [...] "interesting calculations", {{as this is}} less likely to occur.|$|E
5000|$|The cipher had two stages: a {{transposition}} {{followed by}} <b>bigram</b> substitution. In the transposition stage, the cipher clerk would write out the plaintext into a [...] "cage" [...] — a shape {{on a piece}} of paper. Pairs of letters were then substituted using a set of <b>bigram</b> tables.|$|E
50|$|<b>Bigram</b> {{frequency}} is {{one approach}} to statistical language identification.|$|E
40|$|This paper {{describes}} a statistical methodology ibr automatically retrieving collocations from POS tagged Korean text using interrupted <b>bigrams.</b> The free order of Korean {{makes it hard}} to identify collocations. We devised four staffstics, 'frequency', 'randomness', 'condensation', and 'correlation'. to account for the more flexible word order properties of Korean collocations. Ve extracted meaningful <b>bigrams</b> using an evaluation function 'and extended the <b>bigrams</b> to n-gram collocatibns by generating equivalence sets, (-covers. We view a modeling problem for n-gram collocations as that for clustering of co- hesive words...|$|R
30|$|The indexes of {{accuracy}} considering only unigrams and <b>bigrams</b> were 78.5 and 75.37 %, respectively. To combine unigrams and <b>bigrams</b> {{in a single}} variable, we used a multiple linear regression model and for this variable, the index was 78.93 %. For both human evaluators, this index was 93.94 %.|$|R
30|$|Though {{some may}} argue {{that the use of}} <b>bigrams</b> with LSA is not viable for some {{applications}} due to size limitations on the initial matrices (the matrixes were around 1805 × 229), we find it possible to apply <b>bigrams</b> to this domain, since they are composed of short written answers (averaging 25 to 70 words) to open-ended questions from a higher education institution’s exam. Furthermore, we only count those <b>bigrams</b> that appear at least in two answers, as to avoid a high number of null entries in the initial matrix.|$|R
5000|$|... {{and this}} was sent without further encoding, and {{preceding}} the encrypted message. The message was sent by Morse and {{on the receiving end}} the procedure was reversed. Nine <b>bigram</b> tables were known to exist, including FLUSS or FLUSZ (English:River)). Other <b>bigram</b> booklets existed and were used including BACH (1940), STROM (1941) and TEICH, UFER etc.|$|E
5000|$|A major advance {{came through}} Operation Claymore, a {{commando}} {{raid on the}} Lofoten Islands on 4 March 1941. The German armed trawler Krebs was captured, including the complete Enigma keys for February, but no <b>bigram</b> tables or K-book. However, the material was sufficient to reconstruct the <b>bigram</b> tables by [...] "EINS-ing", and by late March they were almost complete.|$|E
5000|$|Linear {{interpolation}} (e.g., {{taking the}} weighted {{mean of the}} unigram, <b>bigram,</b> and trigram) ...|$|E
40|$|We use n-gram {{techniques}} to identify dependencies between student affective states of certainty and subsequent tutor dialogue acts, in an annotated corpus of human-human spoken tutoring dialogues. We first represent our dialogues as <b>bigrams</b> of annotated student and tutor turns. We next use χ 2 analysis to identify dependent <b>bigrams.</b> Our results show dependencies between many student states and subsequent tutor dialogue acts. We then analyze the dependent <b>bigrams</b> and suggest ways that our current computer tutor {{can be enhanced}} to adapt its dialogue act generation based on these dependencies. ...|$|R
40|$|Inconsonant <b>Bigrams</b> {{is what i}} call another wordplay form I 2 ̆ 7 ve dabbled in, {{probably}} not original, that makes sentences out of <b>bigrams</b> in which the vowel and its position are constant and only the consonants are inconstant. This is sort of the inverse of Vowel Movements in the February 1998 Kickshaws, as well as 2 ̆ 2 Vowel Cascades, Vowel Movements and Di-Odes 2 ̆ 2 in the February 2002 Word Ways. (Perhaps a better name for Inconsonant <b>Bigrams</b> would be Consonant Movements.) Is there an official name for this...|$|R
50|$|The {{technique}} encrypts {{pairs of}} letters (<b>bigrams</b> or digrams), instead of single letters {{as in the}} simple substitution cipher and rather more complex Vigenère cipher systems then in use. The Playfair is thus significantly harder to break since the frequency analysis used for simple substitution ciphers does not work with it. The frequency analysis of <b>bigrams</b> is possible, but considerably more difficult. With 600 possible <b>bigrams</b> rather than the 26 possible monograms (single symbols, usually letters in this context), a considerably larger cipher text is {{required in order to}} be useful.|$|R
50|$|<b>Bigram</b> {{frequency}} attacks {{can be used}} in cryptography {{to solve}} cryptograms. See frequency analysis.|$|E
5000|$|Student's t-test {{can be used}} to {{determine}} whether the occurrence of a collocation in a corpus is statistically significant. For a <b>bigram</b> , let [...] be the unconditional probability of occurrence of [...] in a corpus with size , and let [...] be the unconditional probability of occurrence of [...] in the corpus. Then the t-score for the <b>bigram</b> [...] is calculated as: ...|$|E
5000|$|Encipherment with a <b>Bigram</b> table called double-letter {{conversion}} table (German:Doppelbuchstabentauschtafel), arranged with vertical pairs, was as follow: ...|$|E
30|$|Next-Frequent: Recommend the K most {{frequent}} trainings that have appeared immediately after c_m {{in the training}} data. That is, find all <b>bigrams</b> of the form 〈 c_m, x 〉 in the training data, order {{them in terms of}} their frequencies and select the second elements from the top K <b>bigrams.</b>|$|R
40|$|Abstract. This paper {{presents}} the results obtained by the University at Buffalo (UB) in CLEF 2003. Our efforts concentrated in the monolingual retrieval and large multilingual retrieval tasks. We used {{a modified version of}} the SMART system, a heuristic method based on <b>bigrams</b> to generate phrases that works across multiple languages, and pseudo relevance feedback. Query translation was performed using publicly available machine translation software. Our results show small but consistent improvements in performance due to the use of <b>bigrams.</b> We also found that pseudo relevance feedback benefits from using these <b>bigrams</b> for expanding queries in all the 8 languages that we tested. ...|$|R
30|$|<b>Bigrams</b> made of {{pairs of}} {{consecutive}} lemmas (in the same sentence).|$|R
