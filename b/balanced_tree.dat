168|721|Public
25|$|A B-tree {{of depth}} n+1 can hold about U {{times as many}} items as a B-tree of depth n, {{but the cost of}} search, insert, and delete {{operations}} grows with the depth of the tree. As with any <b>balanced</b> <b>tree,</b> the cost grows much more slowly than the number of elements.|$|E
2500|$|One common <b>balanced</b> <b>tree</b> {{structure}} is a binary tree structure {{in which the}} left and right subtrees of every node differ in height by no more than 1. One may also consider binary trees where no leaf is much farther away from the root than any other leaf. (Different balancing schemes allow different definitions of [...] "much farther".) ...|$|E
2500|$|A <b>balanced</b> <b>tree</b> {{has similar}} memory access {{patterns}} and space overhead to a linked list while permitting {{much more efficient}} indexing, taking O(log n) time instead of O(n) for a random access. However, insertion and deletion operations are more expensive due to the overhead of tree manipulations to maintain balance. [...] Schemes exist for trees to automatically maintain themselves in a balanced state: AVL trees or red-black trees.|$|E
50|$|Skip {{lists are}} a {{probabilistic}} data structure that {{seem likely to}} supplant <b>balanced</b> <b>trees</b> as the implementation method of choice for many applications. Skip list algorithms have the same asymptotic expected time bounds as <b>balanced</b> <b>trees</b> and are simpler, faster and use less space.|$|R
40|$|Skip {{lists are}} a data {{structure}} {{that can be}} used in place of <b>balanced</b> <b>trees.</b> Skip lists use probabilistic balancing rather than strictly enforced balancing and as a result the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for <b>balanced</b> <b>trees...</b>|$|R
50|$|This method {{leads to}} a <b>balanced</b> k-d <b>tree,</b> in which each leaf node is {{approximately}} the same distance from the root. However, <b>balanced</b> <b>trees</b> are not necessarily optimal for all applications.|$|R
5000|$|Support for 1 to 23 million e-mail users per domain {{using the}} same <b>balanced</b> <b>tree</b> structure.|$|E
5000|$|NSS is a 64-bit {{journaling}} {{file system}} with a <b>balanced</b> <b>tree</b> algorithm for the directory structure. Its published specifications (as of NetWare 6.5) are: ...|$|E
50|$|An AA tree in {{computer}} science {{is a form of}} <b>balanced</b> <b>tree</b> used for storing and retrieving ordered data efficiently. AA trees are named for Arne Andersson, their inventor.|$|E
2500|$|... Section 6.2.4: Multiway Trees, pp.481–491. Also, pp.476–477 {{of section}} 6.2.3 (<b>Balanced</b> <b>Trees)</b> {{discusses}} 2-3 trees.|$|R
50|$|Φ {{will tend}} to be high for poorly <b>balanced</b> <b>trees</b> and low for {{well-balanced}} trees.|$|R
50|$|As most rope {{operations}} require <b>balanced</b> <b>trees,</b> {{the tree}} {{may need to}} be re-balanced after concatenation.|$|R
5000|$|Red-black trees, {{like all}} binary search trees, allow {{efficient}} in-order traversal (that is: {{in the order}} Left-Root-Right) of their elements. The search-time results from the traversal from root to leaf, and therefore a <b>balanced</b> <b>tree</b> of n nodes, having the least possible tree height, results in [...] search time.|$|E
50|$|A B-tree {{of depth}} n+1 can hold about U {{times as many}} items as a B-tree of depth n, {{but the cost of}} search, insert, and delete {{operations}} grows with the depth of the tree. As with any <b>balanced</b> <b>tree,</b> the cost grows much more slowly than the number of elements.|$|E
50|$|A <b>balanced</b> <b>tree</b> {{can store}} a list while {{providing}} all operations of both dynamic arrays and linked lists reasonably efficiently, but both insertion {{at the end}} and iteration over the list are slower than for a dynamic array, in theory and in practice, due to non-contiguous storage and tree traversal/manipulation overhead.|$|E
50|$|Indices can be {{implemented}} {{using a variety of}} data structures. Popular indices include <b>balanced</b> <b>trees,</b> B+ trees and hashes.|$|R
40|$|Abstract: This article investigates {{numerous}} integer sequences {{derived from}} two special <b>balanced</b> k-ary <b>trees.</b> Main contributions {{of this article}} are two fold. The first one is building a taxonomy of various <b>balanced</b> <b>trees.</b> The other pertains to discovering new integer sequences and generalizing existing integer sequences to <b>balanced</b> k-ary <b>trees.</b> The generalized integer sequence formulae for the sum of heights and depths of all nodes in a complete k-ary tree are given. The explicit integer sequence formula for the sum of heights of all nodes in a size <b>balanced</b> k-ary <b>tree</b> is also given. Key–Words: complete k-ary tree, integer sequence, null-balanced k-ary tree, size-balanced k-ary tree...|$|R
5000|$|In both cases, any Erlang term {{can be used}} as the key. Variations {{include the}} [...] module, {{implementing}} ordered dictionaries, and , implementing general <b>balanced</b> <b>trees.</b>|$|R
50|$|The UB-tree as {{proposed}} by Rudolf Bayer and Volker Markl is a <b>balanced</b> <b>tree</b> for storing and efficiently retrieving multidimensional data. It is basically a B+ tree (information only in the leaves) with records stored according to Z-order, also called Morton order. Z-order is simply calculated by bitwise interlacing the keys.|$|E
50|$|The set I has at most 4n + 1 {{elementary}} intervals. Because T is {{a binary}} <b>balanced</b> <b>tree</b> with at most 4n + 1 leaves, its height is O(logn). Since any interval is stored at most twice {{at a given}} depth of the tree, that {{the total amount of}} storage is O(nlogn).|$|E
50|$|Including {{hash tables}} (unordered {{associative}} containers) in the C++ standard library {{is one of}} the most recurring requests. It was not adopted in C++03 due to time constraints only. Although hash tables are less efficient than a <b>balanced</b> <b>tree</b> in the worst case (in the presence of many collisions), they perform better in many real applications.|$|E
40|$|International audienceThis paper studies {{infinite}} unordered d-ary {{trees with}} nodes labeled by { 0, 1 }. We introduce {{the notions of}} rational and Sturmian trees along with the definitions of (strongly) <b>balanced</b> <b>trees</b> and mechanical trees, and study the relations among them. In particular, we show that (strongly) <b>balanced</b> <b>trees</b> exist and coincide with mechanical trees in the irrational case, providing an effective construction. Such trees also have a minimal factor complexity, hence are Sturmian. We also give several examples illustrating the inclusion relations between these classes of trees...|$|R
40|$|We show that, {{in order}} to achieve {{efficient}} maintenance of a <b>balanced</b> binary search <b>tree,</b> no shape restriction other than a logarithmic height is required. The obtained class of <b>trees,</b> general <b>balanced</b> <b>trees,</b> may be maintained at a logarithmic amortized cost with no balance information stored in the nodes. Thus, in the case when amortized bounds are sufficient, {{there is no need for}} sophisticated balance criteria. The maintenance algorithms use partial rebuilding. This is important for certain applications and has previously been used with weight-balanced trees. We show that the amortized cost incurred by general <b>balanced</b> <b>trees</b> is lower than what has been shown for weight-balanced trees. � 1999 Academic Press 1...|$|R
40|$|Abstract: Links and {{similarities}} between the combinatorial optimization problems and the hierarchical search algorithms are discussed. One is the combinatorial greedy algorithm of step-by-step construction of the column-constraint (0, 1) matrices with the different rows. The second is the base search construction of databases,- the class of the well known weight-balanced binary trees. Noted, that in some approximation each of the above problems might be interpreted {{in terms of the}} second problem. The constraints in matrices imply the novel concept of a differential <b>balance</b> in hierarchical <b>trees.</b> The obtained results extend the knowledge for <b>balanced</b> <b>trees</b> and prove that the known greedy algorithm for matrices is applicable in the world of <b>balanced</b> <b>trees</b> providing optimization on trees in layers...|$|R
5000|$|One common <b>balanced</b> <b>tree</b> {{structure}} is a binary tree structure {{in which the}} left and right subtrees of every node differ in height by no more than 1. One may also consider binary trees where no leaf is much farther away from the root than any other leaf. (Different balancing schemes allow different definitions of [...] "much farther".) ...|$|E
50|$|All {{the above}} {{implementations}} require stack space {{proportional to the}} height of the tree which is a call stack for the recursive and a parent stack for the iterative ones. In a poorly <b>balanced</b> <b>tree,</b> this can be considerable. With the iterative implementations we can remove the stack requirement by maintaining parent pointers in each node, or by threading the tree (next section).|$|E
5000|$|All of the red-black tree {{algorithms}} {{that have}} been proposed are characterized by a worst-case search time bounded by a small constant multiple of [...] in a tree of [...] keys, and the behavior observed in practice is typically that same multiple faster than the worst-case bound, close to the optimal [...] nodes examined that would be observed in a perfectly <b>balanced</b> <b>tree.</b>|$|E
5000|$|... #Caption: Figure 3. Idealized caricatures {{of virus}} phylogenies {{that show the}} effects of immune escape where {{selection}} results in an unbalanced tree (A) and neutral dynamics results in a <b>balance</b> <b>tree</b> (B).|$|R
50|$|<b>Balanced</b> <b>trees</b> require O(log n) {{time for}} indexed access, but also permit {{inserting}} or deleting elements in O(log n) time, whereas growable arrays require linear (Θ(n)) time to insert or delete elements at an arbitrary position.|$|R
40|$|The {{research}} was supported by INTAS 00 - 397 and 00 - 626 Projects. Links and similarities between the combinatorial optimization problems and the hierarchical search algorithms are discussed. One is the combinatorial greedy algorithm of step-by-step construction of the column-constraint (0, 1) matrices with the different rows. The second is the base search construction of databases, - the class of the well known weight-balanced binary trees. Noted, that in some approximation each of the above problems might be interpreted in terms of the second problem. The constraints in matrices imply the novel concept of a differential <b>balance</b> in hierarchical <b>trees.</b> The obtained results extend the knowledge for <b>balanced</b> <b>trees</b> and prove that the known greedy algorithm for matrices is applicable in the world of <b>balanced</b> <b>trees</b> providing optimization on trees in layers...|$|R
50|$|A <b>balanced</b> <b>tree</b> {{has similar}} memory access {{patterns}} and space overhead to a linked list while permitting {{much more efficient}} indexing, taking O(log n) time instead of O(n) for a random access. However, insertion and deletion operations are more expensive due to the overhead of tree manipulations to maintain balance. Schemes exist for trees to automatically maintain themselves in a balanced state: AVL trees or red-black trees.|$|E
5000|$|BATON, <b>BAlanced</b> <b>Tree</b> Over-lay Network, is a {{distributed}} {{tree structure}} for peer-to-peer (P2P) systems. Different from other overlays that use a distributed hash table (DHT), {{such as in}} the Chord system, BATON organizes peers in a distributed tree to support range search. In addition, BATON tries to keep the tree in a balanced manner as the AVL tree. And hence, the search cost is bounded by [...]|$|E
50|$|Unlike {{balanced}} trees, radix trees permit lookup, insertion, and deletion in O(k) time {{rather than}} O(log n). This {{does not seem}} like an advantage, since normally k ≥ log n, but in a <b>balanced</b> <b>tree</b> every comparison is a string comparison requiring O(k) worst-case time, {{many of which are}} slow in practice due to long common prefixes (in the case where comparisons begin {{at the start of the}} string). In a trie, all comparisons require constant time, but it takes m comparisons to look up a string of length m. Radix trees can perform these operations with fewer comparisons, and require many fewer nodes.|$|E
5000|$|Here, [...] is a {{numerical}} parameter {{to be determined}} when implementing weight <b>balanced</b> <b>trees.</b> Larger values of [...] produce [...] "more balanced" [...] trees, but not all values of [...] are appropriate; Nievergelt and Reingold proved that ...|$|R
40|$|Since the {{invention}} of AVL trees in 1962, many kinds of binary search trees have been proposed. Notable are red-black trees, in which bottom-up rebalancing after an insertion or deletion takes O(1) amortized time and O(1) rotations worst-case. But the design space of <b>balanced</b> <b>trees</b> has not been fully explored. We continue the exploration. Our contributions are three. We systematically study the use of ranks and rank differences to define height-based <b>balance</b> in binary <b>trees.</b> Different invariants on rank differences yield AVL trees, red-black trees, {{and other kinds of}} <b>balanced</b> <b>trees.</b> By relaxing AVL trees, we obtain a new kind of <b>balanced</b> binary <b>tree,</b> the weak AVL tree, abbreviated wavl tree, whose properties we develop. Bottom-up rebalancing after an insertion or deletion takes O(1) amortized time and at most two rotations, improving the three or more rotations per deletion needed in all other kinds of <b>balanced</b> <b>trees</b> of which we are aware. The height bound of a wavl tree degrades gracefully from that of an AVL tree as the number of deletions increases, and is never worse than that of a red-black tree. Wavl trees also support top-down, fixed look-ahead rebalancing in O(1) amortized time. Finally, we use exponential potential functions to prove that in wavl trees rebalancing steps occur exponentially infrequently in rank. Thus most of the rebalancing is {{at the bottom of the}} tree, which is crucial in concurrent applications and in those in which rotations take time that depends on the subtree size...|$|R
40|$|We {{present a}} novel {{approach}} to efficiently learn a label tree for large scale classification with many classes. The key contribution of the approach is a technique to simultaneously determine {{the structure of the}} tree and learn the classifiers for each node in the tree. This approach also allows fine grained control over the efficiency vs accuracy trade-off in designing a label tree, leading to more <b>balanced</b> <b>trees.</b> Experiments are performed on large scale image classification with 10184 classes and 9 million images. We demonstrate significant improvements in test accuracy and efficiency with less training time and more <b>balanced</b> <b>trees</b> compared to the previous state of the art by Bengio et al. ...|$|R
