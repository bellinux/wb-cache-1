7|182|Public
40|$|The two-path {{algorithm}} {{is a well-known}} approach for overcoming the dead-lock problem in echo cancellation systems. Typically, a fixed foreground filter is producing the echo cancelled output while a continuously updating <b>background</b> <b>filter</b> adapts to the echo-path. When the <b>background</b> <b>filter</b> is considered to perform better than the foreground filter, the coefficients of the <b>background</b> <b>filter</b> are copied into the foreground filter. To determine which filter is better adjusted to the true echo-path, a filter deviation measure can be used. Recently, a method which introduces a delay in the calculation of the filter deviation measure, yielding a more reliable estimate has been proposed. However, a thorough evaluation {{of the effect of}} different delay settings has not yet been performed. Thus, in this paper a number of simulations with different delay parameter settings are carried out to show how this parameter affects the overall performance of the filter deviation measure...|$|E
40|$|Abstract. Background {{suppression}} of weak small targets in infrared image {{is the key}} of image tracking and monitoring, especially under the cloud background. In the area of image signal processing, {{there are a lot}} of background suppression methods can be used to image filter by combining the characteristics of infrared image under the cloud background. In this paper, we introduce three typical <b>background</b> <b>filter</b> methods such as pulse median filter, multi-structural morphological filter and wavelet threshold method, realize them using MATLAB, and analyze their performances of background {{suppression of}} weak small targets in infrared image under the cloud background...|$|E
40|$|Abstract — The two-path echo {{cancellation}} technique {{is a popular}} method for handling the double-talk problem in acoustic and line {{echo cancellation}} applications. The method uses two filters. A so-called background adaptive filter adapts its coefficients to predict echo {{all or most of}} the time regardless of signal activity on the near-end. A second foreground filter, that also predicts the echo, receives it coefficients from the <b>background</b> <b>filter,</b> but only when the background is performing better than the foreground. Only the foreground residual echo is sent to the far-end, so any background divergence due to double-talk is not observed by the user. The key to good two-path performance is in the definition of the background-to-foreground coefficient download tests. These typically contain a suite of various measures that attempt to ascertain the convergence state of the two filters. In this paper we present a novel, simple statistic that directly and accurately estimates a filter’s convergence state. With the aid of this new statistic we show significant improvement in the overall performance of the two path echo canceller. I...|$|E
3000|$|The {{pipeline}} takes a video feed as an input, subtracts the <b>background,</b> <b>filters</b> each {{frame for}} noise and artifacts, and outputs {{the moving parts}} as binary blobs of pixels. Figure  2 illustrates this process. The following is {{a description of the}} individual steps: [...]...|$|R
40|$|Real-time {{detection}} of moving objects {{is vital for}} video surveillance. Background subtraction serves as a basic method typically used to segment the moving objects in image sequences taken from a camera. Some existing algorithms cannot fine-tune changing circumstances and they need manual calibration in relation to specification of parameters or some hypotheses for dynamic changing background. An adaptive motion segmentation and detection strategy is developed by using motion variation and chromatic characteristics, which eliminates undesired corruption of the background model and it doesn't look on the adaptation coefficient. In this particular proposed work, a novel real-time motion detection algorithm is proposed for dynamic changing background features. The algorithm integrates the temporal differencing along with optical flow method, double <b>background</b> <b>filtering</b> method and morphological processing techniques to achieve better detection performance. Temporal differencing is designed to detect initial motion areas for the optical-flow calculation to produce real-time and accurate object motion vectors detection. The double <b>background</b> <b>filtering</b> method is obtain and keep a reliable background image to handle variations on environmental changing conditions {{that is designed to}} get rid of the background interference and separate the moving objects from it. The morphological processing methods are adopted and mixed with the double <b>background</b> <b>filtering</b> to obtain improved results. The most attractive benefit for this algorithm is that the algorithm does not require to figure out the background model from hundreds of images and can handle quick image variations without prior understanding of the object size and shape...|$|R
40|$|Abstract—Moving object {{detection}} is {{very important}} for video surveillance. In this paper, we present a new real time motion detection algorithm that is based on the integration of accumulative optical flow and double <b>background</b> <b>filtering</b> method (long-term <b>background</b> and short-term background) to achieve better performance. The accumulative optical flow method is used to obtain and keep a stable background image to cope with variations on environmental changing conditions and the double <b>background</b> <b>filtering</b> method is used to eliminate the background information and separate the moving object from it. The biggest advantage of this algorithm {{is that it does not}} need to learn the background model from hundreds of images and can handle quick image variations without prior knowledge about the object size and shape. The algorithm has high capability of anti-interference and preserves high accurate rate detection at the same time. The effectiveness of the proposed algorithm for motion detection is demonstrated in a simulation environment and the evaluation results are reported in this paper. Index Terms—Background filtering, motion detection, optical flow, region-based matching. I...|$|R
40|$|OnLine Analytical Processing (OLAP) is a {{relational}} database technology providing users with rapid access to summary, aggregated {{views of a}} single large database, and is widely recognized for knowledge representation and discovery in high-dimensional {{relational database}}s. OLAP technologies provide intuitive and graphical access to the massively complex set of possible summary views available in large relational (SQL) structured data repositories. The capability of OLAP database software systems to handle data complexity comes at {{a high price for}} analysts, presenting them a combinatorially vast space of views of a relational database. We respond to the need to deploy technologies sufficient to allow users to guide themselves to areas of local structure by casting the space of 'views' of an OLAP database as a combinatorial object of all projections and subsets, and 'view discovery' as an search process over that lattice. We equip the view lattice with statistical information theoretical measures sufficient to support a combinatorial optimization process. We outline 'hop-chaining' as a particular view discovery algorithm over this object, wherein users are guided across a permutation of the dimensions by searching for successive two-dimensional views, pushing seen dimensions into an increasingly large <b>background</b> <b>filter</b> in a 'spiraling' search process. We illustrate this work in the context of data cubes recording summary statistics for radiation portal monitors at US ports...|$|E
30|$|WINDII, the Wind Imaging Interferometer on the Upper Atmospheric Research Satellite {{measures}} {{winds and}} emission rates from selected excited metastable species. Here {{we report on}} measurements of the atmospheric Rayleigh scattering from the O(1 S) <b>background</b> <b>filter</b> at 553 nm wavelength used to derive temperature profiles in the upper mesosphere from 70 km to 95 km, for solstice periods from December 1992 / 93 and January 1993 / 94. The data are first zonally averaged and then combined in local time over about one month. Based on these temperatures, an analysis of planetary wave structures and tidal perturbations employing least-mean-square (LMS) fits to the data has been conducted {{and the results are}} presented. The planetary wave structures observed were well described with a quasi two-day wave (QTDW). Amplitudes of 14 K and 10 K at 85 km height for downleg (descending) and upleg (ascending) sampling respectively at latitudes from 20 °S to 40 °S were found to be in good agreement with QTDW temperature results from the MLS/UARS experiment assuming a vertical amplitude structure of the type described by the HRDI/UARS mesospheric wind observations. It is shown that the diurnal tide amplitudes estimated from latitudes from 25 °N to 35 °S using the LMS fit maximize at the equator with an amplitude of about 6 K and decrease toward tropical latitudes, consistent with the classical tidal theory and predictions from the TIME-GCM model.|$|E
40|$|The main {{theme of}} this thesis is the control of {{acoustic}} echoes for modem voice communication systems by means of echo cancellation. Two important issues in acoustic echo cancellation, namely the efficient adaptation of the echo cancellation filter and the reliable adaptation of the echo cancellation filter in double talk environment, are investigated. The delayless subband adaptive filter architecture is studied. Efficient implementation of the analysis filter bank and the time domain filtering are derived. The transforming of the subband filter weights to a fullhand counterpart is examined. It is shown that the weight transform is a synthesis filtering procedure. Two new weight transform schemes that deliver substantial performance improvements are proposed. The open-loop optimal subband filter impulse responses are shown to be non-causal and several anti-causal laps in the subband filters are required to model this non-causality. Because of the inevitable double talk detection errors, adaptive filtering algorithms with built-in double talk robustness measures are needed for the reliable operation of the echo canceller. The basic idea of robust adaptive filtering is examined. A comparison of different existing time domain robust adaptive filtering algorithms demonstrates that excellent trade-off between the convergence and the tracking properties and the double talk robustness of the adaptive filtering algorithm can he achieved by using Huher’s method for both the update of the echo cancellation filter and the estimation of scale. A delayless closed-loop robust sub- hand adaptive filter is proposed. By independently adapting the scale estimates and normalizing the adaptation in each subband, significant improvement {{in terms of the}} convergence and tracking speed over the time domain robust NLMS algorithm can be obtained without sacrificing the double talk robustness. Moreover, it is demonstrated that by using different thresholds in the update of the echo cancellation filter and the scales, the robust algorithms converge and track echo path variation as fast as their non-robust counter part while still maintaining a sufficiently low sensitivity to double talk detection errors. The application of two path adaptive filters to acoustic echo cancellation is examined. An analysis of the original two path adaptive filtering algorithm shows that it suffers from two kinds of performance degradation due to the divergence of the <b>background</b> <b>filter</b> during double talk, namely the slow tracking of echo path variation and the false filter coefficient copying after double talk. A robust two path adaptive filter is proposed to mitigate these problems...|$|E
40|$|International audienceSmith-Purcell {{radiation}} and Transition Radiation are two radiative phenomenon {{that occur in}} charged particles accelerators. For both the emission can be significantly enhanced with sufficiently short pulses and both {{can be used to}} measure the form factor of the pulse. We compare the yield of these phenomenon in different configurations and look at their application as bunch length monitors, including <b>background</b> <b>filtering</b> and rejection. We apply these calculations to the specific case of the CLIO Free Electron laser...|$|R
40|$|We {{propose a}} method for {{improving}} object recognition in street scene images by identifying and <b>filtering</b> out <b>background</b> aspects. We analyse the semantic relationships between foreground and background objects and use the information obtained to remove areas of the image that are misclassified as foreground objects. We show that such <b>background</b> <b>filtering</b> improves the performance of four traditional object recognition methods by over 40 %. Our method is independent of the recognition algorithms used for individual objects, and can be extended to generic object recognition in other environments by adapting other object model...|$|R
40|$|The {{observations}} {{have been}} reduced and analyzed; unfortunately they were affected by very high background episodes, which have {{made it difficult to}} get a consistent sensitivity and fully achieve the original goals of the proposal. Nevertheless, after much experimenting with <b>background</b> <b>filtering,</b> etc., we believe we have converged on a good compromise and now expect to be able to recover a significant fraction of the observing time. Work on the part of our European collaborators is continuing and should result in a paper that could be ready for publication in the fall...|$|R
40|$|Understanding the {{composition}} of atmospheric organic particulate matter (OPM) is essential for predicting its effects on climate, air quality, and health. However, the polar oxygenated fraction (PO-OPM), which includes a significant mass contribution from carboxylic acids, is difficult to speciate and quantitatively determine by current analytical methods such as gas chromatography-mass spectrometry (GC-MS). The method of chemical derivatization and two-dimensional GC with time of flight MS (GC×GC/TOF-MS) was {{examined in this study}} for its efficacy in: 1) quantifying a high percentage of the total organic carbon (TOC) mass of a sample containing PO-OPM; 2) quantitatively determining PO-OPM components including carboxylic acids at atmospherically relevant concentrations; and 3) tentatively identifying PO-OPM components. Two derivatization reagent systems were used in this study: BF₃/butanol for the butylation of carboxylic acids, aldehydes, and acidic ketones, and BSTFA for the trimethylsilylation (TMS) of carboxylic acids and alcohols. Three α-pinene ozonolysis OPM filter samples and a set of <b>background</b> <b>filter</b> samples were collected by collaborators in a University of California, Riverside environmental chamber. Derivatization/GC×GC TOF-MS was used to tentatively identify some previously unidentified α-pinene ozonolysis products, and also to show the characteristics of all oxidation products determined. Derivatization efficiencies as measured were 40 - 70 % for most butyl derivatives, and 50 - 58 % for most trimethylsilyl derivatives. A thermal optical method was used to measure the TOC on each filter, and a value of the quantifiable TOC mass using a gas chromatograph was calculated for each sample using GC×GC separation and the mass-sensitive response of a flame ionization detector (FID). The TOC quantified using TMS and GC×GC-FID (TMS/TOCGC×GC FID) accounted for 15 - 23 % of the TOC measured by the thermal-optical method. Using TMS and GC×GC/TOF-MS, 8. 85 % of the thermal optical TOC was measured and 48. 2 % of the TMS/TOCGC×GC-FID was semi-quantified using a surrogate standard. The carboxylic acids tentatively identified using TMS and GC×GC/TOF-MS accounted for 8. 28 % of the TOC measured by thermal optical means. GC×GC TOF-MS chromatograms of derivatized analytes showed reduced peak tailing {{due in part to the}} lesser interactions of the derivatized analytes with the stationary phase of the chromatography column as compared to the chromatograms of underivatized samples. The improved peak shape made possible the greater separation, quantification, and identification of high polarity analytes. Limits of detection using derivatization and GC×GC/TOF-MS were μL injected for a series of C 2 -C 6 di-acids, cis-pinonic acid, and dodecanoic acid using both butylation and TMS. Derivatization with GC×GC/TOF-MS was therefore effective for determining polar oxygenated compounds at low concentrations, for determining specific oxidation products not previously identified in OPM, and also for characterizing the probable functional groups and structures of α-pinene ozonolysis products...|$|E
500|$|The digital cel work {{included}} both original illustrations, compositions and manipulation with traditional cel animation {{to create a}} sense of depth and evoke emotion and feelings. Utilized as <b>background,</b> <b>filters</b> like a lens effect were used {{to create a sense}} of depth and motion, by distorting the front background and making the far background out of focus throughout the shot. Ghost in the Shell used a unique lighting system in which light and darkness were integrated into the cels with attention to light and shadow sources instead of using contrast to control the light. Hiromasa Ogura, the art director, described this as [...] "a very unusual lighting technique".|$|R
40|$|We {{report on}} the {{discovery}} of a shell-type supernova remnant in the southern sky. It is a large (8 * 8), low-brightness source with a nonthermal radio spectrum, which requires <b>background</b> <b>filtering</b> to isolate it from the diffuse background emission of the Galaxy. Three 3 EG gamma-ray sources are spatially correlated with the radio structure. We have made 21 -cm line observations of the region and found that two of these sources are coincident with HI clouds. We propose that the gamma-ray emission is the result of hadronic interactions between high-energy protons locally accelerated at the remnant shock front and atomic nuclei in the ambient clouds. Comment: 6 pages, 5 figure...|$|R
5000|$|The digital cel work {{included}} both original illustrations, compositions and manipulation with traditional cel animation {{to create a}} sense of depth and evoke emotion and feelings. Utilized as <b>background,</b> <b>filters</b> like a lens effect were used {{to create a sense}} of depth and motion, by distorting the front background and making the far background out of focus throughout the shot. Ghost in the Shell used a unique lighting system in which light and darkness were integrated into the cels with attention to light and shadow sources instead of using contrast to control the light. Hiromasa Ogura, the art director, described this as [...] "a very unusual lighting technique." ...|$|R
40|$|Traumatic {{brain injury}} to {{the parts of the}} brain {{responsible}} for processing auditory information can result in hearing loss that is difficult to assess and treat. Symptoms can include difficulty in <b>filtering</b> <b>background</b> noises or <b>filtering</b> out specific sounds, confusion, and disorientation or nausea. Treatment of this type of hearing loss varies, but primarily consists of psychological treatment focused around rehabilitation and coping...|$|R
5000|$|... #Caption: The {{result of}} {{applying}} a generalized Wiener filter to a noisy {{observation of the}} cosmic microwave <b>background.</b> The <b>filter</b> results in an image that is signal-dominated at all scales, {{at the cost of}} introducing a bias (seen as blurring in this example).|$|R
50|$|Virtua Fighter 2 was {{released}} in November 1994, adding two new fighters: Shun Di and Lion Rafale. It was built using the Model 2 hardware, rendering characters and <b>backgrounds</b> with <b>filtered</b> texture mapping and motion capture. A slightly-tweaked upgrade, Virtua Fighter 2.1, followed soon after.|$|R
40|$|The {{research}} {{focuses on}} image retrieval problems where the query is formed as {{an image of a}} specific object of interest. The broad aim is to investigate pre-processing for retrieval of images of objects when an example image containing the object is given. The object may be against a variety of backgrounds. Given the assumption that the object of interest is fairly centrally located in the image, the normalized cut segmentation and region growing segmentation are investigated to segment the object from the background but with limited success. An alternative approach comes from identifying salient regions in the image and extracting local features as a representation of the regions. The experiments show an improvement for retrieval by local features when compared with retrieval using global features from the whole image. For situations where object retrieval is required and where the foreground and background can be assumed to have different characteristics, it is useful to exclude salient regions which are characteristic of the background if they can be identified before matching is undertaken. This thesis proposes techniques to filter out salient regions believed {{to be associated with the}} <b>background</b> area. <b>Background</b> <b>filtering</b> using <b>background</b> clusters is the first technique which is proposed in the situation where only the background information is available for training. The second technique is the K-NN classification based on the foreground and background probability. In the last chapter, the support vector machine (SVM) method with PCA-SIFT descriptors is applied in an attempt to improve classification into foreground and background salient region classes. Retrieval comparisons show that the use of salient region <b>background</b> <b>filtering</b> gives an improvement in performance when compared with the unfiltered method. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
50|$|Adobe Presenter Video Express {{ships with}} a large number of {{branding}} videos, <b>backgrounds</b> and video <b>filters</b> to help authors create studio quality videos.|$|R
30|$|Our {{choice of}} {{training}} features was as follows: Gaussian blur, median (voxel intensity averaging); anisotropic diffusion, bilateral, Kuwahara (edge-preserving averaging functions); Sobel filter, derivatives (edge detection); Hessian, Gabor, structure (orientation detection); membrane projections (extended object detection); difference of Gaussians, Laplacian (object size detection); variance, entropy, neighbours (local noise level). We {{did not use}} the mean, minimum, maximum (voxel intensity) or Lipschitz (smoothly varying <b>background</b> subtraction) <b>filters.</b>|$|R
40|$|For the Portland State University FAGE instrument, laser induced OH is {{calculated}} from (OH) laser = Cl(03) amb(H 2 O) amb. The dominant noise sources are the photon-counting fluctuations {{associated with the}} OH signal and the fluorescence background as well as concentration fluctuations in OH and in the species causing the <b>background.</b> Baric <b>filtering</b> and temporal <b>filtering</b> suppress the <b>background</b> by factors of 10 each...|$|R
40|$|Abstract: The ANTARES Collaboration is {{building}} a high-energy neutrino telescope at 2500 m depth in the Mediterranean Sea. The experiment aims to search for high-energy cosmic neutrinos through the detection of Cerenkov light induced by muons and showers resulting from neutrino interactions with the surrounding medium. The detector will consist of a three-dimensional array of 900 optical modules housing photomultipliers. It will be composed of 12 strings, 5 of them being already in operation since January 2007. The muon track is reconstructed from the arrival time and the charge of the signals obtained from the photomultipliers, whose positions are known {{by means of an}} acoustic positioning system. The reconstruction strategies include several steps among which there are: optical <b>background</b> <b>filtering,</b> algorithms for first estimations of the track parameters, and a final fit aiming to reach an angular resolution better than 0. 3 degree above 10 TeV in the full detector. Different reconstruction strategies will be presented and their application to the present real data analysis will be reviewed...|$|R
40|$|Abstract. The use of salient regions is an {{increasingly}} popular approach to image retrieval. For situations where object retrieval is required {{and where the}} foreground and background can be assumed to have different characteristics, it becomes useful to exclude salient regions which are characteristic of the background {{if they can be}} identified before matching is undertaken. This paper proposes a technique to enhance the performance of object retrieval by filtering out salient regions believed {{to be associated with the}} background area of the images. Salient regions from background only images are extracted and clustered using descriptors representing the salient regions. The clusters are then used in the retrieval process to identify salient regions likely to be part of the background in images containing object and background. Salient regions close to background clusters are pruned before matching and only the remaining salient regions are used in the retrieval. Experiments on object retrieval show that the use of salient region <b>background</b> <b>filtering</b> gives an improvement in performance when compared with the unfiltered method...|$|R
40|$|The ANTARES Collaboration is {{building}} a high-energy neutrino telescope at 2500 m depth in the Mediterranean Sea. The experiment aims to search for high-energy cosmic neutrinos through the detection of Cerenkov light induced by muons and showers resulting from neutrino interactions with the surrounding medium. The detector will consist of a three-dimensional array of 900 optical modules housing photomultipliers. It will be composed of 12 strings, 5 of them being already in operation since January 2007. The muon track is reconstructed from the arrival time and the charge of the signals obtained from the photomultipliers, whose positions are known {{by means of an}} acoustic positioning system. The reconstruction strategies include several steps among which there are: optical <b>background</b> <b>filtering,</b> algorithms for first estimations of the track parameters, and a final fit aiming to reach an angular resolution better than 0. 3 degree above 10 TeV in the full detector. Different reconstruction strategies will be presented and their application to the present real data analysis will be reviewed. Comment: Contribution to the 30 th ICRC, Merida Mexico, July 2007 on behalf of the ANTARES Collaboratio...|$|R
40|$|An {{examination}} {{is made of}} parameterised {{gravity waves}} in the Hadley Centre’s HadGAM 2 -A L 60 and small-scale gravity waves retrieved from HIRDLS-AURA (v 2. 04. 09). Seasonal similarities are seen at low and high latitudes during mid summer and winter. Differences are evident during Southern Hemisphere winter at high latitudes, most likely due to sources not represented in HadGAM 2 -A L 60. The diminution of wave amplitude with height is significantly greater in the HIRDLS data and is most likely linked with HIRDLS vertical resolution or saturation processes rather than circulation differences. Maxima are seen in both model and HIRDLS data in the subtropics during summer possibly linked with the ITCZ or Asian Monsoon. 8. Conclusions Significant differences in both latitude variation and the exponential diminution in height of IWM suggest that saturation processes may play a greater role than previously thought. Even so, a significant seasonal cycle is seen in both model and HIRDLS data, indicating <b>background</b> <b>filtering</b> from underlying windshear. Large valued IWM in the southern extratropics is not captured by the model. This is especially apparent during the southern winter, most likely due to unrepresented sources in the model...|$|R
50|$|Family {{businesses}} have many strategic advantages {{such as their}} sharing of family language, values and <b>background.</b> These advantages <b>filter</b> into their large respect towards each family member and their roles to, if necessary, sacrifice their individual tasks for the wellbeing of the business.|$|R
50|$|Image {{embossing}} is {{a computer}} graphics technique in which each pixel of an image is replaced either by a highlight or a shadow, depending on light/dark boundaries on the original image. Low contrast areas are replaced by a gray <b>background.</b> The <b>filtered</b> image will represent the rate of color change at each location of the original image. Applying an embossing filter to an image often results in an image resembling a paper or metal embossing of the original image, hence the name.|$|R
40|$|Colour {{classification}} vision systems face difficulty when a scene contains {{both very}} bright and dark regions. An indistinguishable colour at one exposure may be distinguishable at another. The {{use of multiple}} cameras with varying levels of sensitivity is explored in this thesis, aiding the classification of colours in scenes with high illumination ranges. Titled the Multiple Image Dynamic Exposure Colour Classification (MIDECC) System, pie-slice classifiers are optimised for normalised red/green and cyan/magenta colour spaces. The MIDECC system finds a limited section of hyperspace for each classifier, resulting in a process which requires minimal manual input {{with the ability to}} <b>filter</b> <b>background</b> samples without specialised training. In experimental implementation, automatic multiple-camera exposure, data sampling, training and colour space evaluation to recognise 8 target colours across 14 different lighting scenarios is processed in approximately 30 seconds. The system provides computationally effective training and classification, outputting an overall true positive score of 92. 4 % with an illumination range between bright and dim regions of 880 lux. False positive classifications are minimised to 4. 24 %, assisted by heuristic <b>background</b> <b>filtering.</b> The limited search space classifiers and layout of the colour spaces ensures the MIDECC system is less likely to classify dissimilar colours, requiring a certain ‘confidence’ level before a match is outputted. Unfortunately the system struggles to classify colours under extremely bright illumination due to the simplistic classification building technique. Results are compared to the common machine learning algorithms Naïve Bayes, Neural Networks, Random Tree and C 4. 5 Tree Classifiers. These algorithms return greater than 98. 5 % true positives and less than 1. 53 % false positives, with Random Tree and Naïve Bayes providing the best and worst comparable algorithms, respectively. Although resulting in a lower classification rate, the MIDECC system trains with minimal user input, ignores background and untrained samples when classifying and trains faster than most of the studied machine learning algorithms. Colour classification vision systems face difficulty when a scene contains both very bright and dark regions. An indistinguishable colour at one exposure may be distinguishable at another. The use of multiple cameras with varying levels of sensitivity is explored in this thesis, aiding the classification of colours in scenes with high illumination ranges. Titled the Multiple Image Dynamic Exposure Colour Classification (MIDECC) System, pie-slice classifiers are optimised for normalised red/green and cyan/magenta colour spaces. The MIDECC system finds a limited section of hyperspace for each classifier, resulting in a process which requires minimal manual input with the ability to <b>filter</b> <b>background</b> samples without specialised training. In experimental implementation, automatic multiple-camera exposure, data sampling, training and colour space evaluation to recognise 8 target colours across 14 different lighting scenarios is processed in approximately 30 seconds. The system provides computationally effective training and classification, outputting an overall true positive score of 92. 4 % with an illumination range between bright and dim regions of 880 lux. False positive classifications are minimised to 4. 24 %, assisted by heuristic <b>background</b> <b>filtering.</b> The limited search space classifiers and layout of the colour spaces ensures the MIDECC system is less likely to classify dissimilar colours, requiring a certain ‘confidence’ level before a match is outputted. Unfortunately the system struggles to classify colours under extremely bright illumination due to the simplistic classification building technique. Results are compared to the common machine learning algorithms Naïve Bayes, Neural Networks, Random Tree and C 4. 5 Tree Classifiers. These algorithms return greater than 98. 5 % true positives and less than 1. 53 % false positives, with Random Tree and Naïve Bayes providing the best and worst comparable algorithms, respectively. Although resulting in a lower classification rate, the MIDECC system trains with minimal user input, ignores background and untrained samples when classifying and trains faster than most of the studied machine learning algorithms...|$|R
40|$|We {{propose a}} motion {{segmentation}} algorithm for extracting foreground objects with a pan-tilt camera. Segmentation {{is achieved by}} spatio-temporal filtering of the scene to model the <b>background.</b> Temporal <b>filtering</b> is done {{by a set of}} modified AR (Auto-Regressive) filters which model the background statistics for a particular view of the scene. Backgrounds from different views of the pan-tilt camera are stitched together into a planar mosaic using a real-time image mosaicing strategy. Our algorithms work in real-time, require no user intervention, and facilitate high-quality video transmission at low bandwidths. ...|$|R
40|$|We {{present a}} method for {{determining}} the background of Fermi GBM GRBs using the satellite positional information and a physical model. Since the polynomial fitting method typically used for GRBs is generally only indicative of the background over relatively short timescales, this method is particularly useful {{in the cases of}} long GRBs or those which have Autonomous Repoint Request (ARR) and a background with much variability on short timescales. We give a Direction Dependent Background Fitting (DDBF) method for separating the motion effects from the real data and calculate the duration (T 90 and T 50, as well as confidence intervals) of the nine example bursts, from which two resulted an ARR. We also summarize the features of our method and compare it qualitatively with the official GBM Catalogue. Our <b>background</b> <b>filtering</b> method uses a model based on the physical information of the satellite position. Therefore, it has many advantages compared to previous methods. It can fit long background intervals, remove all the features caused by the rocking behaviour of the satellite, and search for long emissions or not-triggered events. Furthermore, many part of the fitting have now been automatised, and the method have been shown to work for both Sky Survey mode and ARR mode data. Future work will provide a burst catalogue with DDBF. Comment: 16 pages, 28 figure...|$|R
40|$|Abstract—Real-time {{detection}} of moving objects {{is very important}} for video surveillance. In this paper, a novel real time motion detection algorithm is proposed. The algorithm integrates the temporal differencing method, optical flow method, double <b>background</b> <b>filtering</b> (DBF) method and morphological processing methods to achieve better performance. The temporal differencing is used to detect initial coarse motion areas for the optical flow calculation to achieve real-time and accurate object motion detection. The DBF method is used to obtain and keep a stable background image to cope with variations on environmental changing conditions and is used to eliminate the background interference information and separate the moving object from it. The morphological processing methods are adopted and combined with the DBF to get improved results. The most attractive advantage of this algorithm is that the algorithm does not need to learn the background model from hundreds of images and can handle quick image variations without prior knowledge about the object size and shape. The algorithm has high capability of anti-interference and preserves high accurate rate detection at the same time. It also demands less computation time than other methods for the real-time surveillance. The effectiveness of the proposed algorithm for motion detection is demonstrated in a simulation environment and the evaluation results are reported in this paper. Index Terms—Background filtering, motion detection, optical flow, temporal differencing. I...|$|R
40|$|Laser-induced photofragmentation {{fluorescence}} {{has been}} investigated for the imaging of alkali compounds in premixed laminar methane–air flames. An ArF excimer laser, providing pulses of wavelength 193 nm, was used to photodissociate KCl, KOH, and NaCl molecules in the post-flame region and fluorescence from the excited atomic alkali fragment was detected. Fluorescence emission spectra showed distinct lines of the alkali atoms allowing for efficient <b>background</b> <b>filtering.</b> Temperature data from Rayleigh scattering measurements together with simulations of potassium chemistry presented in literature allowed for conclusions on the relative contributions of potassium species KOH and KCl to the detected signal. Experimental approaches for separate measurements of these components are discussed. Signal power dependence and calculated fractions of dissociated molecules indicate the saturation of the photolysis process, independent on absorption cross-section, under the experimental conditions. Quantitative KCl concentrations up to 30 parts per million (ppm) were evaluated from the fluorescence data and showed good agreement with results from ultraviolet absorption measurements. Detection limits for KCl photofragmentation fluorescence imaging of 0. 5 and 1. 0 ppm were determined for averaged and single-shot data, respectively. Moreover, simultaneous imaging of KCl and NaCl was demonstrated using a stereoscope with filters. The {{results indicate that the}} photofragmentation method can be employed for detailed studies of alkali chemistry in laboratory flames for validation of chemical kinetic mechanisms crucial for efficient biomass fuel utilization...|$|R
40|$|This paper {{presents}} an enhanced technique for contrast and visibility improvement for deep sea underwater image which is normally used for underwater robot. The proposed technique uses an integration approach of enhanced <b>background</b> <b>filtering</b> and wavelet fusion methods (EBFWF). The novelty lies {{in this case}} in its methodology and capability of the proposed approach to minimize negative underwater effects such as blue and green color casts, low contrast, and low visibility in comparison with other state-of-the-art methods. The proposed method consists of a few steps that aims to eliminate negative effects and thus improving the contrast and visibility of underwater image. This purpose is carried out to provide a better platform for object detection and recognition processes. The input image is first sharpen before the low frequency background is removed. This minimizes the probability of image data {{to be regarded as}} noise in the consequences processes’ steps. Image histograms are then mapped based on the intermediate color channel to reduce the gap between the inferior and dominant color channels. Wavelet fusion is applied followed by adaptive local histogram specification process. Based on the conduced tests, the proposed EBFWF technique, computationally, more effective and significant in improving the overall underwater image quality. The resultant images processed through the proposed approach could be further used for detection and recognition to extract more valuable information...|$|R
40|$|In ghost imaging with {{narrow-band}} signal in thermal light <b>background,</b> {{signal arm}} <b>filters</b> bring higher value and upper limit of signal-to-noise ratio (SNR), and faster speed {{to reach that}} limit. The narrower bandwidth, the better. Comment: This paper has been withdrawn by the author due to the different description of second-order correlatio...|$|R
