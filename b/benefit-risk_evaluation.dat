13|7|Public
50|$|Risk {{management}} is the discipline within pharmacovigilance {{that is responsible}} for signal detection and the monitoring of the risk-benefit profile of drugs. Other key activities within the area of risk management are that of the compilation of risk management plans (RMPs) and aggregate reports such as the Periodic Safety Update Report (PSUR), Periodic <b>Benefit-Risk</b> <b>Evaluation</b> Report (PBRER), and the Development Safety Update Report (DSUR).|$|E
40|$|Analysis of the {{occurrence}} of adverse events, and in particular of solicited symptoms, following vaccination is often needed for the safety and <b>benefit-risk</b> <b>evaluation</b> of any candidate vaccine, and typically involves taking repeated measurements. In this article, it is shown that Linear Categorical Marginal Models (LCMMs) are well suited {{to take into account}} the dependencies in the data arising from the repeated measurements and provide detailed and useful information for comparing safety profiles of different products while remaining relatively easy to interpret. LCMMs are presented and applied to a Phase III clinical trial of a candidate meningococcal pediatric vaccine...|$|E
40|$|Today, {{drug safety}} data {{collection}} in India is both manual and electronic with reporting of potential overlapping and duplicate data, {{which is likely}} incomplete for further review and analysis. Furthermore, standardized data collection and timelines are not aligned with international standards. Complete coverage of safety data from all sources throughout {{the life of the}} drug cannot be ensured. There is no requirement to submit periodic safety data in clinical trials to regulatory authority. There is clearly a lack of emphasis on deriving meaningful safety data insights for ensuring patient safety. Efforts toward the early detection of drug safety issues are minimal. There is no mandate to publicly disclose drug safety findings. <b>Benefit-risk</b> <b>evaluation</b> of investigational and marketed products cannot be assured merely through annual status reports and periodic safety update reports, respectively. Focused initiatives involving stakeholders from regulatory, health-care, and pharmaceutical industries are required to change the current situation and enable derivation of meaningful insights from safety data. Equal emphasis on assessing real-time safety of the drugs and protection of patients' rights, safety, and well-being is required. Periodic safety data reporting in clinical trials, proactive safety data collection related to potential safety concerns, electronic medical records, electronic expedited reporting, collection of targeted data from stakeholders, and standardized and harmonized data collection aligned to the International Council for Harmonization guidelines are required. The Central Drugs Standard Control Organization should implement requirements to submit Development Safety Update Reports, Periodic <b>Benefit-Risk</b> <b>Evaluation</b> Reports, and Risk Management Plans. Access to clinical trials and postmarketing safety data through central repository would enable researchers to explore the data for application in clinical practice...|$|E
40|$|The role of {{disinfection}} in infection prevention {{has been}} analyzed {{over the past}} 50 years both {{in the form of}} <b>benefit-risk</b> <b>evaluations</b> as well as in an epidemiological sense. This has served as the basis for not only national and international guidelines and recommendations, but has also created the legal and normative framework for regulation of infection control (and hence of disinfection) in numerous and acts and ordinances. Likewise, today the efficacy of disinfection measures, user safety and environmental compatibility in line with {{the state of the art}} are assured. Compliance as regards the conductance of disinfection measures has increased accordingly. The user is able to select and correctly employ the disinfectant most suited to the intended disinfection procedure. The quality of the apparatus used has vastly improved since the coming into force of the German Medical Devices Act (MPG). And finally the preconditions for conductance of disinfection have becom...|$|R
40|$|The role of {{disinfection}} in infection prevention {{has been}} analyzed {{over the past}} 50 years both {{in the form of}} <b>benefit-risk</b> <b>evaluations</b> as well as in an epidemiological sense. This has served as the basis for not only national and international guidelines and recommendations, but has also created the legal and normative framework for regulation of infection control (and hence of disinfection) in numerous and acts and ordinances. Likewise, today the efficacy of disinfection measures, user safety and environmental compatibility in line with {{the state of the art}} are assured. Compliance as regards the conductance of disinfection measures has increased accordingly. The user is able to select and correctly employ the disinfectant most suited to the intended disinfection procedure. The quality of the apparatus used has vastly improved since the coming into force of the German Medical Devices Act (MPG). And finally the preconditions for conductance of disinfection have become so matter of fact that it is easy to forget just what progress has been made here. This applies e. g. to the facilities now available for hand hygiene, for decontamination of instruments, laundry and bedpans with washer-disinfectors as well as for surface disinfection and drinking water disinfection...|$|R
40|$|The role of {{disinfection}} in infection prevention {{has been}} analyzed {{over the past}} 50 years both {{in the form of}} <b>benefit-risk</b> <b>evaluations</b> as well as in an epidemiological sense. This has served as the basis for not only national and international guidelines and recommendations, but has also created the legal and normative framework for regulation of infection control (and hence of disinfection) in numerous and acts and ordinances. Likewise, today the efficacy of disinfection measures, user safety and environmental compatibility in line with {{the state of the art}} are assured. Compliance as regards the conductance of disinfection measures has increased accordingly. The user is able to select and correctly employ the disinfectant most suited to the intended disinfection procedure. The quality of the apparatus used has vastly improved since the coming into force of the German Medical Devices Act (MPG). And finally the preconditions for conductance of disinfection have become so matter of fact that it is easy to forget just what progress has been made here. This applies e. g. to the facilities now available for hand hygiene, for decontamination of instruments, laundry and bedpans with washer-disinfectors as well as for surface disinfection and drinking water disinfection. But it is the human being who continues to pose the greatest risk. Risk awareness does not always result in proper action being taken: it is hard to really grasp something that one cannot experience. As such, hand disinfection is often dispensed with, and without any sense of having done something wrong, the debate about the evidence of the usefulness of floor disinfection continues, and often medical practitioners fail to resort to exclusive automated decontamination of medical devices because of the costs incurred. Hospitals, nursing homes and rehabilitation establishments are obliged to set up a quality management system, and to continue developing this. This calls for a quality assurance system regulating organizational procedures, responsibilities, workflow patterns for the entire domain of infection control within the hospital or medical practitioner’s premises and outcome evaluation (microbiological monitoring, surveillance of nosocomial infections). An indispensable component of primary prevention is assurance of structural and process quality. In turn, disinfection is indispensable for assurance of process quality...|$|R
40|$|A <b>benefit-risk</b> <b>evaluation</b> of the {{evidence}} for including dairy foods in the diet is presented. For many persons dairy products provide {{a substantial portion of}} essential nutrients, but especially calcium, potassium, and magnesium. Dietary supplements and fortified foods can be alternative sources of these nutrients, although other components of dairy foods such as amino acid composition and conjugated linoleic acid may be instrumental in the benefits associated with dairy product consumption for bone health and reduced risk of stroke, metabolic syndrome, and some cancers. Newer evidence shows that protein-induced calciuria does not have a detrimental effect on net calcium retention, and the concentrations of hormones in milk are not outside of the range of endogenous concentrations. Increased dietary protein, including from milk, can elevate serum concentrations of insulin-like growth factor I, which has an unknown relation to cancer. The concern over consumption of milk leading to increased risk of prostate cancer through reduction of serum 1, 25 -dihydroxyvitamin D, a potent anti-prostate cancer hormone, has been resolved with new evidence that local production of this hormone is independent of diet. Overall, evidence suggests that being a lactovegetarian has greater health benefits and reduced health risks than being a vegan...|$|E
40|$|New psychoactive drugs (NPDs, new psychoactive substances) {{enter the}} market all the time. However, it takes {{several months to}} ban these NPDs and {{immediate}} action is generally not possible. Several European countries and drug enforcement officers insist on a faster procedure to ban NPDs. Introduction of generic legislation, in which clusters of psychotropic drugs are banned in advance, has been mentioned as a possible solution. Here we discuss {{the pros and cons}} of such an approach. First, generic legislation could unintentionally increase the expenditures of enforcement, black market practices, administrative burden and health risks for users. Second, it may have a negative impact on research and the development of new treatments. Third, due to the complexity of generic legislation, problems in the enforcement are anticipated due to lack of knowledge about the chemical nomenclature. Finally, various legal options are already available to ban the use, sale and trade of NPDs. We therefore conclude that the currently used scientific <b>benefit-risk</b> <b>evaluation</b> should be continued to limit the adverse health effects of NPDs. Only in emergency cases, where fatal incidents (may) occur, should this approach be overrule...|$|E
40|$|PurposeIn {{consideration}} of possible severe complications thrombolytic agents are administered to only 30 % {{of patients with}} acute myocardial infarction (AMI) admitted to coronary care units in Western Europe. “The 60 -Minutes Myocardial Infarction Project” therefore investigates {{the effect of a}} higher lysis rate (LR) on the frequency of complications. MethodsThe multicenter nationwide study includes 154 hospitals in Germany. During an 8 -month period 4650 consecutive patients with proven transmural AMI were enrolled and complications occurring within 48 hours after admission were registered for clinical centers with a low and high LR (≥ 50 % versus > 50 %). Resultsclinical centers:allLR 50 %complications (within 48 h) :n= 4650 n= 2768 n= 1882 death 8. 0 % 8. 3 % 7. 5 %hemorrhagic stroke 0. 4 % 0. 5 % 0. 2 %ventricular rupture 0. 4 % 0. 4 % 0. 4 %moderate bleeding 2. 4 % 1. 8 % 3, 3 %allergic reaction 0. 8 % 0. 5 % 1. 3 %Both groups were similar in age, sex and coexisting diseases. Conclusions 1. 48 -hour mortality was lower in clinical centers with a higher LR. 2. Severe complications showed no significant difference. 3. Minor complications were significantly more frequent in clinical centers with a higher LR. 4. These results support a less restrictive indication for thrombolytic therapy in AMI based on individual <b>benefit-risk</b> <b>evaluation...</b>|$|E
40|$|AbstractBackgroundThere {{is growing}} {{agreement}} that regulators performing <b>benefit–risk</b> <b>evaluations</b> should take patients’ and caregivers’ preferences into consideration. The Patient-Focused Drug Development Initiative at the US Food and Drug Administration offers patients and caregivers an enhanced opportunity {{to contribute to}} regulatory processes by offering direct testimonials. This process may be advanced by providing scientific evidence regarding treatment preferences through engagement of a broad community of patients and caregivers. ObjectiveIn this article, we demonstrate a community-engaged approach to measure caregiver preferences for potential benefits and risks of emerging therapies for Duchenne muscular dystrophy (DMD). MethodsAn advocacy oversight team led the community-engaged study. Caregivers’ treatment preferences were measured by using best–worst scaling (BWS). Six relevant and understandable attributes describing potential benefits and risks of emerging DMD therapies were identified through engagement with advocates (n = 5), clinicians (n = 9), drug developers from pharmaceutical companies and academic centers (n = 11), and other stakeholders (n = 5). The attributes, each defined across 3 levels, included muscle function, life span, knowledge about the drug, nausea, risk of bleeds, and risk of arrhythmia. Cognitive interviewing with caregivers (n = 7) was used to refine terminology and assess acceptability of the BWS instrument. The study was implemented through an online survey of DMD caregivers, who were recruited in the United States through an advocacy group and snowball sampling. Caregivers were presented with 18 treatment profiles, identified via a main-effect orthogonal experimental design, in which the dependent variable was the respondents’ judgment as to {{the best and worst}} feature in each profile. Preference weights were estimated by calculating the relative number of times a feature was chosen as best and as worst, which were then used to estimate relative attribute importance. ResultsA total of 119 DMD caregivers completed the BWS instrument; they were predominately biological mothers (67. 2 %), married (89. 9 %), and white (91. 6 %). Treatment effect on muscle function was the most important among experimental attributes (28. 7 %), followed by risk of heart arrhythmia (22. 4 %) and risk of bleeding (21. 2 %). Having additional postapproval data was relatively the least important attribute (2. 3 %). ConclusionsWe present a model process for advocacy organizations aiming to promote patient-centered drug development. The community-engaged approach was successfully used to develop and implement a survey to measure caregiver preferences. Caregivers were willing to accept a serious risk when balanced with a noncurative treatment, even absent improvement in life span. These preferences should inform the Food and Drug Administration’s benefit–risk assessment of emerging DMD therapies. This study highlights the synergistic integration of traditional advocacy methods and scientific approach to quantify benefit–risk preferences...|$|R
40|$|Objectives: Longitudinal {{measurements}} of ordinal responses are very frequent {{in clinical trials}} to assess drug efficacy and side effects. Usually, several scores are recorded and this multiplicity is an issue for data analysis. Most of the time, each score is analysed separately or an average/aggregated score is used. Both approaches, however, ignore the correlations between scores which very often document different aspects of a same physio-pathological process (e. g. pain, inflammation) and, in the last case, the actual metric of the scores is not taken into account. Very few methods exist to analyse several scores simultaneously [1, 2]. In 2008, Todem et al. proposed a method {{for the analysis of}} longitudinal bivariate ordinal data using probit-linear mixed effects models [2]. We propose to generalise their approach and apply it to pharmacokinetic/pharmacodynamic analyses. Methods: We use the concept of latent variables to derive the joint distribution of K ordinal responses. Each ordinal response Yk (k = 1 …K) is viewed as the categorisation of a continuous, unobserved variable denoted Zk which is the true variable of interest. We use mixed effects models for the K latent variables, assuming that the random effects for subject i at time tij (inter- and intra-individual variability) are correlated across scores. Model estimation is performed with a SAEM[3, 4]-like algorithm implemented in C++. The multivariate normal cumulative distribution function is approximated using Gauss-Legendre quadratures. Two simulation studies were carried out with different scenarios to assess the applicability of our method. Drug dose or time-varying drug concentration was used as a covariate in the model. In the end, a principal component analysis was performed to summarise the correlations between scores. Results: Our method allowed correct estimation of all model parameters, including correlations between scores. As expected, multivariate and univariate analyses gave different results regarding the percentage of subjects within each “crossing” category. In contrast, they produced similar estimation of marginal distributions. Conclusions: We show that a multivariate analysis can be more appropriate than separate univariate analyses for the assessment of drug efficacy and safety and offers new perspectives in terms of <b>benefit-risk</b> ratio <b>evaluation.</b> The latent variable approach provides a good framework for the modelling of drug effects through various response models...|$|R
40|$|AbstractBackgroundDrug {{safety is}} one of the hottest topics in daily medical practice, {{particularly}} with regard to approving new medication or questioning the possibility of withdrawing a drug from the market. AimThe aim of this review is to highlight the importance of the drug safety concept and its impact on patients’ health. MethodsA literature search was conducted using Pubmed®, EMBASE®, EBSCO and Medline in the period between 1980 and 2013. The terms used in the search included “Drug Safety”, “Medication Safety”, “Patient Safety”, “Drug Interaction”, “Drug Pharmacokinetic”, and “Adverse Drug Reaction”. All retrieved abstracts were evaluated {{within the context of the}} review objectives. The full texts of the selected articles were included in this review. Studies in non-English language were excluded in this review. ResultsSince the early days of the past century, many acts, laws, or amendments have been created to make sure that approved drugs are first safe and then effective. Furthermore, these regulations are continuing to change to make sure that these drugs have a positive benefit–risk balance. Personalized medicine should be considered when medications are given to patients because the pharmacokinetic process inside the body varies from patient to patient and from one specific disease state to another. However, adverse drug reactions can be minimized if more precautions are taken by healthcare professionals, especially including the patient as one pillar of the therapeutic plan and providing more patient counseling, which will improve drug safety. ConclusionThe drug safety concept has earned a lot of attention during the past decade due to the fact it plays a major role in patients’ health. Recent laws stress this concept should be included in the process of new medications’ approval and continued conduct of post-marketing drug <b>evaluations.</b> <b>Benefit–risk</b> assessment should be considered by all health care professionals when they need to give specific drugs to specific groups of patients. Therefore, more care should be given to some patients, such as pregnant women, children and the elderly, since they are considered vulnerable populations...|$|R
40|$|In benefit-risk {{evaluations}} {{there is}} a trend towards a life cycle approach including continuous <b>benefit-risk</b> <b>evaluation</b> instead of a single benefit-risk assessment at a certain (fixed) point in time. The objective of this thesis is to unravel how {{the context in which}} a medicine is used adds to the assessment of the benefit-risk profile, and to gain more insight in the value of this information for both drug development and regulatory decision-making. One of the main findings was {{that it is important to}} select the appropriate patient population for randomised clinical trials (RCTs), especially if both the pharmacological working mechanism and the expected patient population outside the clinical trial setting indicate that safety issues will focus within a certain area. Otherwise, extrapolation of the results to the setting outside clinical trials will be difficult. In some studies (not well-controlled and/or progressive) diabetes has been associated with an increased risk of infections. It is therefore difficult to study the effect of antidiabetic medicines on the occurrence of infections. We performed two studies that both showed that infections were approximately two times more frequently reported for DPP- 4 inhibitors compared to other antidiabetic drugs. These findings, in combination with the biologic plausibility may suggest a potential relation between DPP- 4 inhibitors and infections. Several studies showed that psychiatric disease was almost twice as present among patients starting anti-obesity drugs (AODs) than patients not starting these drugs. In addition, differences in general health care utilisation between these groups increased gradually over the 3 -year period before start of AODs but no specific point in time could be identified from where differences between began to appear. We found that the duration of anti-obesity drug use was limited. One study, for example, showed that patients with a history of psychiatric illness were at increased risk of early discontinuation of rimonabant therapy, most pronounced due to psychiatric events. This implies that patients discontinue treatment because of psychiatric events before the possible cardiovascular benefits could develop, thereby negatively affecting the benefit-risk profile of rimonabant. These findings urge us to be very careful in interpreting the benefits and risks of anti-obesity drugs, both in terms of preventing possible exposure of drugs associated with psychiatric events in susceptible patients and in the evaluation of causality when a possible drug induced problem occurs. Finally we showed that differences in health status exist between users of the two strengths of the anti-obesity drug orlistat which are available through different channels (available on prescription vs. available without prescription, only in pharmacies). This information illustrates that user information from observational studies is also valuable for benefit-risk evaluations of one active component that is being used in two different settings. We concluded that for an adequate <b>benefit-risk</b> <b>evaluation</b> of a medicinal product, information on the complete context in which medicines are being used is necessary. This consists of extensive information on the patient population in which medicines are being used, usage patterns including the duration of use, and the effect of the regulated availability of medicines...|$|E
40|$|Today {{foremost}} {{emphasis is}} being given {{to the protection of}} patient’s safety and ethics during the conduct of clinical trials. Serious considerations by regulatory authorities are taken to safeguard the patient’s right, safety and wellbeing involved in a clinical trial. In addition considerations like International Conference on Harmonization (ICH) guidelines, Investigational New Drug (IND) application, New Drug Application (NDA), Post Marketing Surveillance (PMS) and Periodic <b>Benefit-Risk</b> <b>Evaluation</b> Report (PBRER) formerly known as Periodic Safety Update Report (PSUR) submissions to different regulatory authorities has also been framed to strengthen ethics and patient’s safety. However modern clinical trials have evolved through serious consequences and tragedies like Thalidomide Tragedy, Sulfanilamide Disaster, Clioquinolol Tragedy, etc. associated with high morbidity and mortality. Potential reasons behind these tragedies include unethical clinical practices, inadequate preclinical safety and efficacy data, non-scientific conduct, lack of attentiveness for patient care, misinterpretation of safety data, lack of pharmaco-vigilance, slow withdrawal of drug from market etc. Hence toiling efforts have been made and should be made in investigating lacunas in national as well as international systems that encourage launch of such spurious drugs that needed withdrawals after 10 - 20 years of public use. This manuscript intends to collect and present data on tragic clinical trials, highlight the tragedies that occurred during the dark era of clinical trials and enumerate various corrective actions taken in response to the lessons learnt during those clinical trials...|$|E
40|$|AbstractObjectiveThere is {{consensus}} {{that a more}} transparent, explicit, and rigorous approach to <b>benefit–risk</b> <b>evaluation</b> is required. The objective {{of this study is}} to evaluate the incremental net benefit (INB) framework for undertaking quantitative benefit–risk assessment by performing a quantitative benefit–risk analysis of alosetron for the treatment of irritable bowel syndrome from the patients’ perspective. MethodsA discrete event simulation model was developed to determine the INB of alosetron relative to placebo, calculated as “relative value-adjusted life-years (RVALYs). ”ResultsIn the base case analysis, alosetron resulted in a mean INB of 34. 1 RVALYs per 1000 patients treated relative to placebo over 52 weeks of treatment. Incorporating parameter uncertainty into the model, probabilistic sensitivity analysis revealed a mean INB of 30. 4 (95 % confidence interval 15. 9 – 45. 4) RVALYs per 1000 patients treated relative to placebo over 52 weeks of treatment. Overall, there was > 99 % chance that both the incremental benefit and incremental risk associated with alosetron are greater than placebo. As hypothesized, the INB of alosetron was greatest in patients with the worst quality of life experienced at baseline. The mean INB associated with alosetron in patients with mild, moderate, and severe symptoms at baseline was 17. 97 (− 0. 55 to 36. 23), 29. 98 (17. 05 – 43. 37), and 35. 98 (23. 49 – 48. 77) RVALYs per 1000 patients treated, respectively. ConclusionsThis study demonstrates the potential utility of applying the INB framework to real-life decision-making, and the ability to use simulation modeling incorporating outcomes data from different sources as a benefit–risk decision aid...|$|E
40|$|Introduction Numerous {{publications}} identify that gout {{management is}} often sub-optimal, despite detailed {{understanding of the}} pathogenesis and pathophysiology of the disorder, the ability to establish the diagnosis with certainty, and the likely effectiveness of lifestyle and pharmacological interventions. Barriers to successful gout management include diagnostic inaccuracy, a paucity of guidelines, sub-optimal patient education and patient adherence, co-morbidities and drug-drug interferences that complicate treatment of gout, and limited urate-lowering alternatives. Furthermore, a lack of information exists on the risk-benefit ratios of antihyperuricemic drugs for gout treatment. This thesis studies the clinical pharmacology of antihyperuricemic dugs {{in the treatment of}} gout in clinical practice, with focus on efficacy and tolerability. Studies and reviews of this thesis focus on: management of gout, outcome research with antihyperuricemic drugs, therapeutic drug monitoring of allopurinol, and rasburicase for treatment of gout. Management of gout In chapter 2. 1, we reviewed the literature on management of gout and presented a therapeutic strategy. Limited information on drugs indicated for the treatment of gout is available, making it difficult for physicians to make informed treatment decisions. The current therapeutic strategy is often based on clinical experience. Lifestyle advice is of limited value in the prevention of gout, particularly with regard to restricting alcohol, losing weight in cases of obesity, ensuring adequate diuresis and adhering to a low-purine diet, as most patients are reluctant to make such changes. Therefore, the condition is often treated with pharmacological therapies. Presently, oral colchicine and non-steroidal anti-inflammatory drugs (NSAIDs) are first-choice agents for systemic treatment of acute gout. In the absence of contra-indications, NSAIDs are a convenient and well-accepted option for treatment of acute gout. In case of tophaceous or recurrent gout, the use of urate-lowering drugs is recommended. Allopurinol is currently the first choice drug despite its AE profile at the population level. Many of the currently available treatment options for gout have unwanted side effects highlighting the importance of emerging therapeutics for the treatment of the disease. Benzbromarone (chapter 2. 2) is an old, but very potent urate-lowering drug, and possesses some distinct, recently discovered pharmacological features, which are important for effective and safe use in treatment of gout. Although benzbromarone is on the market for several decades, its place in treatment of gout compared to allopurinol is unclear, because of insufficient trials of good quality. The toxicity of benzbromarone is generally limited, but serious benzbromarone-induced hepatic failure is reported in rare cases. The underlying mechanism has not yet been fully explained, but formation of reactive metabolites by CYP 2 C 9 resulting in mitochondrial toxicity, and CYP 2 C 9 allelic variants might play a role. Important drug-drug interactions may occur with CYP 2 C 9 -substrate drugs, but clinical data are lacking up until now. Outcome research with antihyperuricemic drugs In chapter 3, several studies concerning the efficacy and tolerability of antihyperuricemic drugs in the treatment of gout in clinical rheumatologic practice are presented. In 2003, benzbromarone was withdrawn from the global market. In the Netherlands, suggested alternative treatments were allopurinol (in standard dosage) or probenecid. We studied the market withdrawal of benzbromarone in gout patients in chapter 3. 1, and investigated the efficacy of two alternative treatment strategies: allopurinol (standard dosage) and allopurinol-probenecid combination therapy. A prospective, open study was carried out in 51 patients. Patients were given 200 - 300 mg allopurinol (stage 1); when allopurinol failed to attain the target serum urate concentration, sUr ≤ 0. 30 mmol/l (5. 0 mg/dl), probenecid 1, 000 mg/day was added (stage 2). We found that previous treatment with benzbromarone monotherapy (mean dosage 138 mg/day) resulted in 92 % of patients reaching target levels sUr ≤ 0. 30 mmol/l with a mean sUr decrease of 61 % compared to baseline. In stage 1, 32 patients completed treatment with allopurinol monotherapy (mean dosage 256 mg/day), which resulted in 25 % of patients attaining sUr target levels. Decrease in sUr levels was 36 %, which was significantly less compared to treatment with benzbromarone. In stage 2, 14 patients received allopurinol-probenecid combination therapy, which resulted in 86 % of patients attaining target sUr levels (after failure on allopurinol monotherapy), which was comparable to previous treatment with benzbromarone. Decrease in sUr levels was 53 %, which was a non-significant difference compared to previous treatment with benzbromarone. From the results, it was concluded that benzbromarone is a very effective sUr-lowering drug. Allopurinol in standard dosage was shown to be a less potent alternative for most selected patients to attain target sUr levels. In patients failing on allopurinol monotherapy, the addition of probenecid proves to be an effective treatment strategy for attaining sUr target levels. The results of this study stress the need for effective, evidence-based treatment strategies for lowering of serum urate in gout patients. In The Netherlands, the use of benzbromarone is restricted to gout patients allergic to allopurinol, or otherwise not treatable with this drug. The Dutch general practitioners’ guideline also includes patients who cannot be treated sufficiently with allopurinol. In chapter 3. 2, we investigated the efficacy and tolerability of allopurinol (standard dosage) as first-choice antihyperuricemic treatment for gout, and compared the efficacy and tolerability of benzbromarone and probenecid as second-choice treatment. A multi-centre, open-label, randomised controlled trial was carried out in 96 gout patients with a calculated creatinine clearance > 50 ml/min who were prescribed 300 mg allopurinol daily for 2 months (stage 1). In 82 eligible patients, 24 % attained target sUr ≤ 0. 30 mmol/l, and sUr concentrations decreased 36 % from baseline; 11 % stopped allopurinol because of adverse drug reactions. Then, 62 patients failing on allopurinol were randomised to benzbromarone 200 mg/day or probenecid 2, 000 mg/day (stage 2). After 2 months, 22 out of 24 patients (92 %) were treated successfully with benzbromarone, with a sUr decrease of 64 % on average. Treatment success with probenecid was 20 out of 31 patients (65 %), with a sUr decrease of 50 %. This study showed a poor efficacy and tolerability profile of allopurinol 300 mg/day to attain a biochemical predefined target level of sUr ≤ 0. 30 mmol/l after 2 -months treatment. Whether higher doses of allopurinol would increase treatment success, remains subject of further research (chapter 3. 4). In patients failing on allopurinol 300 mg/day, benzbromarone 200 mg/day is significantly more effective and better tolerated than probenecid 2, 000 mg/day. Serum urate is a well-accepted surrogate parameter for short-term evaluation of gout treatment. Furthermore, information on clinical outcomes, such as prevention of recurrent gout attacks and diminishment of tophi, is essential. A lack of long-term, good-quality, prospective data exists addressing the efficacy of serum urate (sUr) lowering treatment to prevent these clinical symptoms. We conducted an observational follow-up study (chapter 3. 3) to assess the rate of recurrent gouty arthritis in 50 patients with a history of recurrent gouty attacks, normal renal function, using antihyperuricemic treatment, and who completed a randomised controlled trial. After 10. 6 months on average, incidence of gout attacks was largely reduced compared to baseline rates: 74 % of patients were free of gouty attacks (100 % reduction), and 18 % of patients had 50 - 99 % reduction of gouty attacks. Serum urate concentrations were 0. 28 [± 0. 08] mmol/l. We found a high reduction in incidence of gout attacks, that was better than obtained in most previous studies. This might be explained by the good control of serum urate in this study. No correlation was found between reduction of gout attacks and sUr or study drug used, due to lack of power. We concluded that antihyperuricemic therapy is highly effective in reducing and preventing gout attacks in gout patients with normal renal function. In chapter 3. 4, we investigated the efficacy and tolerability of allopurinol 300 - 600 mg/day versus benzbromarone 100 - 200 mg/day to attain a target sUr ≤ 0. 30 mmol/l. A multi-centre, open-label, randomised controlled trial was carried out in 65 patients recently diagnosed with gout, who were randomised to allopurinol 300 mg/day or benzbromarone 100 mg/day (stage 1). When the target sUr was not reached, the dosage was doubled. After stage 1 treatment success was 8 out of 31 (26 %) with allopurinol 300 mg/day, and 13 out of 25 (52 %) with benzbromarone 100 mg/day. Overall treatment success with allopurinol 300 - 600 mg/day was 21 out of 27 (78 %), and with benzbromarone 100 - 200 mg/day was 18 out of 23 (78 %), a non-significant difference. In this study, dosage increase of allopurinol and benzbromarone did not affect tolerability. This study showed that efficacy of allopurinol (and to a lesser extent benzbromarone) in gout patients can be markedly increased with increasing dosage. The overall efficacy of allopurinol and benzbromarone was not significantly different. Therapeutic drug monitoring of allopurinol Chapter 4 concerns the therapeutic drug monitoring of allopurinol treatment. From previous studies it is known that antihyperuricemic efficacy of allopurinol is related to the serum concentration of oxipurinol, the active metabolite of allopurinol. Reference values of oxipurinol 5 - 15 mg/l (trough) are suggested, but poorly investigated. Given the poor efficacy results of allopurinol in literature and clinical practice, optimisation of allopurinol therapy is warranted. Therapeutic drug monitoring of allopurinol might be particularly useful in case of patients with renal impairment, oxipurinol-lowering drug-drug interactions, or suspected poor adherence. In chapter 4. 1, a reversed-phase high-performance liquid chromatography method with UV-detection (HPLC-UV) to obtain a method for the quantification of allopurinol and oxipurinol in human serum, was validated technically and clinically. The method showed acceptable performance on all major aspects of the validation (linearity, intra- and inter-day precision, accuracy, specificity, and lower/upper limits of quantification). For clinical validation, the serum allopurinol and oxipurinol concentrations in 66 gout patients were determined using this HPLC-UV method. Measured serum allopurinol and oxipurinol concentrations in clinical practice showed large variability with a range of < 0. 5 - 4. 3 mg/l for allopurinol and < 1. 0 - 39. 2 mg/l for oxipurinol, respectively. From these results, we concluded that the proposed method could be employed for the assay of allopurinol and oxipurinol in gout patients. Uricase for gout treatment Recently, a new class of powerful urate-lowering drugs has become available with rasburicase, recombinant uricase. Rasburicase is developed for the treatment and prevention of tumour-lysis syndrome. In chapter 5, the potential role of rasburicase in treatment of severe, treatment-resistant gout was reviewed, and explored in two cases. Future perspectives From the chapters 2. 1, 2. 2, and 3. 1, we conclude that a need for more evidence and education on treatment of gout exists, although the pathogenesis of the disease is well understood and antihyperuricemic therapies are available for decades. Indeed, (only) very recently two important guidelines have been developed: the EULAR recommendations on gout (2006) and the British guideline (2007). The - in some countries temporarily - withdrawal of benzbromarone made clear that this was not in the benefit of gout patients in general, because of scarcity of drugs for antihyperuricemic treatment. The <b>benefit-risk</b> <b>evaluations</b> of alternative drugs might not have been addressed properly, and better efforts might have been done for vigilance and understanding of the hepatotoxicity. Since allopurinol is the only drug currently available worldwide, {{it is very important to}} know how to use this drug safely and effectively. Chapter 3. 2, 3. 4 and 4, show that at least in patients with normal renal function, allopurinol often is inadequately dosed and that target serum urate concentrations can be reached with good tolerability by increase of allopurinol dosage and by optimising serum oxipurinol trough concentrations. In the end, good control of serum urate is associated with good control of gout symptoms (chapter 3. 3). Subject of further research is to what extent these findings can be generalised to patients with renal dysfunction, a large group in gout. This is important, because uricosuric drugs are likely to be less effective in renal dysfunction, and a need for optimisation of allopurinol dosage regimens according to renal function exists. Currently, new antihyperuricemic drugs have been developed for gout treatment: febuxostat, a xanthine oxidase inhibitor, and pegloticase, a pegylated form of uricase. New drugs for treatment of gout are welcomed. However, the benefit-risk profiles of these drugs are not undisputed, since febuxostat is associated with liver enzyme elevations, and pegloticase with antibody formation. These new drugs might help management of gout, but more issues require attention to bridge the gap between clinical practice and potential treatment possibilities, such as optimisation of current treatment regimens, evidence of benefit of long-term treatment of gout on clinical outcomes, and patient’s adherence. ...|$|R
40|$|AbstractThe 4 th {{edition of}} the European Code against Cancer {{recommends}} limiting – or avoiding when possible – the use of hormone replacement therapy (HRT) because of the increased risk of cancer, nevertheless acknowledging that prescription of HRT may be indicated under certain medical conditions. Current evidence shows that HRT, generally prescribed as menopausal hormone therapy, is {{associated with an increased}} risk of cancers of the breast, endometrium, and ovary, with the risk pattern depending on factors such as the type of therapy (oestrogen-only or combined oestrogen–progestogen), duration of treatment, and initiation according to the time of menopause. Carcinogenicity has also been established for anti-neoplastic agents used in cancer therapy, immunosuppressants, oestrogen–progestogen contraceptives, and tamoxifen. Medical use of ionising radiation, an established carcinogen, can provide major health benefits; however, prudent practices need to be in place, with procedures and techniques providing the needed diagnostic information or therapeutic gain with the lowest possible radiation exposure. For pharmaceutical drugs and medical radiation exposure with convincing evidence on their carcinogenicity, health benefits have to be balanced against the risks; potential increases in long-term cancer risk should be considered {{in the context of the}} often substantial and immediate health benefits from diagnosis and/or treatment. Thus, apart from HRT, no general recommendations on reducing cancer risk were given for carcinogenic drugs and medical radiation in the 4 th edition of European Code against Cancer. It is crucial that the application of these measures relies on medical expertise and thorough <b>benefit–risk</b> <b>evaluation.</b> This also pertains to cancer-preventive drugs, and self-medication with aspirin or other potential chemopreventive drugs is strongly discouraged because of the possibility of serious, potentially lethal, adverse events...|$|E
40|$|Single high oral {{doses of}} fluoroquinolones (e. g., 1, 200 mg of ofloxacin/kg of body weight) are chondrotoxic in {{juvenile}} rats. Characteristic cartilage lesions are detectable {{as early as}} 12 h after treatment. Since this dosing regimen {{does not reflect the}} therapeutic situation, we studied the effects of a 5 - or 7 -day treatment with ofloxacin at lower oral doses (10, 30, and 100 mg/kg twice a day [b. i. d. ]) on joint cartilage in 4 -week-old rats. We additionally investigated whether the effects of ofloxacin under these conditions are enhanced in animals kept on a magnesium-deficient diet during treatment. Knee joints were examined histologically. The concentrations of ofloxacin and magnesium were determined in plasma and cartilage. The lowest ofloxacin dose at which cartilage lesions occurred in animals on a standard diet was 100 mg/kg b. i. d. for 5 days. Peak plasma ofloxacin levels were approximately 10 mg/liter in these rats and thus were in the same range as the levels in the plasma of humans during therapy with high doses of ofloxacin. Treatment with 30 mg of ofloxacin/kg b. i. d. for 7 days caused no cartilage lesions in rats on a standard diet, but lesions did occur in 10 of 12 rats that were simultaneously fed a magnesium-deficient diet. Magnesium concentrations in bone, plasma, and cartilage from animals on an Mg 2 +-deficient diet were significantly lower than those in the controls. The concentration in plasma from animals on an Mg 2 +-deficient diet was 0. 27 ± 0. 03 mmol/liter, whereas it was 0. 88 ± 0. 08 mmol/liter in plasma from rats on a standard diet (means ± standard deviations). Ofloxacin treatment did not change the total magnesium concentrations in tissues, as determined with ashed samples. The incidence of ofloxacin-induced lesions was higher in the magnesium-deficient animals, suggesting a synergistic effect. These results {{must be taken into account}} for a <b>benefit-risk</b> <b>evaluation</b> if ofloxacin is considered for use in the pediatric population...|$|E
40|$|Background: Natalizumab {{provides}} {{rapid and}} high-efficacy control of multiple sclerosis disease activity with long-term stabilization. However, {{the benefits of}} the drug are countered by a risk of developing progressive multifocal leukoencephalopathy in patients infected with the John Cunningham Virus. Close monitoring is required in patients with increased progressive multifocal leukoencephalopathy risk receiving natalizumab in the long-term for an optimal <b>benefit-risk</b> <b>evaluation.</b> Standardized high-quality monitoring procedures may provide a superior basis for individual benefit and risk evaluation and thus improve treatment decisions. The non-interventional study TRUST was designed to capture natalizumab effectiveness under real-life conditions and to examine alternate approaches for clinical assessments, magnetic resonance imaging monitoring and use of biomarkers for progressive multifocal leukoencephalopathy risk stratification. Methods/Design: TRUST is a non-interventional, multicenter, prospective cohort study conducted at approximately 200 German neurological centers. The study is intended to enroll 1260 relapsing-remitting multiple sclerosis patients with ongoing natalizumab therapy for at least 12  months. Patients will be followed for a period of 3  years, irrespective of treatment changes after study start. Data on clinical, subclinical and patient-centric outcomes will be documented in order to compare the effectiveness of continuous versus discontinued natalizumab treatment. Furthermore, the type and frequency of clinical, magnetic resonance imaging and biomarker assessments, reasons for continuation or discontinuation of therapy and the safety profile of natalizumab will be collected to explore the impact of a systematic patient management approach and its potential impact on patient outcome. Specifically, the role of biomarkers, the use of expert opinions, the impact of high-frequency magnetic resonance imaging assessment for early progressive multifocal leukoencephalopathy detection and the role of additional radiological and clinical expert advice will be explored. Discussion: TRUST was initiated in spring 2014 and enrollment is anticipated to be completed by mid 2016. Annual interim analyses will deliver continuous information and transparency with regard to the patient cohorts and the completeness and quality of data as well as closely monitor any safety signals in the natalizumab-treated cohort. The study’s results may provide insights into opportunities to improve the benefit-risk assessment in clinical practice and support treatment decisions...|$|E
40|$|Background and objectives: Desloratadine and {{levocetirizine}} are histamine H 1 receptor antagonists (antihistamines) {{that were}} {{launched in the}} UK in 2001. Our objective was to compare {{the frequency with which}} drowsiness and sedation were reported for desloratadine and levocetirizine within the first 30 days of observation, as monitored using the observational cohort technique of prescription-event monitoring (PEM). Methods: Exposure data were derived from dispensed prescriptions written by primary care physicians and outcome data were derived from questionnaires that were posted to prescribers at least 6 months after the date of the first prescription for each patient. The odds ratio (OR) was calculated using unconditional logistic regression modelling. The effect of age, sex, reported prescribing indication (allergic rhinitis with asthma/wheezing, allergic rhinitis without asthma/wheezing, 'other'), pattern of use and reported previous antihistamine use on the OR was examined. A time-to-event analysis was performed. Results: The cohorts comprised > 24 000 patients in total. Cohort demographics were similar (both cohorts: median age 37 years; 60 % women); the most frequently reported prescribing indication for both drugs was allergic rhinitis without asthma/wheezing (54 %). The incidence of first reports of drowsiness/sedation for levocetirizine or desloratadine was low (46 [0. 37 %] and 9 [0. 08 %], respectively) and statistically different (p < 0. 0001). These events tended to occur earlier for desloratadine than levocetirizine (50 % at 7 or 14 days of observation, respectively; p = 0. 6487), but the cumulative time to event differed, with more events observed for levocetirizine than expected (p < 0. 0001; 46 vs 28. 09). The final estimates of risk were the sex-adjusted ORs for each prescribing indication category: allergic rhinitis with asthma/wheezing (3. 51; 95 % CI 0. 71, 17. 43; n = 3357), allergic rhinitis without asthma/wheezing (6. 75; 95 % CI 2. 37, 19. 22; n = 12 627) and 'other' (3. 11; 95 % CI 0. 86, 11. 31; n = 6725). Discussion: Although the reporting rates of drowsiness and sedation are low for both drugs, patients prescribed levocetirizine are more likely to experience drowsiness and sedation in the first month of observation (after starting treatment) than patients prescribed desloratadine. For patients with allergic rhinitis without asthma/wheezing, the sex-adjusted odds of drowsiness/sedation were over six times greater in patients using levocetirizine than desloratadine in the first month of observation, with the OR being statistically significant. For the other two indication categories, allergic rhinitis with asthma/wheezing and 'other', the OR was not statistically significant. Conclusions: Although the risk of drowsiness/sedation is low, conditions such as allergic rhinitis are common, which makes any impact on patient cognitive function important. Doctors should be aware of this when prescribing these products to patients where daytime sedation is undesirable. However, essential components of the comparative <b>benefit-risk</b> <b>evaluation</b> of these two products include assessment of efficacy and patient preference (neither of which forms part of this study) ...|$|E

