2039|6168|Public
25|$|Hypothesis-driven {{statistical}} analysis: Identification of {{statistically significant}} changes in gene expression are commonly identified using the t-test, ANOVA, <b>Bayesian</b> <b>method</b> Mann–Whitney test methods tailored to microarray data sets, which take into account multiple comparisons or cluster analysis. These methods assess statistical power based on the variation present in the data {{and the number of}} experimental replicates, and can help minimize Type I and type II errors in the analyses.|$|E
25|$|Dynamic Causal Modeling (DCM) is a <b>Bayesian</b> <b>method</b> for deducing the {{structure}} of a neural system based on the observed hemodynamic (fMRI) or electrophysiologic (EEG/MEG) signal. The first step is to make a prediction as to the relationships between the brain regions of interest, and formulate a system of ordinary differential equations describing the causal relationship between them, although many parameters (and relationships) will be initially unknown. Using previous results on how neural activity is known to translate into fMRI or EEG signals, one can take the measured signal and determine the likelihood that model parameters have particular values. The elucidated model can then be used to predict relationships between the considered brain regions under different conditions. A key factor to consider during the design of neuroimaging experiments involving DCM is the relationship between the timing of tasks or stimuli presented to the subject and the ability of DCM to determine the underlying relationships between brain regions, which is partially determined by the temporal resolution of the imaging modality in use.|$|E
500|$|... (2015) – Report by the Australian Transport Safety Bureau, {{released}} 3 December 2015, {{covering the}} <b>Bayesian</b> <b>method</b> analysis made by Australia's Defence Science and Technology Group and other developments since mid-2014 {{in defining the}} search area.|$|E
40|$|Vanpaemel and Lee (2012) argue, and we agree, {{that the}} {{comparison}} of formal models can be facilitated by <b>Bayesian</b> <b>methods.</b> However, <b>Bayesian</b> <b>methods</b> neither precede nor supplant our proposals (Wills & Pothos, 2012), as <b>Bayesian</b> <b>methods</b> can be applied both to our proposals and to their polar opposites. Furthermore, the use of <b>Bayesian</b> <b>methods</b> to control for model complexity can be actively misleading when combined with the consideration of narrow data sets, and significant development work is required before <b>Bayesian</b> <b>methods</b> {{can be applied to}} some of the leading formal models of categorization. Even where <b>Bayesian</b> <b>methods</b> can be applied, the use of non-Bayesian methods is sometimes preferable due to their computational simplicity (Vanpaemel & Storms, 2010). We also clarify our position on arbitrarily variable parameters, and on the relationship between ordinal properties and overfitting...|$|R
40|$|Abstract — In risk analysis, <b>Bayesian</b> <b>methods</b> {{are more}} {{adaptability}} and flexibility than traditional methods when {{be used to}} construct decision framework, estimate risk distribution and parameterize model, but has shortcomings at the same time. Robust methods make up some limitations of <b>Bayesian</b> <b>methods,</b> the analysis of uncertainty indicate that robust <b>Bayesian</b> <b>methods</b> can produce more reliable inference {{in the absence of}} comprehensive statistical information. Keywords-risk; uncertainty; Bayesian; robust I...|$|R
40|$|Bayesian {{statistics}} is {{an alternative}} form of statistics that provides a way to systematically integrate new information with existing information. - <b>Bayesian</b> <b>methods</b> are very suitable for evidence synthesis. - Bayesian outcomes are easier to interpret than standard statistical outcomes. - For instance, <b>Bayesian</b> <b>methods</b> allow for determining {{the probability that a}} difference in effect between two treatments will be clinically relevant. - The use of <b>Bayesian</b> <b>methods</b> is becoming more prevalent...|$|R
2500|$|Niche College Rankings is an American college ranking {{site that}} {{incorporates}} analysis of college based statistics and reviews. Niche also features A-F rankings for K-12 schools and neighborhoods or districts. Niche's rankings are updated every year. This is shown as they first developed college rankings by major {{as well as}} rankings and graded Report Cards for community colleges and trade schools. Niche provides its own grading system that applies a <b>Bayesian</b> <b>method.</b> [...] In 2017, Niche provides several rankings in each category, [...] "Best Colleges," [...] "Best by Major," [...] "Best by State," [...] "Admissions," [...] "Campus Life," [...] "Student," [...] and [...] "Academics". Niche collects more than 100 million college reviews and survey responses as well as comprehensive data such as U.S Department of Education. Niche also incorporates data from the new College Scorecard Data that was introduced in 2015 by the Obama Administration under the U.S Department of Education.|$|E
5000|$|... #Caption: A {{heat map}} {{indicating}} the probable location of missing Flight 370 {{based on a}} <b>Bayesian</b> <b>method</b> analysis of possible flight paths by Australia's Defence Science and Technology Group.|$|E
5000|$|... #Caption: A heat map, atop a color {{bathymetric}} map, {{indicating the}} probable location of missing Malaysia Airlines Flight 370 {{based on a}} <b>Bayesian</b> <b>method</b> analysis of possible flight paths of the aircraft.|$|E
40|$|This report {{documents}} the {{research into the}} application of hierarchical <b>Bayesian</b> <b>methods</b> for characterizing the population failure rate (i. e. probability of defect) of an electronic component based on test data {{from a number of}} different test modalities. Classical statistical methods, those based on a frequency approach permit the combination of point estimates but stumble when characterizing the resulting confidence limits. Classical <b>Bayesian</b> <b>methods</b> permit the logical combination of test data, but are not fully efficient in incorporating all available information. In particular, classical <b>Bayesian</b> <b>methods</b> assume that the articles under test are not related in any manner even though the articles may be identical. Alternatively, hierarchical <b>Bayesian</b> <b>methods</b> permit the relationship between test articles to be explicitly included in the analysis. Data from four different test modalities are considered in the analysis. Comparisons are made between the current analysis approach (using traditional statistical <b>methods),</b> classical <b>Bayesian</b> <b>methods</b> and a hierarchical Bayesian approach...|$|R
40|$|Although Bayesian {{models of}} mind have {{attracted}} great interest from cognitive scientists, <b>Bayesian</b> <b>methods</b> for data analysis have not. This article reviews several advantages of Bayesian data analysis over traditional null-hypothesis significance testing. <b>Bayesian</b> <b>methods</b> provide tremendous flexibility for data analytic models and yield rich information about parameters {{that can be}} used cumulatively across progressive experiments. Because <b>Bayesian</b> statistical <b>methods</b> can be applied to any data, regardless of the type of cognitive model (Bayesian or otherwise) that motivated the data collection, <b>Bayesian</b> <b>methods</b> for data analysis will continue to be appropriate even if Bayesian models of mind lose their appeal. Cognitive science should be Bayesian even if cognitive scientists are no...|$|R
50|$|<b>Bayesian</b> <b>methods</b> may {{be useful}} in {{difficult}} cases.|$|R
5000|$|HPlus [...] - [...] A {{software}} package for imputation {{and testing of}} haplotypes in association studies using a modified method that incorporates the expectation-maximization algorithm and a <b>Bayesian</b> <b>method</b> known as progressive ligation.|$|E
5000|$|Hui, C., Foxcroft, L.C., Richardson, D.M. & MacFadyen, S. (2011) Defining optimal {{sampling}} {{effort for}} large-scale monitoring of invasive alien plants: a <b>Bayesian</b> <b>method</b> for estimating abundance and distribution. Journal of Applied Ecology, 48: 768-776.|$|E
50|$|In the {{statistics}} {{and computer science}} literature, Naive Bayes models are known {{under a variety of}} names, including simple Bayes and independence Bayes. All these names reference the use of Bayes' theorem in the classifier's decision rule, but naive Bayes is not (necessarily) a <b>Bayesian</b> <b>method.</b>|$|E
5000|$|<b>Bayesian</b> <b>methods</b> are {{characterized}} by concepts and procedures as follows: ...|$|R
40|$|Abstract. Hierarchical {{models are}} {{increasingly}} {{used in many}} applications. Along with this increased use comes a desire to investigate whether the model {{is compatible with the}} observed data. <b>Bayesian</b> <b>methods</b> are well suited to eliminate the many (nuisance) parameters in these complicated models; in this paper we investigate <b>Bayesian</b> <b>methods</b> for model checking. Since we contemplate model checking as a preliminary, exploratory analysis, we concentrate on objective <b>Bayesian</b> <b>methods</b> in which careful specification of an informative prior distribution is avoided. Numerous examples are given and different proposals are investigated and critically compared. Key words and phrases: Model checking, model criticism, objectiv...|$|R
40|$|Epidemiology 16, 225 – 237) {{studied the}} {{association}} between the daily number of visits to emergency departments for cardiovascular disease by the elderly (65 +) and five measures of ambient air pollution. <b>Bayesian</b> <b>methods</b> provide an alternative approach to classical time series modelling and are starting to be more widely used. This paper considers <b>Bayesian</b> <b>methods</b> using the dataset used by Jalaludin et al. (2006), and compares the results from <b>Bayesian</b> <b>methods</b> with those obtained by Jalaludin et al. (2006) using GLM methods. Key words: ambient air pollution; Bayesian Poisson regression model; cardiovascular diseases; generalized linear model. 1...|$|R
5000|$|The {{minimum message length}} {{principle}} (Wallace and Boulton, 1968, WB1968) [...] - [...] an information-theoretic {{principle in}} statistics, econometrics, machine learning, inductive inference and knowledge discovery which can be seen both as a mathematical formalisation of Occams Razor and as an invariant <b>Bayesian</b> <b>method</b> of model selection and point estimation, ...|$|E
5000|$|Assume that , i.e. {{that the}} {{posterior}} distribution factorizes into independent factors for [...] and [...] This type of assumption underlies the variational <b>Bayesian</b> <b>method.</b> The true posterior distribution {{does not in}} fact factor this way (in fact, in this simple case, it {{is known to be}} a Gaussian-gamma distribution), and hence the result we obtain will be an approximation.|$|E
50|$|There {{is a large}} {{literature}} on how one might estimate the ambient lighting from the camera data and then use this information to transform the image data. A variety of algorithms have been proposed, {{and the quality of}} these has been debated. A few examples and examination of the references therein will lead the reader to many others. Examples are Retinex, an artificial neural network or a <b>Bayesian</b> <b>method.</b>|$|E
40|$|Hierarchical {{models are}} {{increasingly}} {{used in many}} applications. Along with this increase use comes a desire to investigate whether the model {{is compatible with the}} observed data. <b>Bayesian</b> <b>methods</b> are well suited to eliminate the many (nuisance) parameters in these complicated models; in this paper we investigate <b>Bayesian</b> <b>methods</b> for model checking. Since we contemplate model checking as a preliminary, exploratory analysis, we concentrate in objective <b>Bayesian</b> <b>methods</b> in which careful specification of an informative prior distribution is avoided. Numerous examples are given and different proposals are investigated. Key words and phrases: model checking; model criticism; objective Bayesian methods; p-values. ...|$|R
40|$|This paper {{estimates}} {{with the}} <b>Bayesian</b> <b>methods</b> a CES production function for Singapore for 1960 - 2009. It is {{found that the}} elasticity of substitution is 0. 6, technical progress is labour augmenting and the steady state growth rate of Singapore is about 1. 8 %. <b>Bayesian</b> <b>methods,</b> CES production function and Technical progress...|$|R
5000|$|<b>Bayesian</b> <b>methods</b> {{have been}} also {{applied to the}} {{interpretation}} of quantum mechanics: ...|$|R
5000|$|Hypothesis-driven {{statistical}} analysis: Identification of {{statistically significant}} changes in gene expression are commonly identified using the t-test, ANOVA, <b>Bayesian</b> <b>method</b> Mann-Whitney test methods tailored to microarray data sets, which take into account multiple comparisons or cluster analysis. These methods assess statistical power based on the variation present in the data {{and the number of}} experimental replicates, and can help minimize Type I and type II errors in the analyses.|$|E
50|$|Both {{cognitive}} model and two underlying algorithms, model tracing and knowledge tracing, {{are used to}} monitor the student's learning. In model tracing, the cognitive tutor uses the {{cognitive model}} in complex problems to follow the student's individual path and provide prompt accuracy feedback and context-specific advice. In knowledge tracing, the cognitive tutor uses a simple <b>Bayesian</b> <b>method</b> of evaluating the student's knowledge and uses this student model to select appropriate problems for individual student.|$|E
50|$|Bayesian {{hierarchical}} modelling is {{a statistical}} model written in multiple levels (hierarchical form) that estimates {{the parameters of}} the posterior distribution using the <b>Bayesian</b> <b>method.</b> The sub-models combine to form the hierarchical model, and the Bayes’ theorem is used to integrate them with the observed data, and account for all the uncertainty that is present. The result of this integration is the posterior distribution, also known as the updated probability estimate, as additional evidence on the prior distribution is acquired.|$|E
5000|$|<b>Bayesian</b> <b>methods</b> in {{structural}} bioinformatics, (co-edited with Thomas Hamelryck and Jesper Ferkinghoff-Borg) ...|$|R
40|$|I {{describe}} {{an approach to}} similarity motivated by <b>Bayesian</b> <b>methods.</b> This yields a similarity function that is learnable using a standard <b>Bayesian</b> <b>methods.</b> The relationship of the approach to variable kernel and variable metric methods is discussed. The approach is related to variable kernel Experimental results on character recognition and 3 D object recognition are presented. ...|$|R
5000|$|It is {{difficult}} to calculate, so we can use Variational <b>Bayesian</b> <b>methods</b> of ...|$|R
50|$|Some {{researchers}} {{refute the}} <b>Bayesian</b> <b>method</b> obtained date, {{and argue that}} we cannot rely {{on the assumption that}} the deposits in which all the dated artefacts were located were undisturbed. They argue that the Bayesian AMS site chronology is problematic because it presents dating for material found above the maxilla returning an older date, implying that the material contexts had been disturbed. Furthermore it has need argued that the geology of the site undermines these dating methods as establishing stratigraphic relationships for sediments deposited in caves is problematic.|$|E
5000|$|The {{advantages}} of the <b>Bayesian</b> <b>method</b> are that all information available is used coherently (i.e., in a [...] "leak-proof" [...] manner) and the method automatically produces estimates of the cost for a given success probability. That is, even {{before the start of}} searching, one can say, hypothetically, [...] "there is a 65% chance of finding it in a 5-day search. That probability will rise to 90% after a 10-day search and 97% after 15 days" [...] or a similar statement. Thus the economic viability of the search can be estimated before committing resources to a search.|$|E
5000|$|Fisher {{designed}} the fiducial method to meet perceived {{problems with the}} Bayesian approach, {{at a time when}} the frequentist approach had yet to be fully developed. Such problems related to the need to assign a prior distribution to the unknown values. The aim was to have a procedure, like the <b>Bayesian</b> <b>method,</b> whose results could still be given an inverse probability interpretation based on the actual data observed. The method proceeds by attempting to derive a [...] "fiducial distribution", which is a measure of the degree of faith that can be put on any given value of the unknown parameter and is faithful to the data in the sense that the method uses all available information.|$|E
40|$|Abstract—Explosive {{growth in}} data and {{availability}} of cheap computing resources have sparked increasing interest in Big learning, an emerging subfield that studies scalable machine learning algorithms, systems, and applications with Big Data. <b>Bayesian</b> <b>methods</b> represent one important class of statistic methods for machine learning, with substantial recent developments on adaptive, flexible and scalable Bayesian learning. This article provides {{a survey of the}} recent advances in Big learning with <b>Bayesian</b> <b>methods,</b> termed Big <b>Bayesian</b> Learning, including nonparametric <b>Bayesian</b> <b>methods</b> for adaptively inferring model complexity, regularized Bayesian inference for improving the flexibility via posterior regularization, and scalable algorithms and systems based on stochastic subsampling and distributed computing for dealing with large-scale applications...|$|R
5000|$|Implementations of <b>Bayesian</b> <b>methods</b> {{generally}} use Markov chain Monte Carlo sampling algorithms, {{although the}} choice of move set varies; selections used in Bayesian phylogenetics include circularly permuting leaf nodes of a proposed tree at each step and swapping descendant subtrees of a random internal node between two related trees. The use of <b>Bayesian</b> <b>methods</b> in phylogenetics has been controversial, largely due to incomplete specification of {{the choice of}} move set, acceptance criterion, and prior distribution in published work. [...] <b>Bayesian</b> <b>methods</b> are generally held to be superior to parsimony-based methods; they can be more prone to long-branch attraction than maximum likelihood techniques, although they {{are better able to}} accommodate missing data.|$|R
40|$|A Bayesian {{approach}} is developed for making inferences about the rate of agreement in a particular decision problem. The problem considers the case where two decision methods make binary decisions, {{with one of the}} methods making objectively correct decisions, and the interest being in the rate with which the second method makes decisions that agree. The <b>Bayesian</b> <b>methods</b> developed allow the calculation of the full posterior distribution for the rate of agreement, and give a simple expression for its expectation. The Bayes Factor comparing models that assume dependence and full independence between the decision methods is also derived. Two simulation studies are reported, showing the superiority of the <b>Bayesian</b> <b>methods</b> to Orthodox estimation and hypothesis testing using the kappa statistic. A practical example involving a medical trial is presented, demonstrating that the <b>Bayesian</b> <b>methods</b> are easily applied and provide a general capability for making rational inferences about agreement for this problem. Keywords: Agreement Rate, Binary Decisions, <b>Bayesian</b> <b>Methods,</b> Bayes Factor, Kappa Statisti...|$|R
