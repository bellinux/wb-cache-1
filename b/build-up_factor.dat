15|17|Public
40|$|Abstract- An {{attempt is}} made to {{generate}} effective atomic number, exposure buildup factor (EBF) in the energy region 0. 015 - 15. 0 MeV up to a penetration depth of 40 mfp for some soils. The five parameters geometrical progression (G-P) fitting approximation {{has been used to}} calculate exposure <b>build-up</b> <b>factor</b> (EBF). The generated exposure buildup factors has been studied as function of incident photon energy & penetration depth and represented graphically. Index Terms- Exposure <b>build-up</b> <b>factor</b> (EBF), Mean free path (mfp), Effective atomic number (Zeff), Equivalent atomic number (Zeq) ...|$|E
40|$|The {{effective}} {{atomic number}} (Z eff) and electron density (N el) of hydroxyapatite (HA) and cortical bone have been computed for total photon interaction in the wide energy range of 1 keV- 100 GeV using WinXCom. The variations of {{effective atomic number}} and electron density with energy of HA are {{compared with that of}} cortical bone. GP. fitting method has been used to compute energy absorption and exposure <b>build-up</b> <b>factor</b> of HA for wide energy range (0. 015 MeV- 15 MeV) up to the penetration depth of 40 mean free path. The computed absorption <b>build-up</b> <b>factor</b> is used to estimate specific absorbed fraction of energy (Ï) and relative dose of photon in HA. <b>Build-up</b> <b>factor</b> increases with increase of penetration depth. The results of the present paper will also help in estimating safe dose levels for radiotherapy patients and also will be useful in dosimetry and diagnostics. Â© 2012 Elsevier Ltd. All rights reserved...|$|E
40|$|In this work, {{we report}} on a closed-form {{formulation}} for the <b>build-up</b> <b>factor</b> and absorbed energy, in one and two di- mensional Cartesian geometry for photons and electrons, in the Compton energy range. For the one-dimensional case we use the LTSN method, assuming the Klein-Nishina scattering kernel for {{the determination of the}} angular radiation intensity for photons. We apply the two-dimensional LTSN nodal solution for the averaged angular radiation evaluation for the two-dimensional case, using the Klein-Nishina kernel for photons and the Compton kernel for electrons. From the angular radiation intensity we construct a closed-form solution for the <b>build-up</b> <b>factor</b> and evaluate the absorbed energy. We present numerical simulations and comparisons against results from the literature...|$|E
40|$|Abstract: Radiographic {{simulation}} of thick components represents a particular challenge, since the Monte-Carlo methods generally applied to obtain accurate scattering predictions are inherently slow, {{and as such}} not suited to applications for inspection procedure qualification, where {{a large number of}} parameter variations has to be studied in a reasonable time. We present a generic radiographic modeling code, which overcomes this impediment by combining a Monte-Carlo approach with a simple straight-line attenuation model and an analytical film-foil model. The code MODERATO has been thoroughly validated and is now used to perform parametric studies for performance demonstration purposes. Introduction: When modeling radiographic inspections for thin components, scattered radiation can often be entirely ignored. In the intermediate thickness range, a commonly used approach accounts for scattered radiation with tabulated <b>build-up</b> <b>factors,</b> often obtained previously with Monte-Carlo codes. For these situations, straight line attenuation models are sufficient to obtain reasonably accurate results. Another approach which has recently attracted interest in th...|$|R
40|$|The aim of {{this paper}} is to further {{validate}} the physical capability of N-VisageTM under more challenging shielding geometries, when the number of mean free paths is greater than one. N-VisageTM is a recently established technique developed at REACT Engineering Ltd. The software locates radionuclide sources and contours radiation magnitude. The N-VisageTM software uses a geometric computer model combined with measured spectra. The software is able to estimate source locations through shielding materials by using mass attenuation coefficients to calculate the number of unscattered gamma photons arriving at the detector, and <b>build-up</b> <b>factors</b> to estimate scatter contribution to dose rate. The experiments described in this paper were carried out in a high-scatter environment using cobalt- 60 and caesium- 137 sources, these two sources are the primary sources of radiological contamination found in the nuclear industry. It is hoped that this will further assist in the identification, characterisation and removal of buried radiologically contaminated waste...|$|R
40|$|The Nuclear Detection Figure Of Merit (NDFOM) portal is a {{database}} of objects and algorithms for evaluating the performance of radiation detectors to detect nuclear material. This paper describes the algorithms used to model the physics and mathematics of radiation detection. As a first-principles end-to-end analysis system, it starts with {{the representation of the}} gamma and neutron spectral fluxes, which are computed with the particle and radiation transport code MCNPX. The gamma spectra emitted by uranium, plutonium, and several other materials of interest are described. The impact of shielding and other intervening material is computed by the method of <b>build-up</b> <b>factors.</b> The interaction of radiation with the detector material is computed by a detector response function approach. The construction of detector response function matrices based on MCNPX simulation runs is described in detail. Neutron fluxes are represented in a three group formulation to treat differences in detector sensitivities to thermal, epithermal, and fast neutrons...|$|R
40|$|We {{consider}} the time dependent neutron diffusion equation for one energy group in cylinder coordinates, assuming translational symmetry along the cylinder axis. This {{problem for a}} specific energy group is solved analytically applying the Hankel transform in the radial coordinate r. Our special interest rests in the <b>build-up</b> <b>factor</b> for a time dependent linear neutron source aligned with the cylinder axis, which {{in the limit of}} zero decay constant reproduces also the static case. The new approach to solve the diffusion equation by integral transform technique is presented and results for several parameter sets and truncation in the solution for the flux and <b>build-up</b> <b>factor</b> are shown and found to be compatible to those of literature [1, 2]. </p...|$|E
40|$|Geometric {{progression}} fitting {{method has}} been used to compute energy absorption <b>build-up</b> <b>factor</b> of teeth enamel outer surface, enamel middle, enamel dentin junction towards enamel, enamel dentin junction towards dentin, dentin middle and dentin inner surface for wide energy range (0. 015 - 15 MeV) up to the penetration depth of 40 mean free path. The dependence of energy absorption <b>build-up</b> <b>factor</b> on incident photon energy, penetration depth, electron density and effective atomic number has also been studied. The energy absorption build-up factors increases with the penetration depth and electron density of teeth. So that the degree of violation of Lambert-Beer (I = I 0 e -Î¼t) law is less for least penetration depth and electron density. The energy absorption build-up factors for different regions of teeth are not same hence the energy absorbed by the different regions of teeth is not uniform which depends on the composition of the medium. The relative dose of gamma in different regions of teeth is also estimated. Dosimetric implication of energy absorption <b>build-up</b> <b>factor</b> in teeth has also been discussed. The estimated absorption build up factors in different regions of teeth may be useful in the electron spin resonance dosimetry. Â© 2011 AkadÃ©miai KiadÃ³, Budapest, Hungary...|$|E
40|$|G-P fitting {{method has}} been used to compute energy {{absorption}} <b>build-up</b> <b>factor</b> of bone compact and bone cortical for wide energy range (0. 015 - 15 MeV). The computed absorption <b>build-up</b> <b>factor</b> is used to estimate specific absorbed fraction of energy. The thickness of the medium up to 10 mm and with penetration depth up to 40 mean free paths considered. The dependence of specific absorbed fraction of energy on incident photon energy, penetration and the thickness of the medium have also been studied. The variations of specific absorbed fraction of energy with incident photon energy, penetration and the thickness of the medium are shown in graphs. The computed specific absorbed fractions of energy values are more accurate than the data available in the literature because the variation of an effective atomic number with energy is also considered in the calculation. The application of the present work is also discussed. Â© 2011 Elsevier Ltd. All rights reserved...|$|E
40|$|Methods used {{to convert}} wind tunnel and ADMS {{concentration}} feld data for a complex building array into effective radiation dose were developed based on simulations of {{a site in}} central London. Pollutant source terms were from positron emitting gases released from a cyclotron and clinical PET radiotracer facility. Five years of meteorological data were analysed to determine the probability distribution of wind direction and speed. A hemispherical plume cloud model (both static and moving) was developed which enabled an expression of gamma-ray dose, taking into account <b>build-up</b> <b>factors</b> in air, in terms of analytic functions in this geometry. The standard building wake model is presented, but this is extended and developed in a new model to cover the concentration feld {{in the vicinity of}} a roof top structure recirculation zone, which is then related to the concentration in the main building wake zone. For all models presented the effective dose was determined from inhalation, positron cloud immersion and gamma ray plume contributions. Results of applying these models for determination of radiation dose for a particular site are presented elsewhere...|$|R
30|$|Stability {{analysis}} of the Tandikat landslide using a rigid block on a quasi-plastic layer assumption and the actual earthquake acceleration suggested that slope failure occurred due to pore pressure <b>build-up.</b> The <b>factor</b> of safety decreased rapidly before earthquake acceleration peaked. At that time, {{the energy of the}} earthquake had not reached its maximum level, suggesting that failure would probably occur on saturated sliding zone even during smaller earthquakes. This finding emphasises the high risk of catastrophic earthquake-triggered landslides in tropical regions with high rainfall.|$|R
30|$|Overall, it is {{difficult}} to give a prognosis for future elderly poverty, as elderly income is influenced by economic, socio-structural and political factors. However, the tendencies we have examined here point to increasing old-age poverty due to the <b>build-up</b> of risk <b>factors.</b> The hardest hit by this will be incapacity allowance claimants, the long-term unemployed and workers in low-paid sectors [11, 30].|$|R
40|$|MicroShield is a point-kernel {{computer}} code used for gamma-ray shielding and dose rate assessment. It allows the modeling of simple source geome-tries and simple shielding layouts {{which lead to}} very accurate results with low computer time consumption, compared with more advanced methods such as Monte Carlo transport code (e. g., MCNP), among others. The short computer time in finding solutions {{is due to a}} deterministic transport using analytic solutions for the direct source contribution (unscattered radiation) to the detector, and then corrected by a <b>build-up</b> <b>factor</b> appropriate for the geometry used in the calculation. On the other hand, Monte Carlo transport codes, such as MCNP, solve the detailed physics of the transport in the real geometry (calculating a <b>build-up</b> <b>factor</b> as a by-product); however, the set up of the geometry and the implementation of variance reduction techniques (always necessary in shielding problems) is complex and time consuming. Al-though the MicroShield software give good results for many 7 -ray shieldin...|$|E
40|$|Abstract: The {{present study}} was {{conducted}} to measure the phosphorus (P) adsorption capacities in a typic Camborthid (Bhalike series) soil of rice tract of Punjab, Pakistan to compute P fertilizer quantities for field application, internal and external P requirements of the wheat, sorghum fodder and rice, Phosphorus Fertility <b>Build-up</b> <b>Factor</b> (PFBF) and level of phosphorus build-up. The soil selection was based on clay percentage, calcium carbonate content. The data showed that soil was free from salinity and sodicity, deficient in organic matter and adequate in available potassium. Sorption isotherm was constructed in the laboratory by...|$|E
40|$|Effective {{atomic number}} (Zeff) and {{electron}} density (Neff) are convenient parameters used to characterise the radiation response of a multi-element {{material in the}} technical and industrial applications, radiation shielding design, absorbed dose and <b>build-up</b> <b>factor</b> calculations. Thus, it is very significant to choose accurate method to determine these parameters unambiguously. In the present study, effective atomic numbers and electron densities {{of different types of}} materials have been calculated by using a direct method and an interpolation method for total photon interaction in the energy region of 1 keV to 100 GeV. In addition, agreements and disagreements of the used methods have been discussed, and from the results, significant variations have been observed between the methods used to compute for the materials in the different energy regions...|$|E
40|$|Distributed ecohydrological {{modelling}} {{can provide}} a useful toot to evaluate the performance of irrigation systems at different spatial and temporal scales. Sirsa district, covering 4270 km(2) {{in the western part}} of Haryana State (India), has been selected for a case study with typical problems of canal water scarcity, poor groundwater quality, rising and declining groundwater levels, and sub-optimal, crop production. The field scale ecohydrological model SWAP including detailed crop growth simulations was extended in a distributed manner to quantify the required hydrological. and biophysical variables for all combinations of weather-crop-soil-irrigation in the study area. Field experiments, satellite images and existing geographical data were used to aggregate the representative input parameters of all so-called homogeneous simulation units' and their boundary conditions. The simulated mean annual evapotranspiration (689 mm) over the entire Sirsa district was 15 % lower as compared to the mean annual evapotranspiration (809 mm) estimated by independent remote sensing approach. The simulated water and salt limited crop yields showed a good correspondence with the independent crop yields data obtained from remote sensing, field measurements and statistical records. The performance of Sirsa district during the agricultural year 2001 - 2002 was evaluated in terms of water productivity, net groundwater recharge and salt <b>build-up.</b> <b>Factors</b> responsible for tow water productivity in Sirsa district include a high percentage of soil evaporation into evapotranspiration (17 - 54 %, highest for rice), percolation from fields and seepage losses from the conveyance system (34 - 43 % of the total canal inflow). The study also revealed a Large variation of net groundwater recharge and salt build-up over different canal commands, which threatens the sustainabitity of irrigated agriculture in Sirsa district. (c) 2006 Elsevier B. V. All rights reserved...|$|R
40|$|Thesis (M. Ing. (Mechanical Engineering)) [...] North-West University, Potchefstroom Campus, 2011. This study {{addresses}} the fatigue {{life of the}} head–to–skirt welds of tall distillation columns. Fatigue tests were done on two types of weld geometries which approximate the head–toskirt configurations. From the fatigue tests {{it was determined that}} the fatigue life of the experimental samples can be substantially improved by applying weld build–up between the head and the skirt. The expected fatigue life of the test samples was determined by way of calculation employing the so called Nominal–Stress–Approach, the Effective–Notch–Stress–Approach and the Stress–Life–Approach. For both the Nominal–Stress–Approach and the Effective–Notch–Stress–Approach the predicted fatigue life was found to be overly conservative compared to the experimental results. The Stress–Life–Approach predicted the fatigue life to within a factor of 1. 3 for both the geometries under investigation when displacements due to welding are taken into account. If displacements due to welding is omitted this factor is increased, for the geometry without weld build–up, to 2. For the geometry with weld <b>build–up</b> the <b>factor</b> remains 1. 3. Master...|$|R
40|$|International audience: We report {{applications}} of dynamic nuclear polarization to enhance proton and vanadium- 51 polarization of vanadyl sulfate samples doped with TOTAPOL under magic angle spinning conditions. The {{electron paramagnetic resonance}} response stemming from the paramagnetic (51) V species was monitored {{as a function of}} pH, which can be adjusted to improve the enhancement of the proton polarization. By means of cross-polarization from the proton bath, (51) V spins could be hyperpolarized. Enhancement <b>factors,</b> <b>build-up</b> times, and longitudinal relaxation times T 1 ((1) H) and T 1 ((51) V) were investigated as a function of pH. Copyright © 2014 John Wiley & Sons, Ltd...|$|R
40|$|Thesis (M. Sc. (Nuclear Engineering)) [...] North-West University, Potchefstroom Campus, 2008. MicroShield is a point-kernel {{computer}} code used for gamma-ray shielding and dose rate assessment. It allows the modeling of simple source geometries and simple shielding layouts {{which lead to}} very accurate results with low computer time consumption, compared with more advanced methods such as Monte Carlo transport code (e. g., MCNP), among others. The short computer time in finding solutions {{is due to a}} deterministic transport using analytic solutions for the direct source contribution (unscattered radiation) to the detector, and then corrected by a <b>build-up</b> <b>factor</b> appropriate for the geometry used in the calculation. On the other hand, Monte Carlo transport codes, such as MCNP, solve the detailed physics of the transport in the real geometry (calculating a <b>build-up</b> <b>factor</b> as a by-product); however, the set up of the geometry and the implementation of variance reduction techniques (always necessary in shielding problems) is complex and time consuming. Although the MicroShield software give good results for many 7 -ray shielding and dose rate calculations, there are still many unanswered questions about the behavior of MicroShield build-up factors and their limit of applicability when the line connecting source and detector is not parallel to the normal of the shielding, creating an angle a (offset from symmetry axis). The objective of this work is to compare similar shielding layouts using MicroShield and MCNP for typical shielding materials and typical energies of interest but explicitly assessing the incidence of the offset; in the results, and therefore determining a limit of applicability for MicroShield The build-UD factors used in the current model of MicroShield have shown to yield reasonable results in terms of the effective dose rates when compared with MCNP calculations. Using the maximum percentage error of 30 percent as recommended from MS manual, the limit of applicability of MS was determined at various materials thickness of lead, iron, and concrete. Master...|$|E
40|$|The {{effective}} {{linear attenuation}} coefficients and build-up factors for single shield of Al, Fe, Pb, and for multi-layer shield of Al-Pb, Al-Fe, Fe-Pb, Al-Fe-Pb {{as a function}} of shield thickness, atomic number, and order of the materials composing the shield are investigated for two photon energies of 0. 662 MeV and 1. 25 MeV. Two derived practical formulas to calculate the effective attenuation coefficient and <b>build-up</b> <b>factor</b> for multilayer shields are used. It is noticed that changing the order of the materials among the shield has no significant effect on the experimental result. Measurement agrees well with the trend of the suggested formulas for calculating the effective attenuation coefficient and the buildup factor. The linear attenuation coefficient is observed to have a strange dependency with the atomic number and photon energy. For single layer shield, the attenuation coefficient increases with decreasing atomic number at low photon energy and increasing with increasing atomic number at high photon energy...|$|E
40|$|Geometric {{progression}} (GP) {{method was}} utilized to investigate gamma-ray exposure build-up factors of fly-ash bricks for energies from 0. 015 to 15 [*]MeV up to 40 [*]mfp penetration depth. The EBFs of the fly-ash bricks are {{dependent upon the}} photon energy, penetration depths, and the chemical compositions of the elements. Appreciable variations in exposure <b>build-up</b> <b>factor</b> (EBF) are noted for the fly-ash bricks. The EBFs {{were found to be}} small in low and high photon energy regions whereas very large in medium energy region. EBF of the bricks is inversely proportional to equivalent atomic number below 10 [*]mfp for entire energy region of interest 0. 015 to 15 [*]MeV. The EBFs of fly-ash, brick of mud, and common brick were similar at 1. 5 [*]MeV photon energy. The EBF of the fly-ash bricks was found to be higher than that of the brick of mud, and common brick. The fast neutron removal cross sections of the fly-ash bricks, brick of mud, and common bricks were also calculated which were found {{to be in the same}} order. It is expected that this study should be very directly useful for shielding effectiveness of fly-ash brick materials and dose estimation...|$|E
40|$|Abstract. Inecosystems where fire {{occurrence}} has significant time-dependence, fire sequences should exhibit system-regulation that is distinguished by nonrandom (nonstationary), self-organizing patch dynamics related to spatially constrained fire probabilities. Exogenous {{factors such as}} fire weather, precipitation variability, and terrain alter the flammability of vegetation and encourage randomness in {{fire occurrence}} within pre-existing patch structure. In Californian chaparral, the roles of succession/fuel <b>build-up</b> and exogenous <b>factors</b> is examined {{by taking advantage of}} a 100 yr "natural experiment " in southern California (SCA) and northern Baja California, Mexico (BCA), where factors influencing fire occurrence have been systematically altered by divergent management systems. In SCA, suppression has been practiced since 1900...|$|R
40|$|In the {{chlorination}} {{process for}} TiO 2 pigment production, blends of titania feedstocks such as ilmenite, synthetic rutile (SR), natural rutile, upgraded slag, and chloride-grade slag are reacted with coke and chlorine at {{a temperature of}} around 1000 °C to form TiCl 4, which is the main product, and other waste metal chlorides. TiCl 4 is the main feed material for the TiO 2 pigment-making process. Feeding different titania materials to the chlorinator affects the amounts of coke and chlorine required for the process, {{the amount of waste}} generated, waste disposal costs, the amount of TiCl 4 produced, and bed <b>build-up</b> rates. These <b>factors</b> influence the value of the feedstock. Generally, a higher TiO 2 feedstock is more valued since less waste is generated and less reagents are consumed. To quantify the impact of different feedstocks on the chlorinator, a techno-economic model was developed to describe the chlorination process and estimate process variables at steady state. This paper describes the development of the model and studies in which the model has been used to quantify the effects of using different feedstocks. [URL]...|$|R
40|$|The goal of {{the thesis}} was to display {{landscape}} changes and some selected socioeconomic factors in the cadastral area of the Kvilda village. The changes were expertised {{on the basis of}} the stabil cadastral map from 1837 until the present - {{on the basis of the}} air photos which were taken in 1949, 1973 and 2008. The development of the changes was observed on agricultural areas, forest areas, freeways and in <b>build-up</b> areas. Socioeconomic <b>factors</b> were selected on the basis of the possibility to make a line of the continuity. The development of the number of population and the number of houses was chosen. Information was brought out from municipal chronicles and literary resources. Reasons of changes and outputs processed in graphs are presented in the practical part of the thesis. The function of the Šumava Mountains has been changed during last 100 years. After 1950, original mountain agriculture with mainly pastoral character and extensive stock raising completed by the work in the forest industry were changed into a partly closed area with the minor tourist industry...|$|R
40|$|An {{aluminium}} calorimeter {{was used}} to determine an absorbed 'dose in water' calibration factor for a thimble ionisation chamber for Co gamma radiation. Several distinct steps were involved in the calibration. An absorbed 'dose in aluminium' calibration factor for the chamber was measured to determine the effect of depth on this factor; this calibration factor {{was used to}} transfer experimentally the measured dose in aluminium to dose in a water phantom at depths of 5 cm and 7 cm for a range of field sizes. A <b>build-up</b> <b>factor</b> (to describe the radiation quality) in the water phantom was calculated as a function of depth and field size. Using these steps, an absorbed dose in water calibration factor for the thimble chamber was measured over a limited range of radiation quality. Two further experiments were made to test the overall calibration procedure. The dose in water measurements were used to determine the G-value for ferric ion production by irradiating ferrous sulphate dosimeters for two or three field sizes at depths of 5 and 7 cm respectively. The measured G-values were compared with those obtained by other workers using calorimetry. The long-term stability of the calorimeter was observed over a period of about 14 months, during which time no change was detected in the calorimeter...|$|E
40|$|The {{characteristics}} of a mobile metal oxide semiconductor field effect transistor (mobile MOSFET) detector for standard bias were investigated for megavoltage photon beams. This study was performed with a brass alloy build-up cap for three energies namely Co- 60, 6 and 15 MV photon beams. The MOSFETs were calibrated and the performance characteristics were analyzed with respect to dose rate dependence, energy dependence, field size dependence, linearity, <b>build-up</b> <b>factor,</b> and angular dependence for all the three energies. A linear dose-response curve was noted for Co- 60, 6 MV, and 15 MV photons. The calibration factors {{were found to be}} 1. 03, 1, and 0. 79 cGy/mV for Co- 60, 6 MV, and 15 MV photon energies, respectively. The calibration graph has been obtained to the dose up to 600 cGy, and the dose-response curve was found to be linear. The MOSFETs were found to be energy independent both for measurements performed at depth {{as well as on the}} surface with build-up. However, field size dependence was also analyzed for variable field sizes and found to be field size independent. Angular dependence was analyzed by keeping the MOSFET dosimeter in parallel and perpendicular orientation to the angle of incidence of the radiation with and without build-up on the surface of the phantom. The maximum variation for the three energies was found to be within ± 2 % for the gantry angles 90 ° and 270 °, the deviations without the build-up for the same gantry angles were found to be 6 %, 25 %, and 60 %, respectively. The MOSFET response was found to be independent of dose rate for all three energies. The dosimetric {{characteristics of}} the MOSFET detector make it a suitable in vivo dosimeter for megavoltage photon beams...|$|E
40|$|Field {{studies were}} {{conducted}} to arrest Phosphorus requirements of wheat, sorghum fodder and rice crops at 95 % relative yield; Phosphorus Fertility Buildup Factor (PFBF) and level of phosphorus buildup in a Typic Camborthid (Sultanpur series) soil of rice tract of the Punjab, Pakistan. Sorption isotherms were constructed in the laboratory and data fitted into linear form of modified Freundlich Model and doses were computed against soil solution P levels. Different theoretical P doses were applied {{in the field to}} develop soil solution P level of 0. 01, 0. 02, 0. 03, 0. 04, 0. 05, 0. 10, 0. 15, 0. 20, 0. 25, 0. 30, 0. 40 and 0. 50 mg LG 1 along with a control (native soil solution P). Phosphorus was also applied at the rate of 60 and 90 mg P 2 O 5 kgG 1 to subsequent sorghum fodder and rice crops, respectively. Wheat grain and straw, fresh sorghum fodder, rice paddy and straw yields were recorded at the harvest. Plant sampling was done at booting stage of wheat and rice and at the harvest of each crop. Soil sampling was also done at the harvest of each crop. The results indicated that maximum wheat grain yield was 4. 05 mg haG 1; sorghum fresh fodder yield was 43. 83 mg haG 1 and rice paddy yield was 4. 43 mg haG 1. Total P uptake by wheat, sorghum and rice was 22. 73, 37. 69 and 20. 48 kg haG 1, respectively. Mean phosphorus fertility <b>build-up</b> <b>factor</b> (mg P required to build 1 mg P kgG 1 soil) was 16. 23 and the level of P buildup (mg P kgG 1 built-up in soil for each mg P kgG 1 soil applied) was 0. 062. Level of P depletion was 0. 141 mg P kgG 1 for NPK check plots while 0. 162 mg P kgG 1 for P check plots. Internal P requirement for wheat was 0. 255 % at booting stage and 0. 281 % for grain stage. For sorghum fodder, internal P requirement was 0. 233 % and for rice, it was 0. 146 % at booting stage and 0. 266 % for paddy stage...|$|E
40|$|The mother’s {{personality}} is a <b>build-up</b> of demographic <b>factors</b> among which employment, marital status and educational level are prominent in shaping child’s abilities and aspirations. This study therefore, determines {{the influence of}} mothers’ employment, marital status and educational level on students’ academic achievement in Business studies. Ex-post facto survey design and stratified random sampling technique were adopted for the study. Structured Questionnaire (MEMSEL Scale, r=. 76) and Business Studies Achievement Test (r=. 80) with a section for demographic data were administered on a sample of Two Hundred and Fifty students from five (5) schools in Ijebu-Ode, Nigeria. Multiple regressionstatisticswas used for data analysisat 0. 05 level of significance. The findings revealed that{{there was a significant}} but negative relationship between mothers' marital status and academic achievement of student's (r=-. 195; p . 05); academic achievement and educational level (r =. 091; p >. 05); employment status and marital status (r = -. 033; p >. 05) and marital status and educational level (r =. 079; p >. 05). However there was a significant combined contribution on the independent variables on students' academic achievement in Business Studies (Adj. R=. 037; F(3, 237) = 4. 111;P <. 05). Thus, it was recommended that parents should provide positive home environments for their children, while school operators should respond favourably and focus attention on the children’s needs. ...|$|R
40|$|This study {{examines}} factors affecting the rate {{and extent of}} biomass build-up among commercially important groupers, snappers, grunts, parrotfish and surgeonfish in a network of four marine reserves in southwest St. Lucia, Caribbean. Reserves constituted 35 % of the total reef area originally available for fishing. Protection was instigated in 1995 after a baseline survey with annual or biennial censuses performed until 2002. Each survey consisted of 114 fifteen minute fish counts in reserves and 83 in fishing grounds, at depths of 5 m and 15 m in a 10 m diameter counting area. Estimates of number and size (cm) of target species were used to calculate fish family biomass. Data were analysed using three-way ANOVA in a before-after-control-impact pairs (BACIP) design. All families increased significantly in biomass over time at nearly all sites. Increases were greater in reserves than fishing grounds, except for grunts, and responses were strongest in parrotfish and surgeonfish. The combined biomass of families more than quadrupled in reserves and tripled in fishing grounds between 1995 and 2002. During this period coral cover declined by 46 % in reserves and 35 % in fishing grounds. Multiple regression showed that neither habitat characteristics nor habitat deterioration significantly affected rates of biomass <b>build-up.</b> The key <b>factor</b> was protection from fishing, which explained 44 % {{of the variance in}} biomass growth. A further 28 % of the variance was explained by sedimentation, a process known to stress reef invertebrates, significantly reducing the rate of biomass build-up. St. Lucia’s reserves succeeded in producing significant gains to fish stocks despite coral cover and structural complexity falling steeply over the period of the study...|$|R
40|$|Xenon {{calibrated}} Two Photon Absorption Laser Induced Fluorescence (TALIF) is used {{to measure}} absolute atomic oxygen concentrations in air, methane-air, and ethylene-air non-equilibrium plasmas, {{as a function of}} time after initiation of a single 25 nsec discharge pulse, and in burst mode, in which a sequence of 2 – 100 discharge pulses is initiated at 100 kHz. Peak O atom mole fraction in air, after a single pulse, is ~ 0. 4 x 10 - 4 at 60 torr, with decay occurring on a time scale of ~ 2 msec. Peak O atom mole fraction in a stoichiometric methane-air mixture is found to be approximately equal to that in pure air, but the rate of decay is found to be faster by a factor of approximately two to three. In Ф = 0. 5 ethylene-air, peak atomic oxygen concentration is reduced by a factor of approximately four, relative to air, and the rate of decay increased by approximately one order of magnitude due to much faster rate of reaction of atomic oxygen with ethylene, compared to methane, at room temperature. Burst mode measurements show very significant (up to ~ 0. 2 %) build-up of atomic oxygen density in air, and some <b>build-up</b> (by a <b>factor</b> of approximately three) in methane-air at Ф= 0. 5. Burst measurements in ethylene-air at Ф= 0. 5 show essentially no build-up, due to rapid O atom reactions with ethylene in the time interval between the pulses. Discharge modeling calculations, incorporating full air species kinetics complemented with GRI Mech 3. 0 hydrocarbon oxidation mechanism, are shown to provide good overall agreement with all the experimental data presented here. Reduced kinetic mechanisms are also identified, which provide additional insight into the key processes of O atom generation and decay...|$|R
40|$|Merging {{companies}} typically anticipate inventory reductions through pooling of inventory, higher {{purchasing power}} or elimination of planning uncertainties {{in a wider}} supply chain. In contrasts, companies appear to experience an inventory build-up in the quarters after an acquisition. This is the first attempt that I am aware of to develop an understanding for when, {{how and why the}} inventory build-up occurs. The research gap is addressed in this work with four research questions. (1) Does the phenomenon of inventory build-ups after mergers exist? (2) When does the inventory build-up occur and does it persist after the post-merger integration? (3) What happens in the post-merger integration and why does the inventory build-up occur? (4) Which companies are affected the most by the inventory build-up? Creating awareness and understanding of the inventory build-up is important because companies may take wrong assumptions when deciding on their next acquisition. The additional inventory position constitutes an implicit premium to the deal value. Unrealistic expectations in the inventory development can affect post-merger integration when companies focus on the wrong actions. Therefore, decision makers should have well founded reasons when they anticipate inventory reductions. The research gap is addressed in this work with four research questions, based on data comprising 926 U. S. mergers in the period 1978 - 2009. Financial data for four quarters before and eight quarters after the merger is retrieved from Standard & Poor's Compustat database. I compare average inventory levels before and after the merger to show a substantial increase in inventory levels. A more detailed analysis of quarterly inventory growth rates shows when the inventory build-up occurs. Inventory responsiveness is used as a measure that reflects inventory growth adjusted for revenue growth. For a sub-sample of 58 deals, I decompose inventory into raw material, work in progress and finished goods. I use a least square dummy variable regression to show which companies are likely to experience strong inventory build-up. The results of this study confirm that the inventory build-up exists. Mean inventory levels increase by $ 99. 4 million or 21. 6 % in the first year after the merger. The higher inventory levels are not reverted in the second year after the merger as mean inventory increases to 35. 3 % above pre-merger level. The inventory build-up happens in the first and second quarter after the merger when inventory growth rates peak at 7. 9 % and 6. 9 % respectively. Revenue growth can partially explain the inventory <b>build-up.</b> However, other <b>factors</b> including operational changes in supply and production play a role. Companies that typically experience high growth in inventory levels operate in high volume businesses and target smaller companies for acquisitions...|$|R

