23|37|Public
50|$|<b>Backup</b> <b>procedures</b> - The auditor should {{verify that}} the client has <b>backup</b> <b>procedures</b> {{in place in the}} case of system failure. Clients may {{maintain}} a backup data center at a separate location that allows them to instantaneously continue operations in the instance of system failure.|$|E
50|$|Corporate amnesia can be {{a result}} of {{sabotage}} by a disgruntled employee. If an employee is sacked, or is aggrieved for some other reason, he/she may seek revenge by deleting files from the company's computer. This risk can be minimised by effective <b>backup</b> <b>procedures.</b>|$|E
50|$|After {{a backup}} is completed, Iperius can {{send an e-mail}} {{containing}} the detailed report of the <b>backup</b> <b>procedures</b> (also through the secure SSL protocol), to keep the user informed about the backup result. It is possible to specify different e-mail recipients and different sending conditions (e.g. to send the e-mail depending on the backup result).|$|E
50|$|The {{technique}} tactile cold scissor metroplasty is a useful, safe, {{and effective}} <b>backup</b> <b>procedure</b> for hysteroscopic metroplasty.|$|R
50|$|AOL Desktop Software client {{facilitates}} backup of PFC files {{as part of}} Business Continuity Planning <b>procedure.</b> The <b>backup</b> <b>procedure</b> {{takes place}} when the application is in offline state. The PFC backup is stored at a user-defined location on the machine for restoration in case of loss of original PFC.|$|R
50|$|Before {{data are}} sent to their storage locations, they are selected, extracted, and manipulated. Many {{different}} techniques {{have been developed to}} optimize the <b>backup</b> <b>procedure.</b> These include optimizations for dealing with open files and live data sources as well as compression, encryption, and de-duplication, among others. Every backup scheme should include dry runs that validate the reliability of the data being backed up. It is important to recognize the limitations and human factors involved in any backup scheme.|$|R
50|$|Shadow IT data <b>backup</b> <b>procedures</b> {{may not be}} {{provided}} or audited. Personnel and contractors in Shadow IT operations may not be put through normal education, procedures or vetting processes. Originators of Shadow IT systems may leave the organization often leaving with proprietary data or leaving behind complicated systems the remainder of staff cannot manage.|$|E
5000|$|Generation Data Groups (GDGs) were {{originally}} designed to support grandfather-father-son <b>backup</b> <b>procedures</b> - if a file was modified, the changed version became the new [...] "son", the previous [...] "son" [...] became the [...] "father", the previous [...] "father" [...] became the [...] "grandfather" [...] and the previous [...] "grandfather" [...] was deleted. But one could set up GDGs {{with a lot more}} than 3 generations and some applications used GDGs to collect data from several sources and feed the information to one program - each collecting program created a new generation of the file and the final program read the whole group as a single sequential file (by not specifying a generation in the JCL).|$|E
5000|$|Johnson {{also helped}} to {{calculate}} the trajectory for the 1969 Apollo 11 flight to the Moon. During the moon landing, Johnson was {{at a meeting in}} the Pocono Mountains. She and a few others crowded around a small television screen watching the first steps on the moon. In 1970, Johnson worked on the Apollo 13 moon mission. When the mission was aborted, her work on <b>backup</b> <b>procedures</b> and charts helped set a safe path for the crew's return to Earth, creating a one-star observation system that would allow astronauts to determine their location with accuracy. In a 2010 interview, Johnson recalled, [...] "Everybody was concerned about them getting there. We were concerned about them getting back." [...] Later in her career, Johnson worked on the Space Shuttle program, the Earth Resources Satellite, and on plans for a mission to Mars.|$|E
5000|$|... #Caption: A Dataflow Diagram of <b>backup</b> and {{recovery}} <b>procedures</b> ...|$|R
5000|$|Determining the {{feasibility}} and compatibility of <b>backup</b> facilities and <b>procedures.</b>|$|R
30|$|A {{backup system}} is not {{provided}} within this system. Regular backup operation on database {{is supposed to be}} provided by the administrator separately. The advantage is that this system stores all necessary information such as synchronization tables and multimedia objects within the same database as particular Moodle database, thereby making it easier for the administrator to focus upon database backup instead of additional file system backup. In the case that Master LMS crashed, the Slave will consider as a new course has been in place. In order to avoid such condition, <b>backup</b> <b>procedure</b> should be taking care of synchronization tables beside of the current Moodle database.|$|R
40|$|A brief {{overview}} of some structural results that came from space station skunk works is presented. Detailed drawings of the pressurized modules, and primary truss structures such as deployable single fold beams, erectable beams and deployable double folds are given. Typical truss attachment devices and deployable <b>backup</b> <b>procedures</b> are also given...|$|E
40|$|The NRC/IMD PC Network Configuration Manual {{documents}} various Network configurations for the PC Network at the National Research Council, Institute for Marine Dynamics (NRC/IMD), St. John's, Newfoundland. This Manual {{is intended}} for Computer Systems operators, including full and part-time staff and students. The Manual concentrates on the functionalities of the IMD Network, including its layout, RAID array configurations, logon and <b>backup</b> <b>procedures,</b> and batch file documentation. Peer reviewed: NoNRC publication: Ye...|$|E
3000|$|... l[*]The {{download}} {{statistics are}} aggregated at calendar months. Due to different submission dates within months, the {{data can be}} quite noisy. Hence the first month downloads on average represent only 15 days of downloads. However, DID specification accounts for this. We also dropped observations with submission dates on December 2010 and January 2011 since search engines and/or <b>backup</b> <b>procedures</b> added exactly 20 downloads to all papers on the latter month. This January peak {{can be observed in}} all papers irrespective of the field or series.|$|E
40|$|We {{present a}} system which enables a user to remove a file from both the file system and all the backup tapes on which the file is stored. The ability to remove files from all backup tapes is {{desirable}} in many cases. Our system erases information from the backup tape without actually writing on the tape. This is achieved by applying cryptography in a new way: a block cipher is used to enable the system to "forget" information rather than protect it. Our system is easy to install and is transparent to the end user. Further, it introduces no slowdown in system performance and little slowdown in the <b>backup</b> <b>procedure...</b>|$|R
40|$|The {{introduction}} {{of the concept of}} sequential decoding by Wozencraft has opened up the possibility of more efficient decoding search procedures than those available with block codes. The {{purpose of this study is}} to improve the search procedures proposed by Pfeiffer and Lin. We show that under most error conditions it is not required to begin the search at the earliest segment in the br-unit indicated by the multiple threshold test. An improved estimate of the probability of correcting an error in a br-unit is given. A new <b>backup</b> <b>procedure</b> and a modified threshold for discard make possible a more efficient search for the best path...|$|R
50|$|The auditor can verify {{this through}} paper and {{paperless}} documentation and actual physical observation. Testing of the <b>backups</b> and <b>procedures</b> is also performed to confirm data integrity and effective processes. The {{security of the}} storage site is also confirmed.|$|R
40|$|SUMMARY. The INNOVACQ and Geac Acquisitions Systems {{have been}} {{successfully}} implemented in several large academic libraries. All basic requirements for a full-scale acquisitions system have been met by both systems. Size, as measured by number of orders placed or number of subscriptions maintained, magnifies the problems, deficiencies, and difficulties of any system. This paper focuses on {{significant differences between the}} two systems, particularly as they relate to large academic libraries. These areas include capacity, in-house control and environmental concerns, <b>backup</b> <b>procedures</b> and printing, command structure, record structure, integration versus interfacing, password security, serials control, invoicing and fund accounting, and management reports...|$|E
40|$|The {{upcoming}} {{pages of}} this bachelor paper {{are dedicated to}} the issue of data backup and data protection in the environment of a household. The first part is focused on theory and explanation of the basic concept of data protection and data backup. Those concepts include basic types of backup, media and forms of backup application. The second part aims for reviewing backup software and cloud storages by different criteria. Applications used in reviews will be running on the Windows 7 Home Premium operating system. At the end of the paper, there will be presented variations of <b>backup</b> <b>procedures</b> and possible economic savings achieved by data backup...|$|E
40|$|The rabies {{tissue culture}} {{infection}} test (RTCIT) and rapid rabies enzyme immunodiagnosis (RREID) {{were compared to}} the fluorescent-antibody test (FAT) with field specimens. At the French National Reference Center for Rabies, 15, 248 specimens were analyzed by FAT and RTCIT, and 2, 290 of those specimens were also tested by RREID; 818 other specimens were tested by FAT and RREID in 12 laboratories located in Africa, Asia, and Latin America. The sensitivities and specificities of RREID and RTCIT were comparable. This study showed that both tests {{can be used as}} <b>backup</b> <b>procedures</b> to confirm FAT. RREID is also strongly recommended for epidemiological studies and for laboratories which are not equipped for performing FAT...|$|E
40|$|Recently, {{the use of}} timeout rooms {{has been}} {{questioned}} by various agencies, and some have adopted policies that prohibit or greatly restrict exclusionary timeout. The present study developed a timeout procedure that did not require removal of the misbehaver from the learning environment. The procedure {{was applied to the}} disruptive behaviors of five severely retarded children in an institutional special-education classroom. An observer prompted all teacher behaviors related to the procedures to assure their precise implementation. After baseline, a reinforcement-only condition was implemented. Each child was given a different colored ribbon to wear as a tie and received edibles and praise every few minutes for good behavior and for wearing the ribbon. When timeout was added, a child's ribbon was removed for any instance of misbehavior and teacher attention and participation in activities ceased for three minutes or until the misbehavior stopped. Reinforcement continued at other times for appropriate behavior. An ABCBC reversal design was used to demonstrate control of the behavior by the conditions applied. On average, the children misbehaved 42 % and 32 % of the time during the baseline and reinforcement conditions respectively but only 6 % of the time during the timeout conditions. A followup probe during the new school year revealed that the teacher was able to conduct the procedure independently and that the children's disruptive behaviors were maintained at low levels. The practicality and acceptability of the procedure were supported further by the successful implementation of the procedure by a teacher in another state and by responses to a questionnaire given to 40 mental health professionals. The ribbon procedure appears to be a viable form of timeout, provided that disruptive behaviors during timeout can be tolerated within the setting, or a <b>backup</b> <b>procedure</b> such as exclusionary timeout can be tolerated within the setting, or a <b>backup</b> <b>procedure</b> such as exclusionary timeout is available when needed...|$|R
5000|$|Data <b>backup</b> and {{recovery}} <b>procedures</b> ensure data {{is stored in}} the right place {{so that it can be}} recovered promptly in crisis situations.|$|R
2500|$|Two {{issues with}} the orbiter's Ku antenna were noted by Cain, {{although}} he stated they would not impact the mission. The antenna was not handing over from Ku to S-band automatically as it should, which meant that teams on the ground had to manually switch the antenna from Ku to S Band and back again. [...] Sarafin noted that this was likely a software issue, and would not affect the crew on board, or the mission. The other issue {{had to do with}} the antenna's failure to [...] "lock on" [...] to satellite targets after being given the pointing data. Instead, the antenna was drifting, which meant that the teams on the ground would have to use an alternate method of pointing the antenna. There was a possibility that the shuttle crew would need to use a <b>backup</b> <b>procedure</b> during rendezvous with the station, but it was not a concern, and would not change the timeline, Cain noted.|$|R
40|$|The Internet {{has changed}} {{information}} handling and escalation of digital contents in recent years, but appropriate storage technology {{is needed for}} effective management of information which is critical to businesses today. The rapid growth of digital contents requires a technology that delivers high availability, scalability, and reliability. Storage Area Network (SAN) is one promising solution providing high speed data transfer with many other storage services, backboned with a high speed Fibre Channel (FC). SAN design and implementation requires careful analysis before SAN {{can be used as}} an enterprise storage solution. This research paper discuss information growth, information handling, and various storage technologies available today, in addition to financial justifications, <b>backup</b> <b>procedures,</b> disaster management and security measures. This paper also recommends an efficient design analysis considering various factors for SAN implementations to meet the customer demands of organizations...|$|E
40|$|A {{letter report}} {{issued by the}} Government Accountability Office with an {{abstract}} that begins "IRS implemented numerous controls and procedures intended to protect key financial and tax-processing systems; nevertheless, control weaknesses in these systems continue to jeopardize the confidentiality, integrity, and availability of the financial and sensitive taxpayer information processed by IRSs systems. Specifically, the agency continues to face challenges in controlling access to its information resources. For example, it had not always (1) implemented controls for identifying and authenticating users, such as requiring users to set new passwords after a prescribed period of time; (2) appropriately restricted access to certain servers; (3) ensured that sensitive data were encrypted when transmitted; (4) audited and monitored systems to ensure that unauthorized activities would be detected; or (5) ensured management validation of access to restricted areas. In addition, unpatched and outdated software exposed IRS to known vulnerabilities, and the agency had not enforced <b>backup</b> <b>procedures</b> for a key system. ...|$|E
40|$|Abstract. We {{describe}} {{a concept of}} mutual remote attestation for two identically configured trusted (TPM based) systems. We provide a cryp-tographic protocol to achieve the goal of deriving a common session key for two systems that have verified each other to be a clone of themselves. The mutual attestation {{can be applied to}} <b>backup</b> <b>procedures</b> without providing data access to administrators, i. e. one trusted systems exports its database to another identical trusted system via a secure channel after mutual attestation is completed. Another application is dynamically parallelizing trusted systems in order to increase the performance of a trusted server platform. We present details of our proposed architecture and show results from ex-tensive hardware tests. These tests show that there are some unresolved issues with TPM-BIOS settings currently distributed by PC hardware manufacturers since the specification regarding measurement of extended platform BIOS configuration is either not met or the usage of undocu-mented options is required...|$|E
40|$|This article {{presents}} {{a new version}} of the Gilbert-Johnson-Keerthi (GJK) algorithm that circumvents the shortcomings introduced by degenerate geometries. The original Johnson algorithm and <b>Backup</b> <b>procedure</b> are replaced by a distance subalgorithm that is faster and accurate to machine precision, thus guiding the GJK algorithm toward a shorter search path in less computing time. Numerical tests demonstrate that this effectively is a more robust procedure. In particular, when the objects are found in contact, the newly proposed subalgorithm runs from 15 % to 30 % times faster than the original one. The improved performance has a significant impact on various applications, such as real-time simulations and collision avoidance systems. Altogether, the main contributions made to the GJK algorithm are faster convergence rate and reduced computational time. These improvements may be easily added into existing implementations; furthermore, engineering applications that require solutions of distance queries to machine precision can now be tackled using the GJK algorithm...|$|R
40|$|Summary: A 26 -year-old woman {{sustained}} a traffic accident injury {{to her left}} medial malleolus. A soft-tissue defect 15 [*]×[*] 7 [*]cm with exposure of bone was found and underwent free anterolateral thigh flap to cover it. On the second postoperative day, venous congestion occurred and re-exploration was performed. Re-anastomosis of the vein was done after the thrombectomy; unfortunately, the flap did not recover. We found {{there was a good}} granulation bed under the failing flap and thinned the failing flap and used it as a full-thickness skin graft. The graft survived completely; 9 months later, the graft site was softer and of good texture. The patient can wear the same size shoes without a debulking procedure. The free flap provided nutrients to the raw surface and nurtured a good granulation bed while it survived for 50 hours; as a result, it was used as “the nutrient flap. ” Reuse of the failing free flap as “the nutrient flap” is useful as an alternative <b>backup</b> <b>procedure...</b>|$|R
5000|$|Two {{issues with}} the orbiters Ku antenna were noted by Cain, {{although}} he stated they would not impact the mission. The antenna was not handing over from Ku to S-band automatically as it should, which meant that teams on the ground had to manually switch the antenna from Ku to S Band and back again. [...] Sarafin noted that this was likely a software issue, and would not affect the crew on board, or the mission. The other issue {{had to do with}} the antennas failure to [...] "lock on" [...] to satellite targets after being given the pointing data. Instead, the antenna was drifting, which meant that the teams on the ground would have to use an alternate method of pointing the antenna. There was a possibility that the shuttle crew would need to use a <b>backup</b> <b>procedure</b> during rendezvous with the station, but it was not a concern, and would not change the timeline, Cain noted.|$|R
40|$|Disaster Recovery with General Parallel File System 2. 2 The {{ability to}} detect and quickly recover from a massive-scale {{hardware}} failure {{is of paramount importance}} to businesses that make use of real-time data processing systems. General Parallel File System (GPFS) provides a number of features that facilitate the implementation of highly-available GPFS environments capable of withstanding catastrophic hardware failures. By maintaining a redundant replica of the file system’s data at another (geographically separated) location, we allow the system to sustain its processing using the secondary replica of the data {{in the event of a}} total failure in the prime environment. In this paper, we present an overview of the disaster recovery features available in the 2. 2 release of GPFS and provide detailed hands-on guidance on implementing the various types of disaster-tolerant configurations supported in this release. Overview and terminology Businesses that depend on real-time data processing systems are vulnerable to a profound negative impact from natural or unnatural disasters such as fires, tornadoes, earthquakes, or power failures. A catastrophe can permanently disable the customer’s data processing infrastructure and, without proper <b>backup</b> <b>procedures,</b> result in a permanent loss of businesscritica...|$|E
40|$|Repair parts make up 92 {{percent of}} the total Army inventory. The number of Class IX items stocked in CONUS or pre-positioned in the theater affects supply {{elements}} and maintenance and aviation units. Maintenance units must be able to obtain supplies to support maintenance activities. Aviation units deliver supplies and aid in the movement of supply units. The number, type, and size of supply items to be moved determine the vehicles needed. AUTOMATED SUPPORT Class IX supply depends on ADP support. Each unit having a repair parts supply mission receives automated stock control support. In war, however, ADP systems are vulnerable to disruption, damage, and destruction. To ensure continued support, contingency or backup automated procedures have been developed for DS 4, SARSS, and SAILS. If automated support is not available in DS 4, item managers should follow manual <b>backup</b> <b>procedures</b> in TM 38 -L 32 - 13. Supply personnel should follow manual procedures in DA Pamphlets 710 - 2 - 1 and 710 - 2 - 2. Because an ADPE outage could result in a loss of records, the document control or stock control section should always maintain a backup of all transaction files and records. ZERO BALANCE Major weapons systems and end items of equipment can be classified as NMCS. Repair parts may not be available due to zero-balance conditions at a DSU or higher level of supply support...|$|E
40|$|Central bankers wish {{to ensure}} {{worldwide}} that large-value transfer systems, {{as a component}} of the key market infrastructure, exhibit sufficiently robust levels of operational resilience. We focus on the operational resilience of the Hungarian real time gross settlement system, known as VIBER. The goal of the research is the quantitative assessment of the ability of the system to withstand certain types of operational shocks. Systemically important participants are identified and it is argued that they overlap with endangered participants. An indicative list of participants who might be endangered by a liquidity shock is compiled by analysing proxies for liquidity risk. We shed light on the capacity of the system to function smoothly in the event of operational problems by simulating the technical default of one or two systemically important participants in VIBER. Altogether six plausible scenarios were formed, three entire-day incidents and three incidents involving less time (part-time incidents). The impact of behavioural reactions of technically non-defaulted participants and the application of existing <b>backup</b> <b>procedures</b> are also considered. The disturbance in the payment system was measured by the value of initially not submitted payments, the value of rejected payments, the total value of queued payments, the maximum queue value, the average queue length and the settlement delay. By means of gross and net liquidity deficit indicators, liquidity assistance required to settle all previously rejected transactions is calculated. By comparing the value of unsettled payments with the value of eligible collaterals in the banks' balance sheet, we can gain insight into whether the liquidity deficit can be financed through normal monetary policy operations...|$|E
40|$|This paper {{describes}} {{development of}} an optimal 3 D path planner with collision avoidance for a 9 DOF robot manipulator. The application of the robot manipulator will be on an unmanned oil platform {{where it will be}} used for inspection. Most of the time the robot manipulator will follow a pre-programmed collision-free path specified by an operator. Situations where it is desirable to move the end effector from the current position to a new position without specifying the path in advance might occur. To make this possible a 3 D path planner with collision avoidance is needed. The path planner presented in this paper is based on the well known Probabilistic Roadmap method (PRM). One of the main challenges using the PRM is to make a roadmap covering the entire collision free Configuration space, Cfree, and connect it into one connected component. It is shown by empirical testing that using a combination of the Bridge Sampling technique and a simple Random sampling technique gives best Coverage of the Cfree space and highest Connectivity in the roadmap for the given environment. An algorithm that increases the Connectivity and sometimes provide Maximal Connection is also described. A <b>backup</b> <b>procedure</b> that can be executed on-line if a query fails is also presented. The <b>backup</b> <b>procedure</b> is slow, but it increases the chances of succeeding a query if the goal is in a difficult area. It is also investigated if the coverage and connectivity can be further improved by using the potential field planner when connecting the waypoints. Empirical testing showed that the improvements of Coverage and Connectivity were limited and the sampling and query time increased. The query time for a roadmap containing 400 nodes and one containing 1000 nodes was compared. It turned out that a large roadmap did not necessarily affect the query time negative because it made it easier to connect the start and goal nodes. Three existing path smoothing algorithms and a new algorithm, called Deterministic Shortcut, were implemented and tested. Empirical testing showed that the Deterministic Shortcut algorithm outperformed the others when it came to path smoothing versus time. </p...|$|R
40|$|A high-harmonic rf {{system is}} going to be {{installed}} in both rings of the DAΦNE Φ-Factory collider to improve the Touschek lifetime. The main goal {{of this paper is to}} study the impact of the 3 rd harmonic cavity on beam dynamics making a special emphasis on the dynamics of a bunch train with a gap. The shift of the coherent synchrotron frequencies of the coupled-bunch modes has been estimated. In the following we investigated the effect of magnification of the synchrotron phase spread and beam spectrum variation due to the gap. Besides we simulated the bunch lengthening for different bunches along the unevenly filled train and evaluated the Touschek lifetime enhancement taking into account the obtained bunch distributions. Finally, the “cavity parking” option is discussed. It can be considered as a reliable <b>backup</b> <b>procedure</b> consisting of tuning the cavity away from the 3 rd harmonic frequency and in between two revolution harmonics. It allows recovering, approximately, the same operating conditions as were before the harmonic cavity installation...|$|R
40|$|The {{purpose of}} this study is to {{determine}} the scope of substantive test in order to audit sales cycle. With using descriptive analytical method, this research come up to conclusion that the company has implemented a satisfied general control and application control. The company has applied all components that will increase control in sales cycle by using software accurate version 3, such as keeping up IT administration, developing system, segregation of IT function, secure control for safeguarding assets and on line, <b>backup</b> <b>procedure.</b> For application control, the company has applied control like validation test for input such as field check, sign check, size check,completeness check and prenumbered document has used in sales cycle. Especially for sales oreder, the cashier have to sign three copies to reach good control. Substantive test of transaction determined by the result of evaluation of General controls and application controls that resulted in satistfying controls, so then audit nature can use test of control, audit timing is interim, and the evidence extent will be smaller as possibl...|$|R
