16|15|Public
40|$|<b>Blind</b> <b>decoding</b> {{of control}} {{information}} {{is used in}} some wireless  multiple access systems such as LTE to achieve adaptive modulation  and coding, {{as well as to}} address the multiple access problem on the  control channel. <b>Blind</b> <b>decoding</b> incurs high computational complexity in mobile terminals. In this paper, we describe a scheme to reduce  the computational complexity associated with the <b>blind</b> <b>decoding.</b> The  main idea is to broadcast a "please-decode-blindly" message to all  terminals that are eligible for scheduling, to instruct a subset of  the terminals to perform the blind search. We propose two schemes to  implement our idea and we investigate their performances via system  simulations...|$|E
40|$|<b>Blind</b> <b>decoding,</b> used on control {{channels}} of some multi-user wireless  access systems, {{is a technique}} for achieving adaptive modulation and  coding. The idea is to adapt the modulation and coding scheme to the  channel quality but instead of signaling the parameters used  explicitly, the receiver blindly tries a number of fixed parameter  combinations until a successful decoding attempt is detected, with  {{the help of a}} cyclic redundancy check. In this paper we suggest a  new method for reducing the complexity and energy consumption  associated with such <b>blind</b> <b>decoding</b> schemes. Our idea is to use a  mini-CRC injected early in the data stream to determine if the  current decoding attempt is using the correct modulation and coding  parameters. We analyze and exemplify the complexity gain of this  approach and also investigate the impact of the rearrangement of the  CRC scheme in terms of the probability of undetected error. The  presented results for the complexity gain are promising and the  impact on the error detection capability turns out to be small if  any...|$|E
40|$|In this paper, a new second-order {{statistics}} (SOS) based {{method for}} <b>blind</b> <b>decoding</b> of orthogonal space time block coded (OSTBC) systems {{with only one}} receive antenna is proposed. To avoid the inherent ambiguities of this problem, the spatial correlation matrix of the source signals must be non-white and known at the receiver. In practice, this {{can be achieved by}} a number of simple linear precoding techniques at the transmitter side. More specifically, it is shown in the paper that if the source correlation matrix has different eigenvalues, then the decoding process can be formulated as the problem of maximizing the sum of a set of weighted variances of the signal estimates. Exploiting the special structure of OSTBCs, this problem can be reduced to a principal component analysis (PCA) problem, which allows us to derive computationally efficient batch and adaptive <b>blind</b> <b>decoding</b> algorithms. The algorithm works for any OSTBC (including the popular Alamouti code) with a single receive antenna. Some simulation results are presented to demonstrate the potential of the proposed procedure. 1...|$|E
3000|$|... [...]) {{were used}} to carry the watermark. Daubechies 9 / 7 wavelets were used {{because they have been}} adopted by the FBI as part of the WSQ {{compression}} standard for fingerprint images [36]. In all experiments, a <b>blind</b> watermark <b>decoding</b> is used so that the parameters [...]...|$|R
40|$|Abstract—We {{propose a}} new {{paradigm}} for <b>blind</b> watermark <b>decoding</b> {{in the presence of}} desynchronization attacks. Employing Forney-style factor graphs to model the watermarking system, we cast the <b>blind</b> watermark <b>decoding</b> problem as a probabilistic inference problem on a graph, and solve it via message-passing. We study a wide range of moderate to strong attacks including scaling, amplitude modulation, fractional shift, arbitrary linear and shift-invariant filtering, and blockwise filtering, and show that the graph-based iterative decoders perform almost as well as if they had exact knowledge of the desynchronization attack parameters. Other desirable features of the graph-based decoders include the flexibility to adapt to other types of attacks and the ability to cope with the “curse of dimensionality ” problem that seemingly results when the desynchronization parameter space has high dimensionality. These properties are unlike most blind watermark decoders proposed to date. Index Terms—Blind watermark decoding, data hiding, desyn-chronization attacks, Forney factor graphs, graphicalmodels, joint estimator-detector, Markov random fields, message passing, quan-tization index modulation (QIM). I...|$|R
40|$|Distortion-Compensated Dither Modulation (DC-DM) {{has been}} {{theoretically}} {{shown to be}} a near-capacity achieving data hiding method, thanks to its use of side information at the encoder. In practice, channel coding is needed to approach its achievable rate limit. However, the most powerful coding methods, such as turbo coding, require knowledge of the channel model. We investigate here the possibility of undertaking <b>blind</b> iterative <b>decoding</b> of DC-DM. To this end, we undertake maximum likelihood estimation of the channel model, intertwining the Expectation-Maximization algorithm within the decoding procedure. 1...|$|R
40|$|This paperproposes {{a method}} to hide {{information}} into imagcs that achieves robustness against printing and scanning with <b>blind</b> <b>decoding.</b> A significant conlrihution {{of this paper is}} a technique to estimate and undo rotation. The method is {{based on the fact that}} laser printers use an ordered digital halftoning algorithm for printing. Using the proposed hiding mcthod, several hundred infurmation hits can be embedded inlo 512 x 512 images with perfect recovery against the print-scan opcration. Moreover. the hidden images also survive other attacks such as Gaussian or median titcring, scaling or aspat ratio changc. heavy JPEC compression, and rows andlor columns removal. 1...|$|E
40|$|Prior to the {{transmission}} of payload data in any multiple access system, there is generally a need to send control information such as scheduling assignments, transmission parameters and HARQ acknowledgments. This process is called control signaling and has {{a significant impact on}} the overall system performance. This dissertation considers different aspects of control signaling and proposes some novel schemes for improving it. The dissertation is split into two parts where in the first part the focus is on {{the transmission}} of scheduling assignments, and in the second part the focus is on improving the “blind decoding” process that is used to achieve adaptive coding and modulation in transmission of control information. More specifically, in the first part of the dissertation we first compare the two conventional schemes for control signaling using extensive system simulations. In doing so, we use practical assumptions on the scheduling algorithm as well as on the compression and transmission of the scheduling information. We then provide two schemes for reducing the amount of control signaling that concerns {{the transmission of}} scheduling assignments. The first scheme, which is reminiscent of source coding with side information, uses the knowledge that each user has about its own channel condition to compress the scheduling information more effectively. The second scheme uses the fact that in wireless multiple access systems, a user with a given channel condition can in principle decode the data intended to the users that have weaker channels. Therefore, the idea is to send the scheduling information of different terminals in a differential manner starting from the user with the weakest channel and letting all the terminals overhear the transmission of one another. Finally, in the last section of this part we use some of the recent results in information theory to form a general framework for the comparison of different control signaling schemes. We formulate an optimization problem that for a given desired error probability finds the minimum required number of channel uses for a given signaling scheme. In the second part of the thesis, we propose three schemes for reducing the complexity of the <b>blind</b> <b>decoding</b> process. The first one is a novel scheme for fast blind identification of channel codes. More precisely, we propose an efficient algorithm that for a given sequence of received symbols and a given linear channel code, finds the posterior probability that all the parity check relations of the code aresatisfied. We then use this quantity to perform a sequential statistical hypotheses test that reduces the computational complexity of <b>blind</b> <b>decoding.</b> The idea in the second scheme is to broadcast a control message prior to the transmission of control information to instruct only a subset of the terminals (ideally only those terminals that have been scheduled for reception of payload data and hence benefit from performing a blind search attempt) to perform blind search decoding, which can be used for instance in LTE to reduce the complexity of the <b>blind</b> <b>decoding</b> process. Finally, in the third scheme we propose to split the CRC, used by the terminals to find their control information, into two parts and inject one part early in the control data stream so that the terminals can detect early if the current decoding attempt will be successful, which ultimately reduces the <b>blind</b> <b>decoding</b> complexity...|$|E
40|$|International audienceIn this paper, {{we present}} new space-time {{multiplexing}} codes (STMC) for multiple-antenna transmissions, which {{rely on a}} three-dimensional tensor modeling of the transmitted/received signals. The proposed codes combine spatial multiplexing and space-time coding by spreading a linear combination of different sub-streams of data over the space and time dimensions. We show the STMC induces a tensor structure on the transmitted/received signal that can be modeled using a trilinear tensor decomposition. Tensor modeling is exploited at the receiver for a <b>blind</b> <b>decoding</b> of the transmitted sub-streams based on linear processing and without any ambiguity. The proposed approach also provides full diversity while benefiting from the maximum multiplexing gain offered by the multiple antennas. Simulation {{results show that the}} tensor-based STMC offer remarkable performance with good diversity-multiplexing trade-of...|$|E
40|$|The device {{described}} in this paper measures the spatial coordinates of the fingers of <b>blind</b> readers <b>decoding</b> texts written in braille. A light-emitting diode is fixed onto {{each of the two}} reading fingers, and a television camera with a MOS pickup device delivers a signal from which is extracted the information required to deduce the vertical and horizontal coordinates of the fingers. The results of these measurements appear as eight-digit binary numbers available for real-time computer data processing. © 1985 Psychonomic Society, Inc. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|A {{receiver}} receives {{information from}} a physical broadcast channel signal, wherein the receiver includes a <b>blind</b> processing and <b>decoding</b> unit that utilizes a hypothesis about how many transmit antennas were used to transmit the signal. Received signal characteristics are detected that indicate how many transmit antennas were used. Each transmit antenna hypothesis in a stored list represents how many transmit antennas were used. For each of the stored hypotheses, a probability value is determined based, at least in part, on the detected signal characteristics. The list of hypotheses is modified to associate the probability values with respective ones of the transmit antenna hypotheses.; The modified list is used to provide antenna hypothesis probabilities, and the <b>blind</b> processing and <b>decoding</b> unit is operated such {{it begins with a}} most probable antenna hypothesis and continues with increasingly less probable antenna hypotheses until successful decoding occurs or all antenna hypotheses have been made...|$|R
40|$|In this thesis, we {{look closely}} at two {{fundamental}} problems that arise {{within the context of}} multimedia <b>blind</b> watermark <b>decoding</b> and timing channels steganalysis. The central problem considered, loosely speaking, is that of implementing optimal (or near-optimal) strategies at the receiver, which is typically tasked to perform reliable decoding or detection, depending on the application at hand, in the presence of numerous unavoidable statistical uncertainties that are rather unique to the problem setup. A typical question we will be asking is, ???Can we perform reliable decoding of hidden data in spite of the presence of unknown channel parameters???? or ???How best can we detect presence of hidden data with unknown, and rather arbitrary, host and observation statistics???? While such questions are naturally relevant from a practical viewpoint, we draw additional inspiration for our study from profound theoretical insights arising from our recent research. As our solution to the first problem, we propose a new paradigm for <b>blind</b> watermark <b>decoding</b> in the presence of various signal distortion operations. Employing Forney-style factor graphs to model the watermarking system, we cast the <b>blind</b> watermark <b>decoding</b> problem as a probabilistic inference problem on a graph, and solve it via messagepassing. We study a wide range of moderate to strong distortions including scaling, amplitude modulation, fractional shift, arbitrary linear and shift invariant (LSI) filtering, and blockwise filtering, and show that the graph-based iterative decoders perform almost as well as if they had exact knowledge of the distortion channel parameters. Other desirable features of the graph-based decoders include the flexibility to adapt to other types of distortions and the ability to cope with the ???curse of dimensionality??? problem that seemingly results when the distortion channel parameters??? space has high dimensionality. These properties are unlike most blind watermark decoders proposed to date, and close an important computational gap in favor of deploying joint estimation-decoding strategies (shown to be theoretically optimal in our earlier work) to cope with common signal distortions. For the second problem, we propose new tools for steganalysis of queuebased stegocodes over covert timing channels. We propose a universal estimator for the Kullback-Leibler (KL) divergence-rate between the covertext process and the stegotext process. We empirically illustrate the performance of our estimator on some simple queue-based stegocodes and study its convergence properties...|$|R
40|$|This paper {{introduces}} {{an audio}} watermark (WM) decoding scheme that performs a Support Vector Machine (SVM) based supervised learning {{followed by a}} <b>blind</b> <b>decoding.</b> The decoding process is modelled as a two-class classification procedure. Initially, wavelet decomposition is performed on the training audio signals, and the decomposed audio frames watermarked with + 1 and- 1 constitute the training sets for Class 1 and Class 2, respectively. The developed system enables to extract embedded WM data at lower than- 40 dB Watermark-to-Signal-Ratio (WSR) levels with more than 95 % accuracy and it is robust to degradations including audio compression (MP 3, AAC), and additive noise. It is shown that the proposed audio WM decoder eliminates the drawbacks of correlation-based methods. 1...|$|E
40|$|From {{its first}} appearance, {{wireless}} communications has changed thelife {{for many people}} worldwide. Currently, {{more than half of}} the world's population are using wireless devices for various purposes on a daily basis. While the early wireless systems could provide simple and specific low-rate services, today's systems can support a variety of more advanced services some of which require high data rate communications. This includes for example web-browsing and streaming multimedia applications. To meet the high demands on the current systems, many technical solutions have been proposed. Many of these solutions are powerful in the sense of boosting the system performance, but on the other hand, they impose a substantial control signaling overhead on the system. The control signaling refers to sending the control information that is necessary to establish and/or maintain the connection as opposed to the payload data that is transmitted during the connection. In this thesis, we are interested in evaluating the relations between the gain of deploying new techniques and the amount of control signaling overhead they incur. Moreover we are interested in finding efficient algorithms that can potentially reduce the control signaling overhead. More specifically, we first focus on the part of the control signaling overhead that concerns sending the scheduling assignments that describe how the channel resources are allocated among the users. We compare two ways for the signaling of scheduling assignments and we will study how different parameters such as scheduling granularity impact the control signaling overhead. We also provide two schemes that reduce the control signaling overhead substantially. We then provide an algorithm for fast blind identification of channel codes. This algorithm is very useful in improving the so-called <b>blind</b> <b>decoding</b> performance. This is essential since <b>blind</b> <b>decoding</b> is used to achieve adaptive modulation and coding in the control channel of some of the wireless communication systems such as 3 GPP Long Term Evolution...|$|E
40|$|International audienceIn this paper, {{we propose}} two <b>blind</b> <b>decoding</b> {{approaches}} for multi-input single-output (MISO) communication systems. We first introduce a nonlinear precoding scheme that allows viewing the received signal as a Volterra-like model {{with the following}} properties: the input solely depends on the coding sequence, assumed to be known to the receiver, while the kernel is a multiway array depending on informative data and on the channel parameters. We show that such a kernel admits a PARAFAC tensor model. After estimating the kernel by using the coding sequence, the data symbols are then recovered. For this purpose, two methods are proposed. The first one directly computes the PARAFAC loading factors {{by means of an}} alternating least squares method. The second one solves the problem by means of a joint diagonalization of matrices constructed with the slices of the tensor. The performance of the proposed methods is evaluated by means of simulations...|$|E
40|$|In this paper, we {{consider}} efficient blind decoder design for orthogonal space-time block codes (OSTBCs). A general decision rule for <b>blind</b> OSTBC <b>decoding</b> is derived assuming a quasi-static flat multiple-input multiple-output (MIMO) Rayleigh fading channel. We use the linear dispersion representation of OSTBCs to derive a blind decoder {{that results in}} a quadratic minimization problem, which can be solved efficiently by semidefinite relaxation, sphere decoding or successive interference cancellation. To resolve phase ambiguity problems inherent in blind detectors, rather than using pilot symbols that results in a bandwidth loss, we propose novel totally blind decoders using dual constellations or a superimposed training scheme. To alleviate the computational burden, a minimum mean-squareerror (MMSE) channel estimator is also proposed to track the time-varying channel without using the blind decoder...|$|R
40|$|International audienceWe {{present a}} joint channel {{estimation}} and decoding method for space-time trellis codes (STTC) transmitted over an unknown flat fading multiple-input multiple-output (MIMO) channel. In a blind context, i. e. when pilot symbols are not available, {{we will show}} that the probability density function (pdf) of the MIMO channel becomes multimodal due to phase ambiguities. To address this problem, a combined state-space model for the time-varying MIMO channel and the STTC is introduced. The proposed algorithm then uses a Gaussian mixture approach to perform joint channel estimation and soft-output detection. We compare our method to several well known algorithms obtained by collapsing the Gaussian mixture to a single Gaussian distribution. A comparison with sequential Monte Carlo methods is also included. Numerical simulations show that the performances of the proposed blind STTC decoder are close to decoding with perfect channel state information (CSI). As a useful application of the proposed soft-output algorithm, we provide an example of <b>blind</b> iterative <b>decoding</b> of concatenated space-time codes...|$|R
40|$|Digital image {{watermarking}} is {{the process}} of encoding information into a digital image without deteriorating the visual quality of the image. Digital watermarking techniques are designed to withstand various attacks such as standard image processing operations, compression and geometric transformations. In this report we focus on watermarking of printed images and argue that this application requires specialized methods. Previous work relating to hardcopy watermarking applied standard digital watermarking schemes or suggested techniques that exploit the specific printing (i. e. halftoning) process. This work proposes a novel transform domain hardcopy watermarking technique that is independent of the halftoning process and is rather based on a noise model for the printing and scanning operations. The proposed scheme allows for <b>blind</b> watermark <b>decoding,</b> i. e. the encoder does not know the original image. It is image adaptable, to enhance the visual quality, and is tuneable on the trade-off between information embedding, rate, and visual quality...|$|R
40|$|In this paper, {{we propose}} a {{solution}} for implementing an asymmetric fingerprinting protocol within a client-side embedding distribution framework. The scheme is based on two novel client-side embedding techniques {{that are able to}} reliably transmit a binary fingerprint. The first one relies on standard spread-spectrum like client-side embedding, while the second one is based on an innovative client-side informed embedding technique. The proposed techniques enable secure distribution of personalized decryption keys containing the Buyer's fingerprint by means of existing asymmetric protocols, without using a trusted third party. Simulation results show that the fingerprint can be reliably recovered by using either non-blind decoding with standard embedding or <b>blind</b> <b>decoding</b> with informed embedding, and in both cases it is robust with respect to common attacks. To the best of our knowledge, the proposed scheme is the first solution addressing asymmetric fingerprinting within a clientside framework, representing a valid solution to both customer's rights and scalability issues in multimedia content distributio...|$|E
40|$|Abstract- We {{present a}} blind data hiding method for JPEG {{compressed}} images which minimizes the perceptual distortion due to data embedding. The proposed system presents {{a number of}} op. tions to the encoder to cast the given hidden bits in the compressed content signal. The perceptual distortion cost of each option is cal-culated from the parameters available to the encoder such as the original image, quantization error due to compression and the Just Noticeable Distortion (JND) levels of the original image derived through an empirical human visual system model. The encoder selects the option with the minimum Jh’D cost to cast the hidden hits. By the definition of <b>blind</b> <b>decoding,</b> the decoder {{should be able to}} extract the hidden bits without any side information on the option selected or the parameters available to the encoder. The decoder of the proposed system uses simple binary addition on the received transform coefficients to extract the hidden bits blindly. System performance is examined by computer experiments at dif-ferent compression levels and at different embedding bitrates. I...|$|E
40|$|This paper {{presents}} a <b>blind</b> <b>decoding</b> watermarking scheme that {{takes advantage of}} two basic properties of the Fourier transform: The image information is transformed into frequency bands centered around {{the origin of the}} coordinate system and the image information, the latter beeing independent from shifts in the original image. (i. e. pixel domain). These properties are exploited to embed a watermark that is inherently robust against translation an rotation in the pixel domain and shows considerable robustness against cropping and scaling as well. The amplitude part of the Fourier representation of the image is divided into rings, and each ring is subdivided into sections. A pair of sections is used to embed one bit of watermark information with the bit value being represented´by a predifined difference between the mean power values of the sections. The playload of the presented watermarking scheme strongly depends {{on the size of the}} image. Tests based on a leightweights implementation of the presented scheme were run with a watermark playload of 16 bits for an image of 512 by 512 pixels...|$|E
30|$|This article investigates {{efficient}} <b>blind</b> watermark <b>decoding</b> {{approaches for}} hidden messages embedded into host images, {{within the framework}} of additive spread spectrum (SS) embedding based for data hiding. We study SS embedding in both the discrete cosine transform and the discrete Fourier transform (DFT) domains. The contributions of this article are multiple-fold: first, we show that the conventional SS scheme could not be applied directly into the magnitudes of the DFT, and thus we present a modified SS scheme and the optimal maximum likelihood (ML) decoder based on the Weibull distribution is derived. Secondly, we investigate the improved spread spectrum (ISS) embedding, an improved technique of the traditional additive SS, and propose the modified ISS scheme for information hiding in the magnitudes of the DFT coefficients and the optimal ML decoders for ISS embedding are derived. We also provide thorough theoretical error probability analysis for the aforementioned decoders. Thirdly, sub-optimal decoders, including local optimum decoder (LOD), generalized maximum likelihood (GML) decoder, and linear minimum mean square error (LMMSE) decoder, are investigated to reduce the required prior information at the receiver side, and their theoretical decoding performances are derived. Based on decoding performances and the required prior information for decoding, we discuss the preferred host domain and the preferred decoder for additive SS-based data hiding under different situations. Extensive simulations are conducted to illustrate the decoding performances of the presented decoders.|$|R
40|$|Setting: Madras, India. Objective: To {{explore the}} utility of a {{standardized}} IS 6110 /PvuII deoxyribonucleic acid (DNA) fingerprinting {{restriction fragment length polymorphism}} (RFLP) typing method for distinguishing between isolates of Mycobacterium tuberculosis, and to assess the potential for distinguishing between relapse versus reinfection rates. Design: To assess RFLP heterogeneity in the population, initial isolates, obtained from the sputum of tuberculous 98 patients on diagnosis and follow-up during short-course chemotherapy, were stored and compared. To assess the frequency of disparity between the RFLP type of the initial isolate and one obtained after successful completion of chemotherapy, either during relapse or as an isolated positive culture, 124 isolates comprising 62 such pairs were coded and compared both <b>blind</b> and after <b>decoding.</b> Results: Although a wide variety of DNA band patterns (fingerprints) was present, the isolates from 39 (40...|$|R
40|$|In {{cases in}} which an {{original}} image is <b>blind,</b> a <b>decoding</b> method where both the image and the messages can be estimated simultaneously is desirable. We propose a spread spectrum watermarking model with image restoration based on Bayes estimation. We therefore need to assume some prior probabilities. The probability for estimating the messages is given by the uniform distribution, and the ones for the image are given by the infinite range model and 2 D Ising model. Any attacks from unauthorized users can be represented by channel models. We can obtain the estimated messages and image by maximizing the posterior probability. We analyzed {{the performance of the}} proposed method by the replica method {{in the case of the}} infinite range model. We first calculated the theoretical values of the bit error rate from obtained saddle point equations and then verified them by computer simulations. For this purpose, we assumed that the image is binary and is generated from a given prior probability. We also assume that attacks can be represented by the Gaussian channel. The computer simulation retults agreed with the theoretical values. In the case of prior probability given by the 2 D Ising model, we evaluated the decoding performance by computer simulations since the replica theory could not be applied. Results using the 2 D Ising model showed that the proposed method with image restoration is as effective as the infinite range model for decoding messages. We compared the performances in a case in which the image was blind and one in which it was informed. The difference between these cases was small as long as the embedding and attack rates were small. This demonstrates that the proposed method with simultaneous estimation is effective as a watermarking decoder...|$|R
40|$|International audienceA new multi-antenna coding {{framework}} is proposed for space-time-frequency (STF) transmissions over broadband {{multiple input multiple output}} (MIMO) systems based on orthogonal frequency division multiplexing (OFDM). A tensor decomposition known as PARAFAC {{is used as}} the core of a multi- stream space-time-frequency coder that jointly multiplex and spreads several input streams over space (transmit antennas), time (symbol periods) and frequency (subcarriers). We coin the term trilinear STF codes since each input symbol is coded over a space-time-frequency grid by a triple product code: each trilinearly coded symbol is interpreted as an element of a third-order tensor, which can be decomposed using PAFAFAC analysis. Trilinear STF codes are designed for an arbitrary number of transmit and receive antennas. They afford a variable degree of multiplexing-spreading over each one of the three signal dimensions while providing full diversity gain for each multiplexed stream. At the receiver, a direct <b>blind</b> <b>decoding</b> based on a relatively simple linear processing is made possible thanks to the PARAFAC modeling of the received signal. Computer simulation results are provided for performance assessment of the proposed codes in a variety of configurations...|$|E
40|$|Abstract—Print-scan {{resilient}} {{data hiding}} finds important applications in document security and image copyright protection. This paper proposes methods to hide information into images that achieve robustness against printing and scanning with <b>blind</b> <b>decoding.</b> The selective embedding in low frequencies scheme hides {{information in the}} magnitude of selected low-frequency discrete Fourier transform coefficients. The differential quantization index modulation scheme embeds information in the phase spectrum of images by quantizing the difference in phase of adjacent frequency locations. A significant contribution {{of this paper is}} analytical and experimental modeling of the print-scan process, which forms the basis of the proposed embedding schemes. A novel approach for estimating the rotation undergone by the image during the scanning process is also proposed, which specifically exploits the knowledge of the digital halftoning scheme employed by the printer. Using the proposed methods, several hundred information bits can be embedded into images with perfect recovery against the print-scan operation. Moreover, the hidden images also survive several other attacks, such as Gaussian or median filtering, scaling or aspect ratio change, heavy JPEG compression, and rows and/or columns removal. Index Terms—Copyright protection, data hiding, digital watermarking, document authentication, print-scan modeling. I...|$|E
40|$|We {{present a}} fast {{algorithm}} that, {{for a given}} input sequence and a linear channel code, computes the syndrome posterior probability (SPP) of the code, i. e., the probability that all parity check relations of the code are satisfied. According to this algorithm, the SPP can be computed blindly, i. e., given the soft information on a received sequence we can compute the SPP for the code without first decoding the bits. We show that the proposed scheme is efficient by investigating its computational complexity. We then consider two scenarios where our proposed SPP algorithm can be used. The first scenario is when {{we are interested in}} finding out whether a certain code was used to encode a data stream. We formulate a statistical hypothesis test and we investigate its performance. We also compare the performance of our scheme with that of an existing scheme. The second scenario deals with how we can use the algorithm for reducing the computational complexity of <b>blind</b> <b>decoding</b> process, the process that, for instance, is used by terminals in LTE for detection of control information. We propose a heuristic sequential statistical hypotheses test to use the fact that in real applications, the data arrives sequentially, and we investigate its performance using system simulations. On the day of the defence date the status of this article was Manuscript. </p...|$|E
30|$|In {{addition}} to the standard CSMA/CA, we compare the results with those of a multipacket reception protocol described in [4]. In [4] and [16] the authors have proposed a multipacket reception (MPR) protocol and investigated its performance for various types of networks and parameters. In [4], uplink transmissions in an infrastructure network are considered, where the AP has Na antennas. STAs compete for the channel according to the DCF request to send/clear to send (RTS/CTS) mechanism. However, if accidentally more than one STA transmits in a time slot and the AP can decode the RTS frames, it sends the CTS frame to all senders. This can be done {{as long as the}} number of concurrent transmissions are less or equal to Na. Afterwards the transmitters send their data packets simultaneously to the AP. The suggested MAC closely follows the standard MAC, however, some modifications are required. For example, as the AP does not have any a priori knowledge about the transmitters and their channels, it should apply <b>blind</b> techniques to <b>decode</b> the RTS frames. Furthermore, it has to allocate orthogonal training sequences to the transmitters once it sends the CTS frames [4].|$|R
30|$|Based on {{the above}} {{two types of}} {{watermarking}} schemes, current researches on watermark extraction can be categorized into two broad topics: watermark decoding [12, 13, 19] for the case of decoding the hidden message and watermark detection [16 – 18, 20 – 22] for the case of detecting {{the presence of a}} specific watermark. Although watermark detection and decoding problems seem to be similar from the hypothesis testing point of view, they actually serve different goals and thus different criteria are used. In watermark decoding, the embedded hidden message should be decoded accurately at the receiver side and therefore the bit error rate is usually used as the performance criterion to measure the accuracy of the decoder in extracting the hidden message, and the watermark decoding problem can be formulated as minimizing the bit error rate. In watermark detection, the goal is to determine whether a specific watermark exists or not, and the detection criteria are mainly based on Neyman-Pearson Theorem (i.e., maximizing the probability of detection for a given probability of false alarm). Performance criterion such as the false alarm probability and the true detection probability are used for evaluating the watermark detector performance. To our knowledge, the majority of the current literature has been focused on watermark detection and many algorithms have been proposed. For instance, in [23] a watermark based on the host content is added and the detection is accomplished with the Neyman-Pearson criterion. In [24], a new perceptual masking is proposed and a correlation based detector is studied for watermark detection. In [25], a class of watermark detectors, including the generalized likelihood ratio, Bayesian, and Rao test detectors are proposed. In this article, we focus on the topic of watermark decoding, since we are particularly interested in communicating hidden message. Since in practice the original host image is generally not available at the decoder side, we focus on <b>blind</b> watermark <b>decoding.</b>|$|R

