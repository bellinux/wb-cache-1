6|30|Public
40|$|Abstract — Massive {{growth of}} the Internet traffic in last decades {{motivated}} the design of high-speed optical network for traffic aggregation from different access technologies. The network architecture proposed in this paper is a low-cost flexible solution consisting of two dual buses located over a physical bidirectional ring network topology. OTDM technology is used for statistical traffic multiplexing while reservation-based, token-rotation, and CSMA/CA with a <b>backpressure</b> <b>control</b> techniques {{can be used for}} access to the shared medium at the link layer. The presented distributed resilience algorithm is able to automatically restore network functionality in case of single link break or node malfunction. Keywords- Bidirectional Optical Ring, Traffic Aggregation. I...|$|E
40|$|Back-pressure {{control of}} traffic signal, which computes the control phase to apply {{based on the}} {{real-time}} queue lengths, has been proposed recently. Features of it include (i) provably maximum stability, (ii) low computational complexity, (iii) no requirement of prior knowledge in traffic demand, and (iv) requirement of only local information at each intersection. The latter three points enable it to be completely distributed over intersections. However, one major issue preventing <b>backpressure</b> <b>control</b> from being used in practice is the utilization of the intersection, especially if the control phase period is fixed, as is considered in existing works. In this paper, we propose a utilization-aware adaptive algorithm of back-pressure traffic signal control, which makes {{the duration of the}} control phase adaptively dependent on the real-time queue lengths and strives for high utilization of the intersection. While advantages embedded in the back-pressure control are kept, we prove that this algorithm is work-conserving and achieves the maximum utilization. Simulation results on an isolated intersection show that the proposed adaptive algorithm has better control performance than the fixed-period back-pressure control presented in previous works...|$|E
40|$|The {{standard}} IEEE 802. 3 x {{is introduced}} to manage XON/XOFF flow control mechanism in full duplex gigabit Ethernet. In a IEEE 802. 3 x network, a downstream station can send XOFF messages to upstream stations {{to stop them}} from sending data until a specified time slot has passed or the downstream station receives a XON message. The development of efficient XON/XOFF flow control mechanism is still an active research topic. This paper describes FLORAX, a IEEE 802. 3 x XON/XOFF control scheme with proposed modifications. It introduces a hop-by-hop <b>backpressure</b> <b>control</b> based on flow rate in order to fully utilize the performance of large scale LANs. The control strategy of FLORAX is based on applying backpressure depending on the bandwidth of the flows, where flow is defined to be a source - destination MAC address pair. FLORAX allows the use of Service Level Agreement (SLA) for quality of service. FLORAX is fair {{in the sense that it}} distributes the bandwidth among flows during congestion. The simulation study is performed to compare the performance of earlier approaches with the FLORAX. Experiment results demonstrate that FLORAX achieves fair bandwidth distribution for the duration of transmission, efficient use of link bandwidth, and reduction in packet loss...|$|E
40|$|This paper {{presents}} three complementary {{components of}} the flow control solution adopted for the Fed-X fabric: high-speed scalable interconnect for a multi-computer system. Each of the three addresses performance problems caused by a particular characteristic of realistic network workloads. The three flow-control techniques introduced in this paper are <b>backpressure</b> flow <b>control,</b> alpha scheduling...|$|R
40|$|Bidirectional shufflenet is {{a virtual}} {{multihop}} topology for optical networks that has been motivated by a need to support <b>backpressure</b> flow <b>control</b> mechanism in the wormhole routing context [14]. The bidirectional shufflenet topology has several desirable features including low average hop distance, support for <b>backpressure</b> flow <b>control,</b> high throughput and deadlock-free routing. In this paper, we analyze the properties of this topology. More specifically, we show how to compute shortest paths and derive {{the average number of}} hops. We compare the average hop results with those of other virtual topologies (shufflenet and bilayered shufflenet). Keywords: multihop virtual topology, shortest path routing, average hop count analysis. 1 Introduction A multihop virtual topology is composed of stations (each with a fixed number of transmitters and receivers) and `links' between these stations such that any station can reach any other station by making one or more hops along the links. A `lin [...] ...|$|R
40|$|Abstract—Multi-source data {{transmission}} in wireless video sensor networks is a challenging problem {{because of the}} high bandwidth demand of video streams and the many-to-one traffic pattern. This paper proposes forepressure transmission control for efficient and fair video transmission in this scenario. Contrary to traditional <b>backpressure</b> transmission <b>control</b> where downstream node creates backpressure and causes upstream node to hold off when its buffer is full, forepressure transmission control creates forepressure and signals upstream node to transmit when the downstream node’s buffer is not full. Forepressure transmission control proactively avoids congestion at little communication overhead. In addition, it is able to provide fairness among concurrent flows. We evaluate forepressure transmission control via NS- 2 simulations, and compare it with both <b>backpressure</b> congestion <b>control</b> and end-to-end rate regulation. Results in three typical topologies show that forepressure transmission control achieves much lower loss ratio and ensures better fairness than the other two schemes. Index Terms—wireless sensor network; video transmission; hop-by-hop control; fair rate allocatio...|$|R
40|$|Transduction of free-energy by Rhodobacter sphaeroides reaction-center-light-harvesting-complex- 1 (RCLH 1) was quantified. RCLH 1 {{complexes}} were reconstituted into liposomal membranes. The {{capacity of}} the RCLH 1 complex {{to build up a}} proton motive force was examined at a range of incident light intensities, and induced proton permeabilities, in the presence of artificial electron donors and acceptors. Experiments were also performed with RCLH 1 complexes in which the midpoint potential of the reaction center primary donor was modified over an 85 -mV range by replacement of the tyrosine residue at the M 210 position of the reaction center protein by histidine, phenylalanine, leucine or tryptophan. The intrinsic driving force with which the reaction center pumped protons tended to decrease as the midpoint potential of the primary donor was increased. This observation is discussed in terms of the control of the energetics of the first steps in light-driven electron transfer on the thermodynamic efficiency of the bacterial photosynthetic process. The light intensity at which half of the maximal proton motive force was generated, increased with increasing proton permeability of the membrane. This presents the first direct evidence for so-called <b>backpressure</b> <b>control</b> exerted by the proton motive force on steady-state cyclic electron transfer through and coupled proton pumping by the bacterial reaction center...|$|E
40|$|As mature fields face {{depletion}} {{the ability}} to reach smaller near- wellbore pockets of hydrocarbon resources at a low cost is paramount to prolong the economical lifetime of the field. The cost associated with drilling and completion conventionally and well engineering risks often results in classifying several fields as uneconomical to develop further. However,increasing awareness {{in the oil industry}} towards this predicament has resulted in progress in technology. Through tubing rotary drilling (TTRD) is a technology that enables access of near wellbore targets at significantly reduced drilling and completion costs by sidetracking from existing completion. Still, performing TTRD operations to increase the economical benefit of a mature field faces a number of challenges. There is an inherent risk of encountering depleted reservoir zones with narrow margins between the pore pressure and fracture pressure of the formation. It is therefore difficult to drill through this fragile formation without introducing considerable formation damage which will reduce the deliverability of the reservoir and impair the safety of the operation. Managed pressure drilling (MPD) is a general term describing technologies that allow control of the annular pressure profile downhole. By implementing MPD in TTRD operations, the problems associated with drilling in fragile formations are mitigated. Managed pressure drilling does not invite influx into the wellbore, in contrast to underbalanced drilling,instead the technology enables drilling at closed to balanced or slightly overbalanced conditions. This makes it possible to drill through fragile formations with minimal formation damage and well control issues. During this work, available MPD technologies where evaluated with the systems inherent limitations and advantages. On this background, four MPD systems were determined applicable for TTRD implementation; pressurized system with <b>backpressure</b> <b>control,</b> low riser return system (LRRS), subsea mudlift drilling (SMD) and drillstring integrated equivalent circulation density reduction tool (DI ECD RT). An analysis was realized to evaluate the selected MPD systems based on TTRD feasibility. The technologies were rated based on a grading system to get a good overview over the methods inherent weaknesses and strength with respect to TTRD integration. The result of the analysis shows a significant potential for improvement by implementing MPD technology compared to conventional drilling various aspects of TTRD operations by implementing MPD technology in TTRD operations. Furthermore a case study was realized to demonstrate the ability of the evaluated MPDmethods to compensate for the added dynamical pressure during circulation. The case is intended to reflect a realistic TTRD drilling scenario with narrow pore pressure and fracture pressure margins and small annular dimensions. It was demonstrated that conventional drilling for the selected drilling scenario would have resulted in severe overbalanced conditions and formation fracture. However, with MPD technology it is possible to produce a pressure relief to compensate for the added dynamical pressure during drilling and bring the well back into balanced conditions. Of the four evaluated MPD systems, it was suggested that the drill string integrated ECDreduction tool was the most applicable technology to implement in TTRD operations. The tool is fueled by the kinetic energy of the circulating fluid and does not require a power source. It can be integrated in the drillstring and repositioned according to operational needs. In order to successfully implement the device the current design of the tool has to be downsized to meet the specifications of the TTRD stack. Further development with respect to annular pump effect, wear resistance and tool usage is also necessary prior to TTRD implementation. In contrast with the drillstring ECD reduction tool, the pressurized system with <b>backpressure</b> <b>control,</b> subsea mud lift drilling and low riser return system offers manual management of the annular pressure profile in the well. However a higher level of complexity is associated with implementing these technologies. </p...|$|E
40|$|This thesis {{presents}} a comprehensive {{investigation into the}} underlying coupled processes in coal in response to high pressure gas injection. This is achieved by i) developing a new high pressure gas experimental facility and conducting a series of experimental tests, and ii) developing and applying a theoretical and numerical model. A novel experimental facility was designed, which offers stable and continuous high-pressure injection of gases in fractured rocks, for detailed study of the reactive transport processes. It consists of the gas supply and <b>backpressure</b> <b>control</b> system. Using the newly developed experimental facility, the response of coal subject to subcritical and supercritical gas injection under stable and variable temperature conditions was studied. The experimental investigation consisted {{of a series of}} tests: i) sorption capacity and kinetics tests, ii) uniaxial compressive tests, iii) sieve analysis tests, iv) flow and deformation tests. Thirty anthracite coal samples from different depths (i. e. 150 m and 550 m) and locations from the South Wales coalfield were characterised and tested. The capabilities of the theoretical and numerical modelling platform of thermal, hydraulic, chemical and mechanical processes were advanced. A new theoretical approach was adopted which successfully incorporates reactive gas transport coupled with coal deformation. The development of constitutive relationships describing the sorption induced elastic isotropic swelling of coal and changes in permeability was considered in detail. Numerical solutions of the governing flow and deformation equations were achieved by employing the finite element method for spatial discretisation and the finite difference method for temporal discretisation. The new model was verified for its accuracy via a series of benchmark tests and validated using high-resolution experimental data. The results of the experimental study showed that the sorption capacity and kinetics are sample-size dependent, particularly for deeper coal. Higher and faster sorption of CO 2 obtained on powdered samples compared to intact samples indicated that sorption processes are governed by fracture interconnectivity and accessibility of pores. Sorption of CO 2 was found to significantly reduce the brittleness, uniaxial compressive strength and elastic modulus of anthracite coals. The results of the post-failure sieve analysis showed that CO 2 saturated samples disintegrated on smaller particles than non-saturated samples indicating that sorption induced swelling weakens the coal structure by enhancing the existing and inducing new fractures. During CO 2 flow through coal under constant stress, samples experienced swelling resulting in initial reduction followed by recovery of measured flow rates. CO 2 sorption induced changes were found to be non-reversible. The results of high CO 2 flow through coal showed that CO 2 reduced the temperature of the system, associated with Joule- Thomson cooling, enhancing the coal swelling and opposite to expected, increasing the flow rates. Overall, the high-resolution data-set obtained is a significant contribution to the scientific community and is able to provide a means of validation for future models. The results of the verification and validation exercises demonstrated the capability of the developed model to simulate coupled processes involved in gas transport in coal. A series of numerical simulations were conducted to investigate the permeability evolution and CO 2 breakthrough in coal subject to supercritical CO 2 injection using the developed model. Different scenarios were considered, involving a range of values of the elastic modulus and the parameter defining the coal swelling. The results of the advanced numerical simulations showed that the effect of CO 2 sorption induced swelling on permeability reduces with a decrease in coal stiffness suggesting that CO 2 sorption induced reduction of elastic modulus would {{have a positive effect on}} the ability of coal to conduct CO 2. In this work, confidence in the feasibility of CO 2 storage in anthracite coals was improved by enhancing the knowledge of high pressure gas-coal interactions through both experimental and numerical investigations. Moreover, it is claimed that newly developed model enables predictions of coupled processes involved in carbon sequestration in coal...|$|E
40|$|ABSTRACT: ATLAS I is a single-chip ATM switch with {{optional}} credit-based (<b>backpressure)</b> flow <b>control.</b> This 4 -million-transistor 0. 35 -micron CMOS chip, {{which is}} currently under development, offers 20 Gbit/s aggregate I/O throughput, sub-microsecond cut-through latency, 256 -cell shared buffer containing multiple logical output queues, priorities, multicasting, and load monitoring. This paper discusses the use of backpressure inside networks based on ATLAS I chips: in switching fabrics of large ATM switches, or in wormhole-style workstation cluster LANs. We explain and we show bysimulation that the ATLAS I backpressure provides a switching fabric with high performance, comparable to an output queued switch, at low cost, comparable to an input buffered switch. 1...|$|R
40|$|High-speed {{networks}} use lightweight protocols and {{a simple}} switch architecture for achieving higher speeds. A lightweight switching technique for local area and campus environments is wormhole routing, in which {{the head of a}} packet (worm), upon arriving at an intermediate switch, is immediately forwarded to the next switch on the path. Thus, the packet, like a worm, may stretch across several intermediate switches and links. Wormhole routing networks provide low latency. However, they are particularly prone to congestion, thus requiring careful flow control. In this paper, we consider high-speed, asynchronous, unslotted wormhole routing networks. For such networks, we compare and contrast two different flow <b>control</b> mechanisms, namely, <b>backpressure</b> flow <b>control</b> and deflection routing (with local input rate <b>control).</b> With <b>backpressure,</b> in order to maintain deadlock-free routing, we assume either Up/Down routing, or shortest path routing with virtual channels. With deflection routing, to [...] ...|$|R
40|$|In {{this paper}} we study the {{bidirectional}} shufflenet topology, which is {{obtained from the}} well-known (unidirectional) shufflenet by considering bidirectional links. More specifically, we define a shortest path routing algorithm, and derive the diameter and the average distance of the topology. The bidirectional shufflenet is then compared, in terms of average distance, with other variations of the perfect shuffle. Bidirectional links are very common in real networks. Possible applications of bidirectional shufflenets are wormhole routing electronic networks with <b>backpressure</b> flow <b>control,</b> and wavelength routing optical networks. In {{the last part of}} the paper, the former class of networks is considered, when virtual channels are used to prevent deadlocks. We show that four virtual channels are sufficient to avoid deadlocks in the bidirectional shufflenet, regardless of the number of nodes in the topology. Index Terms [...] -Deadlock avoidance, shufflenet, wormhole routing. I...|$|R
40|$|In {{the current}} ATM LAN Emulation (LANE) {{standard}} {{the issues of}} flow control and bandwidth allocation in the Access Units have not been adequately addressed. This paper investigates ways to enhance the functionality of typical legacy LAN-ATM Access Units (AUs) {{with the addition of}} low-level flow control mechanisms. The scheme proposed is based on the Available Bit Rate (ABR) control mechanism currently standardized for ATM. <b>Backpressure</b> flow <b>control</b> is not terminated in the AU but is further extended to reach the non-ATM legacy LAN stations. This is achieved by using a subset of the Logical Link Control (LLC) protocol functionality executed between the AU and the legacy LAN stations. Apart from the QoS guarantees, the proposed method is transparent to the upper transport layer protocols and as such it does not require fundamental modifications to existing AUs and LAN stations...|$|R
40|$|In {{order to}} {{minimize}} latency in high-speed interconnection networks, the wormhole routing technique can be employed. With this technique, a switch transmits an incoming message {{as soon as it}} receives it, without waiting for the entire message. The problem then is that a message stretches over several links and locks network resources, thus making a contention situation possible. Two principal congestion control mechanisms can be considered, <b>backpressure</b> flow <b>control</b> and deflection routing. The performance of these mechanisms depends both on the traffic characteristics and on the network topology. In order to compare them, we study analytically the behavior of a wormhole routing network model with random input traffic under both policies. We estimate the probability of collision between messages and express the average message transit delay {{as a function of the}} offered load. Simulation provides a good confirmation for the analytical results. This study gives us an understanding of the [...] ...|$|R
40|$|The Internet has {{traditionally}} relied on end-to-end congestion control {{performed at the}} transport layer by TCP. In this paper, we discuss the limitations of this approach to address {{the large number of}} flows and the large delay-bandwidth product scenarios typical of next generation Internets. As a result, we propose a link layer back-pressure flow control which can be applied to Internet backbones over ATM. More precisely, we use the ABR service and flow control, where routers become virtual sources (VSs) and virtual destinations (VDs) for the ABR control loop. We introduce a VS/VD "behavior" that implements a rate based <b>backpressure</b> flow <b>control</b> and that addresses max-min fairness. Finally, for the case of edge router connectivity to the ATM network (as opposed to ATM {{all the way to the}} host), we discuss approaches that can be used to convey ATM rate control indications to TCP sources connected to legacy LANs...|$|R
40|$|ABSTRACT: We {{describe}} the queue management block of ATLAS I, a single-chip ATM switch (router) with optional credit-based (<b>backpressure)</b> flow <b>control.</b> ATLAS I is a 4 -million-transistor 0. 35 -micron CMOS chip, currently under development, offering 20 Gbit/s aggregate I/O throughput, sub-microsecond cut-through latency, 256 -cell shared buffer containing multiple logical output queues, priorities, multicasting, and load monitoring. The queue management block of ATLAS I is a dual parallel pipeline that manages the multiple queues of ready cells, the per-flow-group credits, and the {{cells that are}} waiting for credits. All cells, in all queues, share one, common buffer space. These 3 - and 4 -stage pipelines handle events {{at the rate of}} one cell arrival or departure per clock cycle, and one credit arrival per clock cycle. The queue management block consists of two compiled SRAM’s, pipeline bypass logic, and multi-port CAM and SRAM blocks that are laid out in full-custom and support special acces...|$|R
40|$|Abstract—Congestion {{control in}} {{wireless}} multi-hop networks is challenging and complicated because of two reasons. First, interference is ubiquitous and causes {{loss in the}} shared medium. Second, wireless multihop networks are characterized {{by the use of}} diverse and dynamically changing routing paths. Traditional end point based congestion control protocols are ineffective in such a setting resulting in unfairness and starvation. This paper adapts the optimal theoretical work of Tassiulas and Ephremedes [33] on cross-layer optimization of wireless networks involving congestion control, routing and scheduling, for practical solutions to congestion control in multi-hop wireless networks. This work is the first that implements in real off-shelf radios, a differential backlog based MAC scheduling and router-assisted <b>backpressure</b> congestion <b>control</b> for multi-hop wireless networks. Our adaptation, called DiffQ, is implemented between transport and IP and supports legacy TCP and UDP applications. In a network of 46 IEEE 802. 11 wireless nodes, we demonstrate that DiffQ far outperforms many previously proposed “practical” solutions for congestion control. I...|$|R
40|$|We {{describe}} the queue management block of ATLAS I, a single-chip ATM switch (router) with optional credit-based (<b>backpressure)</b> flow <b>control.</b> ATLAS I is a 4 -million-transistor 0. 35 -micron CMOS chip, currently under development, offering 20 Gbit/s aggregate I/O throughput, sub-microsecond cut-through latency, 256 -cell shared buffer containing multiple logical output queues, priorities, multicasting, and load monitoring. The queue management block of ATLAS I is a dual parallel pipeline that manages the multiple queues of ready cells, the per-flow-group credits, and the {{cells that are}} waiting for credits. All cells, in all queues, share one, common buffer space. These 3 - and 4 -stage pipelines handle events {{at the rate of}} one cell arrival or departure per clock cycle, and one credit arrival per clock cycle. The queue management block consists of two compiled SRAM's, pipeline bypass logic, and multi-port CAM and SRAM blocks that are laid out in full-custom and support special access Cop [...] ...|$|R
50|$|For an {{oil and gas}} {{separator}} {{to accomplish}} its primary functions, pressure must be maintained in the separator so that the liquid and gas can be discharged into their respective processing or gathering systems. Pressure is maintained on the separator by use of a gas backpressure valve on each separator or with one master <b>backpressure</b> valve that <b>controls</b> the pressure on a battery {{of two or more}} separators. The optimum pressure to maintain on a separator is the pressure that will result in the highest economic yield from the sale of the liquid and gaseous hydrocarbons.|$|R
40|$|In this paper, {{we propose}} an {{adaptive}} fuzzy control traffic shaping {{scheme based on}} leaky bucket in order to solve the traffic congestion problem over wireless networks. It is found that backpressure algorithm is suitable for low traffic and, it prevents buffer overflows. When buffer exceeds the upper threshold, the source receives a backpressure signal and, it pauses sending frames until it receives a signal from the same server. In backoff time using leaky bucket over traffic shaping mechanism, it is suitable for high traffic, Backoff time computations are widely used {{in order to avoid}} the impact on the network performance whenever the increment of the offered load arises. The fluctuation of offered load will cause the congestion at waiting room. We propose a fuzzy <b>control</b> <b>backpressure</b> and backoff time in traffic shaping that aims at detecting violations in parameter negotiation. We evaluate and compare the performance of fuzzy backpressure and backoff time in traffic shaping schemes. The studied approaches are fuzzy backpressure and exponential backoff time (FBE), backpressure in leaky bucket (BP), and exponential backoff time (EB). The performance of fuzzy <b>control</b> <b>backpressure</b> and backoff time has been investigated through fluctuations in telecommunication traffic streams (burst/silent type). Simulation results show that on wireless frames, the fuzzy logic control scheme helps to improve the performance in traffic shaping schemes much better than conventional backpressure algorithm and exponential backoff time. This has been verified by testing various types of burst/silence traffic...|$|R
40|$|A noise-tolerant data {{communications}} fabric {{has been developed}} to meet the real-time data acquisition and control requirements of fast feedback loops, machine protection systems, pulse-to-pulse sequencing, and machine-experiment communications at next-generation pulsed accelerators such as the Next Linear Collider ("NLC"). The fabric is constructed from "platform" or "system-on-a-chip" field programmable gate arrays ("FPGAs") containing embedded processors, block memory, and multi-gigabit serial transceivers interconnected via an array of point-to-point fiber-optic physical links for standard networks such as gigabit Ethernet. The FPGA-based link hardware segments messages of varying priorities into a continuous sequence of fixed-length data cells, interrupting the cell stream of lower priority messages with those comprising higher priority traffic. A high level of noise-tolerance is provided by dedicating almost half the contents of each cell to Reed-Solomon forward error correcting code ("ECC") data. Further reliability is achieved by hardware implementation of algorithms for cell-by-cell receipt acknowledgment, receipt timeout and retransmission after a tunable round-trip propagation delay, and separate <b>backpressure</b> flow <b>control</b> for each priority. Comment: Presented at 2 nd Global Accelerator Network Workshop, Shelter Island, September 17 - 20, 2002, 8 pages, pd...|$|R
40|$|The Ribosome Flow Model (RFM) {{describes}} the unidirectional movement of interacting particles along a one-dimensional chain of sites. As a site becomes fuller, the effective entry rate into this site decreases. The RFM {{has been used}} to model and analyze mRNA translation, a biological process in which ribosomes (the particles) move along the mRNA molecule (the chain), and decode the genetic information into proteins. Here we propose the RFM as an analytical framework for modeling and analyzing linear communication networks. In this context, the moving particles are data-packets, the chain of sites is a one dimensional set of ordered buffers, and the decreasing entry rate to a fuller buffer represents a kind of decentralized <b>backpressure</b> flow <b>control.</b> For an RFM with homogeneous link capacities, we provide closed-form expressions for important network metrics including the throughput and end-to-end delay. We use these results to analyze the hop length and the transmission probability (in a contention access mode) that minimize the end-to-end delay in a multihop linear network, and provide closed-form expressions for the optimal parameter values...|$|R
40|$|In {{this paper}} a {{universal}} model for breaking cycles is described. A method applicable to nondirected graphs is first developed and subsequently applied to communication networks. Loops or cycles {{are particularly important}} in communication networks. Specifically, communication networks using wormhole routing techniques [1, 2, 3] and local area networks with <b>backpressure</b> flow <b>control</b> mechanisms [4, 5, 6] are particularly vulnerable to network states known as deadlock and livelock. An efficient approach to handle deadlocks and livelocks in such networks is based on preventing them by selecting routing policies that are deadlock and livelock free. Cycles in channel dependency graph [7] in such networks {{have been used as}} an indicator for vulnerability for deadlocks. Construction of the channel dependency graph is at best difficult for all but very small networks. Our model provides a simpler alternative. It operates in the network graph domain instead of the channel dependency graph. We present a simple routing strategy for deadlock and livelock free unicasting and multicasting by using minimal number of turn prohibitions to break all cycles in the network graph. Performance of the model is evaluated by simulation experiments for irregular communication networks using unicast and multicast wormhole routing...|$|R
40|$|A {{backpressure}} {{filling system}} {{is a kind of}} air type filling system which could be applied to power type, fine or coarse grain, or mixtures with fine and coarse components. The working principle of backpressure filling system was discussed based on fundamental hydromechanics. The research limit values of backpressure were achieved via mechanical analysis. Comparing with the exit velocity of material by theoretical analysis and numerical simulation, the CFD simulation model was confirmed and its related parameters were determined. The CFD numerical simulation shows the relationship between production capacity of packaging machine and backpressure, and the results matched actual operation of the equipment well. Combining with the demand of device capacity, the range of <b>backpressure</b> could be <b>controlled</b> at 8 [*]kPa~ 11 [*]kPa...|$|R
40|$|Abstract — We {{evaluate}} web browsing performance over {{a multiple}} access satellite channel for three different MAC layer protocols. A web user behavior model {{is used to}} generate realistic source traffic. A new transport layer protocol called RWBP is proposed to solve the TCP problems inside satellite networks. RWBP uses per-flow queuing, round robin scheduling and receiver window <b>backpressure</b> for congestion <b>control.</b> We compare its performance with TCP over the three multiple access protocols. Our simulation results show that RWBP can reduce the multiple access channel load {{and at the same}} time improve the web page response time when driven by realistic web traffic. For the MAC layer protocols, combined free demand assignment multiple access (CFDAMA) always performs better than the other two protocols. I...|$|R
40|$|Abstract. Although ATM (Asynchronous Transfer Mode), is {{a widely}} {{accepted}} standard for WANs (Wide Area Networks), {{it has not yet}} been widely embraced by the NOW community, because (i) most current ATM switches (and interfaces) have high latency, andand(ii) theydropcells when (even short-term) congestion happens. In this paper, we present ATLAS I, a single-chip ATM switch with 20 Gbits/sec aggregate I/O throughput, that was designed to address the above concerns. ATLAS I provides sub-microsecond cut-through latency, and (optional) <b>backpressure</b> (credit-based) ow <b>control</b> which never drops ATM cells. The architecture of ATLAS I has been fully speci ed and the design of the chip is well under progress. ATLAS I will be fabricated by SGS Thomson, Crolles, France, in 0. 5 m CMOS technology. 1...|$|R
40|$|We {{evaluate}} web browsing performance over {{a multiple}} access satellite channel for three different MAC layer protocols. A web user behavior model {{is used to}} generate realistic source traffic. A new transport layer protocol called RWBP is proposed to solve the TCP problems inside satellite networks. RWBP uses per-flow queuing, round robin scheduling and receiver window <b>backpressure</b> for congestion <b>control.</b> We compare its performance with TCP over the three multiple access protocols. Our simulation results show that RWBP can reduce the multiple access channel load {{and at the same}} time improve the web page response time when driven by realistic web traffic. For the MAC layer protocols, combined free demand assignment multiple access (CFDAMA) always performs better than the other two protocols. I...|$|R
40|$|Multiprocessing (MP) on {{networks}} of workstations (NOW) is a high-performance computing architecture of growing importance. In traditional MP's, wormhole routing interconnection networks use fixed-size flits and backpressure. In NOW's, ATM-one {{of the major}} contending interconnection technologies- uses fixed-size cells, while backpressure {{can be added to}} it. We argue that ATM with backpressure has interesting similarities with wormhole routing. We are implementing ATLAS I, a single-chip gigabit ATM switch, which includes credit flow <b>control</b> (<b>backpressure),</b> according to a protocol resembling Quantum Flow Control (QFC). We show by simulation that this protocol performs better than the traditional multi-lane wormhole protocol: high throughput and low latency are provided with less buffer space. Also, ATLAS I demonstrates little sensitivity to bursty traffic, and, unlike wormhole, it is fair in terms of latency in hot-spot configurations. We use detailed switch models, operating at clock-cyc [...] ...|$|R
40|$|Abstract [...] In this paper, {{we propose}} an {{adaptive}} fuzzy control traffic shaping {{scheme based on}} leaky bucket in order to solve the traffic congestion problem over wireless networks. It is found that backpressure algorithm is suitable for low traffic and, it prevents buffer overflows. When buffer exceeds the upper threshold, the source receives a backpressure signal and, it pauses sending frames until it receives a signal from the same server. In backoff time using leaky bucket over traffic shaping mechanism, it is suitable for high traffic, Backoff time computations are widely used {{in order to avoid}} the impact on the network performance whenever the increment of the offered load arises. The fluctuation of offered load will cause the congestion at waiting room. We propose a fuzzy <b>control</b> <b>backpressure</b> and backoff time in traffic shaping that aims at detecting violations in parameter negotiation. We evaluate an...|$|R
40|$|High-speed {{networks}} use lightweight protocols and {{a simple}} switch architecture for achieving higher speeds. A lightweight switching technique for local area and campus environments is wormhole routing, in which {{the head of a}} packet (worm), upon arriving at an intermediate switch, is immediately forwarded to the next switch on the path. Thus, the packet, like a worm, may stretch across several intermediate switches and links. Wormhole routing networks provide low latency. However, they are particularly prone to congestion, thus requiring careful flow control. In this article, the authors consider high-speed, asynchronous, unslotted wormhole routing networks. For such networks, two different flow control mechanisms are compared and contrasted, namely, <b>backpressure</b> flow <b>control</b> and deflection routing (with local input rate <b>control).</b> With <b>backpressure,</b> in order to maintain deadlock-free routing, either up/down routing or shortest path routing with virtual channels is assumed. With deflection routing, to avoid livelocks, worm alignment (delayed deflection) is performed at switches. It is shown via simulation that the throughput performance of the two schemes is comparable (except for up/down routing). The authors also discuss the tradeoffs with respect to complexity of hardware, routing protocols and buffer requirements. The authors further examine the role of input rate control at the hosts to overcome unbounded delays typical of deflection routing, and show it is possible to achieve lower average number of hops and transit delays by employing suitable input rate control policies...|$|R
40|$|PMC-Sierra’s ELAN-EXACT {{switching}} chipset architecture uses intelligent port controllers with embedded RISC cores, a 2 gigabit {{per second}} insertion ring switching bus, and {{a relatively simple}} switch matrix controller design capable of up to 128 ports of 10 / 100 M or 16 ports of Gigabit Ethernet. The combination of an integrated hardware address resolution logic (ARL) function and the embedded RISC processor provides firmware-defined Layer 2 and Layer 3 switching. The RISC processor also provides on-chip <b>backpressure</b> and flow <b>control,</b> address learning, aging and spanning tree. It is also possible to run SNMP and RMON processing and Layer 3 protocol operations such as address resolution, route discovery and IP forwarding on-chip, or in conjunction with an external MPU. A novel 2 gigabit per second insertion ring is used to provide high-speed interconnect and switching between port controllers and switch matrix controllers. By using an 8 B/ 10 B encoded bus with unidirectional signal flow, i...|$|R
40|$|Although ATM (Asynchronous Transfer Mode), is {{a widely}} {{accepted}} standard for WANs (Wide Area Networks), {{it has not yet}} been widely embraced by the NOW community, because (i) most current ATM switches (and interfaces) have high latency, and and (ii) they drop cells when (even short-term) congestion happens. In this paper, we present ATLAS I, a single-chip ATM switch with 20 Gbits/sec aggregate I/O throughput, that was designed to address the above concerns. ATLAS I provides sub-microsecond cut-through latency, and (optional) <b>backpressure</b> (credit-based) flow <b>control</b> which never drops ATM cells. The architecture of ATLAS I has been fully specified and the design of the chip is well under progress. ATLAS I will be fabricated by SGS Thomson, Crolles, France, in 0. 5 ¯m CMOS technology. 1 Introduction Popular contemporary computing environments are comprised of powerful workstations connected via a high-speed network, giving rise to systems called workstation clusters or Networks of Worksta [...] ...|$|R
40|$|In mobile ad-hoc networks, the {{multicast}} {{paradigm is}} of central importance. It {{can help to}} save scarce medium bandwidth if packets are to be delivered to multiple destinations. We consider the problem of congestion control for multicast traffic in wireless multihop networks. We propose to apply a congestion control concept which is tailored to the very special properties of the wireless multihop medium: implicit hop-by-hop congestion control. The idea, so far only having been considered for unicast traffic, is here generalized to multicast. We implement it in the <b>Backpressure</b> Multicast Congestion <b>Control</b> (BMCC) protocol, {{with a focus on}} how to realize it in combination with geographic multicast routing in the Scalable Position-Based Multicast (SPBM) protocol. Our evaluation points out a number of highly desirable properties of the proposed scheme. In particular, it achieves and maintains high throughput and high packet delivery ratios at low packet latencies, even in the presence of significant network load. 1...|$|R
40|$|The Supercomputer SuperNet (SSN) is a {{two-level}} hierarchical high-speed network. The {{lower level}} is a High Speed Electronic mesh fabric; the higher level is a WDM optical backbone network interconnecting the high-speed fabrics distributed across a campus or metropolitan area. The salient characteristics of this architecture are {{the use of}} wormhole routing and <b>backpressure</b> hop-by-hop flow <b>control</b> mechanism. Because of these features, deadlocks are possible in SSN. In this paper, we {{address the issue of}} deadlock-free routing which is an essential prerequisite for the proper operation of SSN. To this end, we first present a deadlock free routing scheme for the WDM backbone which is implemented with a shufflenet multihop virtual topology. We use the notion of virtual channels to obtain mappings of virtual channels to physical channels such that deadlock-free routing is achieved for any (p; k) shufflenet (uni and bidirectional). Then, we compare the virtual channels scheme with the more con [...] ...|$|R
30|$|Experimental {{procedures}} are as follows. (1) In these tests, only one sand pack (No. 1, {{as shown in}} Fig.  2) was used and saturated with the simulated formation water of different salinities (20, 000 and 200, 000  ppm) at a backpressure of 10.28  MPa under different temperatures. The pressure difference across the sand pack, ΔP 1, was measured for calculating the initial permeability of the sand pack. The water injection rate was maintained at 1  mL/min. (2) CO 2 was injected into the sand pack until a gas breakthrough occurred at the outlet of the sand pack. (3) A slug of the gel solution (modified PAM-methenamine-resorcinol gel system) (normally 0.3 pore volume (PV)) was injected into the sand pack. The concentration of the modified PAM used in brine was 1.0  wt%. (4) A slug of CO 2 (0.3 PV) was then injected into the sand pack, and all the valves were turned off for gel reactions. (5) After 8  h, the simulated formation water was injected into the sand pack at an injection rate of 1  mL/min, and the pressure difference (ΔP 2) was measured at different injection volumes. The <b>backpressure</b> regulator may <b>control</b> the water flow more steadily than a CO 2 flow in sand packs and the pressure difference can be measured with relatively higher accuracy using water flow. Hence, {{the performance of the}} gel system for water shutoff was employed to reflect the blocking capacity to CO 2 based on this gel system indirectly.|$|R
40|$|In general, routing {{protocols}} for mobile ad-hoc networks (MANETs) {{can be classified}} into topology-based protocols and position-based protocols. While for unicast routing many proposals for both classes exist, the existing approaches to multicast routing basically implement topology-based algorithms {{and only a few}} of them make use of the geographic positions of the network nodes. These have in common that the sending node has to precalculate the multicast tree over which the packets are distributed and store it in each packet header. This involves two main issues: (a) These approaches are not very flexible with regard to topological changes which abandons the advantages that position-based routing has against topology-based routing, and (b) they do not scale with the number of receivers, since every one of them has to be named in the packet header. This thesis solves these issues and further advances position-based multicast routing. Position-Based Multicast (PBM) enhances the flexibility of position-based multicast routing by following the forwarding principle of position-based unicast routing. It transfers the choice of the next hops in the tree from the sender to the forwarding nodes. Based on the positions of their neighboring nodes, these are able to determine the most suitable next hop(s) at the moment when the packet is being forwarded. The scalability with respect to the number of receiving nodes in a group is solved by Scalable Position-Based Multicast (SPBM). It includes a membership management fulfilling different tasks at once. First, it administers group memberships in order to provide multicast sources with information on whether nodes are subscribed to a specific group. Second, it implements a location service providing the multicast sources with the positions of the subscribed receiver nodes. And third, it geographically aggregates membership data in order to achieve the desired scalability. The group management features two modes of operation: The proactive variant produces a bounded overhead scaling well with the size of the network. The reactive alternative, in contrast, reaches low worst-case join delays but does not limit the overhead. Contention-Based Multicast Forwarding (CBMF) addresses the problems that appear in highly mobile networks induced by outdated position information. Instead of basing forwarding decisions on a perception that may no longer be up to date, the packets are addressed only to the final destination; no explicit next hops are specified. The receiving nodes, which are candidate next hops, then decide by means of contention which of them are the most suitable next hop(s) for a packet. Not only is the decision made based on the most currently available data, but this procedure also saves the regular sending of beacon messages, thus reducing the overhead. The lack of multicast congestion control is another unsolved problem obstructing high-bandwidth data transmission. Sending out more and more packets to a multicast group lets the performance decrease. <b>Backpressure</b> Multicast Congestion <b>Control</b> (BMCC) takes care that the network does not need to handle more packets than it is able to. It achieves this by limiting the packet queues on the intermediate hops. A forwarder may not forward the next packet of a stream before it has noticed [...] -by overhearing the transmission of the next hop [...] -that the previous packet has succeeded. If there is congestion in an area, backpressure is implicitly built up towards the source, which then stops sending out packets until the congestion is released. BMCC takes care that every receiving node will receive packets at the same rate. An alternative mode of operation, BMCC with Backpressure Pruning (BMCC-BP) allows the cutting of congested branches for single packets, permitting a higher rate for uncongested receivers. Besides presenting protocols for multicast communication in MANETs, this thesis also describes implementations of two of the above-mentioned protocols. The first one is an implementation of SPBM for the Linux kernel that allows IP applications to send data via UDP to a group of receivers in an ad-hoc network. The implementation resides between the MAC layer and the network/IP layer of the network stack. It is compatible with unmodified standard kernels of versions 2. 4 and 2. 6, and may be compiled for x 86 or ARM processor architectures. The second implementation is an implementation of CBMF for the ScatterWeb MSB 430 sensor nodes. Due to their low-level programmability they allow an integration of the routing protocol with the medium access control. The absence of periodic beacon messages makes the protocol especially suitable for energy-constrained sensor networks. Furthermore, other constraints like limited memory and computational power demand special consideration as well...|$|R
