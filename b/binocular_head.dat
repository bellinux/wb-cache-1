23|24|Public
40|$|Slant {{perception}} was studied under viewing conditions that combined horizontal-size, vertical-size, and overall-size binocular disparities with motion and static image conditions. For both motion and static conditions, results indicated similar effects of size disparity on perceived slants of disparity and zero-disparity stimuli. Implications for <b>binocular</b> <b>head</b> mounted display (HMD) systems are considered...|$|E
40|$|In this paper, {{we propose}} a new {{automatic}} approach to reconstructing {{a model for}} the 3 D environment by use of an active <b>binocular</b> <b>head.</b> To efficiently store and access the depth estimates, we propose the use of the inverse polar octree which can transform both the unbounded estimate and the unbounded estimation error into a bounded 3 D space with appropriate resolution. The depth estimates are computed by using the asymptotic Bayesian estimation method, which includes the use of Markov random fields. In order to apply this method, the active <b>binocular</b> <b>head</b> (the IIS head) has been calibrated with very high accuracy. The path of the local motion required by the asymptotic Bayesian method is determined online automatically to reduce the ambiguity of stereo matching. Some rules for checking the consistency between the new observation and the previous observations have been developed to properly update the inverse polar octree. Experimental results have shown that the proposed approach is ve [...] ...|$|E
40|$|In {{this article}} we report how Dynamic Cell Structures (DCS) [1] can be {{utilized}} to learn fast and accurate saccade control of a four-degrees-of-freedom <b>Binocular</b> <b>Head.</b> We solve the order selection problem by incremental growing of a DCS network until the controller meets a pre-specified precision. Calculation of the controller output is very fast and suitable for realtime control since the resulting network is as small as possible and only the best matching unit and its topological neighbors are activated on presentation of an input stimulus. Training of the DCS is based on error feedback learning and proceeds in two phases. In the first phase we use a crude model of the cameras and the kinematics of the head to learn the topology of the input submanifold and a rough approximation off-line. In a second phase, the operating phase, we employ error feedback learning for online adaptation of the linear output units. Besides our TRC <b>binocular</b> <b>head</b> we use a Datacube image processing system [...] ...|$|E
40|$|An active {{vision system}} has to enable the {{implementation}} of reactive visual processes and of elementary visual behaviors in real time. In this paper we describe the real-time implementation of several visual behaviors in an active vision system. Issues related to the real-time implementation are discussed, namely in what concerns the modeling of the measurements made in the image. Even though in most applications a fully calibrated system is not required, we also describe a methodology for calibrating the camera head, taking advantage of its degrees of freedom. These calibration parameters are {{used to evaluate the}} performance of the system. Another important issue of the operation of active vision <b>binocular</b> <b>heads</b> is their integration into more complex robotic systems. We claim that higher levels of autonomy and integration can be obtained by designing the system architecture based on the concept of purposive behavior. We show how this architecture can be used to implement a pursuit beh [...] ...|$|R
40|$|An active {{vision system}} has to enable the {{implementation}} of reactive visual processes and of elementary visual behaviors in real time. Therefore the control architecture is extremely important. In this {{paper we discuss a}} number of issues related with the implementation of a real-time control architecture and describe the architecture we are using with camera heads. Another important issue of the operation of active vision <b>binocular</b> <b>heads</b> is their integration into more complex robotic systems. The design of the control architecture has to be suited to the integration of the system in other robotic systems. Higher levels of autonomy and integration can be obtained by designing the system architecture based on the concept of purposive behavior. At the lower levels we consider vision as a sensor and integrate it in control systems (both feed-forward and servo loops) and several visual processes are implemented in parallel, computing relevant measures for the control process. At higher leve [...] ...|$|R
40|$|Two novel {{systems for}} {{immersive}} audio-visual telepresence are presented. The following approaches {{are motivated by}} perceptual studies. First a comparison between human perception of space and conventional technologies for telepresence was made. The results of this comparison have shown a lack of fidelity due to limited support of binaural and binocular cues. Both cues {{play an important role}} in perception of space. Also tactile cues can enhance the perception of space and are used for a special telepresence system. These facts resulted in the development of the Binaural <b>Binocular</b> <b>Heads</b> (BiBiH), systems with enhanced spatial resolution. For data transmission audio and video components have been developed. Additionally a component for the transmission of positional data from a head-tracking system and a robot-controlling component have been developed for the BiBiH. A component for disparity adjustment has been introduced to enhance the operating range of the stereo video system. The advantages of the two systems in teleconferencing and immersive telepresence applications are shown...|$|R
40|$|This paper {{describes}} {{a new approach}} to the integration and control of continuously operating visual processes. Visual processes are expressed as transformations which map signals from virtual sensors into commands for devices. These transformations define reactive processes which tightly couple perception and action. Such transformations may be used to control robotic devices, including fixation an active <b>binocular</b> <b>head,</b> as well as the to select and control the processes which interpret visual data...|$|E
40|$|Abstract. In {{this article}} we report how Dynamic Cell Structures (DCS) [1] can be {{utilized}} to learn fast and accurate saccade control of a four-degrees-of-freedom <b>Binocular</b> <b>Head.</b> We solve the order selection problem by incremental growing of a DCS network until the controller meets a pre-specified precision. Calculation of the controller output is very fast and suitable for realtime control since the resulting network is as small as possible and only the best matching unit and its topological neighbors are activated on presentation of an input stimulus. Training of the DCS is based on error feedback learning and proceeds in two phases. In the first phase we use a crude model of the cameras and the kinematics of the head to learn the topology of the input submanifold and a rough approximation off-line. In a second phase, the operating phase, we employ error feedback learning for online adaptation of the linear output units. Besides our TRC <b>binocular</b> <b>head</b> we use a Datacube image processing system and a Stäubli R 90 robot arm for automated training in the second phase. The controller is demonstrated to successfully correct errors in the model and to rapidly adapt to changing parameters. ...|$|E
40|$|We {{describe}} a novel {{method by which}} a four-axis <b>binocular</b> <b>head</b> platform can autonomously align its cameras so that their optic axes are {{parallel to each other}} and to the forward direction of the robot. The method uses controlled pans and elevations of the robot while viewing an unstructured scene in order to determine lines on the plane at infinity, whose intersection we prove to be the forward direction of the robot. The alignment is completed by fixating the projections of this point in both cameras. We summarize the underlying theory, and present results from a fully autonomous implementation of the algorithm. ...|$|E
40|$|This paper uses {{geometric}} algebra to formulate, in {{a single}} framework, the kinematics of a three finger robotic hand, a <b>binocular</b> robotic <b>head,</b> and the interactions between 3 D objects, {{all of which are}} seen in stereo images. The main objective is the formulation of a kinematic control law to close the loop between perception and actions, which allows to perform a smooth visually guided object manipulation...|$|R
40|$|A 5 degree-of-freedom <b>binocular</b> stereovision <b>head,</b> called Argus, is {{described}} {{which has been}} designed for independent camera control (other than that of occular vergence). The system was inspired by both the abili-ties and behaviors of the chameleon visual system. A unique control architecture {{is described}} which enables hierarchical learning of visual behaviors, including in-dependent search for an object of interest coupled with dual-camera object fixation upon successful completion of the search...|$|R
40|$|An active {{vision system}} has to enable the {{implementation}} of reactzve visual processes and of elementary visual behaviors. in real tzme. Therefore the control architecture is extremely important. In this {{paper we discuss a}} number of issues related with the implementation of a real-ttme control architecture and describe the architecture we are using with camera heads. Another important issue of the operation of active vision <b>binocular</b> <b>heads</b> is their integration into more complex robotic systems. ‘The design of the control architecture has to be suited to the integration of the system in other robotic systems. Higher levels of autonomy and integration can be obtained by designing the system architecture based on the concept of purposive behavior. At the lower levels we consider vision as a sensor and integrate it in control systems (both feed-forward and servo loops) and several visual processes are implemented in parallel, computing relevant measures for the control process. At higher levels the architecture is modeled as a state transition system. Finally we show how this architecture can be used to implement a pursuit behavior using optical pow. Simultaneously vergence control can also be performec! using the same visual processes. 1...|$|R
40|$|This paper {{presents}} {{the use of}} neural networks (NNs) and genetic algorithms (GAs) to enhance the output tracking performance of partly known robotic systems. Two of the most potential approaches of adaptive control, i. e., the concept of variable structure control (VSC) and NN-based adaptive control, are ingeniously combined using GAs to achieve high-performance output tracking. GA is {{used to make the}} maximum use of different performance characteristics of two self-adaptive NN modules by finding the switching function which best combines them. The method will be valid for any rigid revolute robot system. Computer simulations on our active <b>binocular</b> <b>head</b> are included for illustration and verification...|$|E
40|$|An active {{stereo vision}} system is {{introduced}} which {{is able to}} detect {{the face of an}} arbitrary person in a real world environment. The face is zoomed in and tracked while the person is able to give commands to the system by particular hand gestures. The system is based on a robotically controlled <b>binocular</b> <b>head,</b> of which both cameras can be controlled independently. A control supervisor is established which evaluates all visual information and controls particular jobs or actions based on recently obtained results. The presented system design and implementation allows the detection, the zoom, and the tracking of the face, as well as the detection and evaluation of the hand gestures, to be performed in realtime. ...|$|E
40|$|This paper {{describes}} practical, effective {{approaches to}} stereo perception and dead reckoning, and presents results from systems implemented for a prototype lunar rover operating in natural, outdoor environments. The stereo perception hardware includes a <b>binocular</b> <b>head</b> {{mounted on a}} motion-averaging mast. This head provides images to a normalized correlation matcher, that intelligently selects {{what part of the}} image to process (saving time), and subsamples the images (again saving time) without subsampling disparities (which would reduce accuracy). The implementation has operated successfully during long-duration field exercises, processing streams of thousands of images. The dead reckoning approach employs encoders, inclinometers, a compass, and a turn-rate sensor to maintain the position and orientation of the rover as it traverses. The approach integrates classical odometry with inertial guidance. The implementation succeeds in the face of significant sensor noise by virtue of senso [...] ...|$|E
50|$|Owls are birds {{from the}} order Strigiformes, which {{includes}} about 200 species of mostly solitary and nocturnal {{birds of prey}} typified by an upright stance, a large, broad <b>head,</b> <b>binocular</b> vision, binaural hearing, sharp talons, and feathers adapted for silent flight. Exceptions include the diurnal northern hawk-owl and the gregarious burrowing owl.|$|R
50|$|Banded archerfish {{have large}} eyes, which, {{unlike many other}} fishes, are {{positioned}} for <b>binocular</b> vision. The <b>head</b> is slightly shorter than the body, with a distinctively pointed snout. Juveniles may be yellow-green to brown on the dorsal side and silvery on the ventral side. The juveniles' flanks are grey-green. Some banded archerfish have irregular yellow patches between their bands.|$|R
40|$|When visual {{behaviors}} are combined {{to provide a}} speci c functionality needed for a task, the combination is often based on heuristic rules. In this paper we showthat by adopting the Discrete Event Systems (DES) formalism for describing the interaction between visual behaviors {{it is possible to}} provide systems which have well de ned properties in terms of observability and controllability. The method is in particular suited for describing the coupling between action and perception. An introduction to the use of DES is provided and it is demonstrated how DES are used for modeling behaviors and controlling a mobile robot equipped with a <b>binocular</b> camera <b>head</b> and some additional sensors...|$|R
40|$|International audienceIn {{order for}} a <b>binocular</b> <b>head</b> to perform optimal 3 D tracking, it {{should be able to}} verge its cameras actively, while {{maintaining}} geometric calibration. In this work we introduce a calibration update procedure, which allows a robotic head to simultaneously fixate, track, and reconstruct a moving object in real-time. The update method is based on a mapping from motor-based to image-based estimates of the camera orientations, estimated in an offline stage. Following this, a fast online procedure is presented to update the calibration of an active binocular camera pair. The proposed approach is ideal for active vision applications because no image-processing is needed at runtime for the scope of calibrating the system or for maintaining the calibration parameters during camera vergence. We show that this homography-based technique allows an active binocular robot to fixate and track an object, whilst performing 3 D reconstruction concurrently in real-time...|$|E
40|$|This paper {{presents}} a stereo active vision system which performs tracking tasks on smoothly moving objects in complex backgrounds. Dynamic {{control of the}} vergence angle adapts the horopter geometry {{to the target position}} and allows to pick it up easily on the basis of stereoscopic disparity features. We introduce a novel vergence control strategy based on the computation of "virtual horopters" to track a target movement generating rapid changes of disparity. The control strategy is implemented on a <b>binocular</b> <b>head,</b> whose right and left pan angles are controlled independently. Experimental results of gaze holding on a smoothly moving target translating and rotating in a complex surrounding demonstrate the efficiency of the tracking system. 1 Introduction The importance of eye movement to biological visual systems is obvious. In contrast, controlled camera movement have played a small role in computer vision research, but are becoming increasingly recognized as important capabilities in [...] ...|$|E
40|$|This paper {{presents}} an active binocular tracking system using log-polar images with contributions {{in both the}} perceptual and control aspects. The control part {{is based on the}} visual servoing framework, including kinematics and dynamics. We introduce a fixation constraint that simplies the tracking problem by decoupling the visual kinematics and allowing to express system dynamics in image coordinates. Simple dynamic controllers are designed for each degree of freedom directly from image features. In the perceptual part, we use a space variant sensor that emphasizes the center of the visual field (log-polar geometry). We present a new disparity estimation algorithm for log-polar images and provide a theoretical analysis to illustrate the advantages of using space variant images. The overall system is implemented in the Medusa <b>binocular</b> <b>head</b> without any specific processing hardware. The use of log-polar images allows real-time performance (50 Hz). Tracking experiments are presented to [...] ...|$|E
40|$|Abstract – Robots that emulate {{biological}} visual systems must {{solve the}} perceptual problem of {{when and where}} to direct gaze. In this paper, a gaze control scheme for a specific <b>binocular</b> robot <b>head</b> is described and assessed. A well-known computational model of visual attention is used to find attractive target locations and a proportional-integral position control is used to drive pan and tilt servomotors of a dominant camera. Experiments demonstrate {{that the system is}} capable of tracking conspicuous moving targets in real-time (30 fps) in non-cluttered environments without any previous knowledge or strong assumptions. Addition of vergence control for the non-dominant camera is the next step towards a complete binocular control framework...|$|R
40|$|To {{provide insight}} into cloth {{perception}} and manipulation with an active binocular robotic vision system, we compiled a database of 80 stereo-pair colour images with corresponding horizontal and vertical disparity maps and mask annotations, for 3 D garment point cloud rendering has been created and released. The stereo-image garment database is part of research conducted under the EU-FP 7 Clothes Perception and Manipulation (CloPeMa) project and belongs to a wider database collection released through CloPeMa (www. clopema. eu). This database is based on 16 different off-the-shelve garments. Each garment has been imaged in five different pose configurations on the project's <b>binocular</b> robot <b>head.</b> A full copy of the database is made available for scientific research only at [URL] 7 pages, 6 figure, image databas...|$|R
40|$|A {{major goal}} for the {{realization}} {{of a new generation}} of intelligent robots is the capability of instructing work tasks by interactive demonstration. To make such a process efficient and convenient for the human user requires that both the robot and the user can establish and maintain a common focus of attention. We describe a hybrid architecture that combines neural networks and finite state machines into a flexible framework for controlling the behaviour of a vision based robot called GRAVIS-robot (Gestural Recognition Active VIsion System robot). It consists of a <b>binocular</b> camera <b>head,</b> a 6 DOF robot arm and a 9 DOF multifingered hand. We focus primarily on non-verbal communication based on gestural commands of a human instructor which will at a later stage be complemented by spoken instructions. ...|$|R
40|$|We {{present a}} stereo active vision system which {{performs}} tracking tasks on smoothly moving objects in complex backgrounds. Dynamic {{control of the}} camera vergence adapt the horopter geometry {{to the target position}} and allows to pick it up easily on the basis of stereoscopic disparity features. We introduce a novel vergence control strategy based on the computation of "virtual horopters" to track a target movement generating rapid changes of disparity. We then demonstrate the efficiency of the system with experimental results on a two degrees of freedom <b>binocular</b> <b>head</b> performing gaze fixation on a smoothly moving target translating and rotating in a complex surrounding. 1 Introduction The importance of eye movement to biological visual systems is obvious. In contrast, controlled camera movement have played a small role in computer vision research, but are becoming increasingly recognized as important capabilities in robotic visual perception (see, in particular the work of Ballard [1] an [...] ...|$|E
40|$|For mobile robots, {{the problem}} of {{interaction}} with simple objects in a semi-controlled environment is {{a rich source of}} challenging situations. In this paper we present a real experiment dealing with the design of a sequential task and its implications in the active nature of the perceptual process involved. In order to set up this experiment, it is required a non trivial set of functioning senso-motor behaviours. We build on this set to design and test a pallet picking task in which the robot has to locate, approach, obtain the pose and, finally, pick up the target. The only sensorial information available to the robot is its binocular vision system and its internal odometry. To carry out this task we have equipped a RobEx robot with a 1 dof forklift and a 4 dof’s <b>binocular</b> <b>head.</b> We present the conceptual and computational models and the results of the initial experiments in a real setup. ...|$|E
40|$|In this paper, we {{show how}} an active <b>binocular</b> <b>head,</b> the IIS head, {{can be easily}} {{calibrated}} with very high accuracy. Our calibration method can also be applied to many other binocular heads. In addition to the proposal and demonstration of a four-stage calibration process, there are three major contributions in this paper. First, we propose a MFL (Motorized-Focus Lens) camera model which assumes constant nominal extrinsic parameters. The advantage of having constant extrinsic parameters {{is to have a}} simple head/eye relation. Second, a calibration method for the MFL camera model is proposed in this paper, which separates the estimation of the image center and effective focal length from the estimation of the camera orientation and position. This separation has been proved to be crucial; otherwise, the estimates of camera parameters would be very noise-sensitive. Thirdly, we show that, once the parameters of the MFL camera model is calibrated, a nonlinear recursive least-square estimator [...] ...|$|E
40|$|This paper {{describes}} {{a camera and}} hand-eye calibration methodology for integrating an active <b>binocular</b> robot <b>head</b> within a dual-arm robot. For this purpose, we derive the forward kinematic model of our active robot head and describe our methodology for calibrating and integrating our robot head. This rigid calibration provides a closedform hand-to-eye solution. We then present an approach for updating dynamically camera external parameters for optimal 3 D reconstruction that are the foundation for robotic tasks such as grasping and manipulating rigid and deformable objects. We show from experimental results that our robot head achieves an overall sub millimetre accuracy of less than 0. 3 millimetres while recovering the 3 D structure of a scene. In addition, we report a comparative study between current RGBD cameras and our active stereo head within two dual-arm robotic testbeds that demonstrates the accuracy and portability of our proposed methodology...|$|R
40|$|In {{this article}} we {{describe}} a calibration procedure of a <b>binocular</b> camera <b>head</b> with two independent pan and tilt axes. For the field of computer vision the main benefit of the proposed method is the easy computation of the epipolar line in the second camera when selecting a pixel coordinate in the first {{with respect to the}} current commanded position of the two movable cameras. Photogrammetrists may be interested in the proposed unified calibration idea. For the calibration procedure itself no separate rotations of the respective axes and no fixation is required. To get reliable calibration data just a plane surface with known 2 D coordinates of distinguishable target points is needed. key words: active computer vision, calibration, epipolar geometry 1 Mr. Spiess is supported by the Austrian Science Foundation FWF under grant 11420 -OEMA. Spiess & Li: Kinematic Calibration and Online Computation of Epipolar Geometry 1 1 Introduction A binocular camera system usually comprises a [...] ...|$|R
40|$|This article {{presents}} a general approach for the active stereo tracking of multiple moving targets. The problem is formulated on the plane, where cameras are modeled as ”line scan cameras ” and targets {{are described as}} points with unconstrained motion. We propose to control the ac-tive system parameters {{in such a manner}} that the images of the targets in the two views are related by an homography. This homography is specified during the design stage and implicitly encodes the tracking behavior. It is shown that this formulation leads to an elegant geometric framework that enables to decide about the feasibility of a particular active tracking task. We apply it to prove that two cameras with rotation and zoom control, can track up to three mo-ving targets, while assuring that the image location of each target is the same for both views. In addition, the framework is also useful for devising tracking strategies and deriving the required control equations. This feature is illustrated through a real experiment on tracking two independent tar-gets using a <b>binocular</b> stereo <b>head.</b> 1...|$|R
40|$|This paper {{examines}} {{the problem of}} a moving robot tracking a moving object with its cameras, without requiring the ability to recognize the target to distinguish it from distracting surroundings. A novel aspect of the approach taken {{is the use of}} controlled camera movements to simplify the visual processing necessary to keep the cameras locked on the target. A gaze holding system implemented on a robot's <b>binocular</b> <b>head</b> demonstrates this approach. Even while the robot is moving, the cameras are able to track an object that rotates and moves in three dimensions. The central idea is that localizing attention in 3 -D space makes precategorical visual processing sufficient to hold gaze. Visual fixation can help separate the target object from distracting surroundings. Converged cameras produce a horopter (surface of zero stereo disparity) in the scene. Binocular features with no disparity can be located with a simple filter, showing the object's location in the image. Similarly, an object th [...] ...|$|E
40|$|In {{this paper}} a generic {{kinematic}} model for robot structure error analysis is built {{and then is}} extended to analyze an active vision system. An active vision system is a robot device for controlling the motion of cameras based on visual information. Because the models are derived from the Denavit-Hartenberg transformation matrix, differential changes for the transformation matrix and link parameters, and the fundamental algorithm for estimating depth using stereo cameras, they are generic {{and can be used}} for any robot system or for stereo active vision systems. Based on this model, we created a software tool which functions as a C++ class library. The primary advantage of using this tool is that we can estimate the kinematic error at the design stage instead of at the calibration stage, which is more complicated work, especially for an active vision system or a <b>binocular</b> <b>head.</b> Furthermore, we can estimate the robot pose error or depth estimation error given the manufacturing tolerances...|$|E
40|$|Abstract In {{order for}} a <b>binocular</b> <b>head</b> to perform optimal 3 D tracking, it {{should be able to}} verge its cameras actively, while {{maintaining}} geometric calibration. In this work we introduce a calibration update procedure, which allows a robotic head to simultaneously fixate, track, and reconstruct a moving object in real-time. The update method is based on a mapping from motor-based to image-based estimates of the camera orientations, estimated in an offline stage. Following this, a fast online procedure is presented to update the calibration of an active binocular camera pair. The proposed approach is ideal for active vision applications because no image-processing is needed at runtime for the scope of calibrating the system or for maintaining the calibration parameters during camera vergence. We show that this homography-based technique allows an active binocular robot to fixate and track an object, whilst performing 3 D reconstruction concurrently in real-time. Electronic supplementary material The online version of this article (doi: 10. 1007 /s 10514 - 012 - 9311 - 2...|$|E
40|$|AbstractWhen {{asked to}} look through a tube, young {{children}} (normal, strabismic, monocularly enucleated) place it between the eyes, while older children turn the head or shut one eye. We videotaped 174 children (normals and strabismics, 2 – 17 yr of age) and 16 normal adults {{to find out when}} and why head turn occurs. In learning to look with one eye, children progressed through a sequence of four responses, categorized by age or amount of <b>head</b> turn. <b>Binocular</b> children use <b>head</b> turn apparently to avoid diplopia, then, most learn to shut one eye. Adults, forced to use the “non-preferred” eye, revert to turning the head. Copyright © 1996 Elsevier Science Ltd...|$|R
40|$|In any {{measuring}} system the categorization of the error generation factors leads to simplification of complex error problems and to higher {{suppression of the}} error. In this paper we categorize, quantify and analyze the errors that affect a <b>binocular</b> active vision <b>head.</b> Simulations have been made and experimental results on a high resolution pan-tilt-vergence mechanism are also proposed. As a conclusion {{it can be said}} that the system performs optimal when it is initialized so that the two cameras are perfectly aligned and perpendicular to the baseline. Small variations in the vergence angle or small horizontal deviations of the principal point alters the measurement dramatically...|$|R
40|$|In {{order to}} render a high quality, {{versatile}} 3 D talking head, a stable, high frame rate AV {{data acquisition system}} is con-structed. It can capture 3 D position, surface orientation and albedo texture of the talking head video images along with the corresponding speech signals. The system consists of a com-puter controlled LED lighting subsystem; high speed stereo cameras; a microphone; and a computer for synchronous re-cording of multi-stream AV data. The visual image data col-lected is processed through a binocular photometric stereo 3 D reconstruction pipeline. The pipeline automatically segments out the face; computes the depth map with binocular stereo; computes the normal map with photometric stereo; generates albedo texture; and finally constructs a high-detailed 3 d model with depth and normal cues as constraints. By using the data collected with the built system, we can capture high quality dynamic facial performance, synchronized with the subject’s uttered speech. Index Terms: talking <b>head,</b> <b>binocular</b> photometric stereo, fa-cial performance captur...|$|R
