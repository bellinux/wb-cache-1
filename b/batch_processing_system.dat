34|10000|Public
5|$|While a {{graduate}} student and member of TMRC, Dennis introduced his students to the TX-0 on loan to MIT indefinitely from Lincoln Laboratory. In the spring of 1959, McCarthy taught the first course in programming that MIT offered to freshmen. Outside classes, Kotok, David Gross, Peter Samson, Robert A. Saunders and Robert A. Wagner, all friends from TMRC, reserved time on the TX-0. They {{were able to use}} the TX-0 as a personal, single-user tool rather than a <b>batch</b> <b>processing</b> <b>system,</b> thanks to Dennis, faculty advisors and John McKenzie, the operations manager.|$|E
2500|$|The hot {{end of a}} glassworks {{is where}} the molten glass is formed into glass products, {{beginning}} when the batch is fed into the furnace at a slow, controlled rate by the <b>batch</b> <b>processing</b> <b>system</b> (batch house). The furnaces are natural gas- or fuel oil-fired, and operate at temperatures up to [...] The temperature is limited only {{by the quality of}} the furnace’s superstructure material and by the glass composition. [...] Types of furnaces used in container glass making include 'end-port' (end-fired), 'side-port', and 'oxy-fuel'. [...] Typically, furnace [...] "size" [...] is classified by metric tons per day (MTPD) production capability.|$|E
50|$|A <b>batch</b> <b>processing</b> <b>system</b> uses {{spooling}} {{to maintain}} a queue of ready-to-run tasks, which can be started {{as soon as the}} system has the resources to process them.|$|E
50|$|BACHO-format {{transactions}} are primarily used in <b>batch</b> <b>processing</b> <b>systems</b> running on MVS mainframe computers.|$|R
50|$|Sometimes {{operational}} {{systems are}} referred to as operational databases, transaction <b>processing</b> <b>systems,</b> or online transaction <b>processing</b> <b>systems</b> (OLTP). However, the use of the last two terms as synonyms may be confusing, because operational <b>systems</b> can be <b>batch</b> <b>processing</b> <b>systems</b> as well.|$|R
5000|$|EXEC II is a <b>batch</b> <b>processing</b> {{operating}} <b>system</b> {{that supports}} a single job stream with concurrent spooling.|$|R
50|$|The SX-6 uses SUPER-UX, a Unix-like {{operating}} system developed by NEC. A SAN-based global file system (NEC's GFS) {{is available for}} a multinode installation. The default <b>batch</b> <b>processing</b> <b>system</b> is NQSII, but open source batch systems such as Sun Grid Engine are also supported.|$|E
50|$|OS4000 Rel 4 arrived around 1983, and {{upped the}} maximum number of user modules to 150 (again, mainly for the University College London Euclid system), {{together}} with an enhanced <b>Batch</b> <b>processing</b> <b>system.</b> It also included support for the GEC 4090 processor, which introduced a 32-bit addressing mode.|$|E
50|$|The initial versions, George 1 (for the ICT 1901, 1902 and 1903 machines) was {{a simple}} <b>batch</b> <b>processing</b> <b>system.</b> Job {{descriptions}} were read in from cards or paper tape, peripherals and magnetic tape files were dynamically allocated to the job which was then run, producing output on the line printer.|$|E
5000|$|Multi-user {{software}} is software that allows access by multiple users of a computer. Time-sharing systems are multi-user <b>systems.</b> Most <b>batch</b> <b>processing</b> <b>systems</b> for mainframe computers {{may also be}} considered [...] "multi-user", to avoid leaving the CPU idle while it waits for I/O operations to complete. However, the term [...] "multitasking" [...] {{is more common in}} this context.|$|R
50|$|The need of {{constant}} user interaction in interactive computing systems makes it different {{in many ways}} from <b>batch</b> <b>processing</b> <b>systems.</b> Thus different aspects of computing systems are significantly different for interactive computing systems {{and they have been}} focused on different research. The design of a different programming model has been discussed. Another article describes the importance of security and reliability in interactive computing.|$|R
50|$|EXEC I is a {{discontinued}} UNIVAC's original {{operating system}} {{developed for the}} UNIVAC 1107 in 1962. EXEC I is a <b>batch</b> <b>processing</b> operating <b>system</b> that supportes multiprogramming.|$|R
50|$|The Exec is {{at heart}} a real time, multi-threaded <b>batch</b> <b>processing</b> <b>system.</b> Everything {{has been built}} around that model. The Exec itself is largely {{structured}} as a real time program. Functions that are performed as Services in Windows or Daemons in Linux and UNIX are implemented as either activities within the Exec or as batch programs that are always running in the background.|$|E
5000|$|He {{headed the}} team which wrote control {{software}} for ballistic missile defense, using the computers M-40 and M-50. For this research, Korolev was awarded doctorate in 1967.His team produced the first operating system for BESM-6, a <b>batch</b> <b>processing</b> <b>system</b> later named [...] "Dispatcher-68". In 1981 Korolev was elected a corresponding {{member of the}} USSR Academy of Sciences at the Department of Mathematics.|$|E
50|$|George 1 was {{a simple}} <b>batch</b> <b>processing</b> <b>system,</b> Job {{descriptions}} were read from cards or paper tape which controlled the loading and running of programs, either loaded from cards or paper tape or magnetic tape. The job control language allowed definition of the peripherals and files to be used and handling of exception conditions. The job description would be checked for errors before the job was run. George used the trusted program facilities provided by executive to run the user programs.|$|E
50|$|DISC <b>systems</b> are {{primarily}} <b>batch</b> <b>processing</b> <b>systems</b> designed for high throughput. They execute several jobs per analytics, with several tasks per job. The overall {{number of operators}} executing {{at any time in}} a cluster can range from hundreds to thousands depending on the cluster size. Lineage capture forthese systems must be able scale to both large volumes of data and numerous operators to avoid being a bottleneck for the DISC analytics.|$|R
50|$|Long-term {{scheduling}} is {{also important}} in large-scale <b>systems</b> such as <b>batch</b> <b>processing</b> <b>systems,</b> computer clusters, supercomputers, and render farms. For example, in concurrent systems, coscheduling of interacting processes is often required {{to prevent them from}} blocking due to waiting on each other. In these cases, special-purpose job scheduler software is typically used to assist these functions, in addition to any underlying admission scheduling support in the operating system.|$|R
5000|$|Classic Operating Systems: From <b>Batch</b> <b>Processing</b> to Distributed <b>Systems</b> (editor, 2001, [...] ) ...|$|R
50|$|While a {{graduate}} student and member of TMRC, Dennis introduced his students to the TX-0 on loan to MIT indefinitely from Lincoln Laboratory. In the spring of 1959, McCarthy taught the first course in programming that MIT offered to freshmen. Outside classes, Kotok, David Gross, Peter Samson, Robert A. Saunders and Robert A. Wagner, all friends from TMRC, reserved time on the TX-0. They {{were able to use}} the TX-0 as a personal, single-user tool rather than a <b>batch</b> <b>processing</b> <b>system,</b> thanks to Dennis, faculty advisors and John McKenzie, the operations manager.|$|E
5000|$|Exec 8 was {{primarily}} a <b>batch</b> <b>processing</b> <b>system</b> that gave applications (called [...] "tasks") very fine control of CPU scheduling priority for its threads (called [...] "activities"). Processor switching was preemptive, with higher priority threads gaining control of the processor currently running the lowest priority thread of any program. Except in realtime systems, even the lowest priority tasks got some processor time. It was a multiprogramming and multiprocessing operating system with fully symmetric processor management. A test-and-set instruction built into the hardware allowed very efficient and fine-grained locking both within the OS and within multi-threaded applications.|$|E
5000|$|The hot {{end of a}} glassworks {{is where}} the molten glass is formed into glass products, {{beginning}} when the batch is fed into the furnace at a slow, controlled rate by the <b>batch</b> <b>processing</b> <b>system</b> (batch house). The furnaces are natural gas- or fuel oil-fired, and operate at temperatures up to 1,575 C. The temperature is limited only {{by the quality of}} the furnace’s superstructure material and by the glass composition. Types of furnaces used in container glass making include 'end-port' (end-fired), 'side-port', and 'oxy-fuel'. Typically, furnace [...] "size" [...] is classified by metric tons per day (MTPD) production capability.|$|E
5000|$|A <b>batch</b> {{transaction}} <b>processing</b> <b>system,</b> which accepts {{large volumes}} of homogeneous transactions, processes it (possibly updating a database), and produces output such as reports or computations.|$|R
50|$|A <b>batch</b> <b>processing</b> {{operating}} <b>system</b> {{that controls}} execution of CMS-2 components and user jobs {{run on the}} CP-642 computer. It provides input/output, software library facilities and debugging tools. Job accounting is also provided.|$|R
40|$|There {{are several}} {{generally}} accepted suppositions concerning {{the cost and}} benefits of real-time information systems. These suppositions expect that real-time systems can generate sufficient benefits to offset the higher costs of processing relative to traditional <b>batch</b> <b>processing</b> <b>systems.</b> The objective {{of this study was}} to examine in actual operating environments the generally accepted notions of costs and benefits of real-time systems that were supplied by a computer utility. These suppositions were examined by analyzing the empirical data of six matched firms. The cost and benefits of the information systems of three companies which used a computer utility real-time system were compared to the costs and benefits of three similar companies which used private <b>batch</b> <b>processing</b> <b>systems.</b> The findings of the research were the reverse of expectations. The data analysis strongly suggested that the real-time information did not produce any significant information benefits, but that the real-time data processing costs were less than the comparative <b>batch</b> data <b>processing</b> costs. The primary reason the results differed from expectations is that the real-time information was not fruitfully used. The findings of the study suggest that real-time information system benefits are not gained automatically, but can be achieved only if the systems are meaningfully integrated into the management process. ...|$|R
50|$|Several {{versions}} {{were produced}} at Dartmouth over the years, all implemented as compile and go compilers, {{unlike many of}} the versions of the language implemented elsewhere, which were interpreters. The first compiler was produced before the time-sharing system was ready. Known as CardBASIC, it was intended for the standard card-reader based <b>batch</b> <b>processing</b> <b>system.</b> Like all the following versions, it was implemented {{by a team of}} undergraduate programmers working under the direction of Kemeny and Kurtz. The first interactive version was made available to general users in June 1964; the second in October, 1964; the third in 1966; the fourth in 1969; the fifth in 1970; the sixth in 1971; and the seventh in 1979.|$|E
50|$|Before the mid-1960s, {{the only}} {{computers}} were huge mainframe computers. Users submitted jobs (calculations or other requests) on punched cards or similar media to specialist computer operators. The computer stored these, then used a <b>batch</b> <b>processing</b> <b>system</b> {{to run this}} queue of jobs one after another, allowing very high levels of utilization of these expensive machines. As the performance of computing hardware rose through the 1960s, multi-processing was developed. This allowed a mix of batch jobs to be run together, but the real revolution was the development of time-sharing. Time-sharing allowed multiple remote interactive users to share use of the computer, interacting with the computer from computer terminals with keyboards and teletype printers, and later display screens, {{in much the same}} way as desktop computers or personal computers would be used later.|$|E
50|$|SUMITS, a UNIVAC 1110 {{mainframe}} {{was installed}} at the MECC facility at 1925 Sather, address later changed to 2520 Broadway Drive, next to Highway 280. A sturdy industrial building originally used for electrical maintenance, {{part of the building}} was already occupied by the University of Minnesota's Lauderdale computing facility. SUMITS was a <b>batch</b> <b>processing</b> <b>system,</b> however, not time-sharing, and its performance failed to meet the terms of the contract. In 1977 it was replaced with a Control Data Corporation Cyber 73 mainframe, known as the MECC Timesharing System (MTS). It became the largest such system for education in the world, with up to 448 simultaneous connections from up to 2000 terminals throughout the state, most of them Teletype Model 33 teleprinters, connected at 110 and 300 baud through telephones by using acoustically coupled modems. After several years most of the phone lines were replaced with direct circuits to schools across the state.|$|E
40|$|Using {{more than}} one Linux machine • Next time: some more shell {{scripting}} and any other remaining issues CS 108 Spring 2010 2 Distributed Computing Distributed computing {{is the use of}} multiple computational engines to perform a single task. Distributed computing systems can be differentiated by the degree of coupling among computational engines: • Parallel – Multiple CPUs connected via a high speed bus. • Cluster – Multiple computers connected via a high speed network. • Grid – Multiple computers connected via a low speed network. • Batch – Multiple computers not utilizing their interconnections, i. e. running separate instances of a program. CS 108 Spring 2010 3 <b>Batch</b> <b>Processing</b> <b>Systems</b> <b>Batch</b> <b>processing</b> <b>systems</b> are among the simplest distributed computing systems. Their primary benefits are: • Providing users a uniform way to execute multiple instances of a program across multiple computers, thus utilizing greater computational resources and reducing idle cycles. • Providing greater administrative control of resources. • Enforcing “fair ” resource distribution among jobs. CS 108 Spring 2010 4 Condor “Instead of running a CPU-intensive job in the background on their own workstation, Condor finds an available machine on the network and begins running the job on that machine. ...|$|R
50|$|Systems {{with little}} user interaction, such as <b>batch</b> <b>processing</b> or <b>systems</b> that mostly do calculations, benefit little from prototyping. Sometimes, the coding needed {{to perform the}} system {{functions}} may be too intensive and the potential gains that prototyping could provide are too small.|$|R
5000|$|The {{evolution}} of operating systems, In Classic Operating Systems: From <b>Batch</b> <b>Processing</b> to Distributed <b>Systems,</b> P. Brinch Hansen, Ed., Springer-Verlag, New York (2001) ...|$|R
3000|$|Launches all the {{processing}} modules as separate processes (single-core or MPI) and {{keeps track of}} the jobs started. This {{can be done with}} a <b>batch</b> <b>processing</b> <b>system</b> such as SLURM (or any other queuing system) or by launching separate python processes; [...]...|$|E
40|$|In this research, the {{production}} planning and scheduling problems in unison with detailed sequencing activities are addressed {{for a single}} stage, multi-product batch chemical plant in a parallel machines environment. An integrated framework for production planning and scheduling of a single stage multi-product <b>batch</b> <b>processing</b> <b>system</b> has been developed...|$|E
40|$|The {{development}} {{over several}} years of a computer system for hospital bacteriology reporting is described. The system was developed from a manual method to a punch-card <b>batch</b> <b>processing</b> <b>system</b> and finally to a real-time on-line system. The value of the system to the clinical departments and laboratory is discussed...|$|E
40|$|Batching jobs in a {{manufacturing}} {{system is a}} very common policy in most industries. Main reasons for batching are avoidance of setups and/or facilitation of material handling. <b>Batch</b> <b>processing</b> <b>systems</b> often consist of multiple machines of different types for the range and volumes of products {{that have to be}} handled. Building on earlier research in aircraft industry, where the process of hardening synthetic aircraft parts was studied, we discuss a new heuristic for the dynamic scheduling of these types of systems. It is shown by an extensive series of simulation experiments that the new heuristic outperforms existing heuristics for most system configurations. ...|$|R
40|$|The author {{looks back}} on the first half century of {{operating}} systems and selects his favorite papers on classic operating systems. These papers span {{the entire history of}} the field from the <b>batch</b> <b>processing</b> <b>systems</b> of the 1950 s to the distributed systems of the 1990 s. Each paper describes an operating system that combines significant ideas in an elegant way. Most of them were written by the pioneers who had the visions and the drive to make them work. The author summarizes each paper and concludes that operating systems are based on a surprisingly small number of ideas of permanent interest...|$|R
40|$|The {{reaction}} of ilmenite with hydrogen to produce {{water has been}} studied experimentally in order {{to evaluate the effectiveness}} of using a cold trap to improve yields in a continuous flow process. Yields were enhanced, but not to the degree observed in <b>batch</b> <b>processing</b> <b>systems.</b> The terrestrial simulant used in these studies contained traces of iron sulfide, which released H 2 S during processing with a deleterious effect on several components of the test system. More sophisticated testing should be undertaken to obtain kinetic data and attention given to the removal of sulfides in the pre-process beneficiation...|$|R
