249|529|Public
25|$|Since volumes are {{presented}} as block devices, {{they can also be}} formatted with any other file system, to add ZFS features to that file system, although this is not usual practice. For example, a ZFS volume can be created, and then the <b>block</b> <b>device</b> it presents can be partitioned and formatted with a file system such as ext4 or NTFS. This can be done either locally or over a network (using iSCSI or similar). The resulting file system will be accessible as normal, but will also gain ZFS benefits such as data resilience, data integrity/.scrubbing, snapshots, and additional option for data compression.|$|E
25|$|Various {{optimizations}} and tweaks to {{the implementation}} of FAT file system drivers, <b>block</b> <b>device</b> drivers and disk tools have been devised to overcome most of the performance bottlenecks in the file system's inherent design without having to change the layout of the on-disk structures. They can be divided into on-line and off-line methods and work by trying to avoid fragmentation in the file system in the first place, deploying methods to better cope with existing fragmentation, and by reordering and optimizing the on-disk structures. With optimizations in place, the performance on FAT volumes can often reach that of more sophisticated file systems in practical scenarios, {{while at the same time}} retaining the advantage of being accessible even on very small or old systems.|$|E
25|$|While {{the design}} of the FAT file system does not cause any {{organizational}} overhead in disk structures or reduce the amount of free storage space with increased amounts of fragmentation, as it occurs with external fragmentation, the time required to read and write fragmented files will increase as the operating system will have to follow the cluster chains in the FAT (with parts having to be loaded into memory first in particular on large volumes) and read the corresponding data physically scattered over the whole medium reducing chances for the low-level <b>block</b> <b>device</b> driver to perform multi-sector disk I/O or initiate larger DMA transfers, thereby effectively increasing I/O protocol overhead as well as arm movement and head settle times inside the disk drive. Also, file operations will become slower with growing fragmentation as it takes increasingly longer for the operating system to find files or free clusters.|$|E
50|$|SOS has {{two types}} of devices it {{communicates}} with via their device drivers: character <b>devices</b> and <b>block</b> <b>devices.</b> Examples of SOS character devices are keyboards and serial ports. Disk drives are typical <b>block</b> <b>devices.</b> <b>Block</b> <b>devices</b> can read or write one or more 512-byte blocks at a time; character devices can read or write single characters at a time.|$|R
50|$|The device mapper is a {{framework}} {{provided by the}} Linux kernel for mapping physical <b>block</b> <b>devices</b> onto higher-level virtual <b>block</b> <b>devices.</b> It forms the foundation of LVM2, software RAIDs and dm-crypt disk encryption, and offers additional features such as file system snapshots.|$|R
5000|$|Kernel - device-mapper - block {{subsystem}} {{that provides}} layering mechanism for <b>block</b> <b>devices.</b>|$|R
2500|$|Some of the {{perceived}} problems with fragmentation of FAT file systems also result from performance limitations of the underlying <b>block</b> <b>device</b> drivers, which becomes more visible the lesser memory is available for sector buffering and track blocking/deblocking: ...|$|E
2500|$|If bit 14 (on FAT16) or bit 26 (on FAT32) is cleared, the {{operating}} system has encountered disk I/O errors on startup, a possible indication for bad sectors. Operating systems aware of this extension will interpret this as a recommendation {{to carry out a}} surface scan (SCANDISK) on the next boot. (A similar set of bitflags exists in the FAT12/FAT16 EBPB at offset 0x1A or the FAT32 EBPB at offset 0x36. While the cluster 1 entry can be accessed by file system drivers once they have mounted the volume, the EBPB entry is available even when the volume is not mounted and thus easier to use by disk <b>block</b> <b>device</b> drivers or partitioning tools.) ...|$|E
2500|$|A pool {{can also}} contain volumes (also known as zvols), {{which can be}} used as block storage devices by other systems. An example of a volume would be an iSCSI or Fibre Channel target for another system, used to create NAS, a SAN, or any other ZFS-backed raw block storage capability. The volume will be seen by other systems as a bare storage device which they can use as they like. Capabilities such as snapshots, redundancy, [...] "scrubbing" [...] (data {{integrity}} and repair checks), deduplication, compression, cache usage, and replication are operational but not exposed to the remote system, which [...] "sees" [...] only a bare file storage device. Because ZFS does not create a file storage system on the <b>block</b> <b>device</b> or control how the storage space is used, it cannot create nested ZFS datasets or volumes within a volume.|$|E
5000|$|DM Multipath {{provides}} I/O failover and load-balancing of <b>block</b> <b>devices</b> {{within the}} Linux kernel ...|$|R
40|$|In {{this paper}} we propose a {{computational}} procedure to evaluate the performances of inductive <b>blocking</b> <b>devices</b> used for the mitigation of indirect lightning effects on electrical and electronic equipment, with special relation to the avionic environment. The non linear behavior of the <b>blocking</b> <b>devices</b> is simulated using a FEM scheme in time domain. Computations and experimental results are compared and discussed...|$|R
5000|$|Unix makes a {{distinction}} between character <b>devices</b> and <b>block</b> <b>devices.</b> The distinction is roughly as follows: ...|$|R
50|$|Ceph’s {{object storage}} system {{allows users to}} mount Ceph as a thin-provisioned <b>block</b> <b>device.</b> When an {{application}} writes data to Ceph using a <b>block</b> <b>device,</b> Ceph automatically stripes and replicates the data across the cluster. Ceph's RADOS <b>Block</b> <b>Device</b> (RBD) also integrates with Kernel-based Virtual Machines (KVMs).|$|E
50|$|JBD, or {{journaling}} <b>block</b> <b>device,</b> is {{a generic}} <b>block</b> <b>device</b> journaling layer in the Linux kernel written by Stephen C. Tweedie from Red Hat.|$|E
5000|$|... iSCSI: The [...] "target-utils" [...] iscsi {{package on}} many GNU/Linux distributions. The tgtd can {{configure}} the backing storage of a LUN {{to be any}} <b>block</b> <b>device</b> (disk, partition, etc.). This has widest adoption amongst IP-based <b>block</b> <b>device</b> presentation protocols.|$|E
2500|$|Historically, the {{management}} of stored data has involved two aspects — the physical management of <b>block</b> <b>devices</b> [...] such as hard drives and SD cards, and devices such as RAID controllers that present a logical single device based upon multiple physical devices (often undertaken by a volume manager, array manager, or suitable device driver), and {{the management}} of files stored as logical units on these logical <b>block</b> <b>devices</b> (a file system).|$|R
5000|$|... dm-cache is a {{component}} (more specifically, a target) of the Linux kernel's device mapper, {{which is a}} framework for mapping <b>block</b> <b>devices</b> onto higher-level virtual <b>block</b> <b>devices.</b> It allows one or more fast storage devices, such as flash-based solid-state drives (SSDs), {{to act as a}} cache for one or more slower storage devices such as hard disk drives (HDDs); this effectively creates hybrid volumes and provides secondary storage performance improvements.|$|R
5000|$|Historically, the {{management}} of stored data has involved two aspects [...] - [...] the physical management of <b>block</b> <b>devices</b> such as hard drives and SD cards, and devices such as RAID controllers that present a logical single device based upon multiple physical devices (often undertaken by a volume manager, array manager, or suitable device driver), and {{the management}} of files stored as logical units on these logical <b>block</b> <b>devices</b> (a file system).|$|R
5000|$|Mount-able volumes. Bind mountpoint, filesystem, and <b>block</b> <b>device</b> driver.|$|E
50|$|Device mapper {{works by}} passing {{data from a}} virtual <b>block</b> <b>device,</b> which is {{provided}} by the device mapper itself, to another <b>block</b> <b>device.</b> Data can be also modified in transition, which is performed, for example, in the case of device mapper providing disk encryption or simulation of unreliable hardware behavior.|$|E
50|$|Network <b>block</b> <b>device</b> servers are {{typically}} implemented as a userspace program {{running on a}} general-purpose computer. All of the function specific to network <b>block</b> <b>device</b> servers can reside in a userspace process because the process communicates with the client via conventional sockets and accesses the storage via a conventional file system interface.|$|E
5000|$|... {{a list of}} {{character}} and <b>block</b> <b>devices</b> sorted by device ID but giving the {{major part of the}} [...] name too ...|$|R
50|$|Note: In Linux 2.4 and earlier, <b>block</b> <b>devices</b> {{were limited}} to 2 TiB, {{limiting}} the maximum size of a partition, regardless of block size.|$|R
5000|$|Examples of [...] "abstractions" [...] on a PC include video input, printers, {{audio input}} and output, <b>block</b> <b>devices</b> (e.g. hard disk drives or USB flash drive), etc.|$|R
5000|$|Linux: The Journaling <b>Block</b> <b>Device</b> (Kedar Sovani, KernelTrap, June 20, 2006) ...|$|E
5000|$|... linear maps a {{continuous}} range of blocks onto another <b>block</b> <b>device</b> ...|$|E
5000|$|Paravirtualized Xen devices: <b>block</b> <b>device,</b> network card, console, framebuffer {{and input}} device ...|$|E
5000|$|... the header: {{the set of}} {{elements}} (anchor plate, <b>blocking</b> <b>device,</b> etc.) that transmit the traction strength of the anchor to the anchored structure or to the rock ...|$|R
50|$|The {{compressed}} loop device (cloop) is {{a module}} for the Linux kernel. It adds support for transparently decompressed, read-only <b>block</b> <b>devices.</b> It {{is not a}} compressed file system.|$|R
50|$|The ScaleIO {{architecture}} {{is built on}} two components: a data client and a data server. The ScaleIO Data Client (SDC) is a lightweight device driver situated in each host whose application or file system requires access to the ScaleIO virtual SAN <b>block</b> <b>devices.</b> The SDC exposes <b>block</b> <b>devices</b> representing the ScaleIO volumes that are currently mapped to that host. The SDCs maintain a small in-memory map, being able to maintain mapping of petabytes of data with just megabytes of RAM. The inter-node protocol used by SDCs is simpler than iSCSI and uses fewer network resources.|$|R
5000|$|... {{in case of}} a <b>block</b> <b>device</b> systemd-udevd notifies , and [...] and [...]|$|E
5000|$|Global network <b>block</b> <b>device</b> (GNBD) fencing which {{disables}} {{access to}} the GNBD server ...|$|E
5000|$|DRBD: Distributed Replicated <b>Block</b> <b>Device</b> is a {{distributed}} {{storage system}} for the Linux platform ...|$|E
50|$|In the 2.6-series of the Linux Kernel, the LVM is {{implemented}} {{in terms of}} the device mapper, a simple block-level scheme for creating virtual <b>block</b> <b>devices</b> and mapping their contents onto other <b>block</b> <b>devices.</b> This minimizes the amount of relatively hard-to-debug kernel code needed to implement the LVM. It also allows its I/O redirection services to be shared with other volume managers (such as EVMS). Any LVM-specific code is pushed out into its user-space tools, which merely manipulate these mappings and reconstruct their state from on-disk metadata upon each invocation.|$|R
50|$|Some {{relational}} databases {{can also}} be deployed on mass storage devices without an intermediate file system or storage manager. Oracle and MySQL, for example, can store table data directly on raw <b>block</b> <b>devices.</b>|$|R
5000|$|... although, for example, disk {{partitions}} {{may have}} both character devices that provide unbuffered random access to blocks on the partition and <b>block</b> <b>devices</b> that provide buffered random access to blocks on the partition.|$|R
