83|116|Public
5000|$|Asymptotic <b>Bayes</b> <b>analysis</b> for {{the finite}} horizon one armed bandit problem, with A. Burnetas in [...] "Probability in the Engineering and Informational Sciences", Vol. 17(1), 2003.|$|E
50|$|Joods Actueel publishes in July 2016 {{an updated}} {{document}} whereby it states that their previous analysis {{was confirmed by}} CHUV. According to them, the conclusions that are based only on <b>Bayes</b> <b>analysis</b> are not valid as they are not documented with figures. It also reminds juridical errors based on such method as the case of Sally Clark.|$|E
50|$|PBA {{belongs to}} a class of methods that use imprecise probabilities to {{simultaneously}} represent aleatoric and epistemic uncertainties. PBA is a generalization of both interval analysis and probabilistic convolution such as is commonly implemented with Monte Carlo simulation. PBA is also closely related to robust <b>Bayes</b> <b>analysis,</b> which is sometimes called Bayesian sensitivity analysis. PBA is an alternative to second-order Monte Carlo simulation.|$|E
40|$|Abstract: Objective: In this paper, we {{have done}} <b>Bayes</b> Discriminant <b>analysis</b> to EEG data of {{experiment}} objects which are recorded impersonally {{come up with a}} relatively accurate method used in feature extraction and classification decisions. Methods: In accordance with the strength of wave, the head electrodes are divided into four species. In use of part of 21 electrodes EEG data of 63 people, {{we have done}} <b>Bayes</b> Discriminant <b>analysis</b> to EEG data of six objects. Results In use of part of EEG data of 63 people, we have done <b>Bayes</b> Discriminant <b>analysis,</b> the electrode classification accuracy rates is 64. 4 %. Conclusions: Bayes Discriminant has higher prediction accuracy, EEG features (mainly wave) extract more accurate. Bayes Discriminant would be better applied to the feature extraction and classification decisions of EEG data...|$|R
40|$|The paper recals the MCMC methods, {{namely the}} Gibbs {{algorithm}}, the Metropolis [...] Hastings algorithm and variants used for solution of optimization problems, namely the simulated annealing. The {{objective is to}} describe the schemes of the algorithms, to recall their theoretical foundation, and to show their use both in <b>Bayes</b> data <b>analysis</b> and in randomized optimization problem...|$|R
50|$|The {{most widely}} used {{learning}} algorithms are Support Vector Machines, linear regression, logistic regression, naive <b>Bayes,</b> linear discriminant <b>analysis,</b> decision trees, k-nearest neighbor algorithm, and Neural Networks (Multilayer perceptron).|$|R
50|$|There {{are several}} ways to design and conduct a robust <b>Bayes</b> <b>analysis,</b> {{including}} the use of (i) parametric conjugate families of distributions, (ii) parametric but non-conjugate families, (iii) density-ratio (bounded density distributions), (iv) ε-contamination, mixture, quantile classes, etc., and (v) bounds on cumulative distributions. Although calculating the solutions to robust Bayesian problems can, in some cases, be computationally intensive, there are several special cases in which the requisite calculations are, or can be made, straightforward.|$|E
50|$|He {{has made}} many {{important}} contributions to {{many areas of}} statistics. Efron's work has spanned both theoretical and applied topics, including empirical <b>Bayes</b> <b>analysis</b> (with Carl Morris), applications of differential geometry to statistical inference, the analysis of survival data, and inference for microarray gene expression data. He {{is the author of}} a classic monograph, The Jackknife, the Bootstrap and Other Resampling Plans (1982) and has also co-authored (with R. Tibshirani) the text An Introduction to the Bootstrap (1994).|$|E
5000|$|Clark {{was tried}} at Chester Crown Court, before Mr Justice Harrison and a jury. The prosecution, led by Robin Spencer QC, was {{controversial}} {{due to the}} involvement of the paediatrician Professor Sir Roy Meadow, former Professor of Paediatrics at the University of Leeds, who testified based on <b>Bayes</b> <b>analysis</b> at Clark's trial that the chance of two children from an affluent family suffering cot death was 1 in 73 million. He likened the probability to the chances of backing an 80-1 outsider in the Grand National four years running, and winning each time. Unable to recover from the effects of her conviction and imprisonment, she was found dead at her home in 2007 as a result of acute alcohol intoxication.|$|E
40|$|We {{reconstruct}} {{recent work}} on macrosocial stress (Chou, Parmar, & Galinsky, 2016) {{as if it}} were an instance of a research strategy that tests point-alternative hypotheses within a full-fledged research program. Because this strategy is free of various deficits that beset dominant strategies (e. g., meta-analysis, <b>Bayes</b> factor <b>analysis),</b> our article demonstrates one way in which the confidence crisis may be overcome...|$|R
40|$|The {{discrete}} skewed Laplace {{distribution is}} a flexible distribution with integer domain and simple closed form {{that can be}} applied to model count data. Parameters are estimated under empirical <b>Bayes</b> (EB) <b>analysis</b> and comparison are made between the Bayesian parameter estimation and classical parameter estimation, i. e. the maximum likelihood (ML) approach. The results show that the Bayesian parameter estimations are preferable...|$|R
40|$|<b>Bayes</b> linear <b>analysis</b> and {{approximate}} Bayesian computation (ABC) are techniques {{commonly used}} in the Bayesian analysis of complex models. In this article we connect these ideas by demonstrating that regression-adjustment ABC algorithms produce samples for which first and second order moment summaries approximate adjusted expectation and variance for a <b>Bayes</b> linear <b>analysis.</b> This gives regression-adjustment methods a useful interpretation and role in exploratory analysis in high-dimensional problems. As a result, we propose a new method for combining high-dimensional, regression-adjustment ABC with lower-dimensional approaches (such as using MCMC for ABC). This method first obtains a rough estimate of the joint posterior via regression-adjustment ABC, and then estimates each univariate marginal posterior distribution separately in a lower-dimensional analysis. The marginal distributions of the initial estimate are then modified to equal the separately estimated marginals, thereby providing an improved estimate of the joint posterior. We illustrate this method with several examples. Supplementary materials for this article are available online. Comment: To appear in Journal of Computational and Graphical Statistic...|$|R
50|$|C-boxes {{are closely}} related to several other concepts. They are {{comparable}} to bootstrap distributions, and are imprecise generalizations of traditional confidence distributions such as Student's t-distribution. Like it, c-boxes encode frequentist confidence intervals for parameters of interest at every confidence level. They are analogous to Bayesian posterior distributions in that they characterize the inferential uncertainty about statistical parameters estimated from sparse or imprecise sample data, but they can have a purely frequentist interpretation that makes them useful in engineering because they offer a guarantee of statistical performance through repeated use. In the case of the Bernoulli or binomial rate parameter, the c-box is mathematically equivalent to Walley's imprecise beta model with the parameter s=1, which is a special case of the imprecise Dirichlet process, a central idea in robust <b>Bayes</b> <b>analysis.</b>|$|E
5000|$|P-boxes {{serve the}} same role for random {{variables}} that upper and lower probabilities serve for events. In robust <b>Bayes</b> <b>analysis</b> a p-box {{is also known as}} a distribution band. [...] A p-box can be constructed as a closed neighborhood of a distribution F ∈ &#x1D53B; under the Kolmogorov, Lévy or Wasserstein metric. A p-box is a crude but computationally convenient kind of credal set. Whereas a credal set is defined solely in terms of the constraint F as a convex set of distributions (which automatically determine , F, m, and v, but are often very difficult to compute with), a p-box usually has a loosely constraining specification of F, or even no constraint so that F = &#x1D53B;. Calculations with p-boxes, unlike credal sets, are often quite efficient, and algorithms for all standard mathematical functions are known.|$|E
40|$|Abstract Background An {{important}} goal of whole-genome studies concerned with {{single nucleotide polymorphisms}} (SNPs) is the identification of SNPs associated with a covariate of interest such as the case-control status or the type of cancer. Since these studies often comprise the genotypes {{of hundreds of thousands}} of SNPs, methods are required that can cope with the corresponding multiple testing problem. For the analysis of gene expression data, approaches such as the empirical <b>Bayes</b> <b>analysis</b> of microarrays have been developed particularly for the detection of genes associated with the response. However, the empirical <b>Bayes</b> <b>analysis</b> of microarrays has only been suggested for binary responses when considering expression values, i. e. continuous predictors. Results In this paper, we propose a modification of this empirical <b>Bayes</b> <b>analysis</b> that can be used to analyze high-dimensional categorical SNP data. This approach along with a generalized version of the original empirical Bayes method are available in the R package siggenes version 1. 10. 0 and later that can be downloaded from [URL]. Conclusion As applications to two subsets of the HapMap data show, the empirical <b>Bayes</b> <b>analysis</b> of microarrays cannot only be used to analyze continuous gene expression data, but also be applied to categorical SNP data, where the response is not restricted to be binary. In association studies in which typically several ten to a few hundred SNPs are considered, our approach can furthermore be employed to test interactions of SNPs. Moreover, the posterior probabilities resulting from the empirical <b>Bayes</b> <b>analysis</b> of (prespecified) interactions/genotypes can also be used to quantify the importance of these interactions. </p...|$|E
50|$|To {{conduct a}} <b>Bayes</b> linear <b>analysis</b> it is {{necessary}} to identify some values that you expect to know shortly by making measurements D and some future value which you would like to know B. Here D refers to a vector containing data and B to a vector containing quantities you would like to predict. For the following example B and D are taken to be two-dimensional vectors i.e.|$|R
40|$|FIRST BAYES is a Microsoft Windows based {{package to}} assist in {{teaching}} elementary Bayesian statistics. As a Windows program, it is particularly user-friendly, and students can pick up quickly how to use it. First <b>Bayes</b> includes <b>analysis</b> of simple one-parameter models (binomial or Poisson data or normal data with known variance), using essentially arbitrary priors. A range of summaries and plots of prior, posterior and predictive distributions are available. First <b>Bayes</b> also includes <b>analysis</b> of simple linear models (one or more normal samples with common unknown variance, simple linear regression), using conventional improper priors. Summaries as above for posterior marginal densities or predictive densities are available. The regression analysis includes scatter and residual plots. All plots can be resized or printed. They and other summaries are automatically updated if any details of prior or data are changed. Some simple datasets are provided and others may be created in First Bayes. The author is Tony O'Hagan, University of Nottingham, UK. ...|$|R
40|$|Imprecision arises {{naturally}} {{in the context}} of computer models and their relation to reality. An imprecise treatment of general computer models is presented, illustrated with an analysis of a complex galaxy formation simulation known as Galform. The analysis involves several different types of uncertainty, one of which (the Model Discrepancy) comes directly from expert elicitation regarding the deficiencies of the model. The Model Discrepancy is therefore treated within an Imprecise framework to reflect more accurately the beliefs of the expert concerning the discrepancy between the model and reality. Due to the conceptual complexity and computationally intensive nature of such a Bayesian imprecise uncertainty <b>analysis,</b> <b>Bayes</b> Linear Methodology is employed which requires consideration of only expectations and variances of all uncertain quantities. Therefore incorporating an Imprecise treatment within a <b>Bayes</b> Linear <b>analysis</b> is shown to be relatively straightforward. The impact of an imprecise assessment on the input space of the model is determined through the use of an Implausibility measure...|$|R
40|$|<b>Bayes</b> <b>analysis</b> of {{the normal}} model has been {{thoroughly}} investigated by numerous statisticians and reported in the literature. The explicit form of the Bayes estimators under LINEX loss will be derived, {{which has not been}} available in the literature since the estimators are functions of the moment generating function of the t-distribution. [URL]...|$|E
40|$|HPLC of {{amino acids}} and {{riboflavin}} in apple juices clarified {{by means of}} cross-flow membrane technology was used to characterise the juices. The chromatographic information was subjected to pattern recognition methods such as principal component analysis, K-nearest neighbour (KNN), linear discriminant analysis, <b>Bayes</b> <b>analysis,</b> soft independent modelling of class analogy and partial least squares...|$|E
40|$|International audienceSome {{statistical}} models imply that two random vectors are marginally independent {{as well as}} being conditionally independent with respect to another random vector. When the joint distributions of the vectors is normal, Canonical Correlation Analysis may lead to relevant simplifications of the dependence structure. A similar application can be found in elliptical models, where linear independence does not imply statistical independence. Implications for <b>Bayes</b> <b>analysis</b> of the general linear model are discussed...|$|E
50|$|Bayes linear {{statistics}} is a subjectivist {{statistical methodology}} and framework. Traditional subjective Bayesian analysis {{is based upon}} fully specified probability distributions, which {{are very difficult to}} specify at the necessary level of detail. <b>Bayes</b> linear <b>analysis</b> attempts to solve this problem by developing theory and practise for using partially specified probability models. Bayes linear in its current form has been primarily developed by Michael Goldstein. Mathematically and philosophically it extends Bruno de Finetti's Operational Subjective approach to probability and statistics.|$|R
3000|$|Weka (GNU GPL) ver. 3.7. 1 {{was used}} on Mac OSX. A text file with all {{amplification}} factors of each effector {{was used as}} input file for the k-means clustering analysis with Weka using Euclidian distances applying the parameters: “weka. clusterers.SimpleKMeans-N 2 -A [...] "weka.core.EuclideanDistance - R first-last" [...] -I 500 -S 10 ”. The same file except one effector was used as training set for the naïve <b>Bayes</b> classification <b>analysis.</b> The effector removed from the training set input data was used as unknown. The standard parameters used for this analysis were: “weka.classifiers.bayes.NaiveBayes”.|$|R
30|$|Bayesian {{statistics}} We calculated a <b>Bayes</b> factor <b>analysis</b> for {{the proportion}} of yes answers to the contact items in the no causal implication and the conditions with causal implication. The Bayes factor evidence for the null hypothesis in a Bayesian repeated measures ANOVA comparing a model that included the main effects of condition (with causal implication or no causal implication) and expertise (novices, players, and referees) with a model including additionally the interaction of these factors amounted to 4.99, which is conventionally classified as substantial (Rouder, Morey, Speckman, & Province, 2012; Wetzels & Wagenmakers, 2012).|$|R
40|$|An {{efficient}} {{method to}} reduce the dimensionality of microarray gene expression data from thousands or {{tens of thousands of}} cDNA clones down to a subset of the most differentially expressed cDNA clones is essential in order to simplify the massive amount of data generated from microarray experiments. An extension to the methods of Efron et al. [Efron, B., Tibshirani, R., Storey, J., Tusher, V. (2001). Empirical <b>Bayes</b> <b>analysis</b> of a microarray experiment. J. Am...|$|E
40|$|We {{develop a}} new {{empirical}} <b>Bayes</b> <b>analysis</b> in multiple regression models. In the present work we consider multivariate skewnormal as prior for coefficients of the model in a skew-normal population and give empirical Bayes estimation for parameters of the model. The marginal distribution of response {{is found to be}} a closed skew-normal distribution. The empirical Bayes estimator is found in a closed form and the model is applied on a data set...|$|E
40|$|Some {{statistical}} models imply that two random vectors are marginally independent {{as well as}} being conditionally independent with respect to another random vector. When the joint distribution of the vectors is normal, canonical correlation analysis may lead to relevant simplifications of the dependence structure. A similar application can be found in elliptical models, where linear independence does not imply statistical independence. Implications for <b>Bayes</b> <b>analysis</b> of the general linear model are discussed. Bayes linear analysis Canonical correlation analysis Elliptical distributions Sylvester law of nullity Unrelated parameters...|$|E
40|$|Objective To {{investigate}} the clinical significance of <b>Bayes</b> discriminatory <b>analysis</b> on {{identification of the}} causes(acute rejection,AR;acute tubular necrosis,ATN;and nephrotoxicity of calcineurin inhibitor,NOCIN) of inducing an abrupt decrease in urine production at the early stage after kidney transplantation. Methods Of 677 patients undergone kidney transplantation, 125 of them who suffered {{from one of the}} 3 complications listed above within one month after transplantation were included,and assigned either to equation group(n= 100) or verify group(n= 25) with randomized table. The clinical and laboratory data of equation group were retrospectively analyzed. <b>Bayes</b> discriminatory <b>analysis</b> was performed to screen the valuable parameters and construct the diagnostic model. A total of 3 Bayes equations were established for the 3 complications. The clinical data of verify group were entered into the established equations to acquire the differential diagnosis,which were then compared with the final clinical diagnosis to verify the accuracy of the models. Results Three equations were constructed with <b>Bayes</b> discriminatory <b>analysis</b> for diagnosis of 3 common complications,which caused an abrupt decrease of patients’ urine production,emerged within one month after kidney transplantation. The equations were expressed as following. For acute rejection: y 1 =- 162. 384 + 1. 350 x 1 (age) - 6. 329 x 3 (corpse) + 27. 073 x 5 (swell) + 11. 094 x 6 (arthralgia) - 42. 288 x 7 (medication) + 15. 821 x 8 (time) + 5. 444 x 9 (blood pressure) - 0. 978 x 10 (temperature) + 14. 824 x 15 (kalium) + 14. 038 x 16 (BUN) + 41. 856 x 17 (Cr) + 13. 105 x 18 (urine);for acute tubular necrosis: y 2 =- 111. 755 + 3. 678 x 1 (age) + 0. 267 x 3 (corpse) + 4. 845 x 5 (swell) + 0. 106 x 6 (arthralgia) - 37. 255 x 7 (medication) + 8. 382 x 8 (time) + 5. 827 x 9 (blood pressure) - 2. 157 x 10 (temperature) + 8. 177 x 15 (kalium) + 13. 757 x 16 (BUN) + 38. 798 x 17 (Cr) + 9. 600 x 18 (urine);for nephrotoxicity of calcineurin inhibitor: y 3 =- 120. 512 + 2. 690 x 1 (age) - 2. 245 x 3 (corpse) + 18. 833 x 5 (swell) - 1. 353 x 6 (arthralgia) + 41. 266 x 7 (medication) + 9. 192 x 8 (time) + 1. 341 x 9 (blood pressure) + 0. 724 x 10 (temperature) + 5. 739 x 15 (kalium) + 8. 995 x 16 (BUN) + 24. 532 x 17 (Cr) + 20. 531 x 18 (urine). The accuracy rate of Bayes equation for acute rejection was 90 %,for acute tubular necrosis was 100 %,and for nephrotoxicity of calcineurin inhibitor was 90. 9 %. The total accuracy rate was 93. 6 %. Conclusion <b>Bayes</b> discriminatory <b>analysis</b> may be useful in the diagnosis of the 3 complications mentioned above which commonly occur in the early-stage after kidney transplantation...|$|R
40|$|I {{investigate}} how {{a model that}} assumes learning might interact with a rational expectations data generating process. Milani (2007 b) asserts that if agents are learning {{and there is no}} conditional heteroscedasticity then an econometrician may be fooled into estimating ARCH/GARCH models. In addition, I evaluate the contribution of a new endogenous gain, which I have proposed in previous paper, may yield on the fit of the NK model. Initial indications suggest the an endogenous gain can significantly increase the value of the likelihood function, which could mean that model comparison, using <b>Bayes</b> factor <b>analysis,</b> would support a model with an endogenous gain...|$|R
40|$|Smoking is {{the largest}} {{preventable}} cause of death and diseases in the developed world, and advances in modern electronics and machine learning can help us deliver therapies to smokers in novel ways. If a mobile device monitoring a smoker's situation could detect when the smoker {{is likely to have}} an urge to smoke, it would be helpful for optimizing the timing of real-time intervention. In this thesis, we examine different machine learning approaches to use situational features associated with having or not having urges to smoke during a quit attempt in order to accurately classify high-urge states. To test our machine learning approaches [...] specifically naive <b>Bayes,</b> discriminant <b>analysis</b> and decision tree learning methods [...] we used a dataset collected from over 300 participants who had recently initiated a quit attempt. The three classification approaches are evaluated observing sensitivity, specificity, accuracy and precision. The outcome of the analysis showed that algorithms based on feature selection make it possible to obtain high classification rates with only a few features selected from the entire dataset. The classification tree method outperformed the naive <b>Bayes</b> and discriminant <b>analysis</b> methods, with an accuracy of the classifications up to 86 %...|$|R
40|$|In this vignette, we {{show how}} the {{functions}} contained in the R package siggenes {{can be used to}} perform both the Significance Analysis of Mi-croarrays (SAM) proposed by Tusher et al. (2001) and the Empirical <b>Bayes</b> <b>Analysis</b> of Microarrays (EBAM) suggested by Efron et al. (2001). PLEASE NOTE Since there is a patent pending for the Significance Analysis of Microarrays (SAM), this package is only free for non-commercial users. Commercial users MUST have a valid license for the full (Excel) version of the SAM software pro-grammed at Stanford University, se...|$|E
40|$|Transportation Office of Traffic and Safety (TAS), a full <b>Bayes</b> <b>analysis</b> of the {{reduction}} in crash frequency due to 4 -lane to 3 -lane conversions in Iowa was conducted. The study utilized monthly crash data and estimated volumes obtained from TAS for 30 sites, 15 treatment (sites 1 through 15) and 15 control (sites 18 through 32), over 23 years (1982 - 2004). The sites had volumes ranging from 2, 030 to 15, 350 during that timespan and were largely located in smaller urbanized areas (see Table 1 for full site descriptions) ...|$|E
40|$|New normal linear {{modeling}} {{strategies are}} presented for analyzing read counts from RNA-seq experiments. The voom method estimates the mean-variance {{relationship of the}} log-counts, generates a precision weight for each observation and enters these into the limma empirical <b>Bayes</b> <b>analysis</b> pipeline. This opens access for RNA-seq analysts to {{a large body of}} methodology developed for microarrays. Simulation studies show that voom performs as well or better than count-based RNA-seq methods even when the data are generated according to the assumptions of the earlier methods. Two case studies illustrate the use of linear modeling and gene set testing methods. Restricted Access: Metadata Onl...|$|E
40|$|Modelling of {{inspection}} data for large scale physical systems {{is critical to}} assessment of their integrity. We present a general method for inference about system state and associated model variance structure from spatially distributed time series which are typically short, irregular, incomplete and not directly observable. <b>Bayes</b> linear <b>analysis</b> simplifies parameter estimation and avoids often-unrealistic distributional assumptions. Second-order exchangeability judgements facilitate variance learning for sparse inspection time-series. The model is applied to inspection data for minimum wall thickness from corroding pipe-work networks on a full-scale offshore platform, and shown to give materially different forecasts of remnant life compared to an equivalent model neglecting variance learning...|$|R
40|$|The text {{provides}} a thorough coverage of <b>Bayes</b> linear <b>analysis,</b> from {{the development of}} the basic language to the collection of algebraic results needed for efficient implementation, with detailed practical examples. The book covers: The importance of partial prior specifications for complex problems where it is difficult to supply a meaningful full prior probability specification. Simple ways to use partial prior specifications to adjust beliefs, given observations. Interpretative and diagnostic tools to display the implications of collections of belief statements, and to make stringent comparisons between expected and actual observations. General approaches to statistical modelling based upon partial exchangeability judgements. Bayes linear graphical models to represent and display partial belief specifications, organize computations, and display the results of analyses. ...|$|R
40|$|Summary: Time-series and multi-factor {{studies have}} become in-creasingly common in {{metabolomic}} studies. Common tasks for ana-lyzing data from these relatively complex experiments include identi-fication of major variations {{associated with each}} experimental factor, comparison of temporal profiles across different biological condi-tions, as well as detection and validation {{of the presence of}} interac-tions. Here we introduce MetATT, a web-based tool for time-series and two-factor metabolomic data analysis. MetATT offers a number of complementary approaches including 3 D interactive principal component analysis, two-way heatmap visualization, two-way ANOVA, ANOVA-simultaneous component analysis, and multivari-ate empirical <b>Bayes</b> time-series <b>analysis.</b> These procedures are presented through an intuitive web-interface. At the end of each session, a detailed analysis report is generated to facilitate under-standing of the results...|$|R
