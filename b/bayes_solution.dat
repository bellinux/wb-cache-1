18|36|Public
40|$|Inference on high-dimensional {{parameters}} in structured {{linear models}} {{is an important}} statistical problem. In this paper, for the piecewise constant Gaussian sequence model, we develop a new empirical <b>Bayes</b> <b>solution</b> that enjoys adaptive minimax posterior concentration rates and, thanks to the conjugate form of the empirical prior, relatively simple posterior computations. Comment: 10 pages, 1 figur...|$|E
40|$|This paper compares {{classical}} parametric methods with {{recently developed}} Bayesian methods for system identification. A Full <b>Bayes</b> <b>solution</b> is considered together {{with one of}} the standard approximations based on the Empirical Bayes paradigm. Results regarding point estimators for the impulse response as well as for confidence regions are reported. Comment: number of pages = 8, number of figures =...|$|E
40|$|We derive {{a maximum}} a posteriori {{estimator}} for the linear observation model, where the signal and noise covariance matrices are both uncertain. The uncertainties are treated probabilistically by modeling the covariance matrices with prior inverse-Wishart distributions. The nonconvex problem of jointly estimating the signal {{of interest and}} the covariance matrices is tackled by a computationally efficient fixed-point iteration {{as well as an}} approximate variational <b>Bayes</b> <b>solution.</b> The statistical performance of estimators is compared numerically to state-of-the-art estimators from the literature and shown to perform favorably...|$|E
40|$|The {{problem of}} state {{estimation}} with stochastic uncertainties {{in the initial}} state, model noise, and measurement noise is approached using the restricted risk Bayes approach. It is assumed that the a priori distributions of these quantities are not perfectly known but that some a priori information may be available. While offering robustness, the restricted risk Bayes approach incorporates the available a priori information and hence is less conservative than the minimax approach. When attention is restricted to linear estimators based on a quadratic loss function, a systematic method to derive restricted risk <b>Bayes</b> <b>solutions</b> is proposed. When the filtering problem is considered, the restricted risk Bayes approach provides us with a robust method to calibrate the Kalman filter, considering the presence of stochastic uncertainties. This method is illustrated with an example in which Bayes, minimax, and restricted risk <b>Bayes</b> <b>solutions</b> are derived and their performance is compared...|$|R
40|$|Uniform bounds on {{rates of}} L 1 -consistency for the empiric mean of state {{sequences}} {{in a family}} of probability models (compound with finite-mixture-state component) are obtained for MLEs (Section sec 2) and posterior means for quasi-uniform hyperpriors (Section sec 3), both determined in the iid mixture (empirical Bayes) sub-models. Qualitative aspects of results of this type were described by Robbins (1951). Application to the Gilliland and Hannan (1974 / 86) restricted-risk-finite-state-component compound decision problem (Section sec 4) yields uniform bounds on rates of asymptotic regret of <b>Bayes</b> <b>solutions</b> therein (with extension to mixture-state by expectation), giving strong affirmation to an asymptotic form of a Robbins (1951) conjecture. The general extension to mixture-state components (Remark rem 4. 1) strengthens much of the existing compound literature. Asymptotic regret Compound Consistency Maximum likelihood Posterior...|$|R
5000|$|LDA {{approaches}} {{the problem by}} assuming that the conditional probability density functions [...] and [...] are both normally distributed with mean and covariance parameters [...] and , respectively. Under this assumption, the <b>Bayes</b> optimal <b>solution</b> is to predict points as being from the second class if the log of the likelihood ratios is below some threshold T, so that: ...|$|R
40|$|Asymptotically {{efficient}} tests satisfying a minimax type criterion {{are derived}} for testing composite hypotheses involving several parameters in nonergodic type stochastic processes. It is shown, in particular, that the analogue {{of the usual}} Neyman's C ([alpha]) type test (i. e., the score test) is not efficient for the nonergodic case. Moreover, the likelihood-ratio statistic is not fully efficient for the model discussed in the paper. The efficient statistic derived here is {{a modified version of}} the score-statistic discussed previously by Basawa and Koul (1979). Nonergodic processes asymptotic minimaxity modified score statistic <b>Bayes</b> <b>solution...</b>|$|E
40|$|Combinations of one-sided {{sequential}} probability ratio tests (SPRT's) {{are shown}} to be "nearly optimal" for problems involving {{a finite number of}} possible underlying distributions. Subject to error probability constraints, expected sample sizes (or weighted averages of them) are minimized to within o(1) asymptotically. For sequential decision problems, simple explicit procedures are proposed which "do exactly what a <b>Bayes</b> <b>solution</b> would do" with probability approaching one as the cost per observation, c, goes to zero. Exact computations for a binomial testing problem show that efficiencies of about 97 % are obtained in some "small-sample" cases...|$|E
40|$|Recently, several {{works in}} the domain of natural {{language}} processing presented successful methods for word embedding. Among them, the Skip-Gram with negative sampling, known also as word 2 vec, advanced the state-of-the-art of various linguistics tasks. In this paper, we propose a scalable Bayesian neural word embedding algorithm. The algorithm relies on a Variational <b>Bayes</b> <b>solution</b> for the Skip-Gram objective and a detailed step by step description is provided. We present experimental results that demonstrate the performance of the proposed algorithm for word analogy and similarity tasks on six different datasets and show it is competitive with the original Skip-Gram method...|$|E
50|$|For many applications, variational <b>Bayes</b> {{produces}} <b>solutions</b> {{of comparable}} accuracy to Gibbs sampling at greater speed. However, deriving {{the set of}} equations used to iteratively update the parameters often requires {{a large amount of}} work compared with deriving the comparable Gibbs sampling equations. This is the case even for many models that are conceptually quite simple, as is demonstrated below {{in the case of a}} basic non-hierarchical model with only two parameters and no latent variables.|$|R
40|$|<b>Bayes</b> <b>solutions</b> are {{obtained}} for some specific simple statistical decision problems {{which may be}} stated in the following practical terms. The result of a trial of a weapon system is valued as success (1) or failure (0) and p, the true probablility of success is unknown. Prior to testing, {{it is assumed that}} any value of p in the interval (0, 1) is equally likely. Take as an estimate of p, the fraction, Pe of a finite number of trials which result in success. At the conclusion of testing, the weapon system is accepted (terminal decision d 1) if Pe. > 0, and it is rejected (terminal decision d 2) if Pe 0 or (ii) if the weapon system is rejected and the true p lies in an interval (1 - b, 1) where 0 < 1 -b. In this paper we consider only the case where [infinity and [beta] have the same value which we denote as 0 (symmetric case). The cost of wrong decision is defined in terms of a symmetric weight function, W(p,d 1; 0), i = 1, 2; W is simple or linear as defined below...|$|R
40|$|International audienceWe {{consider}} {{the problem of}} grouping items into clusters based on few random pairwise comparisons between the items. We introduce three closely related algorithms for this task: a belief propagation algorithm approximating the <b>Bayes</b> optimal <b>solution,</b> and two spectral algorithms based on the non-backtracking and Bethe Hessian operators. For the case of two symmetric clusters, we conjecture that these algorithms are asymptotically optimal in that they detect the clusters {{as soon as it}} is information theoretically possible to do so. We substantiate this claim for one of the spectral approaches we introduce...|$|R
40|$|This paper {{considers}} {{estimation of}} the predictive density for a normal linear model with unknown variance under alpha-divergence loss for - 1 <= alpha <= 1. We first give a general canonical form for the problem, and then give general expressions for the generalized <b>Bayes</b> <b>solution</b> under the above loss for each alpha. For a particular class of hierarchical generalized priors studied in Maruyama and Strawderman (2005, 2006) for the problems of estimating the mean vector and the variance respectively, we give the generalized Bayes predictive density. Additionally, we show that, for a subclass of these priors, the resulting estimator dominates the generalized Bayes estimator {{with respect to the}} right invariant prior when alpha= 1, i. e., the best (fully) equivariant minimax estimator...|$|E
40|$|We {{consider}} {{a model in}} which there are m products and for each i= 1, [...] .,m, there are n i observations of the service times associated with the i product. Assuming the service times associated with the i product follow an exponential distribution with parameter i #, and i # 's are independent random variables with a common gamma distribution, with unknown parameters # and #, we provide two empirical Bayes, under the squared error loss, forecasts of the (n i + 1) service time for each i. Our proposed empirical Bayes forecasts are obtained by replacing the structural parameters # and # with their consistent estimators in the <b>Bayes</b> <b>solution.</b> A simulation study comparing the performance of our empirical Bayes forecasts with the performance of the Bayes forecasts, which would be available only if # and # were known, is also provided...|$|E
40|$|In {{the minds}} of most statisticians there are (at least) two {{mutually}} exclusive approaches to data analysis. The "classical" or "frequentist" theory consist s of confidence intervals and hypothesis tests. And on the other hand, "Bayesian" statistics, a mode of inference is based on Bayes' Theorem. The goal of statistical inference is to extract and to report all available information about an unknown state of nature (parameter of interest) e. Two important actuarial problems can be successfully solved by the Bayesian approach. The first is the general problem of model-based prediction and the second problem comes under the general name of credibility. The goal {{of this paper is}} to show that the successful application of credibility theory would improve the ability of insurance companies to manage their financial systems with explicit risk components, also to show that even by adopting the Bayesian view, it was clear that the credibility solution is the best linear approximation to the <b>Bayes</b> <b>solution</b> of using the posterior mean...|$|E
40|$|We {{present a}} {{statistical}} decision approach for the point set matching of unordered feature sets. Both feature sets have associated uncertainties, {{and the number}} of elements in each set may be different. Computation of the match likelihood requires a correspondence between feature sets; we solve the correspondence problem in polynomial time using the Hungarian algorithm. We also consider the problem of matching when there is an unknown translation between the point sets. We present <b>Bayes</b> match <b>solutions</b> for both the deterministic and the random translation cases. Finally, we apply this matching method to the problem of synthetic aperture radar target classification from scattering center feature sets. 1...|$|R
40|$|Abstract Efficient {{exploration}} {{is widely}} recognized as a fundamental challenge inherent in reinforcement learning. Algorithms that explore efficiently converge faster to near-optimal policies. While heuristics techniques are popular in practice, they lack formal guarantees and may not work well in general. This chapter studies algorithms with polynomial sample complexity of exploration, both model-based and model-free ones, in a unified manner. These so-called PAC-MDP algorithms behave near-optimally except in a “small ” number of steps with high probability. A new learning model known as KWIK is used to unify most existing model-based PAC-MDP algorithms for various subclasses of Markov decision processes. We also compare the sample-complexity framework to alternatives for formalizing exploration efficiency such as regret minimization and <b>Bayes</b> optimal <b>solutions.</b> ...|$|R
40|$|In this article, {{we present}} a <b>Bayes</b> factor <b>solution</b> for {{inference}} in multiple regression. Bayes factors are principled measures of the relative evidence from data for various models or positions, including models that embed null hypotheses. In this regard, they {{may be used to}} state positive evidence for a lack of an effect, which is not possible in conventional significance testing. One obstacle to the adoption of Bayes factor in psychological science is a lack of guidance and software. Recently, developed computationally attractive default Bayes factors for multiple regression designs. We provide a web applet for convenient computation and guidance and context for use of these priors. We discuss the interpretation and advantages of the advocated Bayes factor evidence measures...|$|R
40|$|It is {{increasingly}} common {{to be faced}} with longitudinal or multi-level data sets that have large number of predictors and/or a large sample size. Current methods of fitting and inference for mixed effects models tend to perform poorly in such settings. When there are many variables, it is appealing to allow uncertainty in subset selection and to obtain a sparse characterization of the data. Bayesian methods are available to address these goals using Markov chain Monte Carlo (MCMC), but MCMC is very computationally expensive and can be infeasible in large p and/or large n problems. As a fast approximate <b>Bayes</b> <b>solution,</b> we recommend a novel approximation to the posterior relying on variational methods. Variational methods are used to approximate the posterior of the parameters in a decomposition of the variance components, with priors chosen to obtain a sparse solution that allows selection of random effects. The method is evaluated through a simulation study, and applied to an epidemiological application...|$|E
40|$|This paper {{describes}} {{a method for}} enhancing the performance of stochastic approximation (s. a.) techniques and for preventing convergence to a local maximum other than the global maximum of the underlying regression function. The strategy involves computing several s. a. estimators all using the same observations but differing in their starting points. The s. a. estimators are then averaged {{in such a way}} that the weighting coefficients of all the s. a. estimators except the one closest (according to a criterion) to the true parameter diminish to zero at a rate that is asymptotically faster than the convergence rates of the s. a. estimators. In effect, the averaging “singles out” the s. a. estimator closest to the true parameter. The approach is discussed in terms of two different regression functions, and computer-simulation results are included. Because the approach is motivated by the <b>Bayes</b> <b>solution,</b> the resulting estimator is called the “quasi-Bayes” estimator...|$|E
40|$|A new {{ensemble}} dimension reduction regression technique, called Correlated Component Regression (CCR), {{is proposed}} that predicts {{the dependent variable}} based on K correlated components. For K = 1, CCR {{is equivalent to the}} corresponding Naïve <b>Bayes</b> <b>solution,</b> and for K = P, CCR is equivalent to traditional regression with P predictors. An optional step-down variable selection procedure provides a sparse solution, with each component defined as a linear combination of only P * < P predictors. For high-dimensional data, simulation results suggest that good prediction is generally attainable for K = 3 or 4 regardless of the number of predictors, and estimation is fast. When predictors include one or more suppressor variables, common with gene expression data, simulations based on linear regression, logistic regression and discriminant analysis suggest that CCR predicts outside the sample better than comparable approaches based on stepwise regression, penalized regression and/or PLS regression. A major reason for the improvement is that the CCR/step-down algorithm is much better than other sparse techniques in capturing important suppressor variables among the final predictors...|$|E
40|$|We {{consider}} {{the problem of}} reducing the dimensionality of labeled data for classification. Unfortunately, the optimal approach of finding the low-dimensional projection with minimal Bayes classification error is intractable, so most standard algorithms optimize a tractable heuristic function in the projected subspace. Here, we investigate a physics-based model where we {{consider the}} labeled data as interacting fluid distributions. We derive the forces arising in the fluids from information theoretic potential functions, and consider appropriate low rank constraints on the resulting acceleration and velocity flow fields. We show how to apply the Gauss principle of least constraint in fluids to obtain tractable solutions for low rank projections. Our fluid dynamic approach is demonstrated to better approximate the <b>Bayes</b> optimal <b>solution</b> on Gaussian systems, including infinite dimensional Gaussian processes. ...|$|R
40|$|Abstract—The {{parameter}} estimation of HMM {{is critical to}} all its applications. The classic B-W algorithm is not flexible with the initial parameters and is easy {{to fall into the}} local optimal <b>solution.</b> <b>Bayes</b> estimation of it makes posterior risk minimization, and make full use of the experience, history information and other information other than samples, is useful in many cases. Employs the great computational power of MCMC, the MCMC estimation of HMM parameter can be more effective...|$|R
40|$|Consider {{a two-way}} {{classification}} model, and let [alpha] and [beta] be the vectors of treatment effects of two factors A and B under investigation. We discuss {{the problem of}} constructing Bayes and empirical Bayes (EB) estimators of the linear functions of [alpha] and [beta]. Under general conditions, EB estimators are found to have smaller mean square error matrix than the least sum of squares <b>solutions.</b> <b>Bayes</b> estimator Empirical Bayes estimator Mean squared error matrix criterion Two-way classification model...|$|R
40|$|Abstract—In {{smart home}} environments, {{it is highly}} {{desirable}} to know who is performing what actions. This knowledge allows the system to accurately build individuals ’ histories and to take personalized action based on the current resident. Without a good handle on identity, multi-resident smart homes are less effective when used for medical and assistive applications. Most smart home systems either have a single occupancy requirement, or rely on a wireless or video device to identify individuals. These requirements are too burdensome in some situations, which can limit the deployment of smart home technologies in environments that would derive benefits from them. This research work introduces the use of passive sensors and a Hidden Markov Model {{as a means to}} identify individuals. The result is a passive, low profile means to attribute individual events to unique residents. For this work, two different pairs of individuals living in a smart home testbed are used to evaluate the tools. The data used is from unscripted, full time occupancy and annotated by the residents themselves for accuracy. Lastly, the Hidden Markov Model approach is compared and contrasted against a prior Naive <b>Bayes</b> <b>solution</b> on the same data sets. I...|$|E
40|$|AbstractFor the {{well-known}} Fay–Herriot small area model, standard variance component estimation methods frequently produce zero {{estimates of the}} strictly positive model variance. As a consequence, an empirical best linear unbiased predictor of a small area mean, commonly used in small area estimation, could reduce to a simple regression estimator, which typically has an overshrinking problem. We propose an adjusted maximum likelihood estimator of the model variance that maximizes an adjusted likelihood defined {{as a product of}} the model variance and a standard likelihood (e. g., a profile or residual likelihood) function. The adjustment factor was suggested earlier by Carl Morris in the context of approximating a hierarchical <b>Bayes</b> <b>solution</b> where the hyperparameters, including the model variance, are assumed to follow a prior distribution. Interestingly, the proposed adjustment does not affect the mean squared error property of the model variance estimator or the corresponding empirical best linear unbiased predictors of the small area means in a higher order asymptotic sense. However, as demonstrated in our simulation study, the proposed adjustment has a considerable advantage in small sample inference, especially in estimating the shrinkage parameters and in constructing the parametric bootstrap prediction intervals of the small area means, which require the use of a strictly positive consistent model variance estimate...|$|E
40|$|In {{probabilistic}} PCA, {{the fully}} Bayesian estimation is computationally intractable. To {{cope with this}} problem, two types of approximation schemes were introduced: the partially Bayesian PCA (PB-PCA) where only the latent variables are integrated out, and the variational Bayesian PCA (VB-PCA) where the loading vectors are also integrated out. The VB-PCA was proposed as an improved variant of PB-PCA for enabling automatic dimensionality selection (ADS). In this paper, we investigate whether VB-PCA is really the best choice from the viewpoints of computational efficiency and ADS. We first show that ADS is not the unique feature of VB-PCA—PB-PCA is also actually equipped with ADS. We further show that PB-PCA is more advantageous in computational efficiency than VB-PCA because the global solution of PB-PCA can be computed analytically. However, we also show the negative fact that PB-PCA results in a trivial solution in the empirical Bayesian framework. We next consider a simplified variant of VB-PCA, where the latent variables and loading vectors {{are assumed to be}} mutually independent (while the ordinary VB-PCA only requires matrix-wise independence). We show that this simplified VB-PCA is the most advantageous in practice because its empirical <b>Bayes</b> <b>solution</b> experimentally works as well as the original VB-PCA, and its global optimal solution can be computed efficiently in a closed form...|$|E
40|$|Decision making {{tasks in}} {{changing}} environments with probabilistic reward schemes present various {{challenges to the}} agents performing the task. These agents must use the experience gained in the past trials to characterize the environment which guides their actions. We present two models to predict an agent's behavior in these tasks-a theoretical model which defines a <b>Bayes</b> optimal <b>solution</b> to the problem under realistic task conditions. The second is a computational model of the basal ganglia which presents a neural mechanism to solve the same. Both the models are shown to reproduce results in behavioral experiments and are compared to each other. This comparison allows us to characterize the theoretical model as a bound on the neural model and the neural model as a biologically plausible implementation of the theoretical model. Furthermore, we predict {{the performance of the}} agents in various stochastic regimes which could be tested in future studies...|$|R
40|$|A {{new method}} for SAR image {{segmentation}} is proposed in this paper. Region segmentation {{can be achieved}} by contour tracking, and we use the general Bayes tracking framework to solve this problem. Due to the non-linearity of the tracking problem and the non-Gaussian noise of SAR image, Monte Carlo based particle filtering algorithm is adopted to obtain the <b>Bayes</b> optimal <b>solution.</b> Based on the tracking framework, a particle filter based contour tracking method is proposed for region segmentation in SAR images. In this method, each particle is assigned to a linear segment with specific location and direction. The response of the local edge detector is used to calculate the particle weight while the global contextual knowledge, such as the smoothness of the region boundary, is guaranteed by the propagation of particles. The proposed method is employed for river boundary extraction on the SAR image. Furthermore, bridges over a river are detected. 1...|$|R
40|$|Nonlinear target {{tracking}} {{is a well}} known problem and its <b>Bayes</b> optimal <b>solution,</b> based on particle filtering techniques, is nowadays applied in high performance surveillance systems. Oftentimes, additional information about {{the environment and the}} target is available, and can be formalized in terms of constraints on target dynamics. Hence, a Constrained version of the Bayesian Filtering problem has to be solved to achieve optimal tracking performance. In this paper we consider the Constrained Filtering problem for the case of perfectly known hard constraints. We clarify that in such a case the Particle Filter (PF) is still Bayes optimal if we can correctly model the constraints. We then show that from a Bayesian viewpoint, exploitation of the available knowledge in the prediction or in the update step are equivalent. Finally, we consider simple techniques to exploit constraints in the prediction and update steps of a PF, and use the Kullback-Leibler divergence to illustrate their equivalence through simulations. ...|$|R
40|$|For the {{well-known}} Fay-Herriot small area model, standard variance component estimation methods frequently produce zero {{estimates of the}} strictly positive model variance. As a consequence, an empirical best linear unbiased predictor of a small area mean, commonly used in small area estimation, could reduce to a simple regression estimator, which typically has an overshrinking problem. We propose an adjusted maximum likelihood estimator of the model variance that maximizes an adjusted likelihood defined {{as a product of}} the model variance and a standard likelihood (e. g., a profile or residual likelihood) function. The adjustment factor was suggested earlier by Carl Morris in the context of approximating a hierarchical <b>Bayes</b> <b>solution</b> where the hyperparameters, including the model variance, are assumed to follow a prior distribution. Interestingly, the proposed adjustment does not affect the mean squared error property of the model variance estimator or the corresponding empirical best linear unbiased predictors of the small area means in a higher order asymptotic sense. However, as demonstrated in our simulation study, the proposed adjustment has a considerable advantage in small sample inference, especially in estimating the shrinkage parameters and in constructing the parametric bootstrap prediction intervals of the small area means, which require the use of a strictly positive consistent model variance estimate. Adjusted density maximization estimator The Fay-Herriot model Parametric bootstrap Prediction intervals...|$|E
40|$|Optimal Doppler {{velocity}} estimation, {{under the}} constraint of small sample size, is explored for a standard Gaussian signal measurement model and thematic maximum likelihood (ML) and Bayes estimation. Because the model considered {{depends on a}} vector parameter [velocity, spectrum width, and signal-to-noise ration (SNR) ], the exact formulation of an ML or <b>Bayes</b> <b>solution</b> involves a system of equations that is neither uncoupled nor explicit in form. Historically, iterative methods {{have been the most}} suggested approach to solving the required equations. In addition to being computationally intensive, it is unclear whether iterative methods can be constructed to perform well given a small-sample size and low signal strength. This report takes a different approach and seeks to construct approximate (ML and Bayes) estimators based on the notion of using constrained adaptive models to deal with nuisance parameter removal. A Monte Carlo simulation is used to determine small-sample estimator statistics and to demonstrate true performance bounds in the case of known nuisance values. Performance comparisons between these optimal forms and other standard estimators [pulse pair (PP) and a frequency domain wind profiler (WP) method] are presented. Performance sensitivity of the optimal algorithms, with respect to uncertainty in the values of model nuisance parameters, is explored and provides the foundation for the recommendations to seek an adaptive method. An adaptive estimation method, closely allied with the derived ML and Bayes formula, is developed using information theoretic methods to constrain the adaptation process. The improved, near optimal performance of the new Doppler velocity estimator is documented by comparison to derived optimal bounds and to the performance of the PP method...|$|E
40|$|For general multiple-decision testing {{problems}}, {{and even}} two-decision problems involving {{more than two}} states of nature, how to construct sequential procedures which are optimal (e. g. minimax, Bayes, or even admissible) is an open question. In the absence of optimality results, many procedures have been proposed for problems in this category. Among these are the procedures studied in Wald and Sobel (1949), DonnellY. (1957), Anderson (1960), and Schwarz (1962), {{all of which are}} discussed in the introduction of the paper by Kiefer and Sacks (1963) along with investigations in sequential design of experiments (notably those of Chernoff (1959) and Albert (1961)) which can be regarded as considering, inter alia, the (non-design) sequential testing problem. The present investigation concerns certain procedures which are asymptotically Bayes as the cost per observation, c, approaches zero and are definable by a simple rule: continue sampling until the a posteriori risk of stopping is less than Qc (where Q is a fixed positive number), and choose a terminal decision having minimum a posteriori risk. This rule, with Q = 1, was first considered by Schwarz and was shown to be asymptotically Bayes, under mild assumptions, by Kiefer and Sacks (whose results easily extend to the case of arbitrary Q > 0). Given an a priori distribution, F, and cost per observation, c, we shall use δ_F(Qc) to denote the procedure defined by this rule and δ_F * (c) to denote a <b>Bayes</b> <b>solution</b> with respect to F and c. The result of Kiefer and Sacks, for Q = 1, states that rc(F, δF(c)), [...] ., r_c(F, δ_F*(c)) as c 0, where rc(F, δ) is the integrated risk of δ when F is the a priori distribution and c is the cost per observation. The principal aim of the present work is to construct upper bounds (valid for all c > 0) on the difference r_c(F, δF(Qc)) - rc(F, δF*(c)), so that one can determine values of c (or the probabilities of error) small enough to insure that simple asymptotically optimum procedures are reasonably efficient...|$|E
40|$|For a {{classification}} problem {{described by the}} joint density P(ω,x), models of P(ωω'|x,x') (the "Bayesian similarity measure") {{have been shown to}} be an optimal similarity measure for nearest neighbor classification. This paper analyzes demonstrates several additional properties of that conditional distribution. The paper first shows that we can reconstruct, up to class labels, the class posterior distribution P(ω|x) given P(ωω'|x,x'), gives a procedure for recovering the class labels, and gives an asymptotically Bayes-optimal classification procedure. It also shows, given such an optimal similarity measure, how to construct a classifier that outperforms the nearest neighbor classifier and achieves Bayes-optimal classification rates. The paper then analyzes Bayesian similarity in a framework where a classifier faces a number of related classification tasks (multitask learning) and illustrates that reconstruction of the class posterior distribution is not possible in general. Finally, the paper identifies a distinct class of classification problems using P(ωω'|x,x') and shows that using P(ωω'|x,x') to solve those problems is the <b>Bayes</b> optimal <b>solution...</b>|$|R
40|$|The {{posterior}} {{parietal cortex}} {{is believed to}} direct eye movements, {{especially in regards to}} target tracking tasks, and a number of debates exist over the precise nature of the computations performed by the parietal cortex, with each side supported by different sets of biological evidence. In this paper I will present my model which navigates a course between some of these debates, towards the end of presenting a model which can explain some of the competing interpretations among the data sets. In particular, rather than assuming that proprioception or efference copies form the key source of information for computing eye position information, I use a biological plausible implementation of a Kalman filter to optimally combine the two signals, and a simple gain control mechanism in order to accommodate the latency of the proprioceptive signal. Fitting within the Bayesian brain hypothesis, the result is a <b>Bayes</b> optimal <b>solution</b> to the eye control problem, with a range of data supporting claims of biological plausibility...|$|R
40|$|Nonlinear target {{tracking}} {{is a well}} known problem, and its <b>Bayes</b> optimal <b>solution,</b> based on particle filtering techniques, is nowadays applied in high performance surveillance systems. Nonetheless, the practical application of Particle Filters (PFs) may still be difficult, so that possibly available external knowledge can be exploited to increase the tracking performance. In this paper we assume such knowledge be formalized in terms of constraints on target dynamics. Hence, a Constrained version of the Filtering problem has to be solved. We first treat the case of perfectly known hard constraints, and show that exploitation of knowledge in the prediction or in the update step of the Bayesian filtering recursion are equivalent. We then focus {{on the case of}} soft constraints. Here, the lack of information on when and how the target violates the constraints makes the filtering problem much more difficult. Simulation results show that a straightforward extension of the Pseudo-Measurements approach is not sufficient. However, detecting the violation of constraints is possible if the knowledge is processed using an Interactive Multiple Models (IMM) scheme...|$|R
