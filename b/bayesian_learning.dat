1292|1287|Public
50|$|In recent years, {{proponents of}} <b>Bayesian</b> <b>learning</b> have begun {{describing}} the theory theory in a precise, mathematical way. The concept of <b>Bayesian</b> <b>learning</b> {{is rooted in}} the assumption that children and adults learn through a process of theory revision; that is, they hold prior beliefs about the world but, when receiving conflicting data, may revise these beliefs depending upon their strength.|$|E
5000|$|An aligner that aligns both {{words and}} phrases using <b>Bayesian</b> <b>learning</b> and {{inversion}} transduction grammars ...|$|E
5000|$|ACT-R {{is similar}} to Soar. It {{includes}} a <b>Bayesian</b> <b>learning</b> system to help prioritize the productions.|$|E
40|$|This paper {{introduces}} online <b>Bayesian</b> network <b>learning</b> in detail. The {{structural and}} parametric learning {{abilities of the}} online <b>Bayesian</b> network <b>learning</b> are explored. The paper starts with revisiting the multi-agent self-organization problem and the proposed solution. Then, we explain the proposed <b>Bayesian</b> network <b>learning,</b> three scoring functions, namely Log-Likelihood, Minimum description length, and Bayesian scores...|$|R
40|$|Bayesian {{network is}} one of the most {{successful}} graph models for representing the reactive oxygen species regulatory pathway. With the increasing number of microarray measurements, it is possible to construct the Bayesian network from microarray data directly. Although large numbers of <b>Bayesian</b> network <b>learning</b> algorithms have been developed, when applying them to <b>learn</b> <b>Bayesian</b> networks from microarray data, the accuracies are low due to that the databases they used to <b>learn</b> <b>Bayesian</b> networks contain too few microarray data. In this paper, we propose a consensus Bayesian network which is constructed by combining Bayesian networks from relevant literatures and <b>Bayesian</b> networks <b>learned</b> from microarray data. It would have a higher accuracy than the <b>Bayesian</b> networks <b>learned</b> from one database. In the experiment, we validated the Bayesian network combination algorithm on several classic machine learning databases and used the consensus Bayesian network to model the Escherichia coli’s ROS pathway...|$|R
50|$|Expectation {{propagation}} (EP) is {{a technique}} in <b>Bayesian</b> machine <b>learning.</b>|$|R
50|$|This can be {{interpreted}} as <b>Bayesian</b> <b>learning</b> where the parameters are updated according to the following equations.|$|E
50|$|<b>Bayesian</b> <b>learning</b> {{neural network}} is {{implemented}} for credit card fraud detection, telecommunications fraud, auto claim fraud detection, and medical insurance fraud.|$|E
50|$|PyMC is an {{open source}} Python library for <b>Bayesian</b> <b>learning</b> of general Probabilistic Graphical Model with {{advanced}} features {{and easy to use}} interface.|$|E
50|$|He is {{well known}} for having {{developed}} <b>Bayesian</b> Program <b>Learning.</b>|$|R
40|$|Abstract. In {{recent years}} {{there has been}} a growing {{interest}} in <b>Bayesian</b> Network <b>learning</b> from uncertain data. While many researchers focus on <b>Bayesian</b> Network <b>learning</b> from data with tuple uncertainty, <b>Bayesian</b> Network structure <b>learning</b> from data with attribute uncertainty gets little attention. In this paper we make a clear definition of attribute uncertain data and <b>Bayesian</b> Network <b>Learning</b> problem from such data. We propose a structure learning method named DTAU based on information theory. The algorithm assumes that the structure of a Bayesian network is a tree. It avoids enumerating all possible worlds. The dependency tree is computed with polynomial time complexity. We conduct experiments to demonstrate the effectiveness and efficiency of our method. The experiments show the clustering results on uncertain dataset by our dependency tree are acceptable...|$|R
40|$|We present new {{algorithms}} for <b>learning</b> <b>Bayesian</b> networks {{from data}} with missing values using a data augmentation approach. An exact <b>Bayesian</b> network <b>learning</b> algorithm is obtained by recasting the problem into a standard <b>Bayesian</b> network <b>learning</b> problem without missing data. To {{the best of}} our knowledge, this is the first exact algorithm for this problem. As expected, the exact algorithm does not scale to large domains. We build on the exact method to create an approximate algorithm using a hill-climbing technique. This algorithm scales to large domains so long as a suitable standard structure learning method for complete data is available. We perform a wide range of experiments to demonstrate the benefits of <b>learning</b> <b>Bayesian</b> networks with such new approach...|$|R
50|$|Late 1980s: Kai-Fu Lee and Sanjoy Mahajan {{created the}} Othello program BILL, whichwas similar to IAGO but {{incorporated}} <b>Bayesian</b> <b>learning.</b> BILL reliably beat IAGO.|$|E
50|$|There are two {{versions}} of the program. The free version can access only a single mail account and does not contain the <b>Bayesian</b> <b>learning</b> filter. The Pro version can access multiple accounts and has additional features.|$|E
5000|$|H.T. Siegelmann and L.E. Holtzman, [...] "Neuronal {{integration}} of dynamic sources: <b>Bayesian</b> <b>learning</b> and Bayesian inference," [...] Chaos: Focus issue: Intrinsic and Designed Computation: Information Processing in Dynamical Systems 20 (3): DOI: 10.1063/1.3491237, September 2010. (7 pages) ...|$|E
40|$|Keywords:Rough set; mutual information; <b>Bayesian</b> network; {{structure}} <b>learning</b> Abstract. In <b>Bayesian</b> {{network structure}} <b>learning</b> for incomplete data set, {{a common problem}} is too many attributes causing low efficiency and high computation complexity. In this paper, an algorithm of attribute reduction based on rough set is introduced. The algorithm can effectively reduce the dimension of attributes and quickly determine the network structure using mutual information for <b>Bayesian</b> network structure <b>learning...</b>|$|R
30|$|There {{are three}} <b>Bayesian</b> related <b>learning</b> {{principles}} {{that can be}} implemented with such the property of automatic model selection.|$|R
40|$|<b>Learning</b> a <b>Bayesian</b> network {{from data}} is an {{important}} problem in biomedicine for the automatic construction of decision support systems and inference of plausible causal relations. Most <b>Bayesian</b> network <b>learning</b> algorithms require discrete data; however discretization may impact {{the quality of the}} learned structure. In this project, we present a comparison of different approaches for learning from continuous data to identify the most promising one and to quantify the impact of discretization in <b>Bayesian</b> network <b>learning...</b>|$|R
50|$|Variational <b>Bayesian</b> <b>learning</b> {{is based}} on probabilities. There is a chance that an {{approximation}} is performed with mistakes, damaging further data representations. Another downside pertains to complicated or corrupted data samples, {{making it difficult to}} infer a representational pattern.|$|E
50|$|<b>Bayesian</b> <b>learning</b> methods {{make use}} of a prior {{probability}} that (usually) gives lower probability to more complex models. Well-known model selection techniques include the Akaike information criterion (AIC), minimum description length (MDL), and the Bayesian information criterion (BIC). Alternative methods of controlling overfitting not involving regularization include cross-validation.|$|E
5000|$|The wake-sleep {{algorithm}} is an unsupervised learning algorithm for a stochastic multilayer neural network. The algorithm adjusts the parameters {{so as to}} produce a good density estimator. There are two learning phases, the “wake” phase and the “sleep” phase, which are performed alternately. It was first designed {{as a model for}} brain functioning using variational <b>Bayesian</b> <b>learning.</b> After that, the algorithm was adapted to machine learning. It {{can be viewed as a}} way to train a Helmholtz Machine ...|$|E
40|$|Abstract: As the {{combination}} of parameter learning and structure <b>learning,</b> <b>learning</b> <b>Bayesian</b> networks can also be examined, Parameter learning is estimation of the dependencies in the network. Structural learning is the estimation of the links of the network. In terms of whether {{the structure of the}} network is known and whether the variables are all observable, there are four types of <b>learning</b> <b>Bayesian</b> networks cases. In this paper, first introduce two cases of <b>learning</b> <b>Bayesian</b> networks from complete data: known structure and unobservable variables and unknown structure and unobservable variables. Next, we study two cases of <b>learning</b> <b>Bayesian</b> networks from incomplete data: known network structure and unobservable variables, unknown network structure and unobservable variables...|$|R
40|$|An {{important}} {{problem in}} the design of neurophysiology experiments is to select stimuli that rapidly probe a neuron’s tuning or response properties. This is especially important in settings where the neural parameter space is multi-dimensional and the experiment is limited in time. <b>Bayesian</b> active <b>learning</b> methods provide a formal solution to this problem using a statistical model of the neural response and a utility function that quantifies what we want to learn. In contrast to staircase and other ad hoc stimulus selection methods, <b>Bayesian</b> active <b>learning</b> methods use the entire set of past stimuli and responses to make inferences about functional properties and select the next stimulus. Here we discuss recent advances in <b>Bayesian</b> active <b>learning</b> methods for closed-loop neurophysiology experiments. We review the general ingredients for <b>Bayesian</b> active <b>learning</b> and then discuss two specific applications in detail: (1) low-dimensional nonlinear response surfaces (also known as “tuning curves ” or “firing rate maps”); and (2) high-dimensional linear receptive fields. Recent work has shown that these methods can achieve higher accuracy in less time, allowing for experiments that are infeasible with non-adaptive methods. We conclude with a discussion of open problems and exciting directions for future research. ...|$|R
40|$|Abstract. Estimation of {{distribution}} algorithms (EDAs) constitute a new branch of evolutionary optimization algorithms, providing {{effective and efficient}} optimization performance {{in a variety of}} research areas. Recent studies have proposed new EDAs that employ mutation operators in standard EDAs to increase the population diversity. We present a new mutation operator, a matrix transpose, specifically designed for <b>Bayesian</b> structure <b>learning,</b> and we evaluate its performance in <b>Bayesian</b> structure <b>learning.</b> The results indicate that EDAs with transpose mutation give markedly better performance than conventional EDAs...|$|R
5000|$|SpamAssassin {{by default}} tries to {{reinforce}} {{its own rules}} through Bayesian filtering, but <b>Bayesian</b> <b>learning</b> is most effective with actual user input. Typically, the user is expected to [...] "feed" [...] example spam mails and example [...] "ham" [...] (useful) mails to the filter, which can then learn {{the difference between the}} two. For this purpose, SpamAssassin provides the command-line tool sa-learn, which can be instructed to learn a single mail or an entire mailbox as either ham or spam.|$|E
5000|$|Agilent Technologies {{sought to}} create one, and so created the RNA Integrity Number. The {{algorithm}} was generated by taking hundreds of samples and having specialists manually assign them all {{a value of}} 1 to 10 based on their integrity, with 10 being the highest. Adaptive learning tools using a <b>Bayesian</b> <b>learning</b> technique were used to generate an algorithm that could predict the RIN, predominantly by using the features listed below under [...] "Computation". This allows for all Agilent software to produce the same RIN for a given RNA sample, standardizing the measurement and making it much less subjective than earlier methods.|$|E
5000|$|Radford M. Neal is a {{professor}} at the Department of Statistics and Department of Computer Science at the University of Toronto, where he holds a Research Chair in statistics and machine learning. He studied computer science at the University of Calgary (B.Sc. 1977, M.Sc. 1980) and at the University of Toronto (Ph.D. 1995). [...] He has made great contributions in the area of machine learning and statistics, where he is particular well known for his work on Markov chain Monte Carlo, error correcting codes and <b>bayesian</b> <b>learning</b> for neural networks. He is also known for his blog and the developer of pqR: a new version of the R interpreter.|$|E
50|$|As {{shown in}} the figure to the right, the <b>Bayesian</b> One-Shot <b>Learning</b> {{algorithm}} significantly outperforms a maximum likelihood procedure on {{a small number of}} training images.|$|R
40|$|<b>Bayesian</b> {{structure}} <b>learning</b> is the NP-hard {{problem of}} discovering a Bayesian network that optimally represents a given set of training data. In this paper we study the computational worst-case complexity of exact <b>Bayesian</b> structure <b>learning</b> under graph theoretic {{restrictions on the}} super-structure. The super-structure (a concept introduced by Perrier, Imoto, and Miyano, JMLR 2008) is an undirected graph that contains as subgraphs the skeletons of solution networks. Our results apply to several variants of score-based <b>Bayesian</b> structure <b>learning</b> where the score of a network decomposes into local scores of its nodes. Results: We show that exact <b>Bayesian</b> structure <b>learning</b> {{can be carried out}} in non-uniform polynomial time if the super-structure has bounded treewidth and in linear time if in addition the super-structure has bounded maximum degree. We complement this with a number of hardness results. We show that both restrictions (treewidth and degree) are essential and cannot be dropped without loosing uniform polynomial time tractability (subject to a complexity-theoretic assumption). Furthermore, we show that the restrictions remain essential if we do not search for a globally optimal network but we aim to improve a given network by means of at most k arc additions, arc deletions, or arc reversals (k-neighborhood local search) ...|$|R
40|$|The naive Bayesian {{classifier}} {{provides a}} simple and effective approach to classifier learning, but its attribute independence assumption is often violated in the real world. A number of approaches have sought to alleviate this problem. A <b>Bayesian</b> tree <b>learning</b> algorithm builds a decision tree, and generates a local naive Bayesian classifier at each leaf. The tests leading to a leaf can alleviate attribute inter-dependencies for the local naive Bayesian classifier. However, <b>Bayesian</b> tree <b>learning</b> still suffers from the replication, fragmentation, and small disjunct problems of tree <b>learning.</b> While inferred <b>Bayesian</b> trees demonstrate low average prediction error rates, {{there is reason to}} believe that error rates will be higher for those leaves with few training examples. This paper proposes the application of lazy <b>learning</b> techniques to <b>Bayesian</b> tree induction and presents the resulting lazy <b>Bayesian</b> rule <b>learning</b> algorithm, called Lbr. For each test example, it builds a most appropria [...] ...|$|R
5000|$|The {{mechanism}} {{behind the}} implicit learning that is hypothesized to occur while people engage in artificial grammar learning is statistical learning or, more specifically, <b>Bayesian</b> <b>learning.</b> <b>Bayesian</b> <b>learning</b> {{takes into account}} types of biases or [...] "prior probability distributions" [...] individuals have {{that contribute to the}} outcome of implicit learning tasks. These biases {{can be thought of as}} a probability distribution that contains the probability that each possible hypothesis is likely to be correct. Due to the structure of the Bayesian model, the inferences output by the model are in the form of a probability distribution rather than a single most probable event. This output distribution is a [...] "posterior probability distribution". The posterior probability of each hypothesis in the original distribution is the probability of the hypothesis being true given the data and the probability of data given the hypothesis is true.This Bayesian model for learning is fundamental for understanding the pattern detection process involved in implicit learning and, therefore, the mechanisms that underlie the acquisition of artificial grammar learning rules. It is hypothesized that the implicit learning of grammar involves predicting co-occurrences of certain words in a certain order. For example, [...] "the dog chased the ball" [...] is a sentence that can be learned as grammatically correct on an implicit level due to the high co-occurrence of [...] "chase" [...] being one of the words to follow [...] "dog". A sentence like [...] "the dog cat the ball" [...] is implicitly recognized as grammatically incorrect due to the lack of utterances that contain those words paired in that specific order. This process is important for teasing apart thematic roles and parts of speech in grammatical processing (see grammar). While the labeling of the thematic roles and parts of speech is explicit, the identification of words and parts of speech is implicit.|$|E
50|$|Whereas {{evolutionary}} {{game theory}} studies {{the behavior of}} large populations of agents, the theory of learning in games focuses on whether {{the actions of a}} small group of players end up conforming to some notion of equilibrium. This is a challenging problem, because social systems are self-referential: the act of learning changes the thing to be learned. There is a complex feedback between a player's beliefs, their actions and the actions of others, which makes the data-generating process exceedingly non-stationary. Young has made numerous contributions to this literature. Foster and Young (2001) demonstrate the failure of <b>Bayesian</b> <b>learning</b> rules to learn mixed equilibria in games of uncertain information. Foster and Young (2003) introduce a learning procedure in which players form hypotheses about their opponents' strategies, which they occasionally test against their opponents' past play. By backing off from rationality in this way, Foster and Young show that there are natural and robust learning procedures that lead to Nash equilibrium in general normal form games.|$|E
5000|$|In 1990-1991, {{articles}} on the Prescient Agents software {{were published in the}} HP Journal and as a cover article in the initial volume (volume 0) of The X Resource Journal published by OReilly & Associates entitled [...] "Prescient Agents: A Radar OReilly for your Desktop". [...] Through this latter publication, McGregors work {{came to the attention of}} editor David Flack who, in the May 1992 edition of UnixWorld, published an editorial entitled [...] "Smarter Programming Bring Smarter Computers" [...] that recognized McGregor for his work on more usable software, and in particular singling out his work on Prescient Agents. The Prescient Agents software work was notable as a very early example of software combining intelligent agents, <b>Bayesian</b> <b>learning</b> techniques, groupware, window systems and hyperlink software to improve the usability of computers in environments with many related frequently changing documents shared by many people. Its initial deployment was in service of distributed parallel software development at Hewlett-Packard.|$|E
40|$|The aim of {{the report}} is to {{summarize}} the mathematical grounding for the <b>Bayesian</b> approach to <b>learning</b> BN structure. This involves introducing <b>Bayesian</b> model for <b>learning</b> BN structures including specification of the mathematical assumptions taken from the literarure. It leads to the formula for the corresponding data vector...|$|R
40|$|The {{purpose of}} this {{assignment}} is to test and possibly expand your knowledge about <b>learning</b> <b>Bayesian</b> networks from data. Recall that <b>learning</b> <b>Bayesian</b> networks involves both structure learning, i. e., learning the graph topology from data, and parameter learning, i. e., learning the actual, local probability distributions from data...|$|R
40|$|Abstract: This article {{shows how}} to learn both the {{structure}} and the parameters of partially observable en-vironment simultaneously while also online performing near-optimal sequence of actions taking into account exploration-exploitation tradeoff. It combines two re-sults of recent research: The former extends model-based <b>Bayesian</b> reinforcement <b>learning</b> of fully observable envi-ronment to bigger domains by learning the structure. The latter shows how a known structure can be exploited to model-based <b>Bayesian</b> reinforcement <b>learning</b> of partially observable domains. This article shows that merging both approaches is possible without too excessive increase in computational complexity. ...|$|R
