357|55|Public
25|$|What sets A* {{apart from}} a greedy <b>best-first</b> <b>search</b> {{algorithm}} is that it takes the cost/distance already traveled, , into account.|$|E
25|$|Any search {{strategy}} {{can be used}} to search this space. Prolog uses a sequential, last-in-first-out, backtracking strategy, in which only one alternative and one sub-goal is considered at a time. Other search strategies, such as parallel search, intelligent backtracking, or <b>best-first</b> <b>search</b> to find an optimal solution, are also possible.|$|E
25|$|A* is an {{informed}} search algorithm, or a <b>best-first</b> <b>search,</b> {{meaning that it}} solves problems by searching among all possible paths to the solution (goal) for the one that incurs the smallest cost (least distance travelled, shortest time, etc.), and among these paths it first considers the ones that appear to lead most quickly to the solution. It is formulated in terms of weighted graphs: starting from a specific node of a graph, it constructs a tree of paths starting from that node, expanding paths {{one step at a}} time, until one of its paths ends at the predetermined goal node.|$|E
30|$|TSA {{adopts a}} <b>best-first</b> tree <b>search</b> {{strategy}} for the branch-and-bound approach. We first describe a basic version of the <b>best-first</b> tree <b>search</b> strategy and then introduce two enhancements to this strategy in the next subsection.|$|R
40|$|Iterative-deepening {{searches}} mimic a breadth-first node expansion with {{a series}} of depth-first searches that operate with successively extended search horizons. They have been proposed as a simple way to reduce the space complexity of <b>best-first</b> <b>searches</b> like A* from exponential to linear in the search depth. But her...|$|R
40|$|Depth-first iterative-deepening mimics a {{breadth-first search}} {{with a series}} of depth-first {{searches}} that operate with successively extended search horizons. It has been proposed as a simple way to reduce the space complexity of <b>best-first</b> <b>searches</b> like A*, thereby making the space complexity linear instead of exponential. But ther...|$|R
5000|$|The A* search {{algorithm}} {{is an example}} of <b>best-first</b> <b>search,</b> as is B*. Best-first algorithms are often used for path finding in combinatorial search. (Neither A* nor B* is a greedy <b>best-first</b> <b>search</b> as they incorporate the distance from start in addition to estimated distances to the goal.) ...|$|E
50|$|DCOP {{algorithms}} can {{be classified}} according to the search strategy (<b>best-first</b> <b>search</b> or depth-first branch-and-bound search), the synchronization among agents (synchronous or asynchronous), the communication among agents (point-to-point with neighbors in the constraint graph or broadcast) and the main communication topology (chain or tree).ADOPT, for example, uses <b>best-first</b> <b>search,</b> asynchronous synchronization, point-to-point communication between neighboring agents in the constraint graph and a constraint tree as main communication topology.|$|E
50|$|What sets A* {{apart from}} a greedy <b>best-first</b> <b>search</b> {{algorithm}} is that it takes the cost/distance already traveled, , into account.|$|E
40|$|Even ambitious {{algorithms}} for {{the generation}} of referring expressions that identify sets of objects are restricted in terms of efficiency or in their expressive repertoire. In this paper, we report on a system that applies a <b>best-first</b> <b>searching</b> procedure, enhancing both its effectiveness and the variety of expressions it can generate. ...|$|R
40|$|Existing {{algorithms}} {{for generating}} referential descriptions to sets of objects have serious deficits: while incremental approaches may produce ambiguous and redundant expressions, exhaustive searches are computationally expensive. Mediating between these extreme control regimes, we propose a <b>best-first</b> <b>searching</b> algorithm for uniquely identifying sets of objects. We incorporate linguistically motivated preferences and several techniques {{to cut down}} the search space. Preliminary results show {{the effectiveness of the}} new algorithm...|$|R
40|$|To harness modern {{multicore}} processors, it {{is imperative}} to develop parallel versions of fundamental algorithms. In this paper, we present a general approach to <b>best-first</b> heuristic <b>search</b> in a shared-memory setting. Each thread attempts to expand the most promising nodes. By using abstraction to partition the state space, we detect duplicate states while avoiding lock contention. We allow speculative expansions when necessary to keep threads busy. We identify and fix potential livelock conditions. In an empirical comparison on STRIPS planning, grid pathfinding, and sliding tile puzzle problems using an 8 -core machine, we show that A* implemented in our framework yields faster search performance than previous parallel search proposals. We also demonstrate that our approach extends easily to other <b>best-first</b> <b>searches,</b> such as weighted A* and anytime heuristic search...|$|R
50|$|<b>Best-first</b> <b>search</b> is {{a search}} {{algorithm}} which explores a graph by expanding {{the most promising}} node chosen according to a specified rule.|$|E
50|$|Hybrids {{of these}} DCOP {{algorithms}} also exist. BnB-Adopt, for example, changes the search strategy of Adopt from <b>best-first</b> <b>search</b> to depth-first branch-and-bound search.|$|E
5000|$|Iterative {{deepening}} A* is a <b>best-first</b> <b>search</b> that performs {{iterative deepening}} based on [...] ""-values {{similar to the}} ones computed in the A* algorithm.|$|E
40|$|Extraction of {{two-dimensional}} object locations using current techniques is a computationally intensive process. In {{this paper}} a parallel algorithm is presented that can specify {{the location of}} objects from edge streaks produced by an edge operator. <b>Best-first</b> <b>searches</b> are carried out {{in a number of}} non-interacting and localized edge streak spaces. The outcome of each search is a hypothesis. Each edge streak votes for a single hypothesis; it may also take part in the formation of other hypotheses. A poll of the votes determined the stronger hypotheses. The algorithm {{can be used as a}} front end to a visual pattern recognition system where features are extracted from the hypothesized object boundary or from the area localized by the hypothesized boundary. Experimental results from a biomedical domain are presented...|$|R
5000|$|In {{computer}} science, B* (pronounced [...] "B star") is a <b>best-first</b> graph <b>search</b> algorithm {{that finds}} the least-cost path from a given initial node to any goal node (out {{of one or}} more possible goals). First published by Hans Berliner in 1979, it is related to the A* search algorithm.|$|R
40|$|Beam {{searches}} are a {{very effective}} algorithm for solving problems that prove intractable to complete algorithms like weighted A * and greedy search. Unfortunately, the inadmis-sible pruning that {{is the hallmark of}} a beam search makes the algorithm incomplete. Existing complete extensions to beam search expand pruned nodes systematically according to generation order. Selecting pruned nodes to expand based upon generation order often causes the expansion of the most promising nodes to be delayed. This can cause the complete backtracking beam searches to expend unnecessary effort ex-ploring less promising parts of the search space leading to delayed solutions, lower quality solutions, or both. In this pa-per, we show that considering heuristic information when de-ciding where to backtrack can significantly improve the per-formance of backtracking beam searches. Although the beam searches using informed backtracking outperform the other kinds of restarting beam searches, none of the backtracking beam search algorithms are competitive with weighted A* and other <b>best-first</b> <b>searches...</b>|$|R
50|$|Recursive <b>best-first</b> <b>search</b> {{is another}} memory-constrained version of A* search {{that can be}} faster in {{practice}} than IDA*, since it requires less regenerating of nodes.|$|E
50|$|In {{computer}} science, {{beam search}} is a heuristic search algorithm that explores a graph by expanding {{the most promising}} node in a limited set. Beam search is an optimization of <b>best-first</b> <b>search</b> that reduces its memory requirements. <b>Best-first</b> <b>search</b> is a graph search which orders all partial solutions (states) according to some heuristic which attempts to predict how close a partial solution is to a complete solution (goal state). But in beam search, only a predetermined number of best partial solutions are kept as candidates. It is thus a greedy algorithm.|$|E
50|$|In some fields, {{artificial}} intelligence in particular, Dijkstra's algorithm or {{a variant of}} it is known as uniform-cost search and formulated as an instance of the more general idea of <b>best-first</b> <b>search.</b>|$|E
40|$|We {{introduce}} planar grouping, {{a technique}} where planar relationship information is {{gathered for a}} set of rigid points. This information is used to accelerate affine transformations and clipping. The planar grouping technique is an optimization problem, implemented in a <b>best-first</b> greedy <b>search.</b> We present two error metrics, one simple and fast, one based on the quadric error metric (QEM) to achieve higher quality planar grouping. We also apply the quadric error metric to linear grouping...|$|R
40|$|Automation of the {{mechanical}} design process has attracted much attention over the last decade. This paper reports a method of computational synthesis of the conceptual design of mechanisms. The design algorithm employs <b>best-first</b> heuristic <b>searches</b> in a library of mechanical devices, represented and classified qualitatively from various perspectives. A number of design alternatives can be generated from a specification. The suggested design solutions are compact and compatible with general engineering design principles. link_to_subscribed_fulltex...|$|R
40|$|Linear {{grouping}} is {{a technique}} where linear relationship information is gathered {{for a set of}} rigid points. This information is used to accelerate vertex transformation, vertex clipping, texture transformation, etc. The linear grouping technique is an optimization problem, originally implemented in a <b>best-first</b> branch-and-bound <b>search.</b> In this paper, we introduce several new extensions and improvements to linear grouping. In particular, the search algorithm is greatly improved. Keywords: real-time rendering, visualization, rendering hardware, transformation, level of detail, OpenGL, linear grouping. 1...|$|R
50|$|<b>Best-first</b> <b>search</b> algorithms, {{like the}} A* search algorithm, find the {{shortest}} path between two vertices or nodes of a weighted graph, trying {{out the most}} promising routes first. A priority queue (also known as the fringe) is used {{to keep track of}} unexplored routes; the one for which the estimate (a lower bound in the case of A*) of the total path length is smallest is given highest priority. If memory limitations make <b>best-first</b> <b>search</b> impractical, variants like the SMA* algorithm can be used instead, with a double-ended priority queue to allow removal of low-priority items.|$|E
50|$|Any search {{strategy}} {{can be used}} to search this space. Prolog uses a sequential, last-in-first-out, backtracking strategy, in which only one alternative and one sub-goal is considered at a time. Other search strategies, such as parallel search, intelligent backtracking, or <b>best-first</b> <b>search</b> to find an optimal solution, are also possible.|$|E
5000|$|Judea Pearl {{described}} <b>best-first</b> <b>search</b> as {{estimating the}} promise of node n by a [...] "heuristic evaluation function [...] which, in general, may depend on the description of n, {{the description of the}} goal, the information gathered by the search up to that point, and most important, on any extra knowledge about the problem domain." ...|$|E
3000|$|To {{find the}} index set K∗ {{which leads to}} the maximum αk,K (among all {{possible}} index set K’s), the tree search algorithm (TSA) performs a <b>best-first</b> branch-and-bound <b>search</b> [23] over a tree structure representing different subsets of { 1, 2,…,n}. In its essence, for each subset J with cardinality no bigger than k, TSA calculates an upper bound of αk,K, which is valid for any set K (with cardinality k) such that J⊆K. If this upper bound is smaller than a lower bound of α [...]...|$|R
40|$|AbstractThe paper {{presents}} a new proof-number (PN) search algorithm, called PDS–PN. It is a two-level search (like PN 2), which performs {{at the first}} level a depth-first proof-number and disproof-number search (PDS), and at the second level a <b>best-first</b> PN <b>search.</b> Hence, PDS–PN selectively exploits the power of both PN 2 and PDS. Experiments {{in the domain of}} Lines of Action are performed. They show that within an acceptable time frame PDS–PN is more effective for really hard endgame positions than αβ and any other PN-search algorithm...|$|R
40|$|Summary. Proof-Number (PN) <b>search</b> is a <b>best-first</b> {{adversarial}} <b>search</b> algorithm especially {{suited for}} finding the game-theoretical value in game trees. The {{strategy of the}} algorithm may be described as developing the tree into the direction where the opposition characterised by value and branching factor is to expect to be the weakest. In this chapter we start by providing a short description of the original PN-search method, and two main successors of the original PN search, i. e., PN 2 search and the depth-first variant Proof-number and Disproof-number Search (PDS). A comparison of the performance between PN, PN 2, PDS, and αβ is given. It is shown that PN-search algorithms clearly outperform αβ in solving endgame positions {{in the game of}} Lines of Action (LOA). However, memory problems make the plain PN search a weaker solver for harder problems. PDS and PN 2 are able to solve significantly more problems than PN and αβ. But PN 2 is restricted by its working memory, and PDS is considerably slower than PN 2. Next, we present a new proof-number search algorithm, called PDS-PN. It is a two-level search (like PN 2), which performs at the first level a depth-first PDS, and at the second level a <b>best-first</b> PN <b>search...</b>|$|R
5000|$|Some {{authors have}} used [...] "best-first search" [...] to refer {{specifically}} to a search with a heuristic {{that attempts to}} predict how close {{the end of a}} path is to a solution, so that paths which are judged to be closer to a solution are extended first. This specific type of search is called greedy <b>best-first</b> <b>search</b> or pure heuristic search.|$|E
50|$|In simple hill {{climbing}}, {{the first}} closer node is chosen, whereas in steepest ascent hill climbing all successors are compared and {{the closest to}} the solution is chosen. Both forms fail {{if there is no}} closer node, which may happen if there are local maxima in the search space which are not solutions. Steepest ascent hill climbing is similar to <b>best-first</b> <b>search,</b> which tries all possible extensions of the current path instead of only one.|$|E
50|$|MTD(f) {{was first}} {{described}} in a University of Alberta Technical Report authored by Aske Plaat, Jonathan Schaeffer, Wim Pijls, and Arie de Bruin, which would later receive the ICCA Novag Best Computer Chess Publication award for 1994/1995. The algorithm MTD(f) was created out of a research effort to understand the SSS* algorithm, a <b>best-first</b> <b>search</b> algorithm invented by George Stockman in 1979. SSS* {{was found to be}} equivalent to a series of alpha-beta calls, provided that alpha-beta used storage, such as a well-functioning transposition table.|$|E
40|$|Abstract. We {{introduce}} planar grouping, {{a technique}} where planar relationship information is {{gathered for a}} set of rigid points. This information is used to accelerate affine transformations and clipping. The planar grouping technique is an optimization problem, implemented in a <b>best-first</b> greedy <b>search.</b> We present two error metrics, one simple and fast, one based on the quadric error metric (QEM) to achieve higher quality planar grouping. We also apply the quadric error metric to linear grouping. Key Words: linear grouping, planar grouping, quadratic error metric MSC 2000 : 68 U 0...|$|R
40|$|Alpha-Beta {{has been}} the {{algorithm}} of choice for game-tree search for over three decades. Its success is largely attributable {{to a variety of}} enhancements to the basic algorithm that can dramatically improve the search efficiency. Although state-ofthe-art game-playing programs build trees that are close in size to the minimal Alpha-Beta search tree, this paper shows that there is still room for improvement. Three new enhancements are presented: <b>best-first</b> Alpha-Beta <b>search,</b> better use of transpositions, and improving aspiration search under real-time constraints. Measurements show that these improvements can reduce search effort b...|$|R
40|$|AND/OR search spaces {{accommodate}} advanced algorithmic {{schemes for}} graphical models which can exploit {{the structure of}} the model. The paper extends and evaluates the depthfirst and <b>best-first</b> AND/OR <b>search</b> algorithms to solving 0 - 1 Integer Linear Programs (0 - 1 ILP) within this framework. We also include a class of dynamic variable ordering heuristics while exploring an AND/OR search tree for 0 - 1 ILPs. We demonstrate the effectiveness of these search algorithms on a variety of benchmarks, including real-world combinatorial auctions, random uncapacitated warehouse location problems and MAX-SAT instances. ...|$|R
