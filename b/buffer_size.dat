1731|942|Public
2500|$|DDR SDRAM's {{prefetch}} <b>buffer</b> <b>size</b> is 2n (two datawords per memory access) ...|$|E
2500|$|DDR2 SDRAM's {{prefetch}} <b>buffer</b> <b>size</b> is 4n (four datawords per memory access) ...|$|E
2500|$|DDR3 SDRAM's {{prefetch}} <b>buffer</b> <b>size</b> is 8n (eight datawords per memory access) ...|$|E
40|$|Recent {{theoretical}} {{results in}} <b>buffer</b> <b>sizing</b> research suggest that core Internet routers can achieve high link utilization, {{if they are}} capable of storing only a handful of packets. The underlying assumption is that the traffic is non-bursty, and that the system is operated below 85 - 90 % utilization. In this paper, we present a test-bed for <b>buffer</b> <b>sizing</b> experiments using NetFPGA [2], a PCI-form factor board that contains reprogrammable FPGA elements, and four Gigabit Ethernet interfaces. We have designed and implemented a NetFPGA-based Ethernet switch with finely tunable <b>buffer</b> <b>sizes,</b> and an event capturing system to monitor buffer occupancies inside the switch. We show that reducing <b>buffer</b> <b>sizes</b> down to 20 - 50 packets does not necessarily degrade system performance. Categories and Subject Descriptor...|$|R
5000|$|Cache <b>buffer</b> <b>sizes</b> can {{be larger}} than what the 32-bit kernel space allows, {{potentially}} increasing I/O performance.|$|R
40|$|In {{choosing}} appropriate <b>buffer</b> <b>sizes</b> {{to study}} environmental influences on physical activity, studies are hampered by insufficient {{insight into the}} distance elderly travel actively. This study aims at getting insight into the number of trips walked and cycled within various <b>buffer</b> <b>sizes</b> using GPS measures. Data {{were obtained from the}} Elderly And their Neighborhood study (Spijkenisse, the Netherlands (2011 - 2012)). Trip length and mode of transport were derived from the GPS data (N= 120; total number of trips= 337). Distance decay functions were fitted to estimate the percentage of trips to grocery stores within commonly used <b>buffer</b> <b>sizes.</b> Fifty percent of the trips walked had a distance of at least 729. m; for trips cycled this was 1665. m. Elderly aged under 75 years and those with functional limitations walked and cycled shorter distances than those over 75 years and those without functional limitations. Males cycled shorter distances than females. Distance decay functions may aid the selection of appropriate <b>buffer</b> <b>sizes,</b> which may be tailored to individual characteristics. © 2014 Elsevier Ltd...|$|R
2500|$|A {{standard}} model of memory that employs association {{in this manner}} is the Search of Associative Memory (SAM) model. Though SAM was originally designed to model episodic memory, its mechanisms are sufficient to support some semantic memory representations, as well. The SAM model contains a short- term store (STS) and long term store (LTS), where STS is a briefly activated subset of {{the information in the}} LTS. [...] The STS has limited capacity and affects the retrieval process by limiting the amount of information that can be sampled and limiting the time the sampled subset is in an active mode. [...] The retrieval process in LTS is cue dependent and probabilistic, meaning that a cue initiates the retrieval process and the selected information from memory is random. [...] The probability of being sampled is dependent on the strength of association between the cue and the item being retrieved, with stronger associations being sampled and finally one is chosen. [...] The <b>buffer</b> <b>size</b> is defined as r, and not a fixed number, and as items are rehearsed in the buffer the associative strengths grow linearly {{as a function of the}} total time inside the buffer. In SAM, when any two items simultaneously occupy a working memory buffer, the strength of their association is incremented. Thus, items that co-occur more often are more strongly associated. Items in SAM are also associated with a specific context, where the strength of that association determined by how long each item is present in a given context. In SAM, then, memories consist of a set of associations between items in memory and between items and contexts. The presence of a set of items and/or a context is more likely to evoke, then, some subset of the items in memory. The degree to which items evoke one another—either by virtue of their shared context or their co-occurrence—is an indication of the items' semantic relatedness.|$|E
50|$|<b>Buffer</b> <b>size</b> for 17 RAW or 56 JPEG with maximum quality.|$|E
5000|$|PRINTMONBUFSIZE (OS/2 only) : Configures <b>buffer</b> <b>size</b> for LPT1, LPT2, LPT3.|$|E
40|$|In {{this letter}} we study {{the problem of}} the optimal design of buffer {{management}} policies within the class of pushout and expelling policies for a shared memory asynchronous transfer mode (ATM) switch or demultiplexer fed by traffic containing two different space priorities. A numerical study of the optimal policies for small <b>buffer</b> <b>sizes</b> is used to help design heuristics applicable to large <b>buffer</b> <b>sizes.</b> Simulation studies for large buffer systems are then presented...|$|R
40|$|International audienceCyclo-Static DataFlow (CSDF) is a {{powerful}} model for the specification of DSP applications. However, as in any asynchronous model, the synchronization of the different communicating tasks (processes) is made through buffers {{that have to be}} sized such that timing constraints are met. In this paper, we want to determine <b>buffer</b> <b>sizes</b> such that the throughput constraint is satisfied. This problem has been proved to be of exponential complexity. Exact techniques to solve this problem are too time and/or space consuming because of the self-timed schedule needed to evaluate the maximum throughput. Therefore, a periodic schedule is used. Each CSDF actor is associated with a period that satisfies the throughput constraint and sufficient <b>buffer</b> <b>sizes</b> are derived in polynomial time. However, within a period, an actor phases can be scheduled in different manners which impacts the evaluation of sufficient <b>buffer</b> <b>sizes.</b> This paper presents a Min-Max Linear Program that derives an optimized periodic phases scheduling per CSDF actor in order to minimize <b>buffer</b> <b>sizes.</b> It is shown through different applications that this Min-Max Linear Program allows to obtain close to optimal values while running in polynomial time...|$|R
40|$|Abstract—In {{this letter}} we study {{the problem of}} the optimal design of buffer {{management}} policies within the class of pushout and expelling policies for a shared memory asynchronous transfer mode (ATM) switch or demultiplexer fed by traffic containing two different space priorities. A numerical study of the optimal policies for small <b>buffer</b> <b>sizes</b> is used to help design heuristics applicable to large <b>buffer</b> <b>sizes.</b> Simulation studies for large buffer systems are then presented. Index Terms—ATM, buffer management, Markov decision theory, sample path techniques, shared memory switch. I...|$|R
5000|$|DDR SDRAM's {{prefetch}} <b>buffer</b> <b>size</b> is 2n (two datawords per memory access) ...|$|E
5000|$|DDR2 SDRAM's {{prefetch}} <b>buffer</b> <b>size</b> is 4n (four datawords per memory access) ...|$|E
5000|$|DDR3 SDRAM's {{prefetch}} <b>buffer</b> <b>size</b> is 8n (eight datawords per memory access) ...|$|E
40|$|Cyclo-Static DataFlow (CSDF) is a {{powerful}} model for the specification of DSP applications. However, as in any asynchronous model, the synchronization of the different communicating tasks (processes) is made through buffers {{that have to be}} sized such that timing constraints are met. In this paper, we want to determine <b>buffer</b> <b>sizes</b> such that the throughput constraint is satisfied. This problem has been proved to be of exponential complexity. Exact techniques to solve this problem are too time and/or space consuming because of the self-timed schedule needed to evaluate the maximum throughput. Therefore, a periodic schedule is used. Each CSDF actor is associated with a period that satisfies the throughput constraint and sufficient <b>buffer</b> <b>sizes</b> are derived in polynomial time. However, within a period, an actor phases can be scheduled in different manners which impacts the evaluation of sufficient <b>buffer</b> <b>sizes.</b> This paper presents a Min-Max Linear Program that derives an optimized periodic phases scheduling per CSDF actor in order to minimize <b>buffer</b> <b>sizes.</b> It is shown through an MP 3 Playback and an H. 263 Encoder that this Min-Max Linear Program allows to obtain close to optimal values while running in polynomial time. The impact of phases scheduling on periodic schedulability of applications with critical cycles is also highlighted on a Channel Equalizer...|$|R
40|$|<b>Buffer</b> <b>sizing</b> has {{received}} a lot of attention recently since it is becoming increasingly difficult to use large buffers in high-speed routers. Much of the prior work has concentrated on analyzing the amount of buffering required in core routers assuming that TCP carries all the data traffic. However, in recent years, the research community has been actively involved in developing better protocols for high-speed applications. Examples of such protocols include Rate Control Protocol (RCP), Explicit Control Protocol (XCP), Max-Net, etc. For these protocols no corresponding <b>buffer</b> <b>sizing</b> results exist in the literature. In this paper, we evaluate the amount of buffering required for RCP on a single congested link, while explicitly modeling flow arrivals and departures. Our theoretical analysis and simulations indicate that <b>buffer</b> <b>sizes</b> of about 10 % of the bandwidth-delay product are sufficient for RCP to deliver good performance to end-users. 1...|$|R
40|$|Estimation of cell loss ratios in a multiclass ATM network {{turns out}} to be a {{computationally}} intensive problem. In this paper, a computationally efficient algorithm is developed through a series of approximations. Multiple classes of bursty input sources are first approximated into an equivalent single class model. Based on the single-class model, the relationship between the arrival process and the <b>buffer</b> <b>sizes</b> is established by way of a renewal process alternating between overload and underload periods. Using variables associated with the renewal process, a typical two-dimensional model involving the arrival process and the <b>buffer</b> <b>sizes</b> is simplified into a onedimensional model. A further approximation is made by estimating the available buffer space at beginnings of overload periods. Numerical and simulation results show a good match at moderate <b>buffer</b> <b>sizes.</b> 1 Introduction A class of homogeneous ATM bursty sources has been modeled by a Fluid-Flow model [1, 10], a Markov-Modulated [...] ...|$|R
5000|$|The minimum <b>buffer</b> <b>size</b> {{for each}} of the 63 {{possible}} services (Service Input Buffers) is 128 bytes.|$|E
50|$|Buffer Override: This program {{compresses}} <b>buffer</b> <b>size,</b> {{resulting in}} the desired stuttering sounds, especially those similar {{to the sound of}} a vocoder.|$|E
50|$|Sliding-window {{flow control}} is best {{utilized}} when the <b>buffer</b> <b>size</b> is limited and pre-established. During a typical communication between a sender and a receiver the receiver allocates buffer space for n frames (n is the <b>buffer</b> <b>size</b> in frames). The sender can send and the receiver can accept n frames {{without having to}} wait for an acknowledgement. A sequence number is assigned to frames {{in order to help}} keep track of those frames which did receive an acknowledgement. The receiver acknowledges a frame by sending an acknowledgement that includes the sequence number of the next frame expected. This acknowledgement announces that the receiver is ready to receive n frames, beginning with the number specified. Both the sender and receiver maintain what is called a window. The size of the window is {{less than or equal to}} the <b>buffer</b> <b>size.</b>|$|E
3000|$|... [...])} as {{a buffer}} state. Depending on the <b>buffer’s</b> <b>size</b> L and the number K of relays, {{the total number of}} buffer states is given by (L[*]+[*] 1) [...]...|$|R
30|$|As the {{cooperative}} willingness of selfish nodes {{is affected by}} their resource constraint, in this section, we compare the performance of proposed protocols under different battery capacities and <b>buffer</b> <b>sizes.</b>|$|R
40|$|The {{performance}} of TCP in wide-area networks (WANs) {{is becoming increasingly}} important with the deployment of computational and data grids. In WAN environments, TCP does not provide good performance for data-intensive applications without the tuning of flow-control <b>buffer</b> <b>sizes.</b> Manual adjustment of <b>buffer</b> <b>sizes</b> is tedious even for network experts. For scientists, tuning is often an impediment to getting work done. Thus, buffer tuning should be automated. Existing techniques for automatic buffer tuning only measure the bandwidth-delay product (BDP) during connection establishment. This ignores the (large) fluctuation of the BDP over the lifetime of the connection. In contrast, the dynamic right-sizing algorithm dynamically changes <b>buffer</b> <b>sizes</b> in response to changing network conditions. In this paper, we describe a new user-space implementation of dynamic right-sizing in FTP (drsFTP) that supports third-party data transfers, a mainstay of scientific computing. In addition to comparing the {{performance of}} the new implementation with the old in a WAN-emulated environment, we give performance results over a live WAN. The new implementation produces transfer rates of up to five times higher than untuned FTP. 1...|$|R
5000|$|...u - Sets the send/receive <b>buffer</b> <b>size</b> in bytes. Default value will be {{automatically}} calculated {{based on}} transfer speed, packet size and host timer accuracy.|$|E
5000|$|The network {{throughput}} of {{a connection with}} flow control, for example a TCP connection, with a certain window size (<b>buffer</b> <b>size),</b> can be expressed as: ...|$|E
5000|$|Note: This is {{sometimes}} denoted C + k where k is the <b>buffer</b> <b>size,</b> {{the number of}} places in the queue above the number of servers C.|$|E
40|$|Average cell {{loss and}} cell delay {{behavior}} of a simulated 155 Mbit/s ATM multiplexer is studied for aggregated traffic {{from a number of}} Pareto-modulated Poisson process (PMPP) sources. PMPP traffic sources are known to generate self-similar traffic with long-range dependence; the dependence of average cell loss ratio and average cell delay parameters on varying <b>buffer</b> <b>sizes</b> is reported. Inappropriateness of large buffers in reducing the cell loss ratio significantly for self-similar, LRD traffic is established. Results shows that if both average CLR and average cell delay are combined together, increasing <b>buffer</b> <b>sizes</b> beyond a limit increases the delay much more significantly than reducing the CLR...|$|R
50|$|USB 2.0 {{oscilloscopes}} from Pico Tech {{are available}} with bandwidths up to 1 GHz, up to 4 input channels, hardware vertical resolutions up to 16 bits, sampling rates up to 5 GS/s, <b>buffer</b> <b>sizes</b> up to 2 GS, and built-in signal generators.|$|R
40|$|Abstract — Conventional wisdom {{suggests}} that bigger switch buffers translate to lower packet loss. However, we have observed in simulations (using ns 2) that <b>buffer</b> <b>sizes</b> {{in the range}} of interest for optical packet switched networks show unexpected behaviour: larger buffers can cause higher losses for open-loop (real-time) traffic when it multiplexes with closed-loop (TCP) traffic. In this short paper we develop a simplified Markov Chain model that helps explain this anomalous behaviour. The phenomenon observed in this paper can be of serious concern to all-optical packet switch designers and network service providers, who make huge investment in setting up the network infrastructure, but only to realise potentially degraded performance if appropriate care is not taken when dimensioning their router <b>buffer</b> <b>sizes.</b> I...|$|R
50|$|One way {{to think}} of the VBV is to {{consider}} both a maximum bitrate and a maximum <b>buffer</b> <b>size.</b> You'll need to know how quickly the video data is coming into the buffer. Keep in mind that video data is always changing the bitrate so there is no constant number to note how fast the data is arriving. The larger question is how long before the buffer overflows. A larger <b>buffer</b> <b>size</b> simply means that the decoder will tolerate high bitrates for longer periods of time, but no buffer is infinite, so eventually even a large buffer will overflow.|$|E
5000|$|An {{improved}} <b>buffer</b> <b>size</b> that at {{its highest}} frame rate (6 frames per second) can store eighteen raw images (entire APS-C frame recorded, 14-bit lossless compressed), whereas the D7100 can store six images.|$|E
50|$|The {{larger the}} buffer is, {{the more time}} it takes to fill it by digital audio data. Large buffers {{increase}} the time required for processing audio in computer, this delay is usually called latency. Every system has certain limitations - too small buffers involving negligible latencies cannot be smoothly processed by computer, so the reasonable size starts at about 32 samples. The processor load does not affect latency directly (it means, once you set certain <b>buffer</b> <b>size,</b> the latency is constant), but with very high processor loads the processing starts dropping out. Increasing <b>buffer</b> <b>size</b> or quitting other application helps to keep playback smooth.|$|E
40|$|Abstract: Buffer memory {{allocation}} {{is one of}} the most important, but also one of the most difficult tasks of database system administration. Typically, database manage-ment systems use several buffers simultaneously for various reasons, e. g., disk speed, page size, access behavior. As a result, available main memory is partitioned among all buffers within the system to suit the expected workload, which is a highly complex optimization problem. Even worse, a carefully adjusted configuration can become inefficient very quickly on workload shifts. Self-tuning techniques automatically ad-dress this allocation problem using periodic adjustments of <b>buffer</b> <b>sizes.</b> The tuning itself is usually achieved by changing memory (re-) allocations based on hit/miss ratios, thereby aiming at minimization of I/O costs. All techniques proposed so far observe or simulate the buffer behavior to make forecasts whether or not increased <b>buffer</b> <b>sizes</b> are beneficial. However, database buffers do not scale uniformly (i. e., in a linear fash-ion) and simple extrapolations of the current performance figures can easily lead to wrong assumptions. In this work, we explore the use of lightweight extensions for known buffer algorithms to improve the forecast quality by identifying the effects of varying <b>buffer</b> <b>sizes</b> using simulation. Furthermore, a simple cost model is presented to optimize dynamic memory assignments based on these forecast results. ...|$|R
40|$|This work solves a sub-problem {{required}} to enable software synthesis for Parallel Heterogeneous Platforms (PHPs). This sub-problem {{is concerned with}} determining the <b>buffer</b> <b>sizes</b> between processing elements. In the design flow, task allocation and scheduling are carried out before <b>buffer</b> <b>sizing.</b> Given a PHP {{with a number of}} processors and a set of tasks, a heuristic is used to allocate tasks onto processors and to schedule them. The input of this algorithm is a precedence DAG, whose vertices represent the tasks and whose edges represent data dependencies. The scheduling algorithm [1] assumes unlimited FIFO sizes between processors, but this is not true in reality. Architectural platforms have finite-depth FIFOs between processors. If the FIFO depth is too small, execution may deadlock. We call this kind of deadlock artificial deadlock [2], as compared to real deadlock which can occur even if the FIFO depth were unlimited. Prior work in this field mainly focuses on the <b>buffer</b> <b>sizing</b> problem in uni-processor platforms [3]. The previous work that deals with multiprocessor buffer minimization [4] does not consider interleaving communication, where two active tasks on different processors can communicate large amounts of data using one-place buffers. In this work, we develop algorithms to address this problem. Theoretical a...|$|R
40|$|Wireless {{networks}} face {{a number}} of fundamental issues that do not arise in wired networks. We consider the <b>sizing</b> of network <b>buffers</b> in 802. 11 based wireless networks. 802. 11 {{is a set of}} standards for implementing wireless local area network (WLAN) computer communication using different frequency bands. They are created and maintained by the IEEE LAN/MAN Standards Committee (IEEE 802). All internet routers contain buffers to hold packets during the time of congestion. Buffers are used to reduce the packet loss and to ensure high link efficiency. The widely used general rule-of-thumb is to have <b>buffers</b> <b>size</b> as the bandwidth-delay product (BDP) of the network, In this paper we argue that the use of the fixed <b>size</b> <b>buffers</b> in 802. 11 based wireless networks results in either undesirable channel under-utilization or unnecessary high delays and the increased packet loss. Our objective is to maintain high network utilization while providing low queuing delays in 802. 11 wireless networks through dynamic <b>buffer</b> <b>sizing</b> algorithms...|$|R
