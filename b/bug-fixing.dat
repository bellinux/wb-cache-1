104|162|Public
5|$|Team member Lucas Davis {{compiled}} {{the development}} tools and documentation for Anachronox and released them in August 2001. Four <b>bug-fixing</b> patches exist for Anachronox. Ion Storm {{created the first}} (1.01), which fixed the Windows 2000 buffer overrun crash and implemented other improvements such as taxi-cabs between distant points and enhanced save game functionality. Ion Storm released the first patch (1.01) on July 2, 2001. Joey Liaw set up a GeoCities website for reporting bugs and technical information after the game's release, and worked on a new patch in his spare time. The second patch (1.02, or build 44) was released in May 2003 and overhauls the save-game system and provides other important stability fixes. The third and fourth patches—1.02 (build 45), released September 2003, and 1.02 (build 46), released April 2004—are fan-made unofficial patches and fix {{most of the remaining}} bugs. Fans have translated the game into German and released a conversion patch. Level designer Rich Carlson released a scrapped secret level for Anachronox in February 2004 after finding it on an old floppy disk.|$|E
500|$|Hironobu Sakaguchi {{likened the}} {{development}} of Chrono Trigger to [...] "play around with Toriyama's universe," [...] citing the inclusion of humorous sequences in the game {{that would have been}} [...] "impossible with something like Final Fantasy." [...] When Square Co. suggested a non-human player character, developers created Frog by adapting one of Toriyama's sketches. The team created the End of Time to help players with hints, worrying that they might become stuck and need to consult a walkthrough. The game's testers had previously complained that Chrono Trigger was too difficult; as Horii explained, [...] "It's because we know too much. The developers think the game's just right; that they're being too soft. They're thinking from their own experience. The puzzles were the same. Lots of players didn't figure out things we thought they'd get easily." [...] Sakaguchi later cited the unusual desire of beta testers to play the game a second time or [...] "travel through time again" [...] as an affirmation of the New Game + feature: [...] "Wherever we could, we tried to make it so that a slight change in your behavior caused subtle differences in people's reactions, even down to the smallest details... I think the second playthrough will hold a whole new interest." [...] The game's reuse of locations due to time traveling made <b>bug-fixing</b> difficult, as corrections would cause unintended consequences in other eras.|$|E
50|$|Generate-and-validate {{techniques}} for automatic <b>bug-fixing</b> {{are still in}} theirinfancy. Two earliest generate-and-validate <b>bug-fixing</b> systems are GenProg andClearView. The effectiveness ofgenerate-and-validate techniques remains controversial, because they typically do not provide patch correctness guarantees. Nevertheless, the reported results of recent state-of-the-art techniques are generallypromising. For example, on systematically collected 69 real world bugs in eight large C softwareprograms, the state-of-the-art <b>bug-fixing</b> system Prophet generates correct patches for 18 out of the 69 bugs.|$|E
40|$|The {{number of}} bugs (or fixes) {{is a common}} factor {{used to measure the}} quality of {{software}} and assist bug related analysis. For example, if software files have many bugs, they may be unstable. In comparison, the <b>bug-fix</b> time—the time to fix a bug after the bug was introduced—is neglected. We believe that the <b>bug-fix</b> time is an important factor for bug related analysis, such as measuring software quality. For example, if bugs in a file take a relatively long time to be fixed, the file may have some structural problems that make it difficult to make changes. In this report, we compute the <b>bug-fix</b> time of files in ArgoUML and PostgreSQL by identifying when bugs are introduced and when the bugs are fixed. This report includes <b>bug-fix</b> time statistics such as average <b>bug-fix</b> time, and distributions of <b>bug-fix</b> time. We also list the top 20 <b>bug-fix</b> time files of two projects...|$|R
40|$|Mining {{software}} repositories for bug detection requires accurate {{techniques of}} identi-fying <b>bug-fix</b> revisions. There {{have been many}} researches to find exact <b>bug-fix</b> revisions. However there are still noises, we call these noises non-fix hunks, even in exactly iden-tified <b>bug-fix</b> revisions. Our goal is to remove these non-fix hunks automatically. First we inspected every 50 <b>bug-fix</b> revisions of three open source projects (Eclipse, Lucene, and Columba). Among total 2146 hunks we found 179 non-fix hunks. We classified these non-fix hunks into 11 patterns. For all patterns we enumerate enabling static analysis techniques. ...|$|R
40|$|Abstract—If a bug gets {{fixed in}} {{duplicated}} code, often all duplicates (so called clones) {{need to be}} modified accordingly. In practice, however, fixes are often incomplete, causing the bug to remain {{in one or more}} of the clones. In this paper, we present an approach to detect such incomplete <b>bug-fixes</b> in cloned code. It analyzes a system’s version history to reveal those commits that fix problems. It then performs incremental clone detection to reveal those clones that became inconsistent as a result of such a fix. We present results from a case study that analyzed incomplete <b>bug-fixes</b> in six industrial and open source systems to demonstrate the feasibility and defectiveness of the approach. We discovered likely incomplete <b>bug-fixes</b> in all analyzed systems. Keywords-code clones, clone detection, incomplete <b>bug-fixes,</b> evolution analysis, repository analysis I...|$|R
50|$|SemFix: The first solver-based <b>bug-fixing</b> {{tool for}} C.|$|E
50|$|Automatic <b>bug-fixing</b> is {{an active}} {{research}} topic in computer science. There aremany implementations of various <b>bug-fixing</b> techniques especially for C and Javaprograms. Note {{that most of these}} implementations are research prototypes fordemonstrating their techniques, i.e., it is unclear whether their currentimplementations are ready for industrial usage or not.|$|E
50|$|GenProg and ClearView are two {{earliest}} generate-and-validate <b>bug-fixing</b> toolspublished at 2009. The benchmark {{collected by}} GenProg authors contains 69 realworld defects {{and it is}} widely used to evaluate many other <b>bug-fixing</b> tools in C as well.The state-of-the-art tool evaluated on GenProg benchmark is Prophet, generating correct patches for 18 out of 69 defects.|$|E
5000|$|JSF 1.1 (2004-05-27) - <b>Bug-fix</b> release. No {{specification}} changes.|$|R
5000|$|... 1.0.0, 1.0.1, 1.0.2, 1.0.3... stable {{release and}} {{follow-up}} <b>bug-fix</b> releases ...|$|R
5000|$|... 1.2.0, 1.2.1, 1.2.2, 1.2.3... stable {{release and}} {{follow-up}} <b>bug-fix</b> releases ...|$|R
50|$|Here {{is a list}} of <b>bug-fixing</b> {{tools for}} C {{programs}} ordered by the published year.|$|E
5000|$|Targeted {{automatic}} <b>bug-fixing</b> techniques generate repairs {{for specific}} classesof errors such as null pointer exception ...|$|E
50|$|At {{the patch}} {{generation}} step, automatic <b>bug-fixing</b> techniques use one or moreof the followings {{to generate a}} set of candidate patches.|$|E
5000|$|Compton-A <b>bug-fixed</b> fork of dcompmgr, {{which is}} a fork of xcompmgr ...|$|R
5000|$|QuarkXPress 6.52 (2006) - <b>Bug-fix</b> release, {{released}} after release of Quark 7.|$|R
5000|$|QuarkXPress 7.5 (2008) - <b>Bug-fix</b> release, {{released}} after release of Quark 8.|$|R
5000|$|... (2001) 2.0: Version 2.0 was a <b>bug-fixing</b> and {{security}} upgrade, which offered additional features like HTML on profiles and colored usernames.|$|E
50|$|AutoFixE: A <b>bug-fixing</b> {{tool for}} Eiffel language. It relies the {{contracts}} (i.e., {{a form of}} formal specification) in Eiffel programs to validate generated patches.|$|E
50|$|In 1998, the {{development}} mostly took a <b>bug-fixing</b> direction as Ritlabs new product The Bat! became a more promising software product with much better commercial potential.|$|E
50|$|The {{developers}} of some forks contribute features and <b>bug-fixes</b> back upstream to DC++.|$|R
50|$|While {{official}} releases {{have recently}} been infrequent, regular development and <b>bug-fixes</b> occur in CVS.|$|R
40|$|Predicting <b>bug-fix</b> time {{is useful}} in several areas of {{software}} evolution, such as predicting software quality or coordinating development effort during bug triaging. Prior work has proposed <b>bug-fix</b> time prediction models that use various bug report attributes (e. g., number of developers who participated in fixing the bug, bug severity, number of patches, bug-opener’s reputation) for estimating the time {{it will take to}} fix a newly-reported bug. In this paper we take a step towards constructing more accurate and more general <b>bug-fix</b> time prediction models by showing how existing models fail to validate on large projects widely-used in bug studies. In particular, we used multivariate and univariate regression testing to test the prediction significance of existing models on 512, 474 bug reports from five open source projects: Eclipse, Chrome and three products from the Mozilla project (Firefox, Seamonkey and Thunderbird). The results of our regression testing indicate that the predictive power of existing models is between 30 % and 49 % {{and that there is a}} need for more independent variables (attributes) when constructing a prediction model. Additionally, we found that, unlike in prior recent studies on commercial software, in the projects we examined there is no correlation between <b>bug-fix</b> likelihood, bug-opener’s reputation and the time it takes to fix a bug. These findings indicate three open research problems: (1) assessing whether prioritizing bugs using bug-opener’s reputation is beneficial, (2) identifying attributes which are effective in predicting <b>bug-fix</b> time, and (3) constructing <b>bug-fix</b> time prediction models which can be validated on multiple projects...|$|R
50|$|Angelix: An {{improved}} solver-based <b>bug-fixing</b> tool. It is evaluated on the GenProg benchmark. For 10 {{out of the}} 69 cases, it generate patches that {{is equivalent}} to human patches.|$|E
50|$|On December 4, 2015, Sony Mobile {{released}} {{another small}} <b>bug-fixing</b> update for the Xperia Z1 models with build number 14.6.A.1.236. Initial reports suggest few noticeable changes {{over the previous}} build (14.6.A.1.216).|$|E
50|$|The {{emulator}} has had continuous enhancement and <b>bug-fixing,</b> {{since its}} original development back in 1995, making it quite bug-free. Later {{versions of the}} emulator are fully functional, {{even when it is}} not registered.|$|E
50|$|Novell later {{released}} <b>bug-fix</b> versions 1.1.1, 1.1.2, 1.1.3 {{and finally}} 1.1.4 on 19 June 1995.|$|R
5000|$|... 1.03: {{included}} in ROM versions JM and TB; a minor <b>bug-fix</b> release issued in late 1984.|$|R
50|$|IBM PC with CGA, August 16, 1984: Published by Sierra in gray {{cardboard}} box. <b>Bug-fixed</b> version, adds RGBI color mode.|$|R
50|$|CodePhage: The first <b>bug-fixing</b> {{tool that}} {{directly}} transfer code across programs to generate patch for C program. Note that although it generates C patches, it can extract code from binary programs without source code.|$|E
50|$|GenProg: A genetic {{improvement}} generate-and-validate <b>bug-fixing</b> tool. Itis evaluated on 105 cases and reported to generate repairs for 55 cases. Alater {{study shows that}} only 69 cases out of the 105 evaluated cases correspondto bugs and correct patches for only 2 cases out of the 69 cases are generated.|$|E
5000|$|Automatic <b>bug-fixing</b> {{techniques}} {{that rely on}} a test suite do not provide patchcorrectness guarantees, because the test suite is incomplete and doesnot cover all cases. A weak test suite may cause generate-and-validatetechniques to produce validated but incorrect patches that have negativeeffects such as eliminating desirable functionalities, causing memory leaks,and introducing security vulnerabilities. This weak test suite issue isalternatively called as [...] "overfitting" [...] of <b>bug-fixing</b> systems.For example, a recent study shows that for 52 out of 55 cases that the previousbug-fixing system GenProg reports to generate repairs, all of the generatedpatches are incorrect. Recent state-of-the-art systems with machine learning orSMT solver techniques are able to generate correct patches for much more caseson the same benchmark set, {{but there are still}} plenty of validated butincorrect patches generated by these systems.|$|E
3000|$|... {{regression}} testing by checking whether new features or <b>bug-fixes</b> affect test results {{and to ensure}} coherence between the RTL code and other design representations.|$|R
40|$|Recent {{studies in}} {{analyzing}} <b>bug-fix</b> patterns recorded in software repositories show that method invocation(MI) fixes are very common. Our {{belief is that}} these bug fixes could be analyzed further to provide detailed information that allows software engineers to avoid these bugs. For example, developers may have a higher awareness of their intentions in choosing which method to invoke. Unfortunately, previous studies could not provide such information. In this paper, we propose atechnique to accurately identify the precise MI <b>bug-fix</b> changes. We have applied our technique to empirically investigate the origins of MI bug fixes in six open source Java software. We have classified these MI <b>bug-fix</b> origins (e. g. from standard Java library, from third-party library, or in standard code-base). Amajor finding is that MI faults involving Java library methods were under-represented when compared to their usage frequency...|$|R
50|$|On 27 May 2012, a new stable version, v1.76.1, was released. This is a <b>bug-fix</b> {{update to}} Oolite 1.76. It does not add new features.|$|R
