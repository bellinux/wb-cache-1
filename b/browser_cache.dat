47|55|Public
5|$|Norton Internet Security version 1.0 for Mac was {{released}} November 1, 2000. It can identify and remove both Windows and Mac viruses. Other features include a firewall, advertisement blocking in the browser, parental controls, {{and the ability}} to prevent confidential information from being transmitted outside the computer. Users are prompted before such information is able to be transmitted. The incorporation of Aladdin Systems' iClean allows users to purge the <b>browser</b> <b>cache,</b> cookies, and browsing history within Norton's interface. Operating system requirements call for Mac OS 8.1. Hardware requirements call for 24 MB of RAM, 12 MB of disk space, and a PowerPC processor.|$|E
5|$|Symantec {{announced}} a Professional Edition on November 19, 2002. Data recovery tools in this version allow users to recover deleted or malware-damaged files. The {{inclusion of a}} data erasure tool allows users to delete files while minimizing the chance of recovery. Web Cleanup removes <b>browser</b> <b>cache</b> files, history, and cookies. To maintain dial-up connections, Connection Keep Alive simulates online activity during periods of user inactivity. Norton Productivity Control enables users to filter Internet content and block newsgroups. When used with the User Access Manager, multiple filtering profiles can be created, assigned to different users.|$|E
2500|$|... "Delete Browsing History" [...] cleans the {{complete}} browsing {{history in a}} single step. Previously this was a multistage process requiring users to delete <b>browser</b> <b>cache,</b> history, cookies, saved form data and passwords {{in a series of}} different steps. This is useful for improving privacy and security in a multiuser environment, such as an Internet café.|$|E
5000|$|... “From <b>Browser’s</b> <b>Cache</b> to the Human Genome - Towards an Extended Notion of Publishing” ...|$|R
2500|$|... "Browser-related issues. Please {{note that}} if you find your browser {{continually}} reloading while attempting to access your Inbox, it's probably a browser issue, {{and it may be}} necessary to clear your <b>browser's</b> <b>cache</b> and cookies." ...|$|R
50|$|Offline support helps <b>browsers</b> <b>cache</b> static pages. They depend more on HTTP {{response}} headers sent by {{web servers}} to fetch HTML, CSS and multimedia required {{to render the}} web page. If everything required to render is cached, then a page loads quickly, but even if one item is not cached then everything slows down dramatically.|$|R
50|$|ETags may be flushable by {{clearing}} the <b>browser</b> <b>cache</b> (implementations vary).|$|E
50|$|ETags can be flushed in some browsers by {{clearing}} the <b>browser</b> <b>cache.</b>|$|E
50|$|However, {{this alone}} will not {{necessarily}} give the user adequate privacy. Other factors {{may need to be}} considered, depending on the user's requirements. Such factors include the contents of the web <b>browser</b> <b>cache,</b> encryption of the data being transmitted over the network, and anonymity/traceability of the user's network connection.|$|E
40|$|This paper {{presents}} an information agent and latent semantic-based indexing architecture to retrieve documents on the Internet. The system optimizes {{the search for}} documents in the Internet by automatically retrieving relevant links. The information used for the search can be obtained, for instance, from Internet <b>browser</b> <b>caches</b> and from grades of relevance manually informed. To leverage the scope of retrieved documents, the system makes use of existing indexing mechanisms. Returned documents are then filtered using Latent Semantic Indexing (LSI). In a co-operative environment, the proposed architecture provides for sharing of documents and grades among the group. The architecture {{has been used in}} a cooperative learning environment, where students share their <b>browser</b> <b>caches</b> and retrieved documents. The paper focuses on the architecture of the information agent; the context reconnaissance, search, and filter modules are described. Scenarios of usage and system performance are also addressed. Three figure...|$|R
40|$|Web {{objects are}} {{typically}} associated with one authority that can originate and modify them (their authoritative server), but can be cached and further distributed from multiple replicating servers. Indeed, caching and replication are widely deployed for reducing Web-servers load, network load, and user-perceived latency. Replicating servers are located in different points in the network and include reverse proxies, proxy <b>caches,</b> and <b>browser</b> <b>caches...</b>|$|R
40|$|Abstract—Like {{conventional}} cookies, cache {{cookies are}} data objects that servers store in Web <b>browsers.</b> <b>Cache</b> cookies, however, are essentially unintentional byproducts of protocol design for <b>browser</b> <b>caches.</b> They {{do not enjoy}} any explicit interface support or security policies. In this paper, we show that despite limitations, cache cookies can play a useful role in the identification and authentication of users. Many users today block conventional cookies in their browsers as a privacy measure. The cache-cookie tools we propose can help restore lost usability and convenience to such users while maintaining good standards for privacy. As we show, our techniques can also help combat online security threats as phishing and pharming that ordinary cookies cannot. In fact, the ideas we introduce for cachecookie management can strengthen ordinary cookies as well. Because cache cookies have been viewed traditionally {{as a threat to}} user privacy, and lack important read-access restrictions, we propose cache-cookie protocols that aim to protect privacy by design...|$|R
5000|$|Items that expire with time: Some caches keep {{information}} that expires (e.g. a news cache, a DNS cache, or a web <b>browser</b> <b>cache).</b> The computer may discard items {{because they are}} expired. Depending {{on the size of}} the cache no further caching algorithm to discard items may be necessary.|$|E
50|$|Temporary Internet Files is {{a folder}} on Microsoft Windows {{which serves as}} the <b>browser</b> <b>cache</b> for Internet Explorer to cache pages and other {{multimedia}} content, such as video and audio files, from websites visited by the user. This allows such websites to load more quickly {{the next time they}} are visited.|$|E
5000|$|... "Delete Browsing History" [...] cleans the {{complete}} browsing {{history in a}} single step. Previously this was a multistage process requiring users to delete <b>browser</b> <b>cache,</b> history, cookies, saved form data and passwords {{in a series of}} different steps. This is useful for improving privacy and security in a multiuser environment, such as an Internet café.|$|E
40|$|Like {{conventional}} cookies, cache {{cookies are}} data objects that servers store in Web <b>browsers.</b> <b>Cache</b> cookies, however, are unintentional byproducts of protocol design for <b>browser</b> <b>caches.</b> They {{do not enjoy}} any explicit interface support or security policies. In this paper, we show that despite limitations, cache cookies can play a useful role in the identification and authentication of users. Many users today block conventional cookies in their browsers as a privacy measure. The cache-cookie tools we propose can help restore lost usability and convenience to such users while maintaining good privacy. As we show, our techniques can also help combat online security threats as phishing and pharming that ordinary cookies cannot. The ideas we introduce for cache-cookie management can strengthen ordinary cookies as well. Because cache cookies have been viewed traditionally {{as a threat to}} user privacy, and lack important read-access restrictions, we propose cache-cookie protocols that aim to protect privacy by design. The full version of this paper may be referenced at www. ravenwhite. com...|$|R
50|$|Overall, users {{experience}} of a site utilising style sheets will generally be quicker than sites that don’t use the technology. ‘Overall’ as the first page will probably load more slowly - because the style sheet AND the content {{will need to be}} transferred. Subsequent pages will load faster because no style information will need to be downloaded - the CSS file will already be in the <b>browser’s</b> <b>cache.</b>|$|R
5000|$|A web <b>browser</b> may <b>cache</b> {{elements}} {{using its}} own algorithms, which can operate without explicit directives in the document's markup.|$|R
50|$|The <b>browser</b> <b>cache</b> {{can also}} be used to store {{information}} that can be used to track individual users. This technique takes advantage of the fact that the web browser will use resources stored within the cache instead of downloading them from the website when it determines that the cache already has the most up-to-date version of the resource.|$|E
50|$|Bandwidth: A stylesheet, {{internal}} or external, specifies the style once {{for a range}} of HTML elements selected by , type or relationship to others. This is much more efficient than repeating style information inline for each occurrence of the element. An external stylesheet is usually stored in the <b>browser</b> <b>cache,</b> and can therefore be used on multiple pages without being reloaded, further reducing data transfer over a network.|$|E
50|$|The browser {{automatically}} cached the Flash file {{while it}} played, {{and it could}} be retrieved from the <b>browser</b> <b>cache</b> once it had fully played. There were also several tools and browser extensions to download the file. It could be then viewed in video players that could handle flash, for example VLC media player, Media Player Classic (with ffdshow installed), MPlayer or an FLV player.|$|E
50|$|HTTP is {{designed}} to permit intermediate network elements to improve or enable communications between clients and servers. High-traffic websites often benefit from web cache servers that deliver content on behalf of upstream servers to improve response time. Web <b>browsers</b> <b>cache</b> previously accessed web resources and reuse them when possible to reduce network traffic. HTTP proxy servers at private network boundaries can facilitate communication for clients without a globally routable address, by relaying messages with external servers.|$|R
40|$|The {{purpose of}} this paper is to {{introduce}} a replicable WWW protocol analysis methodology illustrated by application to data collected in the laboratory. The methodology uses instrumentation to obtain detailed recordings of user actions with a <b>browser,</b> <b>caches</b> Web pages encountered, and videotapes talk-aloud protocols. We apply the current form of the method to the analysis of eight Web protocols, visualizing the structure of the interaction and showing the strong effect of information scent in determining the path followed...|$|R
50|$|The {{extensive}} use of web caches also presented a problem for log file analysis. If a person revisits a page, the second request will often be retrieved from the <b>browser's</b> <b>cache,</b> and so no request will be received by the web server. This means that the person's path through the site is lost. Caching can be defeated by configuring the web server, but this can result in degraded performance for the visitor and bigger load on the servers.|$|R
5000|$|For rapid loading, {{service workers}} store the Basic User Interface or [...] "shell" [...] of the RWD web application. This shell {{provides}} an initial static frame, a layout or architecture into which content can be loaded progressively {{as well as}} dynamically, allowing users to engage with the app despite varying degrees of web connectivity. Technically, the shell is a code bundle stored locally in the <b>browser</b> <b>cache</b> of the mobile device.|$|E
50|$|The toolbar {{includes}} a toggleable pane {{at the bottom}} of the window. The pane shows the structure of the web page; and for each structure, the properties and styles. It exposes its features through a menu hierarchy, and includes toolbar buttons for quick access to features such as clearing the <b>browser</b> <b>cache</b> and enabling the selecting of elements by clicking in the rendered page, rather than navigating through the visual representation of the DOM tree.|$|E
50|$|These factors led to {{interest}} {{in the use of}} large scale storage (and to a lesser extent, processing) resources to cache the response to network requests, first at the Internet endpoint using a Web <b>browser</b> <b>cache</b> and later at intermediate network locations using shared network caches.This line of development also gave rise to Web server replication and other techniques for offloading and distributing the work of delivering large volume Web services to widely dispersed client communities, ultimately resulting in the creation of modern Content delivery networks.|$|E
5000|$|Most web <b>browsers</b> <b>cache</b> applets so {{they will}} be quick to load when {{returning}} to a web page. Applets also improve with use: after a first applet is run, the JVM is already running and starts quickly (the JVM will need to restart each time the browser starts afresh). It {{should be noted that}} JRE versions 1.5 and greater stop the JVM and restart it when the browser navigates from one HTML page containing an applet to another containing an applet.|$|R
5000|$|No Disk <b>Cache</b> - The <b>browser</b> disk <b>cache</b> {{has been}} {{disabled}} to decrease disk size {{and the number of}} writes to the disk, possibly increasing disk life.|$|R
50|$|Dalesa {{can be used}} as an {{alternative}} to centralized web caches in a Local Area Network. This is done by exposing local web <b>browser</b> <b>caches</b> to the entire P2P network. This is achieved through a daemon (computer software) which act as a web proxy server in every participating node. If a web request misses the local cache then the system fail-back to multicast based lookup protocol to query the P2P network, if any other node on the network gives a positive response to this query then the web object will be fetched from that node.|$|R
50|$|In 2011, Soltani and Berkeley law {{professor}} Chris Hoofnagle published a follow-up study, documenting {{the use of}} web <b>browser</b> <b>cache</b> ETags to store persistent identifiers. As with the case of Flash cookies, the identifiers stored in the ETags persisted even after consumers deleted their browser cookies. The ETag tracking issue {{caught the attention of}} several members of Congress, who wrote to the Federal Trade Commission in September 2011 and urged the agency to investigate the use of advanced tracking technologies as a potentially unfair or deceptive business practice.|$|E
50|$|Symantec {{announced}} a Professional Edition on November 19, 2002. Data recovery tools in this version allow users to recover deleted or malware-damaged files. The {{inclusion of a}} data erasure tool allows users to delete files while minimizing the chance of recovery. Web Cleanup removes <b>browser</b> <b>cache</b> files, history, and cookies. To maintain dial-up connections, Connection Keep Alive simulates online activity during periods of user inactivity. Norton Productivity Control enables users to filter Internet content and block newsgroups. When used with the User Access Manager, multiple filtering profiles can be created, assigned to different users.|$|E
50|$|All Windows {{operating}} systems since Windows NT 3.1 {{are designed to}} support roaming profiles. Normally, a standalone computer stores the user's documents, desktop items, application preferences, and desktop appearance on the local computer in two divided sections, consisting of the portion that could roam plus an additional temporary portion containing items such as the web <b>browser</b> <b>cache.</b> The Windows registry is similarly divided to support roaming; there are System and Local Machine hives that stay on the local computer, plus a separate User hive (HKEY CURRENT USER) designed {{to be able to}} roam with the user profile.|$|E
5000|$|<b>Browser</b> {{history and}} <b>cache</b> of Internet Explorer, Firefox, Opera and Netscape ...|$|R
40|$|<b>Browser</b> <b>caches</b> {{are widely}} used to improve the {{performance}} of Web page loads. Unfortunately, current object-based caching is too coarse-grained to minimize the costs associ-ated with small, localized updates to a Web object. In this paper, we evaluate the benefits if caching were performed at a finer granularity and at different levels (i. e., computed layout and compiled JavaScript). By analyzing Web pages gathered over two years, we find that both layout and code are highly cacheable, suggesting that our proposal can rad-ically reduce time to first paint. We also find that mobile pages are similar to their desktop counterparts {{in terms of the}} amount and composition of updates...|$|R
50|$|The Firebug {{command line}} accepts {{commands}} written in JavaScript. The result of executing each command is {{displayed in the}} console, appearing as hyperlinks. The Firebug application contains multiple windows, splitting related features to a common window. Firebug also allows users to view the download time for individual files. It separates different types of objects, such as JavaScript files and images, and can determined which files are loaded from a <b>browser's</b> <b>cache.</b> Firebug also features the ability to examine HTTP headers and time stamps relative to when an HTTP request is made. Its net panel can monitor URLs that the browser requests, such as external CSS, JavaScript, and image files.|$|R
