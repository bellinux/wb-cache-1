14|118|Public
5000|$|In mathematics, {{a normal}} map {{is a concept}} in {{geometric}} topology due to William Browder which is of fundamental importance in surgery theory. Given a Poincaré complex X (more geometrically a Poincaré space), a normal map on X endows the space, roughly speaking, {{with some of the}} homotopy-theoretic global structure of a closed manifold. In particular, X has a good candidate for a stable normal bundle and a Thom collapse map, which is equivalent to there being a map from a manifold M to X matching the fundamental classes and preserving normal <b>bundle</b> <b>information.</b> If the dimension of X is [...] 5 there is then only the algebraic topology surgery obstruction due to C. T. C. Wall to X actually being homotopy equivalent to a closed manifold. Normal maps also apply {{to the study of the}} uniqueness of manifold structures within a homotopy type, which was pioneered by Sergei Novikov.|$|E
40|$|In this paper, {{we present}} {{a study of the}} {{proximal}} point algorithm using very general regularizations for minimizing possibly nondierentiable and nonconvex locally Lipschitz functions. We deduce from the proximal point scheme simple and implementable bundle methods for the convex and nonconvex cases. The originality of our bundle method is that the <b>bundle</b> <b>information</b> incorporates the subgradients of both the objective and the regularization function. The resulting method opens up a broad class of regularizations which are not restricted to quadratic, convex or even dierentiable functions...|$|E
30|$|Step 0. (Initialization). Select a {{starting}} point y^ 0 and set x^ 0 =y^ 0. Set parameters M> 0, R_ 0 > 0, κ∈(0, 1), ϵ≥ 0, and Γ≥ 1. Initialize the iteration counter ℓ= 0, the descent step counter k:=k(ℓ)= 0 with i_ 0 = 0. Set (μ_ 0, η_ 0)=(R_ 0, 0) and J_ 0 :={ 0 }. Compute f(x^ 0), g^ 0 _f∈∂ f(x^ 0) and the <b>bundle</b> <b>information</b> (e^ 0, 0 _f, d^ 0 _ 0, ^ 0 _ 0):=(0, 0, 0). Set s^- 1 _h=g^ 0 _h∈∂ h(x^ 0).|$|E
40|$|Using {{the cable}} {{industry}} as an illustrative case, this article investigates implications of endogenous quality choice when <b>bundling</b> <b>information</b> goods and analyzes welfare effects of an a la carte regulation that forces firms to unbundle products. The analysis shows that a la carte pricing decreases consumer surplus and product quality even when it reduces the average product price. An increase in advertising rates decreases product price, but it also reduces product quality and could make consumers worse off. These findings have important policy implications for media markets where regulators are considering imposition of a la carte pricing. ...|$|R
50|$|Python Eggs {{are a way}} of <b>bundling</b> {{additional}} <b>information</b> with a Python project, {{that allows}} the project's dependencies to be checked and satisfied at runtime, as well as allowing projects to provide plugins for other projects.|$|R
40|$|In {{this paper}} the pricing of {{information}} goods is discussed {{with respect to}} the digital library on the WU-Wien that is called epub. Digital libraries are surveyed with the key properties of their access systems. Different options of price discrimination and models of pricing are examined. This paper focuses on the economics of <b>bundling</b> <b>information</b> goods. The costs of electronic commerce in connection with digital libraries has been researched. This paper tries to derive pricing strategies for the epub out of the theoretical findings and discussions of the models depicted. The strategies are divided into bundling strategies and those with reference to target groups...|$|R
40|$|Even in {{the field}} of history the {{internet}} and its graphic surface, the WorldWideWeb has become more and more important. The main problem is the decentralized structure of the internet which makes it difficult to do systematic research within specific scientific fields. An adequate solution could be a knot which would <b>bundle</b> <b>information</b> or would give references for further data resources. The structure of such a knot - which has been started to develop in a project of history students in Cologne - will be shown as follows...|$|E
40|$|In {{the space}} of density matrix, two estimation-theoretically natural {{geometrical}} structures can be introduced: Uhlmann's parallelism and Nagaoka's quantum information geometry. In this paper, intrinsic relation between them is clearified. Keywords: Uhlmann's curvature, fiber <b>bundle,</b> <b>information</b> geometry, e-connection, quantum estimation theory, Cramer-Rao typebound 1 Department of Mathematical Engineering and Information Physics UniversityofTokyo, Bunkyo-ku,Tokyo 113, Japan 1 1 Introduction Quantum estimation theory deals with {{the identification of the}} density matrix or given system by use of data produced by appropriately desigened experiment [4][5][6]. From this quantum-estimation-theoretical point of view, there are two natural geometridal structures in {{the space of}} full rank density matrices. One is Uhlmann's parallelism and the other is Nagaoka's information geometry. Uhlmann's parallelism is generalization of Berry's phase, which, by far confirmed by several experiments, is a [...] ...|$|E
40|$|In this paper, {{we present}} {{a study of the}} {{proximal}} point algorithm using very general regularizations for minimizing possibly nondierentiable and nonconvex locally Lipschitz functions. We deduce from the proximal point scheme simple and implementable bundle methods for the convex and nonconvex cases. The originality of our bundle method is that the <b>bundle</b> <b>information</b> incorporates the subgradients of both the objective and the regularization function. The resulting method opens up a broad class of regularizations which are not restricted to quadratic, convex or even dierentiable functions. Keywords: mathematical programming, proximal point, bundle methods, nonsmooth regularization This work was partially supported by the Department of Defense Research & Engineering (DDR&E) Multidisciplinary University Research Initiative (MURI) on "Reduced Signature Target Recognition" managed by the Air Force OÆce of Scientic Research (AFOSR) under AFOSR grant AFOSR F 49620 - 96 - 0028. Chretien and He [...] ...|$|E
40|$|The {{representation}} of lexical entries requires special means which basic PATR systems do not include. The language DATR, however, {{can be used}} to define an inheritance network serving as the lexical component. The integration of such a module into an existing PATR system leads to various problems which are discussed together with possible solutions in this paper. means that associated information is represented together or bundled. One advantage of this <b>bundled</b> <b>information</b> is its reusability, which allows redundancy to be reduced. The represen- tation of lexical information should enable us to express a. further kind of generalization, namely the relations between regularity, subregularity, and irregularity. Furthermore, the representation has to be computationally tracta- ble and [...] possibly with the addition of "syntac- fic sugar" [...] more or less readable for human users...|$|R
5000|$|PID <b>bundles</b> the <b>information,</b> {{which was}} {{acquired}} through the Starting up a project and Initiating a Project processes in a PRINCE2 controlled project environment. PRINCE2's 2009 renaming Document to Documentation indicates {{a collection of}} documentation that has been collected up creating a project rather than all {{the information in the}} system.|$|R
40|$|While {{electronic}} {{papers have}} played {{and continue to}} play a primordial role in the dissemination of research results, researchers now recognize that papers are by no means sufficient to communicate and share research results. As a step in this direction, we present research objects as an abstraction for communicating, sharing and reusing research results. As well as the paper describing the contribution made by the scientist, a research object <b>bundles</b> <b>information</b> about the hypothesis the scientist investigated, the workflow implementing the experiment ran to assess the hypothesis, the data set used, the results obtained, and the conclusions drawn by the scientist, and identify a set of research problems that together aim to enable the management of research objects. We also underline the important role that end-users and automation techniques can play to enable scalable management of research objects...|$|R
30|$|The bundle {{that has}} been {{forwarded}} the most, i.e. the highest FP, is dropped first, and the bundle {{that has been}} forwarded the least, i.e. the lowest FP, is forwarded first. LEPR drops the bundle with the lowest delivery probability. In other words, LEPR drops the bundle that has the lowest P. Lastly, HOP-COUNT drops the bundle that has {{the greatest number of}} hops and forwards the bundle that has the smallest number of hops. We also evaluated QM-EBRP against Optimal Global Knowledge (OGK), a scheme that is similar to [21] and [33]. In this policy, we assume that nodes are synchronized with a shared global memory to update <b>bundle</b> <b>information</b> such as the number of disseminated replicas. Accordingly, every node is instantly aware of the accurate number of disseminated replicas of each bundle in the network. This policy thus allows us to compare QM-EBRP against a theoretical scheme.|$|E
40|$|Abstract — We {{present a}} novel {{parametric}} encoding scheme for efficiently recording white matter fiber <b>bundle</b> <b>information</b> obtained from diffusion tensor imaging. The coordinates of fiber tracts are parameterized using a cosine series expansion. For an arbitrary tract, a 19 degree expansion {{is found to}} be sufficient to reconstruct the tract with an average error of about 0. 26 mm. Then each tract is fully parameterized with 60 parameters, which results in a substantial data reduction. Unlike traditional splines, the proposed method does not have internal knots and explicitly represents the tract as a linear combination of basis functions. This simplicity in the representation enables us to design statistical models, register tracts and perform subsequent analysis in a more streamlined mathematical framework. As an illustration, we apply the proposed method in characterizing abnormal tracts that pass through the splenium of the corpus callosum in autistic subjects. I...|$|E
30|$|Our N-to-N gossiping {{protocol}} {{consists of}} n nodes, or peers, that operate in cycles. (The terms “peer” and “node” {{will be used}} interchangeably in this paper). Each cycle is initiated at fixed intervals and is identified by a global cycle ID. For simplicity, we assume {{that there is a}} global synchronization of the cycle ID and frame rate, and that this synchronization is achieved through the use of NTP. The use of a global cycle ID eliminates the need of a peer to manage the sequence numbering of sources individually and the need to transmit sequence numbers of individual chunks in a packet. Other mechanisms to achieve synchronization are possible but we assume that NTP is used so that we can focus on other aspects of our protocol. Each peer in a cycle can generate at most one information frame (e.g. a voice frame) to be distributed to the remaining n- 1 peers through a multi-phase gossiping mechanism. The key to our protocol is the use of a synchronous global cycle ID and synchronous media generation. By “synchronous media generation” we mean that the packet generation rates are exactly the same for all active nodes. Most N-to-N real-time communication protocols in the literature have either assumed an asynchronous operation or have assumed a synchronous operation without addressing how this synchronicity is achieved. If using asynchronous operation, we would need to transmit and process individual sequence numbers as well as to perform frequency alignment across multiple streams. Also, the bundling of information from different sources into one transmitted packet cannot be done in as straightforward a manner - in our protocol, we simply need to <b>bundle</b> <b>information</b> frames with the same cycle ID.|$|E
40|$|This paper {{outlines}} {{a method}} for finding revenue maximizing mixed bundling prices for news websites. This can help better understand paid content strategies for online news content. Drawing on {{work in the field}} of <b>bundling</b> <b>information</b> goods, I apply a two-parameter model of consumer preferences to web site traffic data and a roughly estimated willingness-to-pay curve. We can then calculate revenues for different price points and find the optimal one for any given site. This method is applied to a sample of ten sites. At revenue maximizing prices, the majority of paid revenue for these sites comes from the sale of individual articles, rather than subscriptions. Site traffic showing highly loyal consumers is found to correlate with higher subscription prices. This model suggests that while it is possible for overall revenue to be higher with a paid content plan, total traffic will certainly fall. 1...|$|R
40|$|The goal of {{this work}} is to explore {{applications}} of reservoir computing in biomolecular computation. Reservoir computing is a unique model for representing a mapping from one instance in time to a specific output. A neural network of randomly connected neurons is linked with a single output neuron or multiple output neurons. The output neurons are capable of mapping inputs to desired outputs using adaptable algorithms. This framework is investigated by using the Python programming language and object oriented design and programming. Neurons are created in programs by <b>bundling</b> <b>information</b> like input data and attributes of the network, which utilize methods (for instance the sum of a dot product, the hyperbolic tangent function) to operate on data (e. g. arbitrary input arrays, two variable binary inputs). This work is motivated {{by the idea of}} using adaptable algorithms instead of hardcoding information to solve classification problems in biomolecular computation, such as identifying molecular information like presence of a virus...|$|R
40|$|In {{this thesis}} we {{identify}} and obtain structural results for two different {{problems that are}} motivated by electronic commerce infrastructure and <b>bundling</b> of <b>information</b> goods. Strategic implications of implementing a priority pricing scheme in an ATM-like network owned by a single firm {{is the subject of}} the first study. Network structure consists of a single link modeled as an Mx/D/ 1 queue with non-preemptive head-of-the-line priority service. The network manager 2 ̆ 7 s motive is to maximize the difference between revenue generated and the delay (penalty) cost. We obtain structural results for the two priority case both in the short and in the long run. In equilibrium, it is found that the network manager maximizes the price spread between the two priority class services. We show that when the capacity is also considered as a decision variable, simultaneous capacity and price setting is equivalent to choosing the capacity first and then the prices. Closed form solutions in both cases are provided. The second part of the thesis addresses a vital issue in the provision of <b>bundled</b> <b>information</b> goods. The problem motivation comes from the business practice of forming partnerships to provide bundled products that involve only one of the parties 2 ̆ 7 effort for upgrade. Component based software products exhibit such characteristics. We find that in a duopoly market, upgrade quality may be used to prevent a possible price war hence benefitting both firms by keeping positive revenue flow. However, first period quality level may be deliberately chosen to be low while second period bundle prices are chosen to be high. ...|$|R
40|$|Subgradient {{method and}} bundle methods are {{frequently}} used in Lagrangian relaxation for integer optimization problems. This dissertation develops {{a new generation}} of optimization algorithms which provide better performance. ^ In the subgradient method, the “relaxed problem” must be optimally solved to obtain a subgradient direction. The first part of the dissertation develops a surrogate subgradient method, where a proper direction can be obtained with only approximate optimization of the relaxed problem. This method can obtain directions with much less effort, and provides a new approach that is especially powerful for problems of very large size. While applying this method to job shop scheduling, simplified dynamic programming has been developed, leading to much reduced computation complexity and faster convergence. ^ In bundle methods, in order to obtain good search directions, quadratic programming, line search, and null steps are required. The second part of the dissertation improves bundle methods by making good use of the information obtained from minimizing the relaxed problem—not just the minimum solution, but also near minimum solutions. The <b>bundle</b> <b>information</b> is thus enriched, leading to better search directions and fewer null steps. Furthermore, a simplified bundle method is developed, where quadratic programming, line search, and null steps are no longer necessary. The simplified bundle method is then applied to job shop scheduling, and fuzzy dynamic programming has been developed to obtain a search direction efficiently. ^ The third part of the dissertation presents a novel Lagrangian Relaxation Neural Network (LRNN) for optimization problems by combining recurrent neural network optimization ideas with Lagrangian relaxation for constraint handling. The convergence of the network is proved, and a general framework for neural implementation is established allowing creative variations. When applying the network for job shop scheduling, the neuron-based dynamic programming is developed making innovative use of the subproblem structure. Architectural design issues for the hardware implementation of such neural networks are also explored. A digital circuitry with a micro-controller and an optimization chip is designed, where a parallel architecture and a pipeline architecture are designed for the optimization chip. ...|$|E
40|$|An {{important}} {{objective of}} marketing {{research is to}} uncover perception processes between the implementation of marketing activities and the actual consumer reaction. Only if marketing managers know these processes, {{they are able to}} design effective marketing activities. Therefore, this dissertation addresses three areas of consumer perception that lack understanding. The first project deals with how consumers perceive price inflation. It develops and validates a psychological rating scale to measure perceived inflation across product categories. Overall, consumers tend to overestimate inflation, but individual perception largely depends on consumer and category characteristics. Two processes lead to the fact that perceived inflation differs from official values: consumers’ perceive individual product price changes differently to official price changes and aggregate them using subjective instead of official weights. The second and third project analyze how managers and organizational buyers perceive brands based on a manager survey in Germany, India (only project two), and the U. S. While the second project deals with B 2 B brand strength, the third project assesses how B 2 B brands gain relevance for managers’ purchase decisions. Main finding of project two is that B 2 B brand associations split up into ‘sustainability and corporate governance’ as well as ‘innovation and expertise’. Moreover, product and distribution perception largely shape B 2 B brand strength. Project three shows that B 2 B managers use brands to <b>bundle</b> <b>information</b> on purchase risk and brands’ imagery benefits. Manager and organizational characteristics moderate the influence of B 2 B brand functions on brand relevance. Both projects show that brand perception in B 2 B markets differs to B 2 C markets. Moreover, concepts hold across countries and industries, but ample variation exists for individual effect sizes and the role of moderators. The fourth project deals with the phenomenon of growing cultural diversity. It reviews current literature on how culture may shape response styles in survey research. Overall, this cumulative dissertation provides insights on three questions that have been raised by researchers. The first project contributes {{to the question of how}} subjective data help explain economic phenomena. It offers a tool to track perceived inflation and insights on the drivers of inflation perceptions. As perceived inflation may shape consumer behavior, it provides intuition for managerial decisions and policymaking. The second and fourth project deal with the question of how organizational buyers make purchase decisions. They detail the knowledge on when and how managers include intangible criteria into their decisions. By showing ample variation across countries, industries, and individual managers, this dissertation offers various insights on managerial perception processes and the design of B 2 B branding strategies. The fourth project contributes to the question of how population differences in cognition and communication affect the response process. It provides a framework and generalizations on cultural influences on response styles. Therefore, this dissertation also offers intuition for researchers and practitioners on how to consider potential contamination from cross-cultural surveys and samples...|$|E
40|$|Diffusion MRI (dMRI) {{measurements}} {{allow us}} to infer the microstructural properties of white matter and to reconstruct fiber pathways in-vivo. High angular diffusion imaging (HARDI) allows {{for the creation of}} more and more complex local models connecting the microstructure to the measured signal. One of the challenges is the derivation of meaningful metrics describing the underlying structure from the local models. The aim hereby is to increase the specificity of the widely used metric fractional anisotropy (FA) by using the additional information contained within the HARDI data. A local model which is connected directly to the underlying microstructure through the model of a single fiber population is spherical deconvolution. It produces a fiber orientation density function (fODF), which can often be interpreted as superposition of multiple peaks, each associated to one relatively coherent fiber population (bundle). Parameterizing these peaks one is able to disentangle and characterize these bundles. In this work, the fODF peaks are approximated by Bingham distributions, capturing first and second order statistics of the fiber orientations, from which metrics for the parametric quantification of fiber bundles are derived. Meaningful relationships between these measures and the underlying microstructural properties are proposed. The focus lies on metrics derived directly from properties of the Bingham distribution, such as peak length, peak direction, peak spread, integral over the peak, as well as a metric derived from the comparison of the largest peaks, which probes the complexity of the underlying microstructure. These metrics are compared to the conventionally used fractional anisotropy (FA) and it is shown how they may help to increase the specificity of the characterization of microstructural properties. Visualization of the micro-structural arrangement is another application of dMRI. This is done by using tractography to propagate the fiber layout, extracted from the local model, in each voxel. In practice most tractography algorithms use little of the additional information gained from HARDI based local models aside from the reconstructed fiber bundle directions. In this work an approach to tractography based on the Bingham parameterization of the fODF is introduced. For each of the fiber populations present in a voxel the diffusion signal and tensor are computed. Then tensor deflection tractography is performed. This allows incorporating the complete <b>bundle</b> <b>information,</b> performing local interpolation as well as using multiple directions per voxel for generating tracts. Another aspect of this work is the investigation of the spherical harmonic representation which is used most commonly for the fODF by means of the parameters derived from the Bingham distribution fit. Here a strong connection between the approximation errors in the spherical representation of the Dirac delta function and the distribution of crossing angles recovered from the fODF was discovered. The final aspect of this work is the application of the metrics derived from the Bingham fit to a number of fetal datasets for quantifying the brain’s development. This is done by introducing the Gini-coefficient as a metric describing the brain’s age...|$|E
50|$|As an {{alternative}} to the timezone <b>information</b> <b>bundled</b> with the Java Platform, programmers may choose to use the Joda-Time library. This library includes its own timezone data based on the IANA time zone database.|$|R
5000|$|The {{recognition}} of this requirement led {{to the concept of}} a [...] "bundle" [...] as a high-level way to address the generalized Store-and-Forward problem. Bundles are an area of new protocol development in the upper layers of the OSI model, above the Transport Layer with the goal of addressing the issue of <b>bundling</b> store-and-forward <b>information</b> so that it can reliably traverse radically dissimilar environments constituting a [...] "network of regional internets".|$|R
40|$|In this paper, {{we provide}} a sealed bid, multi-unit auction {{mechanism}} for pricing <b>information</b> goods <b>bundles.</b> With the digitization of various products {{and growth of}} {{the internet as a}} delivery system, there has been increased interest in developing methods to price information goods. The low marginal cost of production, the lack of capacity constraint on production and ease of bundling products affect the pricing and allocation strategies of firms selling information goods. Previous work on <b>bundling</b> <b>information</b> goods assumes ex-ante knowledge about either consumer valuations (or reservation prices) or their distributions. In this paper, we relax these assumptions and develop an incentive-compatible auction mechanism to determine bundle prices and allocation. Of course, when valuations or reservation prices are known ex-ante, one can solve a nonlinear optimization problem which will give a higher revenue than our incentive compatible mechanism. Conversely, even if valuations or reservation prices are unknown, one could use a fixed price strategy to price <b>information</b> goods <b>bundles.</b> We will compare our mechanism with other pricing options for <b>information</b> goods <b>bundles.</b> 1...|$|R
40|$|Political Strategy for Food Labelling Joint Statement of the Scientific Advisory Boards on Consumer and Food Policy and on Agricultural Policy at the Federal Minisity of Food. Agriculture and Consumer Protection September 2011 Consumers {{in modern}} {{consumer}} societies {{are confronted with}} an abundance of largely similar products, especially in the food sector. They are usually completely unable to process the detailed, product-related information these products contain. In this context labels are an important information tool for consumers. They can <b>bundle</b> <b>information</b> and are thus used more often and at an earlier point in time than other information. They can play a key role when it come to trust-related properties of products or services, as consumers do not have a reliable alternative source of this information. To contribute to consumers being able to make an informed decision, however, labels must be easy to understand, based on sound verified criteria and familiar to consumers. In addition to this, they must not be allowed to get lost in a flood of similar and sometimes ambiguous labels. With regard to the supplier side it is essential that labels provide a range of economic incentives to continually increase quality. So far these, challenges have not been sufficiently met by the agri-food industry and agri-food policy in Europe and Germany. From {{the point of view of}} the Scientific Advisory Boards, what is required is a long-term, consistent food labelling strategy that is preferably coordinated throughout the EU and that is based on an integrated view of environmental, food, consumer and agricultural policy and that integrates food labelling in all its complexity, including the context of other instruments. For important trust-related properties (health, environmental impact, social and animal welfare), which are becoming increasingly important for consumers, the Scientific Advisory Boards recommend an optional "umbrella" label showing the 4 above- mentioned labelling areas separately using a multi-level evaluation system. The umbrella label is intended to ensure easy recognition. The multi-level approach allows for differentiated evaluation and provides quality incentives for the suppliers. The focus (aggregation) on important labelling areas ensures a high amount of clarity, especially when terms are simultaneously protected by a ban on (misleading) associations. An overarching concept of this kind is only possible as a state-imposed or state-supported procedure. The Scientific Advisory Boards favour the latter but would like interest groups to be involved too. The animal welfare requirements for livestock offer especially good prerequisites for the testing of a multi-level label as described above. Binary characteristics, such as ingredients, origin, the use of genetic engineering or nanotechnology, are not suitable for an umbrella label concept. For such cases, the recommendation provides a decision grid for classifying the respective labelling area. For specific terms such as "GM-free" or "from mountain farms", the Scientific Advisory Boards recommend maintaining or introducing reserved terms that may only be used when legally defined conditions are met. At the same time, it should also be ensured in this area that terms are protected through a ban on (misleading) allusions. For private-sector labels, logos, references to testing or monitoring systems or specific advertising statements on the process quality, just as for state-imposed or state-supported labels, information should be made available at the point of sale or on the product packaging to enable the consumer to find further details on the system. It should be obligatory to state (e. g. on the internet) by whom the label is awarded and what the award criteria and the control process comprise. It is also necessary to ensure the independence of the inspectors and the control of the label providers (e. g. through accreditation), and to document this transparently. The observance or breach of legal minimum standards should generally not be communicated through a label...|$|E
40|$|An {{effective}} {{design for a}} kettle reboiler is dependent on fitness for purpose while reducing costs. Thus, accurate information concerning two-phase flow behaviour within it is important. Experimental and numerical studies {{have been carried out}} in this research to gain a more detailed understanding of the phenomena associated with two-phase flow in a thin-slice kettle reboiler. The kettle reboiler contained 241 electrically heated tubes arranged as 17 rows of 17 columns in an in-line layout with an outside diameter of 19 mm and a pitch-to-diameter ratio of 1. 34. The working fluids used in this investigation were pentane and the refrigerant R 113. They were boiled at atmospheric pressure at uniform heat fluxes in the range of 10 to 40 kW/m 2. The patterns of flow inside the kettle reboiler were investigated experimentally using ordinary and high speed cameras. Visual observation of the flow patterns showed that the flow in the tube bundle was two-dimensional at heat fluxes of 20 kW/m 2 and above. The quantity of foam and recirculation above the tube bundle were found to depend on both the heat flux and the working fluid used. Observations of the two-phase flow pattern in the shell indicated that the movement of fluid from the centre column of the bundle was affected by the down flow into the top of the tube bundle. Two flow patterns in the tube bundle were identified: bubbly and intermittent. At low heat fluxes, bubbly flow dominated, then, with increasing heat flux, bubble coalescence {{led to the development of}} vapour slugs and intermittent flow was observed. Pressure drop measurements were made in three columns within the tube bundle. The results showed that at heat fluxes below 20 kW/m 2, the pressure drop remained nearly constant and equal to the all-liquid value. At a heat flux of 20 kW/m 2 and above, the pressure drop was found to increasingly fall below the all-liquid value as the bundle row number increased. This effect was especially evident in the centre of the bundle. A change in the flow pattern caused the pressure distribution up the tube bundle to change from roughly constant to decaying with height. Based on a number of assumptions, the two-fluid model has been applied. The two-fluid model’s drag coefficient and tube resistance were deduced from a one-dimensional model. The two-fluid model predictions show good agreement with the experimental results for the pressure distribution and flow distribution. Grid sizes of 10, 8 and 4 mm for the bundle and the pool were considered. It was found that the predicted bundle results were not affected by changing the grid size. However, in the pool region, a small grid size was needed. A grid size of 10 mm was used in the bundle while 4 mm was used in the pool. The pool velocity predictions compared well with measured values available in the open literature. The results indicated that the bundle flow is not significantly affected by the pool flow. This allows the two-fluid model to be further refined: simplifying it and reducing the computational time. A bundle-only two fluid model has been developed to accurately predict two-phase flow behaviour in the kettle reboiler tube <b>bundle.</b> <b>Information</b> available from earlier studies has been used to develop this model because of the difficulties associated with measuring the void fraction and velocities within the tube bundle. The model uses two different boundary conditions: (1) static liquid pressure in the pool and (2) variation of pressure in the pool based on the flow pattern transition. The results predicted by the model have been compared with experimental data and with one and two-fluid models at different heat fluxes. Boundary condition (1) was found to be in good agreement with experimental data and the one and two-fluid models at a heat flux of 10 kW/m 2. This was because the transition flow pattern was not achieved and the bundle was surrounded by a static pool. Boundary condition (2) is based on the Kutateladze number (Ku), which sets the transition point from bubbly to intermittent flow at a certain height in the bundle. For Ku ≤ 1. 09, the bundle flow would be surrounded by liquid, and if Ku > 1. 09, the bundle flow would be surrounded by two-phase flow. At heat fluxes of 20 kW/m 2 and above, boundary condition (2) has been found to be in good agreement with experimental data and the values predicted from the one and two-fluid models for liquid velocities, vertical mass flux and void fraction. The bundle-only model accurately predicts the trend line of constant and decaying pressure drop measured at low and high heat fluxes, respectively, and the observed flow phenomena in the kettle reboiler. The key feature of the model presented is that it allows two-phase flow in the kettle reboiler to be simulated by only modelling the tube bundle. Thus the model is simplified and less computational time is required. A central column model was developed using the minimum pressure gradient approach. The predicted results from this model were compared with experimental data and the values predicted by the two-fluid model and the bundle-only model. Reasonable agreement was obtained indicating that the flow distribution may be linked to the minimum pressure gradient...|$|E
40|$|In {{the context}} of a virtual university's {{information}} broker we study the consumption patterns for information goods and we investigate if Ehrenberg's repeatbuying theory which successfully models regularities in a large number of consumer product markets can be applied in electronic markets for information goods too. First results indicate that Ehrenberg's repeat-buying theory succeeds in describing the consumption patterns of <b>bundles</b> of complementary <b>information</b> goods reasonably well and that this can be exploited for automatically generating anonymous recommendation services based on such <b>information</b> <b>bundles.</b> An experimental anonymous recommender service has been implemented and is currently evaluated in the Virtual University of the Vienna University of Economics and Business Administration at [URL]...|$|R
40|$|More {{and more}} {{newspaper}} and magazine Web sites offer paid content. However, selling information goods at a price higher than the marginal cost means finding a strategy for product or price differentiation. A possible strategy {{to solve this problem}} is the <b>bundling</b> of <b>information</b> goods. In this article, we analyze empirically, with quantitative statistic methods, strategies for selling bundled and unbundled content on {{newspaper and magazine}} Web sites. This analysis is based on the theoretical ap-proach of Bakos and Brynjolfsson (1996). The article shows that a cannibalization takes place if the same <b>bundle</b> of <b>information</b> goods is offered in offline (printed) and online (digital) media at the same time. Traditional bundling models work nonethe-less in an online media if the online content is rebundled (e. g., as dossiers about a topic), but thereby do not compete with the printed version. For studying the economics of paid content, newspaper and magazine markets are of particular importance and interest, because the convergence of media is very strong in these markets, so the submarkets of online and print are often interrelated (Chyi & Sylvie, 2000). Many news...|$|R
40|$|<b>Bundling</b> <b>information</b> {{technology}} (IT) {{applications to}} support logistics activities {{provides a means}} for firms to improve their logistics performance. Grounded in the logistics management and management information systems literature, {{as well as the}} resource-based view (RBV) of the firm, this study empirically: (i) investigates if there exist digitized logistics activities bundles in firms; and if so, (ii) explores the association between digitized logistics activities bundles and logistics performance of firms in terms of logistics cost and logistics service improvements. We surveyed 227 trading firms in Hong Kong and performed a factor analysis of the survey data, from which we identified three digitized logistics activities bundles and found the sample firms were clustered into four types based on the patterns of their digitized logistics activities. We then carried out a MANOVA on the data, the results of which show that different patterns of digitizing logistics activities are associated with different logistics performance outcomes. Specifically, firms with more extensive digitized logistics activities bundles and utilizing them more intensively achieve better logistics performance. Academic and managerial implications for digitizing logistics activities to improve logistics performance are discussed. Department of Logistics and Maritime Studie...|$|R
40|$|With the {{explosion}} in the quantity of on-line text and multimedia information in recent years, demand for text summarization technology is growing. Increased pressure for technology advances is coming from users of the web, on-line information sources, and new mobile devices, {{as well as from}} the need for corporate knowledge management. Commercial companies are increasingly starting to offer text summarization capabilities, often <b>bundled</b> with <b>information</b> retrieval tools. In this paper, I will discuss the significance of some recent developments in summarization technology...|$|R
40|$|<b>Bundling</b> of <b>information</b> goods (such as {{software}} and digitized music or TV) is omnipresent in todayâ s business-to-consumer environment. However, a surprisingly {{small number of}} articles address this issue within the information systems science (ISS) literature. By conducting a thorough literature review on the subject, this article shows that a lionâ s share {{of the most important}} work on <b>information</b> technology product <b>bundling</b> is published outside the ISS arena. On the basis of the literature review, eight future research directions are presented...|$|R
40|$|Social {{network sites}} (SNSs) are <b>bundles</b> of <b>information</b> and {{communication}} tools {{that can be}} used to support collaboration, among other uses. In a qualitative study of adult Facebook users (N= 18), we found that some users did turn to the site for information uses that are embedded in social activities, including organizing events, establishing online groups, and seeking information. We also discuss the features of Facebook that respondents discussed as being important to these uses. Categories and Subject Descriptors H. 5. 3 Group and Organization Interfaces – collaborativ...|$|R
40|$|AbstractHuman {{decision}} {{is not only}} affected by information content but also information order. This study provides additional evidence about order effect {{in the context of}} corporate disclosure. The same <b>bundle</b> of <b>information</b> should be reacted by the same way because those have same information. Information order affects investor decision. Using an experimental study, we provide that sequential information stimulates recency bias. Participants in a group who receives bad (good) news in their sequential information produces lower (higher) valuation. The order effect forms fish-tail pattern. This article contributes to recent studies and corporate disclosure practices...|$|R
40|$|The paper {{investigates the}} {{morphological}} impact of quantitative properties of lexical and sublexical {{structures in the}} decomposition of morphologically complex words {{by means of an}} activation-based simulation. A complex nucleus of blind-to-semantics relationships turns out to allow the emergence of proto-morphological representations and to provide a cognitively efficient route to complex word decomposition. A computational account of how this <b>bundle</b> of <b>information</b> is handled with in the lexical processing of complex pseudo-words is provided. The model is tested against an edit-distance algorithm and a non-word similarity rating task performed by a group of native speakers...|$|R
50|$|In Pandora FMS architecture, servers are {{the core}} of the system because they are the {{recipients}} of <b>bundles</b> of <b>information.</b> They also generate monitoring alerts. It is possible to have different modular configurations for the servers: several servers for very big systems, or just a single server. Servers are also responsible for inserting the gathered data into Pandora's database. It is possible to have several Pandora Servers connected to a single Database. Different servers are used for different kind of monitoring: remote monitoring, WMI monitoring, SNMP and other network monitoring, inventory recollection, etc.|$|R
40|$|Okounkov bodies, {{which are}} closed convex sets defined for big line <b>bundles,</b> have rich <b>information</b> {{on the line}} bundles. On the other hand, Seshadri {{constants}} are invariants which measure the positivity of line bundles. In this paper, we prove that Okounkov bodies give lower bounds of Seshadri constants. Comment: 19 page...|$|R
