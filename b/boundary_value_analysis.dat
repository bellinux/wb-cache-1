50|10000|Public
50|$|Equivalence {{partitioning}} {{is not a}} {{stand alone}} method to determine test cases. It has to be supplemented by <b>boundary</b> <b>value</b> <b>analysis.</b> Having determined the partitions of possible inputs the method of <b>boundary</b> <b>value</b> <b>analysis</b> has {{to be applied to}} select the most effective test cases out of these partitions.|$|E
5000|$|Finding defects using <b>Boundary</b> <b>value</b> <b>analysis</b> {{test design}} {{technique}} {{can be a}} very effective and can be used at all test levels. You can select multiple test cases from valid and invalid input domains based on your needs or previous experience but remember you do have to select at least one test case from each input domain. <b>Boundary</b> <b>value</b> <b>analysis</b> concept: ...|$|E
50|$|A {{test design}} is made after the planning. Subjects are: create, read, update and delete and <b>boundary</b> <b>value</b> <b>analysis.</b>|$|E
5000|$|Mathematical foundations: Numerical {{and applied}} linear algebra, initial & <b>boundary</b> <b>value</b> problems, Fourier <b>analysis,</b> {{optimization}} ...|$|R
5000|$|There are {{two basic}} {{techniques}} that help to write the sufficient test cases to cover {{the most of the}} functionalities of the system. Both these techniques are used in positive testing as well.The two parameters are:* <b>Boundary</b> <b>values</b> <b>analysis</b> [...] <b>Boundary</b> indicates limit to something. In this parameter we design test scenarios {{in such a way that}} it covers the <b>boundary</b> <b>values</b> and validate how application behaves on these boundary values.ExampleIf we have application that accepts Ids ranging from 0-255.Hence in this scenario 0,255 will from the <b>boundary</b> <b>values.</b> The values within the range of 0-255 will constitute the positive testing. Any inputs going below from 0 and input going above from 255 will be considered invalid and will constitute negative testing.|$|R
5000|$|The {{values of}} the test vector at the strict {{condition}} of the equality that is [...] and [...] are called the <b>boundary</b> <b>values,</b> Boundary-value <b>analysis</b> has detailed information about it. Note that the graph only covers the overflow case, first quadrant for X and Y positive values.|$|R
50|$|Examples of {{systematic}} testing methods include the Stream X-Machine testing method and equivalence partition testing with full <b>boundary</b> <b>value</b> <b>analysis.</b>|$|E
50|$|The <b>Boundary</b> <b>value</b> <b>analysis</b> or Boundary {{testing is}} a test design {{technique}} {{that is used to}} find the errors at boundaries of input domain rather than in the center of input.|$|E
50|$|Equivalence Partitioning and <b>Boundary</b> <b>value</b> <b>analysis</b> {{are linked}} {{to each other and}} can be used {{together}} at all levels of testing. Based on the edges of the equivalence classes, test cases can then be derived.|$|E
30|$|In this paper, {{we propose}} two {{generalized}} non-polynomial cubic spline schemes using a variable mesh {{to solve the}} system of non-linear singular two point <b>boundary</b> <b>value</b> problems. Theoretical <b>analysis</b> proves that the proposed methods have second- and third-order convergence. Both methods are applicable to singular <b>boundary</b> <b>value</b> problems. Numerical results are also provided to show the accuracy and efficiency of the proposed methods.|$|R
40|$|In this paper, we {{investigate}} {{the problem of}} existence and nonexistence of positive solutions for the nonlinear <b>boundary</b> <b>value</b> problem: u (n) (t) + λa(t) f(u(t)) = 0, 0 < t < 1, satisfying three kinds of different <b>boundary</b> <b>value</b> conditions. Our <b>analysis</b> relies on Krasnoselskii’s fixed point theorem of cone. An example is also given to illustrate the main results. 1...|$|R
30|$|In this paper, a new nonpolynomial cubic spline {{method is}} {{developed}} for solving two-parameter singularly perturbed <b>boundary</b> <b>value</b> problems. Convergence <b>analysis</b> is briefly discussed. Numerical examples and computational results illustrate and guarantee a higher accuracy by this technique. Comparisons {{are made to}} confirm the reliability and accuracy of the proposed technique.|$|R
50|$|<b>Boundary</b> <b>value</b> <b>analysis</b> {{does not}} require invalid partitions. Take an example where a heater is turned on if the {{temperature}} is 10 degrees or colder. There are two partitions (temperature&le;10, temperature>10) and two boundary values to be tested (temperature=10, temperature=11).|$|E
5000|$|Boundary testing or <b>boundary</b> <b>value</b> <b>analysis,</b> {{is where}} test cases are {{generated}} using {{the extremes of}} the input domain, e.g. maximum, minimum, just inside/outside boundaries, typical values, and error values. It is similar to Equivalence Partitioning but focuses on [...] "corner cases".|$|E
50|$|Where a {{boundary}} value {{falls within the}} invalid partition the test case is designed to ensure the software component handles the value in a controlled manner. <b>Boundary</b> <b>value</b> <b>analysis</b> can be used throughout the testing cycle and is equally applicable at all testing phases.|$|E
40|$|For {{the first}} time it is shown that for thin {{metallic}} films thickness of which not exceed thickness of skin-layer, the problem allows analytical solution for arbitrary <b>boundary</b> <b>value</b> problems. The <b>analysis</b> of dependence of coefficients of transmission, reflection and absorbtion on angle incidence, thickness of films and coefficient of specular reflection is carried out. Comment: 15 pages, 9 figure...|$|R
40|$|AbstractIn this paper, a {{numerical}} method is given for partial differential equations, which combines {{the use of}} Lagrange multipliers with radial basis functions. It is a new method to deal with difficulties that arise in the Galerkin radial basis function approximation applied to Dirichlet (also mixed) <b>boundary</b> <b>value</b> problems. Convergence <b>analysis</b> results are given. Several examples show {{the efficiency of the}} method using TPS or Sobolev splines...|$|R
40|$|In {{this paper}} we discuss {{convergence}} of multigrid methods {{with respect to the}} maximum norm for 2 D elliptic <b>boundary</b> <b>value</b> problems. Our <b>analysis</b> uses Hackbusch's framework based on the Smoothing Property and Approximation Property (cf. [4]). We present a rather general framework for establishing the Smoothing Property in the maximum norm. The analysis fits in nicely with the classical theory of diagonally dominant matrices and of M-matrices. 1 1...|$|R
50|$|Because the {{boundary}} values {{are defined as}} those values {{on the edge of}} a partition, we have identified the following boundary values: -$0.01 (an invalid boundary value because it is at the edge of an invalid partition), $0.00, $100.00, $100.01, $999.99 and $1000.00, all valid boundary values. So by applying <b>boundary</b> <b>value</b> <b>analysis</b> we will have six tests for boundary values.|$|E
5000|$|One of the {{limitations}} of <b>boundary</b> <b>value</b> <b>analysis</b> is that it cannot be used for Boolean and logical variables. Additionally it cannot estimate boundary analysis for some cases such as countries, more over it has limitations that it is not useful for strongly-typed languages. Also it is impossible to test all the dependencies between multiple combinations of the inputs [...]|$|E
5000|$|Black-box testing {{treats the}} {{software}} as a [...] "black box", examining functionality without {{any knowledge of}} internal implementation, without seeing the source code. The testers are only aware of what the software is supposed to do, not how it does it. Black-box testing methods include: equivalence partitioning, <b>boundary</b> <b>value</b> <b>analysis,</b> all-pairs testing, state transition tables, decision table testing, fuzz testing, model-based testing, use case testing, exploratory testing and specification-based testing.|$|E
40|$|Symbolic {{computation}} {{has been}} applied to Runge-Kutta technique in order to solve a two-point <b>boundary</b> <b>value</b> problem. The unknown <b>boundary</b> <b>values</b> are considered as symbolic variables, therefore they will appear in a system of algebraic equations, after the integration of the ordinary differential equations. Then this algebraic equation system can be solved for the unknown initial values and substituted into the solution. Consequently, only one integration pass is enough to solve the problem instead of using an iteration technique like shooting method. This procedure is illustrated by solving the <b>boundary</b> <b>value</b> problem of the mechanical analysis of a liquid storage tank. Computations were carried out by the MATHEMATICA symbolic system. Keywords: symbolic computation, <b>boundary</b> <b>value</b> problem, mechanical <b>analysis,</b> MATHEMATICA. 1...|$|R
40|$|International audienceWe {{study the}} {{stability}} of finite difference schemes for hyperbolic initial <b>boundary</b> <b>value</b> problems in one space dimension. Assuming stability for the dicretization of the hyperbolic operator {{as well as a}} geometric regularity condition, we show that an appropriate determinant condition, that is the analogue of the uniform Kreiss-Lopatinskii condition for the continuous problem, yields strong stability for the discretized initial <b>boundary</b> <b>value</b> problem. The <b>analysis</b> relies on a suitable discrete block structure condition and the construction of suitable symmetrizers. Our work extends the results of Gustafsson, Kreiss, Sundstrom to a wider class of finite difference schemes...|$|R
40|$|AbstractAn {{iterated}} deferred correction algorithm {{based on}} Lobatto Runge-Kutta formulae is {{developed for the}} efficient numerical solution of nonlinear stiff two-point <b>boundary</b> <b>value</b> problems. An <b>analysis</b> of the stability properties of general deferred correction schemes {{which are based on}} implicit Runge-Kutta methods is given and results which are analogous to those obtained for initial value problems are derived. A revised definition of symmetry is presented and this ensures that each deferred correction produces an optimal increase in order. Finally, some numerical results are given to demonstrate the superior performance of Lobatto formulae compared with mono-implicit formulae on stiff two-point <b>boundary</b> <b>value</b> problems...|$|R
50|$|We can {{consider}} {{another example of}} <b>Boundary</b> <b>value</b> <b>analysis</b> where we can apply it to the whole {{of a string of}} characters (e.g. a name or address). The number of characters in the string is a partition, e.g. between 1 and 30 characters is the valid partition with valid boundaries of 1 and 30. The invalid boundaries would be 0 characters (null, just hit the Return key) and 31 characters. Both of these should produce an error message.|$|E
50|$|<b>Boundary</b> <b>value</b> <b>analysis</b> is a {{software}} testing technique in which tests {{are designed to}} include representatives of boundary values in a range. The idea comes from the boundary. Given {{that we have a}} set of test vectors to test the system, a topology can be defined on that set. Those inputs which belong to the same equivalence class as defined by the equivalence partitioning theory would constitute the basis. Given that the basis sets are neighbors, there would exist a boundary between them. The test vectors {{on either side of the}} boundary are called boundary values. In practice this would require that the test vectors can be ordered, and that the individual parameters follows some kind of order (either partial order or total order).|$|E
40|$|In {{partition}} analysis we {{divide the}} input domain to form subdomains {{on which the}} system’s behaviour should be uniform. <b>Boundary</b> <b>value</b> <b>analysis</b> produces test inputs near each subdomain’s boundaries to find failures caused by the boundaries being incorrectly implemented. However, <b>boundary</b> <b>value</b> <b>analysis</b> can be adversely affected by coincidental correctness — the system produces the expected output for the wrong reason. This paper shows how <b>boundary</b> <b>value</b> <b>analysis</b> can be adapted {{in order to reduce}} the opportunity for coincidental correctness. The main contribution is to automated test data generation in which one cannot rely on the expertise of a tester...|$|E
40|$|In this paper, {{we study}} an {{adaptive}} {{finite element method}} for multiple eigenvalue problems. We obtain both convergence rate and quasi-optimal complexity of the adap-tive finite element eigenvalue approximation, without any additional assumption to those required in the adaptive finite element <b>analysis</b> for the <b>boundary</b> <b>value</b> problem. Our <b>analysis</b> {{is based on a}} certain relationship between the finite element eigenvalue approximation and the associated finite element <b>boundary</b> <b>value</b> approximation and a crucial property of eigenspace approximation which are also presented in the paper. Key words. Adaptive finite element, a posteriori error estimator, complexity, convergence, multiple eigenvalue...|$|R
40|$|An {{iterated}} deferred correction algorithm {{based on}} Lobatto Runge-Kutta formulae is {{developed for the}} efficient numerical solution of nonlinear stiff two-point <b>boundary</b> <b>value</b> problems. An <b>analysis</b> of the stability properties of general deferred correction schemes {{which are based on}} implicit Runge-Kutta methods is given and results which are analogous to those obtained for initial value problems are derived. A revised definition of symmetry is presented and this ensures that each deferred correction produces an optimal increase in order. Finally, some numerical results are given to demonstrate the superior performance of Lobatto formulae compared with mono-implicit formulae on stiff two-point <b>boundary</b> <b>value</b> problems. (C) 1998 Elsevier B. V. Ltd. All rights reserved...|$|R
40|$|AbstractOur goal in {{this paper}} is to provide {{sufficient}} conditions for the existence of solutions to discrete, nonlinear systems subject to multipoint boundary conditions. The criteria we present depends {{on the size of the}} nonlinearity and the set of solutions to the corresponding linear, homogeneous <b>boundary</b> <b>value</b> problems. Our <b>analysis</b> is based on the Lyapunov–Schmidt Procedure and Brouwerʼs Fixed Point Theorem. The results presented extend the previous work of D. Etheridge and J. Rodríguez (1996, 1998) [5, 6] and J. Rodríguez and P. Taylor (2007) [18, 19]...|$|R
3000|$|Other model-based testing {{tools in}} the current {{literature}} share similarities with BETA. These tools and/or approaches were also evaluated using different techniques. The closest ones are probably BZ-TT/LTG. BZ-testing-tools [1] is based on <b>boundary</b> <b>value</b> <b>analysis</b> of B and Z specifications, and LEIRIOS test generator [...]...|$|E
40|$|This {{presentation}} {{discusses the}} role and purpose of testing in the systems/Software Development Life Cycle. We examine {{the consequences of the}} 'cost curve' on defect removal and how agile methods can reduce its effects. We concentrate on Black Box Testing and use Equivalence Partitioning and <b>Boundary</b> <b>Value</b> <b>Analysis</b> to construct the smallest number of test cases, test scenarios necessary for a test plan...|$|E
40|$|We {{intend to}} show that using {{automatic}} test generation tools {{make it possible to}} achieve the same test case quality in less time – compared to a traditional approach. In this paper we are comparing two very different ways of generating test-cases; Equivalence class partitioning combined with <b>boundary</b> <b>value</b> <b>analysis</b> against using PEX – an automatic white box test generation tool from Microsoft research. Lastly we try to give a recommendation of best practice. Inde...|$|E
40|$|Analytical {{solutions}} for the strongly exothermic decomposition of combustible material are discussed in this paper. Combustible material uniformly distributed between symmetrically heated parallel plates under Sensitized, Arrhenius and Bimolecular reaction rates are also discussed neglecting consumption of material. Approximate analytical expressions of steady state temperature fields are derived by using Homotopy analysis method (HPM) for various values of relevant dimensionless parameters. Analytical results are compounded with perturbation technique and numerical simulation. Analytical results are coinciding with numerical simulation and agreement is noted. The present method simple, less computational and applicable for solving strongly non-linear initial and <b>boundary</b> <b>value</b> problems. Keywords: Thermal explosions; Kinetics reactions; Non-linear <b>boundary</b> <b>value</b> problem; Homotopy <b>analysis</b> method; Numerical simulation. 1...|$|R
40|$|AbstractThis paper investigates {{convergence}} of the discontinuous finite volume method (DFVM) under minimal regularity assumptions on solutions of second order elliptic <b>boundary</b> <b>value</b> problems. Conventional <b>analysis</b> requires {{the solutions to}} be in Sobolev spaces H 1 +s,s> 12. Here we assume the solutions are in H 1 +s,s> 0 and employ the techniques developed in Gudi (2010) [18, 20] to derive error estimates in a mesh-dependent energy norm and the L 2 -norm for DFVM. The theoretical estimates are illustrated by numerical results, which include problems with corner singularity and intersecting interfaces...|$|R
40|$|The {{expression}} {{levels of}} rod opsin and glial fibrillary acidic protein (GFAP) capture important structural {{changes in the}} retina during injury and recovery. Quantitatively measuring these expression levels in confocal micrographs requires identifying the retinal layer boundaries and spatially corresponding the layers across different images. In this paper, a method to segment the retinal layers using a parametric active contour model is presented. Then spatially aligned expression levels across different images are determined by thresholding the solution to a Dirichlet <b>boundary</b> <b>value</b> problem. Our <b>analysis</b> provides quantitative metrics of retinal restructuring that are needed for improving retinal therapies after injury. Index Terms — Active contours, layer segmentation 1...|$|R
