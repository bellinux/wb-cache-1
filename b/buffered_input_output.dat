0|10000|Public
5000|$|Buffer (B): if {{the buffer}} is not empty qB = q2 else qB = minq1,q2, where the buffer empties as output if {{component}} with 'q value' q2 {{is in an}} [...] "up" [...] state with level at time 0 = Initial Level, otherwise level at time t = level at time (t-1) - (q2 - q1), and the <b>buffer</b> fills as <b>input</b> if component with 'q value' q2 is in a [...] "down" [...] state with level at time 0 = Initial Level, otherwise level at time t = Capacity if level at time (t-1) + q1 > C, otherwise level at time t = level at time (t-1) + (q2 - q1). <b>Buffer</b> <b>input</b> and <b>output</b> may also be limited by buffer constraints.|$|R
40|$|Conventional input {{switches}} usually {{employ a}} single crossbar switch fabric to transfer cells from <b>input</b> <b>buffers</b> to <b>output</b> ports. This type of switches suffer from <b>input</b> and <b>output</b> cell contention problems which cause lower performance than for output buffer switches. However, dividing one crossbar fabric into several smaller crossbar fabrics, we can decrease the <b>input</b> and <b>output</b> contention probabilities. Based on this principle, we propose a new decomposed crossbar switch architecture. Since {{a decrease in}} <b>input</b> and <b>output</b> contention probabilities causes {{an increase in the}} grant probability for the cells at <b>input</b> <b>buffers,</b> the proposed decomposed crossbar switches yield better performance than conventional input switches. We derive the grant probability for a simple arbitration algorithm and evaluate the performance of the proposed switch architecture in terms of the average cell latency through simulation...|$|R
5000|$|The term double {{buffering}} {{is used for}} copying data between two buffers for direct memory access (DMA) transfers, not for enhancing performance, but to meet specific addressing requirements of a device (esp. 32-bit devices on systems with wider addressing provided via Physical Address Extension). Microsoft Windows device drivers are particularly noteworthy {{as a place where}} such {{double buffering}} is likely to be used. On a Linux or BSD system, these are called bounce buffers because data must [...] "bounce" [...] via these <b>buffers</b> for <b>input</b> or <b>output.</b>|$|R
40|$|Abstract- This paper {{describes}} {{the design of}} a high-speed CMOS Sample and Hold circuit in front of an analog to digital converter (ADC). Sample and hold (S/H) circuit employs linear source follower <b>buffer</b> at <b>input</b> and <b>output.</b> Synopsys cosmosSE software tool has been used for schematic design, H-spice for Simulation and Cscope for waveform performance. Complete S/H circuit has designed with tsmc 035 (Taiwan semiconductor manufacturing corporation) technology, with 2. 5 V power supply. Power consumption of 5 mW for 8 MHz at 53 MS/s. Index Terms- sampling and hold circuit analog to digital converter A I...|$|R
40|$|To {{support the}} Internet's {{explosive}} growth and expansion into a true integrated services network, {{there is a}} need for cost-effective switching technologies that can simultaneously provide high capacity switching and advanced QoS. Unfortunately, these two goals are largely believed to be contradictory in nature. To support QoS, sophisticated packet scheduling algorithms, such as Fair Queueing, are needed to manage queueing points. However, the bulk of current research in packet scheduling algorithms assumes an output buffered switch architecture, whereas most high performance switches (both commercial and research) are <b>input</b> <b>buffered.</b> While <b>output</b> buffered systems may have the desired quality of service, they lack the necessary scalability. <b>Input</b> <b>buffered</b> systems, while scalable, lack the necessary quality of service features. In this paper, we propose the construction of switching systems that are both <b>input</b> and <b>output</b> <b>buffered,</b> with the scalability of <b>input</b> <b>buffered</b> switches and the r [...] ...|$|R
40|$|This paper {{describes}} a new architecture for a multicast ATM switch scalable {{from a few}} tens to a few thousands of input ports. The switch, called Abacus switch, has a nonblocking switch fabric followed by small switch modules at the output ports. It has <b>buffers</b> at <b>input</b> and <b>output</b> ports. Cell replication, cell routing, output contention resolution, and cell addressing are all performed in a distributed way {{so that it can}} be scaled up to thousands of <b>input</b> and <b>output</b> ports. A novel algorithm has been proposed to resolve output port contention while achieving <b>input</b> <b>buffers</b> sharing, fairness among the input ports, and call splitting for multicasting. The channel grouping mechanism is also adopted in the switch to reduce the hardware complexity and improve the switch's throughput, while the cell sequence integrity is preserved. The switch can also handle multiple priority traffic by routing cells according to their priority levels. The performance study of the Abacus switch in t [...] ...|$|R
40|$|Crossbars are an {{emerging}} technology in high speed router. In buffered crossbar switch a buffer {{is associated with}} each crossbar. Due {{to the introduction of}} crossbar <b>buffers</b> the <b>input</b> and <b>output</b> contentions are highly eliminated. Both the <b>input</b> and <b>output</b> port work independently and so the scheduling process is highly simplified. With a speed up of 2 it has been proved that 100 % throughput can be achieved. In this paper we propose a 100 % throughput scheduling algorithm without speedup called ISA. In ISA the scheduling decision is purely based on the state information of the local crosspoint buffer. So it is suited for a distributed implementation and it is highly scalable. The main advantage is the crosspoint use a buffer size of 1 which minimizes the hardware cost. Simulation results show that we achieve 100 % throughput without any speedup...|$|R
40|$|Abstract — This paper {{presents}} an analytical {{model for the}} performance analysis of a new cell-based multicast switch for broadband communications. Using distributed control and a modular design, the Balanced Gamma switch features a high performance for unicast, multicast and combined traffic under both random and bursty conditions. Although it has <b>buffers</b> on <b>input</b> and <b>output</b> ports, the multicast BG switch follows predominantly an output-buffered architecture. The analytical model follows the three phase switching operation. The performance is evaluated under multicast random traffic in terms of cell loss ratio and cell delay. Performance under bursty traffic is studied through simulation {{and the results are}} compared to those of an ideal pure output-buffered multicast switch. Index Terms — Multicast, Balanced Gamma (BG) switch, performance analysis, analytical modelling, cell loss ratio, cell delay...|$|R
40|$|In this paper, {{we present}} the {{performance}} {{evaluation of a}} recently proposed multicast switch architecture for broadband communications. Using distributed control and a modular, multistage design, the multicast Balanced Gamma (BG) switch features a high performance for unicast, multicast and combined traffic under both uniform and non- uniform traffic conditions. The key features of the multicast BG switch are that, although it has <b>buffers</b> on <b>input</b> and <b>output</b> ports, it follows a predominantly output-buffered architecture and performs multicast cell replication and conflict contention resolution implicitly within the switch in a distributed fashion. The performance is evaluated in terms of cell loss rate and cell delay. It is shown that the multicast BG switch achieves a performance close to an ideal pure output-buffered switch while keeping hardware complexity reasonable...|$|R
40|$|This paper {{describes}} a new architecture for a multicast ATM switch scalable {{from a few}} tens to a few thousands of input ports. The switch, called Abacus switch, has a nonblocking switch fabric followed by small switch modules at the output ports and has <b>buffers</b> at <b>input</b> and <b>output</b> ports. A novel algorithm has been proposed to resolve output port contention while and achieves <b>input</b> <b>buffers</b> sharing, fairness among the input ports, and call splitting for multicasting. The channel grouping mechanism is also adopted in the switch to reduce the hardware complexity and improve the switch's throughput, while the cell sequence integrity is preserved. A key component for building the Abacus switch called ATM Routing and Contention (ARC) chip has been implemented with CMOS 0. 8 -m technology and tested to operate correctly at 240 Mbit/s. The performance study of the Abacus switch in throughput, average cell delay, and cell loss rate is also presented...|$|R
50|$|All four {{ports in}} the AT89C51 and AT9C52 are bidirectional. Each {{consists}} of a latch (Special Function Registers P0 through P3), an output driver, and an <b>input</b> <b>buffer.</b> The <b>output</b> drivers of Ports 0 and 2, and the <b>input</b> <b>buffers</b> of Port 0, are used in accesses to external memory. In this application, Port 0 outputs the low byte of the external memory address, time-multiplexed with the byte being written or read. Port 2 outputs the high byte of the external memory address when the address is 16 bits wide. Otherwise the Port 2 pins continue to emit the P2 SFR content. All the Port 3 pins, and two Port 1 pins (in the AT89C52)are multifunctional. The alternate functions can only be activated if the corresponding bit latch in the port SFR contains a 1. Otherwise the port pin is stuck at 0. It has less complex feature than other microprocessor.|$|R
40|$|Problem statement: Optical Packet Switching (OPS) and {{transmission}} networks based on Wavelength Division Multiplexing (WDM) have been increasingly {{deployed in the}} Internet infrastructure {{over the last decade}} {{in order to meet the}} huge increasing demand for bandwidth. Several different technologies have been developed for optical packet switching such as space switches, broadcast-and-select, <b>input</b> <b>buffered</b> switches and <b>output</b> buffered switches. These architectures vary based on several parameters such as the way of optical buffering, the placement of optical buffers, the way of solving the external blocking inherited from switching technologies in general and the components used to implement WDM. Approach: This study surveys most of the exiting optical packet switching architectures. A simulation-based comparison of <b>input</b> <b>buffered</b> and <b>output</b> buffered architectures were presented. Results: The performance analysis of the selected two architectures derived using simulation program and compared at different scenarios. We found that the output buffered architectures give better performance than <b>input</b> <b>buffered</b> architectures. Conclusion: The simulation results shows that the-broadcast-and-select architecture is attractive in terms that it has lees number of components compared to other switches. </P...|$|R
40|$|A memory design {{based on}} logical banks is {{analyzed}} for shared memory multiprocessor systems. In this design, each physical bank {{is replaced by}} a logical bank consisting of a fast register and subbanks of slower memory. The subbanks are <b>buffered</b> by <b>input</b> and <b>output</b> queues which substantially reduce the effective cycle time when the reference rate is below saturation. The principal contribution of this work is the development of a simple analytical model which leads to scaling relationships among the efficiency, the bank cycle time, the number of processors, the size of the buffers, and the granularity of the banks. These scaling relationships imply that if the interconnection network has sufficient bandwidth to support efficient access using high-speed memory, then lower-speed memory can be substituted with little additional interconnection cost. The scaling relationships are shown to hold for a full datapath vector simulation based on the Cray Y-MP architecture. The model is used to develop design criteria for a system which supports 192 independent reference streams, and the performance of this system is evaluated by simulation over a range of loading conditions...|$|R
40|$|Abstract — This paper {{presents}} the architecture design {{as well as}} the performance analysis of a new cell-based multicast switch for broadband communications. Using distributed control and a modular design, the Balanced Gamma (BG) switch features a high performance for unicast, multicast and combined traffic under both random and bursty conditions. Although it has <b>buffers</b> on <b>input</b> and <b>output</b> ports, the multicast BG switch follows predominantly an output-buffered architecture. The performance is studied under uniform and non-uniform multicast traffic in terms of cell loss ratio and cell delay. The results are compared with those from an ideal pure output-buffered multicast switch to demonstrate how close its performance is to that of the ideal but impractical switch. Comparisons with other published switches reveals the superior of the BG switch and the tradeoffs between complexity and performance in a packet switch design. It is shown that the multicast BG switch achieves a performance close to the ideal switch while keeping hardware complexity reasonable. Index Terms — Multicast, Balanced Gamma (BG) switch, performance analysis, multistage interconnection network (MIN) ...|$|R
40|$|Abstract—To {{support the}} Internet’s {{explosive}} growth and expansion into a true integrated services network, {{there is a}} need for cost-effective switching technologies that can simultaneously provide high capacity switching and advanced QoS. Unfortunately, these two goals are largely believed to be contradictory in nature. To support QoS, sophisticated packet scheduling algorithms, such as Fair Queueing, are needed to manage queueing points. However, the bulk of current research in packet scheduling algorithms assumes an output buffered switch architecture, whereas most high performance switches (both commercial and research) are <b>input</b> <b>buffered.</b> While <b>output</b> buffered systems may have the desired quality of service, they lack the necessary scalability. <b>Input</b> <b>buffered</b> systems, while scalable, lack the necessary quality of service features. In this paper, we propose the construction of switching systems that are both <b>input</b> and <b>output</b> <b>buffered,</b> with the scalability of <b>input</b> <b>buffered</b> switches and the robust quality of service of output buffered switches. We call the resulting architecture Distributed Packet Fair Queueing (D-PFQ) as it enables physically dispersed line cards to provide service that closely approximates an output-buffered switch with Fair Queueing. By equalizing the growth of the virtual time functions across the switch system, most of the PFQ algorithms in the literature can be properly defined for distributed operation. We present our system using a crossbar for the switch core, as they are widely used in commercial products and enable the clearest presentation of our architecture. Buffering techniques are used to enhance the system’s latency tolerance, which enables the use of pipelining and variable packet sizes internally. Our system is truly distributed in that there is neither a central arbiter nor any global synchronization. Simulation results are presented to evaluate the delay and bandwidth sharing properties of the proposed D-PFQ system. I...|$|R
40|$|Abstract. Internet routers play an {{important}} role during network congestion. All the routers have <b>buffers</b> at <b>input</b> and <b>output</b> ports to hold the packets at congestion. Various congestion control algorithms have been proposed to control the congestion. Recently, some proportional-integral-derivative (PID) controller based algorithms have been proposed as Active Queue Management(AQM) schemes to address performance degradations of end-to-end TCP congestion control. However, most of the proposed PID-controllers for AQM are validated for their performance and stability via intuitive explanation and simulation studies instead of theoretic analysis and performance evaluation. But there are a few drawbacks of PID-controller based AQM algorithms leading to poor performance like causing data retention dropping and oscillation when the time delay is large, which means that the existing PID-controller can not meet the Quality of Service (QoS) requirements. To overcome the drawbacks of traditional PID, we analyze and enhance the PID-controller based AQM algorithm by regarding the TCP congestion control mechanism as an input-rate based Adaptive Fuzzy Neuron PID control algorithm(IRAFNPID) to avoid congestion in TCP/AQM networks. By means of simulations, we evaluate and compare the performance of traditional PID, single neural adaptive PID(SNAPID) and IRAFNPID, simulations with experiment data analysis and find that IRAFNPID has better convergence, stability, robustness, goodput and lower loss ratio. ...|$|R
40|$|Abstract—We {{present a}} novel optical packet {{switching}} fabric ar-chitecture incorporating both <b>input</b> single-stage and <b>output</b> mul-tistage all-optical variable delay <b>buffers</b> as combined <b>input</b> and <b>output</b> queues. For a given optical buffer size (1000 B), the pro-posed architecture, which has combined <b>input</b> and <b>output</b> optical variable buffer queues with optimum partition, achieves packet loss rates (3. 4 E- 5) that are three {{orders of magnitude}} lower than the case without the variable buffers and two orders of magnitude lower than the cases with <b>input</b> or <b>output</b> optical queues alone. Index Terms—All-optical packet switching (OPS), all-optical variable buffer, optical router, slow light, switching fabric archi-tecture. I...|$|R
40|$|Combined <b>input</b> and <b>output</b> queued (CIOQ) {{architectures}} with {{a moderate}} fabric speedup S > 1 {{have come to}} play a major role in the design of high performance switches. The switch policy that controls such switches must consist of two components. A buffer management policy that controls admission to buffers, and a scheduling policy that is responsible for the transfer of packets from <b>input</b> <b>buffers</b> to <b>output</b> buffers. The goal of the switch policy is to maximize the throughput of the switch. When all packets have a uniform value (or importance), this corresponds to the number of packets sent from the switch. When packets have variable values, this corresponds to the total value of the sent packets. We derive a number of scheduling policies for CIOQ switches and analyze their throughput using competitive analysis. We thus give for these policies a uniform throughput guarantee, regardless of specific traffic patterns. For the case of packets with uniform values we present a switch policy that is 3 -competitive for any speedup. For the case of packets with variable values we propose two switch policies. One achieves a competitive ratio of 4 S, and the other achieves a competitive ratio of 8 min(k; 2 dlog e), where k is the number of distinct packet values and is the ratio between the largest and the smallest value...|$|R
50|$|With no signal applied, due to {{the current}} mirrors Q3/Q4 & Q5/Q6, the {{collector}} currents of Q4 and Q6 will be equal in magnitude if the collector currents of Q1 and Q2 are also equal in magnitude. Thus, no current will flow into the <b>buffer's</b> <b>input</b> (or equivalently no voltage will be present at the <b>buffer's</b> <b>input).</b> In practice, due to device mismatches the collector currents are unequal and this results in the difference flowing into the <b>buffer's</b> <b>input</b> resulting in an offset at its output. This is corrected by adjusting the input bias or adding offset nulling circuitry.|$|R
40|$|Background: Within {{cognitive}} neuropsychological models, conduction aphasia {{has been}} conceptualized as a phonological buffer deficit. It {{may affect the}} <b>output</b> <b>buffer,</b> the <b>input</b> <b>buffer,</b> or both. The phonological output buffer is a short-term storage, responsible for the short-term maintenance of phonological units until their articulation, {{as well as for}} phonological and morphological composition. The phonological <b>input</b> <b>buffer</b> holds <b>input</b> strings until they are identified in the input lexicon. Thus, the phonological buffers are closely related to phonological short term memory (pSTM), and hence, it is important to assess pSTM in conduction aphasia. Because the <b>input</b> and <b>output</b> <b>buffers</b> play different roles, impairments in each of them predicts different impairments in the patient's ability to understand certain sentences, to learn new words and names, and to remember and recall lists of words and numbers for short time periods. Aims: This study explored in detail pSTM in individuals with conduction aphasia, comparing individuals with <b>input</b> and <b>output</b> deficits, recall and recognition tasks, and stimuli of various types. It also tested pSTM in 6 age groups of healthy individuals, assessing the effect of age on various types of stimuli. This paper presents a new battery of 10 recall and recognition span tests, designed to assess pSTM in aphasia and to measure spans and effects on spans...|$|R
5000|$|... "Applications of <b>Input</b> <b>Output</b> Analysis for Less Developed Countries", in Sohn, I. (ed.), Readings in <b>Input</b> <b>Output</b> Analysis, Oxford University Press, 1986 ...|$|R
40|$|Evidence from brain-damaged {{patients}} {{suggests that}} there are separate <b>buffers</b> for <b>input</b> and <b>output</b> phonological retention in verbal short-term memory (STM). This possible distinction was investigated with college students (Experiment 1 to 3) and deaf signers of American Sign Language (ASL) (Experiment 4) using different verbal materials in a serial probed recall paradigm. It is reasoned that natural linguistic input (speech for hearing people and ASL for deaf people) would be stored in an <b>input</b> phonological <b>buffer</b> whereas internally generated phonology derived from reading, naming pictured objects, or lip-reading would be stored in an output phonological buffer. In this study, participants were presented with memory lists in which presentation modality (spoken vs. lip-read word, written vs. lip-read word, etc.) was changed after every second item. A probe item from the list was repeated {{at the end of the}} list and participants were instructed to either recall the item in the list that has immediately followed the probe or recall the first item after the probe that is in the same modality. Some of these same-modality items were temporally distant, that is, having two intervening items of a different modality. It is predicted that the temporally distant probe in the same modality with the target results in higher memory performance than the temporally adjacent probe in a different modality only if the switch in modalities is between <b>input</b> and <b>output</b> phonological forms. The results from Experiment 1 demonstrated that spoken words and written words were stored in the <b>input</b> and <b>output</b> phonological <b>buffers,</b> respectively. The results from Experiment 2 and 3 further supported the hypothesis in showing that written words were retained in the same buffer with lip-read words and with nameable pictures, while spoken words were retained in a different buffer from these materials. The findings from lists consisting of words in ASL and nameable pictures in Experiment 4 were not conclusive. However, preliminary data suggested that there might also be a separation between signed words and nameable pictures. Overall, the findings from this study conformed to the predictions from the hypothesis of separate <b>input</b> and <b>output</b> phonological retention...|$|R
2500|$|A {{parallel}} feedback connection at the <b>input</b> (<b>output)</b> {{decreases the}} <b>input</b> (<b>output)</b> resistance {{by a factor}} ( [...] 1 + β AOL [...] ), where AOL = open loop gain.|$|R
30|$|Our {{primary source}} of data is the <b>Input</b> <b>Output</b> Transaction Table of 2007 – 08 {{published}} by Central Statistical Organization (CSO 2012), Government of India. This is a 130 X 130 commodity matrix used for <b>Input</b> <b>Output</b> Analysis.|$|R
40|$|The use of {{measures}} originally suggested by Bennet, Bowley, and Hicks {{in the context}} of cost of living, welfare, and consumer surplus measurement to measure <b>inputs,</b> <b>outputs,</b> and productivity is examined. Suitably normalized versions of the Bennet-Bowley measures are shown to be exact and superlative measures of <b>input,</b> <b>output,</b> and productivity indicators. <b>Input</b> and <b>output</b> measurement, Productivity measurement, Directional distance functions. ...|$|R
5000|$|The general {{conclusion}} from this example {{and a similar}} example for the output resistance case is:A parallel feedback connection at the <b>input</b> (<b>output)</b> decreases the <b>input</b> (<b>output)</b> resistance by a factor ( [...] 1 + β AOL [...] ), where AOL = open loop gain.|$|R
40|$|A network {{management}} system has SNMP agents distributed at {{one or more}} sites, an <b>input</b> <b>output</b> module at each site, and a server module located at a selected site for communicating with <b>input</b> <b>output</b> modules, {{each of which is}} configured for both SNMP and HNMP communications. The server module is configured exclusively for HNMP communications, and it communicates with each <b>input</b> <b>output</b> module according to the HNMP. Non-iconified, informationally complete views are provided of network elements to aid in {{network management}}...|$|R
40|$|Games for system {{analysis}} • Verification: check if a given system is correct → reduces to graph searching System <b>input</b> <b>output</b> Spec: φ(input,output) Environment Games for {{system analysis}} <b>input</b> <b>output</b> Spec: φ(input,output) Environment • Verification: check if a given system is correct → reduces to graph searching • Synthesis: construct a correct system → reduces to game solving – finding a winning strategy Games for system analysis Spec: φ(input,output) • Verification: check if a given system is correct → reduces to graph searching • Synthesis: construct a correct system → reduces to game solving – finding a winning strategy This talk: environment is abstracted as a stochastic process <b>input</b> <b>output</b> Environment <b>input</b> <b>output</b> = Markov decision process (MDP) ? Markov decision proces...|$|R
40|$|The {{goal of the}} Modular Weapon Control Unit (MWCU) {{program was}} to design and develop a {{reconfigurable}} weapon controller (programmer/sequencer) that {{can be adapted to}} different weapon systems based on the particular requirements for that system. Programmers from previous systems are conceptually the same and perform similar tasks. Because of this commonality and the amount of re-engineering necessary with the advent of every new design, the idea of a modular, adaptable system has emerged. Also, the controller can be used in more than one application for a specific weapon system. Functionality has been divided into a Processor Module (PM) and an Input/Output Module (IOM). The PM will handle all operations that require calculations, memory, and timing. The IOM will handle interfaces {{to the rest of the}} system, <b>input</b> level shifting, <b>output</b> drive capability, and detection of interrupt conditions. Configuration flexibility is achieved in two ways. First, the operation of the PM is determined by a surface mount Read-Only Memory (ROM). Other surface-mount components can be added or neglected as necessary for functionality. Second, IOMs consist of configurable <b>input</b> <b>buffers,</b> configurable <b>output</b> drivers, and configurable interrupt generation. Further, these modules can be added singly or in groups to a Processor Module to achieve the required I/O configuration. The culmination of this LDRD was the building of both Processor Module and Input/Output Module. The MWCU was chosen as a test system to evaluate Low-Temperature Co-fired Ceramic (LTCC) technology, desirable for high component density and good thermal characteristics...|$|R
40|$|Acquaye, Alston and Pardey {{report and}} discuss {{agricultural}} <b>input</b> and <b>output</b> price and quantity estimates for various spatial aggregates within the United States {{and a range}} of multi-factor productivity measures for the period 1949 - 1991. Laspeyres, Paasche, Fisher Ideal, and Törnqvist-Theil index number procedures (base year 1949 = 100) were used to develop their estimates, the formulas for which are presented below and elaborated further in Alston, Norton, and Pardey (1995). An Excel spreadsheet file named accompanies these notes. It contains the price and quantity <b>input</b> and <b>output</b> aggregates for each of the 48 contiguous states, 11 USDA production regions (with the Northeast region split into two sub-regions), and a 48 -state (national) total for the period 1949 - 91. The data file also includes various <b>input</b> and <b>output</b> subaggregates (see table 1 from Acquaye, Alston, and Pardey, appended below, for details) and the value shares using prices from the current and past period that are required to reconstruct all these indexes for all the spatial units reported in the paper. Documentation of the primary data files constructed by Craig, Pardey, and Acquaye is also available in the file named Index Number Construction The Laspeyres and Paasche indexes are not chain-linked indexes—they use base-period and current prices and quantities, respectively in the calculation. The Laspeyres <b>input</b> (<b>output)</b> quantity index uses base period <b>input</b> (<b>output)</b> prices to weight both current and base-period <b>input</b> (<b>output)</b> quantities, and was calculated as where Pi 0 is the price of <b>input</b> (<b>output)</b> i in the base-period, and Qi 0 is the quantity of <b>input</b> (<b>output)</b> i in the base-period. N is the number of individual observations of <b>input</b> (<b>output)</b> ...|$|R
40|$|We {{consider}} the busy period in a stochastic fluid flow model with infinite <b>buffer</b> where the <b>input</b> and <b>output</b> rates {{are controlled by}} a finite homogeneous Markov process. We derive an explicit expression for {{the distribution of the}} busy period and we obtain an algorithm to compute it which exhibits nice numerical properties...|$|R
40|$|International audienceMost Network-on-Chip routers {{dedicate}} {{a set of}} <b>buffers</b> to the <b>input</b> and/or <b>output</b> ports. This {{design decision}} leads to buffer underutilization especially when running applications with non-uniform traffic patterns. In order to maximize resource usage for performance and energy gains, we present a synchronous and elastic buffer implementation of a router architecture called Roundabout with intrinsic resource sharing. Roundabout is inspired by real-life traffic roundabouts and consists of lanes shared by multiple <b>input</b> and <b>output</b> ports. Roundabout offers performance improvement of 61 % for uniform traffic pattern and up to 88 % for non-uniform traffic pattern over the Hermes router, a typical <b>input</b> <b>buffered</b> router. In terms of power, it consumes 24 % less than the Hermes router. Roundabout provides a highly parametric architecture that can produce different router configurations with varying topological trade-offs for performance gains without sacrificing area...|$|R
5000|$|... #Article: Hybrid <b>input</b> <b>output</b> (HIO) {{algorithm}} for phase retrieval ...|$|R
5000|$|Imported {{function}} {{can have}} <b>input,</b> <b>output,</b> and inout arguments.|$|R
50|$|<b>Input,</b> <b>Output,</b> and I/O {{fields are}} similar to text boxes.|$|R
5000|$|... #Subtitle level 2: Bootstrapping {{using the}} Basic <b>input</b> <b>output</b> system ...|$|R
