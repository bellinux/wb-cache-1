11|101|Public
3000|$|For the {{convolution}} {{results of}} each feature number, add the <b>bias</b> <b>unit</b> b {{and apply the}} sigmoid function to get the hidden activation.|$|E
40|$|This paper {{estimates}} {{the persistence of}} shocks to Swiss unemployment. Parametric {{as well as a}} non-parametric measures of persistence indicate that the long run impact of shocks to unemployment is larger than their short run effect. Furthermore, the measures show clearly higher values for the official rate than for the level of unemployment. This is not surprising given the official method of computation of the unemployment rate, which seems to introduce a "potential break" in the series and may <b>bias</b> <b>unit</b> root and persistence measures. The conjecture that unemployment persistence is higher in a increasing state than in a decreasing state is confirmed by the estimation results for a Markov switching AR(2) model for the seasonal differences of unemployment. ...|$|E
40|$|The Producer Price Index (PPI) program {{conducted}} a study to determine if nonresponse bias exists in PPI data. The study investigated nonresponse at unit initiation (when units are asked to participate in PPI samples) and during the unit/item repricing period (when units provide prices for the items they've agreed to reprice at initiation). The study consisted of three stages: In the first stage a contingency table analysis and regression models were {{used to analyze the}} relationship between response and several frame variables. In the second stage a regression model was used to analyze the relationship between item short term relatives and the variables which were associated with response from the first stage. The third stage tested the impact of sample adjusted weights on PPI indexes. This paper reports the results of this study. Key Words: Nonresponse <b>bias,</b> <b>unit</b> initiation, item repricing, item short term relative, sample adjusted weight...|$|E
5000|$|... #Caption: Diagram of a {{restricted}} Boltzmann machine with three visible units and four hidden <b>units</b> (no <b>bias</b> <b>units).</b>|$|R
40|$|NOVELTY - The seal has two sealing members each {{having an}} access way that provide access {{from one side}} of the sealing members to the other side of the sealing members. A <b>biasing</b> <b>unit</b> is {{provided}} for biasing the two sealing members towards one another. The <b>biasing</b> <b>unit</b> includes a magnet coupled to each sealing member. A sleeve is configured to curl-up when the sleeve is in closed configuration. A closure member is located between the two sealing members...|$|R
5000|$|Substrate biasing during {{pretreatment}} uses high voltages, {{which require}} purpose-designed arc detection and suppression technology. Dedicated DC substrate <b>biasing</b> <b>units</b> {{provide the most}} versatile option as they maximize substrate etch rates, minimise substrate damage, and can operate in systems with multiple cathodes. An alternative {{is the use of}} two HIPIMS power supplies synchronised in a master-slave configuration: one to establish the discharge and one to produce a pulsed substrate bias ...|$|R
40|$|Abstract- Extraction of high {{resolution}} information signals {{is important in}} all practical applications. The Least Mean Square (LMS) algorithm is a basic adaptive algorithm has been extensively used in many applications {{as a consequence of}} its simplicity and robustness. In this paper we present a novel adaptive filter for de-noising the speech signals based on unbiased and normalized adaptive noise reduction (UNANR) algorithm. The UNANR model does not contain a <b>bias</b> <b>unit,</b> and the coefficients are adaptively updated by using the steepest-descent algorithm. The adaptive filter essentially minimizes the mean-squared error between a primary input, which is the noisy speech, and a reference input, which is either noise that is correlated in some way with the noise in the primary input or a signal that is correlated only with speech in the primary input. To measure the ability of the proposed implementation, signal to noise ratio improvement (SNRI) is calculated. The results show that the performance of the UNANR based algorithm is superior to that of the LMS and conventional Normalized LMS (NLMS) algorithms in noise reductio...|$|E
40|$|In this paper, {{we address}} the {{challenging}} task of simultaneously optimizing (i) the weights of a neural network, (ii) {{the number of}} neurons for each hidden layer, and (iii) the subset of active input features (i. e., feature selection). While these problems are traditionally dealt with separately, we propose an efficient regularized formulation enabling their simultaneous parallel execution, using standard optimization routines. Specifically, we extend the group Lasso penalty, originally proposed in the linear regression literature, to impose group-level sparsity on the network's connections, where each group {{is defined as the}} set of outgoing weights from a unit. Depending on the specific case, the weights can be related to an input variable, to a hidden neuron, or to a <b>bias</b> <b>unit,</b> thus performing simultaneously all the aforementioned tasks in order to obtain a compact network. We carry out an extensive experimental evaluation, in comparison with classical weight decay and Lasso penalties, both on a toy dataset for handwritten digit recognition, and multiple realistic mid-scale classification benchmarks. Comparative results demonstrate the potential of our proposed sparse group Lasso penalty in producing extremely compact networks, with a significantly lower number of input features, with a classification accuracy which is equal or only slightly inferior to standard regularization terms...|$|E
40|$|In this paper, we {{consider}} the joint task of simultaneously optimizing (i) the weights of a deep neural network, (ii) the number of neurons for each hidden layer, and (iii) the subset of active input features (i. e., feature selection). While these problems are generally dealt with separately, we present a simple regularized formulation allowing to solve {{all three of them}} in parallel, using standard optimization routines. Specifically, we extend the group Lasso penalty (originated in the linear regression literature) in order to impose group-level sparsity on the network's connections, where each group is defined as the set of outgoing weights from a unit. Depending on the specific case, the weights can be related to an input variable, to a hidden neuron, or to a <b>bias</b> <b>unit,</b> thus performing simultaneously all the aforementioned tasks in order to obtain a compact network. We perform an extensive experimental evaluation, by comparing with classical weight decay and Lasso penalties. We show that a sparse version of the group Lasso penalty is able to achieve competitive performances, {{while at the same time}} resulting in extremely compact networks with a smaller number of input features. We evaluate both on a toy dataset for handwritten digit recognition, and on multiple realistic large-scale classification problems...|$|E
5000|$|... is the <b>bias</b> of <b>unit</b> [...] in {{the global}} energy function. ( [...] is the {{activation}} threshold for the unit.) ...|$|R
50|$|Jones's mother {{named him}} for the writer James Baldwin. He had {{previously}} worked in the police department's <b>bias</b> crimes <b>unit,</b> and transferred into the 15th Precinct to replace James Martinez.|$|R
40|$|Inspired by the {{hierarchical}} cognitive architecture and the perception-action model (PAM), we {{propose that the}} internal status acts {{as a kind of}} common-coding representation which affects, mediates and even regulates the sensorimotor behaviours. These regulation can be depicted in the Bayesian framework, that is why cognitive agents are able to generate behaviours with subtle differences according to their emotion or recognize the emotion by perception. A novel recurrent neural network called recurrent neural network with parametric <b>bias</b> <b>units</b> (RNNPB) runs in three modes, constructing a two-level emotion regulated learning model, was further applied to testify this theory in two different cases. Comment: Accepted at The 5 th International Conference on Data-Driven Control and Learning Systems. 201...|$|R
40|$|Within speech {{synthesis}} we often wish to give extra focus to words which carry important information, such as names, dates and amounts. In this paper we {{look carefully at}} cost functions {{that can be used}} to <b>bias</b> <b>unit</b> selection in favour of hyperarticulated speech in order to give this impression of focus. Hyper-articulated speech tends to be accented, emphatic and requires more articulatory effort. We apply two cost functions to try to force the selection of hyper-articulated speech. The first operates on the duration of units in the unit selection database, the second on the language redundancy (word trigram predictability) of the word containing the unit. We estimate their relative importance in selecting hyper-articulated speech in unit selection {{speech synthesis}}. A listening test was carried out where these cost functions were applied to one random content word in a haskins anomalous sentence. Listeners were asked to select the two clearest and most focused words from the sentence. The duration increasing cost function was significantly related to an increase in perceived prominence whereas low redundancy, and a combination of both approaches did not produce significant results. Thus, although a significant correlation exists between the average duration and redundancy of diphones and perceived prominence, such a correlation was not smoothly translated into error free method for altering such perceived prominence. 1...|$|E
40|$|We {{present a}} novel {{unbiased}} and normalized adaptive noise reduction (UNANR) system to suppress random noise in electrocardiographic (ECG) signals. The system contains {{procedures for the}} removal of baseline wander with a two-stage moving-average filter, comb filtering of power-line interference with an infinite impulse response (IIR) comb filter, an additive white noise generator to test the system's performance in terms of signal-to-noise ratio (SNR), and the UNANR model that is used to estimate the noise which is subtracted from the contaminated ECG signals. The UNANR model does not contain a <b>bias</b> <b>unit,</b> and the coefficients are adaptively updated by using the steepest-descent algorithm. The corresponding adaptation process is designed to minimize the instantaneous error between the estimated signal power and the desired noise-free signal power. The benchmark MIT-BIH arrhythmia database was used to evaluate the performance of the UNANR system with different levels of input noise. The results of adaptive filtering and a study on convergence of the UNANR learning rate demonstrate that the adaptive noise-reduction system that includes the UNANR model can effectively eliminate random noise in ambulatory ECG recordings., leading to a higher SNR improvement than that with the same system using the popular least-mean-square (LMS) filter. The SNR improvement provided by the proposed UNANR system was higher than that provided by the system with the LMS filter, with the input SNR in the range of 5 - 20 dB over the 48 ambulatory ECG recordings tested. Crown Copyright (C) 2008 Published by Elsevier Ltd on behalf of IPEM. All rights reserved...|$|E
40|$|We {{analyze the}} issue of the impact of {{multiple}} breaks on monetary neutrality results, using annual data on real output and monetary aggregates for Argentina (1884 - 1996), Australia (1870 - 1997), Brazil (1912 - 1995), Canada (1870 - 2001), Italy (1870 - 1997), Mexico (1932 - 2000), Sweeden (1871 - 1988), and the UK (1871 - 2000). In particular, we empirically verify, whether neutrality propositions remain addressable (and if so, whether they hold or not), when unit root tests are carried out allowing for multiple structural breaks in the long-run trend function of the variables. It is found that conclusions on neutrality are sensitive to the number of breaks allowed. In order to interpret the evidence for structural breaks, we utilize a notion of deterministic monetary neutrality, which naturally arises in the absence of permanent stochastic shocks to the variables. We utilize a resampling procedure {{based on the fact that}} changes in the trend function <b>bias</b> <b>unit</b> root tests towards a non-rejection. In particular, using a dynamic programming algorithm to obtain global minimizers of the RSS for locating breaks, we simulate the distribution of the t-statistic for the null hypothesis of a unit root, under the hypotheses that the true models are both a Trend Stationary (TS) model with up to four structural breaks, and a Difference-Stationary (DS) model, both estimated from the data. We then compare the position where the sample estimate of the t-statistic for testing a unit root lies relative to the empirical densities of the t-statistic, under both the estimated TS and DS models. We present evidence in favour of models in which the cycle fluctuates in a stationary way around a broken trend. In other words, the (unit root) permanent stochastic changes vanish, giving rise to stationary behaviour affected by infrequent structural breaks. This leads to interesting questions about the testing for monetary neutrality, and allows us to introduce the concept of deterministic monetary neutrality. Neutrality and Superneutrality of Money, Stationarity, Structural Breaks, Resampling Methods...|$|E
40|$|Version 0. 4. 2 (2016 - 08 - 24) Downloads Source code (zip) Source code (tar. gz) PDF {{documentation}} New Features Added preprocessing. CopyTransformer, a mock {{class that}} returns copies of imput arrays via transform and fit_transform Changes Added AppVeyor to CI to ensure MS Windows compatibility Dataset are now saved as compressed. txt or. csv files {{rather than being}} imported as Python objects feature_selection. SequentialFeatureSelector now supports the selection of k_features using a tuple to specify a "min-max" k_features range Added "SVD solver" option to the PrincipalComponentAnalysis Raise a AttributeError with "not fitted" message in SequentialFeatureSelector if transform or get_metric_dict are called prior to fit Use small, positive <b>bias</b> <b>units</b> in TfMultiLayerPerceptron's hidden layer(s) if the activations are ReLUs {{in order to avoid}} dead neurons Added an optional clone_estimator parameter to the SequentialFeatureSelector that defaults to True, avoiding the modification of the original estimator objects More rigorous type and shape checks in the evaluate. plot_decision_regions function DenseTransformer now doesn't raise and error if the input array is not sparse API clean-up using scikit-learn's BaseEstimator as parent class for feature_selection. ColumnSelector Bug Fixes Fixed a problem when a tuple-range was provided as argument to the SequentialFeatureSelector's k_features parameter and the scoring metric was more negative than - 1 (e. g., as in scikit-learn's MSE scoring function) via wahutch Fixed an AttributeError issue when verbose > 1 in StackingClassifier Fixed a bug in classifier. SoftmaxRegression where the mean values of the offsets were used to update the <b>bias</b> <b>units</b> rather than their sum Fixed rare bug in MLP _layer_mapping functions that caused a swap between the random number generation seed when initializing weights and biase...|$|R
5000|$|... (1980). [...] "Reductionistic Research Strategies {{and their}} <b>Biases</b> in the <b>Units</b> of Selection Controversy." [...] In Scientific Discovery: Case Studies, ed. T. Nickles, pp. 213-259.|$|R
40|$|Item {{response}} theory (IRT) {{has been}} used extensively to study differential item functioning (dif) and to identify potentially biased items. The use of IRT for diagnostic purposes is less preva;ent and has received comparatively less attention. This study addressed differential objective function (dof) to identify potentially <b>biased</b> content <b>units.</b> IRT was used to estimate person abilities and item difficulties, which were used to compute residual objective scores. Residual objective scores were analyzed with analysis of variance using the independent variables gender and ethnicity. Data were from mathematics subtests from the 1992 Connecticut Mastery Test census administration of eighth graders and its database of approximately 32, 000 Connecticut eighth graders. The examples illustrate how dof outcomes {{can be used to}} identify potentially <b>biased</b> content <b>units,</b> to provide diagnostic information at the content level, and to construct profiles of content-based performanfe for different demographic subgroups. Ten figures and two tabli 2 s present analysis results. Two appendixes present dif statistics by demographic subgroup and item-level statistics for dof objectives in foul. tables. (Contains 11 references.) (Author/SLD) Reproductions supplied by EDRS are the best that can be made from the original document...|$|R
40|$|A novel {{method of}} power {{management}} and sequential monitoring of several sensors is proposed in this work. Application specific integrated circuits (ASICs) consisting of analog and digital sub-systems forming a {{system on chip}} (SoC) has been designed using complementary metal-oxide-semiconductor (CMOS) technology. The analog sub-system comprises the sensor-drivers that convert the input voltage variations to output pulse-frequency. The digital sub-system includes the system management unit (SMU), counter, and shift register modules. This performs the power-usage-management, sensor-sequence-control, and output-data-frame-generation functions. ^ The SMU is the key unit within the digital sub-system is that enables or disables a sensor. It captures the pulse waves from a sensor for 3 clocks out of a 16 -clock cycle, and transmits the signal to the counter modules. As a result, the analog sub-system is at on-state for only 3 / 16 th fraction (18 %) of the time, leading to reduced power consumption. Three cycles is an optimal number selected for the presented design as the system is unstable with less than 3 cycles and higher clock cycles result in increased power consumption. However, the system can achieve both higher sensitivity and better stability with increased on-state clock cycles. A current-starved-ring-oscillator generates pulse waves that depend on the sensor input parameter. By {{counting the number of}} pulses of a sensor-driver in one clock cycle, a sensor input parameter is converted to digital. The digital sub-system constructs a 16 -bit frame consisting of 8 -bit sensor data, start and stop bits, and a parity bit. ^ Ring oscillators that drive capacitance and resistance-based sensors use an arrangement of delay elements with two levels of control voltages. A <b>bias</b> <b>unit</b> which provides these two levels of control voltages consists of CMOS cascade current mirror to maximize voltage swing for control voltage level swings which give the oscillator wider tuning range and lower temperature induced variations. The ring oscillator was simulated separately for 250 nm and 180 nm CMOS technologies. The simulation results show that when the input voltage of the oscillator is changed by 1 V, the output frequency changes linearly by 440 MHz for 180 nm technology and 206 MHz for 250 nm technology. In a separate design, a temperature sensitive ring oscillator with symmetrical load and temperature dependent input voltage was implemented. When the temperature in the simulation model was varied from - 50 °C to 100 °C the oscillator output frequency reduced by 510 MHz for the 250 nm and by 810 MHz for 180 nm CMOS technologies, respectively. ^ The presented system does not include memory unit, thus, the captured sensor data has to be instantaneously transmitted to a remote station, e. g. end user interface. This may result in a loss of sensor data in an event of loss of communication link with the remote station. In addition, the presented design does not include transmitter and receiver modules, and thus necessitates the use of separate modules for the transfer of the data. ...|$|E
40|$|The article {{described}} a technique for calibrating accelerometers unit on special test stands. The developed method allows to the determining the <b>bias</b> accelerometers <b>unit,</b> errors of scale factors accelerometers unit and angles of non-orthogonal accelerometers unit without presenting stringent requirements for high-precision testing equipment. Obtained {{by measuring the}} provisions of a test bed to which you want to set a block of accelerometers to obtain estimates of the instrumental errors of the block accelerometers. However, that requires precise measurement outputs of the accelerometers...|$|R
30|$|The DAE has six layers in total. The {{number of}} the layers was {{determined}} using a development set. The number of nodes in each layer is set to be 2048 except for input and output layers 2. The network is initialized using the same RBMs as used for initializing the DNNs described in the last subsection, which were trained using reverberant speech. The lower three layers were initialized using the weights {{of the first three}} RBMs and the hidden <b>unit</b> <b>biases.</b> The upper three layers were initialized using the transpose of the weights mentioned above and the visible <b>unit</b> <b>biases.</b> While the RBM we used for the initialization of the output layer originally has 40 * 11 nodes in the upper layer, we used only the 40 nodes corresponding to the center frame.|$|R
40|$|Proceedings of lnternational Joint Conference on Neural Networks 2005 （IJCNN 2005 ）, 2005 年 8 月１日, Montreal，CanadaKohonen's Self-Organizing Map (SOM), which {{performs}} topology-preserving {{transformation from}} a highdimensional data vector space to a low-dimensional map space, provides {{a powerful tool}} for data analysis, classification and visualization in many application fields. Despite its powerfulness, SOM can only deal with vectorized data, although many expansions have been proposed for various data-type cases. This study aims to develop a novel generalization of SOM called modular Iletwork SOM (mIlSOM), which enables users to deal with general data classes in a consistent manner. mnSOM has an array structure consisting of function modules that are trainable neural networks, e. g. multi-layer perceptrons (MLPs), instead of the vector units of the conventional SOM family. In the case of MLPmodules, mnSOM learns a group of systems or functions in terms of the input-output relationships, {{and at the same time}} mnSOM generates a feature map that shows distances between the learned systems. Thus, mnSOM with MLP modules is an SOM in function space rather than in vector space. From this point of view, the conventional SOM of Kohonen's can be regarded as a special case of mnSOM, the modules consisting of fixed-value <b>bias</b> <b>units.</b> In this paper, mnSOM with MLP modules is described along with some application examples...|$|R
40|$|Kohonen 2 ̆ 7 s Self-Organizing Map (SOM), which {{performs}} topology-preserving {{transformation from}} a highdimensional data vector space to a low-dimensional map space, provides {{a powerful tool}} for data analysis, classification and visualization in many application fields. Despite its powerfulness, SOM can only deal with vectorized data, although many expansions have been proposed for various data-type cases. This study aims to develop a novel generalization of SOM called modular Iletwork SOM (mIlSOM), which enables users to deal with general data classes in a consistent manner. mnSOM has an array structure consisting of function modules that are trainable neural networks, e. g. multi-layer perceptrons (MLPs), instead of the vector units of the conventional SOM family. In the case of MLPmodules, mnSOM learns a group of systems or functions in terms of the input-output relationships, {{and at the same time}} mnSOM generates a feature map that shows distances between the learned systems. Thus, mnSOM with MLP modules is an SOM in function space rather than in vector space. From this point of view, the conventional SOM of Kohonen 2 ̆ 7 s can be regarded as a special case of mnSOM, the modules consisting of fixed-value <b>bias</b> <b>units.</b> In this paper, mnSOM with MLP modules is described along with some application examples. Proceedings of lnternational Joint Conference on Neural Networks 2005 （IJCNN 2005 ）, 2005 年 8 月１日, Montreal，Canad...|$|R
40|$|A new {{jackknife}} {{method is}} introduced {{to remove the}} first order <b>bias</b> in <b>unit</b> root models. It is optimal {{in the sense that}} it minimizes the variance among all the jackknife estimators of the form considered in Phillips and Yu (2005) and Chambers and Kyriacou (2013) after the number of subsamples is selected. Simulations show that the new jackknife reduces the variance of that of Chambers and Kyriacou by about 10 % for any selected number of subsamples without compromising bias reduction. The results continue to hold true in near unit root models. (C) 2014 Elsevier B. V. All rights reserved...|$|R
40|$|The present paper explores, both {{theoretically}} and empirically, the <b>bias</b> of <b>unit</b> value indices {{as opposed}} to genuine price indices in foreign trade. An analysis of German data reveals conceptual and methodological differences, {{and their impact on}} economic indicators, namely imported inflation, terms of trade and gross domestic product, is quantified. By introducing a formal theory, the sources of the discrepancy can be attributed to a Laspeyres effect and a structural component, both strongly negative. Only the latter reflects the <b>unit</b> value <b>bias.</b> Thus, much attention should be paid to gaining {{a better understanding of the}} index concepts...|$|R
40|$|We {{examine whether}} UK {{inflation}} {{is characterized by}} aggregation <b>bias</b> using <b>unit</b> root tests. Our results suggest aggregation bias exists. While a unit root cannot be rejected for aggregate inflation, it can be rejected for some of its sectoral components, with rejection frequencies increasing when we use more disaggregate data. Structural break analysis indicates that monetary policy shifts are the main factor behind breaks in UK inflation. The panel results typically indicate that the unit root hypothesis can be rejected for pooled sectoral inflation rates. Our findings {{have important implications for}} econometric analysis and the conduct of monetary policy. JEL Classification Codes: C 22, C 23 and E 31...|$|R
40|$|Survey {{organizations}} employ numerous {{tactics to}} reduce the potential for <b>bias</b> due to <b>unit</b> nonresponse. After data collection, nonresponse and population weighting adjustments are often utilized to reduce potential bias from nonresponse and undercoverage. Prior to and during data collection, interviewers are trained, and sometimes retrained in techniques for gaining cooperation from reluctant respondents. In addition, interviewers attempt to reduc...|$|R
40|$|ZnO {{films were}} {{deposited}} by de sputtering technique on glass and Pt/Si substrates. The effect of growth parameters is investigated on sheet resistance and noise. The 1 /f noise normalized for <b>bias,</b> frequency and <b>unit</b> area, Cus is proportional with the sheet resistance Rsh. We {{found that the}} noise results correlate strongly with the crystalline structure of ZnO. For comparison, we have also studied the ZnO films structural properties...|$|R
30|$|Assuming no hidden biases, Rosenbaum and Rubin (1983) {{proved that}} when units within strata are {{homogeneous}} {{with respect to}} ê(Z), then the treatment and control units in the same stratum {{will have the same}} distribution on Z. Moreover, Rosenbaum and Rubin showed that instead of using all of the covariates in Z, a certain degree of parsimony can be achieved by using the coarser propensity score ê(Z). Finally, Rosenbaum and Rubin (1983) showed that if there are no hidden <b>biases,</b> then <b>units</b> with the same value on a balancing score (e.g., the propensity score), but assigned to different treatments, will serve as each other’s control in that the expected difference in the responses of the units is equal to the average treatment effect.|$|R
40|$|This paper {{compares the}} {{accuracy}} of traditional ABC and time-driven ABC in complex and dynamic environments through simulation analysis. First, when unit times in time-driven ABC are known or can be flawlessly estimated, time-driven ABC coincides with the benchmark system {{and in this case}} our results show that the overall accuracy of traditional ABC depends on (1) existing capacity utilization, (2) diversity in the actual mix of productive work, and (3) error in the estimated percentage mix. In particular, we find that when error in the estimated percentage mix is low (that is, when the ABC model is regularly adjusted to changes in activity driver volumes), growing unused capacity raises the inaccuracy of ABC, especially when diversity in the actual mix of productive work is high. When error in the estimated percentage mix is high, unused capacity may counterbalance some of the impact of this error but not entirely; the offsetting effect is highest when diversity in the actual mix of productive work is also high. Second, when unit times in time-driven ABC are subject to measurement error, we compare the overall accuracy of traditional ABC versus time-driven ABC and detect that when diversity in the actual mix of productive work is low, time-driven ABC tends to be more accurate than traditional ABC, especially at higher levels of unused capacity. Alternatively, when diversity in the actual mix of productive work is high, traditional ABC tends to be more accurate than time-driven ABC, especially at lower levels of unused capacity. Finally, it is noteworthy that {{the accuracy of}} traditional ABC compared to time-driven ABC increases in case of <b>biased</b> <b>unit</b> time estimates. ABC, time-driven activity-based costing, costing system design, costing errors, simulation...|$|R
40|$|This paper {{presents}} a constraint satisfaction adaptive neural network, together with several heuristics, {{to solve the}} generalized job-shop scheduling problem, one of NP-complete constraint satisfaction problems. The proposed neural network can be easily constructed and can adaptively adjust its weights of connections and <b>biases</b> of <b>units</b> based on the sequence and resource constraints of the job-shop scheduling problem during its processing. Several heuristics that can be combined with the neural network are also presented. In the combined approaches, the neural network is used to obtain feasible solutions, the heuristic algorithms are used to improve {{the performance of the}} neural network {{and the quality of the}} obtained solutions. Simulations have shown that the proposed neural network and its combined approaches are efficient with respect to the quality of solutions and the solving speed...|$|R
40|$|In {{order to}} correct the <b>bias</b> due to <b>unit</b> {{non-response}} for the KOF ETH Zurich's business (mail) surveys, we usually use {{the results of a}} second (phone) survey by the non-respondents. Taking the case of the survey 2000 on Organization and Information Technologies in the Swiss economy, we describe how to build the sample of this second survey and how to use the collected data. Actually, we show how to generate new correcting weights {{to correct the}} non-response bias...|$|R
40|$|Given a {{randomly}} drawn sample, calibration weighting {{can provide}} double {{protection against the}} selection <b>bias</b> resulting from <b>unit</b> nonresponse. This means that if either an assumed linear prediction model or an implied unit selection model holds, the resulting estimator will be asymptotically unbiased in some sense. The functional form of the selection model when using linear alibration adjustment is dubious. The authors discuss an alternative, nonlinear calibration-weighting procedure and software that can, among other things, implicitly estimate a logistic-response model. " (author's abstract...|$|R
40|$|Research {{has been}} {{undertaken}} into the dielectric and rheological properties of electrorheological (ER) fluids. The fluids studied {{were based on}} acene-quinone radical polymers made within the department dispersed in silicone oil. A commercial poly(1 ithium methacrylate) dispersion was also examined. As a means of probing the underlying mechanisms of the E phenomenon, the permittivity of the fluids was measured from 12 Hz to 100 kHz under both static and dynamic conditions. Results indicated that a interfacial polarization process was taking place. A series of visual observations were made of fluids under different fielding patterns. A series of photographs were taken that illustrated the structure formation with elapsed time in a dilute fluid. Also photographs were taken of the final structure formed under different field conditions. [...] To perform permittivity measurements of the fluid when a electric field was applied, a high voltage <b>biasing</b> <b>unit</b> was designed, built and proved. This allowed {{the application of a}} continuous DC electric field of up to 3 kVmm" and the permittivity to be measured from 150 H t 100 kl-Iz. Through a series of experiments {{it was found that the}} low frequency permittivity increased with increasing electric field. This result was partially explained by the Sillars model. The fluids were also subjected to shear rates from 1500 to 60 s". Flow modified permittivity resonances were found at the predicted frequencies. However, the resonant frequency did not move significantly under the application of a electric field. The structuring process was time resolved and a model was made to predict the sealing of the characteristic structuring time. The rheological response of the fluids when subjected t pulsed DC fields was examined and found to be dominated by a instrumentational effect. Al experimental procedures are given along with a comprehensive examination of the equipment. The results are discussed as they occur in terms of the models appropriate to that particular event...|$|R
40|$|A new {{efficient}} {{neural network}} and heuristics hybrid strategy for job-shop scheduling is presented. The neural network has {{the property of}} adapting its connection weights and <b>biases</b> of neural <b>units</b> while solving feasible solution. Heuristics are used to accelerate the solving process of neural network and guarantee its convergence, and to obtain non-schedule schedule from solved feasible solution by neural network with orders of operations determined and unchanged. Computer simulations {{have shown that the}} proposed hybrid strategy is of high speed and excellent efficiency...|$|R
40|$|This paper {{proposes a}} new {{adaptive}} neural network, based on constraint satisfaction, and efficient heuristics hybrid algorithm for job-shop scheduling. The neural network has {{the property of}} adapting its connection weights and <b>biases</b> of neural <b>units</b> while solving feasible solution. Heuristics are used to improve he property of neural network and to obtain local optimal solution from solved feasible solution by neural network with orders of operations determined and unchanged. Computer simulations {{have shown that the}} proposed hybrid algorithm is of high speed and excellent efficiency...|$|R
