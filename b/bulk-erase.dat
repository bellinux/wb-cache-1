8|3|Public
5000|$|The {{aircraft}} {{was equipped with}} a Fairchild Industries Model A-100 cockpit voice recorder (CVR). However, 21 minutes of the 30-minute tape were blank. Tests of the CVR in the aircraft revealed no discrepancies in the CVR's electrical and recording systems.The CVR tape can be erased {{by means of the}} <b>bulk-erase</b> feature on the CVR control panel located in the cockpit. This feature can be activated only after the aircraft is on the ground with its parking brake engaged. In a deposition taken by the Safety Board, the captain stated that he usually activates the <b>bulk-erase</b> feature on the CVR at the conclusion of each flight to preclude inappropriate use of recorded conversations. However, in this instance, he could not recall having done so. The NTSB made the following statement in the accident report: We believe the captain's erasure of the CVR is a factor we cannot ignore and cannot sanction. Although we recognize that habits can cause actions not desired or intended by the actor, we have difficulty accepting the fact that the captain's putative habit of routinely erasing the CVR after each flight was not restrainable after a flight in which disaster was only narrowly averted. Our skepticism persists even though the CVR would not have contained any contemporaneous information about the events that immediately preceded the loss of control because we believe it probable that the 25 minutes or more of recording which preceded the landing at Detroit could have provided clues about causal factors and might have served to refresh the flightcrew's memories about the whole matter.|$|E
40|$|We {{describe}} the design rationale for a hardware tamper resistant secure storage {{system based on}} probe storage with a patterned magnetic medium. This medium supports normal read/write operations by magnetising individual dots perpendicular to the media plane. We report on an experiment to show that in principle the medium also supports a separate class of read/write-once operations by allowing individual dots in the media to be destroyed irreversibly by precise local heating. Security {{stems from the fact}} that <b>bulk-erase</b> is not possible...|$|E
40|$|Abstract. A {{flash memory}} has write-once and <b>bulk-erase</b> {{properties}} so that an intelligent allocation algorithm {{is essential to}} providing appli-cations efficient storage service. This paper first demonstrates that the online version of FLASH allocation problem is difficult, since we can find an adversary that makes every online algorithm to use as many number of blocks as a naive and inefficient algorithm. As a result we propose an offline allocation algorithm called Best Match (BestM) for allocating blocks in FLASH file systems. The experimental results indicate that BestM delivers better performance than a previously proposed First Re-arrival First Serve (FRFS) method. ...|$|E
50|$|Maine and Milne were presenters on {{independent}} Melbourne station 3RRR and {{had access}} to material via radio and Milnes connections with independent record stores Au Go Go and Missing Link Records. They had planned a magazine with a flexidisc, but found {{they were able to}} obtain large quantities of unsold pre-recorded cassettes from manufacturers. They <b>bulk-erased</b> these and repackaged them with new content and labels. Editing, erasing, and dubbing was done using equipment at the 3RRR studio.|$|R
40|$|Abstract: Measurements {{were made}} of {{recording}} medium noise in erased disks using an in-contact magnetoresistive element and an inductive head supported on an air bearing slider. Four types of coatings on aluminum disks were examined: thin, transition-metal al-loy film, CrO,, FeCo particle, and y-Fe,O:,. Results obtained by means of three measurement techniques are in qualitative agreement and indicate that: (1) dc-erased noi of alloy film disks is 14 to 20 dB {{lower than that of}} particulate disks measured; (2) dc-erased noise of particulate disks measured is 6 to 16 dB above their <b>bulk-erased</b> noise: (3) although dc noise of particulate disks increases with write current, dc noise of alloy film disks is independent of write current: (4) the shapes of the noise spectra are similar in dc-erased particulate y-Fe,O, disks and FeCo particle coated disks: and (5) significant modulation noise is detected on particulate disks but not on alloy film disks. The observed dc-erased noise spectrum is compared with the model for small particle noise and is then used to estimate the size of particle agglomerates or voids...|$|R
40|$|The {{information}} densities in {{magnetic recording}} {{systems have been}} in- creased considerably {{over the last few}} decades. Much af the gain in the in- formation density can be ascribed ta the improvement af the magnetic prop- erties af the recording media. However, recording on a magnetic medium is a camplex process which, despite extensive research in the past, is only partly understood. The purpose af the research described in this thesis is ta contribute towards a better understanding af the recording process. The approach that has been followed is a combination af experiment al study with numerical modelling. The thesis consists af four parts, two on the magnetic hysteresis and two on the recording process. 1 : Experimental study of the hysteresis The technique af magnetic recording is possible only thanks ta the magnetic hysteresis. (Hysteresis is the property af magnetic media ta remain magne- tized af ter a temporary exposure ta a magnetic field.) Two new methods for studying the hysteresis af recording media have been developed. The first methad is based upon a generalization af the Wohlfarth re- lation. With this methad, the interactions between the magnetic units in the medium can be studied. In the original methad, the effects af these interactions could be compared for only two initial states af the material, the <b>bulk-erased</b> and the entirely-magnetized state. The generalization en- ables a comparison ta be made between any two initial remanent states. Application af this new methad on a particulate tape sample has revealed the complexity af the interactions. The second methad cap be used ta study the intrinsic magnetic proper- ties af recording media, irrespective af their easy magnetization direction. The demagnetizing fields that may arise from components af the magne- tization perpendicular ta a sample are compensated in this methad. The methad has been applied ta a sputtered Co-Cr medium and a Metal Evap- orated Go-Ni-O medium. The results show that there is a remarkablÃ« re- semblance between these two media in respect of the angular dependence of their coercivity. 2 : Modelling the hysteresis For an accurate simulation of the magnetic hysteresis process, the well- known moving-Preisach and Stoner-Wohlfarth hysteresis models have been combined. With a simple modification, a fast numerical implementation of the combined hysteresis model has been obtained. The magnetic interac- tions, incorporated in a fashion similar to that used in the moving-Preisach model, can account for many of the details of the minor loops, including the anhysteretic susceptibility. The vector properties of the new hystere- sis model are the same as those of the Stoner- Wohlfarth model. With the combination of the two models, the hysteresis 100 ps of different recording media, including the Metal Evaporated Go-Ni-O medium, can be repro- duced very accurately. Only the very fine details of the hysteresis process, involving the interactions between the magnetic units, are not simulated correctly. This has been demonstrated with the new method for studying these interactions. 3 : Experimental study of the recording process Much about the recording process itself can be learned from specific record- ing experiments. The recording process on thick particulate media has been investigated by applying a new analysis method. This method is based upon a scaling argument. The length of a magnetic transition is assumed to be proportion al to the magnetic potential over the gap of the recording head. With this scaling-based analysis, the spacing 1088 can be estimated from a series of frequency responses measured at selected yalues-of the recording current. The method yields a reasonably accurate indication of the head- to-tape spacing. However, the indicated value is somewhat sensitive to the range of recording currents usesl in the experiments. Application of the method to different particulate recording media shows that the Hi 8 MP tape has the best intrinsic frequency response, whereas un-oriented barium ferrite media have a relatively high optimal recording depth. Entirely different phenomena are encountered when thin Go-Gr me- dia with a perpendicular easy axis orientation are rec?rded with a ring head. Additional minima appear in the frequency response of these media. The occurrence of these minima can be described with a double-transition model, in which the transition recorded at {{the leading edge of the}} recording head is only partially erased at the trailing edge. 4 : Modelling the recording process The basic principles of the recording process can be understood from simple recording models. For a more detailed simulation of the recording process, the combined hysteresis model has been implemented in a numerical record- ing model. A modified Newton iteration scheme reduces the computation time considerably. The scaling-based analysis has been evaluated with this recording model. The assumptions on which the analysis was based proved not to be justified. However, owing to a cancellation of errors, the value of the head-to-tape spacing that results from the analysis is still within 25 % of the actual value. The recording model is still under development. Simulations with the current version show that the basic recording characteristics of very differ- ent tapes can be reproduced within 2 dB. However, similar results can be obtained with simpIer models. Future research will have to show that this new recording model is better suited for also reproducing more complex phenomena such as overwrite and bias recording...|$|R
40|$|Flash memory {{technology}} {{is becoming more}} popular in designing and building embedded systems applications because of its shock-resistent, power economic, and nonvolatile nature. Because flash memory is a write-once and <b>bulk-erase</b> medium, the garbage collection mechanism on Flash Translation Layer is needed to provide applications a transparent and high bandwidth storage service. In this paper, we propose and implement a FAT-aware log-based Flash Translation Layer, which has two points of garbage collection time. We also propose two versions of victim selection policy which is to select a log block and invalidate it. The performance between the proposed victim selection policies is evaluated {{in terms of the}} effectiveness and the overhead by a series of experiments over our implemented system...|$|E
40|$|Embedded {{systems have}} been {{developing}} rapidly in re-cent years, and flash memory technology has become an es-sential building block because of its shock-resistance, low power consumption, and non-volatile nature. Since flash memory is a write-once and <b>bulk-erase</b> medium, an in-telligent allocation algorithm is essential to providing applications efficient storage service. In this paper, we pro-pose three allocation algorithms â a First Come First Serve (FCFS) method, a First Re-arrival First Serve (FRFS) method, and an Online First Re-arrival First Serve (OFRFS) method. Both FCFS and OFRFS are on-line allocation mechanisms which make allocation de-cision as the requests arrive. The FRFS method, which serves as an off-line mechanism, is developed as the stan-dard of performance comparison. The capability of the proposed mechanisms is demonstrated {{by a series of}} exper-iments and simulations. The experimental results indicate that FRFS provide superior performance when the data ac-cess pattern is analyzed in advance, and the on-line OFRFS method provides good performance by run-time estima-tion of access patterns. 1...|$|E
40|$|This paper {{describes}} {{the architecture of}} eNVy, a large non-volatile main memory storage system built primarily with Flash memory. Flash provides persistent storage with solid-state memory access times {{at a lower cost}} than other solid-state technologies. eNVy presents its storage space as a linear, memory mapped array rather than as a disk emulator in order to provide an efficient and easy to use software interface. Flash chips are write-once, <b>bulk-erase</b> devices whose contents cannot be updated in-place. They suffer from slow write times and limited program/erase cycles. eNVy uses a copy-on-write scheme, some battery-backed SRAM, and parallel operation to overcome these problems and provide low latency in-place update semantics. A specialized cleaning algorithm maximizes the lifetime of the Flash array. Simulations show that eNVy can handle I/O rates corresponding to approximately 30, 000 TPS on the TPC-A benchmark with average latencies as low as 180 ns for reads and 200 ns for writes...|$|E
40|$|Flash memory {{technology}} is becoming critical in building embedded systems applications {{because of its}} shock-resistant, power economic, and non-volatile nature. With the recent technology breakthroughs in both capacity and reliability, flash-memory storage systems are now very popular in many types of embedded systems. However, because flash memory is a write-once and <b>bulk-erase</b> medium, we need a translation layer and a garbage collection mechanism to provide applications a transparent storage service. In the past work, various techniques were introduced to improve the garbage collection mechanism. These techniques aimed at both performance and endurance issues, but they all failed in providing applications a guaranteed performance. In this paper, we propose a real-time garbage collection mechanism, which provides a guaranteed performance, for hard real-time systems. On the other hand, the proposed mechanism supports non-real-time tasks so that the potential bandwidth of the storage system can be fully utilized. A wear-levelling method, which is executed as a non-real-time service, is presented to resolve the endurance problem of flash memory. The capability of the proposed mechanism is demonstrated {{by a series of}} experiments over our system prototype...|$|E
40|$|This paper {{describes}} {{the architecture of}} eNVy, a large non-volatile main memory storage system built primarily with Flash memory. eNVy presents its storage space as a linear, memory mapped array {{rather than as an}} emulated disk in order to provide an efficient and easy to use software interface. Flash memories provide persistent storage with solid-state memory access times at a lower cost than other solid-state technologies. However, they have a number of drawbacks. Flash chips are write-once, <b>bulk-erase</b> devices whose contents cannot be updated in-place. They also suffer from slow program times and a limit on the number of program/erase cycles. eNVy uses a copy-on-write scheme, page remapping, a small amount of battery backed SRAM, and high bandwidth parallel data transfers to provide low latency, in-place update semantics. A cleaning algorithm optimized for large Flash arrays is used to reclaim space. The algorithm is designed to evenly wear the array, thereby extending its lifetime. Software simulations of a 2 gigabyte eNVy system show that it can support I/O rates corresponding to approximately 30, 000 transactions per second on the TPC-A database benchmark. Despite the added work done to overcome the deficiencies associated with Flash memories, average latencies to the storage system are as low as 180 ns for reads and 200 ns for writes. The estimated lifetime of this type of storage system is in the 10 year range when exposed to a workload of 10, 000 transactions per second...|$|E

