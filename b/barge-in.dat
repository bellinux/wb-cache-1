37|5|Public
50|$|The XVF3000 {{family of}} {{far-field}} voice processors announced in June 2017 includes voice pre-processing DSP for adaptive beamforming, full duplex acoustic echo cancellation with <b>barge-in,</b> noise suppression, automatic gain control.|$|E
50|$|Dr. Rabiner has pioneered a {{range of}} novel {{algorithms}} for digital filtering and digital spectrum analysis. The most well known of these algorithms are the Chirp z-Transform method (CZT) of spectral analysis, {{a range of}} optimal FIR (finite impulse response) digital filter design methods based on linear programming and Chebyshev approximation methods, and a class of decimation/interpolation methods for digital sampling rate conversion. In the area of speech processing, Dr. Rabiner has made contributions to the fields of pitch detection, speech synthesis and speech recognition. Dr. Rabiner built {{one of the first}} digital speech synthesizers that was able to convert arbitrary text to intelligible speech. In the area of speech recognition, Dr. Rabiner was a major contributor {{to the creation of the}} statistical method of representing speech that isknown as hidden Markov modeling (HMM). Dr. Rabiner was the first to publish the scaling algorithm for the Forward-Backward method of training of HMM recognizers. His research showed how to successfully implement an HMM system based on either discrete or continuous density parameter distributions. His tutorial paper on HMM is highly cited. Dr. Rabiner’s research resulted in a series of speech recognition systems that went into deployment by AT&T to enable automation of a range of ‘operator services’ that previously had been carried out using live operators. One such system, called the Voice Recognition Call Processing (VRCP) system, automated a small vocabulary recognition system (5 active words) with word spotting and <b>barge-in</b> capability. It resulted in savings of several hundred millions of dollars annually for AT&T.|$|E
40|$|<b>Barge-in</b> {{enables the}} user to provide input during system speech, facilitating a more natural and {{efficient}} interaction. Standard methods generally focus on singlestage <b>barge-in</b> detection, applying the dialogue policy irrespective of the <b>barge-in</b> context. Unfortunately, this approach performs poorly when used in challenging environments. We propose and evaluate a <b>barge-in</b> processing method that uses a prediction strategy to continuously decide whether to pause, continue, or resume the prompt. This model has greater task success and efficiency than the standard approach when evaluated in a public spoken dialogue system. Index Terms: spoken dialogue systems, <b>barge-in...</b>|$|E
40|$|Incremental {{processing}} allows system {{designers to}} address several discourse phenomena that have previously been somewhat neglected in interactive systems, such as backchannels or <b>barge-ins,</b> {{but that can}} enhance the responsiveness and naturalness of systems. Unfortunately, prior work has focused largely on deterministic incremental decision making, rendering system behaviour less flexible and adaptive than is desirable. We present a novel approach to incremental decision making {{that is based on}} Hierarchical Reinforcement Learning to achieve an interactive optimisation of Information Presentation (IP) strategies, allowing the system to generate and comprehend backchannels and <b>barge-ins,</b> by employing the recent psycholinguistic hypothesis of information density (ID) (Jaeger, 2010). Results in terms of average rewards and a human rating study show that our learnt strategy outperforms several baselines that are not sensitive to ID by more than 23 %. ...|$|R
40|$|The Parlance {{system for}} {{interactive}} search processes dialogue at a microturn level, displaying dialogue phenomena that {{play a vital}} role in human spoken conversation. These dialogue phenomena include more natural turn-taking through rapid system responses, generation of backchannels, and user <b>barge-ins.</b> The Parlance demonstration system differentiates from other incremental systems in that it is data-driven with an infrastructure that scales well. ...|$|R
40|$|We {{describe}} a computational framework for modeling and managing turn-taking in open-world spoken dialog systems. We present a rep-resentation and methodology for tracking the conversational dynamics in multiparty interac-tions, making floor control decisions, and ren-dering these decisions into appropriate behav-iors. We {{show how the}} approach enables an em-bodied conversational agent to participate in multiparty interactions, and to handle a diversity of natural turn-taking phenomena, including multiparty floor management, <b>barge-ins,</b> restarts, and continuations. Finally, we discuss results and lessons learned from experiments. ...|$|R
40|$|Managing various {{behaviors}} of real users is indispensable for spoken dialogue systems to operate adequately in real environments. We have analyzed various users ’ behaviors using data collected over 34 months from the Kyoto City Bus Information System. We focused on “barge-in ” and added <b>barge-in</b> rates to our analysis. Temporal transitions of users ’ behaviors, such as {{automatic speech recognition}} (ASR) accuracy, task success rates and <b>barge-in</b> rates, were initially investigated. We then {{examined the relationship between}} ASR accuracy and <b>barge-in</b> rates. Analysis revealed that the ASR accuracy of utterances inputted with barge-ins was lower because many novices, who were not accustomed to the timing when to utter, used the system. We also observed that the ASR accuracy of utterances with barge-ins differed based on the <b>barge-in</b> rates of individual users. The results indicate that the <b>barge-in</b> rate {{can be used as a}} novel user profile for detecting ASR errors. Index Terms: spoken dialogue system, real user behavior, barge-i...|$|E
40|$|In {{this paper}} we present novel {{solutions}} to problems related to <b>barge-in</b> in telephony-based conversational systems. In particular we address recovery from falsely detected <b>barge-in</b> events and a method for signaling to the user that <b>barge-in</b> is disallowed at a particular dialogue state. The mechanisms and signals used to manage turn taking {{are similar to those}} in human-human conversation, which makes them easy to understand for users without explanation or prior training. 1. INTRODUCTION In telephony-based spoken language systems, it is desirable to let users interrupt system output at any time, in particular if the output is based on erroneous understanding or contain superfluous information. Thus, enabling <b>barge-in,</b> i. e., the ability for the user to start speaking before system output has ended, can significantly enhance the user experience. However, users' new freedom also poses new challenges. One challenge is sorting out true user <b>barge-in</b> from background noise and nonspeech soun [...] ...|$|E
40|$|Modeling of {{individual}} users is a promising way {{of improving the}} performance of spoken dialogue systems deployed {{for the general public}} and utilized repeatedly. We define “implicitly-supervised ” ASR accuracy per user on the basis of responses following the system’s explicit confirmations. We combine the estimated ASR accuracy with the user’s <b>barge-in</b> rate, which represents how well the user is accustomed to using the system, to predict interpretation errors in <b>barge-in</b> utterances. Experimental results showed that the estimated ASR accuracy improved prediction performance. Since this ASR accuracy and the <b>barge-in</b> rate are obtainable at runtime, they improve prediction performance without the need for manual labeling. ...|$|E
40|$|Faced {{with the}} {{difficulties}} of finding an operationalized definition of backchannels, we have previously proposed an intermediate, auxiliary unit – the very short utterance (VSU) – which is defined operationally and is automatically extractable from recorded or ongoing dialogues. Here, we extend that work in the following ways: (1) we test {{the extent to which}} the VSU/NONVSU distinction corresponds to backchannels/non-backchannels in a different data set that is manually annotated for backchannels – the Columbia Games Corpus; (2) we examine to the extent to which VSUS capture other short utterances with a vocabulary similar to backchannels; (3) we propose a VSU method for better managing turn-taking and <b>barge-ins</b> in spoken dialogue systems based on detection of backchannels; and (4) we attempt to detect backchannels with better precision by training a backchannel classifier using durations and inter-speaker relative loudness differences as features. The results show that VSUS indeed capture a large proportion of backchannels – large enough that VSUs can be used to improve spoken dialogue system turntaking; and that building a reliable backchannel classifier working in real time is feasible...|$|R
40|$|Incremental {{dialogue}} {{systems are}} often perceived as more responsive and natural {{because they are}} able to address phenomena of turn-taking and overlapping speech, such as backchannels or <b>barge-ins.</b> Previous work in this area has often identified distinctive prosodic features, or features relating to syntactic or semantic completeness, as marking appropriate places of turn-taking. In a separate strand of work, psycholinguistic studies have established a connection between information density and prominence in language—the less expected a linguistic unit is in a particular context, {{the more likely it is}} to be linguistically marked. This has been observed across linguistic levels, including the prosodic, which plays an important role in predicting overlapping speech. In this article, we explore the hypothesis that information density (ID) also plays a role in turn-taking. Specifically, we aim to show that humans are sensitive to the peaks and troughs of information density in speech, and that overlapping speech at ID troughs is perceived as more acceptable than overlaps at ID peaks. To test our hypothesis, we collect human ratings for three models of generating overlapping speech based on features of: (1) prosody and semantic or syntactic completeness, (2) information density, and (3) both types of information. Results show that over 50...|$|R
40|$|Abstract—In this study, {{we propose}} a novel {{technique}} for acoustic echo suppression (AES) during speech recognition under <b>barge-in</b> conditions. Conventional AES methods based on spectral subtraction apply fixed weights to the estimated echo path transfer function (EPTF) {{at the current}} signal segment and to the EPTF estimated until the previous time interval. However, the effects of echo path changes should be considered for eliminating the undesired echoes. We describe a new approach that adaptively updates weight parameters in response to abrupt changes in the acoustic environment due to background noises or double-talk. Furthermore, we devised a voice activity detector and an initial time-delay estimator for <b>barge-in</b> speech recognition in communication networks. The initial time delay is estimated using log-spectral distance measure, as well as cross-correlation coefficients. The experimental {{results show that the}} developed techniques can be successfully applied in <b>barge-in</b> speech recognition systems. Keywords—Acoustic echo suppression, <b>barge-in,</b> speech recognition, echo path transfer function, initial delay estimator, voice activity detector. I...|$|E
40|$|In our barge-in-able spoken {{dialogue}} system, the user’s {{behaviors such}} as <b>barge-in</b> timing and utterance expressions vary according to his/her characteristics and situations. The system adapts to the behaviors by modeling them. We analyzed 1584 utterances collected by our systems of quiz and news-listing tasks and showed that ratio of using referential expressions depends on individual users and average lengths of listed items. This tendency was incorporated as a prior probability into our method and improved the identification accuracy of the user’s intended items. Index Terms: <b>barge-in,</b> spoken dialogue systems, utterance timing, user characteristic...|$|E
40|$|In {{conversational}} dialogue systems, users {{prefer to}} speak {{at any time and}} to use natural expressions. We have developed an Independent Component Analysis (ICA) based semi-blind source separation method, which allows users to <b>barge-in</b> over system utterances at any time. We created a novel method from timing information derived from <b>barge-in</b> utterances to identify one item that a user indicates during system enumeration. First, we determine the timing distribution of user utterances containing referential expressions and then approximate it using a gamma distribution. Second, we represent both the utterance timing and automatic speech recognition (ASR) results as probabilities of the desired selection from the system’s enumeration. We then integrate these two probabilities to identify the item having the maximum likelihood of selection. Experimental results using 400 utterances indicated that our method outperformed two methods used as a baseline (one of ASR results only and one of utterance timing only) in identification accuracy. Index Terms: spoken dialogue system, conversational interaction, <b>barge-in,</b> utterance timin...|$|E
40|$|We {{exploit the}} <b>barge-in</b> rate of {{individual}} users to predict {{automatic speech recognition}} (ASR) errors. A <b>barge-in</b> is {{a situation in which}} a user starts speaking during a system prompt, and it can be detected even when ASR results are not reliable. Such features not using ASR results can be a clue for managing a situation in which user utterances cannot be successfully recognized. Since individual users in our system can be identified by their phone numbers, we accumulate how often each user barges in and use this rate as a user profile for determining whether a current “barge-in ” utterance should be accepted or not. We furthermore set a window that reflects the temporal transition of the user’s behavior as they get accustomed to the system. Experimental results show that setting the window improves the prediction accuracy of whether the utterance should be accepted or not. The experiments also clarify the minimum window width for improving accuracy. Index Terms: spoken dialogue system, user modeling, <b>barge-in</b> 1...|$|E
40|$|This paper {{describes}} a new interface for a <b>barge-in</b> free spoken dialogue system combining an adaptive sound field control and a microphone array. In order to actualize robustness against {{the change of}} transfer functions due to the various interferences, the <b>barge-in</b> free spoken dialogue system which uses sound field control and a microphone array has been proposed {{by one of the}} authors. However, this method cannot follow the change of transfer functions because the method consists of fixed filters. To solve the problem, we introduce a new adaptive sound field control that follows the change of transfer functions...|$|E
40|$|In this paper, a turn-taking {{phenomenon}} taxonomy is introduced, organised accord-ing to {{the level}} of information conveyed. It is aimed to provide a better grasp of the behaviours used by humans while talking to each other, {{so that they can be}} method-ically replicated in spoken dialogue sys-tems. Five interesting phenomena have been implemented in a simulated environ-ment: the system <b>barge-in</b> with three vari-ants (resulting from either an unclear, an incoherent or a sufficient user message), the feedback and the user <b>barge-in.</b> The experiments reported in the paper illus-trate that how such phenomena are imple-mented is a delicate choice as their impact on the system’s performance is variable. ...|$|E
40|$|We {{develop a}} method to detect {{erroneous}} interpretation results of user utterances by exploiting utterance histories of individual users in spoken dialogue systems that were deployed {{for the general public}} and repeatedly utilized. More specifically, we classify <b>barge-in</b> utterances into correctly and erroneously interpreted ones by using features of individual users ’ utterance histories such as their <b>barge-in</b> rates and estimated automatic speech recognition (ASR) accuracies. Online detection is enabled by making these features obtainable without any manual annotation or labeling. We experimentally compare classification accuracies for several cases when an ASR confidence measure is used alone or in combination with the features based on the user’s utterance history. The error reduction rate was 15 % when the utterance history was used. ...|$|E
40|$|ICSLP 2004 : the 8 th International Conference on Spoken Language Processing, October 4 - 8, 2004, Jeju Island, Korea. This paper {{describes}} a new interface for a <b>barge-in</b> free spoken dialogue system combining an adaptive sound field control and a microphone array. In order to actualize robustness against {{the change of}} transfer functions due to the various interferences, the <b>barge-in</b> free spoken dialogue system which uses sound field control and a microphone array has been proposed {{by one of the}} authors. However, this method cannot follow the large change of transfer functions. To solve the problem, we introduce a new adaptive sound field control that follows the change of transfer functions. The experimental results reveal that the proposed method can improve the reduction accuracy of response sound in comparison with the conventional acoustic echo canceller as well as the previously proposed method which simply uses fixed sound field control system...|$|E
40|$|We {{present a}} {{mechanism}} for handling ``barge-in'' interruptions from a user who {{is engaged in a}} 'social' conversation with an Embodied Conversational Agent (ECA). The ECA is designed to recognise and be empathetic to the emotional state of the user. Occasionally, the ECA will attempt to positively influence the user's emotional state through the conversation. A characteristic of these conversations is that both the user and the ECA will at times speak long, multi sentence utterances as the conversation progresses. The generation of long utterances from the ECA creates opportunities for the user to <b>barge-in</b> whilst the ECA is speaking. Furthermore, the long ECA utterances may even provoke a user interruption since they often include advice to the user about how they should deal with difficult or stressful situations that have arisen. This paper outlines an approach to handling user <b>barge-in</b> interruptions in conversations with an ECA and describes its implementation in the Companions English demonstrator...|$|E
30|$|Because FSTs are {{considered}} to be the equivalent of an automaton with outputs, complicated controls such as interruption (e.g., <b>barge-in),</b> processing according to context, and sequential dialog control can be realized using an FST. On the other hand, it is difficult to describe these complex scripts manually on a large scale; thus, it is necessary to develop techniques such as automated script generation using the database and dedicatedk tools.|$|E
40|$|ICA 2004 : 18 th International Congress on Acoustics, April 4 - 9, 2004, Kyoto, Japan. This paper {{describes}} a new interface for a <b>barge-in</b> free spoken dialogue system combined an adaptive sound field control and a microphone array. It {{is essential for}} an acoustic echo canceller to estimate transfer functions and update the adaptive filter coefficient, {{especially in the case}} of the change of transfer functions due to the various interferences. In addition, the estimation process of transfer functions prevents a user from uttering freely and simultaneously during the response of a dialogue system In order to actualize the robustness against the change of transfer functions, the <b>barge-in</b> free spoken dialogue system which using sound field control and a microphone array has been proposed. However, this method cannot follow the change of transfer functions. To solve the problem, we introduce a new adaptive sound field control that follows the change of transfer functions. The experimental results reveal that the reduction accuracy of response sound is improved in comparison with the MOMNI method...|$|E
40|$|ICASSP 2003 : IEEE International Conference on Acoustics, Speech, and Signal Processing, April 6 - 10, 2003, Hong Kong, China. In this paper, a <b>barge-in</b> free spoken {{dialogue}} system using {{sound field}} control and microphone array is proposed. In the conventional spoken dialogue system using an acoustic echo canceller, it is indispensable to estimate and update the room transfer function, {{especially when the}} transfer function is changed by various interferences. However the estimation process for the transfer function prevents the user from speaking freely and simultaneously with speech responses from the system. In order to resolve the problem, we have already proposed a <b>barge-in</b> free spoken dialogue system that controls a sound field using multiple loudspeakers. In this paper, a microphone array for acquisition of user's speech is newly introduced in the previously proposed system. By introducing the microphone array, we can {{reduce the number of}} loudspeakers to be required in the system, and make the interface for spoken dialogue system more robust against the change of room transfer functions...|$|E
40|$|A {{dialogue}} {{system has}} {{to deal with the problem}} of interruptions by the user, e. g. changes of requests (called <b>barge-in).</b> This contribution is concerned with this problem in the special case of the multimodal dialogue system SmartKom 1. How are gestures used during such interruptions if they are utilized at all? To answer this question we analyzed a number of human-machine dialogues qualitatively. The analysis showed that most overlap situations were not accompanied by gestures at all. In the remaining instances the gestures were almost never "interactional" gestures, but mostly "unidentifiable" and "emotional" ones. We allocated the overlap situations accompanied by gestures to several subcategories of <b>barge-in,</b> pointed out the peculiarities of the gestures in the different cases and discussed their suitability as indicators for the dialogue system. Although from a small-scale in depth analysis no generalizations can be drawn, valuable insights for further investigation have been won. Most importantly it can be noted that the dynamic features of gestures seem far more promising as indicators of dialogue situations that need to be taken care of by the dialogue system than their static features...|$|E
40|$|A <b>barge-in</b> free spoken {{dialogue}} interface using {{sound field}} control and microphone array is proposed. In the conventional spoken dialogue system using an acoustic echo canceller, it is indispensable to estimate a room transfer function, {{especially when the}} transfer function is changed by various interferences. However, the estimation is difficult when the user and the system speak simultaneously. To resolve the problem, we propose a sound field control technique to prevent the response sound from being observed. Combined with a microphone array, the proposed method can achieve high elimination performance with no adaptive process. The efficacy of the proposed interface is ascertained in the experiments {{on the basis of}} sound elimination and speech recognition. </p...|$|E
40|$|This paper {{describes}} a new small-scale interface for a <b>barge-in</b> free spoken dialogue system combining a multichannel sound field control and a microphone array, {{in which the}} response sound from the system can be canceled out at the microphone points. The conventional method inhibits the user from moving because the system forces the user {{to stay in the}} fixed position where the response sound is reproduced. However, since the proposed method doesn’t arrange the control points for the reproduction of the response sound to the user, the user’s move is allowed. Furthermore, relaxation of the strict reproduction for the response sound enables us to design a stable system with fewer loudspeakers than the conventional method. Proposed method shows higher performances in the speech recognition experiments. 1...|$|E
40|$|Abstract — This paper {{presents}} the upper-limit evaluation of robot audition based on ICA-BSS in multi-source, <b>barge-in</b> and highly reverberant conditions. The goal {{is that the}} robot can automatically distinguish a target speech from its own speech and other sound sources in a reverberant environment. We focus on the multi-channel semi-blind ICA (MCSB-ICA), {{which is one of}} the sound source separation methods with a microphone array, to achieve such an audition system because it can separate sound source signals including reverberations with few assumptions on environments. The evaluation of MCSB-ICA has been limited to robot’s speech separation and reverberation separation. In this paper, we evaluate MCSB-ICA extensively by applying it to multi-source separation problems under common reverberant environments. Experimental results prove that MCSB-ICA outperforms conventional ICA by 30 points in automatic speech recognition performance...|$|E
40|$|In this paper, we {{describe}} a new interface for a <b>barge-in</b> free spoken dialogue system combining multichannel sound field control and beamforming, {{in which the}} response sound from the system can be canceled out at the microphone points. The conventional method inhibits a user from moving because the system forces the user to stay at a fixed position where the response sound is reproduced. However, since the proposed method does not set control points for the reproduction of the response sound to the user, the user is allowed to move. Furthermore, the relaxation of strict reproduction for the response sound enables us to design a stable system with fewer loudspeakers than those used in the conventional method. The proposed method shows a higher performance in speech recognition experiments...|$|E
40|$|The paper {{describes}} the ITC-irst approach for handling spoken dialogue interactions {{over the telephone}} network. <b>Barge-in</b> and utterance verication capabilities {{are going to be}} introduced into the developed software architecture. Some research activities that should enable accessing information in a new large applicative domain (i. e. the tourism domain) have been started. Objectives of the research are: language model adaptation and ecient information presentation, using a mixed representation approach. The paper reports the details of the researches. 1 Introduction Recently, ITC-irst has developed a software architecture for information access in restricted domains [1]. The architecture is formed by some modules, namely: telephone driver, dialogue engine, automatic speech recognition, speech synthesizer, database access, graphical interface, scheduler and language generation. Some of the functions performed by the above modules can be invoked through an Application Programm [...] ...|$|E
40|$|EUSIPCO 2005 : the 13 th European Signal Processing Conference, September 4 - 8, 2005, Antalya, Turkey. This paper {{describes}} a new small-scale interface for a <b>barge-in</b> free spoken dialogue system combining a multichannel sound field control and a microphone array, {{in which the}} response sound from the system can be canceled out at the microphone points. The conventional method inhibits the user from moving because the system forces the user {{to stay in the}} fixed position where the response sound is reproduced. However, since the proposed method doesn't arrange the control points for the reproduction of the response sound to the user, the user's move is allowed. Furthermore, relaxation of the strict reproduction for the response sound enables us to design a stable system with fewer loudspeakers than the conventional method. Proposed method shows higher performances in the speech recognition experiments...|$|E
40|$|We {{present an}} Embodied Conversational Agent(ECA) that {{incorporates}} a context-sensitive mechanism for handling user <b>barge-in.</b> The affective ECA engages the user in social conversation, and is fully implemented. We will use actual examples of system behaviour to illustrate. The ECA {{is designed to}} recognise and be empathetic to the emotional state of the user. It is able to detect, react quickly to, and then follow up with considered responses to different kinds of user interruptions. The design of the rules which enable the ECA to respond intelligently to different types of interruptions was informed by manually analysed real data from human–human dialogue. The rules represent recoveries from interruptions as two-part structures: an address followed by a resumption. The system is robust enough to man- age long, multi-utterance turns by both user and system, which creates good opportunities for the user to interrupt while the ECA is speaking...|$|E
40|$|Chang. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. In this paper, we present some techniques of acoustic echo cancellation for far-end (server-side) telephony speech recognition during <b>barge-in</b> situations. We develop a normalized least mean square algorithm for the adaptive filter of an echo canceller, and a double-talk detector for the online speech recognition services. In particular, we devise a voice activity detector for estimating the initial delay due to communication networks. In addition, we propose a hybrid method that uses the log-spectral distance measure, {{as well as the}} cross-correlation coeffi- 1114 Jong Han Joo et al. cients, to estimate the initial delay. From the simulation and the experiments in real environments, we conclude that the developed techniques can be successfully used for far-end telephony speech recognition services...|$|E
40|$|Turn {{taking in}} spoken {{language}} systems {{has generally been}} push-to-talk or strict alternation (user speaks, system speaks, user speaks, …) with some systems such as telephone-based systems handling <b>barge-in</b> (interruption by the user.) In this paper we describe our time sensitive conversational architecture for turn taking that not only allows alternating turns and barge in, but other conversational behaviors as well. This architecture allows backchanneling, prompting the user by taking more than one turn if necessary, and overlapping speech. The architecture is implemented in a Reading Tutor that listens to children read aloud, and helps them. We extended this architecture to allow the Reading Tutor to interrupt the student based on a non-self-corrected mistake – “content-driven interruption”. To {{the best of our}} knowledge, the Reading Tutor is thus the first spoken language system to intentionally interrupt the user based on the content of the utterance. 1...|$|E
40|$|Telephone based spoken {{dialogue}} {{systems have}} the potential to automate many routine tasks. Yet, to become widely accepted they must be natural, easy to use, efficient, and robust. We introduce the Conference Room Reservation System (CRRS), a mixed-initiative natural dialogue system used routinely by the employees of our lab. The CRRS allows callers to reserve or cancel rooms by simply stating their constraints in a natural way. The system prompts for missing information and offers alternative solutions if the original constraints cannot be satisfied. Our system uses Nortel Networks ’ OpenSpeech continuous speech recognizer with <b>barge-in,</b> a robust natural language parser, and a mixed-initiative discourse manager. We describe the overall system with an emphasis on the discourse manager. We present an analysis of real data collected over several months. We then discuss the issue of defining dialogue performance metrics that are independent of the room occupancy rate. 1...|$|E
40|$|Abstract. We {{describe}} a novel dialogue strategy enabling robust interaction under noisy environments where {{automatic speech recognition}} (ASR) results are not necessarily reliable. We have developed a method that exploits utterance timing together with ASR results to interpret user intention, that is, to identify one item that a user wants to indicate from system enumeration. The timing of utterances containing referential expressions is approximated by Gamma distribution, which is integrated with ASR results by expressing both of them as probabilities. In this paper, we improve the identification accuracy by extending the method. First, we enable interpretation of utterances including ordinal numbers, which appear several times in our data collected from users. Then we use proper acoustic models and parameters, improving the identification accuracy by 4. 0 % in total. We also show that Latent Semantic Mapping (LSM) enables more expressions to be handled in our framework. Index Terms: spoken dialogue systems, conversational interaction, <b>barge-in,</b> utterance timing...|$|E
40|$|This paper {{describes}} a new method that allows “Barge-In ” in various environments for robot audition. “Barge-in ” {{means that a}} user begins to speak simultaneously while a robot is speaking. To achieve the function, we must deal with problems on blind dereverberation and echo cancellation at the same time. We adopt Independent Component Analysis (ICA) because it essentially provides a natural framework for these two problems. To deal with reverberation, we apply a Multiple Input/Output INverse-filtering Theorem-based model of observation to the frequency domain ICA. The main problem is its high-computational cost of ICA. We reduce the computational complexity to the linear order of reverberation time by using two techniques: 1) a separation model based on observed signal independence, and 2) enforced spatial sphering for preprocessing. The experimental results revealed that our method improved word correctness of reverberant speech by 10 - 20 points. Index Terms — <b>Barge-In,</b> ICA, MINT, blind dereverberation, echo cancellatio...|$|E
