7|57|Public
5000|$|A fixed-point divide exceptionPoOps is {{recognized}} when significant bits are {{lost in a}} fixed point divide or Convert to <b>Binary</b> <b>instruction.</b>|$|E
50|$|A {{compiler}} converts {{source code}} into <b>binary</b> <b>instruction</b> {{for a specific}} processor's architecture, thus making it less portable. This conversion is made just once, on the developer's environment, and after that the same binary can be distributed to the user's machines {{where it can be}} executed without further translation. A cross compiler can generate binary code for the user machine even if it has a different processor than the machine where the code is compiled.|$|E
5000|$|The Cortex-M0 / M0+ / M1 {{implement}} the ARMv6-M architecture, the Cortex-M3 implements the ARMv7-M architecture, and the Cortex-M4 / M7 implements the ARMv7E-M architecture. [...] The architectures are <b>binary</b> <b>instruction</b> upward compatible from ARMv6-M to ARMv7-M to ARMv7E-M. Binary instructions {{available for the}} Cortex-M0 / M0+ / M1 can execute without modification on the Cortex-M3 / M4 / M7. Binary instructions available for the Cortex-M3 can execute without modification on the Cortex-M4 / M7 / M33. [...] Only Thumb-1 and Thumb-2 instruction sets are supported in Cortex-M architectures, but the legacy 32-bit ARM instruction set isn't supported.|$|E
50|$|When silicon {{technology}} allowed for wider implementations (with more execution units) to be built, the compiled {{programs for the}} earlier generation would not run on the wider implementations, as the encoding of <b>binary</b> <b>instructions</b> depended {{on the number of}} execution units of the machine.|$|R
40|$|Correlation Matrix Memory (CMM) is {{a single}} layer binary neural network. One of the {{principle}} motivations behind the development of binary neural networks was the ease of implementation. Almost all of todays computing machines operate using <b>binary</b> <b>instructions</b> on <b>binary</b> data and therefore lend themselves well to the simulation of binary networks. However as new, more complex, applications are found for neural networks the size of CMM required the amount of data they operate on can grow very fast...|$|R
40|$|Dynamic {{instrumentation}} is {{the process}} of modifying a programâ€™s <b>binary</b> <b>instructions</b> on the fly while the program executes. This technique is used {{in a wide variety of}} tools for performance analysis, profiling, coverage analysis, correctness checking, and testing. Instrumenting applications generated from C++ sources reveals new complications, mainly caused by the C++ exception handling mechanism. This paper presents problems, solutions and experiences specific to dynamic instrumentation of multi-threaded C++ applications for HP-UX running on IA- 64 processors. 1...|$|R
40|$|Abstract. A Virtual Machine (VM) is {{a program}} running on a {{conventional}} microprocessor that emulates the <b>binary</b> <b>instruction</b> set, registers, and memory space of an idealized computing machine: a well-known example being the Java Virtual Machine (JVM). Despite there being many <b>binary</b> <b>instruction</b> set architectures (ISA) in existence, all share a set of core properties which have been tailored to their particular applications. An abstract model may capture these generic properties and be subsequently refined to a particular machine, providing a reusable template for development of formally proven ISAs: this is a task to which the EventB [16, 18] notation is well suited. This paper describes a project to use the RODIN tool-set [24] to perform such a process, ultimately producing the MIDAS (Microprocessor Instruction and Data Abstraction System) VM, capable of running binary executables compiled from high-level languages such as C [9]. The abstract model is incrementally refined to a model capable of automatic translation to C source code, and compilation for a hardware platform using a standard compiler. A second C compiler, targeted to the VM itself, allows C programs to be executed on it. ...|$|E
40|$|Abstract:- This {{research}} {{focuses on}} the design and implementation of a tool to speed-up the development and deployment of heterogeneous wireless sensor networks. The THAWS (Tyndall Heterogeneous Automated Wireless Sensors) tool {{can be used to}} quickly create and configure application-specific sensor networks, based on a list of application requirements and constraints. THAWS presents the user with a choice of options, in order to gain this information on the functionality of the network. With this information, THAWS uses code generation techniques to create the necessary code from pre-written templates and well-tested, optimized software modules from a library, which includes an implementation of novel plug-and-play sensor interface. These library modules can also be modified at the code generation stage. The application code and necessary library modules are then automatically compiled to form <b>binary</b> <b>instruction</b> files for each node in the network. The <b>binary</b> <b>instruction</b> files then wirelessly propagate through the network, and reprogram the nodes. This completes the task of targeting the wireless network towards a specific sensing application. THAWS is an adaptable tool that works with both homogeneous and heterogeneous networks built from wireless sensor nodes that have been developed in the Tyndall National Institute. Its advantage over traditional methods of WSN development is simplification of development...|$|E
40|$|This paper {{presents}} a novel instruction encoding generation technique {{for use in}} architecture exploration for application specific processors. The underlying exploration methodology is based on successive processor model refinement combined with simulation and profiling. Previous approaches require the tedious manual specification of <b>binary</b> <b>instruction</b> opcodes even at very early design stages due {{to the need to}} generate profiling tools. The proposed automatic technique eliminates this bottleneck in ASIP design. It is well adapted to the hierarchical processor modeling style of contemporary architecture description languages. Experimental evaluation for several real-life processor architectures confirms the practical applicability of the presented encoding techniques. Moreover, the results indicate that very compact instruction encoding schemes are generated that compete very well with hand-optimized encodings...|$|E
50|$|<b>Binaries</b> {{incorporate}} additional <b>instruction</b> sets.|$|R
5000|$|LaTeX {{documents}} (...) can {{be opened}} with any text editor. They consist of plain text {{and do not}} contain hidden formatting codes or <b>binary</b> <b>instructions.</b> Additionally, TeX documents can be shared by rendering the LaTeX file to Rich Text Format (...) or XML. This can be done using the free software programs LaTeX2RTF or TeX4ht. LaTeX can also be rendered to PDF files using the LaTeX extension pdfLaTeX. LaTeX files containing Unicode text can be processed into PDFs by the LaTeX extension XeLaTeX.|$|R
40|$|Abstract. This article {{presents}} some new results concerning two algebraic {{attacks against the}} F-FCSR constructions proposed in [2]. We focus on {{the parameters of the}} stream ciphers proposed that permit to mount algebraic attacks when using the IV mode. The complexity obtained for the first attack described here is 245 <b>binary</b> <b>instructions</b> using 215 known IV values for the construction F-FCSR-SF 1. All the proposed attacks are full key recovery at-tacks. We do not contest that the FCSRs are a good and new idea, we just say that the chosen parameters do not ensure the security level claimed...|$|R
40|$|This paper {{describes}} a freshman-level computer organization course designed {{to remove the}} magic surrounding the operation of modern computer systems. Students in the course use a virtual machine with a graphical interface (simulating a processor named TSC) to develop assembly language programming skills. They then use digital design techniques to implement TSC and run their programs on it. We have found the course {{to be successful in}} bringing the students full circle, showing how <b>binary</b> <b>instructions</b> and simple gates can lead to a working computer system. A text has been written to integrate the lecture topics and the labs. The text, labs, and software tools have been made available on the Web. ...|$|R
40|$|ADBI is a BF {{interpreter}} {{which uses}} dynamic code generation to speed program execution, primarily {{by removing the}} need to reinterpret BF code when looping. (With some debugging of GNU lightning, ADBI could also save the compiled code its DCG produces {{so that it would}} not need to reinterpret the BF code when ADBI is ran again.) The Process to Build Code Dynamically ADBI begins by reading in the BF code into an array in memory, after which ADBI begins compiling the loaded BF code (compiling is done in a function oddly enough named compile bf()). ADBI uses a set of macros called GNU lightning, copylefted by the Free Software Foundation, that take the assembly instructions ADBI generates and turns them into <b>binary</b> <b>instructions</b> fo...|$|R
40|$|Performance {{auditing}} is {{an online}} optimization strategy that empirically measures {{the effectiveness of}} an optimization on a particular code region. It {{has the potential to}} greatly improve performance and prevent degradations due to compiler optimizations. Performance auditing relies on the ability to obtain sufficiently many timings of the region of code to make statistically valid conclusions. This work extends the state-of-the-art of performance auditing systems by allowing a finer level of granularity for obtaining timings and thus, increases the overall effectiveness of a performance auditing system. The problem solved by our technique is an instance of the general problem of correlating a programâ€™s high-level behavior with its <b>binary</b> <b>instructions,</b> and thus, can have uses beyond a performance auditing system. We present our implementation and evaluation of our technique in a production Java VM. 1...|$|R
5000|$|... 1996 Intel {{announced}} the MCS-151 family, an up to 6 times faster variant. 8051 fully <b>binary</b> and <b>instruction</b> set compatible, but with pipelined CPU, 16 bit internal code bus and 6x speed. The MCS-151 family was also discontinued by Intel, but is {{widely available in}} binary compatible and partly enhanced variants.|$|R
40|$|In this paper, we are {{interested}} in memoryless computation, a modern paradigm to compute functions which generalises the famous XOR swap algorithm to exchange the contents of two variables without using a buffer. In memoryless computation, programs are only allowed to update one variable at a time. We first consider programs which do not use any memory. We study the maximum and average number of updates required to compute functions without memory. We then derive the exact number of instructions required to compute any manipulation of variables. This shows that combining variables, instead of simply moving them around, not only allows for memoryless programs, but also yields shorter programs. Second, we show that allowing programs to use memory is also incorporated in the memoryless computation framework. We then quantify the gains obtained by using memory: this leads to shorter programs and allows us to use only <b>binary</b> <b>instructions,</b> which is not sufficient in general when no memory is used...|$|R
40|$|Profile-Guided Optimization (PGO) is an {{excellent}} means to improve {{the performance of a}} compiled program. Indeed, the execution path data it provides helps the compiler to generate better code and better cacheline packing. At the time of this writing, compilers only support instrumentation-based PGO. This proved effective for optimizing programs. However, few projects use it, due to its complicated dual-compilation model and its high overhead. Our solution of sampling Hardware Performance Counters overcome these drawbacks. In this paper, we propose a PGO solution for GCC by sampling Last Branch Record (LBR) events and using debug symbols to recreate source locations of <b>binary</b> <b>instructions.</b> By using LBR-Sampling, the generated profiles are very accurate. This solution achieved an average of 83 % of the gains obtained with instrumentation-based PGO and 93 % on C++ benchmarks only. The profiling overhead is only 1. 06 % on average whereas instrumentation incurs a 16 % overhead on average. Comment: 10 page...|$|R
2500|$|Assembly languages, {{like most}} other {{computer}} languages, allow comments {{to be added to}} program source code that will be ignored during assembly. Judicious commenting is essential in assembly language programs, as the meaning and purpose of a sequence of <b>binary</b> machine <b>instructions</b> can be difficult to determine. The [...] "raw" [...] (uncommented) assembly language generated by compilers or disassemblers is quite difficult to read when changes must be made.|$|R
40|$|Jsim/ {{directory}} contents: Jsim_license. html - this license {{applies to}} all files in the jsim/ directory JSim_linux_ 2 _ 12. zip - binary Linux distribution JSim_macos_ 2 _ 12. zip - binary MacOS distribution JSim_src_ 2 _ 12. zip - source distribution JSim_win 32 _ 2 _ 12. zip - binary Windows distribution linux. html - Linux <b>binary</b> distribution installation <b>instructions</b> macos. html - MacOS <b>binary</b> distribution installation <b>instructions</b> source. html - Source distribution build instructions win 32. html - Windows <b>binary</b> distribution installation <b>instructions</b> models/ directory contents: BeelerReuter 77. proj - JSim project used in performance analysis section BTEX 20 simple. mod - model code BTEX 20 simple. proj - JSim project for model figure generation BTEX 30. proj - JSim project used in performance analysis section CTEX 30. proj - JSim project used in performance analysis section MM 2 irrev. mod - model code MM 2 Substrate_irrevers. proj - JSim project for model figure generation model_license. txt - this licensWinslow_Rice_Jafri 1999. proje {{applies to all}} files in the models/ directory. Winslow_Rice_Jafri 1999. proj - JSim project used in performance analysis sectio...|$|R
40|$|Memoryless {{computation}} is {{a modern}} technique to compute any function {{of a set of}} registers by updating one register at a time while using no memory. Its aim is to emulate how computations are performed in modern cores, since they typically involve updates of single registers. The memoryless computation model can be fully expressed in terms of transformation semigroups, {{or in the case of}} bijective functions, permutation groups. In this paper, we consider how efficiently permutations can be computed without memory. We determine the minimum number of basic updates required to compute any permutation, or any even permutation. The small number of required instructions shows that very small instruction sets could be encoded on cores to perform memoryless computation. We then start looking at a possible compromise between the size of the instruction set and the length of the resulting programs. We consider updates only involving a limited number of registers. In particular, we show that <b>binary</b> <b>instructions</b> are not enough to compute all permutations without memory when the alphabet size is even. These results, though expressed as properties of special generating sets of the symmetric or alternating groups, provide guidelines on the implementation of memoryless computation...|$|R
50|$|Most modern {{computers}} use <b>binary</b> encoding for <b>instructions</b> and data. CDs, DVDs, and Blu-ray Discs represent {{sound and}} video digitally in binary form. Telephone calls are carried digitally on long-distance and mobile phone networks using pulse-code modulation, and on voice over IP networks.|$|R
50|$|Code Morphing Software {{consisted}} of an interpreter, a runtime {{system and a}} dynamic <b>binary</b> translator. x86 <b>instructions</b> were first interpreted one instruction {{at a time and}} profiled, then depending upon the frequency of execution and other heuristics, CMS would progressively generate more optimized translations.|$|R
40|$|This {{thesis is}} {{interested}} in format of executable files EXE. It is focused on parts relevant for reverse engineering. It {{is interested in}} assembler, <b>binary</b> representation of <b>instruction</b> and disassembling. Follow IÂ introduce converting from executables to control flow graph, basic structures (branches, cycles) detection...|$|R
40|$|Funding: UK Engineering and Physical Sciences Research Council (EP/K 033956 / 1) Memoryless {{computation}} is a {{new technique}} to compute any function {{of a set of}} registers by updating one register at a time while using no memory. Its aim is to emulate how computations are performed in modern cores, since they typically involve updates of single registers. The memoryless computation model can be fully expressed in terms of transformation semigroups, {{or in the case of}} bijective functions, permutation groups. In this paper, we consider how efficiently permutations can be computed without memory. We determine the minimum number of basic updates required to compute any permutation, or any even permutation. The small number of required instructions shows that very small instruction sets could be encoded on cores to perform memoryless computation. We then start looking at a possible compromise between the size of the instruction set and the length of the resulting programs. We consider updates only involving a limited number of registers. In particular, we show that <b>binary</b> <b>instructions</b> are not enough to compute all permutations without memory when the alphabet size is even. These results, though expressed as properties of special generating sets of the symmetric or alternating groups, provide guidelines on the implementation of memoryless computation. Publisher PDFPeer reviewe...|$|R
40|$|We {{show how}} <b>binary</b> machine <b>instructions</b> {{can be used}} to {{implement}} fast vector operations over the finite field F- 3. Apart from the standard operations of addition, subtraction and dot product, we also consider combined addition and subtraction, weight, Hamming distance, and iteration over all vectors of a given length. Tests show that our implementation can be as much as 10 times faster than the standard method of using modular arithmetic on arrays of bytes. For computing the Hamming distance even a factor of 33 can sometimes be reached, provided a recent CPU is used...|$|R
40|$|Machine language: <b>binary</b> {{encoding}} of <b>instructions</b> {{that are}} executed by a CPU ï¿½ each CPU {{has its own}} machine language ï¿½ Ex: % 10000110; % 01011010 ï¿½ Assembly language: machine instructions are represented into a mnemonic form ï¿½ mnemonic form is then converted into actual processor instructions and associated dat...|$|R
25|$|Many second-generation CPUs {{delegated}} {{peripheral device}} communications to a secondary processor. For example, while the communication processor controlled card reading and punching, the main CPU executed calculations and <b>binary</b> branch <b>instructions.</b> One databus would bear data between the main CPU and core memory at the CPU's fetch-execute cycle rate, and other databusses would typically serve the peripheral devices. On the PDP-1, the core memory's cycle time was 5 microseconds; consequently most arithmetic instructions took 10 microseconds (100,000 operations per second) because most operations took {{at least two}} memory cycles; one for the instruction, one for the operand data fetch.|$|R
50|$|The drum memory held 1K of 40-bit words. The {{computer}} was programmed using <b>binary</b> machine code <b>instructions.</b> When programming the 1201, the machine code instructions were not sequential but were spaced {{to allow for}} the drum's rotation. This ensured the next instruction was passing under the drum's read heads just as the current instruction had been executed.|$|R
40|$|International audienceThe {{instruction}} set architecture (ISA) of a computing machine {{is the definition}} of the <b>binary</b> <b>instructions,</b> registers, and memory space visible to an executable binary image. ISAs are typically implemented in hardware as microprocessors, but also in software running on a host processor, i. e. virtual machines (VMs). Despite there being many ISAs in existence, all share a set of core properties which have been tailored to their particular applications. An abstract model may capture these generic properties and be subsequently refined to a particular machine, providing a reusable template for development of robust ISAs by the formal construction of all normal and exception conditions for each instruction. This is a task to which the Event-B (Metayer etÂ al. in Rodin deliverable 3. 2 Event-B language,, 2005; Schneider in The B-method an introduction, Palgrave, Basingstoke, 2001) formal notation is well suited. This paper describes a project to use the Rodin tool-set (Abrial in Formal methods and software engineering, Springer, Berlin, 2006) to perform such a process, ultimately producing two variants of the MIDAS (Microprocessor Instruction and Data Abstraction System) ISA (Wright in Abstract state machines, B and Z, Springer, Berlin, 2007; Wright in MIDAS machine specification, Bristol University,, 2009) as VMs. The abstract model is incrementally refined to variant models capable of automatic translation to C source code, which this is compiled to create useable VMs. These are capable of running binary executables compiled from high-level languages such as C (Kernighan and Ritchie in The C programming language, Prentice-Hall, Englewood Cliffs, 1988), and compilers targeted to each variant allow demonstration programs to be executed on them...|$|R
40|$|The LONI Pipeline is a {{graphical}} {{environment for}} construction, validation {{and execution of}} advanced neuroimaging data analysis protocols (Rex et al., 2003). It enables automated data format conversion, allows Grid utilization, facilitates data provenance, and provides a significant library of computational tools. There are two main advantages of the LONI Pipeline over other graphical analysis workfl ow architectures. It is built as a distributed Grid computing environment and permits efficient tool integration, protocol validation and broad resource distribution. To integrate existing data and computational tools within the LONI Pipeline environment, no modification of the resources themselves is required. The LONI Pipeline provides several types of process submissions based on the underlying server hardware infrastructure. Only workfl ow instructions and references to data, executable scripts and <b>binary</b> <b>instructions</b> are stored within the LONI Pipeline environment. This makes it portable, computationally efficient, distributed and independent of the individual binary processes involved in pipeline data-analysis workfl ows. We have expanded the LONI Pipeline (V. 4. 2) to include server-to-server (peer-to-peer) communication and a 3 -tier failover infrastructure (Grid hardware, Sun Grid Engine/Distributed Resource Management Application API middleware, and the Pipeline server). Additionally, the LONI Pipeline provides three layers of background-server executions for all users/sites/systems. These new LONI Pipeline features facilitate resource-interoperability, decentralized computing, construction and validation of efficient and robust neuroimaging data-analysis workfl ows. Using brain imaging data from the Alzheimer's Disease Neuroimaging Initiative (Mueller et al., 2005), we demonstrate integration of disparate resources, graphical construction of complex neuroimaging analysis protocols and distributed parallel computing. The LONI Pipeline, its features, specifications, documentation and usage ar e available online ([URL] Â© 2009 Dinov, Van Horn, Lozev, Magsipoc, Petrosyan, Liu, MacKenzie-Graham, Eggert, Parker and Toga...|$|R
40|$|Missions {{involving}} robotic {{space flight}} typically {{have a way}} to change the software that controls the flight system, or some part of it, such as an instrument, after launch. Usually this is accomplished by uplinking small sets of <b>binary</b> machine <b>instructions</b> and writing them to known locations in memory. We present an approach, used on the Aquarius mission, that involves replacing running components of, or adding components to, the running software at a higher logical level, specifically at the software architecture level, and on the C++ rather than machine-language level. This approach provides significant advantages in flexibility, robustness, reliability, and testability. We present the component-based flight software (FSW) design features that enable these capabilities. We then discuss the approach used to verify the robustness and reliability of these techniques, and finally describe usages to date...|$|R
40|$|Distributed {{computing}} on the Internet presents {{new challenges}} and opportunities for tools that inspect and modify program binaries. The dynamic and heterogeneous nature of the Internet environment extends the traditional product development process by requiring program development tools like these, which were once used only internally, to work in live environments too. The concept of compilation process must be expanded along with {{the capabilities of the}} binary tools. This paper presents Vulcan, a second-generation technology that addresses many of these challenges. Vulcan provides both static and dynamic code modification and provides a framework for cross-component analysis and optimization. It provides system-level analysis for heterogeneous <b>binaries</b> across <b>instruction</b> sets. Vulcan works in the Win 32 environment and can process x 86, IA 64, and MSIL binaries. Vulcan scales to large commercial applications and has been used to improve performance and reliability of Microsoft products in a production environment. 1...|$|R
40|$|These notes follow on {{from the}} {{material}} that you studied in CSSE 1000 Introduction to Computer Systems. There you studied details of logic gates, <b>binary</b> numbers and <b>instruction</b> set architectures using the Atmel AVR microcontroller family as an example. In your present course (METR 2800 Team Project I), {{you need to get}} on to designing and building an application which will include such a microcontroller. These notes focus on programming an AVR microcontroller in C and provide a number of example programs to illustrate the use of some of the AVR peripheral devices...|$|R
40|$|Future NASA {{missions}} {{will depend}} on radiation-hardened, power-efficient processing systems-on-a-chip (SOCs) that consist {{of a range of}} processor cores custom tailored for space applications. Aries Design Automation, LLC, has developed a processing SOC that is optimized for software-defined radio (SDR) uses. The innovation implements the Institute of Electrical and Electronics Engineers (IEEE) RazorII voltage management technique, a microarchitectural mechanism that allows processor cores to self-monitor, self-analyze, and selfheal after timing errors, regardless of their cause (e. g., radiation; chip aging; variations in the voltage, frequency, temperature, or manufacturing process). This highly automated SOC can also execute legacy PowerPC 750 <b>binary</b> code <b>instruction</b> set architecture (ISA), which is used in the flight-control computers of many previous NASA space missions. In developing this innovation, Aries Design Automation has made significant contributions to the fields of formal verification of complex pipelined microprocessors and Boolean satisfiability (SAT) and has developed highly efficient electronic design automation tools that hold promise for future developments...|$|R
40|$|In recent years, {{with only}} small {{fractions}} of modern processors now accessible {{in a single}} cycle, computer architects constantly fight against propagation issues across the die. Unfortunately this trend continues to shift inward, and now the even most internal features of the pipeline are designed around communication, not computation. To address the inward creep of this constraint, this work focuses on the characterization of communication within the pipeline itself, architectural techniques to avoid it when possible, and layout co-design for early detection of problems. I present work in creating a novel detection tool for common case operand movement which can rapidly characterize an applications dataflow patterns. The results produced are suitable for exploitation as {{a small number of}} patterns can describe a significant portion of modern applications. Work on dynamic dependence collapsing takes the observations from the pattern results and shows how certain groups of operations can be dynamically grouped, avoiding unnecessary communication between individual instructions. This technique also amplifies the efficiency of pipeline data structures such as the reorder buffer, increasing both IPC and frequency. I also identify the same sets of collapsible instructions at compile time, producing the same benefits with minimal hardware complexity. This technique is also done in a backward compatible manner as the groups are exposed by simple reordering of the <b>binarys</b> <b>instructions.</b> I present aggressive pipelining approaches for these resources which avoids the critical timing often presumed necessary in aggressive superscalar processors. As these structures are designed for the worst case, pipelining them can produce greater frequency benefit than IPC loss. I also use the observation that the dynamic issue order for instructions in aggressive superscalar processors is predictable. Thus, a hardware mechanism is introduced for caching the wakeup order for groups of instructions efficiently. These wakeup vectors are then used to speculatively schedule instructions, avoiding the dynamic scheduling when it is not necessary. Finally, I present a novel approach to fast and high-quality chip layout. By allowing architects to quickly evaluate what if scenarios during early high-level design, chip designs are less likely to encounter implementation problems later in the process. Ph. D. Committee Chair: Scott Wills; Committee Member: David Schimmel; Committee Member: Gabriel Loh; Committee Member: Hsien-Hsin Lee; Committee Member: Yorai Ward...|$|R
