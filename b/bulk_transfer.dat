171|506|Public
50|$|Along the {{southern}} boundary of North Albany lies a railroad owned by CSXT (the Chicago Line), {{which is also}} used by Amtrak. The former D&H Colonie Main Line (now owned by CP Rail) runs through North Albany, at Erie Street and Erie Boulevard sits a <b>bulk</b> <b>transfer</b> rail yard operated by <b>BULK</b> <b>Transfer</b> Services LLC.|$|E
5000|$|I/O {{processor}} interconnection: remote {{procedure call}} over a serial link, DMA controller for <b>bulk</b> <b>transfer</b> ...|$|E
50|$|The {{water is}} {{conveyed}} to the Coppermills Water Treatment Works for treatment, with the facility for <b>bulk</b> <b>transfer</b> to Essex and Suffolk Water.|$|E
40|$|Abstract—The Internet is {{witnessing}} {{explosive growth}} in traffic, {{in large part}} due to <b>bulk</b> <b>transfers.</b> Delivering such traffic is expensive for ISPs because they pay other ISPs based on peak utilization. To limit costs, many ISPs are deploying ad-hoc traffic shaping policies that specifically target bulk flows. However, there is relatively little understanding today {{about the effectiveness of}} different shaping policies at reducing peak loads and what impact these policies have on the performance of <b>bulk</b> <b>transfers.</b> In this paper, we compare several traffic shaping policies with respect to (1) the achieved reduction in peak network traffic and (2) the resulting performance loss for <b>bulk</b> <b>transfers.</b> We identified a practical policy that achieves peak traffic reductions of up to 50 % with only limited performance loss for <b>bulk</b> <b>transfers.</b> However, we found that the same policy leads to large performance losses for <b>bulk</b> <b>transfers</b> when deployed by multiple ISPs along a networking path. Our analysis revealed that this is caused by certain TCP characteristics and differences in local peak utilization times. I...|$|R
5000|$|... {{the data}} {{transfer}} between host and USB-ICC using <b>bulk</b> <b>transfers</b> or control transfers; ...|$|R
40|$|This paper {{evaluates the}} {{suitability}} of Backward Explicit Congestion Notification (BECN) for IP networks. The BECN mechanism has previously been used in non-IP networks, {{but there has been}} limited experimental investigation into the application of the BECN scheme as congestion control mechanism in IP networks. In this paper, we consider an enhanced algorithm for BECN which uses Internet Control Message Protocol (ICMP) Source Quenches for backward congestion notification in IP networks and undertake comparative performance evaluation of Random Early Detection (RED), Explicit Congestion Notification (ECN) and our enhanced BECN mechanism using both longlived TCP <b>bulk</b> <b>transfers</b> and short-lived webtraffic workloads. Our results show that for webtraffic workloads, BECN offers only slight improvement in transfer delay while average goodput for <b>bulk</b> <b>transfers</b> is no worse than that of ECN. For paths that have a high bandwidth delay product our results show that not only can BECN offer significant improvement in average goodput for <b>bulk</b> <b>transfers</b> over the ECN mechanism, but packet drops and transfer delay for short-lived webtraffic connections are also comparatively reduced. Additional observations show that on such paths TCP (NewReno) with RED can offer higher goodput for <b>bulk</b> <b>transfers</b> compared to ECN...|$|R
5000|$|The <b>Bulk</b> <b>Transfer</b> Division {{designs and}} {{manufactures}} variations of rotary railcar dumpers, or [...] "wagon tipplers," [...] {{which are in}} operation worldwide. These include rotary dumpers, C-shaped rotary (CR) dumpers, closed and open-sided turnover dumpers, and single and multiple car dumpers. They also design and manufacture rail car moving devices such as train positioners, train indexing equipment, CUB and other support equipment. <b>Bulk</b> <b>Transfer</b> also offers material handling equipment such as barge unloaders with both grab and continuous bucket designs, and related specialty machinery.|$|E
50|$|A Haul road (also {{haulage road}} or haul track) {{is a term}} for roads {{designed}} for heavy or <b>bulk</b> <b>transfer</b> of materials by haul trucks in the mining industry.|$|E
50|$|The Reliable Data Protocol (RDP) is {{a network}} {{transport}} protocol defined in RFC 908 and was updated in RFC 1151. It {{is meant to}} provide facilities for remote loading, debugging and <b>bulk</b> <b>transfer</b> of images and data. It {{should not be confused}} with RUDP.|$|E
50|$|The Uniform Commercial Code {{is another}} {{responsibility}} of the Business Filings Division, this Code conducts the laws of commercial transactions. This includes the sale of goods, commercial paper, bank deposits and collections, letters of credit, <b>bulk</b> <b>transfers,</b> bills of lading and investment securities.|$|R
50|$|ISO/IEC 7816-12:2005 {{provides}} two protocols {{for control}} transfers. This {{is to support}} the protocol T=0 (version A) or to use the transfer on APDU level (version B). ISO/IEC 7816-12:2005 provides the state diagrams for the USB-ICC {{for each of the}} <b>transfers</b> (<b>bulk</b> <b>transfers,</b> control transfers version A and version B). Examples of possible sequences which the USB-ICC must be able to handle are given in an informative annex.|$|R
5000|$|<b>Bulk</b> <b>transfers</b> tap {{the channel}} as {{bandwidth}} is available. Delivery is guaranteed, but neither transfer rate nor latency are, though the host can attempt to leverage pending transfers or endpoints. They {{are used for}} high-volume transfers exhibiting a sharp time-varying behavior. They use unidirectional pipes.|$|R
5000|$|The {{well-known}} TCP port 119 {{is reserved}} for NNTP. Well-known TCP port 433 (NNSP) may be used when doing a <b>bulk</b> <b>transfer</b> of articles from one server to another. When clients connect to a news server with Transport Layer Security (TLS), TCP port 563 is often used. This is {{sometimes referred to as}} NNTPS. Alternatively, a plain-text connection over port 119 may be changed to use TLS via the [...] command.|$|E
5000|$|One of {{the main}} {{features}} of AMGA, and one unique to it, is the possibility to replicate metadata between different AMGA instances allowing the federation of metadata [...] (e.g. By the Health-e-child project), but also to increase the scalability and improve the access times on a globally deployed Grid (as done by the Wisdom project). Performance and efficiency of the access across WANs has been independently targeted by an access protocol optimised for the <b>bulk</b> <b>transfer</b> of metadata across WANs using data streaming.|$|E
50|$|Many modern {{digital cameras}} from Canon and Nikon can be {{controlled}} via PTP from a USB host enabled computing device (Smartphone, PC or Arduino for example). As is the norm for PTP, the communication takes place over a USB connection. When interacting with the camera in this manner, {{it is expected that}} the USB endpoints are in (synchronous) <b>Bulk</b> <b>Transfer</b> Mode, for getting/setting virtually all the camera's features/properties (such as ISO, Aperture, Shutter speed and focus). Events raised by the camera, in response to specific actions performed by the host device, are sent back to the host via the USB asynchronous Interrupt endpoint.|$|E
5000|$|<b>Bulk</b> milk <b>transfer</b> from Waingawa to Hawera via the Manawatu Gorge ...|$|R
40|$|Abstract We {{characterize}} a TCP implementation by a function, {{called a}} profile, that expresses the instantaneous throughput {{at the source}} {{in terms of the}} instantaneous roundtrip time and instantaneous loss rate for <b>bulk</b> <b>transfers.</b> We empirically obtain profiles of several TCP implementations, accurately enough to distinguish not only the TCP version but also the implementation (BSD, Windows, etc) ...|$|R
50|$|All {{mainline}} rail {{operated by}} PBVR has 286,000 pound gross-weight-on-rail capability. PBVR can store up to 429 rail cars {{at any one}} time. Multi-modal warehouse and trans-load facilities are available. The multi-modal facility {{is located in the}} Gulf Coast Foreign Trade Zone (FTZ) #92 within the industrial park. A trans-loading site is available for other prime sites for <b>bulk</b> <b>transfers</b> and storage of product.|$|R
50|$|Traffic {{classification}} {{describes the}} methods of classifying traffic by observing features passively in the traffic, and in line to particular classification goals. There might be some that only have a vulgar classification goal. For example, whether it is <b>bulk</b> <b>transfer,</b> peer to peer file sharing or transaction-orientated. Some others will set a finer-grained classification goal, for instance {{the exact number of}} application represented by the traffic. Traffic features included port number, application payload, temporal, packet size and the characteristic of the traffic. There are a vast range of methods to allocate Internet traffic including exact traffic, for instance port (computer networking) number, payload, heuristic or statistical machine learning.|$|E
5000|$|Offshore Petroleum Distribution System (OPDS) {{provides}} a semipermanent, all-weather facility for <b>bulk</b> <b>transfer</b> of refined bulk petroleum (e.g., JP5 and JP8) directly from an offshore tanker to a beach termination unit (BTU) located immediately inland from the high-water mark. POL then is either transported inland or {{stored in the}} beach support area. Major OPDS components are: the OPDS tanker with booster pumps and spread mooring winches, a recoverable single-anchor leg mooring (SALM) to accommodate four tankers up to 70,000 DWT, ship to SALM hose lines, up to four miles of six-inch (internal diameter) conduit for pumping to the beach, and two BTUs to interface with the shoreside systems.|$|E
50|$|However, Royal Mail did {{restore the}} {{movement}} of some already-sorted letters by rail {{in time for the}} Christmas season that year, contracting with EWS's competitor GB Railfreight to resume <b>bulk</b> <b>transfer</b> services along the West Coast Main Line between its mail terminals at London (Willesden), Warrington and Glasgow (Sheildmuir) using the dedicated Class 325 electric multiple units that had been in operation since 1996. In 2009 the contract for these mail trains was transferred to EWS's successor DB Schenker Rail. For flexibility Royal Mail had preserved rail access to its distribution centres on Tyneside (Low Fell) and at Tonbridge in Kent, and did occasionally send mail trains to Low Fell, for example when Newcastle Airport was closed by snow. In June 2013, a regular service resumed from Low Fell.|$|E
40|$|Tor is {{vulnerable}} to network congestion and performance problems due to <b>bulk</b> data <b>transfers.</b> A large fraction of the available network capacity is consumed by {{a small percentage of}} Tor users, resulting in severe service degradation for the majority. Bulk users continuously drain relays of excess bandwidth, creating new network bottlenecks and exacerbating the effects of existing ones. While this problem may currently be attributed to rational users utilizing the network, it may also be exploited by a relatively low-resource adversary using similar techniques to contribute to a network denial of service (DoS) attack. Degraded service discourages the use of Tor, affecting both Tor’s client diversity and anonymity. Equipped with mechanisms from communication networks, we design and implement three Tor-specific algorithms that throttle <b>bulk</b> <b>transfers</b> to reduce network congestion and increase network responsiveness. Unlike existing techniques, our algorithms adapt to network dynamics using only information local to a relay. We experiment with full-network deployments of our algorithms under a range of light to heavy network loads. We find that throttling results in significant improvements to web client performance while mitigating the negative effects of <b>bulk</b> <b>transfers.</b> We also analyze how throttling affects anonymity and compare the security of our algorithms under adversarial attack. We find that throttling reduces information leakage compared to unthrottled Tor while improving anonymity against realistic adversaries. ...|$|R
5000|$|<b>Bulk</b> file <b>transfer</b> {{or e-mail}} must be {{reliable}} and have high capacity, but doesn't {{need to be}} instantaneous ...|$|R
40|$|During a <b>bulk</b> data <b>transfer</b> over a {{high speed}} network, {{there is a}} high {{probability}} that the next packet received from the network by the destination host is the next packet in the transfer. An optimistic implementation of a <b>bulk</b> data <b>transfer</b> protocol takes advantage of this observation by instructing the network interface on the destination host to deposit the data of the next packet immediately into its anticipated final location. No copying of the data is required in the common case, and overhead is greatly reduced. Our optimistic implementation of the V kernel <b>bulk</b> data <b>transfer</b> protocols on SUN- 3 / 50 workstations connected by a 10 megabit Ethernet achieves peak process-to-process data rates of 8. 3 megabits per second for 1 -megabyte transfers, and 6. 8 megabits per second for 8 -kilobyte transfers, compared to 6. 1 and 5. 0 megabits per second for the pessimistic implementation. When the reception of a <b>bulk</b> data <b>transfer</b> is interrupted by the arrival of unexpected packets at the destina [...] ...|$|R
50|$|A bulk sale, {{sometimes}} called a <b>bulk</b> <b>transfer,</b> {{is when a}} business sells all or nearly all of its inventory to a single buyer and such a sale {{is not part of}} the ordinary course of business. This type of action is often used in an attempt to dodge creditors who intend to seize such business's inventory; in order to protect the purchaser from claims made by creditors of the seller, the seller must usually complete an affidavit outlining its secured and unsecured creditors, which must usually be filed with a government department, such as a court office. Such procedures are outlined in the bulk sales act of most jurisdictions. If the buyer does not complete the registration process for a bulk sale, creditors of the seller may obtain a declaration that the sale was invalid against the creditors and the creditors may take possession of the goods or obtain judgment for any proceeds the buyer received from a subsequent sale.|$|E
5000|$|By 1950, Heyl & Patterson {{installations}} {{could be}} found in almost every industrial section of the United States and Canada, as well as South America, Europe, Asia and Australia. Though still concentrating in the field of heavy bulk material handling equipment, Heyl & Patterson initiated a diversification policy and added other products to complement its main activities. These products included several that were developed in the company's own research and development department and still others that were handled in the United States for one of Europe's leading engineering firms. As part of its diversification, Heyl & Patterson divided into two business units. The <b>Bulk</b> <b>Transfer</b> Division was formed to design, fabricate, erect, and service the machines that Heyl & Patterson had developed for the bulk material handling industry, as well as more recent product lines such as stackers, reclaimers, belt conveyors, refuse disposal cars and giant loaders for seafaring ships. [...] The Process Division was formed to innovate fluid bed dryer technology to clean and classify coal at coal preparation plants.|$|E
40|$|This thesis {{presents}} {{a set of}} feasible extensions for the low power, low delay ORW routing protocol. It introduces the capability of handling multiple concurrent bulk transfers including various application scenarios, e. g., cross traffic. The extensions added to the ORW protocol include a collision avoidance method applied beside thealready existing, well functioning collision detection technique. This collision avoidance method reduced the overuse of the ORW protocol’s collision detection method from a per packet basis to a per <b>bulk</b> <b>transfer</b> basis. This reduction {{in the frequency of}} collisions allowed a significant improvement in all the metrics in general, but especially in the transmission time and power consumption. Using the collision avoidance extension a <b>bulk</b> <b>transfer</b> was performed in a fraction of the time that would needed for a <b>bulk</b> <b>transfer</b> using the ORW base protocol, while the power consumed during this fraction of time was less accordingly. The second extension’s purpose was to stabilize the EDC routing metric used by the ORW protocol to estimate the duty-cycles needed for a packet to reach the sink from the given node. This extension was relevant in certain scenarios with high intra-path interference stemming from the high number of hops in the paths between the source and the sink nodes. The third, and last, extension forbade the duty-cycling during a <b>bulk</b> <b>transfer</b> for the nodes that were involved in the given <b>bulk</b> <b>transfer.</b> This extension aimed to mitigate the performance degradation that occurred at the case when a given node terminated its duty-cycle notwithstanding that an other node was sending packets to this given node. By applying these extensions it was possible to reach an almost 500 % increase in the throughput with less than 25 % of the power consumption during a <b>bulk</b> <b>transfer</b> on the Indriya testbed...|$|E
40|$|Users {{of cloud}} {{computing}} services {{are faced with}} the problem of planning and transferring large amounts of data across a geographically dispersed network under time and budget constraints. Pandora is the first service to solve the planning problem but underneath it has a set of issues, which are addressed in this work. This thesis enhances Pandora by improving its interface, scalability, modularity, and extensibility. This is done by evaluating the performance of various GPU linear program solvers on Pandora???s workloads, and by designing and implementing two new systems: a modular C++ framework called Pandora???s Toolbox that solves the <b>bulk</b> data <b>transfer</b> problem, and a web service for planning <b>bulk</b> data <b>transfers.</b> Pandora???s Toolbox models the steps of the <b>bulk</b> data <b>transfer</b> problem and has an extensible design that allows various linear program solvers (e. g., GLPK and GPU solvers) to integrate into it. The web service effectively allows users to construct a shipping network and plan <b>bulk</b> data <b>transfers</b> over it through both a web and a RESTful interface...|$|R
40|$|Experimental data validating {{some of the}} {{proposed}} parallel computation models on the Intel Paragon is presented. This architecture {{is characterized by a}} large bandwidth and a relatively large startup cost of a message transmission, which makes it extremely important to employ <b>bulk</b> <b>transfers.</b> The models considered are the BSP model, in which it is assumed that all messages have a fixed short size, and the BPRAM, in which block transfers are rewarded. 1...|$|R
40|$|Abstract—The current Internet {{features}} {{traffic from}} diverse applications; ranging from delay-sensitive web browsing to delay-insensitive data file transfers. This motivates service differentiation, yet router-centric solutions, e. g. diffserv, {{have not been}} widely deployed. The current practice relies on a limited service differentiation at network edges (e. g. through traffic managing middle-boxes or by the end-hosts). End-hosts often implement such emulators of low priority service to differentiate low and normal priority traffic. A low priority service may fit well for some applications, e. g., software updates, but may not be adequate for <b>bulk</b> file <b>transfers</b> that aim at large throughputs. A scenario motivating home users is that of many simultaneous <b>bulk</b> <b>transfers.</b> This is a common feature of peer-to-peer file sharing applications. We develop a novel end-to-end congestion control tha...|$|R
40|$|Numerous {{experiments}} with a scaled pilot facility {{were carried out}} to compare the relative <b>bulk</b> <b>transfer</b> performance of three special devices for applications to drilling systems. The pipe diameter for bulk transportation was 3 in., which corresponds to around half of the actual system dimensions. Two different pressures, 3 and 4 bar, were considered to check the relative performance under different pressure conditions at a bulk storage tank. And to make a practical estimation method of the <b>bulk</b> <b>transfer</b> rate at the early design stages of the bulk handling system, a series of experiments were conducted for real scaled bulk handing systems of two drilling vessels. The pressure drops at each pipe element {{as well as the}} <b>bulk</b> <b>transfer</b> rates were measured under different operating conditions. Using the measured results, the friction factor for each pipe element was calculated and a procedure for transfer rate estimation was developed. Compared to the measured transfer rate results for other drilling vessels, the estimated transfer rates were within a maximum 15 % error bound...|$|E
40|$|Abstract — Sampled NetFlow {{data from}} a core Internet 2 router are {{analyzed}} to characterize the current use and performance of Internet 2, with particular emphasis on bulk TCP transfers. The distribution of throughput, transfer size, duration, and average packet size for 48, 301 observed bulk TCPs is presented. The top 10 % of <b>bulk</b> <b>transfer</b> TCPs achieved throughputs of 3. 9 Mbps or greater, while the top 1 % of <b>bulk</b> <b>transfer</b> TCPs achieved throughputs of 23 Mbps or greater. The median <b>bulk</b> <b>transfer</b> TCP throughput observed was 880 Kbps. Summaries of application and IP protocol mixes are presented. Popular applications included: NNTP (19. 3 % packets, 22. 8 % octets), active FTP (11. 9 % packets, 14. 2 % octets), HTTP (10. 5 % packets, 9. 5 % octets), and multicast (6. 6 % packets, 6. 2 % octets). Most used IP protocols were TCP (85. 6 % packets, 88. 7 % octets), UDP (12. 5 % packets, 10. 0 % octets), and ICMP (1. 4 % packets, 0. 8 % octets). Keywords — Internet 2, Abilene, OC- 48 c, backbone, TCP, throughput, NetFlow...|$|E
40|$|Abstract—The {{steady-state}} {{performance of}} a <b>bulk</b> <b>transfer</b> TCP flow (i. e., a flow with {{a large amount of}} data to send, such as FTP transfers) may be characterized by the send rate, which is the amount of data sent by the sender in unit time. In this paper we develop a simple analytic characterization of the steady-state send rate as a function of loss rate and round trip time (RTT) for a <b>bulk</b> <b>transfer</b> TCP flow. Unlike the models in [7]–[9], and [12], our model captures not only the behavior of the fast retransmit mechanism but also the effect of the time-out mechanism. Our measurements suggest that this latter behavior is important from a modeling perspective, as almost all of our TCP traces contained more time-out events than fast retransmit events. Our measurements demonstrate that our model is able to more accurately predict TCP send rate and is accurate over a wider range of loss rates. We also present a simple extension of our model to compute the throughput of a <b>bulk</b> <b>transfer</b> TCP flow, which is defined as the amount of data received by the receiver in unit time. Index Terms—Empirical validation, modeling, retransmission timeouts, TCP...|$|E
30|$|In their evaluation, k-NN outperforms LDA {{with the}} lowest error rate of 5.1 and 9.4 % for four and seven class classification, respectively. They notice that often {{streaming}} applications behave very similar to <b>bulk</b> data <b>transfer</b> applications. Therefore, either a prioritization rule is necessary to break the tie, or extended/derivative features must be employed to act as good disciminators. In their extended evaluation, the authors employ inter-arrival variability to distinguish between streaming and <b>bulk</b> data <b>transfer</b> applications.|$|R
50|$|The USB module {{is fully}} {{compliant}} with the USB 2.0 specification and supports control, interrupt and <b>bulk</b> <b>transfers</b> at a data rate of 12 Mbps (full speed). The module supports USB suspend, resume and remote wake-up operations {{and can be}} configured for up to eight input and eight output endpoints. The module includes an integrated physical interface (PHY); a phase-locked loop (PLL) for USB clock generation; and a flexible power-supply system enabling bus-powered and self-powered devices.|$|R
40|$|Abstract: Reliability is very {{important}} in digital radio point to point transmission system, especially for <b>bulk</b> data <b>transfer</b> in narrow band channel. Aiming at currently most applications are based on raw UDP service which does not guarantee the reliability, the article presents R 2 UDP(Reduced Reliable UDP) over the air transfer suitable to radio system, smart probe improves the transfer efficiency and saves the bandwidth, and also minimizes the impact of <b>bulk</b> data <b>transfer</b> to other traffic on the shared channel...|$|R
