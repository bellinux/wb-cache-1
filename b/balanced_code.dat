17|180|Public
5000|$|US Patent 7,460,035 (2008) <b>Balanced</b> <b>code</b> with opportunistically reduced {{transitions}} ...|$|E
50|$|In coding theory, a constant-weight code, {{also called}} an m of n code, is an error {{detection}} and correction code where all codewords {{share the same}} Hamming weight.The one-hot code and the <b>balanced</b> <b>code</b> are two widely used kinds of constant-weight code.|$|E
50|$|In coding theory, a <b>balanced</b> <b>code</b> is {{a binary}} forward error {{correction}} code for which each codeword contains {{an equal number of}} zero and one bits. Balanced codes have been introduced by Donald Knuth; they are a subset of so-called unordered codes, which are codes having the property that the positions of ones in a codeword are never a subset of the positions of the ones in another codeword. Like all unordered codes, balanced codes are suitable for the detection of all unidirectional errors in an encoded message. Balanced codes allow for particularly efficient decoding, which can be carried out in parallel.|$|E
30|$|We {{have just}} seen that the amplitudes of <b>balanced</b> <b>codes</b> can have {{continuous}} values. Thus, using the proposed codes instead of classical binary codes such as Walsh codes results in slight increase of complexity of the system, mainly at the receiver side where sequence matched filtering will involve multiplications instead of sign shifts of sampled received signals. Although chip amplitude of <b>balanced</b> <b>codes</b> can have continuous values, in practical systems they should be rounded to remain in some discrete alphabet and thus facilitate digital processing. We have checked that 8 bits encoding of the chips of <b>balanced</b> <b>codes</b> is enough to avoid BER performance degradation for codes of length 32 and codes of length 256. In other words, rounded <b>balanced</b> <b>codes</b> yield no noticeable difference in the BER curves of <b>balanced</b> <b>codes,</b> as it will be shown in section 4.3.|$|R
40|$|Graduation date: 1990 <b>Balanced</b> <b>codes,</b> {{in which}} each {{codeword}} contains equally many 1 's and 0 's, are useful in such applications as in optical transmission and optical recording. When <b>balanced</b> <b>codes</b> are used, {{the same number of}} 1 's and 0 's pass through the channel after the transmission of every word, so the channel is in a dc-null state. Optical channels require this property because they employ AC-coupled devices. Line codes, in which codewords may not be balanced, are also used as dc-free codes in such channels. In this thesis we present the research that leads to the following results: 1 - <b>Balanced</b> <b>codes</b> These have higher information rate than existing codes yet maintain similar encoding and decoding complexities. 2 - Error-correcting <b>balanced</b> <b>codes</b> In many cases, these give higher information rates and more efficient encoding and decoding algorithms than the best-known equivalent codes. 3 - DC-Free coset codes A new technique to design dc-free coset codes was developed. These codes have better properties than existing ones. 4 - Generalization of <b>balanced</b> <b>codes</b> [...] <b>Balanced</b> <b>codes</b> are generalized in three ways among which the first is the most significant: a) <b>Balanced</b> <b>codes</b> with low dc level These codes are designed based on the combined techniques used in (1) and (3) above. A lower dc-level and higher transitions density is achieved at the cost of one extra check bit. These codes are much more attractive, to optical transmission, than the bare-bone <b>balanced</b> <b>codes.</b> b) Non-Binary <b>Balanced</b> <b>Codes</b> <b>Balanced</b> <b>codes</b> over a non-binary alphabet. c) Semi-Balanced Codes [...] Codes in which the number of 1 's and 0 's in every code word differs by at most a certain value. 5 - t-EC/AUED coset codes These are t error correcting/all unidirectional error detecting codes. Again the technique in (3) above is used to design t-EC/AUED coset codes. These codes obtain higher information rate than the best-known equivalent codes and yet maintain the same encoding/decoding complexity...|$|R
40|$|Abstract—In 1986, Don Knuth {{published}} {{a very simple}} algorithm for constructing sets of bipolar codewords with equal numbers of “ 1 ”s and “ 01 ”s, called <b>balanced</b> <b>codes.</b> Knuth’s algorithm is well suited for use with large codewords. The redundancy of Knuth’s <b>balanced</b> <b>codes</b> is a factor of two larger {{than that of a}} code comprising the full set of balanced codewords. In this paper, we will present results of our attempts to improve the performance of Knuth’s <b>balanced</b> <b>codes.</b> Index Terms—Balanced code, channel capacity, constrained code, magnetic recording, optical recording. I...|$|R
40|$|Let Phi(m) {{subset of}} C be {{the set of}} all mth roots of unity, m {{is an element of}} IN. A <b>balanced</b> <b>code</b> over Phi(m) is a block code over the {{alphabet}} Phi(m) such that each code word is balanced; that is, the complex sum of its components (or weight) is equal to 0. Let B-m (n) be the set of all balanced words of length n over Phi(m). In this correspondence, it is shown that when m is a prime number, the set B-m (n) is not empty if, and only if, m divides n. In this case, the minimum redundancy for a <b>balanced</b> <b>code</b> over Phi(m) of length n is rho(B-m(n)) = n [log(m) vertical bar B-m(n) vertical bar] approximate to[(m- 1) / 2]log(m) (2 pi n) - m/ 2. On the other hand, it is shown that when m = 4, the set B- 4 (n) is not empty if, and only if, n is even, and in this case, the minimum redundancy for a <b>balanced</b> <b>code</b> over Phi(4) of length n is rho(B- 4 (n)) = n - [log(4) vertical bar B- 4 (n) vertical bar] approximate to log(4) n + 0. 326. Further, this correspondence completely solves the problem of designing efficient coding methods for balanced codes over Phi(m), when m = 4. In fact, it reduces the problem of designing efficient coding schemes for balanced codes over Phi(4) to the design of efficient balanced codes over the usual bipolar alphabet Phi(2) = {- 1,+ 1 }. [ [...] . ...|$|E
40|$|The {{prototype}} of a {{wireless sensor network}} node of the EYES project uses a cheap radio transceiver from RFM. This transceiver [...] like many others [...] has problems to receive data if it contains long runs of either ones or zeros, especially when On Off Keying (OOK) is used. In order to prevent such long runs, the data should be transmitted using a <b>balanced</b> <b>code.</b> Two such codes are considered in this report: the Manchester code and the 4 b 6 b code...|$|E
3000|$|The HNN decoder {{developed}} here {{uses the}} set of predetermined codewords to determined the connection weights describing the level of connection between the neurons. It has previously been shown how a HNN {{can be used to}} decoded one <b>balanced</b> <b>code</b> at a time, but the HNN MLSE decoder we derive here is able to simultaneously decode any number of concatenated codewords in order to provide the ML transmitted sequence of codewords. After the HNN MLSE decoding, the ML BPSK or 4 -QAM codewords of length 2 [...]...|$|E
30|$|In this article, a novel turbo {{equalizer}} {{is developed}} {{by combining the}} HNN MLSE equalizer developed in [16] and a HNN MLSE decoder (used to decode <b>balanced</b> <b>codes,</b> and only <b>balanced</b> <b>codes),</b> resulting in the Hopfield neural network turbo equalizer (HNN-TE), {{which can be used}} as replacement for a conventional turbo equalizer (CTE), made up of a equalizer/decoder pair, in systems with extremely long memory, where the coded symbols are interleaved before transmission through the multipath channel. The HNN-TE is able to equalize and decode (<b>balanced</b> <b>codes)</b> in systems with extremely long memory, since the computational complexity is nearly independent of the channel memory length. Like the HNN MLSE equalizer, its superior complexity characteristics are due to the high parallelism of its underlying neural network structure.|$|R
30|$|The HNN {{has been}} shown to be able to decode <b>{{balanced}}</b> <b>codes</b> [17, 18]. A binary word of length m is said to be balanced if it contains exactly m[*]/[*] 2 ones and m[*]/[*] 2 zeros [19]. In addition, <b>balanced</b> <b>codes</b> have the property that no codeword is contained in another word, which simply means that positions of ones in one codeword will never be a subset of the positions of ones in another codeword [19].|$|R
50|$|If {{a vehicle}} was {{initially}} allocated a twelve digit number {{according to the}} old UIC regulations, and using the second digit as a balancing number (which, however, was only {{to be found in}} directories), then a TSI compliant number was assigned to the vehicle from 2008. The TSI compliant numbers use the fifth digit as a <b>balancing</b> <b>code.</b> The <b>balancing</b> <b>code</b> is so calculated that the twelve digit and seven digit vehicle number have the same control number.|$|R
40|$|Overlapping {{memory accesses}} with {{computations}} {{is a standard}} technique for improving performance on modern architectures, which have deep memory hierarchies. In this paper, we present a compiler technique for overlapping accesses to secondary memory (disks) with computation. We have developed an Interprocedural <b>Balanced</b> <b>Code</b> Placement (IBCP) framework, which performs analysis on arbitrary recursive procedures and arbitrary control flow and replaces synchronous I/O operations with a balanced pair of asynchronous operations. We demonstrate how this analysis is useful for applications which perform frequent and large accesses to secondary memory, including applications which snapshot or checkpoint their computations or out-of-core applications. (Also cross-referenced as UMIACS-TR- 95 - 114...|$|E
40|$|A {{binary code}} of length n {{is called a}} <b>balanced</b> <b>code</b> if each {{codeword}} contains exactly ⌊n/ 2 ⌋ (or ⌈n/ 2 ⌉) ones and ⌈n/ 2 ⌉ (or ⌊n/ 2 ⌋) zeros. In this paper, we give two improved methods for encoding and decoding the balanced codes. The first one, called improved single map, improves the computation complexity of the complementation methods, first proposed by Knuth. This method, instead of complementing one bit at a time as done in Knuth's method, complements several appropriate bits at a time. Some simulation results show the improvement of this scheme over the previously known methods. The second one is a parallel implementation of this method...|$|E
40|$|We {{report on}} a family of variable-length codes with less {{redundancy}} than the flat code used {{in most of the}} variable size dictionary-based compression methods. The length of codes belonging to this family is still bounded above by [log_ 2 / |D|] where |D| denotes the dictionary size. We describe three of these codes, namely, the <b>balanced</b> <b>code,</b> the phase-in-binary code (PB), and the depth-span code (DS). As the name implies, the <b>balanced</b> <b>code</b> is constructed by a height balanced tree, so it has the shortest average codeword length. The corresponding coding tree for the PB code has an interesting property that it is made of full binary phases, and thus the code can be computed efficiently using simple binary shifting operations. The DS coding tree is maintained {{in such a way that}} the coder always finds the longest extendable codeword and extends it until it reaches the maximum length. It is optimal with respect to the code-length contrast. The PB and balanced codes have almost similar improvements, around 3 % to 7 % which is very close to the relative redundancy in flat code. The DS code is particularly good in dealing with files with a large amount of redundancy, such as a running sequence of one symbol. We also did some empirical study on the codeword distribution in the LZW dictionary and proposed a scheme called dynamic block shifting (DBS) to further improve the codes' performance. Experiments suggest that the DBS is helpful in compressing random sequences. From an application point of view, PB code with DBS is recommended for general practical usage...|$|E
30|$|Finally, above results {{advocate}} {{in favor}} of multilevel <b>balanced</b> <b>codes</b> that can achieve higher correlation performance, {{at the expense of}} relaxation of the constant amplitude property.|$|R
40|$|International audienceIn {{this paper}} we {{introduce}} {{a new class of}} space-time trellis codes (STTC). We call them Balanced STTC (B-STTC) because the points of the constellation are used with the same probability. Comparing to known <b>codes,</b> the <b>balanced</b> <b>codes</b> offer the best performance. Therefore, the systematic search for good codes can be reduced to this class. We present here the design of the 4 -PSK balanced STTC with 2 transmit antennas. A complete list of the best 4 -state and several 16 -state good <b>balanced</b> <b>codes</b> are also given...|$|R
40|$|Abstract—We {{examine and}} compare several {{different}} classes of “balanced ” block codes over q-ary alphabets, namely symbolbalanced (SB) codes, charge-balanced (CB) codes, and polaritybalanced (PB) codes. Known {{results on the}} maximum size and asymptotic minimal redundancy of SB and CB codes are reviewed. We then determine the maximum size and asymptotic minimal redundancy of PB codes and of codes which are both CB and PB. We also propose efficient Knuth-like encoders and decoders for all these types of <b>balanced</b> <b>codes.</b> Index Terms—coding theory, <b>balanced</b> <b>codes,</b> modulation codes, asymptotic redundancy P...|$|R
40|$|In this paper, {{we report}} {{work on a}} family of variable-length codes with less {{redundancy}} than the flat code used {{in most of the}} variable size dictionarybased compression methods. The length of codes belonging to this family is still bounded above by ⌈log 2 |D| ⌉ where |D | denotes the dictionary size. We describe three of these codes, namely, the <b>balanced</b> <b>code</b> [2], the Phase-in-Binary code (PB) [1] and the Depth-Span code (DS). As the name implies, the <b>balanced</b> <b>code</b> is constructed by a height balanced tree, so it has the shortest average codeword length. The corresponding coding tree for the PB code has an interesting property that it is made of full binary phases, and thus the code can be computed efficiently using simple binary shifting operations. The DS coding tree is maintained {{in such a way that}} the coder always finds the longest extendable codeword and extends it until it reaches the maximum length. It is optimal with respect to the code-length contrast. The PB and balanced codes have almost similar improvements, around 3 % to 7 % which is very close to the relative redundancy in flat code. The DS code is particularly good in dealing with files with a large amount of redundancy, such as a running sequence of one symbol. We also did some empirical study on the codeword distribution in the LZW dictionary and proposed a scheme called Dynamic Block Shifting (DBS) to further improve the codes ’ performance. Experiments suggest that the DBS is helpful in compressing random sequences. From an application point of view, PB code with DBS is recommended for general practical usage...|$|E
40|$|Abstract—The {{prior art}} {{construction}} of sets of balanced codewords by Knuth is attractive for its simplicity and absence of look-up tables, but the redundancy of the balanced codes generated by Knuth’s algorithm falls {{a factor of}} two short {{with respect to the}} minimum required. We present a new construction, which is simple, does not use look-up tables, and is less redundant than Knuth’s construction. In the new construction, the user word is modified {{in the same way as}} in Knuth’s construction, that is by inverting a segment of user symbols. The prefix that indicates which segment has been inverted, however, is encoded in a different, more efficient, way. Index Terms—Magnetic recording, optical recording, channel capacity, constrained code, dc-free code, <b>balanced</b> <b>code.</b> I...|$|E
40|$|Oligo arrays are {{important}} experimental tools {{for the high}} throughput measurement of gene expression levels. During production of oligo arrays, {{it is important to}} identify any faulty manufacturing step. We describe a practical algorithm for the construction of optimal quality control designs that accomplish this identification. The algorithm uses hillclimbing, a search technique from combinatorial optimization. We also present the results of using this algorithm on all practical quality control design sizes. Keywords: oligo array, DNA array, quality control, QC matrix, <b>balanced</b> <b>code,</b> hillclimbing. 1 Introduction An oligo array is a small chip containing tens of thousands of spots, to each of which is attached its own synthesized, short, single-stranded DNA molecule. Oligo arrays {{are important}} experimental tools for the high throughput measurement of gene expression levels by a given cell type under given conditions. For more information on oligo arrays see, for example, Lipschu [...] ...|$|E
40|$|This paper {{presents}} a practical writing/reading scheme in nonvolatile memories, called balanced modulation, for minimizing the asymmetric component of errors. The main {{idea is to}} encode data using a <b>balanced</b> error-correcting <b>code.</b> When reading information from a block, it adjusts the reading threshold such that the resulting word is also balanced or approximately balanced. Balanced modulation has suboptimal performance for any cell-level distribution {{and it can be}} easily implemented in the current systems of nonvolatile memories. Furthermore, we studied the construction of <b>balanced</b> error-correcting <b>codes,</b> in particular, <b>balanced</b> LDPC <b>codes.</b> It has very efficient encoding and decoding algorithms, and it is more efficient than prior construction of <b>balanced</b> error-correcting <b>codes.</b> Comment: 2 columns, 15 page...|$|R
30|$|The HNN {{has also}} been shown by several authors to be able to decode <b>balanced</b> check <b>codes</b> [17, 18]. These codes, {{together}} with methods for encoding and decoding, were first proposed in [19], but it was later shown in [17, 18] that single codeword decoding can also be performed using the HNN. To date, <b>balanced</b> <b>codes</b> is the only class of codes that can be decoded with the HNN. The ability of the HNN to detect binary patterns allows it to determine the ML codeword from a predefined set of codewords. In this paper it is shown that the HNN ML decoder can be extended to allow for the ML estimation of a sequence of <b>balanced</b> check <b>codes.</b> It is therefore extendable to an MLSE decoder.|$|R
50|$|Another display {{interface}} based on FPD-Link is OpenLDI. (Sometimes the OpenLDI and FPD-Link terms are used interchangeably.) It enables longer cable lengths {{because of a}} built-in DC <b>balance</b> <b>coding</b> to reduce the effects of intersymbol interference. In the Open LDI version of DC <b>balance</b> <b>coding,</b> {{one of the seven}} serialized bits indicates whether the coding scheme needs to invert the other six bits transmitted in the clock period to maintain DC balance. Therefore, each LVDS pair other than the clock pair effectively transmits six bits per clock cycle. However, OpenLDI lost the video-transfer standards competition to Digital Visual Interface (DVI) in the early twenty-first century, and the result was stand-alone LCD panels using DVI to receive video from a desktop computer.|$|R
40|$|Recently, hashing video {{contents}} {{for fast}} retrieval has received increasing attention {{due to the}} enormous growth of online videos. As the extension of image hashing techniques, traditional video hashing methods mainly focus on seeking the appropriate video features but pay little attention to how the video-specific features can be leveraged to achieve optimal binarization. In this paper, an end-to-end hashing framework, namely Unsupervised Deep Video Hashing (UDVH), is proposed, where feature extraction, <b>balanced</b> <b>code</b> learning and hash function learning are integrated and optimized in a self-taught manner. Particularly, distinguished from previous work, our framework enjoys two novelties: 1) an unsupervised hashing method that integrates the feature clustering and feature binarization, enabling the neighborhood structure to be preserved in the binary space; 2) a smart rotation applied to the video-specific features that are widely spread in the low-dimensional space such that the variance of dimensions can be balanced, thus generating more effective hash codes. Extensive experiments have been performed on two real-world datasets and the results demonstrate its superiority, compared to the state-of-the-art video hashing methods. To bootstrap further developments, the source code will be made publically available...|$|E
40|$|AbstractAn m-ary <b>balanced</b> <b>code</b> with r {{check digits}} and k {{information}} digits is a code over the alphabet Zm = { 0, 1, …, m− 1 } of length n = k+r and cardinality mk such that each codeword is balanced; that is, the real {{sum of its}} components (or weight) is equal to [(m − 1) n/ 2]. This paper contains new efficient methods to design m-ary balanced codes which improve the constructions found in the literature, for all alphabet size m ⩾ 2. To design such codes, the information words which are close to be balanced are encoded using single maps obtained by a new generalization of Knuth's complementation method to the m-ary alphabet that we introduce in this paper. Whereas, the remaining information words are compressed via suitable m-ary uniquely decodable variable length codes and then balanced using the saved space. For any m⩾ 2, infinite families of m-ary balanced codes are given with r check digits and k⩽[1 /(1 − 2 α) ][mr − 1) /(m − 1) ] − c 1 (m, α) r −c 2 (m, α) information digits, where α ϵ [0, 1 / 2) can be chosen arbitrarily close to 1 / 2. The codes can be implemented with O(mk logm k) m-ary digit operations and O(m + k) memory elements to store m-ary digits...|$|E
40|$|In July of 1978 the Secretary of Commerce, Juanita Kreps, {{speaking}} for the Carter Administration, proposed a 2 ̆ 2 comprehensive program to attack the problem of escalating product liability premiums and costs. 2 ̆ 2 The administration felt compelled to become involved because: Serious product liability problems have affected thousands of small businesses that have had great difficulty in obtaining affordable product liability insurance. The problem has also affected consumers because insurance costs have been passed on to {{them in terms of}} higher prices. Consumer groups have also been concerned about restrictive new state laws that have attacked the problem by limiting the rights of persons to recover damages for injuries caused by defective products. Finally, insurers have expressed concern about court rulings imposing substantial damages in product liability cases. Despite the inconsistencies which abound in the government 2 ̆ 7 s statement of why it is troubled, {{there is no question that}} the administration 2 ̆ 7 s intervention reflected a serious concern, among many quite disparate groups, that the increase in size and frequency of product liability judgments somehow was undermining the capacity of American business to function as it should in a free enterprise system. Typically, the government 2 ̆ 7 s proposed approach involved tax changes as a short-range measure (a quite sensible ten year loss carry-back), and a 2 ̆ 2 balanced program that will relieve the product liability problem for American businesses while fully respecting the rights and interests of consumers 2 ̆ 2 as a longer run solution. The keystone of this last approach would be a uniform 2 ̆ 2 <b>balanced</b> <b>code</b> that will add needed stability to product liability law 2 ̆ 2 to control the 2 ̆ 2 uncertainties in the tort system. 2 ̆...|$|E
40|$|Abstract – Recently, it {{has been}} {{established}} that the best spacetime trellis codes (STTCs) belong to a specific class of codes. These codes are called “balanced STTCs ” because they use the points of the MIMO constellation with the same probability. Therefore, the search of the best codes {{can be reduced to}} this class. This paper presents a new and general method to design 2 n-PSK balanced STTCs for any number of transmit antennas. This method is simpler than the first method, which was described only for 4 -PSK modulation and can be generalized for any configuration of the space-time trellis encoder. Simulation results of new 4 -PSK and 8 -PSK <b>balanced</b> <b>codes</b> prove the importance of this class. Keywords—space-time trellis <b>codes,</b> <b>balanced</b> <b>codes,</b> MIMO systems, design method. 1...|$|R
30|$|Correlation and {{cross-correlation}} {{properties of}} codes dictate {{the performance of}} a multiuser communication system at high SNR [26]. For simple receivers based on single-user matched filter, correlation properties are important in particular for receiver synchronization, while in asynchronous systems, cross-correlations of codes limits performance. Thus, we are going to consider these properties and compare them between Walsh <b>codes</b> and <b>balanced</b> <b>codes.</b>|$|R
40|$|The first {{theoretical}} {{bases of}} the space-time trellis codes (STTCs) {{have been established}} by Tarokh (1998). Many STTCs have been published using several criteria proposed by Tarokh (1998) and Chen (2001) for slow and fast Rayleigh fading channels. More recently, {{a new class of}} <b>codes</b> called <b>balanced</b> <b>codes,</b> which contains all the best STTCs has been presented by Ngo (2007, 2008). These <b>balanced</b> <b>codes</b> have the same property: if the data are generated by a binary memoryless source with equally probable symbols, the used points of the MIMO constellation are generated with the same probability. Therefore, the systematic search for the best codes can be reduced to this class. Thus, the time to find the best codes is reduced. The new and general method is proposed to design balanced 2 ^n-PSK STTCs for several transmit antennas. This new method is simpler and faster than the previous one presented by Ngo 2007 in particular when the number of transmit antennas and n increase...|$|R
40|$|This paper {{presents}} {{an investigation of}} design code provisions for steel-concrete composite columns. The study covers the national building codes of United States, Canada and Brazil, and the transnational EUROCODE. The study is based on experimental results of 93 axially loaded concrete-filled tubular steel columns. This includes 36 unpublished, full scale experimental results by the authors and 57 results from the literature. The error of resistance models is determined by comparing experimental results for ultimate loads with code-predicted column resistances. Regression analysis is {{used to describe the}} variation of model error with column slenderness and to describe model uncertainty. The paper shows that Canadian and European codes are able to predict mean column resistance, since resistance models of these codes present detailed formulations for concrete confinement by a steel tube. ANSI/AISC and Brazilian codes have limited allowance for concrete confinement, and become very conservative for short columns. Reliability analysis is used to evaluate the safety level of code provisions. Reliability analysis includes model error and other random problem parameters like steel and concrete strengths, and dead and live loads. Design code provisions are evaluated in terms of sufficient and uniform reliability criteria. Results show that the four design codes studied provide uniform reliability, with the Canadian code being best in achieving this goal. This is a result of a well <b>balanced</b> <b>code,</b> both in terms of load combinations and resistance model. The European code is less successful in providing uniform reliability, a consequence of the partial factors used in load combinations. The paper also shows that reliability indexes of columns designed according to European code can be as low as 2. 2, which is quite below target reliability levels of EUROCODE. (C) 2009 Elsevier Ltd. All rights reserved. CNPq (National Council for Research and Development) FAPESP (Sao Paulo State Foundation for Research...|$|E
40|$|It {{is shown}} that <b>balanced</b> n-bit Gray <b>codes</b> can be {{constructed}} for all positive integers n. A <b>balanced</b> Gray <b>code</b> {{is one in which}} the bit changes are distributed as equally as possible among the bit positions. The strategy used is to prove the existence of a certain subsequence which will allow successful use of the construction proposed by Robinson and Cohn in 1981. Although Wagner and West proved in 1991 that <b>balanced</b> Gray <b>code</b> schemes exist when n is a power of 2, the question for general n has remained open since 1980 when it first attracted attention...|$|R
40|$|International audienceRecently, a {{new class}} of Space-Time Trellis Codes was {{proposed}} as having the best performance. These codes are 'balanced' because they use the points of the constellation with the same probability. In this correspondence, we propose a new and simpler method than exisiting method to design these class for QPSK modulation and several transmit antennas. New and better <b>balanced</b> <b>codes</b> for 3 and 4 transmit antennas are also proposed...|$|R
40|$|Abstract — Levenshtein {{proposed}} {{a class of}} single insertion/deletion correcting codes, based on the number-theoretic construction due to Varshamov and Tenengolt’s. We present several interesting results on the binary structure of these codes, and their relation to constrained codes with nulls in the power spectral density function. One surprising {{result is that the}} higher order spectral null codes of Immink and Beenker are sub-codes of <b>balanced</b> Levenshtein <b>codes.</b> Other spectral null subcodes with similar coding rates, may also be constructed. We furthermore present some coding schemes and spectral shaping markers which alleviate the fundamental restriction on Levenshtein’s codes that the boundaries of each codeword should be known before insertion/deletion correction can be effected. Index Terms—Insertion/deletion correction, spectral nulls, constrained <b>codes,</b> <b>balanced</b> <b>codes.</b> I...|$|R
40|$|International audienceA {{new class}} of 4 -PSK Space Time Trellis Codes (STTC) for 2 and 3 {{transmit}} antennas is proposed in this paper. We call these <b>codes</b> <b>Balanced</b> STTC because they use the points of the constellation with the same probability. Comparing to known codes, these codes offer the best performance. Therefore, the systematic search for good codes {{can be reduced to}} this class. It is shown that all the best published <b>codes</b> are <b>balanced.</b> The paper presents the design of these balanced STTC and gives a complete list of the best 4 -state codes. Several 16 -state <b>balanced</b> <b>codes</b> for 2 and 3 transmit antennas are also given...|$|R
40|$|Describes coding {{schemes for}} HDTV with {{flexible}} bit rates between 34 and 70 Mbit/s. DCT and subband schemes {{have been investigated}} and compared and finally a DCT scheme based on a modified ETSI-codec (CCIR-Rec. 723) has been selected for hardware implementation <b>balancing</b> <b>coding</b> performance, hardware complexity and time constraints. This codec {{is part of a}} satellite transmission system for HDTV contribution, which adapts its user bit rate automatically to the actual transmission conditions...|$|R
