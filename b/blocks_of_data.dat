341|10000|Public
5|$|If the {{controller}} were to background garbage collect {{all of the}} spare blocks before it was absolutely necessary, new data written from the host could be written without having to move any data in advance, letting the performance operate at its peak speed. The trade-off {{is that some of}} those <b>blocks</b> <b>of</b> <b>data</b> are actually not needed by the host and will eventually be deleted, but the OS did not tell {{the controller}} this information. The result is that the soon-to-be-deleted data is rewritten to another location in the flash memory, increasing the write amplification. In some of the SSDs from OCZ the background garbage collection clears up {{only a small number of}} blocks then stops, thereby limiting the amount of excessive writes. Another solution is to have an efficient garbage collection system which can perform the necessary moves in parallel with the host writes. This solution is more effective in high write environments where the SSD is rarely idle. The SandForce SSD controllers and the systems from Violin Memory have this capability.|$|E
25|$|This type of shellcode {{is similar}} to egg-hunt shellcode, but looks for {{multiple}} small <b>blocks</b> <b>of</b> <b>data</b> (eggs) and recombines them into one larger block (the omelette) that is subsequently executed. This is used when an attacker can only inject {{a number of small}} <b>blocks</b> <b>of</b> <b>data</b> into the process.|$|E
25|$|Assemblers {{can be used}} to {{generate}} <b>blocks</b> <b>of</b> <b>data,</b> with no high-level language overhead, from formatted and commented source code, to be used by other code.|$|E
50|$|Yet another {{solution}} to storing persistent data is to associate a name with each <b>block</b> <b>of</b> <b>data,</b> {{and use a}} distributed hash table to pseudo-randomly assign that name {{to one of the}} available servers, and then store that <b>block</b> <b>of</b> <b>data</b> in the assigned server.|$|R
5000|$|... block ciphers, which encrypt <b>block</b> <b>of</b> <b>data</b> <b>of</b> fixed size, and ...|$|R
50|$|When an {{application}} sends data over an ATM connection using AAL5, the host delivers a <b>block</b> <b>of</b> <b>data</b> to the AAL5 interface. AAL5 generates a trailer, divides the information into 48-octet pieces, and transfers each piece across the ATM network {{in a single}} cell. On {{the receiving end of}} the connection, AAL5 reassembles incoming cells into a packet, checks the CRC to ensure that all pieces arrived correctly, and passes the resulting <b>block</b> <b>of</b> <b>data</b> to the host software. The process <b>of</b> dividing a <b>block</b> <b>of</b> <b>data</b> into cells and regrouping them is known as ATM segmentation and reassembly (SAR).|$|R
25|$|A {{hard disk}} drive (HDD), hard disk, hard drive or fixed disk is a data storage device that uses {{magnetic}} storage to store and retrieve digital information using one or more rigid rapidly rotating disks (platters) coated with magnetic material. The platters are paired with magnetic heads, usually arranged on a moving actuator arm, which read and write data to the platter surfaces. Data is accessed in a random-access manner, meaning that individual <b>blocks</b> <b>of</b> <b>data</b> can be stored or retrieved in any order and not only sequentially. HDDs are a type of non-volatile storage, retaining stored data even when powered off.|$|E
2500|$|Like [...] other {{narrow band}} digital modes, PSK31 can often {{overcome}} interference and poor propagation conditions {{in situations where}} voice or other methods of communication fail. However, PSK31 was designed only for leisure use by amateurs, and due to its relatively slow speed and limited error control, is not suitable for transmitting large <b>blocks</b> <b>of</b> <b>data</b> or text, or critical data requiring high immunity from errors.|$|E
2500|$|In {{computer}} science, a B-tree is a self-balancing tree {{data structure}} that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time. The B-tree is a generalization of a {{binary search tree}} in that a node can have more than two children [...] Unlike self-balancing binary search trees, the B-tree is optimized for systems that read and write large <b>blocks</b> <b>of</b> <b>data.</b> B-trees are {{a good example of}} a data structure for external memory. [...] It is commonly used in databases and filesystems.|$|E
25|$|The code values {{shown are}} packed into bytes {{which are then}} packed into <b>blocks</b> <b>of</b> up to 255 bytes. A <b>block</b> <b>of</b> image <b>data</b> begins with a byte that {{declares}} the number of bytes to follow. The last <b>block</b> <b>of</b> <b>data</b> for an image {{is marked by a}} zero block-length byte.|$|R
50|$|A <b>block</b> <b>of</b> <b>data</b> <b>of</b> size 2^(n+1)-1 {{always has}} one {{sub-block}} of size 2^n aligned on 2^n bytes.|$|R
5000|$|... 1、Equally {{divides the}} {{original}} data blocks into [...] blocks, and each <b>block</b> <b>of</b> <b>data</b> has -bit data, recorded as ...|$|R
50|$|This type of shellcode {{is similar}} to egg-hunt shellcode, but looks for {{multiple}} small <b>blocks</b> <b>of</b> <b>data</b> (eggs) and recombines them into one larger block (the omelette) that is subsequently executed. This is used when an attacker can only inject {{a number of small}} <b>blocks</b> <b>of</b> <b>data</b> into the process.|$|E
50|$|ExOR is more {{efficient}} with large <b>blocks</b> <b>of</b> <b>data.</b> These give more chances for a batch to find alternative routes. However, the batchmaps get larger, too. So, <b>blocks</b> <b>of</b> <b>data</b> more than 100,000 bytes are broken into groups of data packets called batches. Smaller messages are just sent by the most reliable route.|$|E
50|$|QSAM is—as {{its name}} says—queued, in this {{specific}} context meaning buffered with deblocking of reads and blocking of writes. It allows programs {{to read and}} write logical records within physical <b>blocks</b> <b>of</b> <b>data,</b> as opposed to the less advanced basic sequential access method (BSAM) which allows programs to access physical <b>blocks</b> <b>of</b> <b>data,</b> but provides no support for accessing logical records within blocks.|$|E
50|$|Cylinder-head-sector (CHS) is {{an early}} method for giving {{addresses}} to each physical <b>block</b> <b>of</b> <b>data</b> on a hard disk drive.|$|R
50|$|It {{can mean}} {{to make a}} copy of a {{removable}} media (CD-ROM, DVD, etc.) directly, without first saving the source on an intermediate medium (a harddisk); for example, copying a CD-ROM from a CD-ROM drive to a CD-Writer drive. The copy process requires each <b>block</b> <b>of</b> <b>data</b> to be retrieved and immediately written to the destination, so that there is room in the working memory to retrieve the next <b>block</b> <b>of</b> <b>data.</b>|$|R
40|$|GSM ??????????, ??????????? ??? ????????? ?????????????The paper {{considers}} a <b>block</b> <b>of</b> <b>data</b> transmission and reception using GSM technologies, intended for mobile flaw detectors? ?????? ??????????????? ???? ??????-???????? ?????? ? ?????????????? GSM ??????????, ??????????????? ??? ????????? ????????????...|$|R
50|$|Often single {{transmission}} channels contain <b>blocks</b> <b>of</b> <b>data</b> at {{more than}} one of the rates.|$|E
5000|$|The {{graphics}} {{processing unit}} (GPU), as a specialized computer processor, addresses the demands of real-time high-resolution 3D graphics compute-intensive tasks. By 2012, GPUs had evolved into highly parallel multi-core systems allowing very efficient manipulation of large <b>blocks</b> <b>of</b> <b>data.</b> This design {{is more effective than}} general-purpose central processing unit (CPUs) for algorithms in situations where processing large <b>blocks</b> <b>of</b> <b>data</b> is done in parallel, such as: ...|$|E
5000|$|Tiling or {{blocking}} - reorganizes a loop {{to iterate}} over <b>blocks</b> <b>of</b> <b>data</b> sized {{to fit in}} the cache.|$|E
5000|$|This [...] "extra" [...] LRC word {{at the end}} <b>of</b> a <b>block</b> <b>of</b> <b>data</b> is {{very similar}} to {{checksum}} and CRC.|$|R
50|$|A packet is a <b>block</b> <b>of</b> <b>data</b> with length {{that can}} vary between {{successive}} packets, ranging from 7to 65,542 bytes, including the packet header.|$|R
50|$|Space-time block codes (STBCs) act on a <b>block</b> <b>of</b> <b>data</b> at once (similarly {{to block}} codes) and also provide {{diversity}} gain but doesn't provide coding gain.|$|R
50|$|Since {{the major}} {{internet}} protocol TCP sends {{a stream of}} data, ExOR uses local proxy data servers to accumulate <b>blocks</b> <b>of</b> <b>data.</b>|$|E
5000|$|... #Caption: Diagram of a RAID 3 setup of six-byte {{blocks and}} two parity bytes, shown are two <b>blocks</b> <b>of</b> <b>data</b> in {{different}} colors.|$|E
50|$|In {{order to}} encrypt or decrypt data, use the {{standard}} block cipher {{mode of operation}} on all but the last two <b>blocks</b> <b>of</b> <b>data.</b>|$|E
50|$|The trivial {{example of}} a large image of solid color {{demonstrates}} the variable-length LZW compression used in GIF files.The code values shown are packed into bytes which are then packed into <b>blocks</b> <b>of</b> up to 255 bytes. A <b>block</b> <b>of</b> image <b>data</b> begins with a byte that declares the number of bytes to follow. The last <b>block</b> <b>of</b> <b>data</b> for an image {{is marked by a}} zero block-length byte.|$|R
40|$|The {{invention}} {{relates to}} {{a method for}} encoding data in a sequence of bursts ( [...] ., Bi- 2, Bi- 1, Bi, Bi+ 1, [...] .), wherein each burst includes a <b>block</b> <b>of</b> <b>data</b> symbols and a <b>block</b> <b>of</b> redundancy symbols. The <b>block</b> <b>of</b> redundancy symbols (Ri) of the current burst (Bi) of the sequence is generated by the calculating the sum {{of a series of}} encoding values relating to a series of bursts (Bi- 2, Bi- 1), each encoding value from the series of encoding values being obtained by a respective encoding function applied to the <b>block</b> <b>of</b> <b>data</b> symbols <b>of</b> the burst corresponding to the series of bursts...|$|R
5000|$|The {{following}} 8008 assembler {{source code}} {{is for a}} subroutine named [...] that copies a <b>block</b> <b>of</b> <b>data</b> bytes <b>of</b> a given size from one location to another.|$|R
5000|$|Instead of {{providing}} a block-oriented interface that reads and writes fixed sized <b>blocks</b> <b>of</b> <b>data,</b> data is organized into flexible-sized data containers, called objects ...|$|E
5000|$|The {{authentication}} tag {{is constructed}} by feeding <b>blocks</b> <b>of</b> <b>data</b> into the GHASH function and encrypting the result. This GHASH function {{is defined by}} ...|$|E
5000|$|Writing {{many small}} <b>blocks</b> <b>of</b> <b>data</b> can even lead to {{negative}} compression rates, {{so it is}} essential for applications to use large write buffers.|$|E
30|$|We {{adopted an}} {{alternative}} naïve equation that measures {{the percentages of}} information loss after anonymization, denoted by Disruption (Ɗ). The disruption value is a benchmark that gives a general indication {{of the size of}} anonymization loss. As shown in Eqs.  8 and 9, each anonymized <b>block</b> <b>of</b> tuples is calculated individually, and finally, the Ɗ value {{is the result of the}} total summation <b>of</b> all anonymized <b>blocks</b> s. Each <b>block</b> <b>of</b> <b>data</b> is a data bag produced by grouping a set of tuples. Let us assume that an anonymized <b>block</b> <b>of</b> <b>data</b> contains some M records, in a total number of N dataset records.|$|R
40|$|Abstract: In this paper, we have {{considered}} {{a real life}} scenario where data is available in blocks over the period of time. We have developed a dynamic cluster based ensemble of classifiers for the problem. We have applied clustering algorithm on the <b>block</b> <b>of</b> <b>data</b> available {{at that time and}} have trained a neural network for each of the clusters. The performance of the network is tested against the next available <b>block</b> <b>of</b> <b>data</b> and based on that performance the parameters of the clustering algorithm is changed at runtime. In our approach increasing the number of clusters is considered as changing of the parameter settings. The misclassified instances <b>of</b> the test <b>data</b> are also joined with the training data to refine the knowledge of the classifiers. The proposed system is capable of identifying the decision boundary of different classes based on the current <b>block</b> <b>of</b> <b>data</b> more precisely. An extensive experiments has been performed to evaluate this dynamic system and to compute the optimal parameters of the proposed procedure. ...|$|R
30|$|This can be {{separated}} into two general situations. In the first situation, the channel is varying sufficiently slowly {{so that it}} can be assumed to be static over the <b>block</b> <b>of</b> <b>data</b> being analyzed.|$|R
