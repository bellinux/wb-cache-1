2198|266|Public
5|$|There are {{numerous}} variations of <b>binary</b> <b>search.</b> In particular, fractional cascading speeds up binary {{searches for the}} same value in multiple arrays, efficiently solving a series of search problems in computational geometry and numerous other fields. Exponential search extends <b>binary</b> <b>search</b> to unbounded lists. The <b>binary</b> <b>search</b> tree and B-tree data structures are based on <b>binary</b> <b>search.</b>|$|E
5|$|A <b>binary</b> <b>search</b> tree is {{a binary}} tree data {{structure}} that works {{based on the}} principle of <b>binary</b> <b>search.</b> The records of the tree are arranged in sorted order, and each record in the tree can be searched using an algorithm similar to <b>binary</b> <b>search,</b> taking on average logarithmic time. Insertion and deletion also require on average logarithmic time in <b>binary</b> <b>search</b> trees. This can faster than the linear time insertion and deletion of sorted arrays, and binary trees retain the ability to perform all the operations possible on a sorted array, including range and approximate queries.|$|E
5|$|In 1946, John Mauchly {{made the}} first mention of <b>binary</b> <b>search</b> {{as part of the}} Moore School Lectures, the first ever set of lectures {{regarding}} any computer-related topic. Every published <b>binary</b> <b>search</b> algorithm worked only for arrays whose length is one less than a power of two until 1960, when Derrick Henry Lehmer published a <b>binary</b> <b>search</b> algorithm that worked on all arrays. In 1962, Hermann Bottenbruch presented an ALGOL 60 implementation of <b>binary</b> <b>search</b> that placed the comparison for equality at the end, increasing the average number of iterations by one, but reducing to one the number of comparisons per iteration. The uniform <b>binary</b> <b>search</b> was presented to Donald Knuth in 1971 by A. K. Chandra of Stanford University and published in Knuth's The Art of Computer Programming. In 1986, Bernard Chazelle and Leonidas J. Guibas introduced fractional cascading as a method to solve numerous search problems in computational geometry.|$|E
5000|$|<b>Binary</b> <b>searching</b> {{the user}} entries (instead of {{sequential}} database access) ...|$|R
5|$|COBOL {{provides}} the SEARCH ALL verb for performing <b>binary</b> <b>searches</b> on COBOL ordered tables.|$|R
25|$|The Kepler results {{indicate}} circumbinary planetary systems are relatively common (as of October 2013 the spacecraft had found seven planets out of roughly 1000 eclipsing <b>binaries</b> <b>searched).</b>|$|R
5|$|In practice, {{interpolation}} {{search is}} slower than <b>binary</b> <b>search</b> for small arrays, as interpolation search requires extra computation. Although its time complexity grows {{more slowly than}} <b>binary</b> <b>search,</b> this only compensates for the extra computation for large arrays.|$|E
5|$|<b>Binary</b> <b>search</b> trees lend {{themselves}} to fast searching in external memory stored in hard disks, as <b>binary</b> <b>search</b> trees can effectively be structured in filesystems. The B-tree generalizes this method of tree organization; B-trees are frequently used to organize long-term storage such as databases and filesystems.|$|E
5|$|Noisy <b>binary</b> <b>search</b> {{algorithms}} {{solve the}} case where the algorithm cannot reliably compare elements of the array. For each pair of elements, {{there is a certain}} probability that the algorithm makes the wrong comparison. Noisy <b>binary</b> <b>search</b> can find the correct position of the target with a given probability that controls the reliability of the yielded position. The noisy <b>binary</b> <b>search</b> problem can be considered as a case of the Rényi-Ulam game, which Alfréd Rényi introduced in 1961.|$|E
500|$|Java {{offers a}} set of {{overloaded}} binarySearch (...) static methods in the classes [...] and [...] in the standard java.util package for performing <b>binary</b> <b>searches</b> on Java arrays and on Lists, respectively.|$|R
5000|$|You can use two <b>binary</b> <b>searches</b> to {{determine}} {{the left and right}} end of the match range for P, and the length of the match range corresponds with the number of occurrences for P.|$|R
5000|$|When {{none of the}} A or B subarrays {{contained}} [...] unique {{values to}} create the internal buffers, a normally suboptimal in-place merge operation is performed where it repeatedly <b>binary</b> <b>searches</b> and rotates A into B. However, the known lack of unique values within any of the subarrays places a hard limit {{on the number of}} <b>binary</b> <b>searches</b> and rotations that will be performed during this step, which is again [...] items rotated up to [...] times, or [...] The size of each block is also adjusted to be smaller in the case where it found [...] unique values but not 2, which further limits the number of unique values contained within any A or B block.|$|R
5|$|Although {{the idea}} is simple, {{implementing}} <b>binary</b> <b>search</b> correctly requires attention to some subtleties about its exit conditions and midpoint calculation.|$|E
5|$|<b>Binary</b> <b>search</b> {{works on}} sorted arrays. <b>Binary</b> <b>search</b> begins by {{comparing}} the middle element of the array with the target value. If the target value matches the middle element, {{its position in the}} array is returned. If the target value is less than or greater than the middle element, the search continues in the lower or upper half of the array, respectively, eliminating the other half from consideration.|$|E
5|$|In {{computer}} science, <b>binary</b> <b>search,</b> {{also known}} as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds {{the position of a}} target value within a sorted array. <b>Binary</b> <b>search</b> compares the target value to the middle element of the array; if they are unequal, the half in which the target cannot lie is eliminated and the search continues on the remaining half until it is successful. If the search ends with the remaining half being empty, the target is not in the array.|$|E
50|$|If one-sided search takes k {{iterations}} to find {{an interval}} that contains x, then it follows that d > 2k-2. <b>Binary</b> <b>searching</b> this range will also take another k iterations. Therefore, finger search for x from y takes O(k) = O(log d) time.|$|R
50|$|These data {{structures}} allow dynamic fractional cascading to {{be performed}} {{at a time of}} O(log n) per insertion or deletion, and a sequence of k <b>binary</b> <b>searches</b> following a path of length k in the catalog graph {{to be performed}} in time O(log n + k log log n).|$|R
5000|$|The {{algorithm}} outlined below {{solves the}} longest increasing subsequence problem efficiently with arrays and <b>binary</b> <b>searching.</b> It processes the sequence elements in order, maintaining the longest increasing subsequence found so far. Denote the sequence values as X0, X1, etc. Then, after processing Xi, the algorithm will have stored values in two arrays: ...|$|R
5|$|In {{terms of}} iterations, no search {{algorithm}} that works only by comparing elements can exhibit better average and worst case performance than <b>binary</b> <b>search.</b> This {{is because the}} comparison tree representing <b>binary</b> <b>search</b> has the fewest levels possible as each level is filled completely with nodes if there are enough. Otherwise, the search algorithm can eliminate few elements in an iteration, {{increasing the number of}} iterations required in the average and worst case. This is the case for other search algorithms based on comparisons, as while they may work faster on some target values, the average performance over all elements is affected. This problem is solved by <b>binary</b> <b>search,</b> as dividing the array in half ensures that the size of both subarrays are as similar as possible.|$|E
5|$|The Euclidean {{algorithm}} {{can be used}} {{to arrange}} the set of all positive rational numbers into an infinite <b>binary</b> <b>search</b> tree, called the Stern–Brocot tree.|$|E
5|$|The above {{procedure}} only performs exact matches, {{finding the}} position of a target value. However, due to the ordered nature of sorted arrays, it is trivial to extend <b>binary</b> <b>search</b> to perform approximate matches. For example, <b>binary</b> <b>search</b> can be used to compute, for a given value, its rank (the number of smaller elements), predecessor (next-smallest element), successor (next-largest element), and nearest neighbor. Range queries seeking the number of elements between two values can be performed with two rank queries.|$|E
50|$|BinTube.com {{also offers}} a free <b>binary</b> Usenet <b>search</b> engine and Usenet access.|$|R
50|$|Note that, at {{any point}} in the algorithm, the sequenceis {{increasing}}. For, if there is an increasing subsequence of length j ≥ 2 ending at XMj, then there is also a subsequence of length j-1 ending at a smaller value: namely the one ending at XPMj. Thus, we may do <b>binary</b> <b>searches</b> in this sequence in logarithmic time.|$|R
500|$|Fractional {{cascading}} is {{a technique}} that speeds up <b>binary</b> <b>searches</b> for the same element for both exact and approximate matching in [...] "catalogs" [...] (arrays of sorted elements) associated with vertices in graphs. Searching each catalog separately requires [...] time, where [...] {{is the number of}} catalogs. Fractional cascading reduces this to [...] by storing specific information in each catalog about other catalogs.|$|R
5|$|An {{infinite}} loop may occur if the exit {{conditions for the}} loop are not defined correctly. Once L exceeds R, the search has failed and must convey {{the failure of the}} search. In addition, the loop must be exited when the target element is found, {{or in the case of}} an implementation where this check is moved to the end, checks for whether the search was successful or failed at the end must be in place. Bentley found that, in his assignment of <b>binary</b> <b>search,</b> most of the programmers who implemented <b>binary</b> <b>search</b> incorrectly made an error defining the exit conditions.|$|E
5|$|For {{implementing}} associative arrays, hash tables, a {{data structure}} that maps keys to records using a hash function, are generally faster than <b>binary</b> <b>search</b> on a sorted array of records; most implementations require only amortized constant time on average. However, hashing is not useful for approximate matches, such as computing the next-smallest, next-largest, and nearest key, {{as the only}} information given on a failed search is that the target is not present in any record. <b>Binary</b> <b>search</b> is ideal for such matches, performing them in logarithmic time. In addition, all operations possible on a sorted array can be performed—such as finding the smallest and largest key and performing range searches.|$|E
5|$|Go's sort {{standard}} library package {{contains the}} functions Search, SearchInts, SearchFloat64s, and SearchStrings, which implement general <b>binary</b> <b>search,</b> {{as well as}} specific implementations for searching slices of integers, floating-point numbers, and strings, respectively.|$|E
40|$|In a {{previous}} study an ordered array o /N keys was considered {{and the problem of}} locating a batch ofM requested keys was investigated by assuming both batched sequential and batched <b>binary</b> <b>searching.</b> This paper introduces the idea of batched interpolation search, and two variations of the method are presented. Comparisons with the two previously defined methods are also made...|$|R
5000|$|Fractional {{cascading}} is {{a technique}} that speeds up <b>binary</b> <b>searches</b> for the same element for both exact and approximate matching in [...] "catalogs" [...] (arrays of sorted elements) associated with vertices in graphs. Searching each catalog separately requires [...] time, where [...] {{is the number of}} catalogs. Fractional cascading reduces this to [...] by storing specific information in each catalog about other catalogs.|$|R
5000|$|As {{a simple}} example of {{fractional}} cascading, {{consider the following}} problem. We are given as input a collection of k ordered lists Li of numbers, such that the total length Σ|Li| of all lists is n, and must process them {{so that we can}} perform <b>binary</b> <b>searches</b> for a query value q in each of the k lists. For instance, with k = 4 and n = 17, ...|$|R
5|$|Rank queries can be {{performed}} using {{a modified version of}} <b>binary</b> <b>search.</b> By returning m on a successful search, and L on an unsuccessful search, the number of elements less than the target value is returned instead.|$|E
5|$|There exist data {{structures}} that may improve on <b>binary</b> <b>search</b> {{in some cases}} for both searching and other operations available for sorted arrays. For example, searches, approximate matches, and the operations available to sorted arrays can be performed more efficiently than <b>binary</b> <b>search</b> on specialized data structures such as van Emde Boas trees, fusion trees, tries, and bit arrays. However, while these operations can always be done at least efficiently on a sorted array regardless of the keys, such data structures are usually only faster because they exploit the properties of keys with a certain attribute (usually keys that are small integers), and thus will be time or space consuming for keys that lack that attribute. Some structures, such as Judy arrays, {{use a combination of}} approaches to mitigate this while retaining efficiency and the ability to perform approximate matching.|$|E
5|$|Fibonacci {{search is}} a method similar to <b>binary</b> <b>search</b> that {{successively}} shortens the interval in which the maximum of a unimodal function lies. Given a finite interval, a unimodal function, and the maximum length of the resulting interval, Fibonacci search finds a Fibonacci number such that if the interval is divided equally into that many subintervals, the subintervals would be shorter than the maximum length. After dividing the interval, it eliminates the subintervals in which the maximum cannot lie until one or more contiguous subintervals remain.|$|E
40|$|While several self-indexes {{for highly}} {{repetitive}} texts exist, developing a practical self-index applicable to real world repetitive texts remains a challenge. ESP-index is a grammar-based self-index {{on the notion}} of edit-sensitive parsing (ESP), an efficient parsing algorithm that guarantees upper bounds of parsing discrepancies between different appearances of the same subtexts in a text. Although ESP-index performs efficient top-down searches of query texts, it has a serious issue on <b>binary</b> <b>searches</b> for finding appearances of variables for a query text, which resulted in slowing down the query searches. We present an improved ESP-index (ESP-index-I) by leveraging the idea behind succinct data structures for large alphabets. While ESP-index-I keeps the same types of efficiencies as ESP-index about the top-down searches, it avoid the <b>binary</b> <b>searches</b> using fast rank/select operations. We experimentally test ESP-index-I on the ability to search query texts and extract subtexts from real world repetitive texts on a large-scale, and we show that ESP-index-I performs better that other possible approaches. Comment: This is the full version of a proceeding accepted to the 11 th International Symposium on Experimental Algorithms (SEA 2014...|$|R
40|$|When {{sequential}} file structures {{must be used}} and <b>binary</b> <b>searching</b> is not feasible, jump searching becomes an appealing alternative. This paper explores variants of the classic jump searching scheme where the optimum jump size is the square root {{of the number of}} records. Multiple level and variable size jump strategies are explored, appropriate applications are discussed and performance is evaluated. Key Words and Phrases: jump searching, {{sequential file}}s, file management, search strategies, databas...|$|R
40|$|The {{interferometric}} {{gravitational wave}} detector Virgo is undergoing an advanced phase of its commissioning, during which short runs are routinely performed, in which data are analyzed online and offline, searching for signals from coalescing binary systems. In this report we present {{the progress of}} the coalescing <b>binaries</b> <b>search</b> activities in Virgo, and we describe details of the detection pipeline including hardware injections, vetoes, and parameter estimation, using recent data taking. © 2007 IOP Publishing Ltd...|$|R
