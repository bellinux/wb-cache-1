0|10000|Public
3000|$|... [k] {{denote the}} real and {{imaginary}} parts of the ensemble cross spectra, respectively. Using Equation (12 a) approximates the <b>bias</b> <b>of</b> <b>estimators</b> [...]...|$|R
3000|$|... is to {{the true}} value 2. From Figures 1, 2 and 3, we observe that the <b>biases</b> <b>of</b> <b>estimators</b> <b>of</b> the nonparametric {{component}} g(·) decrease as the sample size n increases. These show that, for semiparametric partially linear regression models for longitudinal data based on mixing error's structure, the least squares <b>estimator</b> <b>of</b> parametric component β and the <b>estimator</b> <b>of</b> nonparametric component g(·) work well.|$|R
50|$|In a {{simulation}} experiment concerning the properties <b>of</b> an <b>estimator,</b> the <b>bias</b> <b>of</b> the <b>estimator</b> may be assessed using the mean signed difference.|$|R
40|$|In {{this study}} we modify an earlier {{approach}} developed for reducing the <b>bias</b> <b>of</b> the <b>estimator</b> for the mean response in simulation caused by the initial conditions. We try to balance the <b>bias</b> <b>of</b> the <b>estimator</b> in a simulation run by imposing a bias {{in the opposite direction}} in a companion run by suitably setting its initial conditions. We present analytical results for the <b>bias</b> <b>of</b> our <b>estimator</b> for AR(1) and MMs processes. We suggest making independent replications of the pairs of runs to construct a confidence interval for the mean response. We present some empirical results about the coverages and precisions of the confidence intervals. The results suggest that the idea <b>of</b> balancing a <b>bias</b> with a bias in the opposite direction is promising. ...|$|R
40|$|In {{this note}} we derive the <b>bias</b> <b>of</b> the OLS <b>estimator</b> for a {{correlated}} random coefficient model with one random coefficient, {{but which is}} correlated with a binary variable. We provide set-identification to the parameters of interest of the model. We also show how to reduce the <b>bias</b> <b>of</b> the <b>estimator.</b> correlated random coefficient model; bias; discrete choice...|$|R
40|$|Formulas for the {{asymptotic}} <b>biases</b> <b>of</b> the <b>estimators</b> <b>of</b> {{the normal}} theory standard errors in factor analysis are given {{with and without}} the assumption of multivariate normality for observed variables. The biases are derived from the asymptotic variances <b>of</b> standard error <b>estimators</b> and the asymptotic <b>biases</b> <b>of</b> the estimated variances <b>of</b> parameter <b>estimators.</b> The latter biases are derived from the asymptotic variances/covariances and asymptotic <b>biases</b> <b>of</b> the parameter <b>estimators.</b> The formulas cover the cases for unstandardized and standardized variables. Numerical examples using factor analysis models show {{the accuracy of the}} formulas. The <b>biases</b> <b>of</b> standard error <b>estimators</b> are theoretically and empirically shown to be of the same order as that {{of the differences between the}} asymptotic standard errors neglecting higher-order terms and those considering them...|$|R
5000|$|The <b>bias</b> <b>of</b> an <b>estimator</b> is the {{difference}} between an estimator's expected value and the true value of the parameter being estimated.|$|R
40|$|Ordinary {{least square}} is a {{parameter}} estimations for minimizing residual sum of squares. If the multicollinearity {{was found in}} the data, unbias estimator with minimum variance could not be reached. Multicollinearity is a linear correlation between independent variabels in model. Jackknife Ridge Regression(JRR) as an extension of Generalized Ridge Regression (GRR) for solving multicollinearity.   Generalized Ridge Regression is used to overcome the <b>bias</b> <b>of</b> <b>estimators</b> caused <b>of</b> presents multicollinearity by adding different bias parameter for each independent variabel in least square equation after transforming the data into an orthoghonal form. Beside that, JRR can  reduce the <b>bias</b> <b>of</b> the ridge <b>estimator.</b> The result showed that JRR model out performs GRR model. </p...|$|R
40|$|In their paper, Davies and Gather (1993) formalized {{the task}} of outlier identification, {{considering}} also certain performance criteria for outlier identifiers. One of those criteria, the maximum asymptotic bias, is carried over here to multivariate outlier identifiers. We show how this term depends on the respective <b>biases</b> <b>of</b> <b>estimators</b> which are used to construct the identifier. It {{turns out that the}} use <b>of</b> high-breakdown robust <b>estimators</b> is not sufficient toachieve outlier identifiers with bounded maximum asymptotic bias...|$|R
40|$|The optimal minimum {{distance}} (OMD) <b>estimator</b> for models <b>of</b> covariance structures is asymptotically efficient but has much worse finite-sample properties {{than does the}} equally weighted {{minimum distance}} (EWMD) estimator. This paper shows how the bootstrap {{can be used to}} improve the finite-sample performance <b>of</b> the OMD <b>estimator.</b> The theory underlying the bootstrap's ability to reduce the <b>bias</b> <b>of</b> <b>estimators</b> and errors in the coverage probabilities of confidence intervals is summarized. The results of numerical experiments and an empirical example show that the bootstrap often essentially eliminates the <b>bias</b> <b>of</b> the OMD <b>estimator.</b> The finite-sample estimation efficiency of the bias-corrected OMD estimator often exceeds that <b>of</b> the EWMD <b>estimator.</b> Moreover, the true coverage probabilities of confidence intervals based on the OMD estimator with bootstrap-critical values are very close to the nominal coverage probabilities. ...|$|R
25|$|The Cramér–Rao bound {{can also}} be used to bound the {{variance}} <b>of</b> <b>biased</b> <b>estimators</b> <b>of</b> given <b>bias.</b> In some cases, a biased approach can result in both a variance and a mean squared error that are below the unbiased Cramér–Rao lower bound; see estimator bias.|$|R
40|$|In their paper, Davies and Gather (1993) formalized {{the task}} of outlier identification, {{considering}} also certain performance criteria for outlier identifiers. One of those Criteria, the maximum asymptotic bias, is carried over here to multivariate outlier identifiers. We show how this term depends on the respective <b>biases</b> <b>of</b> <b>estimators</b> which are used to construct the identifier. It {{turns out that the}} use of high breakdown robust estimators is not sufficient to achieve outlier identifiers with bounded maximum asymptotic bias...|$|R
40|$|The, 8 -binomial {{model is}} widely used for {{analyzing}} teratological data involving littermates. Recent developments in statistical analyses of teratological data are briefly reviewed with emphasis on the model. For statistical inference of the parameters in the, 8 -binomial distribution, separation of the likelihood introduces an innovation in likelihood inference. This leads to reducing <b>biases</b> <b>of</b> <b>estimators</b> and also to improvingaccuracy of empirical significance levels of tests. Separate inference of the parameters can be conducted in a unified way...|$|R
40|$|In {{the paper}} BLUPs and EBLUPs, their MSEs and <b>estimators</b> <b>of</b> MSEs under Fay-Herrior model (Fay, Herrior (1979)) are presented. This model {{belongs to the}} class of general linear mixed model type A, what means that is assumed for direct {{estimates}} of domain characteristics. What is more, {{it is assumed that}} variances of direct estimates are known. In the paper the influence of replacing the variances by their unbiased estimates and by genereal variance function’s estimates on <b>biases</b> <b>of</b> predictors, MSEs and <b>biases</b> <b>of</b> <b>estimators</b> <b>of</b> MSEs is studied in the simulation based on the real data. The problem of nonormality of area specific random components is also include...|$|R
50|$|The MSE can {{be written}} as {{the sum of the}} {{variance}} <b>of</b> the <b>estimator</b> and the squared <b>bias</b> <b>of</b> the <b>estimator,</b> providing a useful way to calculate the MSE and implying that in the case <b>of</b> unbiased <b>estimators,</b> the MSE and variance are equivalent.|$|R
5000|$|... {{will be an}} {{unbiased}} <b>estimator</b> <b>of</b> , and [...] will be a (<b>biased)</b> <b>estimator</b> <b>of</b> [...]|$|R
5000|$|... #Subtitle level 3: Bound on the {{variance}} <b>of</b> <b>biased</b> <b>estimators</b> ...|$|R
5000|$|... {{will be an}} {{unbiased}} <b>estimator</b> <b>of</b> e&minus;&sigma;2, and ln(1/Re2) will be a (<b>biased)</b> <b>estimator</b> <b>of</b> &sigma;2 ...|$|R
40|$|Due to methodological problems, {{the quality}} of the {{outcomes}} of web surveys may be seriously affected. This paper addresses one of these problems: self-selection of respondents. Self-selection leads to a lack of representativity and thus to biased estimates. It is shown that the <b>bias</b> <b>of</b> <b>estimators</b> in self-selection surveys can be much larger than in surveys based on traditional probability samples. It is explored whether some correction techniques (adjustment weighting and use of reference surveys) can improve {{the quality of}} the outcomes. It turns out that there is no guarantee for success...|$|R
5000|$|The MSEs are {{functions}} of the true value λ. The <b>bias</b> <b>of</b> the maximum-likelihood <b>estimator</b> is: ...|$|R
40|$|A simple {{technique}} is presented for obtaining explicit expressions for the approximate expectation <b>of</b> <b>estimators</b> for general stationary {{autoregressive moving average}} (ARMA) processes. The {{technique is}} based on a Taylor series expansion of the log-likelihood function in terms of the expected values of the sample autocovariances or in terms of the expected value of the periodogram ordinates, depending upon whether the estimation makes use of time-domain methods. For illustrative purpose the expectation <b>of</b> <b>estimators</b> arising from two particular approximations of the likelihood function is obtained, although the proposed technique can be easily extended to other types of log-likelihood functions as well. The results may be used to provide information about the <b>bias</b> <b>of</b> <b>estimators</b> in non-seasonal and seasonal ARMA models...|$|R
40|$|The {{purpose of}} this paper is to review {{recently}} development methods of estimation of nonlinear fixed effects panel data models with reduced bias properties. We begin by describing fixed effects estimators and the incidental parameters problem. Next the explain how to construct analytical <b>bias</b> correction <b>of</b> <b>estimators,</b> followed by <b>bias</b> correction <b>of</b> <b>estimators,</b> followed by <b>bias</b> correction <b>of</b> the moment equation, and bias corrections for the concentrated likelihood. We then turn to discuss other approaches leading to bias correction based on orthogonalization and their extensions. The remaining sections consider quasi maximum likelihood estimation for dynamic models, the estimation of marginal effects, and automatic methods based on simulation. Asymptotic corrections, bias reduction, fixed effects, modifies likelihood, nonlinear models, panel data, simulation methods. ...|$|R
5000|$|A less <b>biased</b> <b>estimator</b> <b>of</b> the {{variance}} {{explained in the}} population is &omega;2 ...|$|R
40|$|Models are {{considered}} in which lsquotruersquo lifetimes are {{generated by a}} Weibull regression model and measured lifetimes are determined from the true times by certain measurement error models. Adjusted estimators are obtained under one parametric specification. The <b>bias</b> properties <b>of</b> these <b>estimators</b> and standard estimators are compared both theoretically, using small measurement error asymptotics, and by simulation. The standard <b>estimators</b> <b>of</b> regression coefficients, other than the intercept, are bias-robust. The adjusted <b>estimator</b> <b>of</b> the shape parameter removes the <b>bias</b> <b>of</b> the standard <b>estimator...</b>|$|R
40|$|AbstractLow {{response}} rates {{and thus a}} certain level of nonignorable unit nonresponse in household surveys cause growing uncertainty about {{the reliability and validity of}} the results. Within the scope of “Mobility in Cities – SrV 2013 ”, 4. 802 persons who had not participated in the main study were successfully encouraged to fill in an abbreviated questionnaire. Hence, it was possible to collect important information concerning the nonrespondent's person and daily mobility. The analysis methodology used is based on multivariate analysis tools. It allows for explanations of failure mechanisms, effectiveness of weighting procedures as well as their consequences regarding potential <b>bias</b> <b>of</b> <b>estimators...</b>|$|R
5000|$|The <b>biased</b> {{weighted}} <b>estimator</b> <b>of</b> variance can {{be shown}} to be: ...|$|R
40|$|Stimulated by {{practical}} {{concerns in}} the use <b>of</b> order restricted <b>estimators,</b> we study some <b>bias</b> issues <b>of</b> isotonic <b>estimators</b> <b>of</b> ordered parameters. We obtain explicit expressions for <b>biases</b> <b>of</b> order restricted <b>estimators</b> <b>of</b> ordered means of two normal populations with common variance. Based on intuitive considerations, we also propose a new <b>estimator</b> <b>of</b> the common variance of two normal populations having ordered normal means and show that it has smaller bias than the maximum likelihood <b>estimator</b> <b>of</b> the variance and has smaller mean squared error than the usual unbiased <b>estimator</b> <b>of</b> the common variance. Order restricted estimators Intuitive considerations Common variance...|$|R
40|$|This paper {{studies the}} {{asymptotic}} <b>bias</b> <b>of</b> the differencing parameter estimator when data are measured with error. The estimator is established via the partial autocorrelation function. Factors {{that affect the}} direction <b>of</b> <b>bias</b> <b>of</b> the <b>estimator</b> are found. © 1999 Elsevier Science S. A. All rights reserved. link_to_subscribed_fulltex...|$|R
5000|$|The {{statistic}} [...] is a <b>biased</b> <b>estimator</b> <b>of</b> [...] Under {{independence of}} X and Y ...|$|R
40|$|Properties {{of various}} types <b>of</b> <b>estimators</b> <b>of</b> the {{regression}} coefficients in linear logistic regression models are considered. The estimators include those based on maximum likelihood, minimum chi-square and weighted least squares. Theoretical approximations to the <b>biases</b> <b>of</b> the <b>estimators</b> are developed. The results of a large scale simulation investigation evaluating the moment properties <b>of</b> the <b>estimators</b> are presented for {{the case of a}} logistic model with a single explanatory variable...|$|R
40|$|When an <b>estimator</b> <b>of</b> the {{variance}} of the sample mean is parameterized by batch size, one approach for selecting batch size is to pursue the minimal mean squared error (mse). We show that the convergence rate of {{the variance}} of the sample mean, and the <b>bias</b> <b>of</b> <b>estimators</b> <b>of</b> {{the variance of}} the sample mean, asymptotically depend on the data process only through its marginal variance and {{the sum of the}} autocorrelations weighted by their absolute lags. Combining these results with variance results of Goldsman and Meketon, we obtain explicit asymptotic approximations for mse, optimal batch size, optimal mse, and robustness for four quadratic-form <b>estimators</b> <b>of</b> the variance of the sample mean. Our empirical results indicate that the asymptotic approximations are reasonably accurate for sample sizes seen in practice. Although we do not discuss batch-size estimation procedures, the empirical results suggest that the explicit asymptotic batch-size approximation, which depends only on a summary measure (which we refer to as the balance point) of the nonnegative-lag autocorrelations, is a reasonable foundation for such procedures. simulation output analysis, estimation, overlapping batch means, standardized time series...|$|R
40|$|With the {{presence}} of unequal sampling in a multilevel model, the weight inflated estimators for variance components can be biased even though the use of survey weights results in design consistent <b>estimators</b> <b>of</b> the parameters. In this thesis I will carry out a simulation study to examine the performance of current existing methods and I will examine the resampling method for correcting <b>bias</b> <b>of</b> <b>estimators</b> <b>of</b> variance components of a multilevel model with covariates. This study {{will be based on}} these three papers: “Weighting for Unequal Selection Probabilities in Multilevel Models” by D. Pfeffermann, C. J. Skinner, D. J. Holmes, H. Goldstein, and J. Rasbash (1998), Journal of the Royal Statistical Society Series B (Statistical Methodology), Vol. 60, No. 1, 23 - 40; “Design Consistent Estimators for a Mixed Linear Model on Survey Data” by Rong Huang and Mike Hidiroglou (2003), Business Survey Methods Division, Statistics Canada, Ottawa, Ontario K 1 Y 0 A 6; and “A resampling approach to estimate variance components of multilevel models” by Zilin Wang and Mary Thompson (2008), working paper...|$|R
40|$|For {{the quantum}} Gaussian state family, Hayashi {{proposed}} a quantum mechanical operation using beam splitters {{to estimate the}} location and scale parameters of the P-function, and he showed that it is asymptotically optimal. In this paper, we analyze the effect of disturbance of his operation caused by the randomness of the transparency of the beam splitters. It is shown {{that even if the}} variance of the random transparency is small, Hayashi's estimators are improper in a sense that they are biased and asymptotically inconsistent. In such a case, we propose to stop the operation and correct the <b>biases</b> <b>of</b> <b>estimators.</b> Comment: latex 2 e, 13 pages, 2 figures, submitted to J. Japan Statist. Soc. on 20 Mar 200...|$|R
40|$|Metode Jackknife dapat digunakan untuk mereduksi bias suatu {{estimator}}. Untuk mengetahui keefektifan dari estimator Jackknife order satu dan estimator Jackknife order dua sebagai pereduksi bias dapat dilihat dari sifat-sifatnya. Ciri-ciri bias estimator terfetak pada suku-suku bias dari estimator yang asli. Kemudian bias dari Jackknife order dua dibandingkan dengan bias estimator yang asli dan juga dibandingkan dengan bias Jackknife order satu. Dari perbandingan ini dapat dilihat untuk keadaan tertentu Jackknife order dua lebih efektif daripada Jackknife order satu maupun terhadap estimator aslinya. Jackknife method {{can be used}} to bias reduction. To {{investigates the}} effectiveness of the first and second order Jackknife estimators,as tools for bias reduction, we must look from the characterized. The <b>biases</b> <b>of</b> <b>estimators</b> are characterized in terms <b>of</b> the <b>bias</b> original <b>estimator.</b> Then <b>biases</b> <b>of</b> the two <b>estimators</b> are compared, biases second order Jackknife are compared with biases first order Jackknife and biases second order Jackknife compared with <b>bias</b> <b>of</b> the original <b>estimator.</b> From this comparison we can see that second order Jackknife more effectif than first order Jackknife or the original estimator. L. This document is Undip Institutional Repository Collection. The author(s) or copyright owner(s) agree that UNDIP-IR may, without changing the content, translate the submission to any medium or kormat for the purpose of preservation. The author(s) or copyright owner(s) also agree that UNDIP-IR may keep more than one copy of this submission for purpose of security, back-up and preservation: ([URL]) ...|$|R
40|$|In {{this paper}} we {{investigate}} the robustness {{properties of the}} class of minimum power divergence estimators for grouped data. This class contains the classical maximum likelihood estimators for grouped data. We find that the <b>bias</b> <b>of</b> these <b>estimators</b> due to deviations from the assumed underlying model can be large. Therefore we propose a more general class <b>of</b> <b>estimators</b> which allow us to construct robust procedures. Statistical Analysis; Evaluation...|$|R
5000|$|The {{jackknife}} technique {{can be used}} {{to estimate}} the <b>bias</b> <b>of</b> an <b>estimator</b> calculated over the entire sample. Say [...] is the calculated <b>estimator</b> <b>of</b> the parameter of interest based on all [...] observations. Letwhere [...] is the estimate of interest based on the sample with the ith observation removed, and [...] is the average of these [...] "leave-one-out" [...] estimates.The jackknife estimate <b>of</b> the <b>bias</b> <b>of</b> [...] is given by: ...|$|R
