245|0|Public
500|$|An early {{result in}} this {{direction}} was provided by [...] using the cell probe model of computation (an artificial model in which the complexity of an algorithm is measured only {{by the number of}} memory accesses it performs). Building on their work, [...] described two data structures, the Q-heap and the atomic heap, that are implementable on a random access machine. The Q-heap is a <b>bit-parallel</b> version of a binary trie, and allows both priority queue operations and successor and predecessor queries to be performed in constant time for sets of [...] items, where [...] is the size of the precomputed tables needed to implement the data structure. The atomic heap is a B-tree in which each tree node is represented as a Q-heap; it allows constant time priority queue operations (and therefore sorting) for sets of [...] items.|$|E
2500|$|In {{addition}} the Selectric mechanism natively used {{a unique}} code {{based on the}} [...] "tilt/rotate" [...] commands to the golf ball. That and the <b>bit-parallel</b> interface and peculiar timing requirements meant the Selectric could not be directly {{hooked up to a}} modem. [...] Indeed, it needed a relatively large amount of logic to reconcile the two devices, and the interface logic often outweighed the printing mechanism in the early years.|$|E
5000|$|<b>Bit-parallel</b> processing: One word of W bits is {{processed}} every clock cycle.|$|E
50|$|Originally, all {{electronic}} {{computers were}} serial (single-bit) computers. The first electronic computer {{that was not}} a serial computer—the first <b>bit-parallel</b> computer—was the 16-bit Whirlwind from 1951.|$|E
5000|$|In {{digital logic}} applications, bit-serial {{architectures}} send data one bit at a time, along a single wire, {{in contrast to}} <b>bit-parallel</b> word architectures, in which data values are sent all bits or a word at once along a group of wires.|$|E
5000|$|In {{addition}} the Selectric mechanism natively used {{a unique}} code {{based on the}} [...] "tilt/rotate" [...] commands to the golf ball. That and the <b>bit-parallel</b> interface and peculiar timing requirements meant the Selectric could not be directly {{hooked up to a}} modem. Indeed, it needed a relatively large amount of logic to reconcile the two devices, and the interface logic often outweighed the printing mechanism in the early years.|$|E
5000|$|By 1947, Forrester and {{collaborator}} Robert Everett {{completed the}} design of a high-speed stored-program computer for this task. Most computers of the era operated in bit-serial mode, using single-bit arithmetic and feeding in large words, often 48 or 60 bits in size, one bit at a time. This was simply not fast enough for their purposes, so Whirlwind included sixteen such math units, operating on a complete 16-bit word every cycle in <b>bit-parallel</b> mode. Ignoring memory speed, Whirlwind ("20,000 single-address operations per second" [...] in 1951) was essentially sixteen times as fast as other machines. Today almost all CPUs do arithmetic in [...] "bit-parallel" [...] mode.|$|E
5000|$|An early {{result in}} this {{direction}} was provided by [...] using the cell probe model of computation (an artificial model in which the complexity of an algorithm is measured only {{by the number of}} memory accesses it performs). Building on their work, [...] described two data structures, the Q-heap and the atomic heap, that are implementable on a random access machine. The Q-heap is a <b>bit-parallel</b> version of a binary trie, and allows both priority queue operations and successor and predecessor queries to be performed in constant time for sets of [...] items, where [...] is the size of the precomputed tables needed to implement the data structure. The atomic heap is a B-tree in which each tree node is represented as a Q-heap; it allows constant time priority queue operations (and therefore sorting) for sets of [...] items.|$|E
40|$|We have {{proposed}} and demonstrated a novel bit-level synchronization technique by perfectly synchronizing all <b>bit-parallel</b> WDM data transmitted over a 27. 5 km single fiber. By sampling temporally skewed <b>bit-parallel</b> WDM data at a common overlapping range with an all optical switch (TOAD), the <b>bit-parallel</b> WDM channels emerge aligned exactly in time. Error free transmission on all WDM channels was achieved. The working range, where TOAD samples all overlapping <b>bit-parallel</b> WDM channels, is 220 ps for our particular experimental setup. For transmissions where the time skew exceeds 140 ps, traditional dispersion compensation techniques must {{be employed to}} contain the time-skew within 220 ps and to transmit longer distances...|$|E
40|$|This paper {{outlines}} {{the design of}} a <b>bit-parallel,</b> multi-string algorithm for high-similarity string comparison. We present it in the framework for the longest common subsequence (LCS) problem developed by the author in [31]. The algorithm is based on a <b>bit-parallel</b> LCS algorithm by Crochemore et al. [14]...|$|E
40|$|Abstract—We {{present a}} new low-complexity <b>bit-parallel</b> {{canonical}} basis multiplier {{for the field}} GF(2 m) generated by an all-onepolynomial. The proposed canonical basis multiplier requires m 2 - 1 XOR gates and m 2 AND gates. We also extend this canonical basis multiplier to obtain a new <b>bit-parallel</b> normal basis multiplier. Index Terms—Finite fields, multiplication, normal basis, canonical basis, all-one-polynomial. ...|$|E
40|$|Abstract. The {{performance}} of the pattern matching algorithms based on bit-parallelism degrades when the input pattern length exceeds the computer word size. Although several divide-and-conquer methods have been proposed to overcome that limitation, the resulting schemes are not that much efficient and hard to implement. This study introduces a new fast <b>bit-parallel</b> pattern matching algorithm {{that is capable of}} searching patterns of any length in a common <b>bit-parallel</b> fashion. The proposed <b>bit-parallel</b> length invariant matcher (BLIM) is compared with the Shift-Or and <b>bit-parallel</b> non-deterministic matching (BNDM) algo-rithms along with the standard Boyer-Moore and Sunday’s quick search, which are known to be the very fast in general. Benchmarks have been conducted on natural language, DNA sequence, and binary alphabet ran-dom texts. Besides the length invariant architecture of the algorithm, experimental results indicate that on the average BLIM is 18 %, 44 %, and 6 % faster than BNDM, which is accepted as one of the fastest al-gorithms of this genre, on natural language, DNA sequence and binary random texts respectively. ...|$|E
40|$|Designs of the bit-serial and <b>bit-parallel</b> {{versions}} of the Discrete Cosine Transform Processor using the universal IIR filter module are presented, with emphasis on the bit-serial design. A bit-serial cell mini-library was created. The designs were performed with the AlliedSignal Aerospace Microelectronics Center's 1. 2 micro double metal p-well CMOS standard cell library. The core of the bit-serial design is the 18 -bit data x 8 -bit coefficient bit-serial multiplier, whose design is also presented in detail; the multiplier is capable of handling negative data and negative coefficients, and has an accuracy of o(2 - 16), The 8 -point 18 -bit bit-serial DCT has a maximum clock speed of 139. 0 MHz and 55. 6 MHz under best and worst case conditions respectively. Two <b>bit-parallel</b> design implementations are presented, one with straight <b>bit-parallel</b> multiplier cells {{and the other with}} ROM multipliers using distributed arithmetic. The <b>bit-parallel</b> designs are also 8 -point, but have an 8 -bit wide input and a 12 -bit wide output, thereby calculating with much less precision. The parallel multiplier chip's maximum speed under best and worst case conditions is 28. 4 MHz and 11. 4 MHz respectively, whereas the ROM multiplier chip's is 36. 3 MHz and 14. 5 MHz respectively. All three designs have a throughput of one clock cycle, with respect to their data input rates. The latencies for the bit-serial and <b>bit-parallel</b> designs are 38 and 5 cycles respectively...|$|E
40|$|A {{method to}} apply <b>bit-parallel</b> {{processing}} at {{all stages of}} robust and nonrobust test pattern generation for path delay faults is presented. Two different modes of <b>bit-parallel</b> processing are combined: fault parallel test pattern generation (FPTPG) and alternative parallel test pattern generation (APTPG). We discuss the problems that appear while exploiting bit-parallelity and we describe how to overcome them. Experimental results demonstrate a reduction of aborted faults and an acceleration up to a factor of nine. ...|$|E
40|$|Schemes {{for direct}} {{implementation}} of recursive digital filters using <b>bit-parallel</b> arithmetic are presented. Two arrays of <b>bit-parallel</b> multipliers {{are used to}} realize the numerator and the denominator of the transfer functions. Latching has been introduced to the computing elements for throughput maximization. The use of latched multipliers/adders restricts the denominator polynomials to be functions of a power of z**-** 1. Such filters can be designed either directly or by transforming a general transfer function into this specialized form...|$|E
40|$|Abstract. This paper {{presents}} a new <b>bit-parallel</b> multiplier for the finite field GF (2 m) generated with an irreducible all-one polynomial. Redundant representation {{is used to}} reduce the time delay of the proposed multiplier, while a three-term Karatsuba-like formula is combined with this representation to decrease the space complexity. As a result, the proposed multiplier requires about 10 percent fewer AND/XOR gates than the most efficient <b>bit-parallel</b> multipliers using an all-one polynomial, while it has almost the same time delay as the previously proposed ones. ...|$|E
40|$|A {{high-performance}} {{implementation of}} the International Data Encryption Algorithm (IDEA) is presented in this paper. The design was implemented in both <b>bit-parallel</b> and bit-serial architectures and a comparison of design tradeoffs using various measures is presented. On an Xilinx Virtex XCV 300 - 6 FPGA, the <b>bit-parallel</b> implementation delivers an encryption rate of 1166 Mb/sec at a 82 MHz system clock rate, whereas the bit-serial implementation offers a 600 Mb/sec throughput at 150 MHz. Both designs are suitable for real-time applications, such as online high-speed networks. The implementation is runtime reconfigurable such that key-scheduling is done by directly modifying the bitstream downloaded to the FPGA, hence enabling an implementation without the logic required for key-scheduling. Both implementations are scalable such that higher throughput is obtained with increased resource requirements. The estimated performances of the <b>bit-parallel</b> and bit-serial implementations on an XCV 1000 - 6 device are 5. 25 Gb/sec and 2. 40 Gb/sec respectively. Keywords: Cryptographic hardware, digital-design, reconfigurable-computing, performance-tradeoffs. ...|$|E
40|$|We {{consider}} a fundamental problem testing if every bit is zero {{in a bit}} vector in a so-called <b>bit-parallel</b> machine. In this machine, a machine word can have unlimited number of bits, and logical operations such as bitwise-and, bitwise-or, and so on, {{can be done in}} O(1) time. However, in each time, only one bit in a bit vector can be examined. We show how to solve this fundamental problem in O(1) time by using the composition of bitwise logical operations and basic arithmetic operations, and apply this technique to solve the multiplepattern matching problem. Multiple-pattern matching is the problem of finding all occurrences of patterns in a text. There are <b>bit-parallel</b> algorithm Shift-And [11] that can solve it. In this paper, we show how to improve the performance of the Shift-And algorithm, and accordingly, to the performance of multiple-pattern matching under the <b>bit-parallel</b> machine we have addressed. Our idea is based on a key lemma from Ou and Lee [12]. ...|$|E
40|$|Wavelength {{division}} multiplexing (WDM) {{is emerging}} as a viable solution to reduce the electronic processing bottleneck in very high-speed optical networks. A set of parallel and independent channels are created on a single fiber using this technique. Parallel communication utilizing the WDM channels may be accomplished in two ways: (i) bit serial, where each source-destination pair communicates using one wavelength and data are sent serially on this wavelength; and (ii) bit parallel, where each sourcedestination pair communicates using a subset of channels and data are sent in multiple-bit words. Three architectures are studied in the paper: single-hop bit-serial star, single-hop <b>bit-parallel</b> star, and multihop <b>bit-parallel</b> shufflenet. The objective {{of this paper is}} to evaluate these architectures with respect to average packet delay, network utilization, and link throughput. It is shown that the Shufflenet offers the lowest latency but suffers from high cost and low link throughput. The star topology with <b>bit-parallel</b> access offers lower latency than the bit-serial star, but is more expensive to implement...|$|E
40|$|The string {{matching}} problem for strings {{in which one}} should find the occurrences of a pattern string within a text, is well-studied in the past literature. The problem can be solved efficiently, e. g., by using so-called <b>bit-parallel</b> algorithms. We adapt the <b>bit-parallel</b> approach to music information retrieval. We consider {{a situation where the}} pattern is monophonic and the text (the musical source) is polyphonic, that is, the pattern is a sequence of symbols, while the source is a sequence of sets of symbols (i. e., chords). The application of the <b>bit-parallel</b> approach is straightforward, if the transposition invariance is not allowed in the matching. However, the problem becomes trickier with transposition invariance, a necessary property in practice. We present algorithms for both cases. Our main contribution is a linear-time transposition-invariant filtering-algorithm for static music databases. We show by experiments that, if the average size of the chords keeps reasonably low, o [...] ...|$|E
40|$|Bit-serial {{architectures}} offer {{a number}} of attractive features over their <b>bit-parallel</b> counterparts such as smaller area cost, lower density interconnection, a reduced number of pins, higher clock frequency, simpler routing and etc. These attractive features make them suitable for using in VLSI design and reduce overall production cost. In this paper, we propose the first least significant bit (LSB) bit-serial sum of absolute difference (SAD) hardware accelerator for integer variable block size motion estimation (VBSME) of H. 264. This hardware accelerator {{is based on a}} previous state-of-art <b>bit-parallel</b> architecture namely propagate partial SAD. In order to reduce area cost and improve throughput, pixel truncation technique is adopted. Due to the bit-serial pipeline architecture and using small processing elements, our architecture works at much higher clock frequency (at least 4 times) and reduces area cost about 32 % compared with its <b>bit-parallel</b> counterpart. The proposed hardware accelerator can be used in different disciplines from low bit rate to high bit rate by making a tradeoff between the degree of parallelism or using fast algorithm or a combination of both...|$|E
40|$|Abstract—In this paper, {{we present}} {{efficient}} algorithms for modular reduction to derive novel systolic and non-systolic archi-tectures for polynomial basis finite field multipliers over GF (2 m) {{to be used}} in Reed-Solomon codec. Using the proposed algorithm for unit degree reduction and optimization of implementation of the logic functions in the processing elements (PE), we have derived an efficient <b>bit-parallel</b> systolic design for finite field multiplier which involves nearly two-third of the area-complexity of the existing design having the same time-complexity. The proposed modular reduction algorithms are also used to derive efficient non-systolic serial/parallel designs of field multipliers over GF (28) with different digit-sizes, where the critical path and the hardware-complexity are further reduced by optimizing the implementation of modular reduction operations and finite field accumulations. The proposed bit-serial design involves nearly 55 % of the minimum of area, and half the minimum of area-time complexity of the existing bit-serial designs. Similarly, the proposed digit-serial/parallel designs involve significantly less area, and less area-time complexities compared with the existing designs of the same digit-size. By parallel modular reduction through multiple degrees followed by appropriate logic-level sub-expression sharing; a hardware-efficient regular and modular form of a balanced-tree <b>bit-parallel</b> non-systolic multiplier is also derived. The proposed <b>bit-parallel</b> non-systolic pipelined design involves less than 65 % of the area and nearly two-third of the area-time complexity of the existing <b>bit-parallel</b> design for a Reed-Solomon codec, while the non-pipelined form offers nearly 25 % saving of area with less time-complexity. Index Terms—Finite field, Galois field, finite field multiplica-tion, Reed-Solomon codec, error-control-coding, systolic array, very large scale integration (VLSI) ...|$|E
40|$|Abstract. We {{consider}} <b>bit-parallel</b> algorithms of Boyer-Moore type for exact string matching. We {{introduce a}} two-way {{modification of the}} BNDM algorithm. If the text character aligned {{with the end of}} the pattern is a mismatch, we continue by examining text characters after the alignment. Besides this two-way variation, we present a simplified version of BNDM without prefix search and an algorithm scheme for long patterns. We also study a different <b>bit-parallel</b> algorithm, which keeps the history of examined characters in a bit-vector and where shifting is based on this bit-vector. We report experiments where we compared the new algorithms with existing ones. The simplified BNDM is the most promising of the new algorithms in practice. ...|$|E
40|$|The authors study {{contention-based}} bus-control {{schemes for}} scheduling processors in using a <b>bit-parallel</b> shared bus. The protocol is designed under the requirements that each processor exhibit a random access behavior, {{that there be}} no centralized bus control in the system, and that access be granted in real time. The proposed scheme is based on splitting algorithms used in conventional contention-resolution schemes, and utilizes two-state information obtained from collision detection. Two versions of the bus-control scheme are studied. The static one resolves contentions of N requesting processors in an average of O(logW/ 2 N) iterations, where W {{is the number of}} bits in the <b>bit-parallel</b> bus. An adaptive version resolves contentions in an average time that is independent of N...|$|E
40|$|Abstract—In this paper, {{we propose}} a novel FPGA-based {{architecture}} for large-scale regular expression matching, called dynamic reconfigurable <b>bit-parallel</b> NFA architecture (dynamic BP-NFA) that allows dynamic reconfiguration of the patterns using <b>bit-parallel</b> NFA-simulation approach. This {{is the first}} dynamic reconfigurable FPGA-based hardware with guaranteed performance for the class of extended patterns, where a extended pattern is a restricted regular expression in linear form consisting of letters, classes of letters, don’t cares, optional letters, bounded and unbounded length gaps and repeatable letters. The key of our architecture {{is the use of}} <b>bit-parallel</b> pattern matching approach that have been developed in string matching communities for the decades. In this approach, the information of an input NFA is compactly encoded in bit-masks stored in a collection of registers and block RAMs. Then, the NFA is efficiently simulated by a fixed circuitry using a combination of bit- and arithmeticoperations on these bit-masks consuming one input letter per clock. As compared with previous approaches of DFA-based dynamic reconfigurable architectures, experimental results show that the proposed architecture achieves higher throughput for the class of exact string patterns and comparable for the class of extended patterns. I...|$|E
40|$|Given a text T [1 ::n] and {{a pattern}} P [1 ::m] the classic dynamic {{programming}} algorithm for computing the edit distance between P and every location of T runs in time O(nm). The <b>bit-parallel</b> computation {{of the dynamic}} programming matrix [6] runs in time O(n dm=we), where w {{is the number of}} bits in computer word. We present a new method that rearranges the <b>bit-parallel</b> computations, achieving time O(dn=we (m + log 2 ()) + n), where is the size of the alphabet. The algorithm is then modi ed to solve the k dierences problem. The expected running time is O(dn=we (L(k) + log 2 ()) + R), where L(k) depends on k, and R is the number of occurrences. The space usage is O(+ m). It is in practice much faster than the existing O(n dk=we) algorithm [6]. The new method is applicable only for small (e. g. dna) alphabets, but this becomes the fastest algorithm for small m, or moderate k=m. If we want to search multiple patterns in a row, the method becomes attractive for large alphabet sizes too. We also consider applying 128 -bit vector instructions for <b>bit-parallel</b> computations...|$|E
40|$|Abstract. Questions of {{development}} and research of new ways parallel and <b>bit-parallel</b> representation of the iterative computing Volder’s algorithms, providing accelerated calculation of elementary functions and performance of operations of arithmetics and geometry are considered. Carefully analyzed are the methods of 1...|$|E
40|$|Abstract. Given a text T [1 [...] n] and {{a pattern}} P [1 [...] m] the classic dynamic {{programming}} algorithm for computing the edit distance between P and every location of T runs in time O(nm). The <b>bit-parallel</b> computation {{of the dynamic}} programming matrix [6] runs in time O(n ⌈m/w⌉), where w {{is the number of}} bits in computer word. We present a new method that rearranges the <b>bit-parallel</b> computations, achieving time O(⌈n/w ⌉ (m + σ log 2 (σ)) + n), where σ is the size of the alphabet. The algorithm is then modified to solve the k differences problem. The expected running time is O(⌈n/w ⌉ (L(k) + σ log 2 (σ)) + R), where L(k) depends on k, and R is the number of occurrences. The space usage is O(σ + m). It is in practice much faster than the existing O(n ⌈k/w⌉) algorithm [6]. The new method is applicable only for small (e. g. dna) alphabets, but this becomes the fastest algorithm for small m, or moderate k/m. If we want to search multiple patterns in a row, the method becomes attractive for large alphabet sizes too. We also consider applying 128 -bit vector instructions for <b>bit-parallel</b> computations. ...|$|E
40|$|Tartan (TRT), a {{hardware}} accelerator for inference with Deep Neural Networks (DNNs), is presented and evaluated on Convolutional Neural Networks. TRT exploits the variable per layer precision requirements of DNNs to deliver execution {{time that is}} proportional to the precision p in bits used per layer for convolutional and fully-connected layers. Prior art has demonstrated an accelerator with the same execution performance only for convolutional layers. Experiments on image classification CNNs show that on average across all networks studied, TRT outperforms a state-of-the-art <b>bit-parallel</b> accelerator by 1 : 90 x without any loss in accuracy while it is 1 : 17 x more energy efficient. TRT requires no network retraining while it enables trading off accuracy for additional improvements in execution performance and energy efficiency. For example, if a 1 % relative loss in accuracy is acceptable, TRT is on average 2 : 04 x faster and 1 : 25 x more energy efficient than a conventional <b>bit-parallel</b> accelerator. A Tartan configuration that processes 2 -bits at time, requires less area than the 1 -bit configuration, improves efficiency to 1 : 24 x over the <b>bit-parallel</b> baseline while being 73 % faster for convolutional layers and 60 % faster for fully-connected layers is also presented...|$|E
40|$|A <b>bit-parallel</b> {{systolic}} multiplier {{based on}} pair-wise grouping of the bit products is presented. The proposed scheme yields significantly lower latency compared to existing systolic multipliers, without increasing the circuit complexity. High throughput is achieved, {{limited by the}} delay of a gated full adder and a latch...|$|E
40|$|We {{present an}} {{efficient}} prototype for music information retrieval. The prototype uses bitparallel algorithms for locating transposition invariant matches of monophonic query melodies within monophonic or polyphonic music {{stored in a}} database. When dealing with monophonic music, we employ a fast approximate <b>bit-parallel</b> algorithm with special edit distance metrics...|$|E
40|$|This paper {{describes}} a bew approach for negating the iteration bound of recursive digital filters. The approach {{is based on}} first applying equivalence transforms to tyhe recursive section signal flow graph to determine the maximum allowable pipeline delay for each feedback loop and then selecting <b>bit-parallel</b> arithmetic where pipelined digit-serial computation does not meet these delay limits. Scattered look-ahead pipelining is considered {{in combination with the}} proposed method. The resultant structures remain predominantly digit-seral in operation, making the approach ideally suited to designs for programmable logic arrays since high resource efficiency is achieved. Using new digit-serial and <b>bit-parallel</b> multiplier offering reduced pipeline dealy, a 14 -bit data path 11 -bit coefficient biquad filter for the Xilinx CX 4010 achieves 36 Msample per sec processing rate, up to 5 times higher than previously reported results...|$|E
40|$|The longest common {{subsequence}} (LCS) is {{a classic}} and well-studied measure of similarity between two strings A and B. This problem has two variants: determining {{the length of the}} LCS (LLCS), and recovering an LCS itself. In this paper we address the first of these two. Let m and n denote the lengths of the strings A and B, respectively, and w denote the computer word size. First we give a slightly improved formula for the <b>bit-parallel</b> O(#m/w#n) LLCS algorithm of Crochemore et al. [4]. Then we discuss the relative performance of the <b>bit-parallel</b> algorithms and compare our variant against one of the best conventional LLCS algorithms. Finally we propose and evaluate an O(#d/w#n) version of the algorithm, where d is the simple (indel) edit distance between A and B...|$|E
40|$|Abstract. We {{present a}} new {{algorithm}} for string matching. The al-gorithm, called BNDM, is the <b>bit-parallel</b> simulation of a known (but recent) algorithm called BDM. BDM skips characters using a au-tomaton " {{which is made}} deterministic in the preprocessing. BNDM, in-stead, simulates the nondeterministic version using bit-parallelism. This algorithm is 20...|$|E
40|$|We {{present an}} {{efficient}} prototype for music information retrieval. The prototype uses <b>bit-parallel</b> algorithms for locating transposition invariant matches of monophonic query melodies within monophonic or polyphonic music {{stored in a}} database. When dealing with monophonic music, we employ a fast approximate <b>bit-parallel</b> algorithm with special edit distance metrics. The fast scanning phase is succeeded by verification where a separate metrics is used for ranking matches. We also offer the possibility to search for exact occurrences of a "distributed" melody within polyphonic databases via a bitparallel filtering technique. In our experiments with a database of 2 million musical elements (notes in a monophonic and chords in a polyphonic database) the responses were obtained clearly within one second in both the cases. Furthermore, our prototype is capable of using various interval classes in matching, producing more approximation when it is needed...|$|E
40|$|In this paper, {{we examine}} several issues of <b>bit-parallel</b> free space optical {{communication}} such as arbitration operations, fault tolerance, and connector alignment. 1. Introduction This paper explores {{some of the}} advantages of <b>bit-parallel,</b> free-space, optical communication as opposed to the more common bit-serial communication techniques. While free-space optical communication promises to overcome many of the current technological limitations for truly massive, high-performance information interchange, we argue {{that it is important to}} send the bits in parallel unlike current optical communication technology. The extension to parallel communication not only provides higher bandwidth but may solve mundane problems of fault tolerance, mutual exclusion, and connector alignment in novel ways. All this is in addition to the "popularity of parallelism" justification. It is not clear if solutions presented are the best given today's technology, 1 however, some solution is required for these [...] ...|$|E
