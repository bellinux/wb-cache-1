724|60|Public
25|$|It is {{possible}} to test whether a given graph is an indifference graph in linear time, by using PQ trees to construct an interval representation of the graph and then testing whether a vertex ordering derived from this representation satisfies the properties of an indifference graph. It is also possible to base a recognition algorithm for indifference graphs on chordal graph recognition algorithms. Several alternative linear time recognition algorithms are based on <b>breadth-first</b> <b>search</b> or lexicographic <b>breadth-first</b> <b>search</b> {{rather than on the}} relation between indifference graphs and interval graphs.|$|E
25|$|Contrasting with depth-first {{order is}} breadth-first order, which always {{attempts}} {{to visit the}} node closest to the root {{that it has not}} already visited. See <b>breadth-first</b> <b>search</b> for more information. Also called a level-order traversal.|$|E
25|$|Alternatively, {{a similar}} {{procedure}} {{may be used}} with <b>breadth-first</b> <b>search</b> in place of depth-first search. Again, each node is given the opposite color to its parent in the search forest, in breadth-first order. If, when a vertex is colored, there exists an edge connecting it to a previously-colored vertex with the same color, then this edge together with the paths in the <b>breadth-first</b> <b>search</b> forest connecting its two endpoints to their lowest common ancestor forms an odd cycle. If the algorithm terminates without finding an odd cycle in this way, then it must have found a proper coloring, and can safely conclude that the graph is bipartite.|$|E
50|$|Chapter 4. The Schottky dance - {{pairs of}} Möbius maps which {{generate}} Schottky groups; plotting their limit sets using <b>breadth-first</b> <b>searches.</b>|$|R
50|$|IDDFS {{combines}} depth-first <b>search's</b> space-efficiency and <b>breadth-first</b> <b>search's</b> completeness (when the {{branching factor}} is finite). It is optimal when the path cost is a non-decreasing {{function of the}} depth of the node.|$|R
50|$|Thus, simple depth-first or <b>breadth-first</b> <b>searches</b> do not {{traverse}} every infinite tree, {{and are not}} efficient on {{very large}} trees. However, hybrid methods can traverse any (countably) infinite tree, essentially via a diagonal argument ("diagonal"—a combination of vertical and horizontal—corresponds {{to a combination of}} depth and breadth).|$|R
25|$|Some hobbyists have {{developed}} computer {{programs that will}} solve Sudoku puzzles using a backtracking algorithm, which {{is a type of}} brute force search. Backtracking is a depth-first search (in contrast to a <b>breadth-first</b> <b>search),</b> because it will completely explore one branch to a possible solution before moving to another branch. Although it has been established that approximately 6.67 x 1021 final grids exist, a brute force algorithm can be a practical method to solve Sudoku puzzles.|$|E
500|$|The {{transitive}} closure {{of a given}} DAG, with [...] vertices and [...] edges, may be constructed in time [...] by using either <b>breadth-first</b> <b>search</b> or depth-first search to test reachability from each vertex. Alternatively, it can be solved in time [...] where [...] is the exponent for fast matrix multiplication algorithms; this is a theoretical improvement over the [...] bound for dense graphs.|$|E
2500|$|Like <b>breadth-first</b> <b>search,</b> A* is {{complete}} {{and will always}} find a solution if one exists provided [...] for fixed [...]|$|E
40|$|Abstract. In this paper, {{we propose}} an {{algorithm}} to compute a counterexample of minimal size to some property in a finite state program, {{using the same}} programmation constraints than SPIN. This algorithm uses nested <b>Breadth-first</b> <b>searches</b> guided by priority queues. This algorithm works in quadratic time and is linear in memory,...|$|R
40|$|We {{integrate}} {{a number}} of new and recent advances in heuristic search, and apply them to the fourpeg Towers of Hanoi problem. These include frontier search, disk-based search, parallel processing, multiple, compressed, disjoint, and additive pattern database heuristics, and <b>breadth-first</b> heuristic <b>search.</b> New ideas include pattern database heuristics based on multiple goal states, a method to reduce coordination among multiple parallel threads, and a method for reducing the number of heuristic calculations. We perform the first complete <b>breadth-first</b> <b>searches</b> of the 21 and 22 -disc fourpeg Towers of Hanoi problems, and extend the verification of “presumed optimal solutions ” to thi...|$|R
40|$|When {{applied to}} {{numerical}} CSPs, the branch and prune algorithm (BPA) computes a sharp covering {{of the solution}} set. The BPA is therefore impractical when the solution set is large, typically when it has a dimension larger than four or five which is often met in underconstrained problems. The {{purpose of this paper}} is to present a new search tree exploration strategy for BPA that hybridizes depthfirst and <b>breadth-first</b> <b>searches.</b> This search strategy allows the BPA discovering potential solutions in different areas of the search space in early stages of the exploration, hence allowing an anytime usage of the BPA. The merits of the proposed search strategy are experimentally evaluated. ...|$|R
2500|$|A single {{spanning}} tree of a graph {{can be found}} in linear time by either depth-first search or <b>breadth-first</b> <b>search.</b> Both of these algorithms explore the given graph, starting from an arbitrary vertex v, by looping through the neighbors of the vertices they discover and adding each unexplored neighbor to a data structure to be explored later. They differ in whether this data structure is a [...] stack (in the case of depth-first search) or a [...] queue (in the case of <b>breadth-first</b> <b>search).</b> In either case, one can form a {{spanning tree}} by connecting each vertex, other than the root vertex v, to the vertex from which it was discovered. This tree is known as a depth-first search tree or a <b>breadth-first</b> <b>search</b> tree according to the graph exploration algorithm used to construct it. Depth-first search trees are a special case of a class of spanning trees called Trémaux trees, named after the 19th-century discoverer of depth-first search.|$|E
2500|$|... {{augment the}} given planar graph by {{additional}} edges, if necessary, {{so that it}} becomes maximal planar (every face in a planar embedding is a triangle). They then perform a <b>breadth-first</b> <b>search,</b> rooted at an arbitrary vertex v, and partition the vertices into levels by their distance from v. If l1 is the median level (the level such that the numbers of vertices at higher and lower levels are both at most n/2) then there must be levels l0 and l2 that are O(√n) steps above and below l1 respectively and that contain O(√n) vertices, respectively, for otherwise {{there would be more}} than n vertices in the levels near l1. They show that there must be a separator S formed by the union of l0 and l2, the endpoints e of an edge of G that does not belong to the <b>breadth-first</b> <b>search</b> tree and that lies between the two levels, and the vertices on the two <b>breadth-first</b> <b>search</b> tree paths from e back up to level l0. The size of the separator S constructed in this way is at most √8√n, or approximately 2.83√n. The vertices of the separator and the two disjoint subgraphs can be found in linear time.|$|E
2500|$|Determining if a graph can be colored with 2 colors is {{equivalent}} to determining {{whether or not the}} graph is bipartite, and thus computable in linear time using <b>breadth-first</b> <b>search</b> or depth-first search. More generally, the chromatic number and a corresponding coloring of [...] perfect graphs can be computed in polynomial time using semidefinite programming. Closed formulas for chromatic polynomial are known for many classes of graphs, such as forests, chordal graphs, cycles, wheels, and ladders, so these can be evaluated in polynomial time.|$|E
40|$|We {{integrate}} {{a number}} of recent advances in heuristic search, and apply them to the four-peg Towers of Hanoi problem. These include frontier search, disk-based search, multiple compressed disjoint additive pattern database heuristics, and <b>breadth-first</b> heuristic <b>search.</b> The main new idea we introduce here is the use of pattern database heuristics to search for any of {{a number of}} explicit goal states, with no overhead compared to a heuristic for a single goal state. We perform the first complete <b>breadth-first</b> <b>searches</b> of the 21 and 22 -disc four-peg Towers of Hanoi problems, and extend the verification of a “presumed optimal solution ” to this problem from 24 to 30 discs, a problem that is 4096 times larger. Four-peg Towers of Hanoi Problem The three-peg Towers of Hanoi problem is well known i...|$|R
40|$|International audienceWe {{propose a}} new {{algorithm}} for the classical problem of computing {{the diameter of}} undirected unweighted graphs, namely, the maximum distance among all the pairs of nodes, where the distance {{of a pair of}} nodes is the number of edges contained in the shortest path connecting these two nodes. Although its worst-case complexity is O(nm) time, where n is the number of nodes and m is the number of edges of the graph, we experimentally show that our algorithm works in O(m) time in practice, requiring few <b>breadth-first</b> <b>searches</b> to complete its task on almost 200 real-world graphs...|$|R
40|$|Continuations {{have proven}} to be useful for {{implementing}} a variety of control structures, including exception handling facilities and <b>breadth-first</b> <b>searching</b> algorithms. However, traditional continuations are not useful in the presence of concurrency, because the notion {{of the rest of the}} computation represented by a continuation does not in general make sense. Traditional continuations can also be difficult to use in nonconcurrent settings, since their global nature is sometimes problematic. This article presents a new type of continuation, called a subcontinuation. Just as a traditional continuation represents the rest of a computation from a given point in the computation, a subcontinuation represents the rest of a subcomputation from a given point in the subcomputation. Subcontinuations may be used to control tree-structured concurrency by allowing nonlocal exits to arbitrary points in a process tree and allowing the capture of a subtree of a computation as a composable continuati [...] ...|$|R
2500|$|... (see also [...] ) {{show that}} a perfect {{elimination}} ordering of a chordal graph may be found efficiently using an algorithm known as lexicographic <b>breadth-first</b> <b>search.</b> This algorithm maintains a partition of the vertices of the graph into a sequence of sets; initially this sequence consists of a single set with all vertices. The algorithm repeatedly chooses a vertex v from the earliest set in the sequence that contains previously unchosen vertices, and splits each set S of the sequence into two smaller subsets, the first consisting of the neighbors of v in S and the second consisting of the non-neighbors. When this splitting process has been performed for all vertices, the sequence of sets has one vertex per set, {{in the reverse of}} a perfect elimination ordering.|$|E
2500|$|A <b>breadth-first</b> <b>search</b> {{partitions}} the vertices of {{the graph}} into layers. The free vertices in [...] {{are used as}} the starting vertices of this search and form the first layer of the partitioning. At the first level of the search, there are only unmatched edges, since the free vertices in [...] are by definition not adjacent to any matched edges. At subsequent levels of the search, the traversed edges are required to alternate between matched and unmatched. That is, when searching for successors from a vertex in , only unmatched edges may be traversed, while from a vertex in [...] only matched edges may be traversed. [...] The search terminates at the first layer [...] where one or more free vertices in [...] are reached.|$|E
50|$|In {{computer}} science, lexicographic <b>breadth-first</b> <b>search</b> or Lex-BFS is {{a linear}} time algorithm for ordering the vertices of a graph. The algorithm {{is different from}} a <b>breadth-first</b> <b>search,</b> but it produces an ordering {{that is consistent with}} <b>breadth-first</b> <b>search.</b>|$|E
40|$|We {{present the}} design of a system that stores and manipulates graphs on {{secondary}} storage. The goal is to minimize the I/O needed to access arbitrary directed graphs, using a bounded amount of main memory. The two key ideas are: a heuristic method for clustering on the same disk page nodes that are likely to be accessed together, and a caching mechanism that adapts well to a variety of graph traversals, including depth-first and <b>breadth-first</b> <b>searches.</b> 1 INTRODUCTION Graphs are pervasive data modeling tools. Storing and manipulating large graphs on secondary storage can be useful in graph-oriented data management systems, such as G+ [1], hypertext systems like HAM [2, 3], or at the object storage level of objectoriented database systems. Several authors have pointed out [4, 5, 6] that most of the recursive queries that appear in practice can be viewed as graph traversals. When graphs are large, simply loading them completely into main memory (or virtual memory) and applying standard [...] ...|$|R
40|$|Most {{beautiful}} {{dreams of}} Artificial Intelligence are still unfulfilled, although some areas, for example Expert Systems, {{have made it}} through to the mainstream technology. In this paper, we propose {{a new approach to}} general problem solving that employs neuromorphic methods rather than these having their roots in formal logic. Our approach addresses many issues that are difficult to overcome in traditional, symbolic systems. The Neurosolver is a neural network based on a model of a biological cortical column. The cortical column has been found to play a fundamental role in information processing in the cerebral cortex. The model of the column presented in this paper exhibits similar functionality. The stress is laid on a cooperative behavior of many artificial columns interconnected in a network. The network is capable of recording behaviors; i. e., trajectories of time related events. These recorded trajectories let the network use time dependencies to perform <b>breadth-first</b> <b>searches.</b> T [...] ...|$|R
40|$|International audienceIn the past, several {{attempts}} have been made to deal with the state space explosion problem by equipping a depth-first search (DFS) algorithm with a state cache, or by avoiding collision detection, thereby keeping the state hash table at a fixed size. Most of these attempts are tailored specifically for DFS, and are often not guaranteed to terminate and/or to exhaustively visit all the states. In this paper, we propose a general framework of hierarchical caches which can also be used by <b>breadth-first</b> <b>searches</b> (BFS). Our method, based on an adequate sampling of BFS levels during the traversal, guarantees that the BFS terminates and traverses all transitions of the state space. We define several (static or adaptive) configurations of hierarchical caches and we study experimentally their effectiveness on benchmark examples of state spaces and on several communication protocols, using a generic implementation of the cache framework that we developed within the CADP toolbox...|$|R
5000|$|In some cases, this {{ordering}} of vertices by the output positions of their predecessors may have ties — two different vertices {{have the same}} earliest predecessor. In this case, {{the order in which}} those two vertices are chosen may be arbitrary. The output of lexicographic <b>breadth-first</b> <b>search</b> differs from a standard <b>breadth-first</b> <b>search</b> in having a consistent rule for breaking such ties. In lexicographic <b>breadth-first</b> <b>search,</b> the output ordering is the order that would be produced by the rule: ...|$|E
50|$|Using a {{distributed}} <b>breadth-first</b> <b>search</b> approach, we {{can find}} our spanning forest in O(d log3 n) time on a graph with diameter d using O(m + n log3 n) messages. The sequential approach is quite simply the running time for <b>breadth-first</b> <b>search,</b> O(m + n).|$|E
5000|$|... {{describe}} {{an extension of}} lexicographic <b>breadth-first</b> <b>search</b> that breaks any additional ties using the complement graph of the input graph. As they show, this {{can be used to}} recognize cographs in linear time. [...] describe additional applications of lexicographic <b>breadth-first</b> <b>search</b> including the recognition of comparability graphs and interval graphs.|$|E
40|$|Abstract—Optimized GPU kernels are {{sufficiently}} complicated {{to write that}} they often are specialized to input data, target architectures, or applications. This paper presents a multi-search abstraction for computing multiple <b>breadth-first</b> <b>searches</b> in par-allel and demonstrates a high-performance, general implementa-tion. Our abstraction removes the burden of orchestrating graph traversal from the user while providing high performance and low energy usage, an often overlooked component of algorithm design. Energy consumption has become a first-class hardware design constraint for both massive and embedded computing platforms. Our abstraction {{can be applied to}} such problems as the all-pairs shortest-path problem, community detection, reachability querying, and others. To map graph traversal efficiently to the GPU, our hybrid implementation chooses between processing active vertices with a single thread or an entire warp based on vertex outdegree. For a set of twelve varied graphs, the implementation of our abstraction saves 42 % time and 62 % energy on average compared to representative implementations of specific applications from existing literature. I...|$|R
40|$|Garbage {{collection}} {{can be done}} in {{vector mode}} on supercomputers like the Cray- 2 and the Cyber 205. Both copying collection and mark-and-sweep can be expressed as <b>breadth-first</b> <b>searches</b> in which the "queue" can be processed in parallel. We have designed a copying garbage collector whose inner loop works entirely in vector mode. We give performance measurements of the algorithm as implemented for Lisp CONS cells on the Cyber 205. Vector-mode garbage collection performs up to 9 times faster than scalar-mode collection [...] - a worthwhile improvement. - 1. Automatic garbage collection on vector supercomputers Languages like Lisp with dynamic storage allocation and automatic garbage collection are increasingly being used on vector supercomputers. Implementations of Lisp have been done for Cray supercomputers [1], and fully supported supercomputer Lisp environments will soon be available (e. g. Common Lisp provided by Cray Research and Franz, Inc.) [2]. This is a natural development. Languages [...] ...|$|R
40|$|In this paper, a {{neural network}} {{based on a}} model of a {{biological}} cortical column is presented. The cortical column has been found to play the fundamental role in information processing in the cerebral cortex. The model of the column presented in this work displays similar functionality. The stress is laid on the cooperative behavior of many artificial columns interconnected in a network. The network is capable of recording trajectories of time related events. Those recorded trajectories let the network use time dependencies to perform <b>breadth-first</b> <b>searches.</b> The device can solve stimulus-response type problems in a given domain and because of that is called Neurosolver. The Neurosolver can use a context update mechanism to perform dynamic searches. The Neurosolver represents the first step toward a neuromorphic general problem solver. 1. 0 Introduction The cortical column, the "module-concept", has been proposed as an anatomical entity by Szentagothai [1]. Later, Mountcastle [2] and [...] ...|$|R
50|$|Applying {{this rule}} {{directly}} by comparing vertices {{according to this}} rule would lead to an inefficient algorithm. Instead, the lexicographic <b>breadth-first</b> <b>search</b> uses a set partitioning data structure {{in order to produce}} the same ordering more efficiently, just as a standard <b>breadth-first</b> <b>search</b> uses a queue data structure to produce its ordering efficiently.|$|E
5000|$|The <b>breadth-first</b> <b>search</b> {{algorithm}} is commonly {{defined by the}} following process: ...|$|E
5000|$|Use lexicographic <b>breadth-first</b> <b>search</b> {{to find a}} lexicographic {{ordering}} of G ...|$|E
40|$|In the past, several {{attempts}} have been made to deal with the state space explosion problem by equipping a depth-first search (DFS) algorithm with a state cache, or by avoiding collision detection, thereby keeping the state hash table at a fixed size. Most of these attempts are tailored specifically for DFS, and are often not guaranteed to terminate and/or to exhaustively visit all the states. In this paper, we propose a general framework of hierarchical caches which can also be used by <b>breadth-first</b> <b>searches</b> (BFS). Our method, based on an adequate sampling of BFS levels during the traversal, guarantees that the BFS terminates and traverses all transitions of the state space. We define several (static or adaptive) configurations of hierarchical caches and we study experimentally their effectiveness on benchmark examples of state spaces and on several communication protocols, using a generic implementation of the cache framework that we developed within the CADP toolbox...|$|R
5000|$|All together, an {{iterative}} deepening search from depth [...] {{all the way}} down to depth [...] expands only about [...] more nodes than a single <b>breadth-first</b> or depth-limited <b>search</b> to depth , when [...]|$|R
40|$|Abstract. Continuations {{have proven}} to be useful for {{implementing}} a variety of control structures, including exception handling facilities and <b>breadth-first</b> <b>searching</b> algorithms. However, traditional continuations are not useful in the presence of concurrency, because the notion {{of the rest of the}} computation represented by a continuation does not in general make sense. Traditional continuations can also be difficult to use in nonconcurrent settings, since their global nature is sometimes problematic. This article presents a new type of continuation, called a subcontinuation. Just as a traditional continuation represents the rest of a computation from a given point in the computation, a subcontinuation represents the rest of a subcomputation from a given point in the subcomputation. Subcontinuations may be used to control tree-structured concurrency by allowing nonlocal exits to arbitrary points in a process tree and allowing the capture of a subtree of a computation as a composable continuation for later use. In the absence of concurrency the localized control achievable with subcontinuations makes them more useful than traditional continuations. 1...|$|R
