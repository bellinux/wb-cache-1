8|18|Public
30|$|It {{is worth}} noting that an {{appropriate}} cut-off angel is used to ignore those satellites with <b>bad</b> <b>geometry</b> and under horizon level (Hofmann-Wellenhof et al., 2008).|$|E
30|$|Figure 5 {{shows the}} {{tracking}} result of one realization, where only the estimated positions of hcEKF and EKF related to mobile node M 3 are plotted {{to avoid an}} overcrowded figure. Thanks to the HF badge detection, the hcEKF is accurately initialized, while the EKF has to be initialized to the coordinates of the scenario’s center because it can only use RSSI measures. When M 3 is in the corridor, the EKF diverges due to the <b>bad</b> <b>geometry</b> of the WSN anchor deployment while the hcEKF is able to follow the real trajectory thanks to hybridization of RFID detection and the cooperation with the other mobile nodes. When M 3 approaches room 2, the standard EKF diverges again while the hcEKF is still able to track the mobile by fusing measurements from HF badge reader and UHF-RFID tag reader.|$|E
40|$|Abstract. A {{number of}} {{three-dimensional}} algorithms {{have been proposed}} {{to solve the problem}} of patching surfaces to rectify and extrapolate missing information due to model problems or <b>bad</b> <b>geometry</b> visibility during data capture. On the other hand, a number of similar yet more simple and robust techniques apply to 2 D image data and are used for texture restoration. In this paper we make an attempt to bring these two-dimensional techniques to the 3 D domain due to their obvious advantage of simplicity and controllability. Creating a depth image with the help of a voxelisation algorithm will allow us to apply a variety of image repair algorithms in order to mend a 3 D object. The use of three variations of the texture synthesis algorithm is investigated. Constrained texture synthesis and its variations using the Haar wavelet and image decomposition methods are also proposed in order to preserve patterns appearing on the object while trying to maintain its geometry intact. ...|$|E
30|$|The {{movement}} of the platform was driven by three stepping motors, respectively. It is able {{to move in the}} Y-axis and to lift in the Z-axis, and it can also rotate around the Z-axis. During the deposition process, the GMAW torch was kept stationary, and thin-walled parts were performed by the {{movement of}} the platform in the Y-axis. After each layer was performed, the platform was lowered by a predefined layer height. It is noted that the deposition direction between adjacent layers were opposite. This is because the thin-walled part deposited in the same direction presents <b>bad</b> <b>geometries</b> {{at both ends of the}} straight wall.|$|R
40|$|RAIM (Receiver Autonomous Integrity Monitoring) {{technology}} has been developing around its two tasks (or functions). One is to detect {{whether there is a}} satellite failure. The other is to determine whether the spatial geometry of the satellites satisfies the navigational precision, pertinent to Horizontal Protection Level (HPL). This paper continues the use of the method for detecting satellite failure using statistics. Differently, it proposes a new method for calculating HPL totally based on statistics, in contrast with the former methods based on the worst-case condition or <b>bad</b> <b>geometries.</b> Its advantage is to maintain the stochastic performance indices perfectly, meanwhile to raise the availability of GPS...|$|R
40|$|A {{model for}} {{accurately}} reproducing the light curves and spectra of the scattered solar X-ray background (SB) affecting ROSAT XRT/PSPC pointed observations is presented and demonstrated. This procedure, the modeling and subtraction of the SB, {{is vital for}} analysis of all observations of extended X-ray objects and the soft X-ray diffuse background where noncosmic background constituents must be precisely known. At the orbital altitude of ROSAT, about 550 km, and the zenith angles at which the XRT/PSPC observers, 97 deg or less, the scattering is dominated by atomic oxygen with Thomson-scattered X-rays in the 1 / 4 keV band and oxygen K-alpha fluorescently scattered X-rays at 0. 54 keV. This produces field-of-view-integrated minimum count rates in the 0. 1 - 1. 0 keV band of about 0. 25 counts/s during dayside observations with excursions to about 40 counts/s or more in particularly <b>bad</b> <b>geometries.</b> Typical cosmic background count rates in the same band range from 3 to 12 counts/s, demonstrating {{the need for the}} procedure described here...|$|R
40|$|Abstract—Geolocation is an {{important}} topic nowadays. Among other applications, geolocation {{can be used by}} frequency regu-lators to monitor the time, frequency and space domain. In this case of a passive geolocation system, Time Difference of Arrival (TDOA) is often used. In this paper we analyze a geolocation system based on a combination of TDOA and Received Signal Strength Differences (RSSD). The benefit of combining the two measurement types is shown using the Cramer Rao Lower Bound (CRLB). The suitability of the Unscented Kalman Filter (UKF) as an algorithm for the hybrid geolocation system is investigated. Simulation results show that by using the UKF, the instability of RSSD geolocation, that is often caused by <b>bad</b> <b>geometry,</b> is compensated. The UKF nearly approaches the CRLB and greatly outperforms the previously proposed least squares hybrid solution. Using the UKF, the information about the signal power can be definitely used to enhance the position estimation accuracy. I...|$|E
40|$|A {{major problem}} of using GPS for {{deformation}} monitoring is signal distortion {{caused by the}} objects which form the skyline. Both local obstacles, like trees surrounding the station, and far away obstacles, like mountain ridges, lead to diffraction of the signal. In this paper we show data with corresponding biases in the observations up to 7 cm and a C/N 0 reduction of 10 - 12 dB. We discuss three different approaches to mitigate such errors. First we discuss the usage of a constant high cut-off angle when collecting or processing the observations. Alternatively, we investigate the usage of an azimuth-dependent elevation mask to cut out the affected observations. In the third approach, we discuss the mitigation of the effect using different variance models. The results show that a sufficiently high constant cut-off angle avoids diffraction effects at the obstacles, but the resulting <b>bad</b> <b>geometry</b> significantly reduces the attainable accuracy. The mitigation of the effects can either be reached by an appropriate azimuth-dependent elevation mask, or by using a variance model based on the signal-to-noise ratio, i. e. the SIGMA-ε variance model. 1...|$|E
40|$|The {{following}} thesis {{documents the}} work carried out throughout two main experiments. The first experiment analyses driver crash data and extracts from it accidents {{that may have}} occurred {{as a result of}} road segments with <b>bad</b> <b>geometry.</b> A visualisation and analysis of this crash data is presented to better determine the relationship ‘if any’ between road geometry and accident points. The second experiment then examines driver behaviour on road segments that also contain bad bends using a purpose built driving simulator. This experiment is ‘driver centric’ as it measures behaviour such as eye movement. Both experiments examine contrasting Irish roadways with an aim to better understand the driver when negotiating various geometries. Findings from the crash data analysis initially show the majority of accidents occurring on straight segments of the road types examined. However, when these accident frequencies are normalised against the percentage of road that consist of straights and bends, interesting signals appear on road types that combine sharp bends with higher road speed limits. Results from driver eye behaviour analysis show drivers fixating on regions of the road based on visible geometry or available sight distance. For example, drivers fixate on areas at the road bend while negotiating sharp bends and fixate further on or above the road surface when traversing straight segments...|$|E
50|$|YAFFS2 uses a more {{abstract}} {{definition of the}} NAND flash allowing it {{to be used with}} a wider variety of flash parts with different <b>geometries,</b> <b>bad</b> block handling rules etc.|$|R
40|$|Multiconstellation {{satellite}} navigation {{is critical in}} signal-degraded environments where signals are strongly corrupted. In this case, {{the use of a}} single GNSS system does not guarantee an accurate and continuous positioning. A possible approach to solve this problem is the use of multiconstellation receivers that provide additional measurements and allows robust reliability testing; in this work, a GPS/GLONASS combination is considered. In urban scenario, a modification of the classical RAIM technique is necessary taking into account frequent multiple blunders. The FDE schemes analysed are the “Observation Subset Testing,” “Forward-Backward Method,” and “Danish Method”; they are obtained by combining different basic statistical tests. The considered FDE methods are modified to optimize their behaviour in urban scenario. Specifically a preliminary check is implemented to screen out <b>bad</b> <b>geometries.</b> Moreover, a large blunder could cause multiple test failures; hence, a separability index is implemented to avoid the incorrect exclusion of blunder-free measurements. Testing the RAIM algorithms of GPS/GLONASS combination to verify the benefits relative to GPS only case is a main target of this work too. The performance of these methods is compared in terms of RMS and maximum error for the horizontal and vertical components of position and velocity...|$|R
40|$|A {{well known}} problem for precise {{positioning}} in real environments {{is the presence}} of outliers in the measurement sample. Its importance is even bigger in ultrasound based systems since this technology needs a direct line of sight between emitters and receivers. Standard techniques for outlier detection in range based systems do not usually employ robust algorithms, failing when multiple outliers are present. The direct application of standard robust regression algorithms fails in static positioning (where only the current measurement sample is considered) in real ultrasound based systems mainly due to the limited number of measurements and the geometry effects. This paper presents a new robust algorithm, called RoPEUS, based on MM estimation, that follows a typical two-step strategy: 1) a high breakdown point algorithm to obtain a clean sample, and 2) a refinement algorithm to increase the accuracy of the solution. The main modifications proposed to the standard MM robust algorithm are a built in check of partial solutions in the first step (rejecting <b>bad</b> <b>geometries)</b> and the off-line calculation of the scale of the measurements. The algorithm is tested with real samples obtained with the 3 D-LOCUS ultrasound localization system in an ideal environment without obstacles. These measurements are corrupted with typical outlying patterns to numerically evaluate the algorithm performance with respect to the standard parity space algorithm. The algorithm proves to be robust under single or multiple outliers, providing similar accuracy figures in all cases. status: publishe...|$|R
40|$|This paper {{presents}} an extended Kalman filter for estimating attitude sensor timing errors. Spacecraft attitude {{is determined by}} finding the mean rotation from a set of reference vectors in inertial space to the corresponding observed vectors in the body frame. Any timing errors in the observations can lead to attitude errors if either the spacecraft is rotating or the reference vectors themselves vary with time. The state vector here consists of the attitude quaternion, timetag biases, and, optionally, gyro drift rate biases. The filter models the timetags as random walk processes: their expectation values propagate as constants and white noise contributes to their covariance. Thus, this filter is applicable to cases where the true timing errors are constant or slowly varying. The observability of the state vector is studied first through {{an examination of the}} algebraic observability condition and then through several examples with simulated star tracker timing errors. The examples use both simulated and actual flight data from the Extreme Ultraviolet Explorer (EUVE). The flight data come from times when EUVE had a constant rotation rate, while the simulated data feature large angle attitude maneuvers. The tests include cases with timetag errors on one or two sensors, both constant and time-varying, and with and without gyro bias errors. Due to EUVE's sensor geometry, the observability of the state vector is severely limited when the spacecraft rotation rate is constant. In the absence of attitude maneuvers, the state elements are highly correlated, and the state estimate is unreliable. The estimates are particularly sensitive to filter mistuning in this case. The EUVE geometry, though, is a degenerate case having coplanar sensors and rotation vector. Observability is much improved and the filter performs well when the rate is either varying or noncoplanar with the sensors, as during a slew. Even with <b>bad</b> <b>geometry</b> and constant rates, if gyro biases are independently known, the timetag error for a single sensor can be accurately estimated as long as its boresight is not too close to the spacecraft rotation axis...|$|E
40|$|GPS {{positioning}} is {{a well-known}} positioning system and used in several applications. However, these signals are sent with low power and do not penetrate walls and have problems in urban areas with tall buildings. On the other hand, GPS shows advantages compared to other technologies when used outside. Since timing {{is one of the}} most important issues when it comes to positioning, some of the timing tools from the GPS can be helpful in other positioning systems. Using terrestrial communication such as television signal, which is designed to penetrate into people’s houses, makes it possible to positioning indoor and in urban areas as well. Still, this is not designed for positioning use, and there are more possible positioning errors. Depending on what the positioning is used for, the accuracy with TV signals may be enough, but when used in violence alarms and for firefighters there is a need for much higher accuracy. It is also important that the altitude can be decided. The Pseudo Television Transmitters (PTT) system has been designed for high accuracy positioning indoor, where it is crucial to reduce errors. Especially the timing and start up order is important and one of the technical things we can control. The rest of the error is often caused by multipath, and <b>bad</b> <b>geometry</b> on the transmitters. The PPT system consist of GPS receivers who give the absolute position for the transmitter, baseband transmitters with special designed antennas which broadcast the TV signals, Software signal generator, filters, and amplifiers. There is an interface controller which connects and controls all the parts and which the communications goes through. In the system discussed and the applications developed in this paper, GPS has been used as a helpful part of the system. The system needs to use GPS for absolute positioning of the baseband receivers, and provides an in common clock for the total system. It also provides a 1 Pulse per Second (1 PPS) signal which is used as a reference to make the system work together in the best way. This paper has focused on the interface controller which is the communication between the parts in the system. One of the most important parts is to optimize the timing and have a start-up sequence where the accuracy errors are reduced as much as possible. This paper is written at and for Rosum Corp, and development done is used in a system which will run live, already sold to a customer. To be able to make an optimized interface controller, a hardware unit is chosen regarding to the specification, and the start-up sequence developed, implemented and written in the programming language C...|$|E
40|$|To summarize, the {{performances}} of LS and SR-LS differ in general. The simulations and discussion here suggest that the worst-case performance ratio p 1 can be larger if the ranges d 1; [...] .;dM span a large range. While {{we believe that the}} examples and discussion here give substantial insight, we must state the complete characterization of <b>bad</b> <b>geometries</b> for SR-LS as an open problem. VI. CONCLUSION Compared to classical LS, SR-LS [1] is a computationally very attractive approach to the source localization problem, since it can find the global minimum of the cost function without resorting to heuristic divide-and-conquer methods or heuristic techniques for solving nonconvex optimization problems. We have computed and compared the asymptotic accuracies of LS and SR-LS. Our main observations are i) there exist geometries, where LS and SR-LS have identical performances and ii) there are geometries, for which the difference in performance between LS and SR-LS is unbounded. We also exemplified the asymptotic performance difference numerically for random geometries. Taken together, SR-LS performs well relative to LS for most geometries, but not for all. If SR-LS is used in practice, then care should be taken to avoid the geometries that the method has difficulties with. If the position of S is approximately known a priori, then the achievable accuracy can be estimated by using (14) and (19), before choosing what localization algorithm to use. The numerical results presented in this paper are reproducible. To obtain the relevant MATLAB programs go to www. commsys. isy. liu. se/ ~egl/rr. Included therein is also Monte Carlo simulation code for numerically verifying the validity of the asymptotic accuracy formulas that we derived...|$|R
40|$|In {{this paper}} we show how {{techniques}} from response surface methodology and mathematical programming {{can be combined}} into a new sequential derivative-free approach for solving unconstrained deterministic black-box optimization problems. In this sequential derivative-free optimization approach local approximations of the underlying objective function are optimized within a trust region framework. If the points that determine the local approximations are located in such away that the approximations become <b>bad,</b> a <b>geometry</b> improving iteration is carried out instead of an objective improving iteration. We incorporate the D-optimality criterion, well-known in design of experiments, in our approach in two different ways. Firstly, {{it is used to}} define a trust region that adapts its shape to the locations of the points in which the objective function has been evaluated. Secondly, it determines an optimal geometry improving point. An attractive feature of our approach is that it is insensitive to affine transformations. ...|$|R
40|$|Location-based {{services}} have been standardized for incorporation into 3 rd generation wireless communications {{as a result}} of the Federal Communications Commission’s (FCC) mandate on wireless carriers to provide automatic location information (ALI) during emergency 911 calls. This mandate has driven the wireless carriers to explore terrestrial, satellite, and hybrid based location technology solutions. This paper presents a communications model that investigates the position accuracy of a Global Standard Mobile (GSM) phone employing the enhanced observed time difference (EOTD) location technology. The EOTD positioning technique requires the mobile station (MS) to detect signals from at least three base stations (BS). This study assumes the three BSs are synchronized in time. For a given BS geometry with respect to the MS, a Monte Carlo simulation was performed to assess the two-dimensional position accuracy of the MS in Rayleigh and Ricean fading channels. In each channel, a Monte Carlo simulation was performed for a good and a <b>bad</b> BS-to-MS <b>geometry.</b> The paper concludes with a list of pros/cons of implementing EOTD as a location technology enabler in telematics applications...|$|R
40|$|Efficient surface {{reconstruction}} and reverse engineering techniques are usually {{based on a}} polygonal mesh representation of the geometry: the resulting models emerge from piecewise linear interpolation {{of a set of}} sample points. The quality of the reconstruction not only depends on the number and density of the sample points but also on their alignment to sharp and rounded features of the original <b>geometry.</b> <b>Bad</b> alignment can lead to severe alias artifacts. In this paper we present a sampling pattern for feature and blend regions which minimizes these alias errors. We show how {{to improve the quality of}} a given polygonal mesh model by resampling its feature and blend regions within an interactive framework. We further demonstrate sophisticated modeling operations that can be implemented based on this resampling technique. 1...|$|R
40|$|Keywords- {{finite element}} method; impeller; stress Abstract. For the large {{centrifugal}} fan impeller, its working condition generally is <b>bad,</b> and its <b>geometry</b> generally is complex. So its displacements and stresses distribution are also complex. In this paper, we can obtain the fan impeller’s displacements and stresses distribution accurately through numerical simulation in G 4 - 73 type centrifugal fan impeller using the {{finite element method}} software ANSYS. The calculation result shows that the maximum total displacement of the impeller is 310303. 0 − × m, it occurs on {{the position of the}} half of the blade near the outlet of the impeller; and the maximum equivalent stress of the impeller is 193 MPa, it occurs on the contacted position of the blade and the shroud near inlet of the impeller. Furthermore, check the impeller strength, the result shows that the strength of the impeller can meet the requirement...|$|R
40|$|One of {{the main}} {{applications}} of the terrestrial laser scanner is the visualization, modeling and monitoring of man-made structures like buildings. Especially surveying applications require on one hand a quickly obtainable, high resolution point cloud but also need observations with a known and well described quality. To obtain a 3 D point cloud, the scene is scanned from different positions around the considered object. The scanning geometry {{plays an important role}} in the quality of the resulting point cloud. The ideal set-up for scanning a surface of an object is to position the laser scanner in such a way that the laser beam is near perpendicular to the surface. Due to scanning conditions, such an ideal set-up is in practice not possible. The different incidence angles and ranges of the laser beam on the surface result in 3 D points of varying quality. The stand-point of the scanner that gives the best accuracy is generally not known. Using an optimal stand-point of the laser scanner on a scene will improve the quality of individual point measurements and results in a more uniform registered point cloud. The design of an optimum measurement setup is defined such that the optimum stand-points are identified to fulfill predefined quality requirements and to ensure a complete spatial coverage. The additional incidence angle and range constraints on the visibility from a view point ensure that individual scans are not affected by <b>bad</b> scanning <b>geometry</b> effects. A complex and large room that would normally require five view point to be fully covered, would require nineteen view points to obtain full coverage under the range and incidence angle constraints. ...|$|R
40|$|Native subject-specific knee {{geometries}} {{are usually}} based on CT and MRI images reconstruction. Unfortunately, while {{the definition of}} bone geometries using CTs is quite consistent, MRIs are often hardly readable, due to the usual lower resolution, and the final shape of cartilage and menisci is not consequently detailed enough. Moreover, further smoothing techniques, necessary to efficiently use these structures for numerical modeling, could result in <b>bad</b> interfaces and/or <b>geometry</b> inaccuracies. In this study a CAD-based approach to generate 3 D cartilages and menisci geometries, avoiding the use of MRIs, was proposed and tested versus the traditional methods that use MRIs segmentation. The femoral, tibial and patellar cartilage layers were generated as offset from the bone geometries, the menisci were obtained by an extrusion based on tibia borders. Such geometries were compared to the reconstructions obtained from MRIs of healthy knee specimens. Overlapping the resulting geometries with the ones traditionally reconstructed, volumes differ from 2 % to 14 %. By using the new methodology, the geometries are obtained in 75 % less time. The CAD-based methods shown in this pilot study is able to generate faster and accurate subject-specific knee cartilage layers and menisci geometries and can be suitable to be applied for numerical modeling. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|Using CORS {{networks}} for land reconstruction after earthquakes and tsunamis is challenging {{due to the}} limited infrastructure remaining after the event. Normally, CORS networks are set up in well established cities of regions with developed infrastructure and utilities. The functionality of a CORS approach is suitable to re-establish more than 10, 000 land parcels in Aceh affected by the tsunami, but can this method still be useful with limited infrastructure? Also, can a CORS network feasibly re-establish cadastral land parcel boundaries previously based on bearings and distances using coordinates? This is a very crucial problem as often no survey marks exist to re-establish property boundaries. CORS networks can provide an external infrastructure allowing the identification of existing survey marks and the lay out of new and existing parcels for {{a large number of}} independent users. Using sophisticated network RTK algorithms, larger inter-receiver distances allow CORS networks 10 cover large areas with a minimal number of reference stations reducing the cost of operations. Also in equatorial regions, such as Aceh, where ionospheric activity is expected to be higher, a slightly denser array of CORS stations ensures reliable initialization. This thesis tries to investigate the utilization of temporary CORS network approach; that is using some higher order stations as base station monuments, setting up a temporary CORS network over a small region and when operations are completed. packing up the system and moving to an adjacent network of high order monuments which comprise a new temporary CORS networks. Due to logistical consideration during the organization of this project, real-time communications were not used in Aceh and only GPS data was logged in the field. Reference stations logged 24 hours of GPS data and were processed using the free online service from AUSPOS. These coordinates are then used in a post-processed simulation mode using the Leica SpiderNet software. As a comparison, there is a similar simulation that has been conducted using the well established network RTK GPS infrastructure that belongs to Singapore Land Authority (SLA) in Singapore. The Aceh data simulation showed that the network. RTK suffered from <b>bad</b> network <b>geometry</b> and lack of the common satellite number. On the other hand, the SLA data struggled in network ambiguity resolution due to ionospheric activity in equatorial region. Overall, single based and network RTK GPS is still reliable if it is used in land reconstruction in equatorial region. But it has to give more attention in the extending range and high density of reference stations...|$|R
40|$|Global Navigation Satellite Systems (GNSS) {{integrity}} {{is defined as}} a measure of the trust that can be placed in the correctness of the information supplied by the navigation system. Although the concept of GNSS integrity has been originally developed in the civil aviation framework as part of the International Civil Aviation Organization (ICAO) requirements for using GNSS in the Communications, Navigation, and Surveillance / Air Traffic Management (CNS/ATM) system, a wide range of non-aviation applications need reliable GNSS navigation with integrity, many of them in urban environments. GNSS integrity monitoring is a key component in Safety of Life (SoL) applications such as aviation, and in the so-called liability critical applications like GNSS-based electronic toll collection, in which positioning errors may have negative legal or economic consequences. At present, GPS integrity monitoring relies on different augmentation systems (GBAS, SBAS, ABAS) that have been conceived to meet the ICAO requirements in civil aviation operations. For this reason, the use of integrity monitoring techniques and systems inherited from civil aviation in non-aviation applications needs to be analyzed, especially in urban environments, which are frequently more challenging than typical aviation environments. Each application has its own requirements and constraints, so the most suitable integrity monitoring technique varies from one application to another. This work focuses on Electronic Toll Collection (ETC) systems based on GNSS in urban environments. Satellite navigation is one of the technologies the directive 2004 / 52 /EC recommends for the European Electronic Toll Service (EETS), and it is already being adopted: toll systems for freight transport that use GPS as primary technology are operational in Germany and Slovakia, and France envisages to establish a similar system from 2013. This dissertation begins presenting first the concept of integrity in civil aviation {{in order to understand the}} objectives and constraints of existing GNSS integrity monitoring systems. A thorough analysis of GNSS-based ETC systems and of GNSS navigation in urban environments is done afterwards with the aim of identifying the most suitable road toll schemes, GNSS receiver configurations and integrity monitoring mechanisms. Receiver autonomous integrity monitoring (RAIM) is chosen among other integrity monitoring systems due to its design flexibility and adaptability to urban environments. A nominal pseudorange measurement model suitable for integrity-driven applications in urban environments has been calculated dividing the total pseudorange error into five independent error sources which can be modelled independently: broadcasted satellite clock corrections and ephemeris errors, ionospheric delay, tropospheric delay, receiver thermal noise (plus interferences) and multipath. In this work the fault model that includes all non-nominal errors consists only of major service failures. Afterwards, the GNSS integrity requirements are derived from the relationship between positioning failures and toll charging errors. Two RAIM algorithms are studied. The first of them is the Weighted Least Squares Residual (WLSR) RAIM, widely used in civil aviation and usually set as the reference against which other RAIM techniques are compared. One of the main challenges of RAIM algorithms in urban environments is the high unavailability rate because of the <b>bad</b> user/satellite <b>geometry.</b> For this reason a new RAIM based on the WLSR is proposed, with the objective of providing a trade-off between the false alarm probability and the RAIM availability in order to maximize the probability that the RAIM declares valid a fault-free position. Finally, simulations have been carried out to study the performance of the different RAIM and ETC systems in rural and urban environments. In all cases, the availability obtained with the novel RAIM improve those of the standard WLSR RAIM...|$|R
40|$|This thesis {{consists}} of three essays in development economics. The first chapter investigates urban form in India. I focus {{on one of the}} determining factors of urban commuting efficiency, highlighted by urban planners but overlooked by economists: city shape. I retrieve the geometric properties of urban footprints in India over time, using satellite data on nighttime lights and historic maps. I propose an instrument for urban shape based on the interaction between topographic obstacles arid mechanically predicted city growth. I then investigate how city shape affects the location choices of consumers and firms, in a spatial equilibrium framework. More compact cities are characterized by larger population, lower wages, and higher rents, consistent with compact shape being a consumption amenity. The welfare cost of deteriorating city shape is estimated to be sizeable. The effects of unfavorable topography appear to be exacerbated by building height restrictions, and mitigated by infrastructure. The second chapter examines the human capital effects of inheritance law in Kenya. I study a 1981 statutory law reform granting Kenyan women equal inheritance rights. I employ a difference-in-differences strategy, exploiting variation in pre-reform inheritance rules across religious groups. Women exposed to the reform are more educated, less likely to undergo genital mutilation and more likely to be medically assisted during childbirth; they also tend to delay childbearing and to have better marriage market outcomes. These effects are more pronounced for women with fewer siblings, for whom the absolute inheritance share is potentially larger. In the third chapter, my coauthor Eliana La Ferrara and I conduct a disaggregated empirical analysis of civil conflict at the sub-national level in Africa over 1997 - 2011, using new gridded data. We construct an original measure of agriculture-relevant shocks exploiting within-year variation in weather and in crop growing season, and spatial variation in crop cover. Temporal and spatial spillovers in conflict are addressed through spatial econometric techniques. Negative shocks during the growing season of local crops affect conflict incidence persistently, and local conflict then spills over in space. We use our estimates to trace the dynamic response to shocks and predict how future warming may affect violence. Cities in <b>Bad</b> Shape: Urban <b>Geometry</b> in India [...] Women's Inheritance Rights and Bargaining Power: Evidence from Kenya [...] Conflict, Climate and Cells: a Disaggregated Analysis. by Mariaflavia Harari. Thesis: Ph. D., Massachusetts Institute of Technology, Department of Economics, 2016. Cataloged from PDF version of thesis. Includes bibliographical references (pages 149 - 159) ...|$|R
40|$|In {{this work}} a GNSS {{navigation}} filter is developed and procedures are derived {{in order to}} provide integrity of the navigation solution. The position solution has to meet high accuracy demands, for example those of zero-visibility precision approach. Therefore, low-noise carrier phase measurements are processed in addition to the GNSS pseudorange measurements. It is essential to resolve the ambiguities of the carrier phase measurements quickly and reliably in order to support high-accuracy real-time kinematic (RTK) positioning. Ambiguity resolution relies in this work on a geometry-based model. It is expected for the near future that the satellite geometry and the signal quality will improve, since GPS is planned to be modernized and GALILEO will be operational. Both factors are relevant for making progress in the domain of RTK carrier phase-based relative positioning. This study is restricted to the use of dualfrequency measurements in order to ensure compatibility with the requirements of civil aviation with respect to the Aeronautical Radio-Navigation Service (ARNS) bands. GPS’s L 1 and L 5 signals or GALILEO’s E 1 and E 5 a signals are considered as measurement input to the filter. The user position and velocity vector, the ambiguities of the phase measurements and ionospheric terms are estimated by the filter. The performance of three different ionosphere models has been investigated. Although the estimation of ionospheric range errors is improved by processing measurements on two different frequencies, the results are only very good in absence of unmodeled biases. For example, if multiple measurements are biased by multipath it might happen that these un-modeled biases intrude into the ionosphere state estimation. The unknown states are only estimated reliably by the Extended Kalman Filter (EKF) if all un-modeled error sources were white Gaussian noise. Both multipath errors and residual tropospheric range errors after double-differencing are neglected in this filter approach. Alternatively to estimating the residual ionospheric errors it has also been considered to utilize ionosphere-free linear combinations. The user velocity vector is derived from instantaneous Doppler shift measurements. All measurements which are processed by the filter are double-differenced {{in order to keep the}} number of parameters to be estimated as small as possible. The disadvantage of doubledifferencing is that the measurement noise is amplified. By implementing the standard equations of the EKF numeric stability cannot be assured. Numerical problems were avoided by choosing the Bierman-Thornton UD filter implementation for the problem at hand. Though, it is already sufficient to make the standard EKF equations more robust by implementing the Joseph form for the update of the covariance matrix of state estimation uncertainty. After introducing this measures in order to improve numeric robustness of the filter in presence of computer round-off errors, no further numerical problems where observed any longer in the succeeding simulation runs. Because of the usage of an EKF it is difficult to derive the integrity risk analytically. The results depend on filter initialization and the concrete data sequence. However, a linear Kalman filter produces optimal state estimates by minimizing the sum of the mean-square errors. The integrity risk can be estimated for the nonlinear navigation filter solution by making some restrictive assumptions. Nevertheless, the effective integrity risk has to be determined by excessive simulations. Autonomous Filter-based fault Detection, Identification and model Adaptation (AFDIA) is proposed in order to detect model invalidations and to compensate them. So far only single-channel biases can be detected and corrected, although the extension to multiple biases is possible, but complex. In the navigation algorithm tests all simulated cycle slips and code outliers were detected successfully and the model was adapted properly afterwards. Protection levels are computed for both the user position estimates and the user velocity estimates. The derivation of the protection levels for the filter-based approach is restricted to two mutually exclusive hypotheses: normal operation of the filter in absence of biases and the fault mode if there is one bias in the measurement data. The non-Gaussian tails of the error distributions are accounted for by introducing inflation factors in the computation of the protection levels. This procedure is referred to as sigma-overbounding. The performance of the navigation filter and the plausibility of the protection levels have been verified by Monte-Carlo simulations. In addition, real-signal tests of a precision approach have been carried out with a hardware simulator and a GALILEO receiver. The accuracy of the position estimates and the magnitude of the protection levels strongly depend on the availability of a carrier phase ambiguity-fixed solution. The float solution is already very accurate after the first hundred observation epochs because of the filter-based approach. In the Monte-Carlo simulations the carrier phase ambiguities could be typically fixed at a baseline length of 20 km between the user receiver and the reference receiver. The probability of wrong ambiguity fixing has been set to 1 · 10 - 9. Successful carrier phase ambiguity resolution is demonstrated in the real-signal tests for a baseline length of 54 km, where the navigation filter has been started when the airplane was about 75 km away from the airport. The results of the real-signal tests are very good because of the availability of low-noise E 5 a pseudorange measurements. Furthermore, only ionospheric delays have been simulated with the hardware simulator. Tropospheric delays and multipath were neglected. The Vertical Protection Level (VPL) of the carrier phase ambiguity fixed position solution is below 20 cm under the condition of good satellite geometry. The associated integrity risk is assumed to be at the order of 3 · 10 - 9. If there are only few visible satellites, the VPL may be as large as 2 m although the ambiguities have already been fixed correctly. There is a great difference between the fault-mode protection level and the fault-free protection level. With respect to <b>bad</b> satellite <b>geometry,</b> the fault-mode protection level clearly dominates the overall protection level. The performance results of the navigation filter are very promising with respect to the position accuracy and the magnitude of the protection levels which can be achieved. Since the actual integrity risk has to be assessed by simulations, it is rather difficult to proof that the integrity risk is indeed in the range of 10 - 9, which is required for zero-visibility precision approach in civil aviation. The application of the navigation filter in domains where even higher position accuracy than in civil aviation is required, but where the specified integrity risk can still be verified by simulations, seems to be more likely. Several airport-related applications can be listed, for example automated cargo traffic, taxiing and coasting, but also precision approach in the military domain...|$|R
40|$|The {{aviation}} {{community has}} to implement very stringent navigation integrity requirements {{in a variety}} of manned and unmanned aircraft applications. This thesis presents the results of the research activities carried out by the Italian Air Force Research and Flight Test Centre (CSV-RSV) in collaboration with the Nottingham Geospatial Institute (NGI) and RMIT University in the area of Avionics Based Integrity Augmentation (ABIA) for mission-essential and safety-critical Global Navigation Satellite Systems (GNSS) applications in the civil/military aviation context. Space and Ground Based Augmentation Systems (SBAS/GBAS) have been developed in recent years to improve GNSS integrity, accuracy and availability for aircraft navigation and particularly for landing applications. SBAS satellites broadcast correction messages back to the earth, where suitably enabled receivers use the information to improve accuracy and integrity. The US, Europe and other nations have developed their own SBAS systems. In the US, the Wide Area Augmentation System (WAAS) exists and is operational. In Europe, SBAS coverage is provided by the European Geostationary Navigation Overlay Service (EGNOS), in Japan by the Multi-functional Satellite Augmentation System (MSAS) and India is developing the GNSS Aided Geo Augmented Navigation (GAGAN) system. An alternative approach to GNSS augmentation is to transmit integrity and correction messages from ground-based systems. An example is the American Local Area Augmentation System (LAAS), which allows a suitably equipped receiver to derive enhanced accuracy and integrity information in a local area. The combination of WAAS and LAAS is targeted to provide the Required Navigation Performance (RNP) in all phases of aircraft navigation, including en-route, terminal, approach/landing and surface operations. Along with SBAS and GBAS, GNSS augmentation may take the form of additional information being provided by other avionics systems. In most cases, the additional avionics systems operate via separate principles than GNSS and, therefore, are not subject to the same sources of error or interference. A system such as this is referred to as an Aircraft Based Augmentation System (ABAS). The additional sensors used in ABAS may include Inertial Navigation Systems (INS), TACAN/VOR-DME, Radar, Vision Based Sensors, etc. Unlike SBAS and GBAS technology, research on ABAS is limited and mainly concentrates on additional information being blended into the position calculation to increase accuracy and/or continuity of the integrated navigation solutions. Additionally, no significant attempts have been made of developing ABAS architectures capable of generating integrity signals suitable for safety-critical GNSS applications (e. g., aircraft precision approach and landing) and no flight certified ABAS products are available at present. During flight test activities with GNSS and Differential GNSS (DGNSS) systems, it was observed that {{one or more of the}} following conditions was prone to cause navigation data outages or severe performance degradations: • Antenna obscuration due to aircraft manoeuvring; • <b>Bad</b> satellite <b>geometries</b> and low carrier-to-noise ratios (C/N 0); • Doppler shifts caused by aircraft-satellites relative motion; • Interference, at the airborne GNSS antenna, caused by non-GNSS RF signals; • Multipath caused by GNSS signals reflected by the earth surface or the aircraft body. The last two problems can be mitigated by existing technology solutions (i. e., choosing a VHF/UHF Data Link, filtering the radio frequency signals reaching the GNSS antenna, identifying suitable locations for the GNSS antenna and providing adequate shielded of the antenna itself, either by physical devices or via dedicated software masks, etc.). However, there is little one can do in order to prevent critical events during realistic test/training manoeuvres and particular approach procedures (e. g., curved and segmented approaches) performed with high performance military aircraft. Furthermore, although in some cases a careful mission planning may significantly reduce the number of GNSS outages, the adoption of specific aircraft piloting strategies (using the information currently available in the cockpit) cannot effectively avoid the occurrence of these events. ABIA is a new concept that progressively evolved based on research with GNSS-based Time and Space Position Information (TSPI) systems. TSPI research activities included design, integration and ground/flight testing carried out on MB- 339 CD, TORNADO and TYPHOON military aircraft. As soon as the validity of the TSPI-ABIA (T-ABIA) concept was established, a prototype system was developed for use in flight test applications. This system is capable of alerting the pilot when the critical conditions for GNSS signal loss are likely to occur (within a specified maximum time-to-alert). In this T-ABIA prototype, the aircraft on-board sensors provide information on the aircraft relevant flight parameters (navigation data, engine settings, etc.) to an Integrity Flag Generator (IFG), which is also connected to the on-board GNSS receiver. The IFG can be incorporated into one of the existing airborne computers or can be a dedicated processing unit. Using the available data on GNSS and the aircraft flight parameters, integrity signals are generated which are displayed on one of the cockpit displays and sent to an Aural Warning Generator. At the same time, an alternate flight path is computed taking into account the geometry and the tracking status of the available GNSS satellites, together with the current mission requirements and the information provided by the aircraft Flight Test Instrumentation (FTI) and standard on-board sensors. Based on the results of T-ABIA research a more advanced ABIA system was developed suitable for manned and unmanned aircraft applications. Detailed mathematical algorithms were developed to cope with the main causes of GNSS signal outages and degradation in flight, namely: obscuration, multipath, interference, fading due to adverse geometry and Doppler shift. Adopting these algorithms, the ABIA system is able to provide steering information to the pilot and electronic commands to the aircraft flight control system, allowing real-time avoidance of safety-critical flight conditions and fast recovery of the required navigation performance in case of GNSS data losses. This is achieved by implementing both caution (predictive) and warning (reactive) integrity flags, as well as 4 -Dimensional Trajectory (4 DT) optimisation models suitable for all phases of flight. The detailed design of the ABIA IFG module was completed and validation activities were performed on TORNADO-IDS, A- 320 and AEROSONDE UAV simulated platforms to determine the Time-to-Alert (TTA) performances of the ABIA system in various flight phases from departure to final approach. The results of these activities were encouraging, showing that the system TTA performance is in line with current ICAO, FAA and CAA requirements for the different flight phases, with a potential synergy with SBAS and GBAS systems to support departure, en-route and TMA operations, including CAT-I/III precision approach. Further research concentrated on the 4 DT computation module and extended the scope of ABIA applications to Unmanned Aircraft Systems (UAS). In particular, an initial investigation was accomplished to identify the potential synergies of ABIA with UAS Sense-and-Avoid (SAA) architectures for mid-air collision avoidance tasks. In conclusion, although current and likely future SBAS/GBAS augmentation systems can provide significant improvement of GNSS navigation performance, it is shown that the novel ABIA system developed in this research can play a key role in GNSS integrity augmentation for mission-essential and safety-critical applications such as aircraft precision approach/auto-landing and UAS sense-and-avoid. Furthermore, using suitable data link and data processing technologies, a certified ABIA system could play a key role as part of a future GNSS Space-Ground-Aircraft Augmentation Network (SGAAN) ...|$|R

