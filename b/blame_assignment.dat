41|7|Public
40|$|Fault {{diagnosis}} in networked {{systems has}} been an extensively studied field in systems engineering. Fault diagnosis generally includes the tasks of fault detection and isolation, and optionally recovery (FDIR). In this paper we further consider the <b>blame</b> <b>assignment</b> problem: given a system trace on which a system failure occurred and an identified set of faulty components, determine which subsets of faulty components are the culprits for the system failure. We provide formal definitions of the notion culprits and the <b>blame</b> <b>assignment</b> problem, under the assumptions that only one system trace is given and the system cannot be rerun. We show {{that the problem is}} equivalent to deciding the unsatisfiability of a set of logical constraints on component behaviors, and present the transformation from a <b>blame</b> <b>assignment</b> instance into an instance of unsatisfiability checking. We also apply the approach to a case study in the medical device interoperability scenario that has motivated our work...|$|E
40|$|Pre/post {{contracts}} for higher-order functions, {{as proposed by}} Findler and Felleisen and provided in Racket, allow run-time verification and <b>blame</b> <b>assignment</b> of higher-order functions. However these contracts treat contracted functions as black boxes, allowing verification of only input and output. It turns out that many interesting concerns about the behaviour of a function require going beyond that black-box approach, {{in order to control}} the actual computation that follows from a function. Examples are prohibiting or verifying that certain functions are called, checking access permissions, time or memory constraints, interaction protocols, etc. To address this need for grey-box verification, while preserving support for higher-order programming and <b>blame</b> <b>assignment,</b> we introduce the notion of computational contracts. A computational contract is a contract over the execution of a contracted entity. We show various applications of computational contracts, and explain how to assign blame in case of a violation. Computational contracts have been integrated with the existing contract system of Racket. Computational contracts is the first contract model with <b>blame</b> <b>assignment</b> in a higher-order setting that provides a systematic way to perform grey box verification. 1...|$|E
40|$|Contract {{systems and}} hybrid type systems provide two {{alternative}} approaches for enforcing precisely-defined interface specifications, with complementary advantages: contract systems excel at <b>blame</b> <b>assignment,</b> whereas hybrid type systems support type-based static analysis. We unify these two approaches by demonstrating that hybrid type checking is sufficiently expressive to encode higher-order contracts with proper <b>blame</b> <b>assignment.</b> In particular, a contract obligation that enforces {{both sides of}} a contract is decomposed into two type casts that each enforce one side of the contract. This expressiveness result provides several benefits, including allowing one of these casts to be lifted from variable references to variable definitions, resulting in improved contract coverage and removing the need for privileged contract obligations. ...|$|E
40|$|Abstract Program {{errors are}} hard to detect and are costly both to program-mers who spend {{significant}} efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniqueshave been applied to imperative and object-oriented languages, like Java and C#, but few have been applied to a higher-order lazy func-tional language, like Haskell. In this paper, we describe a sound and automatic static verification tool for Haskell, that is based oncontracts and symbolic execution. Our approach is modular and gives precise <b>blame</b> <b>assignments</b> at compile-time in the presence ofhigher-order functions and laziness...|$|R
40|$|Program {{errors are}} hard to detect and are costly both to programmers who spend {{significant}} efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C#, but few have been applied to a higher-order lazy functional language, like Haskell. In this paper, we describe a sound and automatic static verification framework for Haskell, {{that is based on}} contracts and symbolic execution. Our approach is modular and gives precise <b>blame</b> <b>assignments</b> at compile-time in the presence of higher-order functions and laziness. D. 3 [Software]: Program...|$|R
40|$|This article {{presents}} {{an overview of}} empirical research {{on the role of}} observer variables in rape victim blaming (female attacked by a male perpetrator). The focus is on literature from the last 15 years. The variables observer gender, ambivalent sexism, rape myth acceptance, and rape empathy are discussed in relation to victim blaming. Most research on rape is conducted using diverse methods and approaches that result in a great disparity regarding the role of these variables in predicting <b>blame</b> <b>assignments.</b> Despite the inconsistencies, most studies show that men hold the victim more responsible for her own victimization than women. Findings further indicate that higher scores on sexist ideologies and rape myth acceptance predict higher victim blame, and that higher rape empathy scores predict lower victim blame. Theoretical and practical implications are discussed...|$|R
40|$|AbstractIn {{this article}} we present a model for multiparty {{contracts}} in which contract conformance is defined abstractly as a property on traces. A key feature of our model is <b>blame</b> <b>assignment,</b> which means that for a given contract, every breach is attributed {{to a set of}} parties. We show that <b>blame</b> <b>assignment</b> is compositional by defining contract conjunction and contract disjunction. Moreover, to specify real-world contracts, we introduce the contract specification language CSL with an operational semantics. We show that each CSL contract has a counterpart in our trace-based model and from the operational semantics we derive a run-time monitor. CSL overcomes limitations of previously proposed formalisms for specifying contracts by supporting: (history sensitive and conditional) commitments, parametrised contract templates, relative and absolute temporal constraints, potentially infinite contracts, and in-place arithmetic expressions. Finally, we illustrate the general applicability of CSL by formalising in CSL various contracts from different domains...|$|E
40|$|<b>Blame</b> <b>assignment</b> is a {{classical}} problem in learning and adaptation. Given a problem solver {{that fails to}} deliver the behaviors desired of it, the blame-assignment task has the goal of identifying the cause(s) of the failure. Broadly categorized, these causes can be knowledge faults (errors in the organization, content, and representation of the problemsolver 's domain knowledge) or processing faults (errors in the content, {{and control of the}} problem-solving process). Much of AI research on <b>blame</b> <b>assignment</b> has focused on identifying knowledge and control [...] of [...] processing faults based on the trace of the failed problem-solving episode. In this paper, we describe a blame-assignment method for identifying content [...] of [...] processing faults, i. e., faults in the specification of the problem-solving operators. This method uses a structure [...] behavior [...] function (SBF) model of the problemsolving process, which captures the functional semantics of the overall task and the operators of the problem solv [...] ...|$|E
40|$|A (multi-party) {{contract}} is a legally binding agreement between individuals or companies {{that describes the}} commitments of each contract participant. For enterprises, contracts serve as the external interface to their clients, and consequently {{it is crucial to}} monitor the execution of these contracts for violations, and to comply with them in order to avoid financial penalties. In this paper we present a trace-based model for multi-party contracts, in which contract conformance is defined abstractly as a property on traces. A highlight of our model is <b>blame</b> <b>assignment,</b> which means that all contract violations are attributed to contract participants, and we analyze how <b>blame</b> <b>assignment</b> affects compositionality. Moreover, in order to specify contracts, we introduce a contract specification language, CSL, which is given a formal semantics by means of a mapping into the abstract model, and which overcomes the limitations of existing contract languages by supporting (a) (history sensitive and conditional) commitments, (b) parametrized contract templates, (c) relative and absolute temporal constraints, (d) contrary-to-duty obligations, (e) potentially infinite contracts, and (f) arithmetic expressions. Last but not least, CSL admits run-time monitoring via rewriting...|$|E
5000|$|Personal responsibility: People can {{no longer}} <b>blame</b> bad project <b>assignments</b> or inept {{immediate}} managers for underperformance, since those are results of their own choices. A person who worked on a bad project, in an open-allocation environment, is at fault.|$|R
40|$|Program {{errors are}} hard to detect and are costly, to both programmers who spend {{significant}} efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C#, for checking basic safety properties such as memory leaks. In a pure functional language, many of these basic properties are guaranteed by design, which suggests the opportunity for verifying more sophisticated program properties. Nevertheless, few automatic systems for doing so exist. In this thesis, we show the challenges and solutions to verifying advanced properties of a pure functional language, Haskell. We describe a sound and automatic static verification framework for Haskell, {{that is based on}} contracts and symbolic execution. Our approach gives precise <b>blame</b> <b>assignments</b> at compile-time in the presence of higher-order functions and laziness. First, we give a formal definition of contract satisfaction which {{can be viewed as a}} denotational semantics for contracts. We then construct two contract checking wrappers, which are dual to each other, for checking the contract satisfaction. We prove the soundness and completeness of the construction of the contract checking wrappers with respect t...|$|R
5000|$|The Pittsburgh Steelers played poorly {{for three}} quarters, {{allowing}} the Buccaneers {{to take a}} 12-0 lead despite the coaching staff's admonitions not to be fooled by the Buccaneers' 0-8 record. James Wilder's 42 carries broke Franco Harris' NFL record, Bill Capece kicked four field goals, and the defense forced seven turnovers. Newcomer Beasley Reece caught two of Cliff Stoudt's three interceptions. The Buccaneer offense was held without a touchdown. The Steelers came {{to life in the}} fourth quarter with rookie Wayne Capers' first NFL touchdown reception, a 57-yard punt return by Paul Skansi that set up a 42-yard Gary Anderson field goal, and a 2-yard Frank Pollard touchdown run. A wide-open Kevin House dropped a potentially game-winning touchdown pass in the fourth quarter. McKay's entire postgame press conference consisted of two sentences: [...] "We did not play well enough to win. We lost our ninth straight game and that is it". McKay later <b>blamed</b> blown <b>assignments</b> and media distractions for the loss. He said that players were bothered by rumors that injured linebacker Andy Hawkins had signed with a USFL team.|$|R
40|$|This paper {{presents}} {{the knowledge base}} refmement rnetl 1 cx of NeoDisciple. The method is based 00 two levels of cooperation. Internally. different learning strategies cooperate in solving the knowledge base refinement problem. Externally. NeoDisciple and the human expen cooperate in solving the problems that are intrinsically difficult for an autonomous learning system as. for instance. the new terms problem and the <b>blame</b> <b>assignment</b> problem. The goal is to show the adequacy of such an approach for me automation ofknowledge acquisition. ...|$|E
40|$|Previous work on {{software}} contracts assumes fixed and statically known boundaries {{between the parties}} to a contract. Implementations of contract monitoring systems rely on this assumption to explain the nature of contract violations and to assign blame to violators. In this paper, we explain how to implement arbitrary, nested, and dynamic contract boundaries with two examples. First, we add nestable contract regions to a static, first-order module system. Second, we show that even a dynamic, higher-order, and hierarchical module system can be equipped with software contracts that support precise <b>blame</b> <b>assignment...</b>|$|E
40|$|Behavioral {{software}} contracts supplement interface {{information with}} logical assertions. A rigorous enforcement of contracts provides useful feedback to developers if it signals contract violations {{as soon as}} they occur and if it assigns blame to violators with precise explanations. Correct <b>blame</b> <b>assignment</b> gets programmers started with the debugging process and can significantly decrease the time needed to discover and fix bugs. Sadly the literature on contracts lacks a framework for making statements about the correctness of <b>blame</b> <b>assignment</b> and for validating such statements. This paper fills the gap and uses the framework to demonstrate how one of the proposed semantics for higher-order contracts satisfies this criteria and another semantics occasionally assigns blame to the wrong module. Concretely, the paper applies the framework to the lax enforcement of dependent higher-order contracts and the picky one. A higher-order dependent contract specifies constraints for the domain and range of higher-order functions and also relates arguments and results in auxiliary assertions. The picky semantics ensures that the use of arguments in the auxiliary assertion satisfies the domain contracts and the lax one does not. While the picky semantics discovers more contract violations than the lax one, it occasionally blames the wrong module. Hence the paper also introduces a third semantics, dubbed indy, which fixes the problems of the picky semantics without giving up its advantages...|$|E
40|$|Abstract. A robust {{software}} component fulfills a contract: it expects data satisfying a certain property {{and promises to}} return data satisfying another property. The object-oriented community uses the design-bycontract approach extensively. Proposals for language extensions that add contracts to higher-order functional programming have appeared recently. In this paper we propose an embedded domain-specific language for typed, higher-order and first-class contracts, which is both more expressive than previous proposals, and allows for a more informative <b>blame</b> <b>assignment.</b> We take some first steps towards an algebra of contracts, and we show how to define a generic contract combinator for arbitrary algebraic data types. The contract language is implemented as a library in Haskell using the concept of generalised algebraic data types. ...|$|E
40|$|Accurate <b>blame</b> <b>assignment</b> for {{security}} violations {{is essential in}} a wide range of settings. For example, proto-cols for authentication and key exchange, electronic voting, auctions, and secure multiparty computation (in the semi-honest model) ensure desirable security properties if pro-tocol parties follow their prescribed programs. However, if they deviate from their prescribed programs and a security property is violated, determining which agents should be blamed and appropriately punished is important to deter agents from committing future violations [1]. Our vision is that actual causation (i. e., identifying which agents’ deviations caused a specific violation) is a useful building block for blame-assignment. The central contribution of this work is formalizing and reasoning about actual causation i...|$|E
40|$|Human {{experience}} with interactive {{games will be}} enhanced if the game-playing software agents learn from their failures and do not make the same mis-takes over and over again. Reinforcement learning, e. g., Q-Learning, provides one method for learning from failures. Model-based meta-reasoning that uses an agent’s self-model for <b>blame</b> <b>assignment</b> provides another. In this paper, we combine the two methods. We describe an experimental inves-tigation of a specific task (defending a city) in a computer war strategy game called FreeCiv. Our results indicate that in the task examined, model-based meta-reasoning coupled with reinforcement learning enables the agent to learn the task with ef-fectiveness matching that of hand coded agents and with speed exceeding that of non-augmented rein-forcement learning. ...|$|E
40|$|A {{behavioral}} {{contract in}} a higher-order language may invoke methods of unknown objects. Although this expressive power allows programmers to formulate sophisticated contracts, it also poses {{a problem for}} language designers. Indeed, two distinct semantics have emerged for such method calls, dubbed lax and picky. While lax fails to protect components in certain scenarios, picky may blame an uninvolved party for a contract violation. In this paper, we present complete monitoring as the fundamental correctness criterion for contract systems. It demands correct <b>blame</b> <b>assignment</b> as well as complete monitoring of all channels of communication between components. According to this criterion, lax and picky are indeed incorrect ways to monitor contracts. A third semantics, dubbed indy, emerges as the only correct variant...|$|E
40|$|We {{thank the}} four {{commentators}} for carefully evaluating our model (Triesch, Teuscher, Deák, & Carlson, 2006) and sharing their opinions. We {{will respond to}} the commentaries one by one. Chris Moore focuses on two important limitations of our model: our choice not to incorporate attentional cueing mechanisms, and our choice to ignore spatial aspects of gaze following. We agree with his comments. It is important to emphasize, however, that {{there are good reasons}} to develop computational models in an incremental fashion. Richardson and Thomas, in their commentary, put it very nicely: ‘Overly complex models are time consuming to build and run the risk of revealing little about the potential causes of a particular behavior, since credit and <b>blame</b> <b>assignment</b> can become opaque. ...|$|E
40|$|Modular Set-Based Analysis from Contracts In PLT Scheme, {{programs}} {{consist of}} modules with contracts. The latter describe the {{inputs and outputs}} of functions and objects via predicates. A run-time system enforces these predicates; if a predicate fails, the enforcer raises an exception that blames a specific module with {{an explanation of the}} fault. In this paper, we show how to use such module contracts to turn set-based analysis into a fully modular parameterized analysis. Using this analysis, a static debugger can indicate for any given contract check whether the corresponding predicate is always satisfied, partially satisfied, or (potentially) completely violated. The static debugger can also predict the source of potential errors, i. e., it is sound with respect to the <b>blame</b> <b>assignment</b> of the contract system...|$|E
40|$|Human {{experience}} with interactive {{games will be}} enhanced if the software agents that play the game learn from their failures. Techniques such as reinforcement learning provide {{one way in which}} these agents may learn from their failures. Model-based meta-reasoning in which an agent uses a self-model for <b>blame</b> <b>assignment</b> provides another. This paper evaluates an framework in which both these approaches are combined. We describe an experimental investigation of a specific task (defending a city) in a computer war strategy game called FreeCiv. Our results indicate that in the task examined, model-based meta-reasoning coupled with reinforcement learning enables the agent to learn the task with performance matching that of an expert designed agent and with speed exceeding that of a pure reinforcement learning agent...|$|E
40|$|In PLT Scheme, {{programs}} {{consist of}} modules with contracts. The latter describe the {{inputs and outputs}} of functions and objects via predicates. A run-time system enforces these predicates; if a predicate fails, the enforcer raises an exception that blames a specific module with {{an explanation of the}} fault. In this paper, we show how to use such module contracts to turn set-based analysis into a fully modular parameterized analysis. Using this analysis, a static debugger can indicate for any given contract check whether the corresponding predicate is always satisfied, partially satisfied, or (potentially) completely violated. The static debugger can also predict the source of potential errors, i. e., it is sound with respect to the <b>blame</b> <b>assignment</b> of the contract system...|$|E
40|$|In nominal type systems, the subtype {{relation}} {{is between}} names of types, and subtype links are explicitly declared. In structural type systems, names are irrelevant; in determining type compatibility, only {{the structure of}} types is considered, and a type name is just an abbreviation for the full type. We analyze structural and different flavors of nominal subtyping {{from the perspective of}} component-based programming, where issues such as <b>blame</b> <b>assignment</b> and modular extensibility are important. Our analysis puts various existing subtyping mechanisms into a common frame of reference and delineates the frontiers of the subtyping design space. In addition, we propose a new subtyping definition in one particularly interesting corner of the design space which combines the safety of nominal subtyping with the flexibility of structural subtyping. ...|$|E
40|$|The {{applicability}} of aspects {{as a means}} of implementing runtime contract checking has been demonstrated in prior work, where contracts are identified as cross-cutting concerns [12, 13]. Checking contracts at runtime encounters a set of challenges within concurrent environments, such as the risk that evaluation will introduce deadlock to code which is otherwise deadlock-free. This paper presents a simple methodology for generating runtime contract checking aspects targeted at concurrent programs. The novel features of this approach allow contracts to depend on active objects without race conditions or deadlock, and addresses issues relating to timing and <b>blame</b> <b>assignment.</b> The CoJava language is discussed whose tool-supported aspect generation methodology allows the correct checking of contracts predicated on active objects. © 2010 ACM...|$|E
40|$|Design by Contract (DbC) and runtime {{enforcement}} of program assertions enables {{the construction of}} more robust software. It also enables the assignment of blame in error reporting. Unfortunately, there is no support for runtime contract enforcement and <b>blame</b> <b>assignment</b> for Aspect-Oriented Programming (AOP). Extending DbC to also cover aspects brings forward a plethora of {{issues related to the}} correct order of assertion validation. We show that there is no generally correct execution sequence of object assertions and aspect assertions. A further classification of aspects as agnostic, obedient, or rebellious defines the order of assertion validation that needs to be followed. We describe the application of this classification in a prototyped DbC tool for AOP named Cona, where aspects are used for implementing contracts, and contracts are used for enforcing assertions on aspects...|$|E
40|$|We {{study the}} problem of {{troubleshooting}} machine learning systems that rely on analytical pipelines of distinct components. Understanding and fixing errors that arise in such integrative systems is difficult as failures can occur at multiple points in the execution workflow. Moreover, errors can propagate, become amplified or be suppressed, making <b>blame</b> <b>assignment</b> difficult. We propose a human-in-the-loop methodology which leverages human intellect for troubleshooting system failures. The approach simulates potential component fixes through human computation tasks and measures the expected improvements in the holistic behavior of the system. The method provides guidance to designers about how they can best improve the system. We demonstrate {{the effectiveness of the}} approach on an automated image captioning system that has been pressed into real-world use. Comment: 11 pages, Thirty-First AAAI conference on Artificial Intelligenc...|$|E
40|$|Session types {{provide a}} means to {{prescribe}} the communication behavior between concurrent message-passing processes. However, in a distributed setting, some processes may be written in languages that do not support static typing of sessions or may be compromised by a malicious intruder, violating invariants of the session types. In such a setting, dynamically monitoring communication between processes becomes a necessity for identifying undesirable actions. In this paper, we show how to dynamically monitor communication to enforce adherence to session types in a higher-order setting. We present a system of <b>blame</b> <b>assignment</b> in the case when the monitor detects an undesirable action and an alarm is raised. We prove that dynamic monitoring does not change system behavior for welltyped processes, {{and that one of}} an indicated set of possible culprits must have been compromised in case of an alarm...|$|E
40|$|Genetic {{programming}} (GP) {{can learn}} com- plex concepts by {{searching for the}} target concept through evolution of population of candidate hypothesis programs. However, unlike some learning techniques, such as Artificial neural networks (ANNs), GP {{does not have a}} principled procedure for changing parts of a learned structure based on that structure's performance on the training data. GP is missing a clear, locally optimal update procedure, an equivalent of gradient-descent backpropagation for ANNs. This article introduces a new mechanism, "internal reinforcement, " for defining and using performance feedback on program evolution. A new connectionist representation for evolving parameterized programs, "neural programming" is also introduced. We present the algorithms for the generation of credit and <b>blame</b> <b>assignment</b> in the process of learning programs using neural programming and internal rein- forcement. The article includes some of our extensive experiments that demonstrate the increased learning rate obtained by using our principled program evolution approach...|$|E
40|$|In {{this paper}} we {{describe}} a tools environment which automates the validation {{and maintenance of}} a requirements model written in many-sorted first order logic. We focus on: a translator, that produces an executable form of the model; <b>blame</b> <b>assignment</b> functions, which input batches of mis-classified tests (i. e. training examples) and output likely faulty parts of the model; and a theory reviser, which inputs the faulty parts and examples and outputs suggested revisions to the model. In particular, we concentrate on the problems encountered when applying these tools to a real application: a requirements model containing air traffic control separation standards, operating methods and airspace information. 1. Introduction A unifying theme in the research areas of knowledge engineering, requirements engineering and formal methods is the construction and validation of requirements models represented as formal systems (using languages such as RML [7]). Within the knowledge based system communi [...] ...|$|E
40|$|Previous {{research}} has shown that counterfactual thinking (“if only…”) is related to event explanation, <b>blame</b> <b>assignment,</b> and future decisions. Using data from a large-scale electoral panel survey (ITANES), we investigated the association between pre-election counterfactual thoughts on the national economy and subsequent voting choice. Results revealed that voters focused counterfactuals on the government and other political or economic actors but also, and more frequently, on unspecified or reified actors. Whereas counterfactuals focused on the government were associated with voting for the challenger, counterfactuals focused on political or economic actors or on reified actors were associated with voting for the incumbent. These associations were even stronger when counterfactuals had a subtractive (“if only X had not…”) rather than an additive (“if only X had…”) structure. The inclusion of the targets of the counterfactuals added significantly to the predictive value of a model of voting choice based on voters’ evaluation of the national economy...|$|E
40|$|AbstractGenetic {{programming}} (GP) {{can learn}} complex concepts by {{searching for the}} target concept through evolution of a population of candidate hypothesis programs. However, unlike some learning techniques, such as Artificial Neural Networks (ANNs), GP {{does not have a}} principled procedure for changing parts of a learned structure based on that structure's performance on the training data. GP is missing a clear, locally optimal update procedure, the equivalent of gradient-descent backpropagation for ANNs. This article introduces a new algorithm, “internal reinforcement”, for defining and using performance feedback on program evolution. This internal reinforcement principled mechanism is developed within a new connectionist representation for evolving parameterized programs, namely “neural programming”. We present the algorithms for the generation of credit and <b>blame</b> <b>assignment</b> in the process of learning programs using neural programming and internal reinforcement. The article includes a comprehensive overview of genetic programming and empirical experiments that demonstrate the increased learning rate obtained by using our principled program evolution approach...|$|E
40|$|Genetic {{programming}} (GP) is {{a successful}} machine learning technique that pro- vides powerful parameterized program primitive constructs using evolution as its search mechanism. However, unlike some machine learning techniques, such as Artificial Neu- ral Networks (ANNs), GP {{does not have a}} principled procedure for changing parts of a learned structure based on that structure's past performance. GP is missing a clear, locally optimal update procedure, the equivalent of gradient-descent backpropagation for ANNs. In this article, we introduce a new- mechanism for defining and using performance feedback on program evolution. This "internal reinforcement" principled algorithm is implemented within a new- connectionist representation for evolving parameterized programs, namely "neural programming. " We present the algorithms for the generation of credit and <b>blame</b> <b>assignment</b> in the process of learning programs using neural programming and internal reinforcement. The article includes a brief overviewof genetic programming and empirical experiments that demonstrate the increased learning rate obtained by using our principled program evolution approach...|$|E
40|$|We {{analyze the}} blame-assignment {{task in the}} context of experience-based design and {{redesign}} of physical devices. We identify three types of blame-assignment tasks that differ in the types of information they take as input: the design does not achieve a desired behavior of the device, the design results in an undesirable behavior, a specific structural element in the design misbehaves. We then describe a modelbased approach for solving the blame-assignment task. This approach uses structure-behavior-function models that capture a designer's comprehension of the way a device works in terms of causal explanations of how its structure results in its behaviors. We also address the issue of indexing the models in memory. We discuss how the three types of blame-assignment tasks require different types of indices for accessing the models. Finally we describe the KRITIK 2 system that implements and evaluates this model-based approach to <b>blame</b> <b>assignment.</b> 1 Introduction Design is a very common a [...] ...|$|E
40|$|Artículo de publicación ISISoftware {{contracts}} {{have proven}} {{to play an important}} role for the development of robust software. Contract systems are widely adopted in statically typed languages and are currently finding their entrance in dynamically-typed programming languages. Most research on higher-order contracts has adopted a black-box approach where only input and output are checked. These systems cannot check many interesting concerns about the behaviour of a function. Examples include prohibiting or ensuring that certain functions are called, checking access permissions, time or memory constraints, interaction protocols, etc. To address this need for behavioural runtime validation, while preserving support for higherorder programming, we introduce the notion of computational contracts. Computational contracts is a contract model with <b>blame</b> <b>assignment</b> in a higher-order setting that provides a systematic way to specify temporal contracts over objects and functions and their possibly higher-order arguments. Weshow various applications of computational contracts, and explain how to assign blame in case of a violation. Computational contracts have been integrated in both Scheme and AmbientTalk, a dynamically-typed object-oriented language built upon the principles of prototype-based programming. FONDECYT Project 111005...|$|E
40|$|TreatJS is a {{language}} embedded, higher-order contract system for JavaScript which enforces contracts by run-time monitoring. Beyond providing the standard abstractions for building higher-order contracts (base, function, and object contracts), TreatJS 2 ̆ 7 s novel contributions are its guarantee of non-interfering contract execution, its systematic approach to <b>blame</b> <b>assignment,</b> {{its support for}} contracts {{in the style of}} union and intersection types, and its notion of a parameterized contract scope, which is the building block for composable run-time generated contracts that generalize dependent function contracts. TreatJS is implemented as a library so that all aspects of a contract can be specified using the full JavaScript language. The library relies on JavaScript proxies to guarantee full interposition for contracts. It further exploits JavaScript 2 ̆ 7 s reflective features to run contracts in a sandbox environment, which guarantees that the execution of contract code does not modify the application state. No source code transformation or change in the JavaScript run-time system is required. The impact of contracts on execution speed is evaluated using the Google Octane benchmark...|$|E
