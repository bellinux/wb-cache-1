3230|2|Public
25|$|Ciresan {{and colleagues}} (2010) in Jurgen Schmidhuber's group showed {{that despite the}} {{vanishing}} gradient problem, GPUs makes <b>back-propagation</b> feasible for many-layered feedforward neural networks.|$|E
25|$|It {{is known}} that changes in {{dendritic}} excitability affect action potential back propagation. Action potentials begin near the axon hillock and propagate {{down the length of}} the axon, but they also propagate backward through the soma into the dendritic arbor. Active back propagation is dependent on ion channels and changing the densities or properties of these channels can influence the degree to which the signal is attenuated. Plasticity of <b>back-propagation</b> in the dendrites occurs in less than one minute and lasts longer than 25 minutes. Back propagation is a method of signaling to the synapses that an action potential was fired. This is important for spike-timing-dependent plasticity.|$|E
50|$|Other typical {{problems}} of the <b>back-propagation</b> algorithm are the speed of convergence {{and the possibility of}} ending up in a local minimum of the error function. Today there are practical methods that make <b>back-propagation</b> in multi-layer perceptrons the tool of choice for many machine learning tasks.|$|E
5000|$|... #Article: Propagation and <b>Back-Propagation</b> Diffusion through Neighborhoods Algorithm ...|$|E
5000|$|Neural Net - A {{small but}} {{functional}} <b>back-propagation</b> network simulator.|$|E
50|$|Digital <b>back-propagation</b> (DBP) is a {{technique}} for compensating all fiber impairments in optical transmission systems. DBP {{is a sort of}} non-linearity compensation (NLC). DBP uses the <b>back-propagation</b> algorithm in the digital domain by solving the inverse nonlinear Schrödinger equation of the fiber link using the split-step Fourier method (SSFM) to calculate the transmitted signal from the received signal.|$|E
5000|$|... neural networks: BP-MLL is an {{adaptation}} of the popular <b>back-propagation</b> algorithm for multi-label learning.|$|E
50|$|CTC scores {{can then}} be used with the <b>back-propagation</b> {{algorithm}} to update the neural network weights.|$|E
50|$|Propagation and <b>Back-Propagation</b> Diffusion through Neighborhoods Algorithm or PB-DNA is an {{optimization}} heuristic {{that belongs}} to Ant Colony Optimization Algorithms (ACA).|$|E
50|$|The {{original}} {{paper presented}} a perceptron network whose connection weights were trained with the <b>back-propagation</b> algorithm, {{this may be}} done in batch or online. The Stuttgart Neural Network Simulator implements that version.|$|E
50|$|There are {{two methods}} {{by which to}} select a CNN {{processor}} along with a template or weights. The first is by synthesis, which involves determine the coefficients offline. This {{can be done by}} leveraging off previous work, i.e. libraries, papers, and articles, or by mathematically deriving co that best suits the problem. The other is through training the processor. Researchers have used <b>back-propagation</b> and genetic algorithms to learn and perform functions. <b>Back-propagation</b> algorithms tend to be faster, but genetic algorithms are useful because they provide a mechanism to find a solution in a discontinuous, noisy search space.|$|E
50|$|In an {{exploration}} space {{that may be}} a non-structured organization without centralized control entities, autonomous and elementary threads (called ant-agents) use the direct communication diffusion process by propagation and <b>back-propagation</b> explorations in order to extract the global minimum from a set of local minima.|$|E
50|$|After winning {{his local}} science fair {{in sixth grade}} with a laser, Vigoda became {{interested}} in artificial neural networks in seventh grade, and {{at the age of}} 15 interned in David Rumelhart's lab at Stanford University studying the effects of adding momentum terms to the <b>back-propagation</b> algorithm.|$|E
5000|$|GMDH {{is used in}} such {{fields as}} data mining, {{knowledge}} discovery, prediction, complex systems modeling, optimization and pattern recognition. Li et. al. (2017)'s results showed that GMDH neural network performed better than the classical forecasting algorithms such as Single Exponential Smooth, Double Exponential Smooth, ARIMA and <b>back-propagation</b> neural network.|$|E
5000|$|Yann LeCun {{was born}} near Paris, France, in 1960. He {{received}} a Diplôme d'Ingénieur from the Ecole Superieure d'Ingénieur en Electrotechnique et Electronique (ESIEE), Paris in 1983, and a PhD in Computer Science from Université Pierre et Marie Curie in 1987 {{during which he}} proposed an early form of the <b>back-propagation</b> learning algorithm for neural networks.|$|E
50|$|Connectionist network {{differs from}} {{computational}} modeling specifically because of two functions: neural <b>back-propagation</b> and parallel-processing. Neural <b>back-propagation</b> {{is a method}} utilized by connectionist network to show evidence of learning. After a connectionist network produce a response, the stimulated results are compared to real-life situational results. The feedback provided by the backward propagation of errors {{would be used to}} improve accuracy for the network’s subsequent responses. The second function, parallel-processing, stemmed from the belief that knowledge and perception are not limited to specific modules but rather are distributed throughout the cognitive networks. The present of parallel distributed processing has been shown in psychological demonstrations like the Stroop effect, where the brain seems to be analyzing the perception of color and meaning of language at the same time. However, this theoretical approach has been continually disproved because the two cognitive functions for color-perception and word-forming are operating separately and simultaneously, not parallel of each other.|$|E
5000|$|Computational {{modeling}} (Tijsseling & Harnad 1997; Damper & Harnad 2000) {{has shown}} that many types of category-learning mechanisms (e.g. both <b>back-propagation</b> and competitive networks) display CP-like effects. In <b>back-propagation</b> nets, the hidden-unit activation patterns that [...] "represent" [...] an input build up within-category compression and between-category separation as they learn; other kinds of nets display similar effects. CP {{seems to be a}} means to an end: Inputs that differ among themselves are [...] "compressed" [...] onto similar internal representations if they must all generate the same output; and they become more separate if they must generate different outputs. The network's [...] "bias" [...] is what filters inputs onto their correct output category. The nets accomplish this by selectively detecting (after much trial and error, guided by error-correcting feedback) the invariant features that are shared by the members of the same category and that reliably distinguish them from members of different categories; the nets learn to ignore all other variation as irrelevant to the categorization.|$|E
50|$|Matlab: The {{neural network}} toolbox has {{functionality}} designed {{to produce a}} time delay neural network give the step size of time delays and an optional training function. The default training algorithm is a Supervised Learning <b>back-propagation</b> algorithm that updates filter weights based on the Levenberg-Marquardt optimizations. The function is timedelaynet(delays, hidden_layers, train_fnc) and returns a time-delay neural network architecture that a user can train and provide inputs to.|$|E
5000|$|Computational {{devices were}} created in CMOS, for both biophysical {{simulation}} and neuromorphic computing. Nanodevices for very large scale principal components analyses and convolution may create {{a new class of}} neural computing because they are fundamentally analog rather than digital (even though the first implementations may use digital devices.) Ciresan and colleagues (2010) in Schmidhuber's group showed that despite the vanishing gradient problem, GPUs makes <b>back-propagation</b> feasible for many-layered feedforward neural networks.|$|E
5000|$|CDBNs use the {{technique}} of probabilistic max-pooling to reduce the dimensions in higher layers in the network. Training of the network involves a pre-training stage accomplished in a greedy layer-wise manner, similar to other deep belief networks. Depending on whether the network {{is to be used}} for discrimination or generative tasks, it is then [...] "fine tuned" [...] or trained with either <b>back-propagation</b> or the up-down algorithm, respectively.|$|E
50|$|Multi-layer {{networks}} use {{a variety}} of learning techniques, the most popular being <b>back-propagation.</b> Here, the output values are compared with the correct answer to compute the value of some predefined error-function. By various techniques, the error is then fed back through the network. Using this information, the algorithm adjusts the weights of each connection {{in order to reduce the}} value of the error function by some small amount. After repeating this process for a sufficiently large number of training cycles, the network will usually converge to some state where the error of the calculations is small. In this case, one would say that the network has learned a certain target function. To adjust weights properly, one applies a general method for non-linear optimization that is called gradient descent. For this, the network calculates the derivative of the error function with respect to the network weights, and changes the weights such that the error decreases (thus going downhill on the surface of the error function). For this reason, <b>back-propagation</b> can only be applied on networks with differentiable activation functions.|$|E
5000|$|<b>Back-propagation</b> allowed {{researchers}} to train supervised deep artificial neural networks from scratch, initially with little success. Hochreiter's diploma thesis of 1991 formally identified {{the reason for}} this failure in the [...] "vanishing gradient problem", which not only affects many-layered feedforward networks, but also recurrent networks. The latter are trained by unfolding them into very deep feedforward networks, where a new layer is created for each time step of an input sequence processed by the network.|$|E
5000|$|The {{standard}} method is called [...] "backpropagation through time" [...] or BPTT, {{and is a}} generalization of <b>back-propagation</b> for feed-forward networks. Like that method, it is an instance of automatic differentiation in the reverse accumulation mode or Pontryagin's minimum principle. A more computationally expensive online variant is called [...] "Real-Time Recurrent Learning" [...] or RTRL, which is an instance of automatic differentiation in the forward accumulation mode with stacked tangent vectors. Unlike BPTT this algorithm is local in time but not local in space.|$|E
50|$|BRNN can {{be trained}} using similar {{algorithms}} compared to RNN, because the two directional neurons {{do not have any}} interactions. However, when <b>back-propagation</b> is applied, additional processes are needed because updating input and output layers cannot be done at once. General procedures for training are as follows: For forward pass, forward states and backward states are passed first, then output neurons are passed. For backward pass, output neurons are passed first, then forward states and backward states are passed next. After forward and backward passes are done, the weights are updated.|$|E
50|$|Intrinsic {{plasticity}} is {{the continuous}} modification of intrinsic electrical properties of a neuron by synaptic or neuronal activity. It can affect diverse processes as synaptic integration, sub-threshold signal propagation, spike generation, spike <b>back-propagation,</b> and meta-plasticity {{as it is}} mediated by changes in the expression level or biophysical properties of ion channels in the membrane. The function of intrinsic plasticity in behaving animals is uncertain but there is experimental evidence for several distinct roles: {{as part of the}} memory engram itself, as a regulator of synaptic plasticity underlying learning and memory, and as a component of homeostatic regulation.|$|E
50|$|Pyramidal neurons, {{like other}} neurons, have {{numerous}} voltage-gated ion channels. In pyramidal cells, {{there is an}} abundance of Na+, Ca2+, and K+ channels in the dendrites, and some channels in the soma. Ion channels within pyramidal cell dendrites have different properties from the same ion channel type within the pyramidal cell soma. Voltage-gated Ca2+ channels in pyramidal cell dendrites are activated by subthreshold EPSPs and by back-propagating action potentials. The extent of <b>back-propagation</b> of action potentials within pyramidal dendrites depends upon the K+ channels. K+ channels in pyramidal cell dendrites provide a mechanism for controlling the amplitude of action potentials.|$|E
50|$|It {{is known}} that changes in {{dendritic}} excitability affect action potential back propagation. Action potentials begin near the axon hillock and propagate {{down the length of}} the axon, but they also propagate backward through the soma into the dendritic arbor. Active back propagation is dependent on ion channels and changing the densities or properties of these channels can influence the degree to which the signal is attenuated. Plasticity of <b>back-propagation</b> in the dendrites occurs in less than one minute and lasts longer than 25 minutes. Back propagation is a method of signaling to the synapses that an action potential was fired. This is important for spike-timing-dependent plasticity.|$|E
5000|$|Hinton's {{research}} investigates ways {{of using}} neural networks for machine learning, memory, perception and symbol processing. He has authored or co-authored over 200 {{peer reviewed publications}} in these areas. He {{was one of the}} first researchers who demonstrated the use of generalized <b>back-propagation</b> algorithm for training multi-layer neural networks that has been widely used for practical applications. He co-invented Boltzmann machines with David Ackley and Terry Sejnowski His other contributions to neural network research include distributed representations, time delay neural network, mixtures of experts, Helmholtz machines and Product of Experts. In 2007 Hinton coauthored an unsupervised learning paper titled [...] "Unsupervised learning of image transformations". An accessible introduction to Geoffrey Hinton's research can be found in his articles in Scientific American in September 1992 and October 1993.|$|E
5000|$|Quantitative {{forecasting}} {{models are}} used to forecast future data {{as a function of}} past data. They are appropriate to use when past numerical data is available and when {{it is reasonable to assume}} that some of the patterns in the data are expected to continue into the future.These methods are usually applied to short- or intermediate-range decisions. Examples of quantitative forecasting methods are last period demand, simple and weighted N-Period moving averages, simple exponential smoothing, poisson process model based forecasting [...] and multiplicative seasonal indexes. Previous research shows that different methods may lead to different level of forecasting accuarcy. For example, GMDH neural network was found to have better forecasting performance than the classical forecasting algorithms such as Single Exponential Smooth, Double Exponential Smooth, ARIMA and <b>back-propagation</b> neural network.|$|E
5000|$|To {{minimize}} total error, {{gradient descent}} {{can be used}} to change each weight in proportion to its derivative with respect to the error, provided the non-linear activation functions are differentiable. The standard method is called [...] "backpropagation through time" [...] or BPTT, a generalization of <b>back-propagation</b> for feedforward networks. A more computationally expensive online variant is called [...] "Real-Time Recurrent Learning" [...] or RTRL. Unlike BPTT this algorithm is local in time but not local in space. An online hybrid between BPTT and RTRL with intermediate complexity exists, with variants for continuous time. A major problem with gradient descent for standard RNN architectures is that error gradients vanish exponentially quickly with the size of the time lag between important events. The Long short-term memory architecture overcomes these problems.|$|E
5000|$|An {{artificial}} {{neural network}} is a network of artificial neurons. An artificial neuron A {{is equipped with a}} function [...] , receives n real-valued inputs [...] with respective weights , and it outputs [...] Some neurons are selected to be the output neurons, and the network function is the vectorial function that associates to the n input values, the outputs of the m selected output neurons.Note that different choices of weights produce different network functions for the same inputs. <b>Back-propagation</b> is a supervised learning method by which the weights of the connections in the network are repeatedly adjusted so as to minimize the difference between the vector of actual outputs and that of desired outputs. Learning algorithms based on backwards propagation of errors can be used to find optimal weights for given topology of the network and input-output pairs.|$|E
50|$|The {{four main}} {{features}} of an ANN are topology, data flow, types of input values, {{and forms of}} activation (Meireles, M. R. G. (2003), Munakata, T. (1998)). Topology can be multilayered, single-layered, or recurrent. Data flow can be recurrent with feedback or non-recurrent with feedforward model. The inputs are binary, bipolar, or continuous. The activation is linear, step, or sigmoid. Multilayer Perceptron (MLP) {{is the most popular}} of all the types, which is generally trained with <b>back-propagation</b> of error algorithm. Each neuron output is connected to every neuron in subsequent layers connected in cascade and with no connections between neurons in the same layer. Figure 4 shows a basic MLP topology (Meireles, M. R. G. (2003)), and a basic telecommunication network (Subramanian, M. (2010)) that most are familiar with. We can equate the routers at the nodes in telecommunication network to neurons in MLP technology and the links to synapses.|$|E
50|$|Moreover, this {{architecture}} {{is capable of}} learning, similar to a <b>back-propagation</b> styled neural network. The weight between the cognitive and feature demons can be adjusted {{in proportion to the}} difference between the correct pattern and the activation from the cognitive demons. To continue with our previous example, when we first learned the letter R, we know is composed of a curved, long straight, and a short angled line. Thus when we perceive those features, we perceive R. However, the letter P consists of very similar features, so during the beginning stages of learning, it is likely for this architecture to mistakenly identify R as P. But through constant exposure of confirming R's features to be identified as R, the weights of R's features to P are adjusted so the P response becomes inhibited (e.g., learning to inhibit the P response when a short angled line is detected). In principle, a pandemonium architecture can recognize any pattern.|$|E
5000|$|Similar {{ideas have}} been used in {{feed-forward}} neural network for unsupervised pre-training to structure a neural network, making it first learn generally useful feature detectors. Then the network is trained further by supervised <b>back-propagation</b> to classify labeled data. The Deep belief network model by Hinton et al. (2006) involves learning the distribution of a high level representation using successive layers of binary or real-valued latent variables. It uses a restricted Boltzmann machine to model each new layer of higher level features. Each new layer guarantees an increase on the lower-bound of the log likelihood of the data, thus improving the model, if trained properly. Once sufficiently many layers have been learned the deep architecture may be used as a generative model by reproducing the data when sampling down the model (an [...] "ancestral pass") from the top level feature activations.Hinton reports that his models are effective feature extractors over high-dimensional, structured data. This work plays a keyrole in reintroducing the interests in deep neural network research and consequently leads to the developments of Deep learning, although deep belief network is no longer the main deep learning technique.|$|E
50|$|Microwave imaging is {{a science}} which has been evolved from older detecting/locating {{techniques}} (e.g., radar) in order to evaluate hidden or embedded objects in a structure (or media)using electromagnetic (EM) waves in microwave regime (i.e., ~300 MHz-300 GHz). Microwave imaging techniques can be classified as either quantitative or qualitative. Quantitative imaging techniques (are also known as inverse scattering methods) give the electrical (i.e., electrical and magnetic property distribution) and geometrical parameters (i.e., shape, size and location) of an imaged object by solving a nonlinear inverse problem. The nonlinear inverse problem is converted into a linear inverse problem (i.e., Ax=b where A and b are known and x (or image) is unknown) by using Born or distorted Born approximations. Despite the fact that direct matrix inversion methods can be invoked to solve the inversion problem, this will be so costly when {{the size of the}} problem is so big (i.e., when A is a very dense and big matrix). To overcome this problem, direct inversion is replaced with iterative solvers. Techniques in this class are called forward iterative methods which are usually time consuming.On the other hand, qualitative microwave imaging methods calculate a qualitative profile (which is called as reflectivity function or qualitative image) to represent the hidden object. These techniques use approximations to simplify the imaging problem and then they use <b>back-propagation</b> (also called time reversal, phase compensation, or back-migration) to reconstruct the unknown image profile. Synthetic aperture radar (SAR), ground-penetrating radar (GPR), and frequency-wave number migration algorithm {{are some of the most}} popular qualitative microwave imaging methods1.|$|E
40|$|The {{conventional}} linear <b>back-propagation</b> {{algorithm is}} replaced by a non-linear version, which avoids the necessity for calculating the derivative of the activation function. This may be exploited in hardware realizations of neural processors. In this paper we derive the non-linear <b>back-propagation</b> algorithms in the framework of recurrent <b>back-propagation</b> and present some numerical simulations of feed-forward networks on the NetTalk problem. A discussion of implementation in analog VLSI electronics concludes the paper. 1 Introduction From a simple rewriting of the <b>back-propagation</b> algorithm [RHW 86] a new family of learning algorithms emerges which we call non-linear <b>back-propagation.</b> In the normal <b>back-propagation</b> algorithm one calculates the errors on the hidden units from the errors on the output neurons by means of a linear expression. The non-linear algorithms presented here have the advantage that the <b>back-propagation</b> of errors goes through the same non-linear units as the forwa [...] ...|$|E
