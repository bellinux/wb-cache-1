5|29|Public
5000|$|PowerBuilder.NET 12.5 {{introduces}} {{support for}} multi-threading (included in Classic for many releases), {{the ability to}} consume RESTful (Representational State Transfer) Web Services and <b>Batch</b> <b>Command</b> Processing. For the [...] "classic" [...] PowerScript, various smaller enhancements were added,too.|$|E
5000|$|Its {{language}} {{structure and}} syntax is {{a cross between}} DOS <b>batch</b> <b>command,</b> Basic, Fortran, and C. It has been developed over the years with functions added and support for things like [...]Net, ActiveX controls, COM (OLE), Unicode, UAC and code signing.|$|E
40|$|Interactive Plotting Program (IAP) {{provides}} {{fast and}} easy method of plotting data in presentable format. Extensive plot editing done with various IAP commands, typed interactively from terminal or read from <b>batch</b> <b>command</b> files. Ability to redirect output to variety of devices enables user to tailor plots with graphics terminal before printing. Designed to allow addition or deletion of code for {{any type of}} terminal or plotting device. Written in FORTRAN 77 and Assembler...|$|E
30|$|Special {{operation}} commands: The McRAIT controller can invoke special operation <b>commands</b> such as <b>batch</b> <b>commands.</b> Those commands {{can be sent}} on each {{channel for}} all tags and can be reissued when a failure occurs.|$|R
5000|$|In {{addition}} to supporting auto-booting [...] files, DOS XLs batch features provided an auto-booting batch feature. Naming a batch file to [...] {{would have it}} execute <b>batch</b> <b>commands</b> on startup (same as OS/A+). Unfortunately, this feature wasnt compatible with some programs (e.g. AtariWriter).|$|R
50|$|Each {{command is}} {{executed}} by a separate shell or command-line interpreter instance. Since operating systems use different command-line interpreters this {{can lead to}} unportable makefiles. For instance, GNU Make by default executes commands with /bin/sh, where Unix commands like cp are normally used. In contrast to that, Microsoft's nmake executes commands with cmd.exe where <b>batch</b> <b>commands</b> like copy are available but not necessarily cp.|$|R
40|$|The MBASIC (TM) batch processor, a {{language}} translator designed {{to operate in}} the MBASIC (TM) environment is described. Features include: (1) a CONVERT TO <b>BATCH</b> <b>command,</b> usable from the ready mode; and (2) translation of the users program in stages through several levels of intermediate language and optimization. The processor is to be designed and implemented in both machine-independent and machine-dependent sections. The architecture is planned so that optimization processes are transparent {{to the rest of the}} system and need not be included in the first design implementation cycle...|$|E
40|$|Abstract iii The {{purpose of}} this thesis is to present a {{specification}} language and its execution mechanism used to define tasks in a networked, distributed computing environment. Because of {{technological advancements in both}} computer hardware and software, computers are increasingly being connected into networks and systems. Machines in a computer network could be used more efficiently if a complex activity comprised of many sub-jobs could be divided and executed on multiple machines. A new type of command file is needed where the underlying interpreting mechanism takes advantage of resources network-wide, detects possibilities for parallel executions of subjobs, and executes them on separate machines. A specification language is presented here that allows a user to create such command files. This file is to be called a &quot;task file, &quot; and it contains information about which sub-jobs should be executed. It is similar to a <b>batch</b> <b>command</b> file; the difference lies i...|$|E
50|$|Hudson is a {{continuous}} integration (CI) tool written in Java, which {{runs in a}} servlet container such as Apache Tomcat or the GlassFish application server. It supports SCM tools including CVS, Subversion, Git, Perforce, Clearcase and RTC, and can execute Apache Ant and Apache Maven based projects, as well as arbitrary shell scripts and Windows <b>batch</b> <b>commands.</b> The primary developer of Hudson was Kohsuke Kawaguchi, who worked for Sun Microsystems at the time. Released under the MIT License, Hudson is free software.|$|R
50|$|Jenkins is an {{open source}} {{automation}} server written in Java. Jenkins helps to automate the non-human part of software development process, with continuous integration and facilitating technical aspects of continuous delivery. It is a server-based system that runs in servlet containers such as Apache Tomcat. It supports version control tools, including AccuRev, CVS, Subversion, Git, Mercurial, Perforce, ClearCase and RTC, and can execute Apache Ant, Apache Maven and sbt based projects as well as arbitrary shell scripts and Windows <b>batch</b> <b>commands.</b> The creator of Jenkins is Kohsuke Kawaguchi. Released under the MIT License, Jenkins is free software.|$|R
5000|$|Many [...]ZAP Files require user intervention. This can be {{overcome}} if the Systems Administrator creates a Batch file and runs a quiet or silent install from a <b>Batch</b> File <b>command.</b> However, running an Executable file (such as setup.exe) often bypasses quiet, passive or silent installation switches, even if specified in the SetupCommand.|$|R
5000|$|RSTS uses {{a serial}} {{communication}} connection {{to interact with}} the operator. The connection might be a local computer terminal with a 20 mA current loop interface, an RS-232 interface (either local serial port or remote connection via modem), or by an ethernet connection utilizing DECnet or LAT. As many as 128 terminals (using multi-terminal service) could connect to a RSTS system, running under a maximum of 63 jobs (depending on the processor being used, the amount of memory and disk space, and the system load). Most RSTS systems had nowhere near that many terminals. Users could also submit jobs to be run in batch mode. There was also a batch program called [...] "ATPK" [...] that allowed users to run a series of commands on an imaginary terminal (pseudo-terminal) in semi-interactive mode similar to <b>batch</b> <b>commands</b> in MS-DOS.|$|R
5000|$|In Unix, Linux {{and other}} Unix-like {{operating}} systems, {{the first two}} bytes in a file can be the characters [...] "#!", which constitute a magic number (hexadecimal 23 and 21, the ASCII values of [...] "#" [...] and [...] "!") {{often referred to as}} shebang, prefix the first line in a script, with the remainder of the line being a command usually limited to a max of 14 (when introduced) up to usually about 80 characters in 2016. If the file system permissions on the script (a file) include an execute permission bit for the user invoking it by its filename (often found through the command search path), it is used to tell the operating system what interpreter (usually a program that implements a scripting language) to use to execute the script's contents, which may be <b>batch</b> <b>commands</b> or might be intended for interactive use. An example would be #!/bin/bash, meaning run this script with the bash shell found in the /bin directory.|$|R
5000|$|Finer-grained context switching, i.e. {{being able}} to switch two {{execution}} threads at the shader-instruction level instead of the single-command level or even <b>batch</b> of <b>commands,</b> was introduced in WDDM/DXGI 1.2 which shipped with Windows 8. [...] This overcomes a potential scheduling problem when application would have very long execution of a single command/batch of commands {{and will have to}} be terminated by the OS watchdog timer.|$|R
5000|$|... and [...] {{commands}} {{limit the}} scope of changes to the environment. Changes made to the command line environment after [...] commands are local to the <b>batch</b> file. [...] <b>command</b> restores the previous settings.|$|R
5000|$|XEmacs {{text-editing}} features {{commands to}} manipulate words and paragraphs (deleting them, moving them, moving through them, and so forth), syntax highlighting for making source code easier to read, and [...] "keyboard macros" [...] for performing arbitrary <b>batches</b> of editing <b>commands</b> {{defined by the}} user.|$|R
40|$|The {{retrieval}} command subsystem {{reference manual}} for the NASA Aerospace Safety Information System (NASIS) is presented. The command subsystem may be operated conversationally {{or in the}} <b>batch</b> mode. Retrieval <b>commands</b> are categorized into search-oriented and output-oriented commands. The characteristics of ancillary commands and their application are reported...|$|R
40|$|Includes bibliographical {{references}} (pages 20 - 21). Introduction: There is unmet clinical {{need for}} {{automated data processing}} of deep sequencing in heterogeneous sample populations in molecular oncology specimens. We have developed clinical assays using Next Generation Sequencing (NGS) for deep sequencing in both solid tumor and hematological indications. We have targeted five genes (ASXL 1, RUNX 1, EZH 2, ETV 6, and TP 53) involved in myelodysplastic syndrome (MDS) and three genes (BRAF, c-KIT, NRAS) in late stage melanoma. We designed and implemented a data processing pipeline that integrates novel and commercial analysis software to provide automated rules-based filtering and annotation of variants. Methods: We used a targeted resequencing approach with the Fluidigm Access Array system for library creation and molecular barcoding for sample multiplexing. Samples were processed in duplicate to filter out potential false positives. Libraries were sequenced using the Ion Torrent Personal Genome Machine (PGM) (Life Technologies, Carlsbad, CA) and the Illumina MiSeq (Illumina Inc., San Diego, CA) systems. Raw data in FastQ format was preprocessed using Windows <b>batch</b> <b>commands</b> and Perl programs that were integrated with NextGENe (SoftGenetics, State College, PA) analysis software for quality trimming, alignment and variant calling against NCBI curated references. Variant calls were compared between duplicate samples and annotated using a separate Perl program that queried databases containing known germline and somatic variants. Results: Quality control was implemented by trimming all downstream reads that contained specified Q-scores (Phred, Q 16 or above) as well as requiring a minimum coverage depth of 500 X per exon. Only variant calls confirmed at greater than 5...|$|R
50|$|Implementation of the {{technique}} is straightforward, using at the bare minimum a shell script on the server and a Windows <b>batch</b> file or <b>command</b> line utility on the client. Overhead on both the server and client in terms of traffic, CPU and memory consumption is minimal. Port knock daemons are not complex to code; any type of vulnerability within the code is obvious and auditable.|$|R
40|$|International audienceThe {{hardware}} simulator {{facilitates the}} test and validation cycles by replicating channel artifacts in a controllable and repeatable laboratory environment. After {{a description of the}} MIMO channel models and the hardware simulator architecture, this paper presents new implementation algorithm of its digital block. The proposed algorithm allows the selection of specific environments and various scenarios, standards (LTE or WLAN 802. 11 ac) and Doppler speeds to implement the digital block architecture. The digital block architecture is implemented for 2 × 2 MIMO channel on a Xilinx Virtex-IV FPGA using <b>batch</b> and <b>command</b> line files. The occupation on the FPGA, the accuracy of the output signals and the latencies of the architecture for each configuration are then analyzed...|$|R
50|$|Emacs is {{primarily}} a text editor and is designed for manipulating pieces of text, although {{it is capable of}} formatting and printing documents like a word processor by interfacing with external programs such as LaTeX, Ghostscript or a web browser. Emacs provides commands to manipulate and differentially display semantic units of text such as words, sentences, paragraphs and source code constructs such as functions. It also features keyboard macros for performing user-defined <b>batches</b> of editing <b>commands.</b>|$|R
5000|$|DOS {{by default}} {{provides}} a primitive ability for shell scripting, via batch files (with the filename extension [...] ). These are text files {{that can be}} created in any text editor. They are executed {{in the same fashion}} as compiled programs, and run each line of the batch file as a <b>command.</b> <b>Batch</b> files can also make use of several internal commands, such as GOTO and conditional statements. GOSUB and simple arithmetic is supported with the DR DOS COMMAND.COM as well as some with third-party shells like 4DOS; however, no real form of programming is usually enabled.|$|R
5000|$|Many workarounds were possible, but {{generally}} only worked in some environments: The [...] command {{was not available}} in older DOS versions, [...] was only available if TCP/IP was installed, and so on. No solution was available from Microsoft, {{but a number of}} small utility programs, could be installed from other sources. A commercial example would be the 1988 Norton Utilities <b>Batch</b> Enhancer (BE) <b>command,</b> where [...] would wait for 1 second, or the free 94-byte WAIT.COM where [...] would wait for 5 seconds, then return control to the script. Most such programs are 16-bit [...]COM files, so are incompatible with 64-bit Windows.|$|R
40|$|In {{their first}} 30 years user {{interfaces}} went {{through at least}} three significant paradigm changes: <b>batch</b> processing, <b>command</b> lines, and WIMP interfaces. Yet for the past 30 years we have been stuck on the WIMP plateau; the predominant user interfaces still draw mainly from the WIMP paradigm. Interactive 3 D graphics may be {{the next step in}} the evolution of user interfaces because they draw on cognitive and physical skills we use in the real 3 D world: spatial memory, spatial understanding, proprioception, wayfinding, and others. In order for developers to widely adopt interactive 3 D for more than games, however, we need to develop an interaction lexicon that they and their users can draw from. Despite years of research on 3 D interaction techniques we are only starting to define this lexicon; I believe that we are holding ourselves back because we are only exploring the part of the design space that clusters around a 1 : 1 mapping to the real world. To expand the interaction lexicon we [...] ...|$|R
40|$|This paper {{describes}} work {{in progress}} on a workbench for symbolic music information retrieval (MIR). Drawn from three broad techniques used to perform symbolic retrieval—state-based matching, dynamic programming, and text IR—the workbench implements several variations based on these techniques. To perform an experiment, the user can either interact with the workbench though command line options, or develop scripts that <b>batch</b> process the <b>commands.</b> The latter is preferable when running a series of experiments. The workbench is also designed {{so it can be}} embedded into a digital music library to provide content-based querying. Development of a graphical user interface is planned for the near future. 1...|$|R
40|$|A {{parametric}} {{model and}} a query language ParaSQL for temporal databases {{has been proposed}} in the past. As the attribute values in the model can vary in length, {{it is difficult to}} use existing relational storage technology. To address this, CanStoreX, our XML-based storage technology has been deployed in a prior implementation. In parallel, the storage technology as well as our style of implementation for database prototypes have gone through an evolution. This has necessitated the previous implementation to be revisited. In addition, a new parser has been developed using JavaCC. Furthermore, a larger subset of ParaSQL has been implemented. For testing, a utility to generate synthetic temporal relations has been developed. Conforming to the new style, the present implementation has been encapsulated in terms of high level commands. This allows end-users to system developers on one hand and various database prototypes on the other, to interact with a central storage system from a common GUI that facilitates execution of <b>batches</b> of <b>commands.</b> Our implementation has helped to identify pragmatic issues in temporal database implementation as well as as the storage technology more clearly...|$|R
40|$|Abstract- A {{tablet press}} is a {{mechanical}} device that compresses powder into tablets of uniform size and weight. To form a tablet, the granulated material must be metered into a cavity formed by two punches and a die, {{and then the}} punches must be pressed together with great force to fuse the material together. A method of structure optimization for tablet press is proposed {{in order to reduce}} mass while assuring adequate stiffness. Pre compressor assembly, main compressor assembly, turret, plates are determined as optimal objects by mass analysis. Key geometric parameters of plates which have relatively larger impacts on mass and stiffness are extracted as design variables. In order to research relationship between stiffness, mass and design variables, <b>command</b> <b>batch</b> file is built by CREO and analysis is done in ANSYS and topology optimization is done in HYPERMESH...|$|R
40|$|DESTA' is {{the acronym}} for the Dialogue Evolutionary Synthesizer of Turnkey Algorithms {{by means of}} a natural {{language}} (Russian or English) functional specification of algorithms or software being developed. DESTA represents the computer-aided and/or automatic artificial intelligence 'forgiving' system which provides users with software tools support for algorithm and/or structured program development. The DESTA system is intended to provide support for the higher levels and earlier stages of engineering design of software in contrast to conventional Computer Aided Design (CAD) systems which provide low level tools for use at a stage when the major planning and structuring decisions have already been taken. DESTA is a knowledge-intensive system. The main features of the knowledge are procedures, functions, modules, operating system <b>commands,</b> <b>batch</b> files, their natural language specifications, and their interlinks. The specific domain for the DESTA system is a high level programming language like Turbo Pascal 6. 0. The DESTA system is operational and runs on an IBM PC computer...|$|R
40|$|This course {{provides}} in ten units {{an introduction}} to the Python programming language and especially to its use in remote sensing applications. This set of units has been aimed at advanced users with a good working knowledge of the field of remote sensing, but intermediate uses (e. g., final year dissertation students) could work through these notes. In fact the beginner can make use of the course if they are prepared to undertake extra work. If the reader has no prior programming or scripting experience it is highly recommended that the student reads a tutorial such as 'How to think like a computer scientist: Learning Python 2 nd Edition’ alongside the notes presented in this course since this course does not have room to cover all the basic details of programming. Course Structure: - Introduction - Basics of Python - Text processing - File system - Plotting - Statistics using NumPy - ArcMap Toolboxes - <b>Batch</b> processing using <b>command</b> line tools - Image processing - LiDAR processing...|$|R
40|$|This work {{focuses on}} a {{methodology}} to help bring many of our database artifacts and prototypes to reside {{on the top of}} a common workbench platform that leads to uniformity and removes overlap across different subsystems. A versatile command format has been developed to allow commands belonging to different subsystems to be interleaved in the same batch unambiguously. Through a collaborative effort carried on in parallel, existing GUIs (Graphical User Interfaces) have also been merged into a common, but simple GUI. The GUI executes a <b>batch</b> of <b>commands.</b> Subsystem currently included are: a runner for SQL on a variety of database platforms, a runner for Quilt queries (Quilt is an early version of XQuery and runs on a platform called KWEELT), ElementalDB, an experimental database system used for instruction in a graduate database implementation course, our own XQuery engine which aims at handling data in terabyte range stored in our storage in paginated form using our pagination algorithm, a research prototype for NC 94, an important spatiotemporal data set in agriculture, and a research prototype for a temporal database. The organization of the subsystems follows strict convention for ease of further development and maintenance. XML is used extensively by various subsystems. An XML based framework has been developed for benchmarking subsystems to make experiments completely repeatable at click of a button starting from creation of storage, loading of data sets, execution of commands, collecting performance data in XML-based logs to reporting using XQuery queries on the XML logs. With a very small learning curve, the resulting workbench can be used by students, instructors, developers and researchers alike and managed easily...|$|R
40|$|The Orbit Determination Toolbox is {{an orbit}} {{determination}} (OD) analysis tool based on MATLAB and Java {{that provides a}} flexible way to do early mission analysis. The toolbox is primarily intended for advanced mission analysis such as might be performed in concept exploration, proposal, early design phase, or rapid design center environments. The emphasis is on flexibility, but it has enough fidelity to produce credible results. Insight into all flight dynamics source code is provided. MATLAB is the primary user interface and is used for piecing together measurement and dynamic models. The Java Astrodynamics Toolbox is used as an engine for things that might be slow or inefficient in MATLAB, such as high-fidelity trajectory propagation, lunar and planetary ephemeris look-ups, precession, nutation, polar motion calculations, ephemeris file parsing, and the like. The primary analysis functions are sequential filter/smoother and <b>batch</b> least-squares <b>commands</b> that incorporate Monte-Carlo data simulation, linear covariance analysis, measurement processing, and plotting capabilities at the generic level. These functions have a user interface {{that is based on}} that of the MATLAB ODE suite. To perform a specific analysis, users write MATLAB functions that implement truth and design system models. The user provides his or her models as inputs to the filter commands. The software provides a capability to publish and subscribe to a software bus that is compliant with the NASA Goddard Mission Services Evolution Center (GMSEC) standards, to exchange data with other flight dynamics tools to simplify the flight dynamics design cycle. Using the publish and subscribe approach allows for analysts in a rapid design center environment to seamlessly incorporate changes in spacecraft and mission design into navigation analysis and vice versa...|$|R
40|$|This {{thesis is}} about the study of {{relationships}} between experimental dynamical systems. The basic approach is to fit radial basis function maps between time delay embeddings of manifolds. We have shown that under certain conditions these maps are generically diffeomorphisms, and can be analysed {{to determine whether or}} not the manifolds in question are diffeomorphically related to each other. If not, a study of the distribution of errors may provide information about the lack of equivalence between the two. The method has applications wherever two or more sensors are used to measure a single system, or where a single sensor can respond on more than one time scale: their respective time series can be tested {{to determine whether or not}} they are coupled, and to what degree. One application which we have explored is the determination of a minimum embedding dimension for dynamical system reconstruction. In this special case the diffeomorphism in question is closely related to the predictor for the time series itself. Linear transformations of delay embedded manifolds can also be shown to have nonlinear inverses under the right conditions, and we have used radial basis functions to approximate these inverse maps in a variety of contexts. This method is particularly useful when the linear transformation corresponds to the delay embedding of a finite impulse response filtered time series. One application of fitting an inverse to this linear map is the detection of periodic orbits in chaotic attractors, using suitably tuned filters. This method has also been used to separate signals with known bandwidths from deterministic noise, by tuning a filter to stop the signal and then recovering the chaos with the nonlinear inverse. The method may have applications to the cancellation of noise generated by mechanical or electrical systems. In the course of this research a sophisticated piece of software has been developed. The program allows the construction of a hierarchy of delay embeddings from scalar and multi-valued time series. The embedded objects can be analysed graphically, and radial basis function maps can be fitted between them asynchronously, in parallel, on a multi-processor machine. In addition to a graphical user interface, the program can be driven by a <b>batch</b> mode <b>command</b> language, incorporating the concept of parallel and sequential instruction groups and enabling complex sequences of experiments to be performed in parallel in a resource-efficient manner...|$|R
40|$|Abstract Background The development, in {{the last}} decade, of {{stochastic}} heuristics implemented in robust application softwares has made large phylogeny inference a key step in most comparative studies involving molecular sequences. Still, {{the choice of a}} phylogeny inference software is often dictated by a combination of parameters not related to the raw performance of the implemented algorithm(s) but rather by practical issues such as ergonomics and/or the availability of specific functionalities. Results Here, we present MetaPIGA v 2. 0, a robust implementation of several stochastic heuristics for large phylogeny inference (under maximum likelihood), including a Simulated Annealing algorithm, a classical Genetic Algorithm, and the Metapopulation Genetic Algorithm (metaGA) together with complex substitution models, discrete Gamma rate heterogeneity, and the possibility to partition data. MetaPIGA v 2. 0 also implements the Likelihood Ratio Test, the Akaike Information Criterion, and the Bayesian Information Criterion for automated selection of substitution models that best fit the data. Heuristics and substitution models are highly customizable through manual <b>batch</b> files and <b>command</b> line processing. However, MetaPIGA v 2. 0 also offers an extensive graphical user interface for parameters setting, generating and running batch files, following run progress, and manipulating result trees. MetaPIGA v 2. 0 uses standard formats for data sets and trees, is platform independent, runs in 32 and 64 -bits systems, and takes advantage of multiprocessor and multicore computers. Conclusions The metaGA resolves the major problem inherent to classical Genetic Algorithms by maintaining high inter-population variation even under strong intra-population selection. Implementation of the metaGA together with additional stochastic heuristics into a single software will allow rigorous optimization of each heuristic as well as a meaningful comparison of performances among these algorithms. MetaPIGA v 2. 0 gives access both to high customization for the phylogeneticist, as well as to an ergonomic interface and functionalities assisting the non-specialist for sound inference of large phylogenetic trees using nucleotide sequences. MetaPIGA v 2. 0 and its extensive user-manual are freely available to academics at [URL]. </p...|$|R

