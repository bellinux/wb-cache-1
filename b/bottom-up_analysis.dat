162|132|Public
50|$|FTA is a deductive, {{top-down}} method aimed at analyzing {{the effects of}} initiating faults and events on a complex system. This contrasts with failure mode and effects analysis (FMEA), which is an inductive, <b>bottom-up</b> <b>analysis</b> method aimed at analyzing the effects of single component or function failures on equipment or subsystems. FTA {{is very good at}} showing how resistant a system is to single or multiple initiating faults. It is not good at finding all possible initiating faults. FMEA is good at exhaustively cataloging initiating faults, and identifying their local effects. It is not good at examining multiple failures or their effects at a system level. FTA considers external events, FMEA does not. In civil aerospace the usual practice is to perform both FTA and FMEA, with a failure mode effects summary (FMES) as the interface between FMEA and FTA.|$|E
50|$|There {{have only}} been two {{detailed}} studies of the economic cost of FOD for civil airline operations. The first was by Brad Bachtel of Boeing, who published a value of $4 billion USD per year. This top-down value was for several years the standard industry figure {{for the cost of}} FOD. The second work (2007) was by Iain McCreary from the consultancy Insight SRI Ltd. This more detailed report offered a first-cut of the cost of FOD, based on a <b>bottom-up</b> <b>analysis</b> of airline maintenance log records. Here, data was broken into Per Flight Direct Costs and Per Flight Indirect Costs for the top 300 global airports, with detailed footnotes on the supporting data. The Insight SRI research was a standard reference for 2007-2009 as it was the only source presenting costs and thus was quoted by regulators, airports, and technology providers alike.|$|E
5000|$|Suding holds a Diploma in {{business}} administration (1973) and a Ph.D. in economics (1983), with specialization in energy economics from the University of Cologne. For his doctoral dissertation [...] he received the Theodor Wessels Award in 1984. Suding has worked since 1973 as researcher and lecturer at the Institute of Energy Economics (EWI) at the University of Cologne, and from 1981 to 1989 as Partner in the German consulting firm ENERWA. He pioneered technical-economic analysis of energy consumption, first disaggregation of residential and small users energy consumption in Germany and <b>bottom-up</b> <b>analysis</b> and energy prognosis. 1976/77 he was Associate in the Global Workshop on Alternative Energy Strategies WAES. In GIZ, {{he was responsible for}} various German bilateral energy and environment programs in Burundi (1989-93), China (1999 - 2006) and Egypt (2008 - 2010), financed by the Federal Ministry of Economic Cooperation and Development (BMZ). He also was from 1993-99 the German Director of the Sustainable Energy and Development cooperation program with the Organización Latino Americana de Energía OLADE and ECLAC (United Nations Economic Commission for Latin America and the Caribbean). From 2008 until retirement in 2014 he was Director of a cooperation program on climate change and energy for Latin America and the Caribbean with the Inter-American Development Bank IDB.|$|E
40|$|This paper {{discusses}} <b>bottom-up</b> grammar <b>analysis</b> {{problems such}} as te EMPTY problem and the FIRST problem. It defines a general class of <b>bottom-up</b> grammar <b>analysis</b> problems, and from this definition it derives a functional program for performing <b>bottom-up</b> grammar <b>analysis.</b> The derivation is purely calculational, using theorems from lattice therory, the Bird-Meertens calculus, and laws for list-comprehensions. Sufficient conditions guaranteeing {{the existence of a}} solution emerge as a byproduct of the calculation. The resulting program is used to construct programs for the EMPTY problem and the FIRST problem...|$|R
50|$|Business process {{discovery}} {{creates a}} process master which complements business process analysis (BPA). BPA tools and methodologies are {{well suited to}} top-down hierarchical process decomposition, and analysis of to-be processes. BPD provides a <b>bottoms-up</b> <b>analysis</b> that marries to the top-down to provide a complete business process, organized hierarchically by BPA.|$|R
50|$|Another {{meaning of}} {{fundamental}} <b>analysis</b> is beyond <b>bottom-up</b> company <b>analysis,</b> {{it refers to}} top-down analysis from first analyzing the global economy, followed by country analysis and then sector analysis, and finally the company level analysis.|$|R
40|$|<b>Bottom-up</b> <b>analysis</b> has {{an elegant}} {{semantic}} basis, straightforward implementation, and flexible application. Several recent studies indicate good prospects for flexible and efficient analysis systems based on bottom-up core semantics. In addition, goal-directed or top-down analyses can be simulated {{through the use}} of query-answer transformations, of which the so-called "magic set" method is one. These transformations can also serve to increase precision with respect to <b>bottom-up</b> <b>analysis.</b> A toolkit of <b>bottom-up</b> <b>analysis</b> tools and query-answer transformations has been built up, based on a number of experiments over three years. These tools and aspects of their implementation will be described. Efficient algorithms for <b>bottom-up</b> <b>analysis</b> {{are at the heart of}} the toolkit. A systematic method for implementing analyses using the tools is then set out. The method is based on (i) abstract compilation of a program into a "domain program", (ii) computation of (an approximation to) the model of th [...] ...|$|E
40|$|Most of {{behavior}} recognition methods proposed so far share {{the limitations of}} <b>bottom-up</b> <b>analysis,</b> and single-object assumption; the <b>bottom-up</b> <b>analysis</b> can be confused by erroneous and missing image features and the single-object assumption prevents us from analyzing image se-quences including multiple moving objects. This paper presents a robust behavior recognition method free from these limitations. Our method is best characterized by 1) top-down image feature extraction by selective atten-tion mechanism, 2) object discrimination by colored-token propagation, and 3) integration of multi-viewpoint images. Extensive experiments of human behavior recognition in real world environments demonstrate the soundness and robustness of our method. ...|$|E
40|$|In {{this section}} we will {{introduce}} some terminology related to computer vision. Terms such as computational vision, image processing, computer vision, image understanding, low-level vision, intermediate-level vision, high-level vision, top-down analysis, <b>bottom-up</b> <b>analysis,</b> and other terms {{are often used}} to describe some aspect o...|$|E
40|$|In this paper, {{a system}} is {{described}} for the recognition of mixtures of noise sources in acoustic input signals. The problem is approached by utilizing both <b>bottom-up</b> signal <b>analysis</b> and top-down predictions of higher-level models. The developments are made using musical signals as test material. Validation experiments are presented both for selfgenerated sound mixtures and for real musical recordings. ...|$|R
40|$|This {{article is}} an {{editorial}} note submitted to CCR. It has NOT been peer reviewed. The author takes {{full responsibility for}} this article’s technical content. Comments can be posted through CCR Online. Network management represents an architectural gap in today’s Internet [1]. Many problems with computer networks today, such as faults, misconfiguration, performance degradation, etc., are due to insufficient support for network management, and the problem takes on additional dimensions with the emerging programmable router paradigm. The Internet Network Management Workshop is working to build a community of researchers interested in solving the challenges of network management via a combination of <b>bottoms-up</b> <b>analysis</b> of data from existing networks and a top-down design of new architectures and approaches driven by that data. This editorial sets {{out some of the}} research challenges we see facing network management, and calls for participation in working to solve them...|$|R
5000|$|In {{this section}} we will {{walk through the}} steps of a <b>bottom-up</b> {{document}} layout <b>analysis</b> algorithm developed in 1993 by O`Gorman. The steps in this approach are as follows: ...|$|R
40|$|Technology {{foresight}} {{studies have}} become an important tool in identifying realistic ways of reducing the impact of modern energy systems on the climate and the environment. Studies on the future cost development of advanced energy technologies are of special interest. One approach widely adopted {{for the analysis of}} future cost is the experience curve approach. The question is, however, how robust this approach is, and which experience curves should be used in energy foresight analysis. This paper presents an analytical framework for the analysis of future cost development of new energy technologies for electricity generation; the analytical framework is based on an assessment of available experience curves, complemented with <b>bottom-up</b> <b>analysis</b> of sources of cost reductions and, for some technologies, judgmental expert assessments of long-term development paths. The results of these three methods agree in most cases, i. e. the cost (price) reductions described by the experience curves match the incremental cost reduction described in the <b>bottom-up</b> <b>analysis</b> and the judgmental expert assessments. For some technologies, the <b>bottom-up</b> <b>analysis</b> confirms large uncertainties in future cost development not captured by the experience curves. Experience curves with a learning rate ranging from 0 % to 20 % are suggested for the analysis of future cost development. ...|$|E
40|$|This Paper {{presents}} {{a new approach}} how to analyze research topics within a given research community. Under {{the guidance of the}} I-system methodology, this paper conducts both top-down and <b>bottom-up</b> <b>analysis.</b> For the <b>bottom-up</b> <b>analysis,</b> similarity measurement and hierarchical clustering are applied to obtain a tree-like dendrogram structure of research topics; for the top-down analysis, the experts' knowledge is included. Then resulting from the iterative dialogue between the above two stages of automatic construction and expert- supervision, an ontology structure of research topics is finally achieved. The original publication is available at JAIST Press [URL] of KSS' 2007 : The Eighth International Symposium on Knowledge and Systems Sciences : November 5 - 7, 2007, [Ishikawa High-Tech Conference Center, Nomi, Ishikawa, JAPAN]Organized by: Japan Advanced Institute of Science and Technolog...|$|E
40|$|Goal {{independent}} {{analysis of}} logic programs is commonly {{discussed in the}} context of the bottom-up approach. However, while the literature is rich in descriptions of top-down analysers and their application, practical experience with <b>bottom-up</b> <b>analysis</b> is still in a preliminary stage. Moreover, the practical use of existing top-down frameworks for goal independent analysis has not been addressed in a practical system. We illustrate the efficient use of existing goal dependent, top-down frameworks for abstract interpretation in performing goal independent analyses of logic programs much the same as those usually derived from bottom-up frameworks. We present several optimizations for this flavour of top-down analysis. The approach is fully implemented within an existing top-down framework. Several implementation tradeoffs are discussed as well as the influence of domain characteristics. An experimental evaluation including a comparison with a <b>bottom-up</b> <b>analysis</b> for the domain Prop is p [...] ...|$|E
50|$|The systematic, {{attentive}} approach {{caused by}} negative affect reduces fundamental attribution error, {{the tendency to}} inaccurately attribute behavior to a person’s internal character without taking external, situational factors into account. The fundamental attribution error (FAE) is connected with positive affect since it occurs when people use top-down cognitive processing based on inferences. Negative affect stimulates <b>bottom-up,</b> systematic <b>analysis</b> that reduces fundamental attribution error.|$|R
50|$|Pattern-oriented {{modeling}} (POM) is {{an approach}} to <b>bottom-up</b> complex systems <b>analysis</b> that was developed to model complex ecological and agent-based systems. A goal of POM is to make ecological modeling more rigorous and comprehensive.|$|R
50|$|York Capital uses a {{fundamental}} <b>analysis,</b> <b>bottom-up</b> approach {{to make its}} investments. The firm focuses on three event-driven investing strategies: merger and acquisition transactions, distressed securities and restructuring opportunities and special situation equity investing.|$|R
40|$|Two generic {{mechanisms}} are proposed that facilitate the efficient integration of audio content analysis algorithms. The first mechanism, priorityrule based interleaving of algorithms, allows the simultaneous interoperation of several <b>bottom-up</b> <b>analysis</b> modules by interleaving their atomic steps. It aims at increased accuracy through controlled manipulation of common data. The second mechanism, top-down routing of requests for data, allows high-level predictions {{to direct the}} <b>bottom-up</b> <b>analysis</b> towards verifying the predicted hypotheses by observations. Examples from automatic music transcription are presented to clarify {{the use of the}} proposed methods. KLAPURI AUDIO CONTENT ANALYSIS AES 110 TH CONVENTION, AMSTERDAM, NETHERLANDS, 2001 MAY 12 [...] 15 2. System should be able to handle uncertain data, and let several alternative explanations evolve side-by-side. In this paper, a so-called blackboard architecture was selected to be the implementational starting point. Blackboard systems, [...] ...|$|E
40|$|This work {{is devoted}} to grammar systems. Defines {{cooperating}} distributed grammar systems CD and parallel communicating grammar systems PC in conjunction with context-free grammars. It also examines their principles and generative forces in different regime and to different languages. Studying the use of grammatical parsing systems. It focuses primarily on top-down parsing and precedential <b>bottom-up</b> <b>analysis</b> {{in conjunction with the}} PC grammar systems...|$|E
40|$|In {{this paper}} {{we present a}} tool to assist in {{teaching}} top-down and <b>bottom-up</b> <b>analysis</b> algorithms. The tool provides simu-lation for the following analysis algorithms: LL, SLR, LALR and LR. During the simulation the student can simultane-ously see the pending input, the analysis stack and tables, the generated output and the parse tree. Categories and Subject Descriptors F. 4. 2 [Mathematical Logic and Formal Languages]: Grammars and other Rewriting Systems—grammar type, parsin...|$|E
50|$|Davidson Kempner uses a {{fundamental}} <b>analysis,</b> <b>bottom-up</b> approach {{to make its}} investments. The firm focuses on five investment strategies: merger arbitrage, distressed investments, long/short equity, convertible bonds arbitrage and long/short credit, with a particular focus on distressed investments and merger arbitrage.|$|R
40|$|Syntax-directed {{translation}} {{based on}} state grammars is introduced in this bachelor's thesis. Theoretical {{section of this}} thesis {{is focused on the}} introduction of theoretical models that are necessary for understanding syntax analysis based on state grammars. The most important theoretical formal models in this thesis include deep pushdown transducer and translation grammar based on state grammar, which can be used in syntax analysis. Practical section of this thesis is focused on <b>bottom-up</b> syntax <b>analysis</b> using state grammar and its implementation...|$|R
40|$|Introduction: Microwave-assisted acid {{hydrolysis}} {{has recently been}} reported in the literature as a tool for <b>bottom-up</b> proteomic <b>analysis</b> as well as increase coverage of proteins when traditional proteolytic cleavage sites are not present, and also for identification and characterization of the termini of proteins. Here two microwave-assisted acid proteolysis methods were compared, one involved the use of trifluoroacetic acid (TFA) and the other with formic acid. In this experiment, we monitored the; acid cleavage specificity; reaction / preparation time overall protein coverage; and N- and C-terminal coverage...|$|R
40|$|We {{conducted}} a <b>bottom-up</b> <b>analysis</b> using stock and usage estimates from secondary sources, {{and our own}} power measurements. We measured power levels {{of the most common}} audio products in their most commonly used operating modes. We found that the combined energy consumption of standby, idle, and play modes of clock radios, portable stereos, compact stereos, and component stereos was 20 TWh/yr, representing about 1. 8 % of the 1998 national residential electricity consumption...|$|E
40|$|Today's complex {{embedded}} systems integrate multiple {{hardware and software}} components, many of them provided as IP from different vendors. Performance analysis is crucial for such heterogeneous systems. There already exists a variety of formal timing analysis techniques for small sub-problems, e. g. task performance, scheduling strategies, etc [...] In this paper, we analyze these individual approaches {{in the context of}} performance analysis of heterogeneous platforms at different levels of abstraction, and present a three-level <b>bottom-up</b> <b>analysis</b> procedure...|$|E
40|$|We firstly {{provide a}} {{systematic}} <b>bottom-up</b> <b>analysis</b> of energy efficiency potentials in different sectors (households, industry, and transport) building on sector specific detail {{and focusing on}} economic potentials which will be refinanced by the energy saving over the lifetime of the appliances. Secondly, the economy-wide impacts of the exploitation of these efficiency potentials are analyzed in a macroeconomic context. Special attention {{is given to the}} rebound effect and the results deliver effects on the sector and economy level...|$|E
40|$|Liquid AP-MALDI {{can produce}} {{predominantly}} multiply charged ESI-like ions and stable durable analyte ion yields with samples allowing good shot-to-shot reproducibility and exhibiting self-healing properties during laser irradiation. In this study, LC-MALDI MS/MS workflows that utilize multiply charged ions are {{reported for the}} first time and compared with standard LC-ESI MS/MS for <b>bottom-up</b> proteomic <b>analysis.</b> The proposed method is compatible with trifluoroacetic acid as an LC ion pairing reagent and allows multiple MS/MS acquisitions of the LC-separated samples without substantial sample consumption. In addition, the method facilitates the storage of fully spotted MALDI target plates for months without significant sample degradation...|$|R
40|$|This paper {{investigates the}} {{economic}} impacts of two policy proposals, "Strom ohne Atom" (SOA) and "Moratorium Plus" (MOP), {{both of which}} contain a premature phase-out of nuclear power in Switzerland. Based on simulations with an intertemporal multi-sector computable general equilibrium (CGE) model of the Swiss economy, we quantify the price tags for risk reduction from nuclear power operation given additional constraints on backup technologies and carbon neutrality. An important feature of the dynamic CGE model underlying our <b>analysis</b> is the <b>bottom-up</b> activity <b>analysis</b> representation of electricity generation in an otherwise top-down framework. nuclear phase-out; computable general equilibrium; activity analysis...|$|R
40|$|Abstract. A {{structural}} knowledge-based {{search method}} is utilized for {{the estimation of}} geometric transforms from airborne video sequences. Examples are projective planar homographies and constraints such as the fundamental matrix. These estimations are calculated from correspondences of interest points between two images. Different approaches are discussed {{to cope with the}} problem of outliercorrespondences. To ensure any-time performance the search process is implemented in a data-driven production system. The pose estimation from planar homographies is compared to estimations from fundamental matrices. A fusion of both approaches is proposed. The image processing is performed by <b>bottom-up</b> structural <b>analysis</b> using an assessment-driven control. Examples are from the thermal spectral domain. ...|$|R
40|$|Most tourism-related {{activities}} require energy {{directly in}} the form of fossil fuels or in{{directly in the}} form of electricity often generated from petroleum, coal or gas. This consumption leads to the emission of greenhouse gases, mainly carbon dioxide. Tourism is not a traditional sector in the System of National Accounts and as a result no country possesses comprehensive national statistics on the energy demand or emissions specifically resulting from tourism. This paper suggests two approaches for accounting for carbon dioxide emissions from tourism: a <b>bottom-up</b> <b>analysis</b> involving industry and tourist analyses, and a top-down analysis using environmental accounting. Using the case study of New Zealand, we demonstrate that both approaches result in similar estimates {{of the degree to which}} tourism contributes to national carbon dioxide emissions. The <b>bottom-up</b> <b>analysis</b> provides detailed information on energy end-uses and the main drivers of carbon dioxide emissions. These results can be used for the development of targeted industry-based greenhouse gas reduction strategies. The top-down analysis allows assessment of tourism as a sector within the wider economy, for example with the purpose of comparing tourism's eco-efficiency with other sectors, or the impact of macroeconomic instruments such as carbon charges. No Full Tex...|$|E
40|$|We {{present a}} {{precursor}} ion independent top-down algorithm (PIITA) {{for use in}} automated assignment of protein identifications from tandem mass spectra of whole proteins. To acquire the data, we utilize data-dependent acquisition to select protein precursor ions eluting from a C 4 -based HPLC column for collision induced dissociation in the linear ion trap of an LTQ-Orbitrap mass spectrometer. Gas-phase fractionation is used {{to increase the number}} of acquired tandem mass spectra, all of which are recorded in the Orbitrap mass analyzer. To identify proteins, the PIITA algorithm compares deconvoluted, deisotoped, observed tandem mass spectra to all possible theoretical tandem mass spectra for each protein in a genomic sequence database without regard for measured parent ion mass. Only after a protein is identified, is any difference in measured and theoretical precursor mass used to identify and locate post-translation modifications. We demonstrate the application of PIITA to data generated via our wet-lab approach on a Salmonella typhimurium outer membrane extract and compare these results to <b>bottom-up</b> <b>analysis.</b> From these data, we identify 154 proteins by top-down analysis, 73 of which were not identified in a parallel <b>bottom-up</b> <b>analysis.</b> We also identify 201 unique isoforms of these 154 proteins at a false discovery rate (FDR) of < 1 %...|$|E
40|$|This study {{examines}} how Palestinian dead bodies and spaces {{of death in}} occupied East Jerusalem are ‘hot spots ’ of criminality. The arguments raised challenge traditional hot-spot theories of crime that build their definition of criminality around official state statistics and information and visible spaces of crime. The paper offers a <b>bottom-up</b> <b>analysis</b> of crimes against the dead and their families in East Jerusalem, examining {{the manner in which}} modes of denial, the logic of elimination and accumulation by dispossession shape experiences of death and dying in a colonial context...|$|E
40|$|In {{recognizing}} spontaneous speech, {{the performance}} of typical speech recognizers tends to be degraded by filled and silent pauses, which are hesitation phenomena frequently occurred in such speech. In this paper, we present a method for improving {{the performance of}} a speech recognizer by detecting and handling both filled pauses (lengthened vowels) and silent (unfilled) pauses. Our method automatically detects these pauses by using a <b>bottom-up</b> acoustical <b>analysis</b> in parallel with a typical speech decoding process, and then incorporates the detected results into the decoding process. From the results of experiments conducted using the CIAIR spontaneous speech corpus, the effectiveness of the proposed method was confirmed...|$|R
50|$|Finally, {{the loss}} of {{positive}} charge at physiological pH caused by citrullination can be utilized. Prior to <b>bottom-up</b> proteomics <b>analysis,</b> proteins are enzymatically cleaved into peptides. Commonly the protease trypsin is used, which cleaves after the positively charged arginine and lysine residues. However, trypsin is unable to cleave after a citrulline residue which is neutral. A missed cleavage after a citrulline residue together with the correct mass shift {{can be used as}} a specific and sensitive marker for citrullination, and the strategy is compatible with standard bottom-up proteomics workflows. Additionally, {{the loss of}} positive charge ensures that the citrullinated and unmodified peptides will not elute simultaneously from reversed phase C18 liquid chromatography columns, which otherwise could be a problem.|$|R
40|$|International audienceIn this article, {{we present}} a best {{practise}} approach for the evaluation and assessment of IT security demands for railway applications. State-of-the-art standards and guidelines are used to identify and evaluate threats concerning the IT security of a given railway system and corresponding requirements are derived. Taking threat mitigation measures into account, the system under consideration is revised based on its technology and system architecture. Using combined " Top-Down " and " <b>Bottom-Up</b> " <b>analysis</b> techniques, the most relevant attack patterns and penetration paths are identified for each system component or function. The result of such an analysis may require iterative revisions and eventually extends IT security requirements {{as compared to the}} derivation from standards...|$|R
