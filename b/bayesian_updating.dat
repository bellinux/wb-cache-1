742|379|Public
2500|$|Principle of {{restricted}} choice – similar {{application of}} <b>Bayesian</b> <b>updating</b> in contract bridge ...|$|E
5000|$|... #Subtitle level 2: Kullback-Leibler {{divergence}} and <b>Bayesian</b> <b>updating</b> ...|$|E
5000|$|Principle of {{restricted}} choice - similar {{application of}} <b>Bayesian</b> <b>updating</b> in contract bridge ...|$|E
40|$|Given: a {{physical}} system modeled by a PDE or ODE with uncertain coefficient q(?), a measurement operator Y (u(q), q), where u(q, ?) uncertain solution. Aim: to identify q(?). The mapping from parameters to observations {{is usually not}} invertible, hence this inverse identification problem is generally ill-posed. To identify q(!) we derived non-linear <b>Bayesian</b> <b>update</b> from the variational problem associated with conditional expectation. To reduce cost of the <b>Bayesian</b> <b>update</b> we offer a unctional approximation, e. g. polynomial chaos expansion (PCE). New: We apply <b>Bayesian</b> <b>update</b> to the PCE coefficients of the random coefficient q(?) (not to the probability density function of q) ...|$|R
40|$|Eichberger, Grant, and Kelsey (2007) {{characterize}} the full <b>Bayesian</b> <b>update</b> rule for capacities. This paper {{shows that a}} conditional preference relation represented by the Choquet expected utility {{with respect to the}} updated capacity through the rule does not satisfy the axiom of Conditional Certainty Equivalence Consistency. A counterexample is provided and it is proved that a relaxation of the axiom maintains their results. <b>Bayesian</b> <b>update,</b> capacity, conditional preference, Choquet expected utility...|$|R
2500|$|This can {{be written}} {{as a set of}} <b>Bayesian</b> <b>update</b> {{equations}} for the posterior parameters in terms of the prior parameters: ...|$|R
50|$|<b>Bayesian</b> <b>updating</b> {{is widely}} used and {{computationally}} convenient. However, {{it is not the}} only updating rule that might be considered rational.|$|E
50|$|Charness, Gary and Dan Levin (2005), “When Optimal Choices Feel Wrong: A Laboratory Study of <b>Bayesian</b> <b>Updating,</b> Complexity, and Affect,” American Economic Review, 95, 1300-1309.|$|E
50|$|The {{principle}} of restricted choice is {{an application of}} Bayes Law. Increases and decreases in the probabilities of original lies of the opposing cards, as the play of the hand proceeds, are examples of <b>Bayesian</b> <b>updating</b> as evidence accumulates.|$|E
5000|$|... {{the family}} {{exhibits}} the first-order (and hence second-order) stochastic dominance in , {{and the best}} <b>Bayesian</b> <b>update</b> of [...] is increasing in [...]|$|R
30|$|Shown are the pdfs {{produced}} by the linear filter according to Eq. (42)—Linear polynomial chaos <b>Bayesian</b> <b>update</b> (Linear PCBU)—a special form of Eq. (28), also with an iterated linear filter—iterative LPCBU—using Newton iterations, i.e. an iterated version of Eq. (42), and using polynomials up to order two, the quadratic polynomial chaos <b>Bayesian</b> <b>update</b> (QPCBU). One may observe that due to the nonlinear observation, {{the differences between the}} linear filters and the quadratic one are already significant, the QPCBU yielding a better update.|$|R
50|$|Predictive coding is a neurobiologically {{plausible}} {{scheme for}} inferring {{the causes of}} sensory input based on minimizing prediction error. These schemes are related formally to Kalman filtering and other <b>Bayesian</b> <b>update</b> schemes.|$|R
5000|$|In fact, {{there are}} non-Bayesian {{updating}} rules that also avoid Dutch books (as {{discussed in the}} literature on [...] "probability kinematics" [...] following the publication of Richard C. Jeffreys' rule, which is itself regarded as Bayesian). The additional hypotheses sufficient to (uniquely) specify <b>Bayesian</b> <b>updating</b> are substantial and not universally seen as satisfactory.|$|E
50|$|Richard T. Cox {{showed that}} <b>Bayesian</b> <b>updating</b> follows from several axioms, {{including}} two functional equations and a hypothesis of differentiability. The assumption of differentiability or even continuity is controversial; Halpern found a counterexample {{based on his}} observation that the Boolean algebra of statements may be finite. Other axiomatizations have been suggested by various authors {{with the purpose of}} making the theory more rigorous.|$|E
50|$|The {{conventional}} {{method of}} Surveillance {{does not apply}} for a partially visible system. Therefore, a new method is required to observe such complex system at any time given. The Surveillance of a partially observable system offers a mathematical model that uses Markov Chains, paired with a <b>Bayesian</b> <b>updating</b> function. The method estimates the statistical impacts of surveillance observations and modified surveillance policies.|$|E
25|$|The Ensemble Kalman Filter (EnKF) is a Monte Carlo {{implementation}} of the <b>Bayesian</b> <b>update</b> problem: given a probability density function (pdf) {{of the state of}} the modeled system (the prior, called often the forecast in geosciences) and the data likelihood, the Bayes theorem is used to obtain the pdf after the data likelihood has been taken into account (the posterior, often called the analysis). This is called a <b>Bayesian</b> <b>update.</b> The <b>Bayesian</b> <b>update</b> is combined with advancing the model in time, incorporating new data from time to time. The original Kalman Filter assumes that all pdfs are Gaussian (the Gaussian assumption) and provides algebraic formulas for the change of the mean and the covariance matrix by the <b>Bayesian</b> <b>update,</b> as well as a formula for advancing the covariance matrix in time provided the system is linear. However, maintaining the covariance matrix is not feasible computationally for high-dimensional systems. For this reason, EnKFs were developed. EnKFs represent the distribution of the system state using a collection of state vectors, called an ensemble, and replace the covariance matrix by the sample covariance computed from the ensemble. The ensemble is operated with as if it were a random sample, but the ensemble members are really not independent – the EnKF ties them together. One advantage of EnKFs is that advancing the pdf in time is achieved by simply advancing each member of the ensemble. For a survey of EnKF and related data assimilation techniques, see G. Evensen.|$|R
40|$|In a Bayesian setting, inverse {{problems}} and uncertainty quantification (UQ) - {{the propagation of}} uncertainty through a computational (forward) model - are strongly connected. In the form of conditional expectation the <b>Bayesian</b> <b>update</b> becomes computationally attractive. This is especially the case as together with a functional or spectral approach for the forward UQ {{there is no need}} for time-consuming and slowly convergent Monte Carlo sampling. The developed sampling-free non-linear <b>Bayesian</b> <b>update</b> is derived from the variational problem associated with conditional expectation. This formulation in general calls for further discretisation to make the computation possible, and we choose a polynomial approximation. After giving details on the actual computation in the framework of functional or spectral approximations, we demonstrate the workings of the algorithm on a number of examples of increasing complexity. At last, we compare the linear and quadratic <b>Bayesian</b> <b>update</b> on the small but taxing example of the chaotic Lorenz 84 model, where we experiment with the influence of different observation or measurement operators on the update. Comment: 25 pages, 17 figures. arXiv admin note: text overlap with arXiv: 1201. 404...|$|R
30|$|It is {{well-known}} {{that such a}} <b>Bayesian</b> <b>update</b> is in fact closely related to conditional expectation [1, 6, 10, 18, 24], {{and this will be}} the basis of the method presented. For these and other probabilistic notions see for example [22] and the references therein. As the <b>Bayesian</b> <b>update</b> may be numerically very demanding, we show computational procedures to accelerate this update through methods based on functional approximation or spectral representation of stochastic problems [17, 18]. These approximations are in the simplest case known as Wiener’s so-called homogeneous or polynomial chaos expansion, which are polynomials in independent Gaussian RVs—the “chaos”—and which can also be used numerically in a Galerkin procedure [17, 18].|$|R
5000|$|Indeed, {{there are}} non-Bayesian {{updating}} rules that also avoid Dutch books (as {{discussed in the}} literature on [...] "probability kinematics") following the publication of Richard C. Jeffrey's rule, which applies Bayes' rule to the case where the evidence itself is assigned a probability. The additional hypotheses needed to uniquely require <b>Bayesian</b> <b>updating</b> have been deemed to be substantial, complicated, and unsatisfactory.|$|E
5000|$|The THERP HRAETs implicitly {{assume that}} each sub-task’s HEP is {{independent}} from all others i.e. the HRAET does not update {{itself in the}} event that an operator takes a sub-optimal route through the task path. This is reinforced by the HEP being merely reduced by the chance of recovery from a mistake, rather than by introducing alternative (i.e. sub-optimal) “success” routes into the event-tree, which could allow for <b>Bayesian</b> <b>updating</b> of subsequent HEPs.|$|E
50|$|In fact, that step, Bayes' rule of updating, can be justified, as {{necessary}} and sufficient, through a dynamic Dutch book argument that is additional to the arguments {{used to justify}} the probability axioms. This argument was first put forward by David Lewis in the 1970s though he never published it. The dynamic Dutch book argument for <b>Bayesian</b> <b>updating</b> has been criticised by Hacking, H. Kyburg,, D. Christensen and P. Maher. It was defended by Brian Skyrms.|$|E
40|$|We {{describe}} a simple method for exact on-line inference {{and decision making}} for par-tially observable and large Markov decision processes. This {{is based on a}} closed form <b>Bayesian</b> <b>update</b> procedure for certain classes of models exhibiting a special conditional in-dependence structure, which can be used for prediction, and consequently for planning. 1...|$|R
40|$|MM {{stochastic}} {{control of}} dosage regimens permits essentially {{full use of}} information, either in a population pharmacokinetic model or a <b>Bayesian</b> <b>updated</b> MM parameter set, to achieve and maintain selected therapeutic goals with optimal precision. The regimens are visibly more precise than those developed using mean parameter values. Bayesian MM feedback has now also been implemented...|$|R
40|$|An {{evolutionary}} form of {{a generalized}} <b>Bayesian</b> <b>update</b> method, which is strictly derivative- free yet directed through an additive update term based purely on the statistical moments of the design variables, is proposed for nonlinear inverse problems in general and applied in particular to an optical imaging problem, the ultrasound modulated optical tomography (UMOT). The additive update term, which bypasses most pitfalls of a conventional weight- based <b>Bayesian</b> <b>update,</b> results from a change of measures aimed at driving appropriately derived observation-prediction error terms or increments of cost functionals to zero-mean Brownian martingales. This constitutes a novel characterization corresponding to the extremization of the cost functional(s), where the design unknowns are represented as diffusion processes evolving {{with respect to a}} continuously parameterized iteration variable. This leads to a recursive prediction-update algorithm to implement the search. The scheme offers freedom from sample degeneracy and the accompanying divergence of the conventional weight-based <b>Bayesian</b> <b>update</b> schemes. We obtain the order of convergence of the conditioned process and also establish that the solutions are stable against tolerable variations in the regularizing noise terms, even as the original inverse problem remains severely ill-posed. Numerical evidence on solutions to the UMOT problem also confirms substantive improvements in the reconstruction efficacy through the proposed method vis-à- vis a Gauss-Newton approach, especially where the regularized quasi-Newton direction has low sensitivity to variations in the design unknowns. Comment: 42 pages, 3 figures (not yet published in a refereed journal or any conference proceedings...|$|R
5000|$|<b>Bayesian</b> <b>updating</b> {{the first}} opinion {{with the second}} (or the other way round) implies {{certainty}} that the cause is B. Dempster's rule of combination lead to the same result. This {{can be seen as}} paradoxical, since although the two doctors point at different causes, A and C, they both agree that B is not likely. (For this reason the standard Bayesian approach is to adopt Cromwell's rule and avoid the use of 0 or 1 as probabilities.) ...|$|E
50|$|The {{expected}} value of including uncertainty (EVIU) compares {{the value of}} modeling uncertain information as compared to modeling a situation without taking uncertainty into account. Since the impact of uncertainty on computed results is often analysed using Monte Carlo methods, EVIU appears to be {{very similar to the}} value of carrying out an analysis using a Monte Carlo sample, which closely resembles in statement the notion captured with EVSI. However, EVSI and EVIU are quite distinct—a notable difference between the manner in which EVSI uses <b>Bayesian</b> <b>updating</b> to incorporate the simulated sample.|$|E
5000|$|Bayesian {{inference}} is {{a method}} of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics. <b>Bayesian</b> <b>updating</b> is particularly important in the dynamic analysis of a sequence of data. Bayesian inference has found application {{in a wide range}} of activities, including science, engineering, philosophy, medicine, sport, and law. In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called [...] "Bayesian probability".|$|E
30|$|Note that eq. (28) is {{effectively}} {{the same as}} the conventional <b>Bayesian</b> estimation <b>update</b> eq. (18).|$|R
40|$|International audienceAmbiguous {{beliefs are}} beliefs which are {{inconsistent}} with a unique, additive prior. The problem of their update in face {{of new information}} has been {{dealt with in the}} theoretical literature, and received several contradictory answers. In particular, the maximum likelihood update and the full <b>Bayesian</b> <b>update</b> have been axiomatized. This experimental study attempts to test the descriptive validity of these two theories by using the Ellsberg experiment framework...|$|R
40|$|In this work, {{we tried}} to show {{connections}} between <b>Bayesian</b> <b>update</b> and tensor completion techniques. Usually, only a small/sparse vector/tensor of measurements is available. The typical measurement {{is a function of}} the solution. The solution of a stochastic PDE is a tensor, the measurement as well. The idea is to use completion techniques to compute all "missing" values of the measurement tensor and only then apply the Bayesian technique...|$|R
50|$|An {{extensive}} {{amount of}} scientific research and philosophical discussion exists around the modification of beliefs, which is {{commonly referred to as}} belief revision.Generally speaking, the process of belief revision entails the believer weighing the set of truths and/or evidence, and the dominance of a set of truths or evidence on an alternative to a held belief can lead to revision. One process of belief revision is <b>Bayesian</b> <b>updating</b> and is often referenced for its mathematical basis and conceptual simplicity. However, such a process may not be representative for individuals whose beliefs are not easily characterized as probabilistic.|$|E
50|$|There {{are many}} systems {{that can be}} {{considered}} as partially observable due to their unknown or partially known structures or the nature of their unknown products and/or partially known results. The impacts of the consumption of genetically modified food (GM) are an example of a system that is only partially observable. The safety of genetically modified foods (GM) products has caused much controversy. Absence of sufficient and reliable information prevents neither certain confidence about the harmlessness of product consumption, nor any certain conclusion to merit a ban for fear of harm. The lack of any reliable or conclusive post-market observation and consumption effects information, make it difficult to establish a global protocol for such products. This paper introduces a model for the analysis of partially observable information from the surveillance of post-market consumption of systems such as genetically modified foods (GM) products. This model uses Markov Chains, paired with a <b>Bayesian</b> <b>updating</b> function to estimate the statistical impacts of surveillance observations and modified surveillance policies. A case study on population health status is used as an illustrative example, which is modeled to demonstrate the impact of policy interventions on simulated data. A cost decision analysis model is also applied to illustrate the impact of policy intervention costs. The model uses a first order Markov chain to estimate the period-over-period change in health status and a <b>Bayesian</b> <b>updating</b> procedure to estimate the population health status based on observations from post-market surveillance. The results show how observation samples can be used to provide information on system changes and improvements.|$|E
5000|$|In {{contract}} bridge, {{the principle}} of restricted choice states that play of a particular card decreases the probability its player holds any equivalent card. For example, South leads a low spade, West plays a low one, North plays the queen, East wins with the king. The ace and king are equivalent cards; East's play of the king decreases the probability East holds the ace [...] - [...] and increases the probability West holds the ace. The principle helps other players infer the locations of unobserved equivalent cards such as that spade ace after observing the king. The increase or decrease in probability {{is an example of}} <b>Bayesian</b> <b>updating</b> as evidence accumulates and particular applications of restricted choice are similar to the Monty Hall problem.|$|E
40|$|Based on the {{framework}} of partially observable Markov decision processes (POMDPs), this paper describes a practical real-time spoken dialogue {{system in which the}} underlying belief state is represented by a dynamic Bayesian Network and the policy is parameterized using a set of action-dependent basis functions. Tractable real-time <b>Bayesian</b> belief <b>updating</b> is made possible using a novel form of Loopy Belief Propagation and policy optimisation is performed using an episodic Natural Actor Critic algorithm. Details of these algorithms are provided along with evaluations of their accuracy and efficiency. The proposed POMDP-based architecture was tested using both simulations and a user trial. Both indicated that the incorporation of <b>Bayesian</b> belief <b>updating</b> significantly increases robustness to noise compared to traditional dialogue state estimation approaches. Furthermore, policy learning worked effectively and the learned policy outperformed all others on simulations. In user trials the learned policy was also competitive, although its optimality was less conclusive. Overall, the <b>Bayesian</b> <b>update</b> of dialogue state framework was shown to be a feasible and effective approach to building real-world POMDP-based dialogue systems...|$|R
40|$|A {{pressing}} {{question in}} Bayesian statistics and machine learning is {{to introduce a}} unified theoretical framework that brings together {{some of the many}} statistical models and algorithmic methodologies employed by practitioners. In this paper we suggest that the variational formulation of the <b>Bayesian</b> <b>update,</b> coupled with the theory of gradient flows, provides both an overarching structure and a powerful tool for the analysis of many such models and algorithms. As particular instances of our general framework, we provide three variational formulations of the <b>Bayesian</b> <b>update</b> with three associated gradient flows that converge to the posterior. We highlight the key unifying role of the concept of geodesic convexity, as it determines [...] -in all three instances [...] - the rate of convergence of the flows to the posterior. These gradient flows naturally suggest stochastic processes to be used to build proposals for Markov chain Monte Carlo (MCMC) algorithms. Moreover, by construction the processes are guaranteed to satisfy certain optimality criteria. A core part of the paper is to explore three areas of application: the variational formulation of high-dimensional classification and Bayesian image denoising, and the optimal choice of metric in Riemannian MCMC methods...|$|R
40|$|In this paper, {{we discuss}} {{a class of}} {{distributed}} detection algorithms which {{can be viewed as}} implementations of Bayes' law in distributed settings. Some of the algorithms are proposed in the literature most recently, and others are first developed in this paper. The common feature of these algorithms is that they all combine (i) certain kinds of consensus protocols with (ii) <b>Bayesian</b> <b>updates.</b> They are different mainly in the aspect of the type of consensus protocol and the order of the two operations. After discussing their similarities and differences, we compare these distributed algorithms by numerical examples. We focus on the rate at which these algorithms detect the underlying true state of an object. We find that (a) The algorithms with consensus via geometric average is more efficient than that via arithmetic average; (b) The order of consensus aggregation and <b>Bayesian</b> <b>update</b> does not apparently influence the performance of the algorithms; (c) The existence of communication delay dramatically slows down the rate of convergence; (d) More communication between agents with different signal structures improves the rate of convergence. Comment: 6 pages, 3 figures. This paper has been submitted to Chinese Control Conference 2015 at Hangzhou, People's Republic of Chin...|$|R
