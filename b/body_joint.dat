115|717|Public
25|$|Markerless gait capture systems utilize {{one or more}} color cameras or 2.5D depth sensors (i.e. Kinect) to {{directly}} calculate the <b>body</b> <b>joint</b> positions from a sequence of images. The markerless system allows non-invasive human gait analysis in a natural environment without any marker attachment. Eliminating markers can expand the applicability of human gait measurement and analysis techniques, considerably reduce the preparation time, and enable efficient and accurate motion assessment {{in all kinds of}} applications. Currently, the main markerless system is the video-based motion capture with monocular camera or multiple camera studio. Nowadays, the depth sensor-based gait analysis for clinical applications becomes more and more popular. Since depth sensors can measure the depth information and provide a 2.5D depth image, they have effectively simplified the task of foreground/background subtraction and significantly reduced pose ambiguities in monocular human pose estimation.|$|E
50|$|Cold-frequent {{urination}} {{with clear}} urine, cold extremities, aversion to cold, perhaps <b>body</b> <b>joint</b> aches and diarrhea. treatment method is warming.|$|E
50|$|There {{is a risk}} of {{electric}} shock when touching {{the parts of the}} system under voltage by the <b>body</b> <b>joint.</b> As a countermeasure, so-called protective conductors and residual current circuit breakers are used in electrical engineering.|$|E
50|$|After {{subjecting}} {{a bus to}} a {{rollover test}} in 1967, Ward Body Works discovered that bus construction of the time resulted in panel separation in <b>body</b> <b>joints</b> during a rollover crash; the company pointed out that many of their competitors were using relatively few rivets and fasteners. In contrast, in its own research, Wayne Corporation found that the <b>body</b> <b>joints</b> themselves as the weak points (regardless {{of the number of}} fasteners used). As a result, {{to reduce the risk of}} body panel separation, side panels began to be constructed from fewer and larger stampings. In 1973, the Wayne Lifeguard became the first school bus with single-stamping side and roof panels, eliminating major <b>body</b> <b>joints.</b> While single-piece stampings seen in the Lifeguard had their own manufacturing challenges, today's school buses use relatively few side panels to minimize <b>body</b> <b>joints.</b>|$|R
50|$|The Public <b>Bodies</b> (<b>Joint</b> Working) (Scotland) Act 2014 {{provides}} the legislative {{framework for the}} integration of health and social care in Scotland.|$|R
5000|$|In {{the years}} {{following}} the Lifeguard's introduction, competing body manufacturers began using fewer, larger body panels to reduce <b>body</b> <b>joints.</b> However, none had become as progressive as Wayne's use of the full-length panels when the focus on structural integrity resulted in the upgraded requirements of the U.S. Federal Motor Vehicle Safety Standards for school buses (#220 and #221), which became applicable on April 1, 1977. After that date, most manufacturers (including Wayne) added special structural adhesives to other fasteners at <b>body</b> <b>joints</b> ...|$|R
50|$|Although {{once made}} {{of various kinds}} of wood, glass or ivory, piccolos today are made {{from a range of}} materials, {{including}} plastic, resin, brass, nickel silver, silver, and a variety of hardwoods, most commonly grenadilla. Finely made piccolos are often available with a variety of options similar to the flute, such as the split-E mechanism. Most piccolos have a conical body with a cylindrical head, which is like the Baroque flute and later flutes before the popularization of the Boehm bore used in modern flutes. Unlike other woodwind instruments, in most wooden piccolos the tenon joint connecting the head to the body has two interference fit points which surround both the cork and metal side of the piccolo <b>body</b> <b>joint.</b>|$|E
50|$|Mechanical {{motion capture}} systems {{directly}} track <b>body</b> <b>joint</b> angles {{and are often}} referred to as exoskeleton motion capture systems, due to the way the sensors are attached to the body. A performer attaches the skeletal-like structure to their body and as they move so do the articulated mechanical parts, measuring the performer’s relative motion. Mechanical motion capture systems are real-time, relatively low-cost, free-of-occlusion, and wireless (untethered) systems that have unlimited capture volume. Typically, they are rigid structures of jointed, straight metal or plastic rods linked together with potentiometers that articulate at the joints of the body. These suits tend to be in the $25,000 to $75,000 range plus an external absolute positioning system. Some suits provide limited force feedback or haptic input.|$|E
5000|$|Markerless gait capture systems utilize {{one or more}} color cameras or 2.5D depth sensors (i.e. Kinect) to {{directly}} calculate the <b>body</b> <b>joint</b> positions from a sequence of images. The markerless system allows non-invasive human gait analysis in a natural environment without any marker attachment. Eliminating markers can expand the applicability of human gait measurement and analysis techniques, considerably reduce the preparation time, and enable efficient and accurate motion assessment {{in all kinds of}} applications. Currently, the main markerless system is the video-based motion capture with monocular camera or multiple camera studio. Nowadays, the depth sensor-based gait analysis for clinical applications becomes more and more popular. Since depth sensors can measure the depth information and provide a 2.5D depth image, they have effectively simplified the task of foreground/background subtraction and significantly reduced pose ambiguities in monocular human pose estimation.|$|E
3000|$|... {{landmark}} {{positions of}} the HBM (typically, the <b>body</b> <b>joints</b> {{and the end of}} the limbs) corresponding to the pose described by the state variable [...]...|$|R
3000|$|Upper body posture {{was found}} to be highly {{correlated}} with student activities such as observing slides and writing. Features were computed from <b>body</b> <b>joints</b> given in 3 D camera space, p [...]...|$|R
50|$|Once {{down on the}} tatamis (mats) {{the match}} enters its Part III. Here points are given for {{immobilisation}} techniques, controlled strangulations or levers on <b>body</b> <b>joints</b> that bring the opponent to yield.|$|R
5000|$|Some of the {{differences}} between virtual dance and physical possibility were obvious from the start: in the first production, Olmannen (2007), dancers flew, morphed into non-human shapes, and performed other feats impossible in the physical world. At first, the productions more closely resembled physical dance than later, as the artists explored the possibilities and limitations of the virtual format. For instance, there are no restrictions on the height or duration of leaps, physical <b>body</b> <b>joint</b> limits, the number of turns, or gravity such as hovering or flying. The restrictions which can occur are usually due to [...] "lag" [...] or latency -- timing difficulties stemming from the host computer interacting with the viewers' computers. But in Phylogeny (2009), which examined the reverse development of the species from humans to dragons, the lag was actually utilized in the choreography to allow differences in every performance where exciting interactions between the dancers could happen.|$|E
50|$|Joint motions {{are focused}} on the lower extremities; {{although}} there is recognition of upper <b>body</b> <b>joint</b> movements during the kick. Starting in stage 3, the kicking limb moves posterior of the positioned body, which is possible with hip extension. The hip is also adducted and externally rotated with knee flexion, knee internal rotation, and slight plantar flexion at the ankle joint on the kicking leg to prepare for impact with the ball. When the kicking foot comes into contact with the ball, hip goes into flexion, abduction, and external rotation with knee at a slight constant flexion. The pelvis rotates around the supporting limb by raising the thigh of the kicking limb forward.Forward motion is initiated by rotating the pelvis around the supporting leg and by bring the thigh of the kicking leg forwards while the knee continues to flex.During the last stages (stage 5 and 6) of the kick, the kicking foot exhibits plantar flexion at the ankle joint when coming into contact with the ball.Throughout each stage of the kick, the supporting limb knee is at a constant flexion. It is required to “absorb the impact of landing” and helps with reducing the forward motion. Once the kicking limb is near contact with the ball, the supporting knee initiates extension to stabilize the action. Prior to contact with the ball, there is a lateral flexion between the supporting limb and the trunk of the performer.|$|E
40|$|Three {{dimensional}} convolutional {{neural networks}} (3 D CNNs) {{have been established}} as a powerful tool to simultaneously learn features from both spatial and temporal dimensions, which is suitable {{to be applied to}} video-based action recognition. In this work, we propose not to directly use the activations of fully-connected layers of a 3 D CNN as the video feature, but to use selective convolutional layer activations to form a discriminative descriptor for video. It pools the feature on the convolutional layers under the guidance of <b>body</b> <b>joint</b> positions. Two schemes of mapping body joints into convolutional feature maps for pooling are discussed. The <b>body</b> <b>joint</b> positions can be obtained from any off-the-shelf skeleton estimation algorithm. The helpfulness of the <b>body</b> <b>joint</b> guided feature pooling with inaccurate skeleton estimation is systematically evaluated. To make it end-to-end and do not rely on any sophisticated <b>body</b> <b>joint</b> detection algorithm, we further propose a two-stream bilinear model which can learn the guidance from the body joints and capture the spatio-temporal features simultaneously. In this model, the <b>body</b> <b>joint</b> guided feature pooling is conveniently formulated as a bilinear product operation. Experimental results on three real-world datasets demonstrate the effectiveness of <b>body</b> <b>joint</b> guided pooling which achieves promising performance...|$|E
5000|$|A pygopag(ous) (from the Greek pygè 'buttock' and pagein 'attached') was {{a monster}} in Ancient (Greek) mythology {{consisting}} of two <b>bodies</b> <b>joint</b> by common buttocks, now a medical term for 'Siamese' twins thus joint back-to-back ...|$|R
30|$|The {{possibility}} {{offered by}} the tracking of <b>body</b> <b>joints</b> provides new keys for mid-level features construction or pose extraction. Still, for recognition purposes, an appropriate local characterization of the body motions is required, at each frame of a sequence.|$|R
50|$|The {{group also}} uses some unusual running techniques, {{such as a}} {{pronounced}} swinging of the hips, {{which is designed to}} rely more on the natural range of motion of the <b>body's</b> <b>joints</b> rather than the burning of muscle fuel for propulsion.|$|R
3000|$|Each <b>body</b> <b>joint</b> {{trajectory}} i {{is represented}} as a sequence of {P_i,t=(x_i,t,y_i,t,z_i,t)}_t= 0 ^N- 1 coordinates in a 3 D Cartesian system of coordinates (Oxyz) where N denotes the number of frames of the sequence. As a pre-processing, normalization step, several elementary transforms are applied to the body at each frame of its trajectory before the computation of descriptors. The objective is to set each <b>body</b> <b>joint</b> i in a new position P_i,t^trans=(x_i,t^trans,y_i,t^trans,z_i,t^trans) [...] at frame t so that the (xOy), (yOz) and (zOx) planes (Fig. 1), respectively, correspond to sagittal, vertical, and horizontal body planes.|$|E
40|$|This paper {{focuses on}} {{developing}} {{a novel approach}} for measuring <b>body</b> <b>joint</b> angles, mainly the knee angles, for surface electrical stimulator system. In this work, we only focus on the sensing mechanism for measuring the knee joint angle using wearable sensors. Our system consists of multiple flex-sensors mounted on a supportive cloth and microelectromechanical systems (MEMS) vibratory gyroscope. In Body Sensor Network (BSN) field for medical purpose, <b>body</b> <b>joint</b> angle measurement system is quite important and useful for continuous monitoring in rehabilitation activities especially for Spinal Cord Injury (SCI) patients. <b>Body</b> <b>joint</b> angle measurement system is sensory type systems that provide information about angle movement of <b>body</b> <b>joint.</b> It is usually used at knee and arm joint to monitor the movement while patients do some exercises. This very important and helpful for the therapists and physicians {{in order to see}} the effectiveness of rehabilitations training. For knee angle movement evaluation, lower limb joint angles and segment angles were estimated by the Kalman filter from the data measured with wireless MEMS vibratory gyroscope and flex-sensors. Electrical stimulation was applied to the common peroneal nerve or the tibialis anterior muscle by detecting stimulus timing automatically from the data of wireless sensor attached at the back of knee which known as popliteal fossa and shank of the paraplegic side. The developed system performed well in monitoring the effectiveness of rehabilitations training with the knee joint angle measurement average error rate of 6. 92 °. The comparison between measured data of the gyroscope and flex-sensors for knee joint angle measurement system were also demonstrated...|$|E
30|$|One of the {{advantages}} of using depth sensors for HAR is that it facilitates the estimation of accurate 3 D <b>body</b> <b>joint</b> positions from depth maps via skeleton tracking. These 3 D positions can be more direct cues for HAR, providing robustness against variations in viewpoints. Such 3 D <b>body</b> <b>joint</b> trajectories used to be available only with expensive equipments such as motion capture devices (MoCap) [28], as in [29]. But currently, they are obtainable with commodity RGB-D sensors with built-in real-time 3 D human tracking capabilities (e.g., Microsoft Kinect), although the tracking is not exempt from errors [7]. For example, Xia et al. [8] proposed to use the body joints provided by Kinect to perform HAR using HMMs.|$|E
6000|$|One can not {{appreciate}} {{the horror of}} this disease until he looks upon it in all its ghastliness, in Naaman's ancient dwelling in Damascus. Bones all twisted out of shape, great knots protruding from face and <b>body,</b> <b>joints</b> decaying and dropping away--horrible! ...|$|R
5000|$|The {{body was}} {{mounted on a}} {{sub-frame}} with ample insulating material between frame and <b>body.</b> <b>Body</b> <b>joints</b> received treatment to avoid squeaks and the doors were fitted with silencers"Specialised bodies by leading coach builders" [...] available on all chassis, ordered from The Rover Company ...|$|R
40|$|Abstract—Human action {{analysis}} has achieved great success {{especially with the}} recent development of advanced sensors and algorithms that can effectively track the <b>body</b> <b>joints.</b> Temporal motion of <b>body</b> <b>joints</b> carries crucial information about human actions. However, current dynamic models typically assume stationary local transition and therefore are limited to local dy-namics. In contrast, we propose a novel human action recognition algorithm that is able to capture both global and local dynamics of joint trajectories by combining a Gaussian-Binary restricted Boltzmann machine (GB-RBM) with a hidden Markov model (HMM). We present a method to use RBM as a generative model for multi-class classification. Experimental results on benchmark datasets demonstrate the capability of the proposed method in exploiting the dynamic information at different levels. I...|$|R
40|$|To {{strengthen}} limbs {{which are}} injured in an accident, a traditional rehabilitation device has been adopted. However, it is heavy and complex, a light-weight <b>body</b> <b>joint</b> bending actuator {{which is made}} of a Shape Memory Alloy (SMA) and is simpler than traditional rehabilitation devices is therefore proposed. Here, an SMA-made actuator can offer the resistance needed for a rehabilitation program. A Ti-Ni based SMA is adopted for the <b>body</b> <b>joint</b> bending actuator. To facilitate the swinging angle and the related bending torque, various structures of the SMA-made <b>body</b> <b>joint</b> bending actuators (a one-bunch SMA actuator and a six-bunch SMA actuator) have been adjusted in the experimental work by varying the number of SMA fibers in a bounded bunch. Results reveal that the structure-A (a six-bunch SMA fiber with 8 fibers per bunch) and the structure-B (a one-bunch SMA actuator with 50 fibers per bunch) have similar functions- the bending angle is 158 ° and the maximum bending torque is 0. 155 Nm. Moreover, depending on the patient’s condition, both the maximum swinging angle and the velocity are adjustable by the patient via the PC-based control system. In addition, to avoid damage to the actuator, a maximum operating temperature of 90 °C is preset on the SMA...|$|E
40|$|Abstract — Several recently-designed robots {{are able}} to scale steep {{surfaces}} using animal-inspired strategies for foot attachment and leg kinematics. These designs could be valuable for reaching high vantage points or for overcoming large obstacles. However, most of these robots cannot transition between intersecting surfaces. For example, our previous Climbing Mini-Whegs ™ robot cannot make a 90 ° transition from a vertical wall up onto a flat horizontal surface. It is known that cockroaches bend their body to accomplish such transitions. This concept has been simplified to a single-axis <b>body</b> <b>joint</b> which allows ground-walking robots to cross uneven terrain. In this work, we {{examine the effect of}} a <b>body</b> <b>joint</b> on wall-climbing vehicles using both a kinematic simulation and two prototype Climbing Mini-Whegs ™ robots. The simulation accurately predicts that the better design has the body join...|$|E
40|$|We {{address the}} problem of {{communicating}} emotions with a humanoid robot merely with its <b>body</b> <b>joint</b> movements, without facial information, querying human users for emotional scores attributed to the movements. Machine learning can help convey the intended emotions more clearly, by selecting the next actions and parameters that need tuning and rewarding successful action–emotion matches...|$|E
40|$|A {{finite element}} method to model dynamic {{structural}} systems undergoing large rotations is presented. The dynamic systems are composed of rigid <b>joint</b> <b>bodies</b> and flexible beam elements. The configurations of these systems {{are subject to change}} due to the relative motion in the joints among interconnected elastic beams. A body fixed reference is defined for each <b>joint</b> <b>body</b> to describe the <b>joint</b> <b>body's</b> displacements. Using the {{finite element method}} and the kinematic relations between each flexible element and its corotational reference, the total displacement field of an element, which contains gross rigid as well as elastic effects, can be derived in terms of the translational and rotational displacements of the two end nodes. If one end of an element is hinged to a <b>joint</b> <b>body,</b> the <b>joint</b> <b>body's</b> displacements and the hinge degree of freedom at the end are used to represent the nodal displacements. This results in a highly coupled system of differential equations written in terms of hinge degrees of freedom as well as the rotational and translational displacements of <b>joint</b> <b>bodies</b> and element nodes...|$|R
2500|$|An {{open-source}} {{simulation platform}} for creating dynamic mechanical models built from combinations of rigid and deformable <b>bodies,</b> <b>joints,</b> constraints, and various force actuators. [...] It is specialized for creating biomechanical models of human anatomical structures, {{with the intention}} to study their function and eventually assist {{in the design and}} planning of medical treatment.|$|R
40|$|In this paper, {{we propose}} an {{effective}} method to recognize human actions from 3 D positions of <b>body</b> <b>joints.</b> With {{the release of}} RGBD sensors and associated SDK, human <b>body</b> <b>joints</b> can be extracted in real time with reasonable accuracy. In our method, we propose {{a new type of}} features based on position differences of joints, EigenJoints, which combine action information including static posture, motion, and offset. We further employ the Naïve-Bayes-Nearest-Neighbor (NBNN) classifier for multi-class action classification. The recognition results on MSR Action 3 D dataset demonstrate that our approach significantly outperforms the state-of-the-art methods. In addition, we investigate how many frames are necessary for our method to recognize actions in MSR Action 3 D dataset. We observe that 15 - 20 frames are sufficient to achieve comparable results to that using the entire video sequences. 1...|$|R
40|$|A contextual rescoring {{method is}} {{proposed}} {{for improving the}} detection of body joints of a pictorial structure model for human pose estimation. A set of mid-level parts is in-corporated in the model, and their detections are used to extract spatial and score-related features relative to other <b>body</b> <b>joint</b> hypotheses. A technique is proposed for the auto-matic discovery of a compact subset of poselets that covers a set of validation images while maximizing precision. A rescoring mechanism {{is defined as a}} set-based boosting classifier that computes a new score for <b>body</b> <b>joint</b> detections, given its relationship to detections of other body joints and mid-level parts in the image. This new score comple-ments the unary potential of a discriminatively trained pictorial structure model. Exper-iments on two benchmarks show performance improvements when considering the pro-posed mid-level image representation and rescoring approach in comparison with other pictorial structure-based approaches. ...|$|E
40|$|This paper {{proposes a}} new hybrid {{architecture}} {{that consists of}} a deep Convolu-tional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose esti-mation in monocular images. The architecture can exploit structural domain con-straints such as geometric relationships between <b>body</b> <b>joint</b> locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques. ...|$|E
40|$|The {{need for}} {{longer and more}} labor-intensive extra-vehicular {{activities}} (EVA) is required for construction and maintenance of the International Space Station (ISS). Issues pertaining to human performance while wearing a space suit (EMU) for prolonged periods have become more important. This project was conducted to investigate how a pressurized Extra-vehicular Mobility Unit (EMU) affects human upper <b>body</b> <b>joint</b> strength and fatigue and how to predict it from computer models based on the data collected...|$|E
40|$|The {{problem we}} {{consider}} {{in this paper}} is to take a single two-dimensional image containing a human <b>body,</b> locate the <b>joint</b> positions, and use these to estimate the body configuration and pose in three-dimensional space. The basic approach is to store a number of exemplar 2 D views of the human body in a variety of different configurations and viewpoints with respect to the camera. On each of these stored views, the locations of the <b>body</b> <b>joints</b> (left elbow, right knee etc) are manually marked and labelled for future use. The test shape is then matched to each stored view, using the technique of shape context matching. Assuming that there is a stored view sufficiently similar in configuration and pose, the correspondence process will succeed. The locations of the <b>body</b> <b>joints</b> are then transferred from the exemplar view to the test shape. Given the joint locations, the 3 D body configuration and pose are then estimated. We present results of our method on a corpus of human pose data. ...|$|R
40|$|Depth sensing camera Tracks 20 <b>body</b> <b>joints</b> in {{real time}} Recognises your face and voicedepth image (camera view) What the Kinect SeesWhat the Kinect Sees top view side view depth image (camera view) Structured light object at depth d 2 object at depth d 1 y z x imaging plane optic centre of IR laser optic centre of camer...|$|R
40|$|We {{propose a}} new method to quickly and {{accurately}} predict 3 D positions of <b>body</b> <b>joints</b> {{from a single}} depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3 D proposals of several <b>body</b> <b>joints</b> by reprojecting the classification result and finding local modes. The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve {{state of the art}} accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching. 1...|$|R
