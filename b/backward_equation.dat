88|1295|Public
2500|$|Kimura {{soon found}} Iowa State College too restricting; {{he moved to}} the University of Wisconsin to work on {{stochastic}} models with James F. Crow and join a strong intellectual community of like-minded geneticists, including Newton Morton and most significantly, Sewall Wright. [...] Near the end of his graduate study, Kimura gave a paper at the 1955 Cold Spring Harbor Symposium; though few were able to understand it (both because of mathematical complexity and Kimura's English pronunciation) it received strong praise from Wright and later J.B.S. Haldane. [...] His accomplishments at Wisconsin included a general model for genetic drift, which could accommodate multiple alleles, selection, migration, and mutations, as well as some work based on R.A. Fisher's fundamental theorem of natural selection. [...] He also built on the work of Wright with the Fokker-Planck equation by introducing the Kolmogorov <b>backward</b> <b>equation</b> to population genetics, allowing the calculation of the probability of a gene to become fixed in a population. [...] He received his PhD in 1956, before returning to Japan (where he would remain {{for the rest of his}} life, at the National Institute of Genetics).|$|E
5000|$|... #Subtitle level 2: Formulating the Kolmogorov <b>backward</b> <b>equation</b> ...|$|E
5000|$|The {{behaviour}} of {{the function}} u above when the time t is varied is addressed by the Kolmogorov <b>backward</b> <b>equation,</b> the Fokker-Planck equation, etc. (See below.) ...|$|E
50|$|In {{the context}} of a {{diffusion}} process, for the <b>backward</b> Kolmogorov <b>equations</b> see Kolmogorov <b>backward</b> <b>equations</b> (diffusion). The forward Kolmogorov equation are also known as Fokker-Planck equation.|$|R
40|$|We study existence, uniqueness, semi-group property, and {{a priori}} {{estimates}} for solutions for <b>backward</b> parabolic Ito <b>equations</b> in domains with boundary. We study also duality between forward and <b>backward</b> <b>equations.</b> The semi-group for <b>backward</b> <b>equations</b> is {{established in the}} form of some anti-causality. The novelty is that the semi-group property involves the diffusion term that {{is a part of the}} solution...|$|R
40|$|We study existence, uniqueness, and {{a priori}} {{estimates}} for solutions for <b>backward</b> parabolic Ito <b>equations</b> in domains with boundary. The proofs are based duality between forward and <b>backward</b> <b>equations.</b> This duality is used also {{to establish that}} <b>backward</b> parabolic <b>equations</b> have some causality (more precisely, some anti-causality) ...|$|R
50|$|While the Fokker-Planck {{equation}} is used with problems where the initial distribution is known, {{if the problem}} is to know the distribution at previous times, the Feynman-Kac formula can be used, which {{is a consequence of}} the Kolmogorov <b>backward</b> <b>equation.</b>|$|E
5000|$|The Kolmogorov <b>backward</b> <b>equation</b> (KBE) (diffusion) and its adjoint {{sometimes}} {{known as}} the Kolmogorov forward equation (diffusion) are partial differential equations (PDE) that arise {{in the theory of}} continuous-time continuous-state Markov processes. Both were published by Andrey Kolmogorov in 1931. [...] Later it was realized that the forward equation was already known to physicists under the name Fokker - Planck equation; the KBE on the other hand was new.|$|E
5000|$|In {{mathematics}} [...] - [...] specifically, in stochastic analysis [...] - [...] the infinitesimal generator of a {{stochastic process}} is a partial differential operator that encodes {{a great deal of}} information about the process. The generator is used in evolution equations such as the Kolmogorov <b>backward</b> <b>equation</b> (which describes the evolution of statistics of the process); its L2 Hermitian adjoint is used in evolution equations such as the Fokker-Planck equation (which describes the evolution of the probability density functions of the process).|$|E
40|$|We {{consider}} a càdlàg process the filtration generated by Y and generated by step processes Yn defined from Y by discretization in time. We study the stability in (with Skorokhod topology) of -martingales and of -solutions of related <b>backward</b> <b>equations,</b> when Yn [...] >Y. We get this stability (in law) when Y is Markov and (in probability) under stronger assumptions on the coefficients of <b>equations.</b> Martingales <b>Backward</b> <b>equations</b> Skorokhod topology Convergence in law...|$|R
3000|$|... {{without the}} compact support assumption. To proceed, we obtain the {{following}} system of Kolmogorov <b>backward</b> <b>equations</b> for switching diffusions; see also [2].|$|R
50|$|In {{probability}} theory, Kolmogorov equations, including Kolmogorov forward <b>equations</b> and Kolmogorov <b>backward</b> <b>equations,</b> characterize stochastic processes. In particular, {{they describe}} how {{the probability that}} a stochastic process is in a certain state changes over time.|$|R
5000|$|The {{transition}} probability , {{the probability of}} going from [...] to , is introduced here; the expectation can be written asNow we replace {{in the definition of}} , multiply by [...] and integrate over [...] The limit is taken onNote now thatwhich is the Chapman-Kolmogorov theorem. Changing the dummy variable [...] to , one getswhich is a time derivative. Finally we arrive toFrom here, the Kolmogorov <b>backward</b> <b>equation</b> can be deduced. If we instead use the adjoint operator of , , defined such thatthen we arrive to the Kolmogorov forward equation, or Fokker-Planck equation, which, simplifying the notation , in its differential form reads ...|$|E
5000|$|... {{where the}} initial state is [...]The time {{dependent}} control Hamiltonian has the typical form: where [...] is the control field. Optimal control solves for the optimal field using the {{calculus of variations}} introducing Lagrange multipliers. A new objective functional is definedwhere [...] is a wavefunction like Lagrange multiplier and the [...] parameter regulates the integral intensity.Variation of [...] with respect to [...] and [...] leads to two coupled Schrödinger equations A forward equation for [...] with initial condition and a <b>backward</b> <b>equation</b> for the Lagrange multiplier [...] with final condition [...] Finding a solution requires an iterative approach.Different algorithms have been applied for obtaining the control field such as the Krotov method.|$|E
50|$|Kimura {{soon found}} Iowa State College too restricting; {{he moved to}} the University of Wisconsin to work on {{stochastic}} models with James F. Crow and join a strong intellectual community of like-minded geneticists, including Newton Morton and most significantly, Sewall Wright. Near the end of his graduate study, Kimura gave a paper at the 1955 Cold Spring Harbor Symposium; though few were able to understand it (both because of mathematical complexity and Kimura's English pronunciation) it received strong praise from Wright and later J.B.S. Haldane. His accomplishments at Wisconsin included a general model for genetic drift, which could accommodate multiple alleles, selection, migration, and mutations, as well as some work based on R.A. Fisher's fundamental theorem of natural selection. He also built on the work of Wright with the Fokker-Planck equation by introducing the Kolmogorov <b>backward</b> <b>equation</b> to population genetics, allowing the calculation of the probability of a gene to become fixed in a population. He received his PhD in 1956, before returning to Japan (where he would remain {{for the rest of his}} life, at the National Institute of Genetics).|$|E
40|$|This paper {{proposes a}} novel vector control method based on Rotor flux Field-Oriented Control (RFOC) for {{single-phase}} Induction Motor (IM) drives. It is shown {{that in a}} rotating reference frame, the single-phase IM equations can be separated into forward and <b>backward</b> <b>equations</b> with balanced structures. In order to accommodate for these forward and <b>backward</b> <b>equations,</b> a drive system consisting of two RFOCs that are switched interchangeably, is proposed. Alternatively, these two RFOC algorithms can be simplified as a single FOC algorithm. The analysis, controller design and simulation of the proposed technique showed that it is feasible for single-phase IM drive for high performance applications...|$|R
40|$|We prove {{existence}} and uniqueness of solutions of reflected <b>backward</b> stochastic differential <b>equations</b> in time-dependent adapted and càdlàg convex regions D={D_t;t∈[0,T]}. We {{also show that}} the solution may be approximated by solutions of <b>backward</b> <b>equations</b> with reflection in appropriately defined discretizations of D and by a modified penalization method. The approximation results are new even in the one-dimensional case. Comment: Two references adde...|$|R
40|$|International audienceWe {{consider}} a stochastic control problem which {{is composed of}} a controlled stochastic differential equation, and whose associated cost functional is defined through a controlled <b>backward</b> stochastic differential <b>equation.</b> Under appropriate convexity assumptions on the coefficients of the forward and the <b>backward</b> <b>equations</b> we prove {{the existence of an}} optimal control on a suitable reference stochastic system. The proof is based on an approximation of the stochastic control problem by a sequence of control problems with smooth coefficients, admitting an optimal feedback control. The quadruplet formed by this optimal feedback control and the associated solution of the forward and the <b>backward</b> <b>equations</b> is shown to converge in law, at least along a subsequence. The convexity assumptions on the coefficients then allow to construct from this limit an admissible control process which, on an appropriate reference stochastic system, is optimal for our stochastic control problem...|$|R
30|$|We now {{state the}} Feynman-Kac formula, {{which is a}} {{generalization}} of the Kolmogorov <b>backward</b> <b>equation.</b>|$|E
40|$|This paper {{proposes a}} {{smoothing}} algorithm {{based on the}} Monte Carlo Particle filter and the backward transition equation of states (a <b>backward</b> <b>equation).</b> Our method is applicable to any nonlinear non-Gaussian state space model if a <b>backward</b> <b>equation</b> is given analytically. The computational complexity of our smoothing algorithm {{is equal to the}} complexity of the Monte Carlo Particle filter because it can be realized by a minor modification of the Monte Carlo Particle filter. Moreover, we propose a filter initialization algorithm based on the smoothing distribution which is obtained by our smoothing algorithm and a <b>backward</b> <b>equation.</b> In this paper, we demonstrate the effectiveness of our method by applying it to a linear Gaussian state space model, a linear non-Gaussian state space model, a stochastic volatility model, and a stochastic volatility model with a t-distribution...|$|E
40|$|Monte Carlo estimators of {{sensitivity}} indices and the marginal {{density of the}} price dynamics are derived for the Hobson-Rogers stochastic volatility model. Our approach is based mainly upon the Kolmogorov <b>backward</b> <b>equation</b> by {{making full use of}} the Markovian property of the dynamics given the past information. Some numerical examples are presented with a GARCH-like volatility function and its extension to illustrate the effectiveness of our formulae together with a clear exhibition of the skewness and the heavy tails of the price dynamics. Asset price dynamics, density estimation, GARCH, Kolmogorov <b>backward</b> <b>equation,</b> Markov processes, Monte Carlo simulation, sensitivity analysis, stochastic volatility...|$|E
40|$|In an {{incomplete}} financial market where asset prices are continuous semimartingales, we establish {{the convergence of}} the p-optimal martingale measures to the minimal entropy martingale measure as p tends to 1. The result is achieved exploiting the theory of BMO-martingales and semimartingale <b>backward</b> <b>equations...</b>|$|R
40|$|We {{develop the}} theory of linear {{evolution}} equations associated with the adjacency matrix of a graph, focusing in particular on infinite graphs of two kinds: uniformly locally finite graphs as well as locally finite line graphs. We discuss in detail qualitative properties of solutions to these problems by quadratic form methods. We distinguish between backward and forward evolution equations: the latter have typical features of diffusive processes, but cannot be well-posed on graphs with unbounded degree. On the contrary, well-posedness of <b>backward</b> <b>equations</b> is a typical feature of line graphs. We suggest how to detect even cycles and/or couples of odd cycles on graphs by studying <b>backward</b> <b>equations</b> for the adjacency matrix on their line graph. Comment: 27 pages; to appear in Disc. Cont. Dyn. Syst. ...|$|R
5000|$|In {{the context}} of a continuous-time Markov process, the Kolmogorov equations, {{including}} Kolmogorov forward <b>equations</b> and Kolmogorov <b>backward</b> <b>equations,</b> are a pair of systems of differential equations that describe the time-evolution of the probability , where [...] (the state space) and [...] are the final and initial time respectively.|$|R
40|$|Abstract We {{consider}} an incomplete ¯nancial market model, where {{the dynamics of}} asset prices is determined by an Rd-valued continuous semi-martingale. Using the dynamic programming approach we give a descrip-tion of the p-optimal martingale measure {{in terms of the}} value process for a suitable problem of an optimal equivalent change of measure and show that this value process uniquely solves the corresponding semimartingale <b>backward</b> <b>equation.</b> This result is applied to approximate the lower price and the corresponding hedging strategy of a contingent claim. Key Words Semimartingale <b>backward</b> <b>equation,</b> contingent claim pricing, p-optimal martingale measure, incomplete markets, lower and upper prices...|$|E
40|$|A {{model of}} bank’s dynamic asset {{management}} problem {{in case of}} partially observed future economic conditions and requirements concerning level of risk taken has been built. It requires solving the resulting optimal control with random terminal condition resulting from partial observation of parameter of maximized functional. Stochastic Maximum Principle reduces the problem to solving FBSDE. As optimization may usually imply dependence of forward equation on solutions of <b>backward</b> <b>equation</b> we allow the drift and diffusion of forward part to be functions of solution of <b>backward</b> <b>equation.</b> The necessary conditions for existence of solutions of FBSDE in such a form have been derived. A numerical scheme is then implemented for a particular choice of parameters of the problem. ...|$|E
40|$|International audienceThis {{paper is}} devoted to {{forward-backward}} systems of stochastic differential equations in which the forward equation is not coupled to the backward one, both equations are infinite dimensional and on the time interval [0, + ∞). The forward equation defines an Ornstein-Uhlenbeck process, {{the driver of the}} <b>backward</b> <b>equation</b> has a linear part which is the generator of a strongly continuous, dissipative, compact semigroup, and a nonlinear part which is assumed to be continuous with linear growth. Under the assumption of equivalence of the laws of the solution to the forward equation, we prove the existence of a solution to the <b>backward</b> <b>equation.</b> We apply our results to a stochastic game problem with infinitely many player...|$|E
40|$|We define {{heavy-tailed}} fractional reciprocal gamma and Fisher-Snedecor diffusions by a nonMarkovian time {{change in}} the corresponding Pearson diffusions. Pearson diffusions are governed by the <b>backward</b> Kolmogorov <b>equations</b> with space-varying polynomial coefficients and are widely used in applications. The corresponding fractional reciprocal gamma and Fisher-Snedecor diffusions are governed by the fractional <b>backward</b> Kolmogorov <b>equations</b> and have heavy-tailed marginal distributions in the steady state. We derive the explicit expressions for the transition densities of the fractional reciprocal gamma and Fisher-Snedecor diffusions and strong solutions of the associated Cauchy problems for the fractional <b>backward</b> Kolmogorov <b>equation...</b>|$|R
40|$|Abstract. We {{consider}} a BSDE (<b>backward</b> stochastic differential <b>equation)</b> { −dY (t) = f(B(·), t, Y (t), Z(t)) dt − Z(t) ∗dB(t), Y (1) = ξ. We construct <b>backward</b> stochastic difference <b>equations</b> approximating the BSDE, where {{time and space}} are discrete. We show the existence and uniqueness of the solutions of the <b>backward</b> stochastic difference <b>equations.</b> Also we show a convergence result of the solutions of the <b>backward</b> stochastic difference <b>equations</b> towards that of the BSDE. 1...|$|R
40|$|In this paper, we {{consider}} the fully coupled forward-backward stochastic functional differential equations (FBSFDEs) with stochastic functional differential equations as the forward equations and the generalized anticipated <b>backward</b> stochastic differential <b>equations</b> as the <b>backward</b> <b>equations.</b> We will prove the existence and uniqueness theorem for FBSFDEs. As an application, we deal with a quadratic optimal control problem for functional stochastic systems, and get the explicit form of the optimal control by virtue of FBSFDEs. Comment: 20 page...|$|R
40|$|A retarded <b>backward</b> <b>equation</b> for a non-Markovian process {{induced by}} dichotomous noise (the random telegraphic signal) is deduced. The mean-first-passage {{time of this}} process is exactly obtained. The Gaussian white noise and the white shot noise limits are studied. Explicit {{physical}} results in first approximation are evaluated...|$|E
40|$|Kimura (1955 b) {{proposed}} {{a solution for}} the time-dependent probability of fixation, or loss, of a gene under selection. Example calculations suggest the formulas are prone to numerical inaccuracies. An alternative solution is proposed; the correctness of the solution is confirmed by numerically solving the Kolmogorov <b>backward</b> <b>equation</b> and by simulation...|$|E
40|$|We {{present a}} model of a bank's dynamic asset {{management}} problem in the case of partially observed future economic conditions and with regulatory requirements governing the level of risk taken. The result is an optimal control problem with a random terminal condition arising from the partial observation of a parameter of a maximized functional. The Stochastic Maximum Principle reduces the problem to finding a solution to a Forward Backward Stochastic Differential Equation (FBSDE). As optimization usually implies the dependence of the forward equation on solutions of the <b>backward</b> <b>equation</b> we allow the drift and diffusion of the forward part to be functions of the solution of the <b>backward</b> <b>equation.</b> The necessary conditions for the existence of solutions of FBSDE in such a form are derived. A numerical scheme is then implemented to solve a particular case. Portfolio optimization, bank assets, partial observation, stochastic maximum principle, FBSDEs,...|$|E
40|$|We {{discuss a}} {{quadratic}} criterion optimal control problem for stochastic linear system with delay in {{both state and}} control variables. This problem {{will lead to a}} kind of generalized forward-backward stochastic differential equations (FBSDEs) with Itô’s stochastic delay equations as forward <b>equations</b> and anticipated <b>backward</b> stochastic differential <b>equations</b> as <b>backward</b> <b>equations.</b> Especially, we present the optimal feedback regulator for the time delay system via a new type of Riccati equations and also apply to a population optimal control problem...|$|R
40|$|A general {{model of}} an optimal {{equivalent}} change of measure is considered. Existence and uniqueness conditions {{of a solution}} of <b>backward</b> semimartingale <b>equation</b> for the value process are given. This result is applied to determine the maximum price of a contingent claim. <b>Backward</b> semimartingale <b>equation</b> Stochastic control Contingent claim pricing Martingale measures...|$|R
40|$|Abstract In this paper, {{we apply}} the <b>backward</b> <b>equations</b> of Markov {{skeleton}} processes to queueing systems. The transient {{distribution of the}} waiting time of a GI/G/ 1 queueing system, the transient distribution {{of the length of}} a GI/G/N queueing system and the transient distribution of the length of queueing networks are obtained...|$|R
