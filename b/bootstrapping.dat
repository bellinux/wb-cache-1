6174|10000|Public
5|$|The most {{complete}} coverage of Engelbart's <b>bootstrapping</b> ideas {{can be found}} in Boosting Our Collective IQ, by Douglas C. Engelbart, 1995. This includes three of Engelbart's key papers, edited into book form by Yuri Rubinsky and Christina Engelbart to commemorate the presentation of the 1995 SoftQuad Web Award to Doug Engelbart at the World Wide Web conference in Boston in December 1995. Only 2,000 softcover copies were printed, and 100 hardcover, numbered and signed by Engelbart and Tim Berners-Lee. Engelbart's book is now being republished by the Doug Engelbart Institute.|$|E
5|$|Engelbart was Founder Emeritus of the Doug Engelbart Institute, {{which he}} founded in 1988 with his {{daughter}} Christina Engelbart, who is Executive Director. The Institute promotes Engelbart's philosophy for boosting Collective IQ—the concept of dramatically improving how we can solve important problems together—using a strategic <b>bootstrapping</b> approach for accelerating our progress toward that goal. In 2005, Engelbart received a National Science Foundation grant to fund the open source HyperScope project. The Hyperscope team built a browser component using Ajax and Dynamic HTML designed to replicate Augment's multiple viewing and jumping capabilities (linking within and across various documents).|$|E
25|$|See also: <b>Bootstrapping</b> (finance); Fixed-income attribution#Modeling {{the yield}} curve.|$|E
40|$|A {{modified}} <b>bootstrap</b> {{procedure is}} proposed. It {{is based on}} the outlier <b>bootstrap</b> sample concept introduced by Muñoz-García et al. (1997). The consistency of the modified <b>bootstrap</b> distribution estimator and of the modified <b>bootstrap</b> variance estimator is established for Féchet differentiable statistical functionals. The modified <b>bootstrap</b> variance estimator requires less stringent conditions for its consistency than the ordinary <b>bootstrap</b> variance estimator. <b>Bootstrap</b> Outlier <b>bootstrap</b> sample Distribution estimation Variance estimation Fréchet differentiability Consistency...|$|R
40|$|We show that, {{compared}} to the classical <b>bootstrap,</b> the modified <b>bootstrap</b> provides faster consistency rates for the <b>bootstrap</b> distribution of U-quantiles. This shows that the modified <b>bootstrap</b> is useful, not only {{in cases where the}} classical <b>bootstrap</b> fails, but also in situations where it is valid. Consistency rates Modified <b>bootstrap</b> Quantiles...|$|R
40|$|The fast double <b>bootstrap,</b> or FDB, is a {{procedure}} for calculating <b>bootstrap</b> P values {{that is much}} more computationally efficient than the double <b>bootstrap</b> itself. In many cases, it can provide more accurate results than ordinary <b>bootstrap</b> tests. For the fast double <b>bootstrap</b> to be valid, the test statistic must be asymptotically independent of the random parts of the <b>bootstrap</b> data generating process. This paper presents simulation evidence {{on the performance of}} FDB tests in three cases of interest to econometricians. One of the cases involves both symmetric and equal-tail <b>bootstrap</b> tests, which, interestingly, can have quite different power properties. Another highlights the importance of imposing the null hypothesis on the <b>bootstrap</b> DGP. <b>bootstrap</b> test, serial correlation, ARCH errors, weak instruments, double <b>bootstrap,</b> fast double <b>bootstrap,</b> FDB...|$|R
25|$|<b>Bootstrapping</b> an {{operating}} system install or disk cloning operation, often across a network.|$|E
25|$|A {{method of}} {{accounting}} fraud detection based on <b>bootstrapping</b> and regression has been proposed.|$|E
25|$|The gcj Java {{compiler}} can target {{either a}} native machine language architecture or the Java virtual machine's Java bytecode. When retargeting GCC {{to a new}} platform, <b>bootstrapping</b> is often used.|$|E
40|$|The {{asymptotic}} refinements {{attributable to}} the block <b>bootstrap</b> for time series are not as large {{as those of the}} nonparametric iid <b>bootstrap</b> or the parametric <b>bootstrap.</b> One reason is that the independence between the blocks in the block <b>bootstrap</b> sample does not mimic the dependence structure of the original sample. This is the join-point problem. In this paper, we propose a method of solving this problem. The idea is not to alter the block <b>bootstrap.</b> Instead, we alter the original sample statistics to which the block <b>bootstrap</b> is applied. We introduce block statistics that possess join-point features that {{are similar to those of}} the block <b>bootstrap</b> versions of these statistics. We refer to the application of the block <b>bootstrap</b> to block statistics as the block-block <b>bootstrap.</b> The asymptotic refinements of the block-block <b>bootstrap</b> are shown to be greater than those obtained with the block <b>bootstrap</b> and close to those obtained with the nonparametric iid <b>bootstrap</b> and parametric <b>bootstrap.</b> Asymptotics, Block <b>bootstrap,</b> Block statistics, Edgeworth expansion, Extremum estimator, Generalized method of moments estimator, Maximum likelihood estimator, t statistic, Test of over-identifying restrictions...|$|R
50|$|This <b>bootstrap</b> {{works with}} {{dependent}} data, however, the <b>bootstrapped</b> observations {{will not be}} stationary anymore by construction. But, it was shown that varying randomly the block length can avoid this problem. This method {{is known as the}} stationary <b>bootstrap.</b> Other related modifications of the moving block <b>bootstrap</b> are the Markovian <b>bootstrap</b> and a stationary <b>bootstrap</b> method that matches subsequent blocks based on standard deviation matching.|$|R
40|$|International audienceIn {{regression}} models, appropriate <b>bootstrap</b> {{methods for}} inference robust to heteroskedasticity of unknown form are the wild <b>bootstrap</b> and the pairs <b>bootstrap.</b> The finite sample {{performance of a}} heteroskedastic-robust test is investigated with Monte Carlo experiments. The simulation results suggest that one specific version of the wild <b>bootstrap</b> outperforms the other versions of the wild <b>bootstrap</b> and of the pairs <b>bootstrap.</b> It {{is the only one}} for which the <b>bootstrap</b> test gives always better results than the asymptotic test...|$|R
25|$|Stage1 {{begins with}} only what is {{necessary}} to build a toolchain (the various compilers, linkers, and language libraries necessary to compile other software) for the target system; compiling this target toolchain from another, pre-existing host system is known as <b>bootstrapping</b> the target system.|$|E
25|$|The fusion {{reactions}} release high-energy particles, some of which, primarily alpha particles, {{collide with}} the surrounding high density fuel and heat it further. If this process deposits enough energy in a given area it can cause that fuel to undergo fusion as well. However, the fuel is also losing heat through x-ray losses and hot electrons leaving the fuel area, so the rate of alpha heating must be greater than these losses, a condition known as <b>bootstrapping.</b> Given the right overall conditions of the compressed fuel—high enough density and temperature—this <b>bootstrapping</b> process {{will result in a}} chain reaction, burning outward from the center where the shock wave started the reaction. This is a condition known as ignition, which will lead to {{a significant portion of the}} fuel in the target undergoing fusion and releasing large amounts of energy.|$|E
25|$|In {{the money}} market {{practitioners}} might use different techniques to solve for {{different areas of}} the curve. For example, at the short end of the curve, where there are few cashflows, the first few elements of P may be found by <b>bootstrapping</b> from one to the next. At the long end, a regression technique with a cost function that values smoothness might be used.|$|E
40|$|Although it {{is common}} to refer to “the <b>bootstrap,</b> ” there are {{actually}} a great many different <b>bootstrap</b> methods {{that can be used in}} econometrics. We emphasize the use of <b>bootstrap</b> methods for inference, particularly hypothesis testing, and we also discuss <b>bootstrap</b> confidence intervals. There are important cases in which <b>bootstrap</b> inference tends to be more accurate than asymptotic inference. However, it is not always easy to generate <b>bootstrap</b> samples in a way that makes <b>bootstrap</b> inference even asymptotically valid...|$|R
40|$|There {{are many}} <b>bootstrap</b> methods {{that can be}} used for econometric analysis. In certain circumstances, such as {{regression}} models with independent and identically distributed error terms, appropriately chosen <b>bootstrap</b> methods generally work very well. However, there are many other cases, such as regression models with dependent errors, in which <b>bootstrap</b> methods do not always work well. This paper discusses a large number of <b>bootstrap</b> methods that can be useful in econometrics. Applications to hypothesis testing are emphasized, and simulation results are presented for a few illustrative cases. <b>bootstrap,</b> Monte Carlo test, wild <b>bootstrap,</b> sieve <b>bootstrap,</b> moving block <b>bootstrap...</b>|$|R
40|$|It is {{well known}} that Efron's <b>bootstrap</b> can fail in {{settings}} where the data are heavy tailed and when regularity conditions do not hold. Naturally this applies to weighted <b>bootstrap</b> schemes such as the Bayesian <b>bootstrap.</b> To deal with this, we introduce a Bayesian <b>bootstrap</b> analogue of the m out of n <b>bootstrap.</b> This <b>bootstrap</b> differs from traditional m out of n <b>bootstraps</b> in that all n observations are used in the <b>bootstrap</b> test statistic. Moreover, the method is relatively robust to the selection of m. We establish consistency for the new <b>bootstrap</b> and examine its other useful properties including a connection to the Dirichlet process. Several examples illustrating consistency in settings where the Efron <b>bootstrap</b> fails are given. Further generalizations are suggested. (c) 2008 Elsevier B. V. All rights reserved...|$|R
25|$|SOMs {{have been}} helpful to {{researchers}} in identifying and investigating the constraints and variables of interest {{in a number of}} acquisition processes, and in exploring the consequences of these findings on linguistic and cognitive theories. By identifying working memory as an important constraint both for language learners and for current computational models, researchers have been able to show that manipulation of this variable allows for syntactic <b>bootstrapping,</b> drawing not just categorical but actual content meaning from words' positional co-occurrence in sentences.|$|E
25|$|In 2007, v6-MiniPerl6 ("mp6") and its reimplementation, v6-KindaPerl6 ("kp6") {{were written}} {{as a means}} to {{bootstrap}} the Perl-6.0.0 STD, using Perl 5. The STD is a full grammar for Perl 6 and is written in Perl 6. In theory, anything capable of parsing the STD and generating executable code is a suitable <b>bootstrapping</b> system for Perl 6. kp6 is currently compiled by mp6 and can work with multiple backends. mp6 and kp6 are not full Perl 6 implementations and are designed only to implement the minimum featureset required to bootstrap a full Perl 6 compiler.|$|E
25|$|Although many {{personal}} computers accommodate SD cards as an auxiliary storage device through a built-in slot or a USB adaptor, SD cards {{cannot be used}} as the primary hard disk through the onboard ATA controller because none of the SD card variants support ATA signalling. This use requires a separate SD controller chip or an SD-to-CompactFlash converter. However, on computers that support <b>bootstrapping</b> from a USB interface, an SD card in a USB adaptor can be the primary hard disk, provided it contains an operating system that supports USB access once the bootstrap is complete.|$|E
50|$|Histograms of the <b>bootstrap</b> {{distribution}} and the smooth <b>bootstrap</b> distribution appear below. The <b>bootstrap</b> {{distribution of the}} sample-median has {{only a small number}} of values. The smoothed <b>bootstrap</b> distribution has a richer support.|$|R
5000|$|Percentile <b>Bootstrap.</b> The {{percentile}} <b>bootstrap</b> proceeds in {{a similar}} way to the basic <b>bootstrap,</b> using percentiles of the <b>bootstrap</b> distribution, but with a different formula (note the inversion of the left and right quantiles!): ...|$|R
40|$|Abstract: The article {{proposes a}} {{computationally}} efficient procedure for bias adjustment in the iterated <b>bootstrap.</b> The new technique replaces {{the need for}} successive levels of <b>bootstrap</b> resampling by proposing an approximation for the double <b>bootstrap</b> “calibrating coefficient ” using only one draw from the second level probability distribution. Extensive Monte Carlo evidence suggest that the proposed approximation performs better than the ordinary <b>bootstrap</b> bias correction. The article evaluates {{the usefulness of the}} <b>bootstrap</b> and fast <b>bootstrap</b> in reducing the bias of generalized method of moments estimators under weak instruments. In identified models, this fast <b>bootstrap</b> bias correction leads to estimators with lower variance than those based on the double <b>bootstrap.</b> The proposed fast iterated <b>bootstrap</b> performs better than the double <b>bootstrap</b> in all scenarios and especially when the model has the weakest instrument relevance and the highest degree of endogeneity. However, when the estimators have no finite moments and the instruments are weak, the <b>bootstrap</b> does not work well and iterating it makes things worse...|$|R
25|$|Selecting a {{different}} test usually identifies {{a different}} list of significant genes since each test operates under a {{specific set of}} assumptions, and places a different emphasis on certain features in the data. Many tests begin with the assumption of a normal distribution in the data, because that seems like a sensible starting point and often produces results that appear more significant. Some tests consider the joint distribution of all gene observations to estimate general variability in measurements, while others look at each gene in isolation. Many modern microarray analysis techniques involve <b>bootstrapping</b> (statistics), machine learning or Monte Carlo methods.|$|E
25|$|Rakudo Perl 6 targets {{a number}} of virtual machines, such as MoarVM, the Java Virtual Machine and JavaScript. MoarVM is a virtual machine built {{especially}} for Rakudo Perl 6 and the NQP Compiler Toolchain. There is a layer between Perl 6 and the virtual machines called Not Quite Perl 6, or NQP, which implements Perl 6 rules for parsing Perl 6, {{as well as an}} Abstract syntax tree and backend-specific code generation. Large portions of Rakudo are written in Perl 6 itself, or in its subset NQP. Rakudo is not a completely self-hosting implementation, nor are there concrete plans at this point to make Rakudo a <b>bootstrapping</b> compiler.|$|E
500|$|In {{order for}} BitLocker to encrypt the volume holding the {{operating}} system, {{at least two}} NTFS-formatted volumes are required: one for the operating system (usually C:) and another with a minimum size of 100MB from which the operating system boots. BitLocker requires the latter to remain unencrypted—on Windows Vista this volume must be assigned a drive letter, while on Windows 7 that is not required. Unlike previous versions of Windows, Vista's [...] "diskpart" [...] command-line tool includes the ability to shrink {{the size of an}} NTFS volume so that this volume may be created from already allocated space. A tool called the BitLocker Drive Preparation Tool is also available from Microsoft that allows an existing volume on Windows Vista to be shrunk to make room for a new boot volume and for the necessary <b>bootstrapping</b> files to be transferred to it.|$|E
40|$|Efron (1979) {{introduced}} the <b>bootstrap</b> method for independent data but it cannot be easily applied to spatial data {{because of their}} dependency. For spatial data that are correlated {{in terms of their}} locations in the underlying space the moving block <b>bootstrap</b> method is usually used to estimate the precision measures of the estimators. The precision of the moving block <b>bootstrap</b> estimators is related to the block size which is difficult to select. In the moving block <b>bootstrap</b> method also the variance estimator is underestimated. In this paper, first the semi-parametric <b>bootstrap</b> is used to estimate the precision measures of estimators in spatial data analysis. In the semi-parametric <b>bootstrap</b> method, we use the estimation of the spatial correlation structure. Then, we compare the semi-parametric <b>bootstrap</b> with a moving block <b>bootstrap</b> for variance estimation of estimators in a simulation study. Finally, we use the semi-parametric <b>bootstrap</b> to analyze the coal-ash data. Moving block <b>bootstrap</b> Semi-parametric <b>bootstrap</b> Plug-in kriging Monte Carlo simulation Coal-ash data...|$|R
40|$|This paper {{provides}} bounds on {{the errors}} in coverage probabilities of maximum likelihood-based, percentile-t, parametric <b>bootstrap</b> confidence intervals for Markov time series processes. These bounds {{show that the}} parametric <b>bootstrap</b> for Markov time series provides higher-order improvements (over confidence intervals based on first order asymptotics) that are comparable to those obtained by the parametric and nonparametric <b>bootstrap</b> for iid data and are better than those obtained by the block <b>bootstrap</b> for time series. Additional results are given for Wald-based confidence regions. The paper also shows that k-step parametric <b>bootstrap</b> confidence intervals achieve the same higher-order improvements as the standard parametric <b>bootstrap</b> for Markov processes. The k-step <b>bootstrap</b> confidence intervals are computationally attractive. They circumvent the need to compute a nonlinear optimization for each simulated <b>bootstrap</b> sample. The latter is necessary to implement the standard parametric <b>bootstrap</b> when the maximum likelihood estimator solves a nonlinear optimization problem. Asymptotics, Edgeworth expansion, Gauss-Newton, k-step <b>bootstrap,</b> maximum likelihood estimator, Newton-Raphson, parametric <b>bootstrap,</b> t statistic...|$|R
40|$|The <b>bootstrap</b> is an {{increasingly}} popular method for performing statistical inference. This paper provides the theoretical foundation {{for using the}} <b>bootstrap</b> as a valid tool of inference for quasimaximum likelihood estimators (QMLE). We provide a unified framework for analyzing <b>bootstrapped</b> extremum estimators of nonlinear dynamic models for heterogeneous dependent stochastic processes. We apply our results to two block <b>bootstrap</b> methods, the moving blocks <b>bootstrap</b> of Künsch (1989) and Liu and Singh (1992) and the stationary <b>bootstrap</b> of Politis and Romano (1994), and prove the first order asymptotic validity of the <b>bootstrap</b> approximation to the true distribution of QML estimators. Further, these block <b>bootstrap</b> methods are shown to provide heteroskedastic and autocorrelation consistent standard errors for the QMLE, thus extending the already large literature on robust inference and covariance matrix estimation. We also consider <b>bootstrap</b> testing. In particular, we prove the first order asymptotic validity of the <b>bootstrap</b> distribution of a suitable <b>bootstrap</b> analog of a Wald test statistic for testing hypotheses...|$|R
2500|$|One {{consensus}} {{definition of}} <b>bootstrapping</b> {{sees it as}} [...] "a collection of methods used to minimize the amount of outside {{debt and equity financing}} needed from banks and investors". Most commonly, entrepreneurs engaging in <b>bootstrapping</b> incur personal credit-card debt, but they may utilize a wide variety of methods. While <b>bootstrapping</b> involves increased risk for entrepreneurs, the absence of any other stakeholder gives the entrepreneur more freedom to develop the company. Many successful companies, including Dell Computer and Facebook, started by <b>bootstrapping.</b>|$|E
2500|$|Even <b>bootstrapping</b> of the system, or Initial Program Load (IPL) in IBM nomenclature, {{is carried}} out by channels, {{although}} the process is partially simulated by the CPU (through an [...] "implied" [...] Start I/O [...] instruction, an [...] "implied" [...] Channel Address Word [...] at location 0 and an [...] "implied" [...] channel program [...] , also at location 0). Command chaining is assumed, so the [...] "implied" [...] CCW at location 0 falls through to {{the continuation of the}} channel program at locations 8 and 16, and possibly elsewhere should one of those CCWs be a transfer-in-channel (TIC).|$|E
2500|$|In 2012, NASA {{researchers}} Metzger, Muscatello, Mueller, and Mantovani {{argued for}} a <b>bootstrapping</b> approach to start self-replicating factories in space. They developed this concept {{on the basis of}} In Situ Resource Utilization (ISRU) technologies that NASA has been developing to [...] "live off the land" [...] on the Moon or Mars. Their modeling showed that in just 20 to 40 years this industry could become self-sufficient then grow to large size, enabling greater exploration in space as well as providing benefits back to Earth. In 2014, Thomas Kalil of the White House Office of Science and Technology Policy published on the White House blog an interview with Metzger on <b>bootstrapping</b> solar system civilization through self-replicating space industry. Kalil requested the public submit ideas for how [...] "the Administration, the private sector, philanthropists, the research community, and storytellers can further these goals." [...] Kalil connected this concept to what former NASA Chief technologist Mason Peck has dubbed [...] "Massless Exploration", the ability to make everything in space so that you do not need to launch it from Earth. Peck has said, [...] "...all the mass we need to explore the solar system is already in space. It's just in the wrong shape." [...] In 2016, Metzger argued that fully self-replicating industry can be started over several decades by astronauts at a lunar outpost for a total cost (outpost plus starting the industry) of {{about a third of the}} space budgets of the International Space Station partner nations, and that this industry would solve Earth's energy and environmental problems in addition to providing massless exploration.|$|E
40|$|A {{functional}} law for an I(1) {{sample data}} {{version of the}} continuous-path block <b>bootstrap</b> of Paparoditis and Politis (2001) is given. The results provide an alternative demonstration that continuous-path block <b>bootstrap</b> unit root tests are consistent under the null. Asymptotic theory, Block <b>bootstrap,</b> <b>Bootstrap,</b> Brownian motion, Continuous path <b>bootstrap,</b> Embedding, Unit root...|$|R
40|$|In this paper, a sieve <b>bootstrap</b> scheme, {{the neural}} network sieve <b>bootstrap,</b> for {{nonlinear}} time series is proposed. The approach, which is nonparametric in its spirit, retains the conceptual simplicity of a classical residual <b>bootstrap,</b> {{and it has}} some advantages {{with respect to the}} blockwise schemes and kernel <b>bootstrap</b> techniques. The resampling scheme from the residuals of the feedforward neural networks is shown to be asymptotically justified. A Monte Carlo simulation study shows that the procedure performs similar to the autoregressive (AR) -sieve <b>bootstrap</b> for linear processes, while it outperforms the AR-sieve <b>bootstrap,</b> the moving block <b>bootstrap</b> and kernel <b>bootstrap</b> for nonlinear processes, both in terms of bias and variability...|$|R
40|$|In {{regression}} models, appropriate <b>bootstrap</b> {{methods for}} inference robust to heteroskedasticity of unknown form are the wild <b>bootstrap</b> and the pairs <b>bootstrap.</b> The finite sample {{performance of a}} heteroskedastic-robust test is investigated with Monte Carlo experiments. The simulation results suggest that one specific version of the wild <b>bootstrap</b> outperforms the other versions of the wild <b>bootstrap</b> and of the pairs <b>bootstrap.</b> It {{is the only one}} for which the <b>bootstrap</b> test gives always better results than the asymptotic test. wild bootstrap; pairs bootstrap; heteroskedasticity-robust test; Monte Carlo simulations...|$|R
