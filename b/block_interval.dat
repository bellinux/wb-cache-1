10|119|Public
40|$|Micro-basin tillage is a {{soil and}} water {{conservation}} practice that requires building individual earth blocks along furrows. In this study, plot experiments were conducted to assess the efficiency of micro-basin tillage on sloping croplands between 2012 and 2013 (5 °and 7 °). The conceptual, optimal, <b>block</b> <b>interval</b> model was used to design micro-basins which are meant to capture the maximum amount of water per unit area. Results indicated that when compared to the up-down slope tillage, micro-basin tillage could increase soil water content and maize yield by about 45 % and 17 %, and reduce runoff, sediment and nutrients loads by about 63 %, 96 % and 86 %, respectively. Meanwhile, micro-basin tillage could reduce the peak runoff rates and delay the initial runoff-yielding time. In addition, micro-basin tillage with the optimal <b>block</b> <b>interval</b> proved to be the best one among all treatments with different intervals. Compared with treatments of other block intervals, the optimal <b>block</b> <b>interval</b> treatments increased soil moisture by around 10 % and reduced runoff rate by around 15 %. In general, micro-basin tillage with optimal <b>block</b> <b>interval</b> represents an effective {{soil and water}} conservation practice for sloping farmland of the black soil region...|$|E
3000|$|... is a {{normalized}} random vector {{having a}} zero-mean complex Gaussian distribution. Throughout this paper, we consider a quasi-static fading where the CIRs remain constant {{within a single}} <b>block</b> <b>interval,</b> i.e., a single time slot, but vary from block to block [14]. Therefore, to distinguish the CIR generated in the odd time slot between [...]...|$|E
40|$|To achieve {{unlimited}} concurrency {{and hence}} throughput in an area-efficient manner, a sliding block Viterbi decoder (SBVD) is implemented that combines the filtering {{characteristics of a}} sliding block decoder with the computational efficiency of the Viterbi algorithm. The SBVD approach reduces decode of a continuous input stream to decode of independent overlapping blocks, without constraining the encoding process. A systolic SBVD architecture is presented that combines forward and backward processing of the <b>block</b> <b>interval.</b> The architecture is demonstrated in a four-state, R = 1 / 2, eight-level soft decision Viterbi decoder that has been designed and fabricated in double-metal CMOS. The 9. 21 mm × 8. 77 mm chip containing 150 k transistors is fully functional at a clock rate of 83 MHz and dissipates 3. 0 W under typical operating conditions (V = 5. 0 V, T = 27 °C). This corresponds to a block decode rate of 83 MHz, equivalent to a decode rate of 1 Gb/s. For low-power operation, typical parts are fully functional at a clock rate of greater than 12 MHz. equivalent to a decode rate of 144 Mb/s, and dissipate 24 mW at V = 1. 5 V, demonstrating extremely low power consumption at such high rates...|$|E
40|$|Fixed-priority schedulers {{received}} a lot of attention from the real-time community, and a big effort has been performed to develop accurate and more general schedulability analysis that can ensure the correct execution of the system. Nevertheless, only few works analysed the overhead and <b>blocking</b> <b>intervals</b> introduced by the scheduler and the associated kernel routines, modifying the schedulability tests to take into account these overheads. However, all these works assume a very simple scheduler that uses trivial data structures to stores the tasks information. Thi...|$|R
40|$|The <b>block</b> {{bootstrap}} confidence <b>interval</b> for dependent {{data can}} outperform the conventional normal approximation only with nontrivial studentization which, {{in the case}} of complicated statistics, calls for specialist treatment and often results in unstable endpoints. We propose two double block bootstrap approaches for improving the accuracy of the <b>block</b> bootstrap confidence <b>interval</b> under very general conditions. The first approach calibrates the nominal coverage level and the second calculates studentizing factors directly from a block bootstrap series without the need for nontrivial analytical treatment. We prove that the two approaches reduce the coverage error of the <b>block</b> bootstrap <b>interval</b> by an order of magnitude with simple tuning of block lengths at the two block bootstrapping levels. Empirical properties of the procedures are investigated by simulations and application to an econometric time series. © 2009 Biometrika Trust. link_to_subscribed_fulltex...|$|R
40|$|This {{paper is}} focused on such topics as {{possibility}} of using classification decision trees for forecasting continuous values and related problems: classification tree modification, choosing the best tree and managing the <b>blocked</b> value <b>intervals.</b> Section 2 presents theoretical solutions to the mentioned problems and Section 3 shows how methods, considered in Section 2, are realised in practise...|$|R
40|$|Abstract — To achieve {{unlimited}} concurrency {{and hence}} throughput in an area-efficient manner, a sliding block Viterbi decoder (SBVD) is implemented that combines the filtering {{characteristics of a}} sliding block decoder with the computational efficiency of the Viterbi algorithm. The SBVD approach reduces decode of a continuous input stream to decode of independent overlapping blocks, without constraining the encoding process. A systolic SBVD architecture is presented that combines forward and backward processing of the <b>block</b> <b>interval.</b> The architecture is demonstrated in a four-state, R = 1 = 2, eightlevel soft decision Viterbi decoder that has been designed and fabricated in double-metal CMOS. The 9. 21 mm 2 8. 77 mm chip containing 150 k transistors is fully functional at a clock rate of 83 MHz and dissipates 3. 0 W under typical operating conditions (VDD = 5 : 0 V, TA = 27 C). This corresponds to a block decode rate of 83 MHz, equivalent to a decode rate of 1 Gb/s. For low-power operation, typical parts are fully functional at a clock rate of greater than 12 MHz, equivalent to a decode rate of 144 Mb/s, and dissipate 24 mW at VDD = 1 : 5 V, demonstrating extremely low power consumption at such high rates. Index Terms—Forward error correction, trellis codes, Viterbi decoding, Viterbi detection, Viterbi estimation. I...|$|E
40|$|The {{problem of}} {{constructing}} space-time (ST) block codes over a fixed, desired signal constellation is considered. In this situation, {{there is a}} tradeoff between the transmission rate as measured in constellation symbols per channel use and the transmit diversity gain achieved by the code. The transmit diversity {{is a measure of}} the rate of polynomial decay of pairwise error probability of the code with increase in the signal-to-noise ratio (SNR). In the setting of a quasi-static channel model, let n(t) denote the number of transmit antennas and T the <b>block</b> <b>interval.</b> For any n(t) <= T, a unified construction of (n(t) x T) ST codes is provided here, for a class of signal constellations that includes the familiar pulse-amplitude (PAM), quadrature-amplitude (QAM), and 2 (K) -ary phase-shift-keying (PSK) modulations as special cases. The construction is optimal as measured by the rate-diversity tradeoff and can achieve any given integer point on the rate-diversity tradeoff curve. An estimate of the coding gain realized is given. Other results presented here include i) an extension of the optimal unified construction to the multiple fading block case, ii) a version of the optimal unified construction in which the underlying binary block codes are replaced by trellis codes, iii) the providing of a linear dispersion form for the underlying binary block codes, iv) a Gray-mapped version of the unified construction, and v) a generalization of construction of the S-ary case corresponding to constellations of size S-K. Items ii) and iii) are aimed at simplifying the decoding of this class of ST codes...|$|E
40|$|Orthogonal Frequency Division Multiplexing (OFDM) is {{a popular}} {{technique}} used to combat frequency selective fading in multipath channels. When spectral nulls {{are present in the}} channel, they can severely degrade or cancel out OFDM tones, resulting in an irreducible error rate. To combat this, standards typically employ forward error correction (FEC) techniques. Code-Spread OFDM (CS-OFDM) combines the characteristics of OFDM and Code Division Multiple Access (CDMA) to create a more robust modulation scheme which provides substantial performance improvements relative to standard OFDM. In CS-OFDM, each sinewave carries a weighted sum of all the information symbols being transmitted in an OFDM <b>block</b> <b>interval.</b> The MMSE estimator is derived for each symbol for a number of cases, including when the number of carriers is greater than the number of symbols. To enhance the BER performance while maintaining a low receiver complexity, subcarrier grouping is combined with the Local Maximum Likelihood (LML) method of Rugini et al. ^ This dissertation expands on idea of code spreading for MIMO-OFDM and proposes a space-time-frequency coding scheme that achieves full rate for an arbitrary number of antennas with complex-valued information symbols. In addition, the proposed scheme provides full diversity with ML receivers. In the new scheme, the spatial and frequency spreading is followed by a temporal spreading that facilitates simple separation of the respective signals sent by the various transmit antennas. This temporal spreading enables perfect separation of the superimposed transmit signals at the receiver prior to channel estimation. Simulations are presented demonstrating the efficacy of the new scheme and is compared to Orthogonal Space Time Block Code (OSTBC) based schemes and the performance of MMSE, ML, and LML receivers are also noted. ...|$|E
40|$|This paper {{establishes}} {{that the}} minimum error rates in coverage probabilities of one- and sym-metric two-sided <b>block</b> bootstrap confidence <b>intervals</b> are of orders O(n− 3 / 4) and O(n− 4 / 3), respec-tively, for normalized and studentized smooth functions of sample averages. The block lengths that minimize the error in coverage probabilities of one- and symmetric two-sided <b>block</b> bootstrap con-fidence <b>intervals</b> are proportional to n 1 / 4 and n 1 / 3, respectively. Existing literature provides Monte Carlo evidence that such small {{improvement over the}} coverage precision of asymptotic confidence intervals is to be expected. 1...|$|R
5000|$|A new {{gameplay}} {{feature is}} {{introduced in the}} form of [...] "one-two attacks". When the player presses a heavy attack button while performing a light attack or <b>blocking,</b> the <b>interval</b> between light attacks is reduced, making combos easier to perform. While this feature is not mentioned on the instruction card, the final page of the home Neo-Geo version's manual mentions it, describing as the [...] "one-two attack" [...] system.|$|R
30|$|Different {{operations}} are implemented {{according to whether}} the preamble symbols are present or not. In this way, the power consumption of the <b>blocks</b> in the <b>interval</b> that no preamble symbol is present can be greatly reduced.|$|R
40|$|In this thesis, {{we propose}} the novel Space-Time Coding (STC) concept of Space-Time Shift Keying (STSK) and explore its {{characteristics}} in the contexts of both co-located and cooperative Multiple-Input Multiple-Output (MIMO) systems using both coherent and non-coherent detection. Furthermore, we conceive new serially-concatenated turbo-coding assisted STSK {{arrangements for the}} sake of approaching the channel capacity limit, which are designed with the aid of EXtrinsic Information Transfer (EXIT) charts. The basic STSK concept is first proposed for the family of co-located MIMO systems employing coherent detection. More specifically, in order to generate space-time codewords, these Coherent STSK (CSTSK) encoding schemes activate one out of Q dispersion matrices. The CSTSK scheme is capable of striking an attractive tradeoff between the achievable diversity gain and the transmission rate, hence having the potential of outperforming other classic MIMO arrangements. Since no inter-channel interference is imposed at the CSTSK receiver, the employment of single-stream-based Maximum Likelihood (ML) detection becomes realistic. Furthermore, {{for the sake of}} achieving an infinitesimally low Bit-Error Ratio (BER) at low SNRs, we conceive a three-stage concatenated turbo CSTSK scheme. In order to mitigate the effects of potential Channel State Information (CSI) estimation errors as well as the high pilot overhead, the Differentially-encoded STSK (DSTSK) philosophy is conceived with the aid of the Cayley transform and differential unitary space-time modulation. The DSTSK receiver benefits from low-complexity non-coherent single-streambased ML detection, while retaining the CSTSK scheme’s fundamental benefits. In order to create further flexible STSK architecture, the above-mentioned co-located CSTSK scheme is generalized so that P out of Q dispersion matrices are activated during each space-time <b>block</b> <b>interval.</b> Owing to its highly flexible structure, this generalized STSK scheme subsumes diverse other MIMO arrangements. Finally, the STSK concept is combined with cooperative MIMO techniques, which are capable of attaining the maximum achievable diversity gain by eliminating the undesired performance limitations imposed by uncorrelated fading. More specifically, considering the usual twin-phase cooperative transmission regime constituted by a broadcast phase and by a cooperative phase, the CSTSK and DSTSK schemes developed for co-located MIMO systems are employed during the cooperative transmission phase. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|International audienceA stratigraphic {{section in}} the basal Fort Union Formation (Paleocene) in southwestern North Dakota was used to study in detail the post-crisis {{recovery}} {{as well as to}} reconstruct the local environment and its evolution using sedimentology, palynology, fossil floras and vertebrate data. This report will focus on the flora from this site, corresponding to the first appearance data for Paleocene floral recovery, just above the Cretaceous­Tertiary (K/T) Boundary. The studied flora consist of an assemblage of tightly stacked leaves preserved as carbon imprints (also called leaf mats), a preservation condition that makes the extraction of each individual leaf difficult to achieve directly on site. As a result, a new technique was tested, allowing the study of every leaf preserved, their sedimentological context as well as their position relative to each other. A large block of matrix including the leaf mat was jacketed in plaster and was taken to the museum laboratory for analysis under controlled conditions. Preparation consisted of removing sediments at a millimeter scale and recording of placement and orientation of all fossil materials for three-dimensional reconstructions. Using this technique, a description and census of more than 300 leaf specimens was possible within an area of only 0. 5 m 2. The general sedimentological context indicates that the leaves were deposited in a near-stream environment associated with short-term flood events. Detailed information on depositional environment was gathered both by cutting a stratigraphic column from the Hell Creek/Fort Union formational contact up through the basal 4 m of the Fort Union Formation and by studying sediments and leaf preservation mode in detail within the leaf mat. Significant changes in taxonomic abundances correlated with different lithologies was observed, and a leaf species new to the study area was reported. The new methodology proves to be an efficient way to recover additional taphonomic and paleoenvironmental information from leaf mats necessary to understand the depositional dynamics of a fossiliferous leaf site, as well as to improve the record of taxonomic census. In a biostratigraphical prospective, the specimens recovered represent a low-diversity Fort Union flora composed exclusively of dicots that do not exist in the Hell Creek Formation. Preliminary palynological analysis reveal a Cretaceous age for the entire stratigraphic section, implying that the studied leaf mat is part of the FU 0 megafloral zone (as defined by the occurrence of a Fort Union flora with Cretaceous palynomorphs). However, this Cretaceous age attribution for the entire section is questioned due to the occurrence of Paranymphaea crassifolia (part of the Paleocene FUI megafloral zone) within another leaf mat located 266 cm above the base of the coal representing the formational contact, and the occurrence of Paleocene PU 1 mammals, reported from sediment within the leaf <b>block</b> <b>interval...</b>|$|E
40|$|Over {{the past}} few years there has been an {{extensive}} growth in data traffic consumption devices. Billions of mobile data devices are connected to the global wireless network. Customers demand revived services and up-to-date developed applications, like real-time video and games. These applications require reliable and high data rate wireless communication with high throughput network. One way to meet these requirements is by increasing the number of transmit and/or receive antennas of the wireless communication systems. Massive multiple-input multiple-output (MIMO) has emerged as a promising candidate technology for the next generation (5 G) wireless communication. Massive MIMO increases the spatial multiplexing gain and the data rate by adding an excessive number of antennas to the base station (BS) terminals of wireless communication systems. However, building efficient algorithms able to decode a coherently or non-coherently large flow of transmitted signal with low complexity is a big challenge in massive MIMO. In this dissertation, we propose novel approaches to achieve optimal performance for joint channel estimation and signal detection for massive MIMO systems. The dissertation consists of three parts depending on the number of users at the receiver side. In the first part, we introduce a probabilistic approach {{to solve the problem of}} coherent signal detection using the optimized Markov Chain Monte Carlo (MCMC) technique. Two factors contribute to the speed of finding the optimal solution by the MCMC detector: The probability of encountering the optimal solution when the Markov chain converges to the stationary distribution, and the mixing time of the MCMC detector. First, we compute the optimal value of the “temperature 2 ̆ 72 ̆ 7 parameter such that the MC encounters the optimal solution in a polynomially small probability. Second, we study the mixing time of the underlying Markov chain of the proposed MCMC detector. We assume the channel state information is known in the first part of the dissertation; in the second part we consider non-coherent signal detection. We develop and design an optimal joint channel estimation and signal detection algorithms for massive (single-input multiple-output) SIMO wireless systems. We propose exact non-coherent data detection algorithms in the sense of generalized likelihood ratio test (GLRT). In addition to their optimality, these proposed tree based algorithms perform low expected complexity and for general modulus constellations. More specifically, despite the large number of the unknown channel coefficients for massive SIMO systems, we show that the expected computational complexity of these algorithms is linear in the number of receive antennas (N) and polynomial in channel coherence time (T). We prove that as N →∞, the number of tested hypotheses for each coherent block equals T times the cardinality of the modulus constellation. Simulation results show that the optimal non-coherent data detection algorithms achieve significant performance gains (up to 5 dB improvement in energy efficiency) with low computational complexity. In the part three, we consider massive MIMO uplink wireless systems with time-division duplex (TDD) operation. We propose an optimal algorithm in terms of GLRT to solve the problem of joint channel estimation and data detection for massive MIMO systems. We show that the expected complexity of our algorithm grows polynomially in the channel coherence time (T). The proposed algorithm is novel in two terms: First, the transmitted signal can be chosen from any modulus constellation, constant and non-constant. Second, the algorithm decodes the received noisy signal, which is transmitted a from multiple-antenna array, offering exact solution with polynomial complexity in the coherent <b>block</b> <b>interval.</b> Simulation results demonstrate significant performance gains of our approach compared with suboptimal non-coherent detection schemes. To the best of our knowledge, this is the first algorithm which efficiently achieves GLRT-optimal non-coherent detections for massive MIMO systems with general constellations...|$|E
40|$|This paper {{establishes}} the optimal bootstrap block lengths for coverage probabilities when the bootstrap {{is applied to}} covariance stationary ergodic dependent data. It is shown that the block lengths that minimize the error in coverage probabilities of one- and two-sided <b>block</b> bootstrap confidence <b>intervals</b> of normalized and studentized smooth functions of sample averages are proportional to $n^{ 1 / 4 }$. The minimum error rates in coverage probabilities of one- and two-sided <b>block</b> bootstrap confidence <b>intervals</b> are of order O($n^{- 3 / 2 }$) and O($n^{- 5 / 4 }$), respectively, for normalized and studentized statistics. This constitutes a refinement over the asymptotic confidence intervals. ...|$|R
40|$|Acute {{myocarditis}} is {{an infection}} in infants {{which may be}} complicated by cardiac dysfunction and arrhythmias. Sinus tachycardia with low-voltage QRS complexes, T waves and ST-segment changes, atrial or ventricular tachycardia, atrioventricular <b>block,</b> QT <b>interval</b> prolongation on electrocardiogram (ECG) {{may be seen in}} patients with acute myocarditis. Although atrial or ventricular arrhythmias have been reported in myocarditis, there are limited reports of arrhythmias complicating with each other. We describe the case on an infant presented with supraventricular tachycardia complicating to the QT interval prolongation and back to the sinus rhythm in viral myocarditis...|$|R
40|$|This paper {{considers}} blockwise empirical likelihood for real-valued linear time processes {{which may}} exhibit either short- or long-range dependence. Empirical likelihood approaches intended for weakly dependent time series can fail {{in the presence}} of strong dependence. However, a modified blockwise method is proposed for confidence interval estimation of the process mean, which is valid for various dependence structures including long-range dependence. The finite-sample performance of the method is evaluated through a simulation study and compared to other confidence interval procedures involving subsampling or normal approximations. <b>blocking,</b> confidence <b>interval,</b> empirical likelihood, FARIMA, long-range dependence...|$|R
40|$|The {{quality of}} the ranging data {{provided}} by a global navigation satellite systems (GNSS) receiver largely depends on the synchronization error, that is, on {{the accuracy of the}} propagation time-delay estimation of the line-of-sight (LOS) signal. In case the LOS signal is corrupted by several superimposed delayed replicas (reflective, diffractive, or refractive multipath) and/or additional radio frequency interference (RFI), the estimation of the propagation time-delay and thus the position can be severely degraded using state-of-the-art GNSS receivers. Multi-antenna GNSS receivers enable application of array processing for effective multipath and interference mitigation. Especially, beamforming (spatial filtering) approaches have been studied intensely for GNSS in the past years due to a balanced trade-off between performance and complexity. Usually these beamforming approaches require knowledge of the spatial signature (spatial reference) of the desired signal and thus require detailed knowledge of the direction-of-arrival (DOA) of the LOS signal and/or non-LOS signals, the antenna response, the array geometry, and other hardware biases. Even if the antenna array response can be approximately determined, either by empirical measurements (array calibration) or by making certain assumptions (e. g. identical sensor elements in known locations), the true antenna array response can be significantly different due to for example changes in antenna location, temperature, calibration inaccuracy and the surrounding environment. Thus, robust beamforming algorithms were developed in order to cope with errors in the array response model to be applied to derive the spatial filter. In this work we propose a blind adaptive beamforming approach based on orthogonal projections for GNSS, for which knowledge about the array response and spatial reference for the LOS signal are not required. The proposed approach is capable of adaptively mitigating RFI and multipath components based on orthogonal projections. In order to derive the needed projectors adaptively two eigendecompositions of the estimate of the spatial covariance matrix before (pre-correlation) and after (post-correlation) despreading are performed. Based on these eigendecompositions appropriate estimations of subspaces are achieved in order to derive projectors onto the interference free and multipath free subspaces, respectively. At pre-correlation stage the covariance matrix estimation can be evaluated over a short time interval in order to realize good performance in case of a jammer with a high time-frequency dynamic (e. g. Chirp-like jammer). For the implementation within a real-time receiver, dedicated building-blocks are used. Computation of the covariance matrix and the projection into the interference free subspace is performed by hardware-macros at sampling-rate. In contrast, the eigendecomposition is executed on a processor achieving projector update-rates in the kHz-range. Implementation issues addressing quantization losses related to wordlength configurations for both hardware building-blocks are discussed. Once interfering signals are removed from the input signals, wordlengths can be reduced in order to minimize implementation costs for the subsequent despreading or correlation. Wordlength reduction is realized using a digital automatic gain control (AGC). At post-correlation stage all available degrees of freedom are used for multipath mitigation, noise reduction and further cancellation of residual interferences. After despreading, projection into the multipath free subspace becomes an individual process for each channel of the receiver. Considering the computational load on a navigation processor, this is a very challenging task since covariance matrices and eigendecompositions have to be computed individually for each channel. A cost-analysis in terms of processing cycles on an embedded processor for the covariance matrix computation and eigendecomposition is provided. In addition, the relation between the covariance observation time and multipath mitigation performance are analyzed for selected scenarios. Simulation results show that the proposed blind adaptive beamforming approach based on orthogonal projections achieves effective interference and multipath mitigation capabilities compared to state-of-the-art non-blind beamforming algorithms. The overall complexity required by the blind beamformer is discussed and a feasible hardware implementation is derived. The accuracy and numerical stability of estimation of the spatial covariance matrix before and after despreading are shown for both <b>block</b> <b>interval</b> and recursive estimation methods. Providing costs in terms of computational requirements and navigation performance related to a specific implementation a trade-off between estimation robustness, time-frequency characterization and mitigation capability is derived. Based on this analysis a complete multi-antenna GNSS receiver architecture is proposed taking into account hardware complexity and navigation performance. A software bit accurate representation of the receiver hardware platform is used for performance evaluation. As the proposed blind approach does not require precise a priori information about the DOAs of the LOS (spatial reference) or non-LOS signals and about the antenna array response, robustness with respect to errors in the antenna array response model and additional hardware biases can be achieved without further increase of complexity...|$|E
40|$|Topological and metric entropies of the DNA {{sequences}} {{from different}} organisms were calculated. Obtained results were compared {{each other and}} with ones of corresponding artificial sequences. For all envisaged DNA sequences there is a maximum of heterogeneity. It falls in the <b>block</b> length <b>interval</b> [5, 7]. Maximum distinction between natural and artificial sequences is shifted on 1 - 3 position from the maximum of heterogeneity to the right as for metric as for topological entropy. This point on the specificity of real DNA sequences in the interval. Comment: 10 pages 7 figures submitted to PL...|$|R
40|$|The <b>block</b> {{bootstrap}} confidence <b>interval</b> {{based on}} dependent data can outperform the computationally more convenient normal approximation only with non-trivial Studentization which, {{in the case}} of complicated statistics, calls for highly specialist treatment. We propose two different approaches to improving the accuracy of the <b>block</b> bootstrap confidence <b>interval</b> under very general conditions. The first calibrates the coverage level by iterating the block bootstrap. The second calculates Studentizing factors directly from block bootstrap series and requires no non-trivial analytic treatment. Both approaches involve two nested levels of block bootstrap resampling and yield high-order accuracy with simple tuning of block lengths at the two resampling levels. A simulation study is reported to provide empirical support for our theory. The 1 st Institute of Mathematical Statistics Asia Pacific Rim Meeting (IMS-APRM), Seoul, Korea, 28 June- 1 July 2009...|$|R
40|$|Invasive {{species are}} {{typically}} {{viewed as an}} economic bad because they cause economic and ecological damages, and {{can be difficult to}} control. When direct management is limited, another option is indirect management via bio-controls. Here management is directed at the bio-control species population (e. g., supplementing this population through stocking) with the aim that, through ecological interactions, the bio-control species will control the invader. We focus on stocking salmon to control invasive alewives in Lake Michigan. Salmon are valuable to recreational anglers, and alewives are their primary food source in Lake Michigan. We illustrate how stocking salmon can be used to control alewife, {{while at the same time}} alewife can be turned from a net economic bad (having a negative shadow value) into a net economic good (having a positive shadow value) by providing valuable ecosystem services that support the recreational fishery. Using optimal control theory, we solve for a stocking program that maximizes social welfare. Optimal stocking results in cyclical dynamics. We link concepts of natural capital and indirect management, population dynamics, non-convexities, and multiple-use species and demonstrate that species interactions are critical to the values that humans derive from ecosystems. This research also provides insight into the management of salmon fisheries in the Great Lakes. Bioeconomics Optimal control <b>Blocked</b> <b>intervals</b> Fisheries Multiple-use species Invasive species...|$|R
2500|$|To avoid intersymbol {{interference}} in multipath fading channels, a guard interval of length [...] is inserted {{prior to the}} OFDM <b>block.</b> During this <b>interval,</b> a cyclic prefix is transmitted such that the signal in the interval [...] equals the signal in the interval [...] The OFDM signal with cyclic prefix is thus: ...|$|R
50|$|The Lisk network forges <b>blocks</b> in 10s <b>intervals.</b> In {{the event}} that a {{delegate}} fails to properly forge their assigned block, the transactions {{move to the next}} block in the round, causing the block to be extended by 10s. Each subsequent missed block results in a 10s delay for transaction processing and confirmations.|$|R
5000|$|To avoid intersymbol {{interference}} in multipath fading channels, a guard interval of length [...] is inserted {{prior to the}} OFDM <b>block.</b> During this <b>interval,</b> a cyclic prefix is transmitted such that the signal in the interval [...] equals the signal in the interval [...] The OFDM signal with cyclic prefix is thus: ...|$|R
40|$|Abstract. Topological and metric entropies of the DNA {{sequences}} {{from different}} organisms were calculated. Obtained results were compared {{each other and}} with ones of corresponding artificial sequences. For all envisaged DNA sequences there is a maximum of heterogeneity. It falls in the <b>block</b> length <b>interval</b> [5, 7]. Maximum distinction between natural and artificial sequences is shifted on 1 - 3 position from the maximum of heterogeneity to the right as for metric as for topological entropy. This point on the specificity of real DNA sequences in the interval. PACS number(s) : 87. 10 +e KEY WORDS: entropy DNA analysis 1...|$|R
50|$|I narrated {{the script}} of Kantri to Puri Jagan {{when we went}} to Manali to shoot Desamuduru for 30 days. He listened to the {{beginning}} scene, <b>interval</b> <b>block</b> and pre-climax and said that this film will become a hit. He also liked Kantri title and immediately registered it on Vaishno banner so that others won't squat on it.|$|R
50|$|In a British study, {{students}} were closely observed by teams of researchers who recorded their “moment to moment” behaviors in <b>blocks</b> of 10-second <b>intervals.</b> The {{researchers found that}} adding five students to a class decreased the odds of students’ being on task by nearly a quarter. In classes of 30, low-attaining {{students were}} nearly {{twice as likely to}} be disengaged as they were in classes of 15.|$|R
40|$|A 55 {{year old}} man with history of {{palpitation}} was referred for electrophysiologic study. Baseline ECG, physical examination and transthoracic echocardiographic study were normal. Electrophysiologic study revealed normal AH and HV intervals. Pacing of right atrium with a cycle length of 300 msec showed 2 : 1 AV <b>block.</b> AH <b>interval</b> was 252 msec and the block was infra-his (Figure 1). With continual of right atrial pacing, one to one AV conduction with increasing AH interval to 282 msec and QRS widening (LBBB pattern) were being observed. HV intervals during 2 : 1 block and during 1 : 1 AV conduction were normal. What is the mechanism? Is it an abnormal finding in this patient...|$|R
40|$|This paper {{develops}} a {{general theory of}} sequential irreversible investments in capital where a firm has the option to expand its current capacity or just wait for better time. Facing economic uncertainty, the firm has an operating function of the current capacity and an exogenous stochastic factor modelled by semimartingale. This general model encompasses all previously studied models, including the deterministic case {{as well as the}} stochastic case with Geometric Brownian motions, Lévy processes and even with regime shift. In this paper, general existence and uniqueness results are first provided for irreversible investments with finite and infinite horizon, respectively. As the main contribution of this paper, a new method is proposed to characterize the optimal investment policy, the base capacity policy. Under the policy, the capacity is kept always at or above the base capacity which is characterized by a stochastic backward equation. This new method gives a number of new qualitative insights into the nature of the irreversible investment. It is demonstrated that the optimal policy equals the marginal operating profit and the user cost of capital in those free intervals when the irreversibility constraint does not bind. While, the equality holds true only on average in <b>block</b> <b>intervals</b> when no investment occurs. Besides, this method easily leads to some general comparative statics results: When the operating profit function is supermodular, the base capacity increases monotonically with the exogenous shock; and the firm size always declines with the user cost of capital. Finally, explicit solutions are derived when the exogenous economic shocks are modelled by Lévy processes and the operating profit function is of Cobb–Douglas style...|$|R
40|$|The growing {{popularity}} of wireless communications networks has resulted in greater bandwidth contention and therefore spectrally efficient transmission schemes are highly sought after by designers. Space-time block codes (STBCs) in multiple-input, multiple-output (MIMO) systems are able to increase channel capacity as well as reduce error rate. A general linear space-time structure known as linear dispersion codes (LDCs) can be designed to achieve high-data rates and {{has been researched extensively}} for flat fading channels. However, very little research has been done on frequency-selective fading channels. The combination of ISI, signal interference from other transmitters and noise at the receiver mean that maximum likelihood sequence estimation (MLSE) requires high computational complexity. Detection schemes that can mitigate the signal interference can significantly reduce the complexity and allow intersymbol interference (ISI) equalization to be performed by a Viterbi decoder. In this thesis, detection of LDCs on frequency-selective channels is investigated. Two predominant detection schemes are investigated, namely linear processing and zero forcing (ZF). Linear processing depends on code orthogonality and is only suited for short channels and small modulation schemes. ZF cancels interfering signals when a sufficient number of receive antennas is deployed. However, this number increases with the channel length. Channel decay profiles are investigated for high-rate LDCs to ameliorate this limitation. Performance improves when the equalizer assumes a shorter channel than the actual length provided the truncated taps carry {{only a small portion of}} the total channel power. The LDC is also extended to a multiuser scenario where two independent users cooperate over half-duplex frequency-selective channels to achieve cooperative gain. The cooperative scheme transmits over three successive <b>block</b> <b>intervals.</b> Linear and zero-forcing detection are considered...|$|R
40|$|Let G=(V,E) be a graph without {{isolated}} vertices. A set S⊆ V is a paired-domination set {{if every}} vertex in V-S is {{adjacent to a}} vertex in S and the subgraph induced by S contains a perfect matching. The paired-domination problem {{is to determine the}} paired-domination number, which is the minimum cardinality of a paired-dominating set. Motivated by a mistaken algorithm given by Chen, Kang and Ng [Paired domination on interval and circular-arc graphs, Disc. Appl. Math. 155 (2007), 2077 - 2086], we present two linear time algorithms to find a minimum cardinality paired-dominating set in <b>block</b> and <b>interval</b> graphs. In addition, we prove that paired-domination problem is NP-complete for bipartite graphs, chordal graphs, even split graphs. Comment: 15 page...|$|R
50|$|Outside {{the mating}} season, the platypus {{lives in a}} simple ground burrow, the {{entrance}} of which is about 30 cm above the water level. After mating, the female constructs a deeper, more elaborate burrow up to 20 m long and <b>blocked</b> at <b>intervals</b> with plugs (which may act as a safeguard against rising waters or predators, or {{as a method of}} regulating humidity and temperature). The male takes no part in caring for its young, and retreats to his year-long burrow. The female softens the ground in the burrow with dead, folded, wet leaves, and she fills the nest {{at the end of the}} tunnel with fallen leaves and reeds for bedding material. This material is dragged to the nest by tucking it underneath her curled tail.|$|R
30|$|In Experiment 1 b, {{participants}} {{performed the}} peripheral target detection and manual tracking tasks concurrently. Participants {{were encouraged to}} maintain accuracy on both tasks, while also aiming to minimize RTs on the detection task. As in Experiment 1 a, the task involved one <b>block</b> of tracking <b>intervals,</b> comprising one 60 -s practice interval followed by 20 60 -s experimental intervals. Lastly, participants completed the FLANDERS questionnaire, recorded their driving experience, and were debriefed.|$|R
40|$|This paper {{develops}} a {{general theory of}} irreversible investment of a single firm that chooses a dynamic capacity expansion plan in an uncertain environment. The model is set up free of any distributional or any parametric assumptions and hence encompasses all the existing models. As the first contribution, a general existence and uniqueness result is provided for the optimal investment policy. Based upon an alternative approach developed previously to dynamic programming problems, we derive the optimal base capacity policy such that the firm always keeps the capacity {{at or above the}} base capacity. The critical base capacity is explicitly constructed and characterized via a stochastic backward equation. This method allows qualitative insights into the nature of the optimal investment under irreversibility. (It is demonstrated that the marginal profit is indeed equal to the user cost of capital in free intervals where investment occurs in an absolutely continuous way at strictly positive rates. However, the equality is maintained only in expectation on average in <b>blocked</b> <b>intervals</b> where no investment occurs. Whenever the uncertainty is generated by a diffusion, the investment is singular with respect to Lebesgue measure. In contrast to the deterministic and Brownian motion case where lump sum investment takes place only at time zero, the firm responses in general more frequently in jumps to shocks. Nevertheless, lump sum investments are shown to be possible only at information surprises which is defined as unpredictable stopping time or unanticipated information jump even at the predictable time.) Furthermore, general monotone comparative statics results are derived for the relevant ingredients of the model. Finally, explicit solutions are derived for infinite time horizon, a separable operating profit function of Cobb?Douglas type and an exponential L 4 evy process modelled economic shock...|$|R
30|$|Tectonically, the Moxinpo mine {{is located}} in {{southern}} part of Chongqing fold bundle and west limb of the Guanyinxia anticline. Tectonic line trend orients mainly NNE-SSW. Anticlines of Xishan, Libixia, Wentangxia, Guanyinxia and Longwangdong, synclines among the anticlines are the southern extension of the Chongqing fold bundle, which is a typical <b>interval</b> <b>block</b> fold and characterized by close anticlinal folds, synclinal fold-relief. The fracture zone is developed mainly by reverse fault, shown in Fig. 1 b.|$|R
