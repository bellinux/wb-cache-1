8|20|Public
6000|$|... "Oh, yes, {{you just}} bet they will," [...] he {{answered}} cheerfully. [...] "Jim Grant and Number Sixty {{are a very}} <b>bad</b> <b>pair</b> to beat; he'll either jump the track or rush her through it. He's backing her out {{now for the first}} lead." ...|$|E
60|$|Excellenz Seckendorf, whom Friedrich Wilhelm so loves, is by {{no means}} a {{beautiful}} man; far the reverse. Bodily,--and the spirit corresponds,--a stiff-backed, petrified, stony, inscrutable-looking, and most unbeautiful old Intriguer. Portraits of him, which are frequent, tell all one story. The brow puckered together, in a wide web of wrinkles from each temple, as if it meant to hide the <b>bad</b> <b>pair</b> of eyes, which look suspicion; inquiry, apprehension, habit of double-distilled mendacity; the indeterminate projecting chin, with its thick, chapped under-lip, is shaken out, or shoved out, in mill-hopper fashion,--as if to swallow anything there may be, spoken thing or other, and grind it to profitable meal for itself. Spiritually he was an old Soldier let for hire; an old Intriguer, Liar, Fighter, what you like. What we may call a human Soul standing like a hackney-coach, this half-century past, with head, tongue, heart, conscience, at the hest of a discerning public and its shilling.|$|E
50|$|The 2 real players answer {{questions}}. After 5 {{questions are}} answered, the players play a minigame to test if {{the players are}} a good pair or a <b>bad</b> <b>pair.</b> The starter Miis for the best pair are Matt and Lucia (70) while the starter Miis for the worst pair are Tatsuaki and Abby (26).|$|E
40|$|Abstract. With {{pairwise}} testing, {{the test}} {{model is a}} list of N param-eters. Each test case is an N-tuple; the test space is the cross product of the N parameters. A pairwise test is a set of N-tuples where every pairwise combination of the parameter values is contained in {{at least one of the}} N-tuples. Well-known algorithms generate pairwise test sets far smaller than the test space. Pairwise testing has good tool support and is widely known in industry and academia. Empirical results have shown the effectiveness of the approach. While pairwise testing is used to generate test inputs, we propose a novel analysis of the test outputs. We focus on bad pairs: those which always result in a failed test case. We experimentally evaluate the frequency of occurrence of <b>bad</b> <b>pairs</b> using mutation testing with 1 and 2 faults per mutant. The results provide use-ful insights into two important relationships: (1) between faults and <b>bad</b> <b>pairs</b> and (2) between input selection and <b>bad</b> <b>pairs.</b> We then apply the approach to an industrial example in network vulnerability testing. We also present error-locating arrays, a recent theoretical result providing a powerful tool for <b>bad</b> <b>pairs</b> analysis...|$|R
5000|$|Heteroduplexes are {{actually}} double strands of DNA containing a strand from the wild-type allele and a sprig from the polymorphic allele. The formation of such DNA fragments then causes {{the appearance of}} a [...] "mismatch" [...] or <b>bad</b> <b>pairing</b> where is located the polymorphism.|$|R
40|$|AbstractIn his 1964 paper, de Bruijn (Math. Comp. 18 (1964) 537) {{called a}} pair (a,b) of {{positive}} odd integers good, if Z=aS⊖ 2 bS, where S is {{the set of}} nonnegative integers whose 4 -adic expansion has only 0 's and 1 's, otherwise he called the <b>pair</b> (a,b) <b>bad.</b> Using the 2 -adic integers we obtain a characterization of all <b>bad</b> <b>pairs.</b> A positive odd integer u is universally bad if (ua,b) is <b>bad</b> for all <b>pairs</b> of positive odd integers a and b. De Bruijn showed that all positive integers of the form u= 2 k+ 1 are universally bad. We apply our characterization of <b>bad</b> <b>pairs</b> to give another proof of this result of de Bruijn, and to show that all integers of the form u=φpk(4) are universally bad, where p is prime and φn(x) is the nth cyclotomic polynomial. We consider {{a new class of}} integers we call de Bruijn universally bad integers and obtain a characterization of such positive integers. We apply this characterization to show that the universally bad integers u=φpk(4) are in fact de Bruijn universally bad for all primes p> 2. Furthermore, we show that the universally bad integers φ 2 k(4), and more generally, those of the form 4 k+ 1, are not de Bruijn universally bad...|$|R
30|$|As {{shown by}} Amig ó et al. [30], {{there are many}} ways to extrinsically {{evaluate}} clustering involving different quality measures, such as good and <b>bad</b> <b>pair</b> counting, purity, entropy measures, etc.|$|E
40|$|Let G be an {{undirected graph}} on n nodes, and let k be an integer that divides n. Ak-equi{{partition}} # of G is a partition of V (G) into k equal-sized pieces V 1, [...] ., V k. A pair V i, V j of distinct sets in # {{is called a}} <b>bad</b> <b>pair</b> if {{there is at least}} one edge v i [...] v j of E(G) such that v i # V i and v j # V j. The parameterized equipartition problem is: given G and k, find an optimal k-equipartition of G, i. e., one with the smallest possible number of bad pairs. More generally, a nontrivial equipartition of G is a k-equipartition, for some proper divisor k of n. The equipartition problem is: given G, find a nontrivial equipartition with the minimum number of bad pairs, where the minimum is taken over all divisors k of n and all k-equipartitions. We prove that there are relatively sparse graphs all of whose equipartitions have the maximum number of bad pairs (up to constant factors). We also prove that the parameterized and unparameterized versions of the equipartition proble [...] ...|$|E
40|$|Abstract—In this paper, we {{investigate}} {{the effect of}} the representation of safety specification on the complexity of adding masking fault tolerance to programs—where, in the presence of faults, the program 1) recovers to states from where it satisfies its (safety and liveness) specification and 2) preserves its safety specification during recovery. Specifically, we concentrate on two approaches for modeling the safety specifications: 1) the bad transition (BT) model, where safety is modeled as a set of bad transitions that should not be executed by the program, and 2) the <b>bad</b> <b>pair</b> (BP) model, where safety is modeled as a set of finite sequences consisting of at most two successive transitions. If the safety specification is specified in the BT model, then it is known that the complexity of automatic addition of masking fault tolerance to high atomicity programs—where processes can read/write all program variables in an atomic step — is polynomial in the state space of the program. However, for the case where one uses the BP model to specify safety specification, we show that the problem of adding masking fault tolerance to high atomicity programs is NPcomplete. Therefore, we argue that automated synthesis of fault-tolerant programs is likely to be more successful if one focuses on problems where safety can be represented in the BT model. Index Terms—Fault-tolerance, automatic addition of fault tolerance, safety specification, formal methods, program synthesis. ...|$|E
40|$|AbstractComplementary pairing by RecA was {{examined}} in vitro to investigate how homology is deciphered from non-homology. Somewhere {{in a window}} of 40 – 50 % sequence complementarity, RecA pairing begins to manifest the specificity of homology. Quantitation reveals a hierarchy among non-Watson-Crick mispairs: RecA reaction treats six out of 12 possible mispairs as good ones and three each of the remaining ones as moderate and <b>bad</b> <b>pairs.</b> The mispairs seem to function as independent pairing units free of sequence context effects. The overall strength of pairing is simply {{the sum of the}} constituent units. RecA mediated gradation of mispairs, free of sequence context effects, might offer a general thumb-rule for predicting the pairing strength of any alignment that carries multiple mispairs...|$|R
5000|$|Pavlok is a {{wearable}} device that uses operant conditioning through haptic feedback to modify behavior. Users {{are said to}} be able to break <b>bad</b> habits by <b>pairing</b> the behavior with up to 150 volts of [...] "zaptic feedback", and can establish new routines by pairing the behavior with vibration.|$|R
5|$|Steph is {{diagnosed}} with cervical cancer {{and does not}} tell Gilly, who later finds out from Cheryl. Gilly is angry at Steph for keeping this from him. Steph undergoes a hysterectomy to remove the cancer. However, doctors tell her and Gilly it failed. She is soon told her cancer is terminal. Gilly takes the news <b>bad.</b> The <b>pair</b> split up when Steph feels it is unfair on Gilly, but they get back together and start to plan their wedding. Gilly and Steph eventually get married beside the village river.|$|R
40|$|In this paper, we {{investigate}} {{the effect of}} the representation of safety specification on the complexity of adding masking fault-tolerance to programs – where, in the presence of faults the program (1) recovers to states from where it satisfies its (safety and liveness) specification, and (2) preserves its safety specification during recovery. Specifically, we concentrate on two approaches for modeling the safety specifications: (i) bad transition (BT) model where safety is modeled as a set of bad transitions that should not be executed by the program, and (ii) <b>bad</b> <b>pair</b> (BP) model where safety is modeled as a set of finite sequences consisting of at most two successive transitions. If the safety specification is specified in the BT model then it is known that the complexity of automatic addition of masking fault-tolerance to high atomicity programs – where processes can read/write all program variables in an atomic step – is polynomial in the state space of the program. However, for the case where one uses the BP model to specify safety specification, we show that the problem of adding masking fault-tolerance to high atomicity programs is NP-complete. Therefore, we argue that automated synthesis of fault-tolerant programs is likely to be more successful if one focuses on problems where safety can be represented in BT model. Keywords: Fault-tolerance, Automatic addition of fault-tolerance...|$|E
40|$|Suppose G and G ′ are graphs on {{the same}} vertex set V such that for each x ∈ V there is an {{isomorphism}} θx of G−x to G′−x. We prove in this paper {{that if there is}} a vertex x ∈ V and an automorphism σ of G − x such that θx agrees with σ on all except for at most three vertices of V −x, then G is isomorphic to G′. As a corollary we prove that if a graph G has a vertex which is contained in at most three bad pairs, then G is reconstructible. Here a pair of vertices x, y of a graph G is called a <b>bad</b> <b>pair</b> if there exist u, v ∈ V (G) such that {u, v} 6 = {x, y} and G − {x, y} is isomorphic to G − {u, v}. All graphs discussed here are finite simple graphs. The vertex set and edge set of a graph G are denoted by V (G) and E(G) respectively. If A is a subset of V (G), we use G|A and G−A to denote the subgraphs of G induced by A and V (G) −A respectively. When A = {x} is a singleton, we use G−x instead of G−{x}. For two subsets X, Y of V (G), we use eG(X, Y) to denote the number of edges joining a vertex of X to a vertex of Y. For brevity, we write eG(x,X) for eG({x}, X) and eG(X) for eG(X,X). The degree of x in G is denoted by dG(x). We shall use some notations defined in [4]. Two graphs G and H are hypomorphic if there exists a bijection f: V (G) → V (H) such that G − x i...|$|E
40|$|Consider a profinite group G, and a {{collection}} of continuous representations ρℓ: G → GLn(Qℓ), indexed by a set L of rational primes ℓ. Suppose that G is endowed with a dense subset of “Frobenius ” elements {Fα|α ∈ A}. The system {ρℓ} is called a compatible system of ℓ-adic representations if, for every α ∈ A, the characteristic polynomial of ρℓ(Fα) has coefficients in the field of rational numbers and does not depend on ℓ. In 6. 5, we will give a more precise and less restrictive definition which allows us to throw out some <b>bad</b> <b>pairs</b> (ℓ, α) in order to accomodate ramification. Our notion slightly generalizes Serre’s original definition [14]; to recover Serre’s definition, we take G to be the Galois group of a number field K and Fα to be Frobenius representatives for primes of K. Let Gℓ be the Zariski closure of ρℓ(G) in GLn,Qℓ. This is the algebraic monodromy group at ℓ. Our question is the following: How does Gℓ vary with ℓ? One hopes for some kind of “ℓ-independence. ” At best, there can exist a global algebraic group G ⊂ GLn,Q such that every Gℓ is conjugate to G ×Q Qℓ. Unfortunately, this does not always happen in the abstract setting in which we work, so we must settle for weaker ℓ-independence results. We first recall what is already known in this direction. The compatibility condition bears only on the semisimple part of the elements ρℓ(Fα), so we lose no information by assuming all ρℓ to be semisimpl...|$|R
50|$|He married Paola Biagi, an Italian national, in 1956 (they {{met with}} a heated {{discussion}} about if orange and pink were a good or <b>bad</b> colour <b>pair).</b> He then took up a scholarship to study at the Yale School of Art and Architecture at Yale University, under Alvin Eisenman, Norman Ives, Herbert Matter, Bradbury Thompson, Josef Albers and Paul Rand. He visited Robert Brownjohn, Ivan Chermayeff and Tom Geismar in New York, became friends with Bob Gill, and was commissioned by Leo Lionni to design a cover for Fortune magazine in 1958. After a visit to Venezuela, he returned to London in 1959, having worked briefly for Saul Bass in Los Angeles and Pirelli in Milan.|$|R
50|$|One of {{the most}} {{prevalent}} ways of assessing implicit racism is through response latency procedures, such as the implicit-association test (IAT). In an IAT measuring implicit racism, individuals will be shown images and asked to press the same key for {{an image of a}} black person and or a word that indicates something good, and another key for an image of a white person or something <b>bad.</b> These <b>pairs</b> will also be tested in reverse order (one key for a white person or something good, another for a black person or something bad). The greater the disparity in reaction times and accuracy between the different pair groups, the greater implicit racism is measured in that individual.|$|R
5000|$|In 2011, Douglas {{released}} three albums {{within the}} span of five months through Greenleaf Music. The albums were released only in digital format and contained approximately 30 to 50 minutes of music per album, referencing album lengths of the LP era. Released under the unifying label of the Greenleaf Portable Series, or GPS, the albums showcased ensembles that Douglas may only [...] "rarely get to play with" [...] in some cases. The first album, Rare Metals featured Douglas' Brass Ecstasy ensemble. The second album, Orange Afternoons included Ravi Coltrane on tenor sax, Vijay Iyer on piano, Linda Oh on bass, Marcus Gilmore on drums. The third, <b>Bad</b> Mango, <b>paired</b> Douglas with the innovative quartet So Percussion.|$|R
5000|$|Meanwhile, {{the deputy}} COS of CIA in Bangkok had called on McGehee (now {{back in the}} north) {{to report to the}} station. Also given a fictitious name, the deputy had {{acquired}} a bad reputation (bullying, manipulation, grudge holding). The COS and his deputy made a good cop, <b>bad</b> cop <b>pair.</b> As McGehee listened in the deputy's office, he eventually came to the point where, McGehee writes, he [...] "was tearing down my superiors in my presence and asking me to spy on them for him!" [...] Consequently, McGehee's ethics disappointed the ambitious deputy. McGehee figured he became the latest addition to the deputy's enemy list; he then thought that people like this deputy COS, who put his career above the mission, were [...] "aberrations" [...] among otherwise dedicated CIA agents. Rather McGehee continued to idealize CIA activities as [...] "somewhere between the Peace Corps and missionary work".|$|R
40|$|In this article, {{we present}} a novel idea for {{entanglement}} purification with joint measurements, the joint entanglement purification protocol(joint-EPP). In some quantum communication tasks using entangled pairs, one party holds the whole entangled pairs at the final stage, {{he or she is}} able to perform joint measurements on the pairs. In this situation the proposed joint-EPP can improve the entanglement purification by allowing a higher tolerated error rate, faster convergence which uses less steps to achieve a high fidelity, and higher production rate which produces more number of good entangled pairs from a given number of <b>bad</b> entangled <b>pairs.</b> We have established the general correspondence between linear classical codes and the joint-EPP. It has been shown that the joint-EPP can correct errors as long as the error threshod is no larger than 0. 5. The joint-EPP works even for fidelity less than 0. 5 {{as long as it is}} larger than 0. 25. We give several concrete examples, definitions and applications of the joint-EPP...|$|R
40|$|We {{document}} that cross-sectional FX correlation disparity is countercyclical, as exchange rate pairs with high average correlation become more correlated in <b>bad</b> times whereas <b>pairs</b> with low average correlation become less correlated. We show that currencies that perform badly (well) {{during periods of}} high cross-sectional disparity in conditional FX correlation yield high (low) average excess returns, suggesting that correlation risk is priced in currency markets. Furthermore, we find a negative cross-sectional relationship between average FX correlations and average FX correlation risk premia. Finally, we propose a no-arbitrage model that can match salient properties of FX correlations and correlation risk premia...|$|R
2500|$|News of the {{sighting}} {{was rushed}} to 11 Group and the Navy at Dover by [...] (One pilot then mentioned a big ship and a certain sighting was received as he was being debriefed.) By coincidence, two senior fighter pilots from RAF Kenley had decided to fly an intruder mission to the French coast at [...] while the other pilots were grounded due to the <b>bad</b> weather. The <b>pair</b> spotted two Messerschmitt Bf 109s (Bf 109) and attacked, then found themselves over a German flotilla of two big ships, a destroyer screen and an outer ring of E-boats. The Spitfires were dived on by about [...] fighters and escaped through anti-aircraft fire from the ships, strafed an E-boat and made off at wave-top height. After they landed at [...] the pilots reported that the German ships had been [...] off Le Touquet at [...] by [...] the alarm had been raised that the Brest Group was entering the Straits of Dover with air cover.|$|R
30|$|Recently, quality {{assessment}} in face images has renewed interest attributed to insights from the Good, Bad, and Ugly (GBU) dataset[79]. The challenging dataset used in Face Recognition Vendor Test (FRVT) 2006 [80] consists of 9, 307 frontal neutral expression face images taken in indoor or outdoor settings from 570 subjects. From this dataset, {{a subset of}} 2, 170 images from 437 subjects is chosen and split into three sub-partitions (Good, Bad and Ugly) such that the fusion {{of the top three}} algorithms from FRVT 2006 results in GAR of 0.98, 0.80, and 0.15 at an FAR of 0.001. Further, no image appears in more than one subset and the subjects in all three partitions are the same. This unique partitioning of data enables researchers to focus on the hard matching problems of face recognition within the database. Also, this dataset can be used to better understand and model the change in recognizability of a subject in different environmental conditions. Phillips et al.[7, 81] show that simple image quality metrics can be combined to predict face recognition performance. Using a greedy pruning approach, ranking is predicted from a quality oracle. Aggarwal et al.[82] show that good, <b>bad,</b> ugly <b>pairs</b> can be predicted by using partial least square regression between image-based features (sharpness, hue, and intensity) and geometric attributes of a face (obtained using active appearance modeling). Hua et al.[83] use modulation transformation function to compute the sharpness in face images. Their results also indicate that sharpness is an important factor to improve face recognition results.|$|R
5000|$|News of the {{sighting}} {{was rushed}} to 11 Group and the Navy at Dover by 11:05 a.m. (One pilot then mentioned a big ship and a certain sighting was received as he was being debriefed.) By coincidence, two senior fighter pilots from RAF Kenley had decided to fly an intruder mission to the French coast at 10:10 a.m., while the other pilots were grounded due to the <b>bad</b> weather. The <b>pair</b> spotted two Messerschmitt Bf 109s (Bf 109) and attacked, then found themselves over a German flotilla of two big ships, a destroyer screen and an outer ring of E-boats. The Spitfires were dived on by about 12 German fighters and escaped through anti-aircraft fire from the ships, strafed an E-boat and made off at wave-top height. After they landed at 11:09 a.m., the pilots reported that the German ships had been [...] off Le Touquet at 10:42 a.m. by 11:25 a.m., the alarm had been raised that the Brest Group was entering the Straits of Dover with air cover.|$|R
40|$|Challenge problem The Good, the Bad, and the Ugly Face Challenge Problem {{was created}} to {{encourage}} the development of algo-rithms that are robust to recognition across changes that occur in still frontal faces. The Good, the Bad, and the Ugly consists of three partitions. The Good partition contains pairs of images that are considered easy to recognize. The base verification rate (VR) is 0. 98 at a false accept rate (FAR) of 0. 001. The <b>Bad</b> partition con-tains <b>pairs</b> of images of average difficulty to recognize. For the Bad partition, the VR is 0. 80 at a FAR of 0. 001. The Ugly partition contains pairs of images considered difficult to recognize, with a VR of 0. 15 at a FAR of 0. 001. The base performance is from fusing the output {{of three of the}} top performers in the FRVT 2006. The design of the Good, the Bad, and the Ugly controls for posevariation, subject aging, and subject “recogniz-ability. ” Subject recognizability is controlled by having the same number of images of each subject in every partition. This implies that the differences in performance among the partitions are a result of how a face is presented in each image. Published by Elsevier B. V. 1...|$|R
40|$|CsEnVi Pairwise Parallel Corpora {{consist of}} Vietnamese-Czech {{parallel}} corpus and Vietnamese-English parallel corpus. The corpora were assembled {{from the following}} sources: - OPUS, the open parallel corpus is a growing multilingual corpus of translated open source documents. The majority of Vi-En and Vi-Cs bitexts are subtitles from movies and television series. The nature of the bitexts are paraphrasing of each other's meaning, rather than translations. - TED talks, {{a collection of short}} talks on various topics, given primarily in English, transcribed and with transcripts translated to other languages. In our corpus, we use 1198 talks which had English and Vietnamese transcripts available and 784 talks which had Czech and Vietnamese transcripts available in January 2015. The size of the original corpora collected from OPUS and TED talks is as follows: 	CS/VI 	EN/VI Sentence 	 1337199 / 1337199 	 2035624 / 2035624 Word 	 9128897 / 12073975 	 16638364 / 17565580 		 Unique word	 224416 / 68237 	 91905 / 78333 We improve the quality of the corpora in two steps: normalizing and filtering. In the normalizing step, the corpora are cleaned based on the general format of subtitles and transcripts. For instance, sequences of dots indicate explicit continuation of subtitles across multiple time frames. The sequences of dots are distributed differently in the source and the target side. Removing the sequence of dots, along with a number of other normalization rules, improves the quality of the alignment significantly. In the filtering step, we adapt the CzEng filtering tool [1] to filter out <b>bad</b> sentence <b>pairs.</b> The size of cleaned corpora as published is as follows: 	CS/VI 	EN/VI Sentence 	 1091058 / 1091058 	 1113177 / 1091058 Word 	 6718184 / 7646701 	 8518711 / 8140876 Unique word	 195446 / 59737 	 69513 / 58286 The corpora are used as training data in [2]. References: [1] Ondřej Bojar, Zdeněk Žabokrtský, et al. 2012. The Joy of Parallelism with CzEng 1. 0. Proceedings of LREC 2012. ELRA. Istanbul, Turkey. [2] Duc Tam Hoang and Ondřej Bojar, The Prague Bulletin of Mathematical Linguistics. Volume 104, Issue 1, Pages 75 – 86, ISSN 1804 - 0462. 9 / 201...|$|R
40|$|People dislike giving bad news, and one {{strategy}} {{they use to}} ease the process is to <b>pair</b> <b>bad</b> news with some good news, a phenomenon called blended news delivery. Often, blended news arrives from people in power positions such as physicians, managers, or teachers. But followers also find themselves needing to give bad news to those in higher power positions. Similarly, people can choose how they deliver bad news, such as in person or over email. The current study brings much needed empirical attention to this phenomenon and the way power imbalance and physical distance may influence blended news delivery. Participants completed the study alongside one confederate whom they believed would receive personality test results {{at the end of}} the session. Participants completed personality measures and then participated in an origami task in which they were randomly assigned to either a leader or follower role (the confederate played the other role). After the origami task, participants were randomly assigned to deliver the confederate's test results in person or through email. In person interactions were video-recorded. Participants then completed one final questionnaire about the experience. Trained research assistants provided ratings of the news-delivery videos and emails. Although power did not influence how people delivered blended news, physical distance affected the news people began and ended with, whether they sandwiched bad news, and the relative emphasis placed on bad news compared to good news. The way people delivered blended news also influenced ratings of warmth, social skills, directness and bluntness. These findings suggest a number of considerations and recommendations for people who deliver bad news...|$|R

