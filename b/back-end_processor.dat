6|9|Public
40|$|As {{the notion}} of {{ubiquitous}} computing becomes a reality, the keyboard and mouse paradigm become less satisfactory as an input modality. The ability to interpret gestures can open another dimension in the user interface technology. In this paper, we present a novel approach for dynamic hand gesture modeling using neural networks. The results show high accuracy in detecting single and multiple gestures, which makes this a promising approach for gesture recognition from continuous input with undetermined boundaries. This method is independent of the input device and can be applied as a general <b>back-end</b> <b>processor</b> for gesture recognition systems. ...|$|E
40|$|Ths paper {{presents}} a stmple approach for extendmg the relattonal system INGRES rate one supporting a semanttc data model It describe a DBMS conststmg of O) a user-friendly front-end, supportmg the GEM semanttc data model and query language under the UNIX' tme-sharmg system, and (u) a dedtcated <b>back-end</b> <b>processor</b> provtdmg efSctent support for database transacttons, concurrency control and recovery GEM extends the relattonal model {{to support the}} nottons of enttttes wtth surrogates, the relattonshtps of aggregabon and generahzatton, null values and set-valued attributes, and provtdes stmple extenstons of QUEL to handle these new constructs In thts proposed tmplementatton of GEM, the relabonal database processor IDM 500 by Bntton-Lee ts used as the back-end machme...|$|E
40|$|I have {{designed}} and am currently building {{a computer that}} is optimized for a microcoded interpreter for Scheme. The native language of this computer is SCode, a tree-structured, typed-pointer representation of Scheme. The memory system is built with high speed RAM and offers low latency as well as high throughput. Multiple execution units in the processor {{make it possible to}} finish most complex operations in less than one memory cycle, thus allowing efficient use of memory bandwidth. The processor provides hardware support for tagged data objects and runtime type checking. This computer is designed as a <b>back-end</b> <b>processor</b> to a Hewlett Packard workstation which will handle bootstrapping and I/O operations. I will discuss the motivation for such a machine, its architecture, why it is expected to interpret Scheme efficiently, and the computer aided design tools I have developed for building this computer...|$|E
50|$|Front-end {{processors}} have {{connections to}} various card associations and supply authorization and settlement {{services to the}} merchant banks’ merchants. <b>Back-end</b> <b>processors</b> accept settlements from front-end processors and, via The Federal Reserve Bank for example, move {{the money from the}} issuing bank to the merchant bank.|$|R
40|$|As <b>processor</b> <b>back-ends</b> {{get more}} aggressive, {{front-ends}} {{will have to}} scale as well. Although the <b>back-ends</b> of superscalar <b>processors</b> have continued to become more parallel, the front-ends remain sequential. This paper describes techniques for fetching and renaming multiple non-contiguous portions of the dynamic instruction stream in parallel using multiple fetch and rename units. It demonstrates that parallel front-ends are {{a viable alternative to}} high-performance sequential front-ends...|$|R
40|$|<b>Back-end</b> <b>processors</b> {{have been}} {{conventionally}} used for speeding up {{of only a}} specific set of compute intensive functions. Such co-processors are, generally, &quot;hardwired &quot; and cannot be used for a new function. In this paper, we discuss the design considerations and parameters of a general purpose reconfigurable co-processor. We also propose architecture of such a co-processor and discuss its implementation issues. The concept of a reconfigurable co-processor has become feasible because of the availability of static RAM based FPGAs. The key architectural features of our system are: scalable topology, shared memory space between the main processor and co-processor and efficient reconfigurability. A small prototype of the system has been implemented. We have demonstrated a two orders of speedup using our system over pure software solutions for a set of compute intensive applications. ...|$|R
40|$|In {{this paper}} {{we present a}} {{description}} of a new Web search engine model, namely, the compressed index-query (CIQ) Web search engine model, which incorporates two bit-level compression layers implemented at the <b>back-end</b> <b>processor</b> (server) side, one layer resides after the indexer acting as a second compression layer to generate a double compressed index (index compressor), and the second layer resides after the query parser for query compression (query compressor) to enable bit-level compressed index-query search. The data compression algorithm used in this model is the Hamming codesbased data compression (HCDC) algorithm, which is an asymmetric, lossless, bit-level algorithm permits CIQ search. The different components of the new Web model are implemented in a prototype CIQ test tool (CIQTT), which is used as a test bench to validate the accuracy and integrity of the retrieved data, and to evaluate the performance of new Web search engine model. The test results demonstrate that the new CIQ model reduces disk space requirements and searching time by more than 24 %, and attains a 100 % agreement when compared with an uncompressed model. Keywords Web search engine; indexes; query optimization; full-text compressed self-index; bit-level compression; HCDC algorithm. 1...|$|E
40|$|Includes bibliographical {{references}} (page 57) Throughout {{the history}} of Computer Science, {{one of the main}} objectives in the development of new systems and architectures has been to increase the systems performance. Towards this goal, this thesis proposes a design for a Multiple Processor I Shared Memory Controller for use in a real-time environment. The Shared Memory Controller (SMC) is a device that allows a number of Host computers access to a shared memory in a concurrent fashion. The SMC provides many built-in functions that would normally be performed in the Host computers, thus offloading much of the typical burdens of processing from them. The Multiple Processor Shared Memory Controller is designed as a <b>back-end</b> <b>processor</b> in a real-time data processing environment. The performance increase over typical single processor systems {{is due to the fact}} that this system is designed to process far more data in a similar time frame. The SMC can be programmed to suit the individual needs of the user. It consists of a number of microprocessors, called Processing Elements, connected together via a specially designed message bus. The SMC interfaces to multiple Host computers through a network, and sends information back and forth, as well as internally, through the use of message commands...|$|E
40|$|The Goddard Radio-Frequency Explorer (GREX) is {{the latest}} fast-sampling {{radiometer}} digital <b>back-end</b> <b>processor</b> {{that will be used}} for radiometry and radio-frequency interference (RFI) surveying at Goddard Space Flight Center. The system is compact and deployable, with a mass of about 40 kilograms. It is intended to be flown on aircraft. GREX is compatible with almost any aircraft, including P- 3, twin otter, C- 23, C- 130, G 3, and G 5 types. At a minimum, the system can function as a clone of the Soil Moisture Active Passive (SMAP) ground-based development unit [1], or can be a completely independent system that is interfaced to any radiometer, provided that frequency shifting to GREX's intermediate frequency is performed prior to sampling. If the radiometer RF is less than 200 MHz, then the band can be sampled and acquired directly by the system. A key feature of GREX is its ability to simultaneously sample two polarization channels simultaneously at up to 400 MSPS, 14 -bit resolution each. The sampled signals can be recorded continuously to a 23 TB solid-state RAID storage array. Data captures can be analyzed offline using the supercomputing facilities at Goddard Space Flight Center. In addition, various Field Programmable Gate Array (FPGA) - amenable radiometer signal processing and RFI detection algorithms can be implemented directly on the GREX system because it includes a high-capacity Xilinx Virtex- 5 FPGA prototyping system that is user customizable...|$|E
40|$|The {{main idea}} behind the {{intelligent}} networks (IN) concept is to place the intelligence/service logic in the dedicated server and to meet various service requirements of subscribers {{and the development of}} new services in time. The (N + 1) –type architecture of the IN service system consists of front-end <b>processors</b> (FEP) and <b>back-end</b> <b>processors</b> (BEP), which are currently in service by a telecommu-nications company in Korea. The main characteristic of this architecture is a separation between the data plane and control plane of the network, such that the load-balancing table is used to distribute the traffic load among the processors, FEP and BEP, taking into account services. Since the values used in the load-balancing table affect the IN system performance significantly, this paper simulates the IN system and evaluates system performance depending on the values used in the table...|$|R
40|$|It was not {{too long}} ago that {{designers}} were looking to dedicated hardware to solve the "I/O problem". However, despite the claimed improvements of such <b>back-end</b> <b>processors,</b> with few exceptions, they never reached commercial viability. With today's exponential growth in data, there is growing concern that we are once again reaching a "memory wall" and there is talk of intelligent processing by I/O. While the basic I/O performance characteristics are governed by physics, we can adjust how we view, store, and process data so as to be more in consonance with the I/O devices themselves. Key factors are data granularity and achieving synchronous operation. This paper examines the performance issues of non-numeric applications that are primarily I/O bound. By using a two dimensional data model, logical topology of data is physically preserved on disk. This enables the disk to operate more in a synchronous fashion with granular data access. Using several benchmarks, we contrast the performance of the 2 D model with a lineal model and find that improvements are on the order of 10 - 100 X and roughly in proportion to the granularity of the data. By using intelligent controllers, each controlling a set of spindles, a high degree of parallelism can be achieved without the overhead usually associated with parallel architectures...|$|R
5000|$|EXCP's {{front-end}} {{is always}} in TCB mode, as EXCP is a Type 1 SVC. In MVS/370 and subsequent instances of the OS, the EXCP processor invokes STARTIO to schedule execution of the channel program. Although the EXCP <b>processor's</b> <b>back-end</b> {{is always in}} SRB mode, the back-end contains emulation code which allows the appendages developed for earlier, pre-MVS instances of the OS, specifically for EXCP, to function largely as before and thereby {{to appear to be}} in TCB mode, for which these appendages were originally designed. This distinction can complicate conversion of certain [...] "roll-your-own" [...] access methods and applications to MVS.|$|R
40|$|Narrow {{values that}} can be {{represented}} by less number of bits than the full machine width occur very frequently in programs. On the other hand, clustering mechanisms enable cost- and performance-effective scaling of <b>processor</b> <b>back-end</b> features. Those attributes can be combined synergistically to design special clusters operating on narrow values (a. k. a. Helper Cluster), potentially providing performance benefits. We complement a 32 -bit monolithic processor with a low-complexity 8 -bit Helper Cluster. Then, in our main focus, we propose various ideas to select suitable instructions to execute in the data-width based clusters. We add data-width information as another instruction steering decision metric and introduce new data-widt...|$|R
40|$|While {{offering}} unique {{performance and}} energy saving advantages, {{the use of}} field-programmable gate ar-rays (FPGAs) for database acceleration has demanded major concessions from system designers. Either the programmable chips {{have been used for}} very basic application tasks (such as implementing a rigid class of selection predicates), or their circuit definition had to be completely re-compiled at runtime—a very CPU-intensive and time-consuming effort. This work eliminates the need for such concessions. As part of our XLynx implementation—an FPGA-based XML filter—we present skeleton automata, which is a design principle for data-intensive hardware circuits that offers high expressiveness and quick re-configuration at the same time. Skeleton automata provide a generic implementation for a class of finite-state automata. They can be parameterized to any particular automaton instance in a matter of micro-seconds or less (as opposed to minutes or hours for complete re-compilation). We showcase skeleton automata based on XML projection [Marian and Siméon 2003], a filtering technique that illustrates the feasibility of our strategy for a real-world and challenging task. By performing XML projection in hardware and filtering data in the network, we report on performance improvements of several factors while remaining non-intrusive to the <b>back-end</b> XML <b>processor</b> (we evaluate XLynx using the Saxon engine) ...|$|R
40|$|We {{introduce}} asymmetric frequency clustering (AFC), a micro-architectural {{technique that}} reduces the dynamic power dissipated by a <b>processor's</b> <b>back-end</b> while maintaining high performance. We present a dual-cluster, dual-frequency machine comprising a performance oriented cluster and a power-aware one. The power-aware cluster operates at half {{the frequency of the}} performance oriented cluster and uses a lower voltage supply. We show that this organization significantly reduces back-end power dissipation by executing non-performance-critical instructions in the power-aware cluster. AFC localizes the two frequency/voltage domains. Consequently, it mitigates many of the complexities associated with maintaining multiple supply voltage and frequency domains on the same chip. Key to the success of this technique are methods that assign as many instructions as possible to the slower/ lower power cluster without impacting overall performance. We evaluate our techniques using a subset of SPEC 2000 and SPEC 95. AFC provides a 16 % back-end power reduction with 1. 5 % performance loss compared to a conventional, dual-clustered processor where each cluster has schedulers of the same width and length...|$|R

