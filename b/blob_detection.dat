135|11|Public
25|$|Examples of {{applications}} include <b>blob</b> <b>detection,</b> corner detection, ridge detection, and object recognition via the scale-invariant feature transform.|$|E
2500|$|In practice, the affine shape {{adaptation}} process {{described here}} is often combined with interest point detection automatic scale selection {{as described in}} the articles on <b>blob</b> <b>detection</b> and corner detection, to obtain interest points that are invariant to the full affine group, including scale changes. Besides the commonly used multi-scale Harris operator, this affine shape adaptation can also be applied to other types of interest point operators such as the Laplacian/Difference of Gaussian blob operator and the determinant of the Hessian [...] (Lindeberg 2008). Affine shape adaptation can also be used for affine invariant texture recognition and affine invariant texture segmentation.|$|E
5000|$|... #Subtitle level 3: Lindeberg's watershed-based grey-level <b>blob</b> <b>detection</b> {{algorithm}} ...|$|E
40|$|This paper {{presented}} an efficient and reliable smoke detection algorithm {{on the video}} sequences. The key components developed in this algorithm are slowly moving <b>blobs</b> <b>detection,</b> classification of the blobs obtained and smoke regions tracking. We use preprocessing, slowly moving areas and pixels segmentation in a current input frame based on adaptive background subtraction algorithm, merge of the slowly moving areas and pixels into blobs at a stage slowly moving <b>blobs</b> <b>detection.</b> Calculation of Weber contrast is applied to classification and the primary direction of smoke propagation is considered. On a tracking step we trace texture and color smoke features using Cam Shift algorithm. The performed experiments have shown that our smoke detector quickly and reliable finds out a smoke on a complex dynamic scene. Experimental results are presented. Представлен эффективный и надежный алгоритм обнаружения дыма на видеопоследовательности. Основные компоненты алгоритма - обнаружение движущихся объектов, их классификация и отслеживание очага задымления...|$|R
40|$|The {{automatic}} detection of meaningful phases in a soccer game {{depends on the}} accurate localization of players and the ball at each moment. However, the automatic analysis of soccer sequences is a challenging task due {{to the presence of}} fast moving multiple objects. For this purpose, we present a multi-camera analysis system that yields the position of the ball and players on a common ground plane. The detection in each camera is based on a code-book algorithm and different features are used to classify the detected <b>blobs.</b> The <b>detection</b> results of each camera are transformed using homography to a virtual top-view of the playing field. Within this virtual top-view we merge trajectory information of the different cameras allowing to refine the found positions. In this paper, we evaluate the system on a public SOCCER dataset and end with a discussion of possible improvements of the dataset...|$|R
5000|$|The infinitesimal {{generator}} (and hence characteristic operator) of a Brownian motion on Rn {{is easily}} calculated to be ½Δ, where Δ denotes the Laplace operator. In image processing and computer vision, the Laplacian operator {{has been used}} for various tasks such as <b>blob</b> and edge <b>detection.</b> This observation is useful in defining Brownian motion on an m-dimensional Riemannian manifold (M, g): a Brownian motion on M is defined to be a diffusion on M whose characteristic operator [...] in local coordinates xi, 1 ≤ i ≤ m, is given by ½ΔLB, where ΔLB is the Laplace-Beltrami operator given in local coordinates by ...|$|R
50|$|Blob {{extraction}} {{is related}} to but distinct from <b>blob</b> <b>detection.</b>|$|E
50|$|Treatment of the {{difference}} of Gaussians approach in <b>blob</b> <b>detection.</b>|$|E
5000|$|Blobs: Blobs {{represent}} {{regions of}} images, {{which can be}} detected using <b>blob</b> <b>detection</b> method.|$|E
40|$|AbstractThe {{masking effect}} of a Gaussian <b>blob</b> on <b>detection</b> of a Gaussian target was {{measured}} {{as a function of}} the position, disparity, width and polarity of the mask. The data reveal a large degree of disparity-specific masking that cannot be explained by the masking of its monocular constituents. At 5 ° eccentricity, the masking range extends about ± 1 ° around the lines of sight of the two eyes and 1 – 3 ° in disparity, depending on the size of the test stimuli. The masking effects can be modeled as having three additive components, one that has a fixed disparity range and is polarity independent, one with a center/surround form keyed to both the disparity and the polarity of the mask, and one that derives from the monocular masking in each eye. Thus, the profound disparity interaction behavior is not limited to the simple monocular masking properties of the stimuli but reveals extensive connectivity across the disparity domain. Future models of disparity encoding will need to take these properties into account...|$|R
40|$|Abstract—In this paper, {{we propose}} an {{enhanced}} method for detecting light blobs (LBs) for intelligent headlight control (IHC). The main {{function of the}} IHC system is to automatically convert high-beam headlights to low beam when vehicles {{are found in the}} vicinity. Thus, to implement the IHC, it is necessary to detect preceding or oncoming vehicles. Generally, this process of detecting vehicles is done by detecting LBs in the images. Previous works regarding LB detection can largely be categorized into two approaches by the image type they use: low-exposure (LE) images or autoexposure (AE) images. While they each have their own strengths and weaknesses, the proposed method combines them by integrating the use of the partial region of the AE image confined by the lane detection information and the LE image. Consequently, the proposed method detects headlights at various distances and taillights at close distances using LE images while handling taillights at distant locations by exploiting the confined AE images. This approach enhances the performance of detecting the distant LBs while maintaining low false detections. Index Terms—Intelligent headlight control (IHC), lane <b>detection,</b> light <b>blob</b> (LB) <b>detection,</b> low-exposure (LE) image, vanishing-point estimation. I...|$|R
40|$|DE 10351925 A UPAB: 20050720 NOVELTY - A surface error {{detection}} unit processes {{an image of}} the surface to detect pixels outside a set intensity deviation from a set threshold and group clusters of candidate pixels as blobs for examination to detect contrast edges for comparison with reference edges to determine possible errors. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for procedures used by the unit. USE - Surface {{error detection}} unit for inspection of complex metal castings used for cars, sanitary fittings and similar uses. ADVANTAGE - The process of selecting candidate pixels and grouping them into <b>blobs</b> allows rapid <b>detection</b> of contours and is suitable for automatic inspection use. Avoids producing many artefacts in areas of average illumination where characteristics are not expected...|$|R
5000|$|... #Caption: Showing Rana <b>blob</b> <b>detection.</b> The {{extent of}} the blob (a moving bee) is shown by the {{bounding}} rectangle ...|$|E
50|$|In {{computer}} vision, <b>blob</b> <b>detection</b> {{methods are}} aimed at detecting regions in a digital image that differ in properties, such as brightness or color, compared to surrounding regions. Informally, a blob is a region of an image in which some properties are constant or approximately constant; all the points in a blob can be considered in some sense {{to be similar to}} each other. The most common method for <b>blob</b> <b>detection</b> is convolution.|$|E
5000|$|As {{discussed}} in Mikolajczyk et al.(2005), by choosing points that maximize the determinant of the Hessian, this measure penalizes longer structures that have small second derivatives (signal changes) {{in a single}} direction. [...] This type of measure {{is very similar to}} the measures used in the <b>blob</b> <b>detection</b> schemes proposed by Lindeberg (1998), where either the Laplacian or the determinant of the Hessian were used in <b>blob</b> <b>detection</b> methods with automatic scale selection.|$|E
40|$|This paper {{presents}} a method based on skin colormodel face detection and human body proportion constraints {{to estimate the}} number and position of people entering the monitored scene as a compact group. This helps to split the group into individual persons and solve a common lack in traditional background subtraction based detection and tracking methods: despite common systems, this algorithm can recognize the number and position {{of the people in}} a single change <b>detection</b> <b>blob.</b> The hypotheses are: standing subjects, face visibility {{from the point of view}} of the camera, a calibrated map to estimate objects’ distance from the sensor and to estimate expected people’s height on the image plane. These estimations allow dynamic thresholding of several shape parameters and lead to very interesting results. 1...|$|R
40|$|The thesis {{consists}} of three parts. Theoretical description of digital image processing, optical character recognition and design of system for car licence plate recognition (LPR) in image or video sequence. Theoretical part describes image representation, smoothing, methods used for blob segmentation and proposed are two methods for optical character recognition (OCR). Concern of practical part is to find solution and design procedure for LPR system included OCR. The design contain image pre-processing, <b>blob</b> segmentation, object <b>detection</b> based on its properties and OCR. Proposed solution use grayscale trasformation, histogram processing, thresholding, connected component,region recognition based on its patern and properties. Implemented is also optical recognition method of licence plate where acquired values are compared with database used to manage entry of vehicles into object...|$|R
50|$|The Laplacian {{occurs in}} {{differential}} equations that describe many physical phenomena, such as electric and gravitational potentials, the diffusion equation for heat and fluid flow, wave propagation, and quantum mechanics. The Laplacian represents the flux {{density of the}} gradient flow of a function. For instance, the net rate at which a chemical dissolved in a fluid moves toward or away from some point {{is proportional to the}} Laplacian of the chemical concentration at that point; expressed symbolically, the resulting equation is the diffusion equation. For these reasons, it is extensively used in the sciences for modelling all kinds of physical phenomena. The Laplacian is the simplest elliptic operator, and {{is at the core of}} Hodge theory as well as the results of de Rham cohomology. In image processing and computer vision, the Laplacian operator has been used for various tasks such as <b>blob</b> and edge <b>detection.</b>|$|R
50|$|Differences of Gaussians {{have also}} been used for <b>blob</b> <b>detection</b> in the scale-invariant feature transform. In fact, the DoG as the {{difference}} of two Multivariate normal distribution has always a total null sum and convolving it with a uniform signal generates no response. It approximates well a second derivate of Gaussian (Laplacian of Gaussian) with K~1.6 and the receptive fields of ganglion cells in the retina with K~5. It may easily be used in recursive schemes and is used as an operator in real-time algorithms for <b>blob</b> <b>detection</b> and automatic scale selection.|$|E
5000|$|Note {{that this}} notion of blob {{provides}} a concise and mathematically precise operational definition {{of the notion of}} [...] "blob", which directly leads to an efficient and robust algorithm for <b>blob</b> <b>detection.</b> Some basic properties of blobs defined from scale-space maxima of the normalized Laplacian operator are that the responses are covariant with translations, rotations and rescalings in the image domain. Thus, if a scale-space maximum is assumed at a point [...] then under a rescaling of the image by a scale factor , there will be a scale-space maximum at [...] in the rescaled image (Lindeberg 1998). This in practice highly useful property implies that besides the specific topic of Laplacian <b>blob</b> <b>detection,</b> local maxima/minima of the scale-normalized Laplacian are also used for scale selection in other contexts, such as in corner detection, scale-adaptive feature tracking (Bretzner and Lindeberg 1998), in the scale-invariant feature transform (Lowe 2004) as well as other image descriptors for image matching and object recognition.|$|E
50|$|In {{computer}} vision, maximally stable extremal regions (MSER) {{are used}} {{as a method of}} <b>blob</b> <b>detection</b> in images. This technique was proposed by Matas et al. to find correspondences between image elements from two images with different viewpoints. This method of extracting a comprehensive number of corresponding image elements contributes to the wide-baseline matching, and it has led to better stereo matching and object recognition algorithms.|$|E
40|$|Amblyopia is a {{developmental}} abnormality of visual cortex. Although amblyopes experience perceptual deficits in spatial vision tasks, {{they have less}} temporal sensitivity loss. We investigated whether their temporal synchrony sensitivity is impaired. In experiment 1, four Gaussian blobs, located at the top, bottom, left, and right of a presentation screen, were flickering in 3 Hz {{and one of them}} was flickering in out-of-phase fashion in time. Participants needed to tell which blob was different from the other three and contrast threshold of the blobs was measured to determine the synchrony detection threshold. We found the thresholds were not correlated with the contrast thresholds for detecting the flickering <b>blobs,</b> suggesting synchrony <b>detection</b> and temporal detection threshold are processed by different mechanisms. In experiment 2, synchrony thresholds were measured as participants' ability to tell if one of the four high contrast Gaussian blobs was flickering asynchronously in time. Three temporal frequencies (1, 2, and 3 Hz) and two element separations (1. 25 and 5 deg) were compared. We found that the amblyopic group exhibited a deficit only for the 1. 25 deg element separation in amblyopic eye but was normal for the other configurations compared to controlled participants. It suggests amblyopes have deficits in temporal processing but only for foveal vision. We also found the sensitivity for the non-strabismic anismetropia group is reduced for all three temporal frequencies whereas for the strabismic anisometropia group it was reduced at 3 Hz only, suggesting the impairment in temporal synchrony might be different for different types of amblyopia...|$|R
40|$|This report {{documents}} the modifications {{made to the}} frame processing module of the NUbot vision system for improvement in robot soccer competition {{and particularly in the}} variable lighting challenge. The frame processing module involves the classification of images with respect to a look up table (LUT), a new system of secondary colour classification for blue robots that uses edge <b>detection,</b> <b>blob</b> formation and blob filtering. Soft colour classification was used as the basis of improvement in frame processing. This involved several specific modifications to the previous system. Additional soft colours were integrated into colour classification to assist the differentiation between field objects of similar shades. A secondary classification method that uses edge detection was implemented to account for the unique edge-colour characteristics of blue uniformed robots. This method allows the classification of blue robots; this has not been achieved effectively using standard classification methods. Modifications to the blob formation method were required to account for the soft colour classification system. The modified blobs were then filtered to extract useful data, which is interpreted by object recognition. The LUT system used in the classification of images was modified to increase accuracy and robustness of object data. The modification involved the implementation of a 7 * 7 * 7 bit LUT system. Another improvement of the system involved the modification and implementation of a Support Vector Machine (SVM) to partially automate and hence optimise LUT generation. The modifications to vision have improved accuracy in object data and robustness in colour classification. Additionally, these modifications are effective under wider range of lighting conditions than previously. i...|$|R
5000|$|This {{algorithm}} {{with its}} applications in computer vision {{is described in}} more detail in Lindeberg's thesis [...] as well as the monograph on scale-space theory [...] partially basedon that work. Earlier presentations of this algorithm can also be found in. More detailed treatments of applications of grey-level <b>blob</b> <b>detection</b> and the scale-space primal sketch to computer vision and medical image analysis are given in.|$|E
50|$|Historically, {{the notion}} of {{interest}} points {{goes back to the}} earlier notion of corner detection, where corner features were in early work detected with the primary goal of obtaining robust, stable and well-defined image features for object tracking and recognition of three-dimensional CAD-like objects from two-dimensional images. In practice, however, most corner detectors are sensitive not specifically to corners, but to local image regions which have a high degree of variation in all directions. The use of interest points also goes back to {{the notion of}} regions of interest, which have been used to signal the presence of objects, often formulated in terms of the output of a <b>blob</b> <b>detection</b> step. While blob detectors have not always been included within the class of interest point operators, there is no rigorous reason for excluding blob descriptors from this class. For the most common types of blob detectors (see the article on <b>blob</b> <b>detection),</b> each blob descriptor has a well-defined point, which may correspond to a local maximum, a local maximum in the operator response or a centre of gravity of a non-infinitesimal region. In all other respects, the blob descriptors also satisfy the criteria of an interest point defined above.|$|E
5000|$|Compared {{to other}} {{watershed}} methods, the flooding in this algorithm stops once the intensity level falls below the intensity {{value of the}} so-called delimiting saddle point associated with the local maximum. However, it is rather straightforward to extend this approach to other types of watershed constructions. For example, by proceeding beyond the first delimiting saddle point a [...] "grey-level blob tree" [...] can be constructed. Moreover, the grey-level <b>blob</b> <b>detection</b> method was embedded in a scale space representation and performed {{at all levels of}} scale, resulting in a representation called the scale-space primal sketch.|$|E
5000|$|In {{computer}} vision and biological vision, scaling transformations arise {{because of the}} perspective image mapping and because of objects having different physical size in the world. In these areas, scale invariance refers to local image descriptors or visual representations of the image data that remain invariant when the local scale in the image domain is changed. [...] Detecting local maxima over scales of normalized derivative responses provides a general framework for obtaining scale invariance from image data.Examples of applications include <b>blob</b> <b>detection,</b> corner detection, ridge detection, and object recognition via the scale-invariant feature transform.|$|E
50|$|Following this {{approach}} of gamma-normalized derivatives, {{it can be}} shown that different types of scale adaptive and scale invariant feature detectors can be expressed for tasks such as <b>blob</b> <b>detection,</b> corner detection, ridge detection and edge detection (see the specific articles on these topics for in-depth descriptions of how these scale-invariant feature detectors are formulated).Furthermore, the scale levels obtained from automatic scale selection {{can be used for}} determining regions of interest for subsequent affine shape adaptation to obtain affine invariant interest points or for determining scale levels for computing associated image descriptors, such as locally scale adapted N-jets.|$|E
50|$|In {{terms of}} applications, {{the use of}} corner {{detection}} and <b>blob</b> <b>detection</b> are also overlapping. Today, a main application of interest points is to signal points/regions in the image domain that are likely candidates to be useful for image matching and view-based object recognition. For this purpose, several types of corner detectors and blob detectors have been demonstrated to be highly useful in practical applications (see respective articles for references). Blob detectors and corner detectors have also been used as primitives for texture recognition, texture analysis and for constructing 3D models from multiple views of textured objects.|$|E
50|$|In practice, the affine shape {{adaptation}} process {{described here}} is often combined with interest point detection automatic scale selection {{as described in}} the articles on <b>blob</b> <b>detection</b> and corner detection, to obtain interest points that are invariant to the full affine group, including scale changes. Besides the commonly used multi-scale Harris operator, this affine shape adaptation can also be applied to other types of interest point operators such as the Laplacian/Difference of Gaussian blob operator and the determinant of the Hessian (Lindeberg 2008). Affine shape adaptation can also be used for affine invariant texture recognition and affine invariant texture segmentation.|$|E
50|$|Once {{features}} {{have been}} detected, a local image patch around the feature can be extracted. This extraction may involve quite considerable amounts of image processing. The result {{is known as}} a feature descriptor or feature vector. Among the approaches that are used to feature description, one can mention N-jets and local histograms (see scale-invariant feature transform for one example of a local histogram descriptor). In addition to such attribute information, the feature detection step by itself may also provide complementary attributes, such as the edge orientation and gradient magnitude in edge detection and the polarity and the strength of the blob in <b>blob</b> <b>detection.</b>|$|E
50|$|This keypoint {{detection}} step is {{a variation}} {{of one of the}} <b>blob</b> <b>detection</b> methods developedby Lindeberg by detecting scale-space extrema of the scale normalized Laplacian, that is detecting points that are local extrema with respect to both space and scale, in the discrete case by comparisons with the nearest 26 neighbours in a discretized scale-space volume. The difference of Gaussians operator can be seen as an approximation to the Laplacian, with the implicit normalization in the pyramid also constituting a discrete approximation of the scale-normalized Laplacian.Another real-time implementation of scale-space extrema of the Laplacian operator has been presented by Lindeberg and Bretzner based on a hybrid pyramid representation, which was used for human-computer interaction by real-time gesture recognition in Bretzner et al. (2002).|$|E
50|$|These {{detectors}} {{are more}} completely described in <b>blob</b> <b>detection.</b> The scale-normalized Laplacian of the Gaussian and difference-of-Gaussian features (Lindeberg 1994, 1998; Lowe 2004) {{do not necessarily}} make highly selective features, since these operators may also lead to responses near edges. To improve the corner detection ability of the differences of Gaussians detector, the feature detector used in the SIFT system therefore uses an additional post-processing stage, where the eigenvalues of the Hessian of the image at the detection scale are examined {{in a similar way}} as in the Harris operator. If the ratio of the eigenvalues is too high, then the local image is regarded as too edge-like, so the feature is rejected. Also Lindeberg's Laplacian of the Gaussian feature detector can be defined to comprise complementary thresholding on a complementary differential invariant to suppress responses near edges.|$|E
50|$|Usually {{those methods}} consist of two parts. The first stage is to detect {{interest}} points, fiducial markers or optical {{flow in the}} camera images. This step can use feature detection methods like corner detection, <b>blob</b> <b>detection,</b> edge detection or thresholding and/or other image processing methods. The second stage restores a real world coordinate system from the data obtained in the first stage. Some methods assume objects with known geometry (or fiducial markers) {{are present in the}} scene. In some of those cases the scene 3D structure should be precalculated beforehand. If part of the scene is unknown simultaneous localization and mapping (SLAM) can map relative positions. If no information about scene geometry is available, structure from motion methods like bundle adjustment are used. Mathematical methods used in the second stage include projective (epipolar) geometry, geometric algebra, rotation representation with exponential map, kalman and particle filters, nonlinear optimization, robust statistics.|$|E
5000|$|There {{are several}} motivations for {{studying}} and developing blob detectors. One main reason {{is to provide}} complementary information about regions, which is not obtained from edge detectors or corner detectors. In early work in the area, <b>blob</b> <b>detection</b> was used to obtain regions of interest for further processing. These regions could signal the presence of objects or parts of objects in the image domain with application to object recognition and/or object tracking. In other domains, such as histogram analysis, blob descriptors {{can also be used}} for peak detection with application to segmentation. Another common use of blob descriptors is as main primitives for [...] analysis and texture recognition. In more recent work, blob descriptors have found increasingly popular use as interest points for wide baseline stereo matching and to signal the presence of informative image features for appearance-based object recognition based on local image statistics. There is also the related notion of ridge detection to signal the presence of elongated objects.|$|E
40|$|International audienceIn this letter, {{we propose}} a novel {{approach}} to <b>blob</b> <b>detection</b> based on wavelet transform modulus maxima. We use maxima lines in scale-space {{to build a new}} blob detector. The algorithm we propose enables automatic <b>blob</b> <b>detection</b> and blob size determination. The robustness to noise of the blob detector we propose is also show...|$|E
