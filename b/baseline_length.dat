379|241|Public
25|$|In 1922, the U.S. Coast and Geodetic Survey began {{two years}} of {{painstaking}} measurement of the baseline using the recently available invar tapes. With the <b>baseline</b> <b>length</b> established in 1924, measurements were carried {{out over the next}} two years to obtain the published value of 299,796±4km/s.|$|E
50|$|Originally it {{was thought}} {{necessary}} to make measurements at essentially every <b>baseline</b> <b>length</b> and orientation out to some maximum: such a fully sampled Fourier transform formally contains the information exactly equivalent to the image from a conventional telescope with an aperture diameter equal to the maximum baseline, hence the name aperture synthesis.|$|E
50|$|The Decca Navigator System {{consisted}} {{of a number of}} land-based radio beacons organised into chains. Each chain {{consisted of}} a master station and three (occasionally two) secondary stations, termed Red, Green and Purple. Ideally, the secondaries would be positioned at the vertices of an equilateral triangle with the master at the centre. The <b>baseline</b> <b>length,</b> that is, the master-secondary distance, was typically 60-120 nmi km.|$|E
40|$|Global Positioning System, GPS, {{used to make}} global {{geodetic}} measurements without use of fiducial site coordinates. <b>Baseline</b> <b>lengths</b> and geocentric radii {{for each}} site determined without having to fix any site coordinates. Given n globally distributed sites, n <b>baseline</b> <b>lengths</b> and n geocentric radii form polyhedron with each site at vertex and with geocenter at intersection of all radii. Geodetic information derived from structure of polyhedron and its change with time. Approach applied to any global geodetic technique...|$|R
40|$|Daily {{measurements}} {{by using}} GPS {{had been carried}} out at Kyoto, Kochi, Aso and Tottori sites in Southwest Japan from September 1990 to September 1991. The long term repeatability of the <b>baseline</b> <b>lengths</b> determined was 0. 26 ppm, which was comparable to the short term repeatability of them on even as long baseline as about 200 km. The <b>baseline</b> <b>lengths</b> showed annual changes, amplitude of which were about 1 ppm. It seems that such changes were caused by insufficient consideration of tropospheric delay in computation of baseline vector...|$|R
40|$|The {{technique}} of range differencing with Lageos ranges to obtain more accurate estimates of <b>baseline</b> <b>lengths</b> and polar motion variation was studied. Differencing quasi simultaneous range observations eliminate {{a great deal}} of orbital biases. Progress is reported on the definition and maintenance of a conventional terrestrial reference system...|$|R
5000|$|Strain means Deformation, and {{is defined}} as {{relative}} change in length. The Lagrangian formula εL = (L-L0)/L0 = ΔL/L0, where L0 is <b>baseline</b> <b>length</b> and L is the resulting length, defines strain {{in relation to the}} original length as a dimensionless measure, where shortening will be negative, and lengthening will be positive. It is usually expressed in percent. An alternative definition, Eulerian strain defines the strain in relation to the instantaneous length: εE = ΔL/L. For a change over time, the Lagrangian strain will be: εL = Σ ΔL/L0, and Eulerian Strain εE = Σ (ΔL/L). The term was first used by Mirsky and Parmley in describing regional differences in deformation between normal and ischemic myocardium ...|$|E
5000|$|Errors {{associated}} with the stick method and the clinometer and tape method: Aside from the obvious errors {{associated with}} bad measurements of distances or misreading the angles with the clinometer, there are several less apparent sources of error that can compromise {{the accuracy of the}} tree height calculations. With the stick method if the stick is not held vertically, the similar triangle will be malformed. This potential error can be offset by fastening a string with a small, suspended weight {{to the top of the}} stick so that the stick can be aligned with the weighted string to assure it is being held vertically. A more pernicious error occurs in both methods where 1) the treetop is offset from the base of the tree, or 2) where the top of the tree has been misidentified. Except for young, plantation-grown conifers, the top of the tree is rarely directly over the base; therefore a right triangle used as the basis for the height calculation isn’t truly being formed. An analysis of data collected by the Native Tree Society (NTS), of over 1800 mature trees found, on average, the top of the tree was offset from the perspective of the surveyor by a distance of 8.3 feet (2.5 m), and therefore was offset from the base of the tree by around 13 feet (4 m). Conifers tended to have offsets less than that average and large, broad canopied hardwoods tended to have higher offsets. The top of the tree therefore has a different <b>baseline</b> <b>length</b> than the bottom of the tree resulting in height errors: ...|$|E
5000|$|Shape {{analysis}} {{begins by}} removing the information that is not about shape. By definition, shape is not altered by translation, scaling or rotation. [...] Thus, to compare shapes, the non-shape information {{is removed from the}} coordinates of landmarks. There is {{more than one way to}} do these three operations. One method is to fix the coordinates of two points to (0,0) and (0,1), which are the two ends of a baseline. In one step, the shapes are translated to the same position (the same two coordinates are fixed to those values), the shapes are scaled (to unit <b>baseline</b> <b>length)</b> and the shapes are rotated. [...] An alternative, and preferred method, is Procrustes superimposition. This method translates the centroid of the shapes to (0,0); the x coordinate of the centroid is the average of the x coordinates of the landmarks, and the y coordinate of the centroid is the average of the y-coordinates. Shapes are scaled to unit centroid size, which is the square root of the summed squared distances of each landmark to the centroid. The configuration is rotated to minimize the deviation between it and a reference, typically the mean shape. In the case of semi-landmarks, variation in position along the curve is also removed. Because shape space is curved, analyses are done by projecting shapes onto a space tangent to shape space. Within the tangent space, conventional multivariate statistical methods such as multivariate analysis of variance and multivariate regression, can be used to test statistical hypotheses about shape.|$|E
50|$|In 1947, {{white light}} {{interference}} based measurement system {{was taken to}} use. It was developed by Yrjö Väisälä. Before that baseline was defined by quartz made measuring rod, which was used to calibrate 24-meter long invar-wire. Standard <b>baselines</b> <b>length</b> is invar-wire multiplied by 36, which is 864 meters.|$|R
3000|$|... 2,[*]α) to {{the output}} (the height information) {{with respect to}} the {{different}} <b>baseline</b> <b>lengths.</b> In this method, we use four objects with different heights for the experiment. After that, in order to obtain the distribution map of height value, we change the <b>length</b> of <b>baseline</b> and its relevant parameters (i.e., θ [...]...|$|R
40|$|The angular {{broadening}} of compact radio sources observed {{through a}} medium having turbulent density irregularities is usually estimated using the phase structure function. We employ an exact formulation for the phase structure function that helps in obtaining an accurate estimate of angular broadening when the <b>baseline</b> <b>lengths</b> {{are comparable to}} the inner scale of the turbulent spectrum. Comment: International Symposium on Solar-Terrestrial Physic...|$|R
40|$|Cost-effecctiveness is a {{requirement}} of most geodetic projects. In order to estimate the minimum duration of GPS static observations to determine an optimum, cost- effective accuracy in <b>baseline</b> <b>length</b> measurements, a statistical analysis of data collected during a 6 -day long record, {{in the framework of}} the GERCOP project, were analyzed. Using a random number generator we defined each time 9 sets of observations, 15 min to 3 days long from this 6 -day record. These sets of data were analyzed on the basis of post-processing static analysis and a commercial software, and the corresponding baseline lengths were computed. The differences between the average and maximum estimated <b>baseline</b> <b>length</b> for each data set from the best estimate <b>baseline</b> <b>length</b> and their standard deviation were subsequently computed. A plot of the obtained result versus time revealed an exponential trend for the decay of the uncertainty of the <b>baseline</b> <b>length</b> versus time. This analysis reveals that only a slight improvement in the accuracy of the <b>baseline</b> <b>length</b> is obtained after 3 and definitely after 24 hours of observations. This indicates that the optimum duration of GPS static observation for short <b>baseline</b> <b>length</b> measurements in Greece is...|$|E
40|$|Additional {{nonlinear}} <b>baseline</b> <b>length</b> constraint {{is often}} used for GNSS dynamic relative positioning, but the LAMBDA method can only deal with linear constraint model. So, {{it is necessary to}} linearize and approximate nonlinear constraint conditions. Linearized approximate constraint usually increases the success rate of fixing integer ambiguity, but for the ultra-short baseline, the opposite results may be derived. When will the linearized approximate <b>baseline</b> <b>length</b> constraint can improve the success rate of fixing ambiguity? This article attempts to answer these questions. Firstly, the float solution's maximum influence value formula is derived when using linearized approximate <b>baseline</b> <b>length</b> constraint, based on GNSS relative positioning model; Secondly, a discriminant condition is given to determine whether <b>baseline</b> <b>length</b> constraint can be linear approximation. When the condition is met, the influence can be ignored, linearized approximate <b>baseline</b> <b>length</b> constraint can improve the accuracy of float solution and increase the success rate of fixing ambiguity,on the contrast, the influence may not be ignored, linear approximation will result in a biased float solution and the ambiguity cannot be fixed correctly; At last, the foregoing conclusions are verified with some numerical example in this paper...|$|E
40|$|We {{investigated}} {{scattering of}} the GPS site coor dinates and <b>baseline</b> <b>length</b> changes using daily GEONET solutions. We first calculated <b>baseline</b> <b>length</b> changes {{from the daily}} coordinates, and then calculated their standard deviations every tendays. The standard deviations, which are small in winter and large in summer, clearly show seasonal variations. Another characteristics is that the standard deviations are dependent on the <b>baseline</b> <b>length.</b> These facts suggested that uncorrected water vapor effects affected on {{the accuracy of the}} GEONET solutions. The standard deviations of both <b>baseline</b> <b>length</b> and ellipsoidal height show some dependency on the GEONET station IDs, which are related to the year of establishment and the region of the sites. The standard deviations before 1996 are larger than those after 1996. Theyare small near Tsukuba, and are generally large in western Japan compared with eastern Japan. Spatial pattern of the standard deviations at the sites of Trimble receivers seems to have a relation with the regional administration boundaries. This may suggest that environments of observation points or differences of the installation methods affect on the accuracy...|$|E
40|$|We {{present an}} {{approach}} to building interferometric telescopes using ideas of quantum information. Current optical interferometers have limited <b>baseline</b> <b>lengths,</b> and thus limited resolution, because of noise and loss of signal due to the transmission of photons between the telescopes. The technology of quantum repeaters {{has the potential to}} eliminate this limit, allowing in principle interferometers with arbitrarily long baselines. Comment: 10 pages, v 2 improved clarit...|$|R
40|$|An antenna in {{geostationary}} orbit {{was used for}} VLBI observations at 2. 3 GHz, in combination with ground antennas in Australia and Japan. 23 of the 25 observed sources were detected on orbiter-ground <b>baselines,</b> with <b>baseline</b> <b>lengths</b> as large as 2. 15 earth diameters. Brightness temperatures between 10 to the 12 th K and 4 x 10 to the 12 th K were measured for 10 sources...|$|R
40|$|This {{proposed}} design {{prototype for}} a short-baseline optical astronomical interferometer provides superior UV-plane coverage and yet is cost-effective. This enhanced UV-plane coverage {{is achieved by}} employing variable <b>baseline</b> <b>lengths</b> and variable <b>baseline</b> orientations, which allow for increased detector integration times and fixed/reproducible interferometer baseline orientations. By synthesizing existing technologies, materials, and techniques it is feasible to construct an astronomical interferometer capable of viable scientific research for minima...|$|R
3000|$|The {{proportional}} constant factor λ {{was calculated}} using Eq. 18. The {{result of the}} improved method was λ[*]=[*] 330.1302 and T=λT; therefore, the final translation vector obtained using our calibration method was Τ[*]=[*][0.3301,  1.3205, ‐[*] 330.1302]. The modulus of vector T is the calibrated <b>baseline</b> <b>length.</b> The <b>baseline</b> <b>length</b> of our system was 332  mm. The deviation between our calibration and true value was 1.8698  mm with an error of 0.56 [...]...|$|E
30|$|Moreover, {{we showed}} that the <b>baseline</b> <b>length</b> repeatabilities as a general measure of {{accuracy}} of <b>baseline</b> <b>length</b> determinations improve for the turbulence-based solution. In comparison with the reference solution and other refinement strategies, up to 50  % of the baselines are improved by at least 1 mm, whereas only a few baselines are degraded. With this approach, also far more realistic standard deviations of the derived target parameters, such as station coordinates or Earth orientation parameters, were achieved.|$|E
30|$|The maximum {{baseline}} of {{the network}} comes from the pair of nodes connecting the mainland and the island. On the other hand, the baseline {{on the east coast}} is the shortest, which is due to the high weight around the mountain chain. Excluding these exceptions, the <b>baseline</b> <b>length</b> is fairly well distributed and shows a small variation around the mean value of 59 km. Therefore, the MST and mean and/or maximum <b>baseline</b> <b>length</b> can also be a criterion for completion {{of the network}} selection process.|$|E
40|$|We {{consider}} {{the effect of}} neutrino propagation through the matter of earth's crust on nu (mu) [...] > nu (e) oscillations in long baseline experiments within a three flavour oscillation framework. We show that, given the constraints from solar neutrino and CHOOZ data, matter effects enhance the mixing for neutrinos rather than for anti-neutrinos. To discern the matter effects, we need data from two different experiments with different <b>baseline</b> <b>lengths</b> (such as K 2 K and MINOS) ...|$|R
40|$|The Low Frequency Array (LOFAR) {{is a new}} {{generation}} of electronic radio telescope based on aperture array technology and working in the frequency range of 30 - 240 MHz. The telescope is being developed by ASTRON, and currently being rolled-out across the Netherlands and other countries in Europe. The plan is to build at least 36 stations in the Netherlands (with <b>baseline</b> <b>lengths</b> of up to 100 km), 5 stations in Germany, and 1 station in each of Sweden, France and the UK. With <b>baseline</b> <b>lengths</b> of up to 2000 km, sub-arcsecond resolution will be possible at the highest frequencies. The Key Science Projects being addressed by the project include: deep, wide-field cosmological surveys, transients, the epoch of re-ionisation and cosmic ray studies. We present the current status of the project, including the development of the super-core in Exloo and the completion of the first 3 stations. 'First fringes' from these stations is also presented. Comment: 6 pages, invited review presented at "Science and Technology of Long Baseline Real-Time Interferometry: The 8 th International e-VLBI Workshop - EXPReS 09 " Madrid, Spain June 22 - 26, 2009. To be published in Proceedings of Science (PoS...|$|R
40|$|University of Minnesota Ph. D. dissertation. May 2010. Major: Aerospace Engineering and Mechanics. Advisor:Demoz Gebre-Egziabher. 1 {{computer}} file (PDF); ix, 173 pages, appendix A. This thesis explores the methods for enhancing {{the performance of}} using low cost, single frequency Carrier phase Differential Global Navigation Satellite System (CDGNSS) in real-time, safety or liability critical applications. This is done by improving the integer ambiguity resolution performance and carrier phase error modeling. CDGNSS is considered for {{a broad range of}} real-time applications which require both a high precision relative positioning and attitude determination system. This is because of the drift-free nature of the GNSS measurement errors and the precise nature of the carrier phase measurement. The key to making full use of the precise nature of the carrier phase measurement is to fix the integer ambiguity quickly and reliably. This poses the biggest challenge for a low cost single frequency system. For the attitude determination problem, the precisely known <b>baseline</b> <b>lengths</b> can be used to improve the integer ambiguity resolution performance. Traditionally, the relative positioning problem was solved independently of the attitude determination problem and, thus could not leverage the precisely known <b>baseline</b> <b>lengths</b> of the attitude determination system. However, by integrating the two systems together, the precisely known <b>baseline</b> <b>lengths</b> can be used to improve the relative positioning system as well. The first part of the thesis develops an integration framework to improve the integer ambiguity resolution performance for the relative positioning system and the attitude determination system simultaneously. The second part of the thesis provides a GNSS antenna Phase Center Variation (PCV) error model development to improve the accuracy of the integrated system. It also examines the feasibility analysis of using the developed error model for a real-time dynamic application. The challenging of using this in the real time {{lies in the fact that}} PCV error magnitude is small (less than 2 cm) and the developed error model is a function of unknown parameter such as attitude. A feasibility analysis of the developed model with a set of specific antennas is performed and assessed...|$|R
40|$|Results of VLBI and GPS {{observations}} were analyzed with goal to investigate differences in observed <b>baseline</b> <b>length</b> derived from both techniques. VLBI coordinates for European stations {{were obtained from}} processing of all available observations collected on European and global VLBI network. Advanced model for antenna thermal deformation was applied to account for change of horizontal component of <b>baseline</b> <b>length.</b> GPS data were obtained from re-processing of the weekly EPN (European Permanent GPS Network) solutions. Systematic differences between results obtained with two techniques including linear drift and seasonal effects are determined. Comment: 9 p...|$|E
30|$|It {{is known}} that errors in tropospheric {{parameters}} propagate to the estimates of station coordinates (Nilsson et al. 2013). With a better handling of the tropospheric delays, improvements {{in the quality of}} derived station coordinates are expected. Widely used measures to quantify the effects on station positions are station coordinate and <b>baseline</b> <b>length</b> repeatabilities (Davis et al. 1985). Nilsson et al. (2015) showed that by using a Kalman filter instead of least squares adjustment, an improvement in the <b>baseline</b> <b>length</b> repeatabilities of about 10 % is possible. Here, we wanted to focus on the effect of a station-specific noise model for ZWD.|$|E
40|$|Very Long Baseline Interferometry (VLBI) {{results are}} {{presented}} for the two baseline sectors between the Goldstone DSN antenna complex and the overseas sites at Canberra, Australia and Madrid, Spain. Results from solutions using data taken between 1978 September and 1983 May show an apparent California-Spain <b>baseline</b> <b>length</b> increase of 21 cm during this time span, while the California-Australia length has remained constant. Statistical investigations of {{the integrity of the}} data are discussed along with dominant systematic error sources and their effect on <b>baseline</b> <b>length</b> determination. Results and interpretation of the time behavior of the angle between DSN baselines are also described...|$|E
40|$|In {{order to}} make {{successful}} earthquake predictions, detection and monitoring of baseline changes are important for investigating their origins, including precursory crustal deformations in tectonically active areas. In this study, differencing two baselines that run approximately {{parallel to each other}} and normal to the expected crustal deformations, and that share a station is proposed for analysis. Differencing reduces common systematic baseline errors, thereby enabling detection of subtle transient systematic changes in the baseline time-series that are otherwise buried in the measurement noise. Mean shift analysis, a well-known statistical technique to determine hether the mean of a stochastic process has shifted using cumulative sum charts, can then be used to locate the change points in the time-series. The application of this method to the differences of concurrently observed very long baseline interferometry (VLBI) and global positioning system (GPS) baselines in the Japanese Keystone project, where periodic and persistent baseline changes are removed, revealed transient variations in the <b>baseline</b> <b>lengths</b> several months prior to the seismic activity in the Izu Islands that started on June 26, 2000. Reproduction of the results using GPS and VLBI, two alternative baseline measurement techniques, validated the accuracy of the proposed approach for detecting previously hidden transient changes in the <b>baseline</b> <b>lengths.</b> Department of Land Surveying and Geo-Informatic...|$|R
40|$|We {{consider}} nu(mu) [...] >nu(e) oscillations in {{long baseline}} experiments within a three flavor oscillation framework. A non-zero measurement of this oscillation probability {{implies that the}} (13) mixing angle phi is non-zero. We consider the effect of neutrino propagation through the matter of Earth's crust and show that, given the constraints from solar neutrino and CHOOZ data, matter effects enhance the mixing for neutrinos rather than for anti-neutrinos. We need data from two different experiments with different <b>baseline</b> <b>lengths</b> (such as K 2 K and MINOS) to discern {{the effect of the}} matter term...|$|R
40|$|Results are {{presented}} for two recent short baseline experiments, with <b>baseline</b> <b>lengths</b> of 6 and 253 km, showing delay residuals of 10 ps or less for angularly close sources. On the 6 -km baseline, a fiber-optic link {{was used to}} distribute a common frequency reference, enabling coherent operation of the two stations. The observed delay residuals correspond to a differential angular accuracy of about 10 nrad on the 253 -km baseline. Future plans are discussed, including {{the development of a}} realtime correlation capability on a 22 -km baseline at Goldstone, CA...|$|R
40|$|We {{study the}} optimal setup for {{observation}} of the CP asymmetry in neutrino factory experiments — the <b>baseline</b> <b>length,</b> the muon energy and the analysis method. First, we {{point out that the}} statistical quantity which has been used in previous works doesn’t represent the CP asymmetry, and hence cannot be used to measure it., which is sensitive to the CP Then we propose the more suitable quantity, ≡ χ 2 2 asymmetry. We investigate the behavior of χ 2 2 with ambiguities of the theoretical parameters. The fake CP asymmetry due to the matter effect increases with the <b>baseline</b> <b>length.</b> Therefore, the error in the estimation of the fake CP asymmetry grows with the <b>baseline</b> <b>length</b> due to the ambiguities of the theoretical parameters. Thus we insist that we lose the sensitivity to the genuine CP-violation effect in longer baseline such as L ≥ 1000 km. Finally we examine the T-violation mode. We show that in this mode the genuine CP asymmetry is observed very clearly even if we have the ambiguities in the theoretical parameters...|$|E
40|$|We {{study the}} optimal setup for {{observation}} of the CP asymmetry in neutrino factory experiments [...] - the <b>baseline</b> <b>length,</b> the muon energy and the analysis method. First, we {{point out that the}} statistical quantity which has been used in previous works doesn't represent the CP asymmetry. Then we propose the more suitable quantity, ≡χ^ 2 _ 2, which is sensitive to the CP asymmetry. We investigate the behavior of χ^ 2 _ 2 with ambiguities of the theoretical parameters. The fake CP asymmetry due to the matter effect increases with the <b>baseline</b> <b>length</b> and hence the error in the estimation of the fake CP asymmetry grows with the <b>baseline</b> <b>length</b> due to the ambiguities of the theoretical parameters. Namely, we lose the sensitivity to the genuine CP-violation effect in longer baseline. Comment: 8 pages, 2 figures, Talk given by J. Sato at Joint U. S. / Japan Workshop on New Initiatives in Muon Lepton Flavor Violation and Neutrino Oscillation with High Intense Muon and Neutrino Sources, Honolulu, Hawaii, 2 - 6 Oct 200...|$|E
3000|$|... × {{with the}} motion {{parameters}} [R,[*]T] {{can only be}} obtained as [R,T], that is, with the difference of a non-zero factor, where T=λT. Here, the physical meaning of the non-zero factor λ is the <b>baseline</b> <b>length.</b>|$|E
40|$|Aims. The aim of {{this study}} is to enhance our {{knowledge}} of the characteristics and distribution of the circumstellar dust associated with the individual components of the young hierarchical triple system T Tau. Methods. To reach this goal, observations in the N-band (8 - 13 µm) with the two-telescope interferometric instrument MIDI at the VLTI were performed. For the northern component of the T Tau system, projected <b>baseline</b> <b>lengths</b> of 43 m, 62 m, and 85 m were used. For the southern binary projected <b>baseline</b> <b>lengths</b> of equivalent resolution could be utilised. Our study is based on both the interferometric and the spectrophotometric measurements and is supplemented by new visual and infrared photometry. Also, the phases were investigated to determine the dominating mid-infrared source in the close southern binary. The data were fit with the help of a sophisticated physical disc model. This model utilises the radiative transfer code MC 3 D that is based on the Monte-Carlo method. Results. Extended mid-infrared emission is found around all three components of the system. Simultaneous fits to the photometric and interferometric data confirm the picture of an almost face-on circumstellar disc around T Tau N. Towards this star, the silicate band is seen in emission. This emission feature is used to model the dust content of the circumstellar disc. Clear signs of dus...|$|R
40|$|The {{very first}} VLBI {{observation}} {{was carried out}} only 20 years ago. But the VLBI technique faces some difficult problems, such as measurement of propagation delay due to the atmosphere, improvement of the physical model etc. GPS interferometric observations were carried out in Japan {{for a variety of}} <b>baseline</b> <b>lengths,</b> and from this analysis it is concluded that 1 ∿ 2 ppm accuracy of <b>baseline</b> <b>lengths</b> can be attainable with the GPS interferometric positioning. One of the important problems in the Electro-optical Distance Measurement (=EDM) is how to estimate the refractive index n or refractivity N (=(n- 1) ×(10) ^) under concerned atmospheric conditions. In practise the mean refractivity N_m is calculated by the mean temperature T_m and pressure P_m averaged from the observations at the two end points. The reasonable results can be obtained by using these N_m and P_m when the observations are carried out two hours before or after the sunset or sunrise. When the observations are obliged to be carried out at other times, We need another estimation of refractivity. Kukkamaki proposed a refraction correction formula based on his empirical temperature model : t=a+bZ^c where a, b, and c are constants and Z is the height above the ground. We estimated the temperature midway between the two end points by this formula...|$|R
30|$|In the following, a phase-to-height mapping {{model is}} {{presented}} for parameters’ influence analysis. In this model, a rigorous mathematical relationship {{that exists between}} the height of an object’s surface, the phase difference distribution map, and {{the parameters of the}} setup is firstly derived. Based on this model, we then study the problem of how the uncertainty of relevant parameters, particularly the <b>baseline’s</b> <b>length,</b> affects the 3 -D shape measurement accuracy. The uncertainty analysis on the proposed model including partial derivative analysis, relative error analysis, and sensitivity analysis are performed. Moreover, the Monte Carlo simulation experiment is also conducted.|$|R
