12|248|Public
50|$|Lake Gregory, {{also known}} as the Isis <b>Balancing</b> <b>Storage</b> or simply as The Duckpond is a small {{impoundment}} between Bundaberg and Childers in Queensland, Australia. It is 2 square kilometres in area with an average depth of 3.1 m and holds just over 6000 ML.|$|E
50|$|The Little Para Reservoir {{was built}} between 1974 and 1977 and {{commissioned}} in 1979, functioning {{largely as a}} <b>balancing</b> <b>storage</b> for Murray River water, and also serving a flood mitigation role. The reservoir has a capacity of 20,800 megalitres and almost 300,000 cubic metres of rock {{was used in the}} reservoir's construction. The Reservoir has two lookouts and public toilets and was open to the public until June 2008.|$|E
40|$|A {{comparison}} is made between several domain decomposition {{strategies for the}} solution of threedimensional partial differential equations on a MIMD distributed memory parallel computer. The grids used are structured, and the numerical algorithm is ADI. Important implementation issues regarding load <b>balancing,</b> <b>storage</b> requirements, network latency, and overlap of computations and communications are discussed. Results of {{the solution of the}} threedimensional heat equation on the Intel iPSC/ 860 are presented for the three most viable methods. It is found that the Bruno-Cappello decomposition delivers optimal computational speed through an almost complete elimination of processor idle time, while providing good memory efficiency. 1 Introduction Implicit numerical algorithms for the solution of multi-dimensional partial differential equations (PDE's) are usually more efficient computationally than explicit methods, when implemented on conventional (vector) computers. However, they are harde [...] ...|$|E
5000|$|EOTTL (extents on the twig level) [...] - [...] fully <b>balanced</b> <b>storage</b> tree, {{meaning that}} all paths to objects are of equal length ...|$|R
30|$|We {{concluded}} in (Sobe et al. 2011 a) that efficient replacement or clean-up {{has to be}} done in order to avoid blocking the transport of units. A clean-up is triggered if a certain storage level is reached, which leads to a <b>balanced</b> <b>storage</b> load of the system.|$|R
50|$|Millbrook covers 178 ha {{behind a}} 288 m clay-cored earth dam. It lies on Chain of Ponds creek, a {{tributary}} of the River Torrens. Water in the reservoir is piped from a weir near Gumeracha but it is also used to <b>balance</b> <b>storage</b> of River Murray water via the Mannum - Adelaide pipeline. It is used to capture approximately half of the Torrens' water flow.|$|R
40|$|In {{the past}} few years, several DHT-based abstractions for {{peer-to-peer}} systems have been proposed. The main characteristic is to associate nodes (peers) with objects (keys) and to construct distributed routing structures to support efficient location. These approaches partially consider the load problem by <b>balancing</b> <b>storage</b> of objects without, however, considering lookup traffic. In this paper we present an analysis of structured peer-to-peer systems taking into consideration Zipf-like requests distribution. Based on our analysis, we propose a novel approach for load balancing taking into account object popularity. It is based on dynamic routing table reorganization in order to balance the routing load and on caching objects to balance the request load. We can therefore significantly improve the load balancing of traffic in these systems, and consequently their scalability and performance. Results from experimental evaluation demonstrate the effectiveness of our approach...|$|E
40|$|Abstract — In {{the past}} few years, several DHT-based abstractions for {{peer-to-peer}} systems have been proposed. The main characteristic is to associate nodes (peers) with objects (keys) and to construct distributed routing structures to support efficient location. These approaches partially consider the load problem by <b>balancing</b> <b>storage</b> of objects without, however, considering lookup traffic. In this paper we present an analysis of structured peer-to-peer systems taking into consideration Zipf-like requests distribution. Based on our analysis, we propose a novel approach for load balancing taking into account object popularity. It is based on dynamic routing table reorganization in order to balance the routing load and on caching objects to balance the request load. We can therefore significantly improve the load balancing of traffic in these systems, and consequently their scalability and performance. Results from experimental evaluation demonstrate the effectiveness of our approach. Keywords—peer-to-peer, popularity, traffic load balancing. I...|$|E
40|$|Replication {{is widely}} used in {{unstructured}} peer-to-peer systems to improve search or achieve availability. We identify and solve a subclass of replication problems where each object {{is associated with a}} maintainer node, and its replicas should only be available as long as its maintainer is part of the network. Such requirement can be found in various applications, e. g., when objects are directory lists, service lists, or subscriptions of a publish/subscribe system. We provide maintainers with proven guarantees on the number of replicas, in spite of network churn and crash failures. We also tackle the related problems of changing the number of replicas, updating replicas, <b>balancing</b> <b>storage</b> load in a heterogeneous network, and eliminating replicas left by crashing maintainers. Our algorithm is based on probabilistic methods and is simple to implement. We show by simulation and formal proof that our algorithm is correct. 1...|$|E
50|$|The stmsboot {{program is}} an {{administrative}} command to manage fibre channel devices under Solaris. When enabled, MPxIO will discover multiple paths {{to the same}} fibre channel drives and map them as one device under a new device name. This mapping creates a highly-available and multiplexed (trunked and load <b>balanced)</b> <b>storage</b> presentation on the server configured. The stmsboot command automatically updates /etc/vfstab and dump configuration to properly leverage the new device names.|$|R
40|$|We {{describe}} a generic database {{structure of a}} multi-period two-stage stochastic optimization based decision support system. The model {{is an extension of}} earlier work (Dutta & Fourer; 2004). The model could be used with no or little knowledge of OR/MS. The model maximizes expected contribution subject to material balance, facility capacity, facility input, facility output, <b>storage</b> inventory <b>balance,</b> <b>storage</b> area constraints. The model also considers non-anticipativity constraints for first stage decision variables. 1...|$|R
30|$|Typically, the {{popularity}} of content is dynamic and replicas of content with decreasing popularity have to be handled to <b>balance</b> the <b>storage.</b> This {{can be done by}} introducing clean-up mechanisms; however, the challenge is to identify unnecessary replicas.|$|R
40|$|A set {{of three}} {{scenarios}} has been created {{in order to examine}} the incorporation of extensive penetrations of micro-generators into electricity networks (termed 'highly distributed power systems'). The scenarios have been created as a synthesis of the Future Network Technologies scenarios and the UK domestic carbon model, and yields energy use and carbon dioxide emissions of the UK housing stock from inputs of household numbers, house type, thermal efficiency, appliance efficiency, as well as the number and efficiency of micro-generators used. The centralized supply mix also varies between scenarios and features extensive penetrations of large-scale renewables. The scenarios illustrate the scale of change required to reduce CO 2 emissions by 60 per cent by 2050, which has substantial impacts for electricity network operation. Moving from a centralized system to the one where one-third of electricity comes from distributed sources poses significant challenges including: reverse power flow on networks, load <b>balancing,</b> <b>storage</b> requirements, phase unbalance, harmonics, and ancillary services...|$|E
40|$|This paper {{presents}} the design, implementation, {{and evaluation of}} EnviroMic, a novel distributed acoustic monitoring, storage, and trace retrieval system. Audio {{represents one of the}} least exploited modalities in sensor networks to date. The relatively high frequency and large size of audio traces motivate distributed algorithms for coordinating recording tasks, reducing redundancy of data stored by nearby sensors, filtering out silence, and <b>balancing</b> <b>storage</b> utilization in the network. Applications of acoustic monitoring with EnviroMic range from the study of mating rituals and social behavior of animals in the wild to audio surveillance of military targets. EnviroMic is designed for disconnected operation, where the luxury of having a basestation cannot be assumed. We implement the system on a TinyOS-based platform and systematically evaluate its performance through both indoor testbed experiments and a preliminary outdoor deployment. Results demonstrate up to a 4 -fold improvement in effective storage capacity of the network compared to uncoordinated recording. Index Terms Sensor networks, applications, acoustics, distributed storage, group managemen...|$|E
40|$|Platform-as-a-Service (PaaS) offerings are {{fundamentally}} chang-ing traditionally held beliefs about software deployment en-vironments. Developers {{can no longer}} assume that they control {{the entirety of the}} software stack: the source, the compiler, the run-time environment, etc. In PaaS, develop-ers write code locally and deploy it “in the cloud. ” While decoupling ownership of the deployment environment from the developer has benefits (i. e. - load <b>balancing,</b> <b>storage),</b> it hinders the developer’s ability to specify secure data flow as-sertions. When developers no longer control the data, they can make no guarantees to end users about the security of their data. To address these shortcomings of PaaS, we present An-noFlow, an annotation framework for CloudSpace (a PaaS offering) that allows developers to define application-specific data flow assertions. We demonstrate how developers can protect sensitive data in the cloud. In addition, we intro-duce an auditing framework that enables developers to re-trieve relevant performance metrics from their cloud-based applications. Finally, we evaluate the performance overhead associated with AnnoFlow. 1...|$|E
40|$|Abstract We {{consider}} {{the problem of}} horizontally partition-ing a dynamic relation across {{a large number of}} disks/nodes by the use of range partitioning. Suchpartitioning is often desirable in large-scale parallel databases, as well as in peer-to-peer (P 2 P) sys-tems. As tuples are inserted and deleted, the partitions may need to be adjusted, and data moved, inorder to achieve <b>storage</b> <b>balance</b> across the participant disks/nodes. We propose efficient, asymptot-ically optimal algorithms that ensure <b>storage</b> <b>balance</b> at all times, even against an adversarial in-sertion and deletion of tuples. We combine the above algorithms with distributed routing struc-tures to architect a P 2 P system that supports efficient range queries, while simultaneously guar-anteeing <b>storage</b> <b>balance...</b>|$|R
40|$|Abstract—DHT {{systems are}} {{structured}} overlay networks capable of using P 2 P resources as a scalable platform for very large data storage applications. However, their efficiency expects {{a level of}} uniformity in the association of data to index keys that is often not present in inverted indexes. Index data tends to follow non-uniform distributions, often power law distributions, creating intense local storage hotspots and network bottlenecks on specific hosts. Current techniques like caching cannot, alone, cope with this issue. We propose a distributed data structure based on a decentralized balanced tree to <b>balance</b> <b>storage</b> data and network load more uniformly across hosts. The {{results show that the}} data structure is capable of balancing resources, in particular when performin...|$|R
40|$|We {{consider}} {{the problem of}} horizontally partitioning a dynamic relation across {{a large number of}} disks/nodes by the use of range partitioning. Such partitioning is often desirable in large-scale parallel databases, as well as in peer-to-peer (P 2 P) systems. As tuples are inserted and deleted, the partitions may need to be adjusted, and data moved, in order to achieve <b>storage</b> <b>balance</b> across the participant disks/nodes. We propose efficient, asymptotically optimal algorithms that ensure <b>storage</b> <b>balance</b> at all times, even against an adversarial insertion and deletion of tuples. We combine the above algorithms with distributed routing structures to architect a P 2 P system that supports efficient range queries, while simultaneously guaranteeing <b>storage</b> <b>balance.</b> ...|$|R
40|$|We present ADDSEN {{middleware}} as {{a holistic}} solution for Adaptive Data processing and dissemination for Drone swarms in urban SENsing. To efficiently process sensed {{data in the}} middleware, we have proposed a cyber-physical sensing framework using partially ordered knowledge sharing for distributed knowledge management in drone swarms. A reinforcement learning dissemination strategy is implemented in the framework. ADDSEN uses online learning techniques to adaptively balance the broadcast rate and knowledge loss rate periodically. The learned broadcast rate is adapted by executing state transitions {{during the process of}} online learning. A strategy function guides state transitions, incorporating a set of variables to reflect changes in link status. In addition, we design a cooperative dissemination method for the task of <b>balancing</b> <b>storage</b> and energy allocation in drone swarms. We implemented ADDSEN in our cyber-physical sensing framework, and evaluation results show that it can achieve both maximal adaptive data processing and dissemination performance, presenting better results than other commonly used dissemination protocols such as periodic, uniform and neighbor protocols in both single-swarm and multi-swarm cases...|$|E
40|$|Database storage {{management}} in clustered storage environments is a manual, time-consuming, and error-prone task. Such management involves regular movement of database objects across nodes {{in the storage}} cluster so that storage utilization is maximized. We present STORM, an automated approach that guides this task by combining low-overhead information gathering about database access and storage usage patterns, efficient analysis of gathered information, and effective decision-making for reconfiguring data layout. The reconfiguration process is guided by the primary optimization objective of minimizing the total data movement required for the reconfiguration, with the secondary constraints of space and balanced I/O bandwidth utilizations across the storage nodes in the cluster. We model the reconfiguration decision-making as a multiconstraint optimization problem which is N P-hard. We then present a heuristic that provides an approximate solution in O(Nlog (N M ber of storage nodes and N is {{the total number of}} database objects. A simulation study shows that the heuristic converges to an acceptable solution that is successful in <b>balancing</b> <b>storage</b> utilization with an accuracy that lies within 7 % of the ideal solution. ...|$|E
40|$|Event log {{processing}} and analysis {{play a key role}} in applica-tions ranging from security management, IT trouble shoot-ing, to user behavior analysis. Recent years have seen a rapid growth in system scales and the corresponding rapid increase in the amount of log event data. At the same time, as logs are found to be a valuable information source, log analysis tasks have become more sophisticated demand-ing both interactive exploratory query {{processing and}} batch computation. Desirable query types include selection with time ranges and value filtering criteria, join within time win-dows, join between log data and reference tables, and various aggregation types. In such a situation, parallel solutions are necessary, but existing parallel and distributed solutions ei-ther support limited query types or perform only batch com-putations on logs. With a system called LogKV, this paper reports a first study of using Key-Value stores to support log {{processing and analysis}}, exploiting the scalability, reli-ability, and efficiency commonly found in Key-Value store systems. LogKV contains a number of unique techniques that are needed to handle log data in terms of event inges-tion, load <b>balancing,</b> <b>storage</b> optimization, and query pro-cessing. Preliminary experimental results show that LogKV is a promising solution. 1...|$|E
30|$|We also {{advocate}} for using smarter replica-assignment policies to achieve better workload <b>balance</b> and efficient <b>storage</b> space management.|$|R
40|$|A {{flexible}} {{file format}} for Solid Freeform Fabrication data is presented which significantly improves on the de-facto industry standard STL format. The new format removes the redundancy present in STL files and can contain topological information. Its specification flexibility {{allows users to}} <b>balance</b> <b>storage</b> and processing costs. Since facet boundary models currently provide the greatest common denominator for data exchange between many CAD systems, they are supported by this format. Additionally, representation of CSG primitives is provided, as are capabilities to represent multiple instances of both facet and CSG solids. Format extensibility, without obsoleting existing programs, is made possible by interleaving the format schema with the data. User data {{can be added to}} existing entities, or new entities can be created. This allows the addition of NURBS based geometries in the future. ...|$|R
40|$|DHT {{systems are}} {{structured}} overlay networks capable of using P 2 P resources as a scalable platform for very large data storage applications. However, their efficiency expects {{a level of}} uni- formity in the association of data to index keys that is often not present in inverted indexes. Index data tends to follow non- uniform distributions, often power law distributions, creating in- tense local storage hotspots and network bottlenecks on specific hosts. Current techniques like caching cannot, alone, cope with this issue. We propose a new distributed data structure based on a decen- tralized balanced tree to <b>balance</b> <b>storage</b> data and network load more uniformly across all hosts. The approach is stackable with standard DHTs and ensures that the DHT storage subsystem re- ceives an uniform load by assigning fixed sized, or low variance, blocks...|$|R
40|$|DHTs {{implement}} a distributed dictionary, supporting key insertion, deletion and lookup. They use hashing to (a) enable efficient dictionary operations, and (b) achieve <b>storage</b> <b>balance</b> across the participant nodes. Hashing can be inappropriate for both problems, as it (a) destroys data ordering, thus making sequential key access and range queries expensive, and (b) fails to provide <b>storage</b> <b>balance</b> when keys are not unique. We propose generaliz-ing DHTs to create Distributed Balanced Tables (DBTs), which eliminate the above two problems. To solve prob-lem (a), we discuss how DHT routing structures {{can be adapted}} for use in DBTs, while preserving {{the costs of the}} standard dictionary operations and supporting effi-cient range queries. To solve problem (b), we describe an efficient algorithm that guarantees <b>storage</b> <b>balance,</b> even against an adversarial insertion and deletion of keys...|$|R
40|$|The <b>balance</b> between <b>storage</b> and {{computation}} {{of complex}} words {{is a major}} point of departure both for theories of lexical representation (e. g., Goldberg 2006, Halle & Marantz 1993, Jackendoff 1975) and processing (e. g., Baayen et al. 1997, Butterworth 1983, Taft 2004). The atoms of lexical memory that are implicated in lexica...|$|R
40|$|Main {{memory is}} {{continuously}} improving both in price and capacity. With this comes new storage {{problems as well}} as new directions of usage. Just before the millennium, several main memory database systems are becoming commercially available. The hot areas include boosting the performance of web-enabled systems, such as search-engines, and auctioning systems. We present a novel data storage structure [...] the# -storage structure, a high performance data structure, allowing automatically indexed storage of very large amounts of multi-attribute data. The experiments show excellent performance for point retrieval, and highly e#cient pruning for pattern searches. It provides the <b>balanced</b> <b>storage</b> previously achieved by random kd-trees, but avoids their increased pattern match search times, by an e#ective assignment bits of attributes. Moreover, it avoids the sensitivity of the kd-tree to insert orders. 1991 ACM Computing Classification System: D. 4. 2 : Storage Management [...] Main Memor [...] ...|$|R
30|$|Another {{important}} issue {{to consider is}} what simulation time step should be used. Using a shorter time step will increase the accuracy of this hydraulic analysis and often results in feasible optimization times for storages that empty or fill {{in a day or}} two (as would likely be the case for the stormwater ponds and Macquarie pipeline <b>balancing</b> <b>storages).</b> Simulating the behavior of Suma Park dam is more challenging, however, as the variations in the water levels can have a period of several years. Thus, the computation times with a short time step become prohibitively long. A balance needs to be found between using a short enough time step for the detailed hydraulics and a long simulation time for the large storages without having a prohibitively large computational time. Given the data availability (there is 118  years of rainfall and inflow data available, with a daily time step) the time step chosen is 1 day.|$|R
40|$|P 2 P {{overlays}} offer {{a convenient}} way to host an infrastructure that can scale {{to the size}} of the Internet and yet manageable. Current proposals, however, do not offer support for structuring data, other than assuming a distributed hash table. In reality, both applications and users typically organize data in a structured form. One such popular structure is tree as employed in a file system, and a database. A naïve approach such as hashing the pathname not only ignores locality in important operations such as file/directory lookup, but also results in uncontrollable, massive object relocations when rename on a path component occur. In this paper, we investigate policies and strategies that place a tree onto the flat storage space of P 2 P systems. We found that, in general, there exists a tradeoff between lookup performance and <b>balanced</b> <b>storage</b> utilization, and attempts to balance these two requirements calls for intelligent placement decision. ...|$|R
40|$|This paper {{describes}} the BID Data Suite, {{a collection of}} hardware, software and design patterns that enable fast, large-scale data mining at very low cost. By co-designing all of these elements we achieve single-machine performance levels that equal or exceed reported cluster implementations for common benchmark problems. A key design criterion is rapid exploration of models, hence the system is interactive and primarily single-user. The elements of the suite are: (i) the data engine, a hardware design pattern that <b>balances</b> <b>storage,</b> CPU and GPU acceleration for typical data mining workloads, (ii) BIDMat, an interactive matrix library that integrates CPU and GPU acceleration and novel computational kernels (iii), BIDMach, a machine learning system that includes very efficient model optimizers, (iv) Butterfly mixing, a communication strategy that hides the latency of frequent model updates needed by fast optimizers and (v) Design patterns to improve performance of iterative update algorithms. We present several benchmark problems {{to show how the}} above elements combine to yield multiple orders-of-magnitude improvements for each problem...|$|R
40|$|The {{key role}} {{compression}} plays in efficient information retrieval systems {{has been recognized}} for some time. However, applying a traditional compression algorithm to the contents of an information retrieval system is often not the best solution. For example, it is inefficient to perform search operations in maximally compressed data or to find the intersection of maximally compressed sets. In order to perform these operations, the data representation must be fully decompressed. This thesis explores practical space versus time trade-offs which <b>balance</b> <b>storage</b> space against the competing requirement that operations be performed quickly. In particular, {{we are interested in}} variable length coding methods which are both practical and allow codeword boundaries to be found directly in the compressed representation. The latter property allows considerable flexibility in developing algorithms which can manipulate compact sets and sequences and allow selective decompression. Applications of such coding methods are plentiful. For instance, variations of this theme provide practical solutions to the compressed pattern matching problem. The...|$|R
40|$|Modern {{applications}} {{expand to}} fill the space available to them, exploiting local storage to improve performance by caching, prefetching and precomputing data. In virtual-ized settings, this behavior compromises storage elastic-ity owing to a rigid contract between the hypervisor and the guest OS: once space is allocated to a virtual disk and used by an application, it cannot be reclaimed by the hy-pervisor. In this paper, we propose a new guest filesystem called Harmonium that exploits the ephemeral or deriva-tive nature of application data. Each file in Harmonium optionally has a motif that describes how the file can be reconstructed via computation, network accesses, or oper-ations on other files. Harmonium expands files from their motifs when space is available, and contracts {{them back to their}} motifs when it is scarce. Given a target size, the sys-tem selects files to expand or contract based on the load on the CPU, network, and storage, as well as expected access patterns. As a result, Harmonium enables elastic cloud storage, allowing the hypervisor to dynamically <b>balance</b> <b>storage</b> across multiple VMs. ...|$|R
40|$|Abstract—Distributed Hash Tables (DHTs) {{establish}} a struc-tured Peer-to-Peer (P 2 P) overlay network by applying proactive routing algorithms. Due to their well defined structure {{this class of}} P 2 P protocols is able to locate any content in the system within {{a limited number of}} hops. However, basic DHT algorithms are limited to queries for content that exactly matches the search term. In this paper, we propose a Prefix-based Multi-Attribute Key-word Search (PriMA KeyS) that is specially designed for searching persons in a distributed phone book and similar applications. Our architecture is fully distributed and pays special attention to a <b>balanced</b> <b>storage</b> load distribution as well as low network traffic. Hierarchical identifiers generated from multiple keywords help to reduce the load on nodes that host common keywords. Additionally, a locality preserving hash function enables prefix-based queries. An extensive linguistic analysis of search keywords is carried out to select optimum design parameters. Using sample queries we show that our system can efficiently handle both detailed and unspecific queries. I...|$|R
40|$|Although calorie dense, the starchy, {{tuberous}} {{roots of}} cassava provide the lowest sources of dietary protein within the major staple food crops (Manihot esculenta Crantz). (Montagnac JA, Davis CR, Tanumihardjo SA. (2009) Compr Rev Food Sci Food Saf 8 : 181 - 194). Cassava was genetically modified to express zeolin, a nutritionally <b>balanced</b> <b>storage</b> protein under {{control of the}} patatin promoter. Transgenic plants accumulated zeolin within de novo protein bodies localized within the root storage tissues, resulting in total protein levels of 12. 5 % dry weight within this tissue, a fourfold increase compared to non-transgenic controls. No significant differences were seen for morphological or agronomic characteristics of transgenic and wild type plants in the greenhouse and field trials, but relative to controls, levels of cyanogenic compounds were reduced by up to 55 % in both leaf and root tissues of transgenic plants. Data described here represent a proof of concept towards the potential transformation of cassava from a starchy staple, devoid of storage protein, to one capable of supplying inexpensive, plant-based proteins for food, feed and industrial applications...|$|R
40|$|We {{address the}} problem of secure {{authenticated}} broadcast in fully connected networks where every user has a communication channel with every other user. The problem poses interesting challenges and current solutions tradeoff either storage or computational overhead. We describe three solutions that provide a good <b>balance</b> of <b>storage</b> and computational complexity. Our solutions use concepts like compatible keys, one-way hash chains and logarithmic keying to achieve efficiency. By using a logical hierarchical partitioning of users our solutions achieve scalability. ...|$|R
30|$|Since {{peers are}} not likely to provide {{unlimited}} storage for other peers and in a dynamic system the popularity of units changes, in this paper we investigate different measures to efficiently <b>balance</b> the <b>storage</b> of the peers. We periodically apply different strategies if a certain storage level is reached. We compare LRU (Least Recently Used), LFU (Least Frequently Used) and a hormone-based clean-up. We show that the chosen clean-up mechanism has an impact on the delivery performance and that the system is still robust against peer failure.|$|R
