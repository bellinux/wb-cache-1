14|28|Public
50|$|UHAB also {{provides}} cost-saving programs for housing cooperatives such as fire and liability insurance, fuel purchases and <b>bookkeeping</b> <b>services.</b>|$|E
50|$|After leaving BankSA Dave {{set up his}} own {{business}} providing consulting and <b>bookkeeping</b> <b>services</b> for businesses in the Barossa Valley.|$|E
5000|$|Nomad Financial is a {{financial}} services and {{consulting firm that}} provides advisory, accounting and <b>bookkeeping</b> <b>services</b> for high growth startups.|$|E
50|$|Denby is {{a member}} of {{numerous}} community boards and organizations, and is the former owner of a <b>bookkeeping</b> <b>service.</b>|$|R
50|$|In 1903, Ernst and {{his older}} brother Theodore founded the Ernst & Ernst <b>bookkeeping</b> <b>service</b> with an {{invested}} capital of $500. In October 1906, Theodore left the business.|$|R
50|$|Finally, the Logging and <b>Bookkeeping</b> <b>service</b> (LB) tracks jobs {{managed by}} the WMS. It {{collects}} events from many WMS components and records the status {{and history of the}} job.|$|R
50|$|Bookminders is an American company {{providing}} outsourced {{accounting and}} <b>bookkeeping</b> <b>services</b> {{for small businesses}} and nonprofit organizations, and is an innovator in utilizing a home-based professional workforce.|$|E
50|$|Like {{any other}} {{non-profit}} organization, the SPCA {{relies heavily on}} not only financial donations but also on volunteers donating their time to various jobs - from clerical or <b>bookkeeping</b> <b>services</b> to odd jobs on the 218 acre grounds.|$|E
50|$|Bench {{provides}} US-based small businesses, independent contractors, {{and entrepreneurs}} with professional <b>bookkeeping</b> <b>services.</b> Clients are paired {{up with a}} dedicated team of professional bookkeepers who utilize an intuitive interface to display the organized financials and overall financial health of their business. This includes a monthly Profit & Loss and Balance Sheet, reconciliation, and expense categorization. Bench is integrated with third-party providers for Payroll as well as Invoicing.|$|E
50|$|Charlie Tygard {{runs the}} Accurate Tax and <b>Bookkeeping</b> <b>Service.</b> Previously, {{he was the}} Executive Director of Youth Incorporated. He {{graduated}} from Vanderbilt University with a Bachelor of Arts degree in Business Administration and Economics.|$|R
5000|$|<b>Bookkeeping</b> {{or other}} <b>services</b> related to {{accounting}} {{records of the}} Insurer ...|$|R
50|$|The ISD is {{responsible}} for economic and operational matters. It manages the premises of the Institute, the Institute's computer network, IT, <b>bookkeeping,</b> legal <b>services,</b> etc. The head of department is JUDr. Petr Kaňka.|$|R
5000|$|Economic {{cooperation}} with other kibbutzim {{in the area}} includes a regional date-packing plant, Ardom Computing Services, and Ardag, a large fish hatchery near Eilat. Many members work outside the kibbutz in professional positions such as teachers, physical and occupational therapists, researchers, social workers, and more. Ketura also offers accounting and <b>bookkeeping</b> <b>services,</b> with many members working in these positions. A number of members work in the local NGO - The Arava Institute for Environmental Studies (www.arava.org) ...|$|E
40|$|The thesis {{discusses}} {{the business plan}} {{to open a new}} company, which will offer <b>bookkeeping</b> <b>services,</b> tax consulting and payroll. The business plan takes account of the theoretical bases and issues of the proposed solution. The thesis includes also financial plan of business with financial prediction of revenues and expenses. This prediction is processed in pessimistic, realistic and optimistic scenarios...|$|E
40|$|We {{describe}} an agent-based approach for engineering problems {{in which the}} constraints and general control of problem solving are distributed. In order to overcome previous problems with engineering constraint solvers, we divide responsibilities between domain-specific agents, which control the overall problem solving, and generic, reusable agents. One of these generic agents is Redux 0, which provides general problem solving <b>bookkeeping</b> <b>services.</b> Another is a Constraint Manager, which provides constraint consistency services. We demonstrate that the utility of this approach on a previously-defined simple, but difficult distributed constraint problem...|$|E
5000|$|Stephen Vardin & Colleagues, Inc. :Full <b>service</b> <b>bookkeeping,</b> tax {{preparation}} and training.|$|R
5000|$|<b>Bookkeeping</b> {{or other}} <b>services</b> {{related to the}} {{accounting}} records or financial statements of the audit client; ...|$|R
40|$|The Data <b>Bookkeeping</b> <b>Service</b> (DBS) {{provides}} an event data catalog for Monte Carlo and recorded {{data of the}} Compact Muon Solenoid (CMS) Experiment at the Large Hadron Collider (LHC) at CERN, Geneva. It contains all the necessary information used for tracking datasets, like their processing history and associations between runs, files and datasets, {{on a large scale}} of about $ 10 ^ 5 $ datasets and more than $ 10 ^ 7 $ files. The DBS is widely used within CMS, since all kind of data-processing like Monte Carlo production, processing of recorded event data as well as physics analysis done by the user, are relying on the information stored in DBS...|$|R
30|$|Based on the {{regression}} result for secondary data (Sig. 0.000) as {{backed by the}} result of respondents’ views (p =  0.000), the alternative hypothesis was accepted which says {{that there is a}} significant relationship between outsourcing of back office activities and performance of SMEs in Benue state, Nigeria. From the responses gotten through the questionnaire, this research found out that, SMEs outsource back office activities such as, security services, cleaning services, <b>bookkeeping</b> <b>services,</b> order processing and other administrative services. Giving out these services to outside vendors who can perform them better has also resulted in a decrease in the cost of running the enterprises. Giving out theses services which are practically augmenting in nature also paves way for the enterprises to focus on their core areas and so enjoy the benefits of specialization.|$|E
40|$|We {{describe}} an agent-based approach for engineering problems {{in which the}} constraints and general control of problem solving are distributed. In order to overcome previous problems with engineering constraint solvers, we divide responsibilities between domain-specific agents, which control the overall problem solving, and generic, reusable agents. One of these generic agents is Redux 0, which provides general problem solving <b>bookkeeping</b> <b>services.</b> Another is a Constraint Manager, which provides constraint consistency services. We demonstrate the utility of this approach on a previously-defined simple, but difficult, distributed constraint problem. This work was funded by Navy contract SHARE N 00014 - 92 -J- 1833 under the US DARPA RaDEO program. An Engineering Constraint Manager Agent Constraint solving is a common function in engineering projects. As distributed and concurrent engineering become more common, the requirement to solve various kinds of constraints spanning d [...] ...|$|E
40|$|This paper details {{a second}} stage of a study into the use of small {{business}} computerised accounting systems (CAS), together with the role and impact of the accountant across businesses that use and do not use computerised systems. The most popular accounting software product is MYOB and the CAS was predominantly used for operational activities rather than for strategic purposes. Despite many owner-managers implementing a CAS, {{there was still a}} heavy reliance on accountants to review financial statements and to perform <b>bookkeeping</b> <b>services.</b> In fact, non-CAS users tended to utilise accountants’ services less than computerised accounting businesses. The findings of this study would be useful for accountants in determining marketing strategies for their small business clients, and for small business owners in general in encouraging them to utilise a CAS to provide more cost effective accounting information...|$|E
40|$|The CMS Dataset <b>Bookkeeping</b> <b>Service</b> (DBS) {{has been}} {{developed}} to catalog all CMS event data from Monte Carlo and Detector sources. It provides the ability to identify MC or trigger source, track data provenance, construct datasets for analysis, and discover interesting data. CMS requires processing and analysis activities at various service levels and the DBS system provides support for localized processing or private analysis, as well as global access for CMS users at large. Catalog entries can be moved among the various service levels with a simple set of migration tools, thus forming a loose federation of databases. DBS is available to CMS users via a Python API, Command Line, and a Discovery web page interfaces. The system is built as a multi-tier web application with Java servlets running under Tomcat, with connections via JDBC to Oracle or MySQL database backends. Clients connect to the service through HTTP or HTTPS with authentication provided by GRID certificates and authorization through VOMS. DBS {{is an integral part}} of the overall CMS Data Management and Workflow Management systems...|$|R
40|$|The Logging and <b>Bookkeeping</b> <b>service</b> tracks job {{passing through}} the Grid. It col-lects {{important}} events generated by both the grid middleware components and ap-plications, and processes them at a chosen L&B server to provide the job state. The events are transported through secure reliable channels. Job tracking is fully distributed and {{does not depend on}} a single information source, the robustness is achieved through speculative job state computation in case of reordered, delayed or lost events. The state computation is easily adaptable to modified job control flow. The events are also passed to the related Job Provenance (JP) service. Its purpose is a long-term storage of information on job execution, environment, and the exe-cutable and input sandbox files. The data can be used for debugging, post-mortem analysis, or re-running jobs. The data are kept by the job-provenance storage service in a compressed format, accessible on per-job basis. A complementary index service is able to find particular jobs according to configurable criteria, e. g. submission time or "tags " assigned by the user...|$|R
40|$|Abstract—This paper {{describes}} {{a new direction}} in the develop-ment of the Logging and <b>Bookkeeping</b> <b>service,</b> a gLite component tracking job life cycles in high performance computing grids. From its early days, Logging and Bookkeeping is used to track not only jobs themselves, but also the wider details of the job execution environment. Since {{a large portion of}} the grid infrastructure is now virtualized, the work at hand concerns tracking the virtualized nature of that runtime environment. With virtualization and cloud technologies being highly flexible and dynamic, the authors believe that it is very important to gather and keep status information for virtual machines used to run the workload. A newly defined monitoring entity – a virtual machine – is integrated with job state information and provides an enhanced view of the current state and history of both the computing job and the underlying infrastructure, as well as their mutual relationship. This paper explains the motivation and discusses the architecture of the newly emerged solution for monitoring virtualized resources – uniquely – in the same context as the workload they are processing. Keywords-grid; cloud; virtualization; monitoring; relationship I...|$|R
40|$|The {{research}} {{was on the}} impact of bookkeeping on the survival and growth of small and medium enterprises. The study was motivated by the fact that new players enter the field each year and almost the same number leave. A similar trend has been like that from 2010 to 2013 at the Mutare Green Market complex. An in-depth review of the literature related to the aforementioned factors under study was carried out. Qualitative and quantitative research methods were used in gathering information. Administering of five interviews and thirty three Questionnaires were the techniques employed to gather data. Major findings were that small businesses at the Green Market Complex in Mutare kept business records, the majority of them use single entry bookkeeping system and that this bookkeeping practice were not effective in improving their survival and growth. The study recommends that the government should make it mandatory for SMEs to submit yearly financial statements, impart accounting skills to the SMEs through seminars and that the SMEs owners should take the initiative to get workshops done for them and outsource the <b>bookkeeping</b> <b>services...</b>|$|E
40|$|As the Internet {{begins to}} {{encompass}} {{a larger and}} more mobile set of devices, including our cars, portable phones, and sensing nodes, a major challenge lies in the integration of location information into the network architecture. Two trends in particular, increasing mobility of nodes and increasing density of network nodes, have led to discussions {{about the role of}} location at the network layer. First, mobile IP offers a network layer handoff to enable seamless communications while a node moves between different IP (sub-) networks. Second, geographic routing approaches are widely hailed as a solution to manage the complexity of routing tables, especially in large wireless networks. These services require in-network support for efficient deployment. While these mechanisms have first been proposed about a decade ago, they have so far shared the fate of many other network layer improvements such as multicast, IPv 6 addressing, etc. This lack of adoption has raised questions about the viability of evolving the current Internet architecture at the IP layer, and motivates this research for more groundbreaking architectural designs that are free of legacy IP constraints. Apart from network optimizations at the IP layer, the integration of location information will also support a set of novel applications. First, the internal network <b>bookkeeping</b> <b>services</b> for mobile communications can be extended to allow location tracking and location finding of large numbers of objects. This service will be useful for monitoring automotive traffic densities or implementing a lost-object-search function. Second, the availability of location-informatio...|$|E
40|$|This {{paper is}} the first report on a new {{direction}} {{in the development of}} the Logging and <b>Bookkeeping</b> <b>service,</b> a gLite component tracking grid job life cycle. From the early days, Logging and Bookkeeping tracks not only jobs themselves but also the wider details of the job execution environment. Since a great portion of the infrastructure is now virtualized, the work at hand concerns tracking the virtualized nature of that runtime environment. With virtualization and cloud technologies being highly flexible and dynamic, we believe it is very important to gather and keep status information for machines used to run the workload. A newly created monitoring entity (a machine) will be integrated with job state information and provide an enhanced view of the current state and history of both the job and the infrastructure. This paper focuses on motivation, requirements coming from the Czech National Grid Initiative and possible consequences rather than the actual implementation. As a report on ``work in progress'' it describes an idea that is now being further elaborated and implemented to provide a solution for monitoring virtualized resources in the same context as the workload they are processing...|$|R
40|$|The CMS {{experiment}} has {{implemented a}} flexible and powerful system enabling users to find data within the CMS physics data catalog. The Dataset <b>Bookkeeping</b> <b>Service</b> (DBS) comprises a database and the services used to store and access metadata related to CMS physics data. To this, we have added a generalized query system {{in addition to}} the existing web and programmatic interfaces to the DBS. This query system is based on a query language that hides the complexity of the underlying database structure by discovering the join conditions between database tables. This provides a way of querying the system that is simple and straightforward for CMS data managers and physicists to use without requiring knowledge of the database tables or keys. The DBS Query Language uses the ANTLR tool to build the input query parser and tokenizer, followed by a query builder that uses a graph representation of the DBS schema to construct the SQL query sent to underlying database. We will describe the design of the query system, provide details of the language components and overview of how this component fits into the overall data discovery system architecture...|$|R
50|$|During {{this time}} Giant {{computerized}} its inventory data, customer information, and payroll and <b>bookkeeping</b> operations. Customer <b>service</b> features {{added in the}} 1950s included self-opening doors, mechanized checkouts, and open display cases to make meats and frozen food directly accessible to the customer.|$|R
50|$|The company {{provided}} accounting <b>services</b> like <b>bookkeeping</b> and write-up <b>services,</b> financial forecast, {{cash flow}} & budgeting analysis and financial statements. Others include tax planning and preparations, auditing services and IRS presentation. It focused on consulting services on accounting automation system, estate and business planning, and fraud detection and prevention.|$|R
40|$|The {{client-server}} architecture is used widely throughout complex software systems, but {{is susceptible to}} the problem of fate sharing between its various internal components. Fate sharing is bad because the malfunction of the server can lead to incorrect behavior of the client. We have narrowed down the primary cause of such fate sharing to state spill, a phenomenon in which a server entity holds client-specific state after serving the client’s request, tightly binding the two entities’ fates. The problem is exacerbated when multiple clients utilized the same server, because it effectively binds all clients’ fates together as well. In this work, we propose DRILL, a solution that mitigates the effects of fate sharing in server-like entities by using fine-grained checkpoint and restore (C/R) techniques to reduce state spill. We describe the design of DRILL within the context of Android system services — entities that control most system resources and act as middlemen between the kernel and applications — because they are a representative example of server entities that suffer from fate sharing due to state spill. DRILL attaches its C/R module to the system service to checkpoint and restore internal clients’ states in a per-object fashion. This module is service-agnostic and non-intrusive, which is generic and can be used for many system services without much modification. A special <b>bookkeeping</b> <b>service</b> preserves each service’s checkpointed states in an external storage area so that it can resend the states to a new service instance post-crash. To demonstrate the effectiveness of our approach, we implement DRILL on a Google Nexus 5 phone running Android 6. 0. 1 and apply our C/R technique to two different classes of Android system services. We show that DRILL can successfully restore a failed system service to its pre-crash state, keeping the application blissfully unaware of any service crashes because its fate is decoupled from that of the service. Our results indicate that the performance overhead and service downtime of our approach are affordable and that the limitations of the DRILL design do not restrict it from being applied to other systems beyond Android...|$|R
40|$|Eugene Fama's {{influential}} {{argument that}} the price level and real allocations are independent of the volume and composition of private financial portfolios, including bank deposits, is examined. An incomplete analysis {{of the role of}} financial assets leads to a failure to distinguish between real <b>bookkeeping</b> or accounting <b>services</b> of cash or bank deposits, which are separable from portfolio compositions, and their real settlement services, which are not. This failure undermines the policy conclusions that control of the monetary base is sufficient to control the price level and that banks and related financial intermediaries stand in no need of special regulation. Copyright 1988 by Royal Economic Society. ...|$|R
30|$|From Table  4, {{the summary}} of respondent’s {{views about the}} {{outsourcing}} (subcontracting) {{of one or more}} of back office activities such as security <b>services,</b> cleaning <b>services,</b> <b>bookkeeping,</b> payroll, billing, order processing, payment processing, others are categorized based on SMEs area of operation. The distribution revealed that 34 (16 %) respondents strongly disagreed to the assertion that they have outsourced supporting activities within the past five years. Also, 67 (31 %) disagreed while 37 (17 %) are neutral. However, 38 (17 %) agreed to the assertion that they have outsourced supporting activities within the past five years. Also 42 (19 %) strongly agreed. This result shows that, not all SMEs outsource their back office activities; only a small percentage does.|$|R
40|$|Short overview: Both Grid {{middleware}} {{services and}} applications face failures, {{and the more}} widely deployed they are, the higher is the price for not detecting the failures early (lost jobs, wasted resources [...] .). Automated detection, diagnosis, and ultimately management, of software/hardware problems define autonomic dependability. This work report on a generic mechanism for autonomic detection of EGEE failures involving abrupt changes in the behaviour of quantities of interest, and on some applications. Analysis: The complexity of the hardware/software components, and the intricacy of their interactions, defeat attempts to build fault models only from a-priori knowledge. A black-box approach, where we observe the events to spot outliers, is appealing by its simplicity, and large body of experience in quality control. The general challenge is to detect anomalies as soon as possible. Much better solutions than simple thresholding are routinely used in e. g. clinical trials and the supervision of production lines. In the case of abrupt changes, the Page-Hinkley statistics provides a provably efficient method, which minimizes the time to detection for a prescribed false alarm rate. We have applied this method to quantities (e. g. number of arrived and served jobs per unit of time) that are easily computed from the output of existing services. The main result {{is that we are}} able to efficiently detect failures of very different origins (e. g. some software bugs, blackholes) without human tuning. Impact: Fast and reliable detection of failures can both raise alarms bringing operator intervention, as well as trigger automatic reaction, e. g. avoid job submission to blackhole sites. The proposed method is quite general, and can be applied at various points in the middleware, including the site level, or by end-user software. Nonetheless, gLite Logging and <b>Bookkeeping</b> <b>service,</b> which concentrates information on the job processing, would be the most effective target. The approach of affecting job scheduling by LB-computed statistics had been used before. Experimental validation and comparison is thus desirable: a significant dataset of “challenge examples” should be available. Examples tagged by system administrators are rare. The Job Provenance (archive of LB data and more) provides the required information from two aspects: easy access to filtered L&B data, and valuable information for calibrating and evaluating failure detection methods wrt. known and well-understood past events. Conclusions: The implementation of the statistics per-se is fairly straightforward. The codes for exploiting the test on archived data, including both the extraction of the quantities of interest and the test itself, will be released through the Grid Observatory, in order to demonstrate the performance and scalability levels required for the production environment. Full integration into gLite raises the usual technical issues, and appropriate tools (triggering alarms etc.) remain to be developed...|$|R
40|$|Scientific {{applications}} on the Grid are in {{most cases}} heavily data-dependent. Therefore, improving scheduling decisions based on the co-allocation of data and jobs becomes a primary issue. Hence, {{it is crucial to}} analyse the behaviour of existing data management systems in order to provide accurate information for decision-making middlewares in a scalable way. We show current research issues in understanding the behaviour of data management systems on the petascale to improve Grid performance. We analyse the Distributed Data Management system Don Quijote 2 (DQ 2) of the High- Energy Physics experiment ATLAS at CERN. ATLAS presents unprecedented data transfer and data storage requirements on the petascale and DQ 2 was built to fulfill these requirements. DQ 2 is built upon the EGEE infrastructure, while seamlessly enabling interoperability with the American OSG and the Scandinavian NorduGrid infrastructures. Thus it serves as a relevant production-quality system to analyse aspects of dataflow behaviour in the petascale. Controlled data transfers are analysed using the central DQ 2 <b>bookkeeping</b> <b>service</b> and an external monitoring dashboard, provided by ARDA. However monitoring dynamic data transfers of jobs and enduser data transfers cannot happen centrally because there is no single point of reference. Therefore we provide opportunistic clients tools for all scientists to access, query and modify data. Those tools report the needed usage information in a non-intrusive, scalable way. We characterise three areas for improvement of dataflow. First, controlled data transfers issued by experiment operators or Gridsite operators. This is constant data export from the experiment to distributed computing facilities, mostly defined by experiment computing models. Second, dynamic data transfers issued by jobs on a Gridsite. Those production jobs may need to access data that is only available on remote sites. Third, uncontrolled data transfers issued by end-users; scientists fetching data for direct analysis. We argue that on the petascale complete replication of files is not a suitable option anymore as there is too much data and that erratic and unpredictable data movements are the norm. Furthermore it is important to value the relevance of certain data with respect to time to find useful data on the Grid. Our model derives those usage patterns implicitly. Therefore global data movement and usage patterns on data {{must be taken into account}} when doing job/data co-allocation. The objective of reasonable organisation of scientific data on the Grid is not a new one. Already, many approaches especially in file replication show good improvements. We argue though that once we approach petascale, low-level file reorganisation is not sufficient anymore and a global view of Grid dataflow must be taken into account. We provide a preliminary model and its accompanying tools to understand erratic and unpredictable dataflows and show their usefulness in the production EGEE Grid...|$|R
40|$|In the {{agri-food}} sector the SMEs demand more efficiences in marketing, logistics, production planning and controlling, <b>bookkeeping</b> and information <b>services.</b> For these tasks they need correct information in {{any time and}} anywhere. The best solution can be an integrated information system, an ERP system. The tendency is that these types of organization introduce ERP system successfully. It can give a flexible solution, enabling us to meet and exceed our business requirements. The introduction of a computerized information system, similarly to any other investment requires pre- and post calculations for the economic efficiency, repayment and efficacy of the fixed assets and if possible for its profitability as well. In small enterprises human resources are restricted. For this reason project analyse are neglected {{in most of the}} cases. The SMEs and ERP dealer need tools for selecting the right system and evaluate the investment...|$|R
