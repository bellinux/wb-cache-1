27|73|Public
5000|$|... #Subtitle level 2: <b>Batch</b> <b>filter</b> press {{versus a}} {{continuous}} {{vacuum belt filter}} ...|$|E
50|$|In {{terms of}} cake handling, <b>batch</b> <b>filter</b> press {{requires}} large discharge tray size {{in order to}} contain large amount of cake and the system is more expensive compared to continuous filter press with the same output.|$|E
40|$|Orbit {{determination}} {{techniques used}} during the highly successful flight of Mariner 10 to Venus and Mercury are presented. Comparisons are made between different data sets, different sets of parameters, and between a conventional least squares <b>batch</b> <b>filter</b> and a sequential <b>batch</b> <b>filter</b> and smoother that was designed for this mission. The sequential filter was able to account for small spacecraft forces that the <b>batch</b> <b>filter</b> was unable to handle effectively, and hence, contributed greatly to the mission success. The sequential filter and smoother design is given as well as results for each phase of the mission. ...|$|E
40|$|We {{applied a}} multi-class k-nearest-neighbor based text {{classification}} algorithm to the adaptive and <b>batch</b> <b>filtering</b> {{problems in the}} TREC 9 filtering track. While our systems performed well in the <b>batch</b> <b>filtering</b> tasks, they did not perform {{as well in the}} adaptive filtering tasks, in part because we did not have an adequate mechanism for taking advantage of the relevance feedback information provided by the filtering tasks. Since TREC- 9, we have made considerable improvements in our <b>batch</b> <b>filtering</b> results and discovered some serious problems with both the T 9 P and T 9 U metrics. In this paper, we discuss these issues and their impact on our filtering results...|$|R
50|$|Pushers offer higher {{processing}} capacities than <b>batch</b> <b>filtering</b> centrifuges such as vertical {{basket and}} inverting filter.|$|R
40|$|Oracle’s {{objective}} in TREC- 10 was {{to study the}} behavior of Oracle information retrieval in previously unexplored application areas. The software used was Oracle 9 i Text[1], Oracle’s full-text retrieval engine integrated with the Oracle relational database management system, and the Oracle PL/SQL procedural programming language. Runs were submitted in filtering and Q/A tracks. For the filtering track we submitted three runs, in adaptive <b>filtering,</b> <b>batch</b> <b>filtering</b> and routing. By comparing the TREC results, {{we found that the}} concepts (themes) extracted by Oracle Text can be used to aggregate document information content to simplify statistical processing. Oracle's Q/A system integrated information retrieval (IR) and information extraction (IE). The Q/A system relied on a combination of document and sentence ranking in IR, named entity tagging in IE and shallow parsing based classification of questions into pre-defined categories. 1. Filtering based on Theme Signature As a first time filtering track participant, Oracle submitted runs for adaptive <b>filtering,</b> <b>batch</b> <b>filtering</b> and routing this year. Only linear-utility optimized runs were submitted for adaptive <b>filtering</b> and <b>batch</b> <b>filtering.</b> The filtering system is built based on the Oracle 9 i database with PL/SQL- an Oracle supported database access language. Since the routing sub-task outputs the top 1000 ranked documents per category, and the training process and similarity score calculation algorithm are the same for <b>batch</b> <b>filtering</b> and routing, we will focus our discussion on <b>batch</b> <b>filtering</b> and adaptive filtering. The filtering system can be divided into three parts based on functionality...|$|R
40|$|The {{main purpose}} of the current {{research}} is to introduce the alternative algorithm of the non-recursive <b>batch</b> <b>filter</b> based on the unscented transformation in which the linearization process is unnecessary. The presented algorithm is applied to the orbit determination of a low earth orbiting satellite and compared its results with those of the well-known Bayesian batch least squares estimation and the iterative UKF smoother (IUKS). The system dynamic equations consist of the Earth`s geo-potential, the atmospheric drag, solar radiation pressure and the lunar/solar gravitational perturbations. The range, azimuth and elevation angles of the satellite measured from ground stations are used for orbit determination. The characteristics of the non recursive unscented <b>batch</b> <b>filter</b> are analyzed for various aspects, including accuracy of the determined orbit, sensitivity to the initial uncertainty, measurement noise and stability performance in a realistic dynamic system and measurement model. As a result, under large non-linear conditions, the presented non-recursive <b>batch</b> <b>filter</b> yields more accurate results than the other batch filters about 5 % for initial uncertainty test and 12 % for measurement noise test. Moreover, the presented filter exhibits better convergence reliability than the Bayesian least squares. Hence, it is concluded that the non-recursive <b>batch</b> <b>filter</b> based on the unscented transformation is effectively applicable for highly nonlinear batch estimation problems...|$|E
40|$|A <b>batch</b> <b>filter</b> {{has been}} {{designed}} to autonomously estimate the orbit of a LEO spacecraft using data only from a magnetometer and a sun sensor. The goal of this study has been to prove the feasibility of a proposed low-cost, moderate-accuracy autonomous orbit determination system. The system uses a <b>batch</b> <b>filter</b> to estimate the Keplerian orbital parameters, a drag parameter, magnetometer biases, and corrections to the Earth's magnetic field. It does this by minimizing the square errors between measured and estimated values of two quantities, the Earth's magnetic field magnitude and the cosine of the angle between the sun vector and the Earth's magnetic field vector, both measured at the spacecraft. The proposed system is observable, and reasonable accuracy is obtainable. Given a magnetometer with a 10 nT 1 -σ accuracy and a sun sensor with a 0. 005 o 1 -σ accuracy, the system can achieve 1 -σ position accuracies on the order of 500 m for inclined LEO orbits...|$|E
40|$|The use is {{described}} of a sequential least squares filter in the orbit determination for the Mariner Venus-Mercury (Mariner 10) spacecraft. The orbit determination strategy outlining {{the use of}} both the sequential filter and a conventional <b>batch</b> <b>filter</b> is given. Highlighted are the mission events from launch to the first Mercury encounter with emphasis on the sequential filter performance. Advantages to the mission derived from the sequential filter are pointed out...|$|E
5000|$|... 25. Reporting latency. Because server {{log files}} must be <b>batched,</b> <b>filtered,</b> and {{transferred}} to a database for reporting, significant delays exist before reporting data is available.|$|R
40|$|The TREC- 10 ltering track {{measures}} {{the ability of}} systems to build persistent user profiles which successfully separate relevant and non-relevant documents. It consists of three major subtasks: adaptive <b>filtering,</b> <b>batch</b> <b>filtering,</b> and routing. In adaptive filtering, the system begins with only a topic statement and {{a small number of}} positive examples, and must learn a better profile from on-line feedback. <b>Batch</b> <b>filtering</b> and routing are more traditional machine learning tasks where the system begins with a large sample of evaluated training documents. This report describes the track, presents some evaluation results, and provides a general commentary on lessons learned from this year's track...|$|R
40|$|The TREC- 8 {{filtering}} track {{measures the}} ability of systems to build persistent user profiles which successfully separate relevant and non-relevant documents. It consists of three major subtasks: adaptive <b>filtering,</b> <b>batch</b> <b>filtering,</b> and routing. In adaptive filtering, the system begins with only a topic statement and must learn a better profile from on-line feedback. <b>Batch</b> <b>filtering</b> and routing are more traditional machine learning tasks where the system begins with a large sample of evaluated training documents. This report describes the track, presents the evaluation results in graphical format, and provides a general commentary on lessons learned from this year's track. 1 Introduction A text filtering system sifts through a stream of arriving information to find documents relevant {{to a set of}} user profiles. Unlike the traditional search query, user profiles are persistent, and tend to reflect a long term information need. With user feedback, the system can learn a better pro [...] ...|$|R
40|$|The worst error {{performance}} of the sequential filter is compared with the {{performance of}} the <b>batch</b> <b>filter</b> which is still in general use in the deep space tracking. An approach phase of a spacecraft on a typical mission to the planet Mars is considered. The estimated parameters include the position and the speed of the spacecraft, nongravitational acceleration acting on the spacecraft, and the locations of the tracking stations...|$|E
40|$|A {{combined}} algorithm {{which has}} global and local optimization capabilities {{is applied to}} a statistical orbit determination problem. The objective is to estimate initial states of a near-earth satellite nonlinear dynamical system, as well as unknown parameters, by using discrete observations. A particle swarm optimizer is the selected global search tool, and it {{is used in the}} first phase to obtain the preliminary results over a large searching space. A <b>batch</b> <b>filter</b> which has faster convergence and higher accuracy in local optimization is applied in the second phase to refine the preliminary results. The initial experimental results show that the combined algorithm has the potential to solve a statistical orbit determination problem. I...|$|E
40|$|The {{modelling}} {{relations and}} calibration {{techniques of the}} miniature analogue sun sensors, developed at Surrey Satellite Technology Limited (SSTL), are discussed in this paper. Two model equations, an algebraic model based on a multi-variable polynomial algebraic curve-fitting procedure and a physical model based on analytical geometry relations, were developed. Parameter sensitivity analyses were conducted for the physical model, and an in-orbit calibration approach is proposed and was implemented with the sun sensors on-board UoSAT- 12 and Tsinghua- 1. A sequential <b>batch</b> <b>filter</b> algorithm was developed, {{based on the principle}} of the least-square estimation for regression models, to handle the large amount of in-orbit data in a sequential way. Satisfactory performance improvements have been achieved through the in-orbit calibration analyses for both satellites...|$|E
40|$|For filtering, we {{participate}} in the sub-task of adaptive and <b>batch</b> <b>filtering.</b> Vector representation and computation are heavily applied in filtering procedure. Four runs have been submitted, which includes one T 10 SU and one T 10 F run for adpative filtering, as well as another one T 10 SU and one T 10 F run for <b>batch</b> <b>filtering.</b> We have tried many natural language processing techniques in our QA system, including statistical sentence breaking, POS tagging, parsing, name entity tagging, chunking and semantic verification. Various sources of world knowledge are also incorporated, such as WordNet and geographic information. For web retrieval, relevant document set is first created by an extended Boolean retrieval engine, and then reordered according to link information. Four runs with different combination of topic coverage and link information are submitted. On video track, We take part in both of the sub-tasks. In the task of shot boundary detection, we have submitted two runs with different parameters. In the task of video retrieval, we have submitted the results of 17 topics among all the topics. 1. Filtering Our research on filtering focuses on how to create the initial filtering profile and set the initial threshold...|$|R
40|$|In TREC- 8, we {{participated in}} {{automatic}} ad-hoc retrieval {{as well as}} the query and filtering tracks. The theme of our participation is `retrieval lists combination', and the technique is applied throughout our experiments to various degree. It is pointed out that our PIRCS system may be considered as a combination of probabilistic retrieval model and a language model approach. For adhoc, three types of experiments were done with short, medium and long queries as before. General approach is similar to TREC- 7, but combination of retrieval lists from different query types were used to boost effectiveness. For query track, we submitted one shortquery set, and performed retrieval for twenty one natural language query vairants. For filtering track, experiments for adaptive, <b>batch</b> <b>filtering,</b> and routing were performed. For adaptive, historical selected document list was used to train profile term weights and dynamically vary retrieval status value (rsv) threshold for deciding document selection during the course of <b>filtering.</b> For <b>batch</b> <b>filtering,</b> Financial Times FT 92 data was used to define 6 retrieval profiles whose results were combined based on coefficients trained via a genetic algorithm. Logistic regression transforms rsvs to probabilities. Routing was similarly done with additional training data obtained from non-FT collections and two additional profiles were defined and combined 1...|$|R
40|$|ABSTRACT This year at TREC 2002 we {{participated in}} the {{adaptive}} filtering sub-task of the filtering track with some models for training a Rocchio classifier. Results were poorer than average on the utility type measures. Using simple feature selection produced better than average results on an F-type measure. The key to our approach {{was the use of}} pseudojudgments, and an approach to threshold updating. We also {{participated in the}} <b>batch</b> <b>filtering</b> sub-task of the filtering track and investigated the use of rank based feature selection techniques in conjunction with a very simple classification rule. 1...|$|R
40|$|The Global Navigation Satellite System (GNSS) is a {{valuable}} tool for Earth and Atmospheric Science, as it not only provides position and attitude information for remote-sensing platforms, but its variety of radio signals may {{also be used to}} probe the atmosphere. This dissertation presents a set of projects that aim to improve several of these functions by employing model-based estimation techniques. The first algorithm addresses the issue of large uncertainties in the dynamic variations of signal observables due to refraction during Earth limbscanning. It pre-processes raw GNSS data with a Levenberg-Marquardt <b>batch</b> <b>filter,</b> and performs signal tracking with a Square-Root Extended Kalman Filter (SREKF) in a new type of combined phase-locked/delay-locked loop. This constitutes an alternate way for deducing meteorological conditions down to few metres from the terrestrial surface using GNSS signals. The second project estimates the attitude of a spinning sounding rocket carrying sensors for studying space weather. The GPS attitude determination problem for this rocket poses two major challenges that result from equipment limitations: Frequent signal data gaps due to telemetry bandwidth restrictions and only one antenna baseline vector with which to perform full, three-axis attitude determination. The first problem is circumvented by an adaptation of the algorithm from the first project, and the second by using another Levenberg-Marquardt <b>batch</b> <b>filter</b> that contains an Euler dynamics model. The last project combines refractive ray- tracing concepts and an SREKF, utilizing both ionosonde and GNSS signals, in order to solve for the parameters of a node-based profile of the ionosphere. In addition, a trust-region-reflective algorithm, a modern form of the LevenbergMarquardt algorithm, is used to extract electron content information from GNSS data to parameterize ionospheric irregularities resulting from an experiment that involves controlled heating of the ionosphere...|$|E
40|$|A <b>batch</b> <b>filter</b> {{has been}} {{designed}} and analyzed to autonomously determine the orbits of 2 spacecraft based on measurements of the relative position vector from one spacecraft to the other. This system provides a means for high-precision autonomous orbit determination for systems that cannot be dependent on signals from the GPS constellation or ground stations. The filter uses a time series of the inertiallyreferenced relative position vector, and it uses orbital dynamics models for the two spacecraft. It estimates the 6 -element orbital state vectors of both spacecraft along with a drag parameter for each one. The observability of this system is demonstrated in this proof-of-concept study, and the filter’s predicted position determination accuracy is analyzed {{for a number of}} situations. Position accuracies on the order of 1 m RMS are predicted for certain configurations...|$|E
40|$|Abstract — This paper {{investigates the}} use of {{statistical}} linearization to improve iterative non-linear least squares estimators. In particular, we look at improving long range stereo by filtering feature tracks from sequences of stereo pairs. A novel filter called the Iterated Sigma Point Kalman Filter (ISPKF) is developed from first principles; this filter is shown to achieve superior performance in terms of efficiency and accuracy {{when compared to the}} Extended Kalman Filter (EKF), Unscented Kalman Filter (UKF), and Gauss-Newton filter. We also compare the ISPKF to the optimal <b>Batch</b> <b>filter</b> and to a Gauss-Newton Smoothing filter. For the long range stereo problem the ISPKF comes closest to matching the performance of the full batch MLE estimator. Further, the ISPKF is demonstrated on real data in the context of modeling environment structure from long range stereo data. I...|$|E
40|$|CAS-ICT {{took part}} in the TREC conference for the second time this year and we {{undertook}} two tracks of TREC- 11. For filtering track, we have submitted results of all three subtasks. In adaptive filtering, we paid more attention to undetermined documents processing, profile building and adaptation. In <b>batch</b> <b>filtering</b> and routing, a centroid-based classifier is used with preprocessed samples. For Web track, we have submitted results of both two subtasks. Different factors are considered to improve the overall performance of our Web systems. This paper describes our methods in detail. Keywords: TREC- 11, Filtering, Web track 1...|$|R
40|$|Abstract We develop {{further the}} S-D {{threshold}} optimization method. Specifically, {{we deal with}} the bias problem introduced by receiving relevance judgements only for documents retrieved. The new approach estimates the parameters of the exponential-Gaussian score density model without using any relevance judgements. The standard expectation maximization (EM) method for resolving mixtures of distributions is used. In order {{to limit the number of}} documents that need to be buffered, we apply nonuniform document sampling, emphasizing the right tail (high scores) of the total score distribution. For learning filtering profiles, we present a version of Rocchio's method which is suitable and efficient for adaptive filtering. Its main new features are the initial query degradation and decay, while it is fully incremental in query updates and in calculating document score statistics. Initial query degradation eliminates gradually the contribution of the initial query as the number of relevant training documents increases. Decay considers relevant instances (documents and/or initial query) of the near past more heavily than those of the early past. This is achieved by the use of half-life, i. e. the age that a training instance must be before it is half as influential as a fresh one in training/updating a profile. All these new enhancements are consistent with the initial motivation of Rocchio's formula. We, moreover, use a form of term selection for all tasks (which in adaptive tasks is applied repeatedly), and query zoning for <b>batch</b> <b>filtering</b> and routing. 1 Introduction This paper describes the participation in the TREC 10 Filtering Track by researchers from the Katholieke Universiteit Nijmegen (KUN). We participated in all three subtasks: adaptive <b>filtering,</b> <b>batch</b> <b>filtering,</b> and routing. The description of the tasks and evaluation measures can be found in [10]. We have mainly used the FilterIt system for all but one routing run which was made by the lcs system. Table 1 summarizes the runs we submitted...|$|R
3000|$|... is the FIR filter gain {{determined}} using a given cost criterion. Note that {{a distinctive}} {{difference between the}} FIR with IIR filters is that only one nearest past measurement {{is used in the}} recursive IIR (Kalman) filter to provide the estimate, while the convolution-based <b>batch</b> FIR <b>filter</b> requires N most recent measurements.|$|R
40|$|An {{innovative}} {{orbit determination}} method which {{makes use of}} gravity gradients for Low-Earth-Orbiting satellites is proposed. The measurement principle of gravity gradiometry is briefly reviewed and the sources of measurement error are analyzed. An adaptive hybrid least squares <b>batch</b> <b>filter</b> based on linearization of the orbital equation and unscented transformation of the measurement equation is developed to estimate the orbital states and the measurement biases. The algorithm is tested with the actual flight data from the European Space Agency Gravity field and steady-state Ocean Circulation Explorer. The orbit determination results are compared with the GPS-derived orbits. The radial and cross-track position errors are {{on the order of}} tens of meters, whereas the along-track position error is over one order of magnitude larger. The gravity gradient based orbit determination method is promising for potential use in GPS-denied spacecraft navigation. Comment: 34 pages, 8 figure...|$|E
40|$|This paper {{describes}} {{a system for}} relative navigation and automated proximity operations for a microsatellite using continuous thrust propulsion and low-cost visible and infrared imagers. Image processing algorithms provide range, range rate, and spherical angle estimates relative to a target spacecraft using knowledge of the target spacecraft’s geometry. A differential correction <b>batch</b> <b>filter</b> is used to provide relative navigation and state estimation. These state estimates are used to provide input for the automated control of the chaser spacecraft via a Linear Quadratic Regulator. Propulsive maneuvers are accomplished via low-thrust, non-throttleable thrusters using pulse-width modulation and thrust vectoring. A waypoint logic controller is used to define intermediate goals to reach the final goal in order to limit operational risk from an error in estimation of the spacecraft’s relative state. The system is described and simulation test results are shown...|$|E
40|$|International audienceAn {{innovative}} {{orbit determination}} method which {{makes use of}} gravity gradients for Low-Earth-Orbit satellites is proposed. The measurement principle of gravity gradiometry is briefly reviewed and the sources of error are analyzed. An adaptive hybrid least squares <b>batch</b> <b>filter</b> based on linearization of the orbital equation and unscented transformation of the measurement equation is developed to estimate the orbital states and the measurement biases. The algorithm is tested with real flight data from the European Space Agency’s Gravity field and steady-state Ocean Circulation Explorer (GOCE). The orbit determination results are compared with the GPS derived orbits. The radial and cross-track position errors are {{on the order of}} tens of meters, whereas the along-track position error is over one order of magnitude larger. The gravity gradient based orbit determination method is promising for potential use in GPS-denied navigation and in outer space planetary exploration...|$|E
40|$|In this survey, {{the authors}} examine the {{trade-off}} between the unbiased, optimal, and in-between solutions in finite impulse response (FIR) filtering. Specifically, {{they refer to}} linear discrete real-time invariant state-space models with zero mean noise sources having arbitrary covariances (not obligatorily delta shaped) and distributions (not obligatorily Gaussian). They systematically analyse the following <b>batch</b> <b>filtering</b> algorithms: unbiased FIR (UFIR) subject to the unbiasedness condition, optimal FIR (OFIR) which minimises the mean square error (MSE), OFIR with embedded unbiasedness (EU) which minimises the MSE subject to the unbiasedness constraint, and optimal UFIR (OUFIR) which minimises the MSE in the UFIR estimate. Based on extensive investigations of the polynomial and harmonic models, the authors show that the OFIR-EU and OUFIR filters have higher immunity against errors in the noise statistics and better robustness against temporary model uncertainties than the OFIR and Kalman filters...|$|R
5000|$|...Test Method F662-86 (1992)e1 Standard Test Method for Measurement of Particle Count and Size Distribution in <b>Batch</b> Samples for <b>Filter</b> Evaluation Using an Electrical Resistance Particle Counter ...|$|R
40|$|In {{this paper}} an {{algorithm}} for orbit determination in deep space using only measurements of attitude and of {{line of sight}} of known celestial bodies is presented. Measurements are then processed using two different filters reconstructing part or the entire state vector: a <b>batch</b> least squares <b>filter</b> and a combination of <b>batch</b> and Kalman <b>filter.</b> The strategy {{and the effectiveness of}} the two filters are compared on two sample cases of interplanetary trajectory toward Mercury (inner part of the solar system) and toward Jupiter (outer part of the solar system) ...|$|R
40|$|This paper {{presents}} trajectory {{reconstruction of}} the ST- 9 sounding rocket experiment using the onboard IMU data and descent imagery. The raw IMU accelerometer measurements are first converted into inertial acceleration and then used in trajectory integration. The descent images are pre-processed using a map-matching algorithm and unique landmarks for each image are created. Using the converted IMU data and descent images, the result from dead-reckoning and the kinematic-fix approaches are first compared with the GPS measurements. Then, both the IMU data and landmarks are processed together using a batch least-squares filter and the position, velocity, stochastic acceleration, and camera orientation of each image are estimated. The reconstructed trajectory is compared with the GPS data and the corresponding formal uncertainties are presented. The result shows that IMU data and descent images processed with a <b>batch</b> <b>filter</b> algorithm provide the trajectory accuracy required for pin-point landing...|$|E
40|$|A {{discussion}} of the generation of the best estimate trajectory (BET) of the first Space Shuttle Orbiter entry flight is presented. The BET defines a time history of the state, attitude, and atmospheric relative parameters throughout the Shuttle entry from an altitude of approximately 183 km to rollout. The inertial parameters were estimated utilizing a weighted least squares <b>batch</b> <b>filter</b> algorithm. Spacecraft angular rate and acceleration data derived from the Inertial Measurement Unit were utilized to predict the state and attitude which was constrained in a weighted least squares process to fit external tracking data consisting of ground based S-band and C-band data. Refined spacecraft altitude and velocity during and post rollout were obtained by processing artificial altimeter and Doppler data. The BET generation process is discussed. Software and data interface discussions are included. The variables and coordinate systems utilized are defined. STS- 1 mission peculiar inputs are summarized. A listing {{of the contents of}} the actual BET is provided...|$|E
40|$|AbstractIn a {{pico-satellite}} {{with small}} volume, measurements from on-board three-axis magnetometer (TAM) are not accurate, {{as it can}} be easily disturbed by other electronic systems. To improve its accuracy, a scheme of compensation methods is introduced in this article. The scheme is based on an improved measurement model of pico-satellite TAM, and it mainly consists of three steps. First, in satellite design stage, several techniques are recommended to simplify the afterwards compensations. Then after satellite assembly, TAM ground tests and pre-launch calibration with least-square <b>batch</b> <b>filter</b> are introduced to improve magnetometer performance. At the end, a post-launch calibration with unscented Kalman filter (UKF) is implemented with in-orbit data. The compensation scheme is used in the development of Chinese pico-satellite ZDPS- 1 A made by Zhejiang University. Results show that with the introduced compensation scheme, the maximum error of ZDPS- 1 A TAM can be reduced from 80 mG to 6 mG (1 G= 10 − 4 T) ...|$|E
40|$|DigitalCommons@UMaine {{has seen}} it all with our Electronic Theses and Dissertations community: {{migrating}} content from a legacy site, <b>batch</b> loading, <b>filtering</b> content into other communities, building integrated workflows for multiple departments and finally realizing the goal of student/author direct postings. Our ETD {{is one of the}} most popular series in our institutional repository with great support along the way from the bepress team...|$|R
40|$|Introduction The Clairvoyance team {{participated in}} the Filtering Track, {{submitting}} two runs in the <b>Batch</b> <b>Filtering</b> category. While we have been exploring the question of both topic modeling and ensemble filter construction (as in our previous TREC filtering experiments [5]), we had one distinct objective this year, to explore the viability of monolithic filters in classification-like tasks. This is appropriate to our work, in part, because monolithic filters are a crucial starting point for ensemble filtering, {{and it is possible}} for them to contribute substantially in the ensemble approach. Our primary goal in experiments this year, thus, was to explore two issues in monolithic filter construction: (1) term count selection and (2) filter threshold optimization. In fact, our pre-TREC experiments were conducted in a brief period and we were unable to complete all the tests we had planned. Our official submissions reflect essentially our first, baseline results. They are overall poor i...|$|R
40|$|Introduction The tests we {{performed}} for TREC- 7 {{were focused on}} automatic ad hoc and filtering tasks. With regard to the automatic ad hoc task we assessed two query modification strategies. Both were based on blind relevance feedback processes. The first one carried on with the TREC 6 tests: new parameter values of the relevance backpropagation formulas have been tuned. On the other hand, we proposed a new query modification strategy that uses a text mining approach. Three runs were sent. We sent two runs for the relevance backpropagation strategy: one used long topics (titles, descriptions and narratives) {{and the other one}} used titles and descriptions. We sent one run for the text mining strategy using long topics. With regard to the filtering task, we sent runs in <b>batch</b> <b>filtering</b> and routing using both relevance backpropagation and gradient neural backpropagation. 2 Mercure model Mercure is an information retrieval system based on a connectionist approach an...|$|R
