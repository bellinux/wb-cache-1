241|74|Public
25|$|Action {{potentials}} {{initiated in}} the axon normally travel down the axon {{away from the}} soma. However, {{it is also possible}} for an action potential to travel in the opposite direction, invade the soma, and then travel down the dendrite as a dendritic spike. This retrograde signal provides information to the synapse that the neuron has fired an output. The efficacy of the signal varies among different neuronal types. For example, <b>backward</b> <b>propagation</b> of action potentials is very limited in cerebellar Purkinje cells but is quite prevalent in interneurons of the medium ganglionic layer of the cerebellum-like lobe of some fish.|$|E
2500|$|Dendritic spikes most {{commonly}} propagate backwards from the soma to distal dendritic branches. [...] <b>Backward</b> <b>propagation</b> serves {{a number of}} functions in the neuron. These functions vary based on the neuronal cell types. In general, backwards propagation serves to communicate output information to the post synaptic membrane. In many neurotransmitter releasing neurons, <b>backward</b> <b>propagation</b> of dendritic spikes signals the release of neurotransmitters. For example, Mitral cells seem to serve both as projection neurons and as local interneurons. If the axonal output of mitral cell is shut down by soma inhibition, local dendritic action potential causes the mitral cell to release neurotransmitters into the environment. <b>Backward</b> <b>propagation</b> of dendritic spikes has been demonstrated in various neuronal types in the brain but has rarely been studied outside of the brain. Other than neurons in the brain, dendritic spikes have been observed in the neurons of the spinal cord.|$|E
5000|$|Migration {{refers to}} this wave's <b>backward</b> <b>propagation.</b> The {{two-dimensional}} Fourier transform of the wave at depth [...] is given by: ...|$|E
40|$|In {{the field}} of water technology, forward {{uncertainty}} propagation is frequently used, whereas <b>backward</b> uncertainty <b>propagation</b> is rarely used. In forward uncertainty analysis, one moves from a given (or assumed) parameter subspace towards the corresponding distribution of the output or objective function. However, in the <b>backward</b> uncertainty <b>propagation,</b> one moves in the reverse direction, from the distribution function towards the parameter subspace. <b>Backward</b> uncertainty <b>propagation,</b> which is a generalisation of parameter estimation error analysis, gives information essential for designing experimental or monitoring programmes, and for tighter bounding of parameter uncertainty intervals. The procedure of carrying out <b>backward</b> uncertainty <b>propagation</b> is illustrated in this technical note by working example for an oxidation ditch wastewater treatment plant. Results obtained have demonstrated that essential information {{can be achieved by}} carrying out <b>backward</b> uncertainty <b>propagation</b> analysi...|$|R
40|$|The Liouville-space Green {{function}} formalism is used {{to compute}} the current density profile across a single molecule attached to electrodes. Time ordering is maintained in real, physical, time, avoiding the use of artificial time loops and <b>backward</b> <b>propagations.</b> Closed expressions for molecular currents, which only require DFT calculations for the isolated molecule, are derived to fourth order in the molecule/electrode coupling. Comment: 21 page...|$|R
50|$|In 2002, {{rather than}} using SRR-wire configuration, or other 3-D media, {{researchers}} looked at planar configurations that supported <b>backward</b> wave <b>propagation,</b> thus demonstrating negative refractive index and focusing as a consequence.|$|R
50|$|Dendritic spikes most {{commonly}} propagate backwards from the soma to distal dendritic branches. <b>Backward</b> <b>propagation</b> serves {{a number of}} functions in the neuron. These functions vary based on the neuronal cell types. In general, backwards propagation serves to communicate output information to the post synaptic membrane. In many neurotransmitter releasing neurons, <b>backward</b> <b>propagation</b> of dendritic spikes signals the release of neurotransmitters. For example, Mitral cells seem to serve both as projection neurons and as local interneurons. If the axonal output of mitral cell is shut down by soma inhibition, local dendritic action potential causes the mitral cell to release neurotransmitters into the environment. <b>Backward</b> <b>propagation</b> of dendritic spikes has been demonstrated in various neuronal types in the brain but has rarely been studied outside of the brain. Other than neurons in the brain, dendritic spikes have been observed in the neurons of the spinal cord.|$|E
50|$|<b>Backward</b> <b>propagation</b> {{predictions}} {{can be used}} {{to analyze}} the surface vibration patterns of acoustic radiators such as ultrasonic transducers. Forward propagation {{can be used to}} predict the influence of inhomogeneous, nonlinear media on acoustic transducer performance.|$|E
50|$|Technically it calculates the {{gradient}} of {{the loss}} function. It is commonly used in the gradient descent optimization algorithm. It is also called <b>backward</b> <b>propagation</b> of errors, because the error is calculated at the output and distributed back through the network layers.|$|E
5000|$|It can be {{seen that}} a {{negative}} index will occur for one polarization if κ > [...] In this case, it is not necessary that either or both εr and µr be negative for <b>backward</b> wave <b>propagation.</b>|$|R
40|$|This article {{proposes a}} {{framework}} {{to investigate the}} consequences of natural disasters. This framework {{is based on the}} disaggregation of Input-Output tables at the business level, through the representation of the regional economy as a network of production units. This framework accounts for (i) limits in business production capacity; (ii) forward propagations through input shortages; and (iii) <b>backward</b> <b>propagations</b> through decreases in demand. Adaptive behaviors are included, with the possibility for businesses to replace failed suppliers, entailing changes in the network structure. This framework suggests that disaster costs depend on the heterogeneity of losses and on the structure of the affected economic network. The model reproduces economic collapse, suggesting that it may help understand the difference between limited-consequenc...|$|R
40|$|We {{provide a}} new {{canonical}} approach for studying dissipation {{by considering the}} quantum mechanical damped harmonic oscillator. Explicit expressions for lagrangians characterising forward and <b>backward</b> time <b>propagations</b> are given. A hamiltonian analysis, showing the equivalence with the lagrangian approach, is also done...|$|R
50|$|The angular {{spectrum}} {{method is}} a technique for modeling the propagation of a wave field. This technique involves expanding a complex wave field into a summation of infinite number of plane waves. Its mathematical origins lie {{in the field of}} Fourier Optics but it has been applied extensively in the field of ultrasound. The technique can predict an acoustic pressure field distribution over a plane, based upon knowledge of the pressure field distribution at a parallel plane. Predictions in both the forward and <b>backward</b> <b>propagation</b> directions are possible.|$|E
50|$|Action {{potentials}} {{initiated in}} the axon normally travel down the axon {{away from the}} soma. However, {{it is also possible}} for an action potential to travel in the opposite direction, invade the soma, and then travel down the dendrite as a dendritic spike. This retrograde signal provides information to the synapse that the neuron has fired an output. The efficacy of the signal varies among different neuronal types. For example, <b>backward</b> <b>propagation</b> of action potentials is very limited in cerebellar Purkinje cells but is quite prevalent in interneurons of the medium ganglionic layer of the cerebellum-like lobe of some fish.|$|E
5000|$|The {{response}} of the Fabry-Pérot resonator to an electric field incident upon mirror 1 is described by several Airy distributions (named after the mathematician and astronomer George Biddell Airy) that quantify the light intensity in forward or <b>backward</b> <b>propagation</b> direction at different positions inside or outside the resonator with respect to either the launched or incident light intensity. The {{response of}} the Fabry-Pérot resonator is most easily derived by use of the circulating-field approach. This approach assumes a steady state and relates the various electric fields to each other (see figure [...] "Electric fields in a Fabry-Pérot resonator").|$|E
40|$|Space-time {{modulation}} induced non-reciprocity in EM metasurfaces {{is proposed}} and numerically demonstrated using rigorous Generalized Sheet Transitions Conditions (GSTCs) under oblique plane-wave incidence. It is phenomenologically {{shown that the}} space-time modulation of surface susceptibilities create an inherent asymmetry {{with respect to the}} directional perturbation on the metasurface and the transverse wave momentum of the input wave, between forward and <b>backward</b> <b>propagations,</b> resulting in non-reciprocal wave transmission. Exploiting the periodicity of the surface susceptibilities in both time and space, Floquet mode expansion method is used to rigorously compute the scattered fields from, inherently dispersive metasurfaces, by solving GSTCs in combination with causal Lorentzian surface susceptibilities. Various harmonic solutions are shown and the non-reciprocal wave transmission has been confirmed under oblique plane-wave incidence. Comment: 6 pages, 6 figure...|$|R
40|$|In this paper, the {{reduction}} with a scaling strategy from Hessenberg matrix to Frobenius-like form is given. An estimation of <b>backward</b> error <b>propagation</b> and numerical tests demonstrate that {{the reduction}} to Frobenius-like form and the operation on quasi-Routh array are numerically stable {{and they can be}} addressed for numerical determination of matrix stability...|$|R
40|$|Various {{methods have}} been {{proposed}} {{in an attempt to}} solve problems in artifact and/or alarm identification including expert systems, statistical signal processing techniques, and artificial neural networks (ANN). ANNs consist {{of a large number of}} simple processing units connected by weighted links. To develop truly robust ANNs, investigators are required to train their networks on huge training data sets, requiring enormous computing power. We implemented a parallel version of the <b>backward</b> error <b>propagation</b> neural network training algorithm in the widely portable parallel programming language C-Linda. A maximum speedup of 4. 06 was obtained with six processors. This speedup represents a reduction in total run-time from approximately 6. 4 hours to 1. 5 hours. We conclude that use of the master-worker model of parallel computation is an excellent method for obtaining speedups in the <b>backward</b> error <b>propagation</b> neural network training algorithm...|$|R
5000|$|... #Caption: Electric {{fields in}} a Fabry-Pérot resonator. The electric-field mirror reflectivities are [...] and [...] Indicated are the {{characteristic}} electric fields produced by an electric field [...] incident upon mirror 1: [...] initially reflected at mirror 1, [...] launched through mirror 1, [...] and [...] circulating inside the resonator in forward and <b>backward</b> <b>propagation</b> direction, respectively, [...] propagating inside the resonator after one round trip, [...] transmitted through mirror 2, [...] transmitted through mirror 1, {{and the total}} field [...] propagating backward. Interference occurs at the left- and right-hand sides of mirror 1 between [...] and , resulting in , and between [...] and , resulting in , respectively.|$|E
50|$|With {{the advent}} of the digital computer, stock market {{prediction}} has since moved into the technological realm. The most prominent technique involves the use of artificial neural networks (ANNs) and Genetic Algorithms. Scholars found bacterial chemotaxis optimization method may perform better than GA. ANNs {{can be thought of as}} mathematical function approximators. The most common form of ANN in use for stock market prediction is the feed forward network utilizing the <b>backward</b> <b>propagation</b> of errors algorithm to update the network weights. These networks are commonly referred to as Backpropagation networks. Another form of ANN that is more appropriate for stock prediction is the time recurrent neural network (RNN) or time delay neural network (TDNN). Examples of RNN and TDNN are the Elman, Jordan, and Elman-Jordan networks. (See the Elman And Jordan Networks)..|$|E
50|$|Connectionist network {{differs from}} {{computational}} modeling specifically because of two functions: neural back-propagation and parallel-processing. Neural back-propagation {{is a method}} utilized by connectionist network to show evidence of learning. After a connectionist network produce a response, the stimulated results are compared to real-life situational results. The feedback provided by the <b>backward</b> <b>propagation</b> of errors {{would be used to}} improve accuracy for the network’s subsequent responses. The second function, parallel-processing, stemmed from the belief that knowledge and perception are not limited to specific modules but rather are distributed throughout the cognitive networks. The present of parallel distributed processing has been shown in psychological demonstrations like the Stroop effect, where the brain seems to be analyzing the perception of color and meaning of language at the same time. However, this theoretical approach has been continually disproved because the two cognitive functions for color-perception and word-forming are operating separately and simultaneously, not parallel of each other.|$|E
40|$|We {{describe}} {{a method of}} using Genetic Algorithms for training multi-layer perceptron neworks in which the chromosomes encode "rules" for changing the network weights rather than the weights themselves. The genetic operators of crossover, selection and mutation are used to generate new rules which are then applied to the weight matrix. The approach is significantly better than other approaches to training networks using genetic algorithms and successfully solves a number of benchmark problems which {{are known to be}} difficult for <b>backward</b> error <b>propagation.</b> 1 Introduction The determination of the weights of a multi-layer perceptron is fundamentally a multi-dimensional search problem. <b>Backward</b> error <b>propagation</b> and its variants are currently the most common methods for searching for an optimal point in weight space. However, genetic algorithms provide an alternative method for implementing search [4]. The genetic algorithm approach involves encoding potential solutions as bit stings of [...] ...|$|R
40|$|Computing {{response}} functions {{by following}} the time evolution of superoperators in Liouville space (whose vectors are ordinary Hilbert space operators) offers an attractive alternative to the diagrammatic perturbative expansion of many-body equilibrium and nonequilibrium Green functions. The bookkeeping of time ordering is naturally maintained in real (physical) time, allowing the formulation of Wick’s theorem for superoperators, giving a factorization of higher order response functions in terms of two fundamental Green’s functions. <b>Backward</b> <b>propagations</b> and the analytic continuations using artificial times (Keldysh loops and Matsubara contours) are avoided. A generating functional for nonlinear response functions unifies quantum field theory and the classical mode coupling formalism of nonlinear hydrodynamics and {{may be used for}} semiclassical expansions. Classical response functions are obtained without the explicit computation of stability matrices. Pacs numbers: 05. 30. − d, 05. 20. Jj, 42. 65 + k, 11. 10. − z 1 I...|$|R
30|$|The connectional weights {{are updated}} during the <b>backward</b> error <b>propagation</b> {{according}} to the learning algorithm. This process is repeated until the error between the network output and desired output (radar measurements) meets the prescribed requirement. When the training process is complete, the network is ready for application. Rainfall identification can be obtained if SEVIRI data are applied to the network at this stage.|$|R
40|$|Three-phase {{power flow}} for {{unbalance}} distribution system {{is carried out}} using forward- <b>backward</b> <b>propagation</b> technique. The equivalent injection current method is employed to represent the loads and shunt admittances. The algorithm starts with mapping the distribution network to determine the forward and <b>backward</b> <b>propagation</b> paths. The <b>backward</b> <b>propagation</b> {{is used to calculate}} branch currents using the bus injection currents. The forward propagation is employed to calculate bus voltages using the obtained branch currents and line impedances. The algorithm offers robust and good convergence characteristics for radial distribution system. The algorithm is presented for the IEEE 34 - bus system. The unbalance level of the system is also analysed...|$|E
40|$|We present highly {{efficient}} algorithms for performing forward and <b>backward</b> <b>propagation</b> of Convolutional Neural Network (CNN) for pixelwise classification on images. For pixelwise classification tasks, such as image segmentation and object detection, surrounding image patches are fed into CNN for predicting the classes of centered pixels via forward propagation and for updating CNN parameters via <b>backward</b> <b>propagation.</b> However, forward and <b>backward</b> <b>propagation</b> was originally designed for whole-image classification. Directly applying it to pixelwise classification in a patch-by-patch scanning manner is extremely inefficient, because surrounding patches of pixels have large overlaps, {{which lead to}} a lot of redundant computation. The proposed algorithms eliminate all the redundant computation in convolution and pooling on images by introducing novel d-regularly sparse kernels. It generates exactly the same results as those by patch-by-patch scanning. Convolution and pooling operations with such kernels are able to continuously access memory and can run efficiently on GPUs. A fraction of patches of interest can be chosen from each training image for <b>backward</b> <b>propagation</b> by applying a mask to the error map at the last CNN layer. Its computation complexity is constant with respect to the number of patches sampled from the image. Experiments have shown that our proposed algorithms speed up commonly used patch-by-patch scanning over 1500 times in both forward and <b>backward</b> <b>propagation.</b> The speedup increases with the sizes of images and patches...|$|E
40|$|Abstract: <b>Backward</b> <b>propagation</b> {{of output}} vectors through a combinational circuit {{lies at the}} core of many applications, {{including}} automatic test pattern generation (ATPG). This paper describes and evaluates an approach for the <b>backward</b> <b>propagation</b> using don’t care justification. This approach gets high performance due to large amounts of fine-grain parallelism in the implication process. The results of this new method are compared with HW implementation of the basic backtrace algorithm proposed recently. The experimental results have been obtained for the ISCAS’ 85 benchmarks...|$|E
50|$|The {{inherent}} {{parameters of}} the medium are the mass density ρ, bulk modulus β, and chirality k. Chirality, or handedness, determines the polarity of wave propagation (wave vector). Hence within the last equation, Veselago-type solutions (n2 = u*ε) are possible for wave propagation as the negative or positive state of ρ and β determine the forward or <b>backward</b> wave <b>propagation.</b>|$|R
30|$|The connectional weights {{are updated}} during the <b>backward</b> error <b>propagation</b> {{according}} to the learning algorithm. This process is repeated until the error between the network output and desired output (PR measurements) meets the prescribed requirement. When the training process is complete, the network is ready for application. Rainfall detection can be obtained if combining SEVIRI and TMI data are applied to the network at this stage. The details of the algorithm are described by (Azimi-Sadjadi and Liou 1992).|$|R
40|$|We {{show that}} {{there are two types of}} leaky modes in a left-handed slab (i) leaky slab modes which are always {{backward}} and (ii) leaky surface plasmons which may be forward or <b>backward.</b> The <b>propagation</b> direction of these modes are studied using complex plane analysis. The fact that slab modes are backward explains several previously reported results concerning lateral shifts. The complex plane analysis is shown to be particularly relevant for the study of this structure. ...|$|R
40|$|We {{present an}} {{alternative}} method {{based on the}} time-reversal process to locate faults in transmission line networks. The proposed procedure considers different media for the forward and the <b>backward</b> <b>propagation</b> phases. Specifically, the transverse branch representing the fault {{is removed from the}} circuit in the <b>backward</b> <b>propagation</b> since its location represents the solution of the process and, therefore, is not known in advance. The advantage of the proposed method is twofold. First, the proposed backward model requires only one simulation for the time-reversed <b>backward</b> <b>propagation</b> phase, thus reducing significantly the computational burden. Second, we demonstrate that this modified <b>backward</b> <b>propagation</b> medium satisfies a property such that the fault location can be identified by computing, in the frequency domain, the argument of the voltage along the line. The theory is first formulated for the case of a lossless homogeneous single-phase transmission line; then, its applicability is extended to lossy inhomogeneous transmission line networks. A single-phase inhomogeneous transmission line and an inhomogeneous Y-shape network are specifically considered to support this claim. We show that the proposed procedure can provide high fault location accuracy (i. e., in the range of ± 1 m), using only one observation point. Furthermore, we propose a criterion to link the bandwidth of the sampling system to the desired fault location accuracy...|$|E
40|$|This paper {{proposes a}} {{hierarchical}} internal constraint network and interval propagation techniques for automatic tolerance design. The nodes in interval constraint networks represent the entities, the attributes, and the functional {{requirements of the}} mechanical design or the constraint functions. The arcs represent {{the relationships between the}} entities, the attributes, the functional requirements and the constraint functions. We developed the forward propagation technique for tolerance analysis and the <b>backward</b> <b>propagation</b> technique for tolerance synthesis. In tolerance analysis, given the entity tolerances, the goal is to ensure that the functional requirement tolerances are met. In tolerance synthesis, given the functional requirement tolerances, the goal is to synthesize a new set of entity tolerances. In <b>backward</b> <b>propagation,</b> the minimization of the manufacturing cost is also considered. During <b>backward</b> <b>propagation,</b> the tolerances of entities, which have a smaller impact on manufacturing costs, will be tightened first. Using this mechanism, we ensure the constraints are satisfied and the manufacturing costs are minimized. published_or_final_versio...|$|E
30|$|We {{model the}} {{interaction}} between trains with a mechanism of propagation of delay from other trains to train i. The investigations performed on the datasets suggest that such interaction can occur only when nearby trains are in the <b>Backward</b> <b>propagation</b> configuration of Fig.  3.|$|E
40|$|In this paper, we numerically {{demonstrate}} a near-infrared negative-index metamaterial (NIM) slab consisting of {{multiple layers of}} perforated metal-dielectric stacks and exhibiting low imaginary part of index over the wavelength of negative refraction. The effective index is obtained using two different numerical methods and found to be consistent. <b>Backward</b> phase <b>propagation</b> is verified by calculation of fields inside the metamaterial. These results point to a new design of low loss thick metamaterial at optical frequencies. Comment: 18 page...|$|R
40|$|This paper {{presents}} an automatic relevance feedback method for improving retrieval accuracy in video database. We first demon-strate a representation {{based on a}} template-frequency model (TFM) that allows the full use of the temporal dimension. We then in-tegrate the TFM with a self-training neural network structure to adaptively capture different degrees of visual importance in a video sequence. Forward and <b>backward</b> signal <b>propagation</b> is the key in this automatic relevance feedback method {{in order to enhance}} re-trieval accuracy. 1...|$|R
40|$|We {{study the}} valence {{approximation}} in lattice QCD of hadrons where the cloud quarks and antiquarks are deleted by truncating the <b>backward</b> time <b>propagation</b> (Z graphs) in the connected insertions. Whereas, the sea quarks are eliminated via the quenched approximation {{and in the}} disconnected insertions. It is shown that the ratios of isovector to isoscalar matrix elements in the nucleon reproduce the SU(6) quark model predictions in a lattice QCD calculation. We also discuss how the hadron masses are affected. ...|$|R
