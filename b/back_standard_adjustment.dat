0|797|Public
40|$|This paper {{suggests}} {{a method of}} approximating the development of investment in transition economies through an amendment of the <b>standard</b> <b>adjustment</b> cost formulation for investment within dynamic Computable General Equilibrium (CGE) models. Letting adjustment cost depend on {{the difference between the}} investment levels of two periods (rather than only on the gross investment ratio) leads to an investment behavior of the representative household that resembles the observed time paths of investment in transition countries. In contrast to <b>standard</b> <b>adjustment</b> costs, which predict a sharp rise in investment due to the high marginal productivity of each unit of capital after a capital shock, augmented adjustment costs lead to a gradual rise in investment. Computable General Equilibrium Model,Transition,Adjustment Costs,Investment Behavior...|$|R
40|$|Public {{performance}} measurement systems rarely use formal performance <b>standards</b> <b>adjustment</b> procedures. After weighing {{the pros and}} cons and describing processes, the authors recommend how public sector {{performance measurement}} systems can be improved and argue this is a rich area for experimentation and academic research...|$|R
5000|$|Bass Drums: (22") PowerStroke 4 (w/Remo FalamSlam) - <b>back,</b> <b>Standard</b> Tama Head — front ...|$|R
40|$|Acemoglu, Johnson, Robinson, and Yared (2008) {{demonstrate}} that {{estimation of the}} <b>standard</b> <b>adjustment</b> model with country-fixed and time-fixed effects removes the statistical significance of income as a causal factor of democracy. We argue that their empirical approach must produce insignificant income effects and that a small change in the estimation process immediately reveals the strong effect of income on democracy. Democracy, Modernization hypothesis, fixed-effects estimation...|$|R
50|$|With the Minimal Supersymmetric <b>Standard</b> Model, <b>adjustment</b> of {{parameters}} {{can make}} this unification exact. This unification is not unique.|$|R
50|$|However, Timberlake {{does not}} reject the gold {{standard}}. While many economists blame {{the gold standard}} for the monetary collapse, Timberlake cites data that refutes the validity of their complaints. He shows that the Fed Banks and U.S. Treasury had plenty of gold in the 1929-1933 period. Timberlake concludes that government interference with gold <b>standard</b> <b>adjustments</b> caused most of the trouble in the past, producing cycles of money growth and deflation, panic and depression.|$|R
40|$|Abstract: A {{reduction}} in real wages arising from price liberalisation {{has been a}} standard feature of economies undergoing industrial restructuring. In this paper, the impact of real wages on industrial performance is examined using a panel dataset of Romanian industries from 1990 to 1996. Using both static and dynamic panel estimation, real wages are found not to be negatively associated with either output or employment. These {{results are consistent with}} a view that an institutionalist approach, aimed at improving productivity, {{may be more likely to}} achieve the long-term objective of successful industrial restructuring than <b>standard</b> <b>adjustment</b> programmes based on neo-classical theory. Have Lower Real Wages Helped Industrial Restructuring in Romania? Abstract: A {{reduction in}} real wages arising from price liberalisation has been a standard feature of economies undergoing industrial restructuring. In this paper, the impact of real wages on industrial performance is examined using a panel dataset of Romanian industries from 1990 to 1996. Using both static and dynamic panel estimation, real wages are found not to be negatively associated with either output or employment. These results are consistent with a view that an institutionalist approach, aimed at improving productivity, may be more likely to achieve the long-term objective of successful industrial restructuring than <b>standard</b> <b>adjustment</b> programmes based on neo-classical theory. 1...|$|R
40|$|Fuzzy gold <b>standard</b> <b>adjustment</b> {{is a novel}} {{fuzzy set}} theoretic {{pre-processing}} strategy that compensates for the possible imprecision of a well-established gold standard (reference test) by adjusting, if necessary, the class labels in the design set while maintaining the gold standard's discriminatory power. The adjusted gold standard incorporates robust withinclass centroid information. This strategy was applied to biomedical data acquired from a MR spectrometer {{for the purpose of}} classifying human brain neoplasms. It is shown that consistent improvement (10 - 13 %) to the discriminatory power of the underlying classifier i...|$|R
40|$|In India, {{year-on-year}} percentage {{changes of}} price indexes {{are widely used}} as the measure of inflation. In terms of monthly data, each observation of a one-year change in inflation {{is the sum of}} twelve one-month changes. This suggests that better information about inflationary pressures can be obtained using point-on-point monthly changes. This requires seasonal <b>adjustment.</b> <b>Standard</b> seasonal <b>adjustment</b> procedures are applied in order to obtain a point-on-point seasonally adjusted monthly time-series of inflation in India. [NIPFP WP No. 54]. percentage changes, price indexes, inflation, inflationary pressures, time series, India, seasonal <b>adjustment,</b> <b>standard,</b> monthly data, research, whole, WPI, economic survey, point on point, POP, methodology, dummy variable regrssion, robust, ARIMA, autocorrelation function, ACF...|$|R
50|$|Hi-MD units {{can play}} <b>back</b> <b>standard</b> MiniDiscs {{recorded}} in non-Hi-MD units, {{in addition to}} record on standard MiniDiscs and higher-capacity 1 GB Hi-MD discs. There are two user-selectable operational modes on Hi-MD units (which Sony calls Disc Modes): MD mode and Hi-MD mode.|$|R
40|$|A {{reduction}} in real wages arising from price liberalisation {{has been a}} standard feature of economies undergoing industrial restructuring. In this article, the impact of real wages on industrial performance is examined using a panel dataset of Romanian industries from 1990 - 96. Using both static and dynamic panel estimation, real wages are found not to be negatively associated with either output or employment. These {{results are consistent with}} a view that an institutionalist approach, aimed at improving productivity, {{may be more likely to}} achieve the long-term objective of successful industrial restructuring than <b>standard</b> <b>adjustment</b> programmes based on neo-classical theory. industrial restructuring, transition, Romania, panel data,...|$|R
40|$|This paper {{investigates the}} reasons why firms use {{fixed-term}} contracts. Two distinctive features of these contracts - reduced firing costs and the prohibition of contract rollover - are highlighted. Firms' decision related to temporary contracts - {{the choice of the}} contract on offer and contract conversion - are modeled within <b>standard</b> <b>adjustment</b> costs and matching settings. Regression analysis is performed on the stock of fixed-term contracts and the flows of temporary workers to permanent positions. Results from a beta-binomial regression model indicate that screening workers for permanent positions {{is the single most important}} reason why firms use this type of contract. Fixed-Term Contracts, Adjustment Costs, Temporary Employment...|$|R
40|$|This note {{provides}} a generalization of the <b>standard</b> <b>adjustment</b> cost-rational expectations model due to Sargent (1978), which, {{in addition to}} the cost of changing the level of the decision variable, also allows for the cost of altering the "speed" with which decisions are changed. It establishes the existence of a unique stable solution for this more general model, derives an explicit solution for the underlying decision problem, and {{provides a}} necessary order condition for identification of the structural parameters. The note also contains an application of the model to the determination of employment in the U. K. coal industry over the 1956 - 83 period. Copyright 1991 by MIT Press. ...|$|R
5000|$|In {{relation}} to the general observation that, in regression analysis, a fitted relationship appears to perform less well on a new data set than on the data set used for fitting. In particular {{the value of the}} coefficient of determination 'shrinks'. This idea is complementary to overfitting and, separately, to the <b>standard</b> <b>adjustment</b> made in the coefficient of determination to compensate for the subjunctive effects of further sampling, like controlling for the potential of new explanatory terms improving the model by chance: that is, the adjustment formula itself provides [...] "shrinkage." [...] But the adjustment formula yields an artificial shrinkage, in contrast to the first definition.|$|R
50|$|CommCare and CommCareHQ are {{released}} under the Apache v2.0 and BSD Licenses, respectively. The CommCare application {{is built on}} OpenRosa standard tools and protocols, and leverages many different open-source technologies. Protocols are represented using XForms a W3C <b>backed</b> <b>standard</b> approach to more advanced forms that support nested and repeatable elements, decision support, advanced validation, and extensive user interface controls.|$|R
40|$|The {{occupational}} {{skill structure}} {{depends on the}} business cycle if employers respond to shortages of applicants during upturns by lowering their hiring standards. Devereux uses this implication to construct empirical tests for the notion of hiring <b>standards</b> <b>adjustment</b> (the so-called Reder hypothesis) and finds affirmative evidence for the U. S labour market. The authors replicate his analysis using German employment register data. Regarding the occupational skill composition they obtain somewhat lower but qualitatively similar responses to the business cycle despite of well known institutional differences between the U. S. and German labour market. The responsiveness of occupational composition wages to the business cycle is considerably lower in Germany. [...] Hiring standards,business cycle adjustment,occupational upgrading,wage structure,wage setting,overqualification...|$|R
5000|$|... #Caption: ANA Boeing 767-300ER in panda livery (since repainted <b>back</b> into <b>standard</b> livery) ...|$|R
50|$|In 1995 the {{locomotives}} {{were converted}} <b>back</b> to <b>standard</b> SNCF Class BB 22200 type.|$|R
50|$|UCSD Pascal, under Professor Kenneth Bowles, {{was based}} on the Pascal-P2 kit, and {{consequently}} shared several of the Pascal-P language restrictions. UCSD Pascal was later adopted as Apple Pascal, and continued through several versions there. Although UCSD Pascal actually expanded the subset Pascal in the Pascal-P kit by adding <b>back</b> <b>standard</b> Pascal constructs, it was still not a complete standard installation of Pascal.|$|R
40|$|A {{firm that}} faces {{insufficient}} supply of labor can either increase the wage offer {{to attract more}} applicants, or reduce the hiring standard to enlarge the pool of potential employees, or do both. This simultaneous adjustment of wages and hiring standards has been emphasized in a classical contribution by Reder (1955) and implies that wage reactions to employment changes {{can be expected to}} be more pronounced for low wage workers than for high wage workers. We test this hypothesis (together with a related hypothesis on firm-specific human capital) by applying a bootstrap-based quantile regression approach to censored panel data from the German employment register. Our findings suggest that market clearing is achieved by a combination of wage and hiring <b>standards</b> <b>adjustment.</b> ...|$|R
40|$|Size {{reduction}} {{is a process}} of reducing large solid unit masses into small unit masses, coarse particles or fine particles. Size reduction process is also termed as comminution or diminution or pulverizations. In addition to the <b>standard</b> <b>adjustments</b> of the milling process (i. e., speed, screen size, design of rotor, load), special techniques of milling may be useful including special atmosphere, temperature control, sonocrystallization, supercritical fluid process. etc. Moreover, some advance technologies of size reduction including Micron Technologies, Gran-U-Lizer Technology, Jet-O-Mizer and Microfluidics &#x 00 AE; have been popular. Various application of size reduction concept covers oral delivery of poorly soluble drugs, micronization, nanotechnology (micro- and nano suspensions), etc. This systemic review highlights advantages and disadvantages, mechanisms, theories, techniques, advances, and pharmaceutical applications of size reduction technology...|$|R
40|$|A {{high-pressure}} liquid chromatographic {{method has}} been developed for the quantitative determination of rosaramicin in serum. This procedure involves addition of an internal <b>standard,</b> <b>adjustment</b> to alkaline pH, treatment with potassium carbonate, ether extraction, and a reverse-phase column separation with acetonitrile-acetate buffer mixture as the mobile phase. This technique produces a good linear relationship between the peak height ratio and the rosaramicin concentration. In addition, this method {{has proven to be}} quite specific for rosaramicin, since many of its derivatives tested do not interfere with the assay. The method is accurate and reproducible with a sensitivity of about 0. 01 microgram of rosaramicin per ml of serum. It may be useful in monitoring drug levels in serum of patients and also for the pharmacokinetic studies of the drug in humans...|$|R
40|$|Estimation {{of average}} {{treatment}} effects in observational, or non-experimental in pre-treatment variables. If {{the number of}} pre-treatment variables is large, and their distribution varies substantially with treatment status, <b>standard</b> <b>adjustment</b> methods such as covariance adjustment are often inadequate. Rosenbaum and Rubin (1983) propose an alternative method for adjusting for pre-treatment variables based on the propensity score conditional probability of receiving the treatment given pre-treatment variables. They demonstrate that adjusting solely for the propensity score removes all the bias associated with differences in pre-treatment variables between treatment and control groups. The Rosenbaum-Rubin proposals deal exclusively with the case where treatment takes on only two values. In this paper an extension of this methodology is proposed that allows for estimation of average causal effects with multi-valued treatments while maintaining {{the advantages of the}} propensity score approach. ...|$|R
50|$|In the United States and elsewhere, athletes {{previously}} ran the 220-yard dash (201.168 m) {{instead of}} the 200 m (218.723 yards), though the distance is now obsolete. The <b>standard</b> <b>adjustment</b> used for the conversion from times recorded over 220 yards to 200 m times is to subtract 0.1 seconds, but other conversion methods exist. Another obsolete version of this race is the 200 metres straight, which was run on tracks that contained such a straight. Initially, when the International Amateur Athletic Association (now known as the International Association of Athletics Federations) started to ratify world records in 1912, only records set on a straight track were eligible for consideration. In 1951, the IAAF started to recognise records set on a curved track. In 1976, the straight record was discarded.|$|R
50|$|Running martingale: This design adds {{leverage}} to {{a bit and}} features a split fork beginning at the chest with a ring {{on each side of}} the fork through which the reins pass, enabling the rider to more easily keep the horse under control, but also allowing the horse freedom of movement when needed. Fitted correctly, the running martingale only controls how high the horse carries its head when the rider tightens the reins. The <b>standard</b> <b>adjustment</b> of a running martingale is to set the rings at a height where they do not engage and add {{leverage to}} the reins when the horse carries its head at the proper height. Sometimes a running martingale may be adjusted at a greater or lesser length depending on the needs of the horse and rider.|$|R
5000|$|<b>Standard</b> <b>adjustment</b> of a noseband is {{to allow}} one or two fingers between the noseband and the nasal bone of the horse's head, though many riders adjust it tighter. Research is ongoing to {{determine}} stress and pain levels related to excessively tight nosebands. [...] Recent studies in equitation science now strongly recommend that traditional and crank nosebands be adjusted so that two fingers can be inserted at the [...] "nasal midline"—where the noseband crosses {{the top of the}} nose. The International Society for Equitation Science has stated that tight nosebands may lead to physiological stress and mask unwanted behavior and they encourage competition rules to be amended to require horse show stewards to check noseband tightness with a standardized gauge and see that competitors adjust their equipment accordingly.|$|R
50|$|Sébastien Pocognoli (born 1 August 1987) is a Belgian {{international}} footballer {{who plays}} as a left <b>back</b> for <b>Standard</b> Liège.|$|R
40|$|Analysis {{of sample}} survey data often {{requires}} adjustments {{to account for}} missing data in the outcome variables of principal interest. <b>Standard</b> <b>adjustment</b> methods based on item imputation or on propensity weighting factors rely heavily {{on the availability of}} auxiliary variables for both responding and non-responding units. Application of these adjustment methods can be especially challenging in cases for which the auxiliary variables are numerous and are themselves subject to substantial incomplete-data problems. This paper shows how classification and regression trees and forests can overcome some of the computational difficulties. An in-depth simulation study based on incomplete-data patterns encountered in the U. S. Consumer Expenditure Survey is used to compare the methods with two standard methods for estimating a population mean in terms of bias, mean squared error, computational speed and number of variables that can be analyzed...|$|R
40|$|The major {{findings}} of this study are as follows: (1) Simple cross section estimates grossly underestimate cohort profiles during the period 1960 - 70. Furthermore the growth in earnings is not uniform across experience groups and more recent vintages tend to have steeper profiles in most fields. Consequently the rate of return or present value comparisons based on cross sections are likely to be misleading even if the <b>standard</b> <b>adjustment</b> for growth is made. (2) For purposes of estimating mean profiles and mean effects of variables estimates based on pooled independent cross sections are quite close to those based on the more expensive longitudinal data. (3) There are important persistent unmeasured individual effects on both the level and growth of earnings. Consequently, individuals with the same observed characteristics will still have a wide variance in their permanent income. ...|$|R
40|$|Four growing {{experiments}} {{were conducted to}} evaluate the use of dry rolled corn (DRC) and either dry (DDGS) or wet distillers grains plus solubles (WDGS) as energy sources in high forage diets. In Exp. 1, steers were fed a blend of sorghum silage and alfalfa hay and supplemented 1 of 4 inclusions of WDGS, DDGS or a MIX (67 % WDGS: 33 % Straw). In Exp. 2, Exp. 3 and Exp. 4, steers were fed diets including WDGS, DDGS or DRC at different inclusions, replacing sorghum silage and grass hay. In Exp. 1, WDGS, DDGS and MIX produced greater ending BW, ADG and G:F compared to the basal diet. Increasing distillers grains improved ADG and G:F in forage based diets. Data from Exp. 2 - 4 were pooled and ADG was regressed against inclusion thereby allowing the energy value of WDGS to be calculated relative to that of DRC. The energy value of WDGS was 137 % and 136 % of DRC when fed at 15 and 30 % of the diet DM, respectively. In vitro digestibility and in vivo digestibility estimates are highly correlated but absolute values differ. Therefore, our objective was to determine in vivo digestibilities of 5 forages and use these forages as standards for in vitro digestibility procedures when in vivo estimates are needed for unknown forage samples. Eight in vitro runs were conducted using 5 hay standards and 6 forage samples with unknown in vivo digestibilities in order to predict actual in vivo values from in vitro estimates. Runs were evaluated using either regression equations or <b>standard</b> mean <b>adjustment.</b> Using regression equations increase forage*run variation. Forage*run variation decreased using the <b>standard</b> mean <b>adjustment.</b> <b>Standard</b> mean <b>adjustment</b> appears to be a valid method to adjust IVOMD values and estimate in vivo digestibility. Advisors: Terry Klopfenstein and Galen Erickso...|$|R
30|$|As {{shown in}} Table  8, the {{high-temperature}} stability of AR-SMA- 13 I reduced the filler proportion from 10  % to 8  %, yielded a better mixture {{than the other}} two types, and is the only mixture that meets the technical <b>standards.</b> Gradation <b>adjustment</b> to optimize the high-temperature performance of AR-SMA- 13 is therefore feasible.|$|R
25|$|Two Il-18Ds {{modified}} for ice reconnaissance {{similar to}} the IL-20M but with civilian reconnaissance equipment, both later modified <b>back</b> to <b>standard</b> configuration and sold.|$|R
2500|$|EH-60C Black Hawk: UH-60A {{modified}} {{with special}} electronics equipment and external antenna. (All examples of type {{have been taken}} <b>back</b> to <b>standard</b> UH-60A configuration.) ...|$|R
5000|$|Two Il-18Ds {{modified}} for ice reconnaissance {{similar to}} the IL-20M but with civilian reconnaissance equipment, both later modified <b>back</b> to <b>standard</b> configuration and sold.|$|R
40|$|Obtaining {{a digital}} {{model of a}} {{real-world}} 3 D scene is a challenging task pursued by computer vision and computer graphics. Given an initial approximate 3 D model, a popular refinement process is to perform a bundle adjustment of the estimated camera position, camera orientation, and scene points. Unfortunately, simultaneously solving for both camera position and camera orientation is an ill-conditioned problem. To address this issue, we propose an improved, cameraorientation independent cost function {{that can be used}} instead of the <b>standard</b> bundle <b>adjustment</b> cost function. This yields a new bundle adjustment formulation which exhibits noticeably better numerical behavior, but at the expense of an increased computational cost. We alleviate the additional cost by automatically partitioning the dataset into smaller subsets. Minimizing our cost function for these subsets still achieves significant error reduction over <b>standard</b> bundle <b>adjustment.</b> We empirically demonstrate our formulation using several different size models and image sequences. 1...|$|R
5000|$|Russia (Observed DST in 1917-1919 and 1921 (some areas), 1981-2010. 2011-2014, used year-round DST. In 2014, Russia {{discontinued}} year-round DST {{and switched}} <b>back</b> to <b>standard</b> time) ...|$|R
