13|10|Public
5000|$|When {{using an}} array of bytes to {{represent}} a set of bits, i.e., a bit array or <b>bitset,</b> the index of the byte in the array associated with a bit [...] can be calculated using division: ...|$|E
50|$|A {{wealth of}} {{features}} {{made it a}} versatile calculator. Named variables, and interactive formulas of up to 79 keystrokes, could be stored, subject to a total memory usage of 440 bytes. Some features included a simultaneous equations solver, a polynomial root finder, two-variable statistics, complex numbers, and a recall feature, which would display the last equation entered and its answer. It had several features useful to computer programmers, such as radix modes and conversions and <b>bitset</b> operators. It had an alphanumeric keyboard and display.|$|E
40|$|AbstractThis paper {{presents}} the extremely simple algorithms for NP-hard subset-sum like {{problems with the}} <b>bitset</b> class. The presented algorithms decrease the time and space complexity of dynamic programming algorithms by exploiting word parallelism. The computational experiments demonstrate that the achieved results are not only of theoretical interest, but also that the techniques developed may actually lead to considerably faster algorithms...|$|E
40|$|In this paper, a {{branch-and-bound}} algorithm {{for finding}} all cliques of size k in a k-partite graph is proposed that improves upon {{the method of}} Grunert et al (2002). The new algorithm uses bit-vectors, or <b>bitsets,</b> as the main data structure in bit-parallel operations. <b>Bitsets</b> enable {{a new form of}} data representation that improves branching and backtracking of the branch-and-bound procedure. Numerical studies on randomly generated instances of k-partite graphs demonstrate competitiveness of the developed method...|$|R
50|$|Like other 'plus' media, it is {{possible}} to change the book type to increase the compatibility of DVD+R media (though unlike DVD+RW, it is a one way process). This is also known as <b>bitsetting.</b>|$|R
25|$|A {{number is}} a square if every number in its {{exponent}} vector is even. For example, the vectors (3,0,0,1) and (1,2,0,1) add to (4,2,0,2), so (56)(126) is a square. Searching for a square requires knowledge {{only of the}} parity of the numbers in the vectors, so {{it is possible to}} reduce the entire vector mod 2 and perform addition of elements mod 2: (1,0,0,1) + (1,0,0,1) = (0,0,0,0). This is particularly efficient in practical implementations, as the vectors can be represented as <b>bitsets</b> and addition mod 2 reduces to bitwise XOR.|$|R
40|$|We {{propose a}} dynamic faceted search system for discoverydriven {{analysis}} on data with both textual content and structured attributes. From a keyword query, {{we want to}} dynamically select a small set of “interesting ” attributes and present aggregates on them to a user. Similar to work in OLAP exploration, we define “interestingness ” as how surprising an aggregated value is, based on a given expectation. We make two new contributions by proposing a novel“navigational”expectation that’s particularly useful {{in the context of}} faceted search, and a novel interestingness measure through judicious application of p-values. Through a user survey, we find the new expectation and interestingness metric quite effective. We develop an efficient dynamic faceted search system by improving a popular open source engine, Solr. Our system exploits compressed bitmaps for caching the posting lists in an inverted index, and a novel directory structure called a <b>bitset</b> tree for fast <b>bitset</b> intersection. We conduct a comprehensive experimental study on large real data sets and show that our engine performs 2 to 3 times faster than Solr. 1...|$|E
40|$|Profiling of the {{learning}} classifier system XCS [11] has revealed that its execution time tends {{to be dominated by}} rule matching [8], it is therefore important for rule matching to be efficient. To date, the fastest speedups for matching have been achieved by exploiting parallelism [8], but efficient sequential approaches, such as <b>bitset</b> and “specificity” matching [2], can be utilised if there is no platform support for the vector instruction sets that [8] employs. Previous sequential approaches have focussed on improving the efficiency of matching individual rules; in this paper, we introduce a population-based approach that partially matches many rules simultaneously. This is achieved by maintaining the rule-base in a rooted 3 -ary tree over which a backtracking depthfirst search is run to find the matchset. We found that the method generally outperformed standard and specificity matching on raw matching and on several benchmarking tasks. While the <b>bitset</b> approach attained the best speedups on the benchmarking tasks, we give an analysis that shows that it can be the least efficient of the approaches on long rule conditions. A limitation of the new method is that it is inefficient when the proportion of “don’t care” symbols in the rule conditions is very large, which could perhaps be remedied by combining the method with the specificity technique...|$|E
40|$|A <b>bitset</b> is a {{set that}} encodes for a binary number. Bitsets are at {{the basis of a}} {{beautiful}} theory of recombination with n-loci and here we begin from scratch and advance to include the derivation of the fundamental results about the evolution of gamete frequencies and of disequilibrium measures with and without migration. All techniques have been illustrated and we have invested moreover a great effort to make the mathematics of this work accessible even for students in their first year at the university. Comment: 44 pages, 10 figure...|$|E
25|$|For example, {{it may be}} used to {{represent}} sparse <b>bitsets,</b> i.e., subsets of a much larger, fixed enumerable set. In such a case, the trie is keyed by the bit element position within the full set. The key is created from the string of bits needed to encode the integral position of each element. Such tries have a very degenerate form with many missing branches. After detecting the repetition of common patterns or filling the unused gaps, the unique leaf nodes (bit strings) can be stored and compressed easily, reducing the overall size of the trie.|$|R
50|$|One {{common cause}} of {{compatibility}} problems is {{the failure of a}} device to recognize the book type of the disc, most likely because the device had been manufactured before that particular book type was defined; for example, most DVD playback devices made before mid-2004 cannot recognize the relatively new DVD+R DL Book Type. For DVD+R, DVD+RW, and DVD+R DL discs, it is possible to change the Book Type field value to the value associated with the DVD-ROM format (or in some rare and unorthodox cases, even the value associated with the DVD-R format - though only DVD+R can be changed to this) in order to fool older devices, which is a trick known as <b>bitsetting.</b>|$|R
40|$|Myth is a {{programming}} language that {{is an extension of}} C. Myth adds modules, interfaces, tuple returns, and bit sets. These features are very helpful in nearly any programming environment. The Myth language as a whole is a good choice for embedded systems where resources are limited. Modules help organize code into logical groupings. Interfaces provide an automated mechanism to write reusable code. Tuple returns provide a simple mechanism for returning multiple values from a function. <b>Bitsets</b> make it easy to define logical groups of bit flags. Bisets are particularly useful in code that interfaces with hardware. The advantage of Myth is modules, tuple returns, and interfaces without the overhead of full-blown object orientation. Myth has been implemented as a preprocessor that produces C source code...|$|R
40|$|T 10 graphic {{processor}} and demonstrate up to 100 X speedup {{as compared with}} several state-of-the-art FIM algorithms on a CPU. In order to map the Apriori algorithm onto the SIMD execution model, we have designed a “static <b>bitset</b> ” memory structure to represent the input database. This data structure improves upon the traditional approach of the vertical data layout in state-of-the art Apriori implementations. In our implementation, we perform a parallelized version of the support counting step on the GPU. Experimental results show that GPApriori consistently outperforms CPU-based Apriori implementations. Our results demonstrate the potential for GPGPUs in speeding up data mining algorithms...|$|E
40|$|International audienceComputer Science abounds in folktales {{about how}} — {{in the early}} days of {{computer}} programming — bit vectors were ingeniously used to encode and manipulate finite sets. Algorithms have thus been developed to minimize memory footprint and maximize efficiency by taking advantage of microarchitectural features. With the development of automated and interactive theorem provers, finite sets have also made their way into the libraries of formalized mathematics. Tailored to ease proving, these representations are designed for symbolic manipulation rather than computational efficiency. This paper aims to bridge this gap. In the Coq proof assistant, we implement a <b>bitset</b> library and prove its correct-ness with respect to a formalization of finite sets. Our library enables a seamless interaction of sets for computing — bitsets — and sets for proving — finite sets...|$|E
40|$|A <b>bitset</b> is a {{set that}} encodes for a binary number. Bitsets are at {{the basis of a}} {{beautiful}} theory of recombination with n-loci and here we begin from scratch and advance to include the derivation of the fundamental results about the evolution of gamete frequencies and of disequilibrium measures with and without migration. All techniques have been illustrated and we have invested moreover a great effort to make the mathematics of this work accessible even for students in their first year at the university. 1 RECOMBINANT OPERATORS Amphimictic diploid organisms are those that develop from a single cell which results from the fusion of paternal haploid spermatozoa and maternal haploid ovule. Each cell in the resulting organism will have approximately the same genetic material, although as cellular subdivisions run, especially those at gametic meiosis, linkage can change and the individual will produce gametes with mixed maternal and paternal genomes. The process leading to this ordered mixing is called recombination...|$|E
40|$|Graph {{theory is}} {{fascinating}} branch of math. Leonhard Euler introduced {{the concept of}} Graph Theory in his paper about the seven bridges of Konigsberg published in 1736. In a nutshell, graph theory {{is the study of}} pair-wise relationships between objects. Each object is represented using a vertex and in case of a relationship between a pair of vertices, they will be connected using an edge. In this dissertation, graph theory is used to study several important combinatorial optimization problems. In chapter 2, we study the multi-dimensional assignment problem using their underlying hypergraphs. It will be shown how the MAP can be represented by a k-partite graph and how any solution to MAP is associated to a k-clique in the respective k-partite graph. Two heuristics are proposed to solve the MAP and computational studies are performed to compare the performance of the proposed methods with exact solutions. On the heels of chapter 3, a new branch-and-bound method is proposed {{to solve the problem of}} finding all k-cliques in a k-partite graph. The new method utilizes <b>bitsets</b> as the data-structure to represent graph data. A new pruning method is introduced in BitCLQ, and CPU instructions are used to improve the performance of the branch-and-bound method. BitCLQ gains up to 300 % speed up over existing methods. In chapter 4, two new heuristic to solve decomposable cost MAP 2 ̆ 7 s are proposed. The proposed heuristic are based on the partitioning of the underlying graph representing the MAP. In the first heuristic method, MAP 2 ̆ 7 s are partitioned into several smaller MAP 2 ̆ 7 s with the same dimensiality and smaller cardinality. The solution to the original MAP is constructed incrementally, by using the solutions obtained from each of the smaller MAP 2 ̆ 7 s. The second heuristic works in the same fashion. But instead of partitioning the graph along the cardinality, graphs are divided into smaller graphs with the same cardinality but smaller dimensionality. The result of each heuristic is then compared with a well-known existing heuristic. An important problem in graph theory is the maximum clique problem (MCQ). A clique in a graph is defined as a complete subgraph. MCQ problem entails finding the size of the largest clique contained in a graph. General branch-and-bound methods to solve MCQ use graph coloring to find an upper bound on the size of the maximum clique. Recently, a new MAX-SAT based branch-and-bound method for MCQ is proposed that improves the quality of the upper bound obtained from graph coloring. In chapter 5, a branch and bound algorithm is proposed for the maximum clique problem. The proposed method uses <b>bitsets</b> as the data-structure. The result of the computational studies to compare the proposed method with existing methods for MCQ is provided. Chapter 6 contains an application of a graph theory in solving a risk management problem. A new mixed-integer mathematical model to formulate a risk-based network is provided. It will be shown that an optimal solution of the model is a maximal clique in the underlying graph representing the network. The model is then solved using a graph-theoretic approach and the results are compared to CPLEX...|$|R
40|$|Added Store and Proxy {{classes for}} memory {{efficiency}} MMTF, DXBIN, DCD files format parsers 'unitcell' representation stage. makeImage (returns Promise) take NCS operations {{into account when}} creating unitcell & supercell assemblies added multi sample antialias rendering added support for spinning around an axis use <b>bitsets</b> for storing selections of atoms Assembly and AssemblyPart classes stage. toggleFullscreen method read occupancy data when available (mmCIF, pdb, mmtf) occupancy color scheme alternate location support in selections, e. g. %B read insertion codes when available (mmCIF, pdb, mmtf) insertion code support in selections, e. g. ^A numeric residue name support in selections, e. g. [032] Queue class to handle async tasks Changed fixed transformation matrix in mrc/ccp 4 parser optimized near clipping Fiber class remanamed to Polymer more consistent fog use workers more sparsely due to the large overhead of creating them create font SDF on demand, remove asset dependency integrated three. js lighting into custom shaders MIGRATION: chainname read from auth_asym_id instead of from label_asym_id field DOC: clarified apache configuration for deployment FIX: cif parser, ignore non-displayable bonds between symmetry mates FIX: cif parser, struct_conn bonds not added for multiple altloc atoms LIB: updated signals. js LIB: updated promise. js LIB: updated three. js LIB: updated pako. js to pako_inflate. js (no deflation support needed) CODE: support loading of Blob objects in addition to File objects CODE: tweaked DistanceRepresentation visibility params Removed zip, lzma, bzip 2 decompression removed async. js mdsrv related code and documentation stage. exportImage (makes image and triggers download), use stage. makeImag...|$|R
40|$|A {{variety of}} methods for ranking fuzzy sets has been suggested. Generally, these methods fall under two main categories: a fuzzy-real sets mapping, a {{dominance}} relation of one fuzzy set over another. The original approach proposed in this paper belongs to the second category, as the ranking {{is based on the}} degree of inclusion in the MIN of two fuzzy numbers. The novelty lies mainly in the intuitive connection between the topological relationship of fuzzy shapes (triangles, trapezoids, etc.) and the measure of inclusion or dominance referred as inclusion index. This connection led to the classification of different topological relationships into classes identified by a binary pattern. This operation is referred to as <b>Bitset</b> Encoding. Consequently, the outcome of a ranking is already decided for most cases by merely identifying its pattern. Ultimately, the method is validated by the axiomatic system of Wang and Kerre and proven to be a reliable, efficient and strong potential alternative to the other prominent methods...|$|E
40|$|Abstract. Discovering {{contrasts}} between {{collections of}} data {{is an important}} task in data mining. In this paper, we introduce {{a new type of}} contrast pattern, called a Minimal Distinguishing Subsequence (MDS). An MDS is a minimal subsequence that occurs frequently in one class of sequences and infrequently in sequences of another class. It is a natural way of representing strong and succinct contrast information between two sequential datasets and can be useful in applications such as protein comparison, document comparison and building sequential classification models. Mining MDS patterns is a challenging task and is significantly different from mining contrasts between relational/transactional data. One particularly important type of constraint that can be integrated into the mining process is the gap constraint. We present an efficient algorithm called ConSGapMiner (Contrast Sequences with Gap Miner), to mine all MDSs satisfying a minimum and maximum gap constraint, plus a maximum length constraint. It employs highly efficient <b>bitset</b> and boolean operations, for powerful gap based pruning within a prefix growth framework. A performance evaluation with both sparse and dense datasets, demonstrates the scalability of ConSGapMiner and shows its ability to mine patterns from high dimensional datasets at low supports...|$|E

