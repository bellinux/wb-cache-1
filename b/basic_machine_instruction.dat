0|1323|Public
50|$|Many {{authors have}} {{augmented}} the <b>basic</b> counter <b>machine</b> model <b>instruction</b> set, {{with a more}} complex instructions, {{for this kind of}} studies.|$|R
5000|$|The 6000-series <b>machine's</b> <b>basic</b> <b>instruction</b> set {{had more}} than 185 single-address one-word {{instructions}}. [...] The basic instructions were one word. The addresses pointed to operand descriptors which contained the actual operand address and additional information.|$|R
40|$|Abstract- The {{ability to}} reduce power {{consumption}} of a device is attractive for several reasons. On one hand, reducing power in high end computers {{will reduce the}} cost of cooling and the performance loss due to overheating cores. On the other hand, ubiquitous battery powered devices will enjoy a longer battery life due to the reduction in power consumption. In this paper, we present a set of mechanisms that uses instruction scheduling to reduce the power consumption of RISC like microcontrollers that are common in battery powered devices. Initially, we devised a method to measure the approximate power consumption of each basic assembly instruction of the microcontroller. By a statistical analysis of the power measurement, we categorized the basic instructions into groups. Our measurements demonstrate that some instruction combinations consume more power than others which will perform the same functional operations. We leveraged this observation to rearrange the scheduling of <b>basic</b> <b>machine</b> <b>instructions</b> of a high level programming language, such that the final program is optimized for power. Some of our test cases demonstrate significant reduction in power consumption without any performance degradation. The resultant ideas can therefore be used by both system programmers and compiler designers. Index Terms- energy, instruction scheduling, microcontroller, power aware scheduling, power consumptio...|$|R
40|$|This manual {{has been}} {{prepared}} {{as a guide}} to operating the central processor for the GE- 225 Information Processing system. It includes {{a brief description of the}} major components of the system, general operating practices, system startup and shutdown, and a detailed description of the controls on the operator's cocsole and ty 2 ewriter. Part I has been revised to include descriptions and illustrations of equipment not included in the earlier editions of this manual. The appendix includes a section on number systems, a table of powers of 2, and octal-decimal conversion tables. Much of the <b>basic</b> information about <b>machine</b> <b>instruction</b> repertoire and programs is necessarily brief, since this information is contained in detail in the GE- 225 Programming Reference Manual (CPB- 252). This manual supersedes the former GE- 225 System Operating Manual (CPB- 247 A). The operating information on peripheral subsystems contained in that manual is now covered in separate manuals for each subsystem. A list of these manuals appears in Appendix E. Much of the information in this manual is also applicable to the GE- 205 and GE- 215 central processors which have virtually identical operating controls and procedures...|$|R
5000|$|In the {{top most}} {{simulation}} level the microcode simulator continuously executes micro instructions without interrupt. In this level, <b>machine</b> <b>instruction</b> by <b>machine</b> <b>instruction</b> is loaded. So, {{it is possible}} to focus on the interaction of the CPU with external devices.|$|R
25|$|That such minimalism is {{possible}} {{does not mean}} that it is necessarily desirable; after all, computers theoretically need only one <b>machine</b> <b>instruction</b> (subtract one number from another and branch if the result is negative), but practical computers have dozens or even hundreds of <b>machine</b> <b>instructions.</b>|$|R
5000|$|LOADALL, undocumented <b>machine</b> <b>instructions</b> purportedly used by Microsoft's RAMDRIVE.SYS ...|$|R
5000|$|... #Subtitle level 3: Advantages of stack <b>machine</b> <b>instruction</b> sets ...|$|R
5000|$|... #Subtitle level 2: Analogy to {{bytecode}} / virtual <b>machine</b> <b>instruction</b> set ...|$|R
5000|$|The NAR 2 {{processor}} uses 32-bit machine words. Each <b>Machine</b> <b>instruction</b> contains: ...|$|R
5000|$|The {{next logical}} phase is the {{disassembly}} of <b>machine</b> code <b>instructions</b> into a <b>machine</b> independent intermediate representation (IR). For example, the Pentium <b>machine</b> <b>instruction</b> mov eax, ebx+0x04might be translated to the IR eax := mebx+4; ...|$|R
40|$|This book {{presents}} a comprehensive, structured, up-to-date survey on instruction selection. The survey is structured {{according to two}} dimensions: approaches to instruction selection from the past 45 years are organized and discussed according to their fundamental principles {{and according to the}} characteristics of the supported <b>machines</b> <b>instructions.</b> The fundamental principles are macro expansion, tree covering, DAG covering, and graph covering. The <b>machine</b> <b>instruction</b> characteristics introduced are single-output, multi-output, disjoint-output, inter-block, and interdependent <b>machine</b> <b>instructions.</b> The survey also examines problems that have yet to be addressed by existing approaches. The book is suitable for advanced undergraduate students in computer science, graduate students, practitioners, and researchers. QC 20160810 </p...|$|R
5000|$|... efficiency: a {{statistically}} dominant fraction of <b>machine</b> <b>instructions</b> must be executed without VMM intervention ...|$|R
5000|$|TXT records {{contain the}} <b>machine</b> <b>instructions</b> or data which {{is held by}} the module.|$|R
40|$|Basic {{building}} blocks of the computer: logic gates, memory cells, wires. • Units built from these (like register units, control unit). • Other Hardware components (monitors, hard disks • Representation and manipulation of data. • <b>Machine</b> <b>instructions</b> and assembly languages. • Translation of high level languages into <b>machine</b> <b>instructions.</b> • High performance architectures like super scalar/pipelined architectures and instruction level parallelism...|$|R
40|$|In {{a virtual}} machine interpreter, the code for each virtual <b>machine</b> <b>instruction</b> has {{similarities}} to code for other instructions. We present an interpreter generator that automatically generates code for the virtual <b>machine</b> <b>instructions</b> from simple instruction descriptions; it generates code for the virtual machine interpreter, for generating virtual machine code, for virtual machine code disassembly, for tracing, and for profiling...|$|R
5000|$|From the 1940s to {{the late}} 1970s, {{a large portion of}} {{programming}} was done in assembly language; higher-level instructions mean greater programmer productivity, so an important advantage of microcode was the relative ease by which powerful <b>machine</b> <b>instructions</b> can be defined. The ultimate extension of this are [...] "Directly Executable High Level Language" [...] designs, in which each statement of a high-level language such as PL/I is entirely and directly executed by microcode, without compilation. The IBM Future Systems project and Data General Fountainhead Processor are examples of this. During the 1970s, CPU speeds grew more quickly than memory speeds and numerous techniques such as memory block transfer, memory pre-fetch and multi-level caches were used to alleviate this. High-level <b>machine</b> <b>instructions,</b> made possible by microcode, helped further, as fewer more complex <b>machine</b> <b>instructions</b> require less memory bandwidth. For example, an operation on a character string can be done as a single <b>machine</b> <b>instruction,</b> thus avoiding multiple instruction fetches.|$|R
5000|$|Uses a non-virtualized, model-dependent <b>machine</b> <b>instruction</b> as {{a signal}} between CMS and CP: DIAG ("diagnose").|$|R
5000|$|Efficiency / Performance: A {{statistically}} dominant {{fraction of}} <b>machine</b> <b>instructions</b> must be executed without VMM intervention.|$|R
5000|$|On {{a system}} that uses {{conditional}} branching, this might translate to <b>machine</b> <b>instructions</b> looking similar to: ...|$|R
50|$|Since there is, typically, a {{one-to-one}} {{relationship between}} assembly <b>instructions</b> and <b>machine</b> <b>instructions,</b> the instruction path length is frequently taken {{as the number}} of assembly instructions required to perform a function or particular section of code. Performing a simple table lookup on an unsorted list of 1,000 entries might require perhaps 2,000 <b>machine</b> <b>instructions</b> (on average, assuming uniform distribution of input values), while performing the same lookup on a sorted list using a binary search algorithm might require only about 40 <b>machine</b> <b>instructions,</b> a very considerable saving. Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 - a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length.|$|R
5000|$|... #Caption: A {{high-level}} illustration {{showing the}} decomposition of <b>machine</b> <b>instructions</b> into micro-operations, performed during typical fetch-decode-execute cycles.|$|R
50|$|Execution {{optimization}} {{has gone}} even further; processors not only translate many <b>machine</b> <b>instructions</b> {{into a series}} of μops, but also do the opposite when appropriate; they combine certain <b>machine</b> <b>instruction</b> sequences (such as a compare followed by a conditional jump) into a more complex μop which fits the execution model better and thus can be executed faster or with less machine resources involved. This is also known as macro-op fusion.|$|R
40|$|Prolog {{has been}} widely {{recognized}} as a powerful programming language for artificial intelligence. It was also chosen as a kernel language for the Japanese Fifth Generation Project. The project is a large scale effort to initiate {{a new generation of}} computing. Due to the wide range of applications that Prolog has, many methods have been developed for extracting parallelism from standard Prolog in order to achieve faster execution on a multiprocessor. This project designs an execution model for Prolog, which attempts to exploit the parallelism mainly at the argument level through the unification operation. The model consisting of a number of virtual <b>machine</b> <b>instructions,</b> has been implemented in Occam 2 on a Transputer Development System. A few Prolog procedures have been hand compiled to the virtual <b>machine</b> <b>instructions,</b> and have been run on a Transputer Development System with a single transputer. This model of virtual <b>machine</b> <b>instructions</b> can be applied to a multiple transputer system. This project gives the details of the implementation of the virtual <b>machine</b> <b>instructions...</b>|$|R
5000|$|Run-time control ... With all implementations, debug tools {{can start}} and stop the processor, modify registers, and single-step <b>machine</b> <b>instructions.</b>|$|R
5000|$|... {{simulating}} a few <b>machine</b> <b>instructions</b> {{that are}} present on some, but not all, {{models of the}} S/360 or S/370 computers, ...|$|R
50|$|From {{either of}} two 3-instruction base sets {{all the other}} counter <b>machine</b> <b>instructions</b> can be derived. Both have {{advantages}} and disadvantages.|$|R
40|$|This paper {{describes}} a PC-based mainframe computer emulator called VisibleZ {{and its use}} in teaching mainframe Computer Organization and Assembly Programming classes. VisibleZ models IBM’s z/Architecture and allows direct interpretation of mainframe assembly language object code in a graphical user interface environment that was developed in Java. The VisibleZ emulator acts as an interactive visualization tool to simulate enterprise computer architecture. The provided architectural components include main storage, CPU, registers, Program Status Word (PSW), and I/O Channels. Particular attention is given to providing visual clues to the user by color-coding screen components, <b>machine</b> <b>instruction</b> execution, and animation of the machine architecture components. Students interact with VisibleZ by executing <b>machine</b> <b>instructions</b> in a step-by-step mode, simultaneously observing the contents of memory, registers, {{and changes in the}} PSW during the fetch-decode-execute <b>machine</b> <b>instruction</b> cycle. The object-oriented design and implementation of VisibleZ allows students to develop their own instruction semantics by coding Java for existing specific z/Architecture <b>machine</b> <b>instructions</b> or design and implement new <b>machine</b> <b>instructions.</b> The use of VisibleZ in lectures, labs, and assignments is described in the paper and supported by a website that hosts an extensive collection of related materials. VisibleZ has been proven a useful tool in mainframe Assembly Language Programming and Computer Organization classes. Using VisibleZ, students develop a better understanding of mainframe concepts, components, and how the mainframe computer works. ACM Computing Classification System (1998) : C. 0, K. 3. 2...|$|R
50|$|In modern CPUs this is {{accomplished}} on the processor itself, in a single <b>machine</b> <b>instruction,</b> {{rather than having to}} go through RAM.|$|R
50|$|In 1936 Konrad Zuse {{anticipated}} in two patent {{applications that}} <b>machine</b> <b>instructions</b> could {{be stored in}} the same storage used for data.|$|R
50|$|Microcode {{typically}} {{resides in}} special high-speed memory and translates <b>machine</b> <b>instructions,</b> state <b>machine</b> data or other input into sequences of detailed circuit-level operations. It separates the <b>machine</b> <b>instructions</b> from the underlying electronics so that instructions {{can be designed}} and altered more freely. It also facilitates the building of complex multi-step instructions, while reducing the complexity of computer circuits. Writing microcode is often called microprogramming and the microcode in a particular processor implementation is sometimes called a microprogram.|$|R
50|$|In 1936, Konrad Zuse also {{anticipated}} in two patent {{applications that}} <b>machine</b> <b>instructions</b> could {{be stored in}} the same storage used for data.|$|R
5000|$|User-accessible {{registers}} {{can be read}} {{or written}} by <b>machine</b> <b>instructions.</b> The most common division of user-accessible registers is into data registers and address registers.|$|R
40|$|We {{show how}} to {{generate}} {{the back end of}} an optimizing compiler from a formal description of the syntax and semantics of <b>machine</b> <b>instructions.</b> Our generated back ends for x 86, ARM, and PowerPC perform as well as their hand-written counterparts. Automatic generation is enabled by two new ideas: a model of machine-level computation that reduces back-end generation to the problem of finding implementations of about a hundred simple, machine-level operations; and an algorithm that finds these implementations by combining <b>machine</b> <b>instructions.</b> 1...|$|R
50|$|In 1991, the crashme tool was released, {{which was}} {{intended}} to test the robustness of Unix and Unix-like operating systems by executing random <b>machine</b> <b>instructions.</b>|$|R
5000|$|Jasmin, takes text {{descriptions}} for Java classes, {{written in}} a simple assembly-like syntax using Java virtual <b>machine</b> <b>instruction</b> set and generates a Java class file ...|$|R
