14|13|Public
25|$|The cost {{difference}} is more evident {{when compared with}} mutual funds that charge a front-end or <b>back-end</b> <b>load</b> as ETFs do not have loads at all. The redemption fee and short-term trading fees are examples of other fees associated with mutual funds that do not exist with ETFs. Traders should be cautious if they plan to trade inverse and leveraged ETFs for short periods of time. Close attention should be paid to transaction costs and daily performance rates as the potential combined compound loss can sometimes go unrecognized and offset potential gains {{over a longer period}} of time.|$|E
5000|$|<b>Back-end</b> <b>load.</b> Some {{funds have}} a <b>back-end</b> <b>load,</b> which is {{paid by the}} {{investor}} when shares are redeemed. If the <b>back-end</b> <b>load</b> declines the longer the investor holds shares, it is called a contingent deferred sales charges (CDSC). Like the front-end load, the <b>back-end</b> <b>load</b> is paid by the investor; it is deducted from the redemption proceeds.|$|E
5000|$|Neither {{class of}} shares {{typically}} charges a front-end or <b>back-end</b> <b>load</b> ...|$|E
50|$|The {{expense ratio}} equals {{recurring}} fees and expenses charged {{to the fund}} during the year divided by average net assets. The management fee and fund services charges are ordinarily included in the expense ratio; front-end and <b>back-end</b> <b>loads,</b> securities transaction fees and shareholder transaction fees are normally excluded.|$|R
50|$|A single {{mutual fund}} may give investors {{a choice of}} {{different}} combinations of front-end <b>loads,</b> <b>back-end</b> <b>loads</b> and distribution and services fee, by offering several different types of shares, known as share classes. All of them invest in the same portfolio of securities, but each has different expenses and, therefore, a different net asset value and different performance results. Some of these share classes may be available only to certain types of investors.|$|R
50|$|PowerDNS {{is a free}} {{software}} DNS server {{with a variety of}} data storage <b>back-ends</b> and <b>load</b> balancing features. Authoritative and recursive server functions are implemented as separate applications.|$|R
50|$|It's {{similar to}} a <b>back-end</b> <b>load</b> in that no sales charges are paid when buying the fund. Instead a <b>back-end</b> <b>load</b> may be charged if the shares {{purchased}} are sold within a given time frame. The distinction between level loads and low loads as opposed to back-end loads, is that this time frame where charges are levied is shorter.|$|E
50|$|B shares carry a <b>back-end</b> <b>load,</b> whereas A shares carry a {{front-end}} load.|$|E
5000|$|In the United States, a {{fund that}} calls itself [...] "no-load" [...] cannot charge a {{front-end}} load or <b>back-end</b> <b>load</b> under any circumstances and cannot charge a distribution and services fee greater than 0.25% of fund assets ...|$|E
5000|$|Virtual {{relationship}} hyperlink marketing, wherein a major {{search engine}} (like Yahoo's main page) offers articles seemingly presenting interesting news related items, but which are actually <b>back-end</b> <b>loaded</b> with a links page containing multiple [...] "mental references" [...] to film characters, storylines or products. Example: Bond, Transformers, etc..., {{are connected to}} scientific invention news stories about advanced weaponry or robotics discoveries, which quickly leads the reader to pages loaded with the latest 007 or Megatron movie clip or art director's fantastical ideas and designs, thus hooking readers with a [...] "bait and switch" [...] story.|$|R
5000|$|Associated {{with class}} [...] "B" [...] mutual fund shares. Also known as Deferred Sales Charge, {{this is a}} fee paid when shares are sold. Also known as a [...] "back-end load," [...] this fee {{typically}} goes to the Stockbrokers that sell the fund's shares. <b>Back-end</b> <b>loads</b> start with a fee about 5 to 6 percent, which incrementally discounts for each year that the investors own the fund’s shares. The {{rate at which the}} fee declines is disclosed in the prospectus. The amount of this type of load will depend on how long the investor holds his or her shares and typically decreases to zero if the investor holds his or her shares long enough.|$|R
40|$|This paper employs Data Envelopment Analysis {{to measure}} {{for the first}} time the {{performance}} of Greek domestic equity mutual funds over four different one-year horizons and for the whole four-year period. In particular, the model used examines whether fund managers employ inputs (i. e. assets, loads, and risk) efficiently to produce output (returns). The results demonstrate that the efficient funds form the smaller part of the examined sample of funds, the average efficiency rises over time, and that the mean-variance efficiency hypothesis holds for the inefficient funds over the whole period. Moreover, the evidence from the identified sources of inefficiency suggests that fund managers should put more emphasis on the management of assets and the specification of front-end and <b>back-end</b> <b>loads.</b> (JEL: G 20, G 23...|$|R
50|$|Class C shares {{might have}} a 12b-1 fee, other annual expenses, and either a front- or {{back-end}} sales load. But the front- or <b>back-end</b> <b>load</b> for Class C shares tends to be lower than for Class A or Class B shares, respectively. Unlike Class B shares, Class C shares generally do not convert to another class. Class C shares tend to have higher annual expenses than either Class A or Class B shares.|$|E
50|$|The cost {{difference}} is more evident {{when compared with}} mutual funds that charge a front-end or <b>back-end</b> <b>load</b> as ETFs do not have loads at all. The redemption fee and short-term trading fees are examples of other fees associated with mutual funds that do not exist with ETFs. Traders should be cautious if they plan to trade inverse and leveraged ETFs for short periods of time. Close attention should be paid to transaction costs and daily performance rates as the potential combined compound loss can sometimes go unrecognized and offset potential gains {{over a longer period}} of time.|$|E
40|$|The {{absence of}} {{investor}} {{reaction to the}} poor performance of mutual funds is a widely reported phenomenon. This article investigates the role of load costs as {{an explanation for the}} phenomenon and concludes that <b>back-end</b> <b>load</b> fees are an obstacle to reaction. We found evidence consistent with the hypothesis that medium and long-term investors do not react to poor performances {{due to the fact that}} they are 'imprisoned' by <b>back-end</b> <b>load</b> fees. ...|$|E
40|$|Cash flow {{management}} {{is one of}} the most important determinants of the success of construction project management. Overdraft, retainage, financing, payment and billing policies constitute the most significant financial issues that contractors must plan, control and manage for the successful completion of construction jobs. Particularly, in an attempt to reduce project costs, contractors must balance cost savings of material discounts due to early payments and extra interest expenses because of additional overdraft. Through identifying feedback loops in project cash flows, a system dynamics model is developed for project cash flow management. The model is flexible to incorporate typical front-end and <b>back-end</b> <b>loading</b> cash flow management strategies and provides an interactive predication of project cash flows. A warehouse project is discussed to demonstrate how various cash flow strategies improve overdraft financing requirements and profitability. Especially, the analysis shows an 11 % reduction on overdraft requirements while using an overbilling strategy, and 30 % reduction if the trade credit strategy is implemented. Project cash flow, overdraft, cash flow management strategies, system dynamics, scenario analysis,...|$|R
40|$|In recent years, {{the oil and}} gas {{industry}} has been facing unprecedented cost and time overruns while delivering megaprojects both in Norway and internationally. Combined with a dramatic oil price drop, cost overruns became a hot topic in both academic and business worlds. Whilst the project management aspects were in the spotlight, external factors, such as government policies, were paid much less attention. Although, oil companies are cost minimizers, in a situation of a moral hazard presented in the oil and {{gas industry}}, certain petroleum fiscal designs can create incentives for cost inflation. Thus, the focus of the current master thesis is to understand how different fiscal designs affect cost consciousness of the companies on the examples of Norway, UK, Indonesia and China. According to the comparative study, petroleum fiscal design that incorporates high marginal rates on the profits rather than revenues, i. e. more <b>back-end</b> <b>loaded,</b> in combination with additional capital allowances and uplifts, tends to create higher incentives for operators to inflate their costs. However, such a design is also referred to as neutral and provides additional incentives for investments. Therefore, the optimal balance in risk sharing between the company and the host government in petroleum fiscal designs is crucial. nhhma...|$|R
40|$|The paper {{describes}} a novel algorithms for a load balancer, allocates {{the work to}} the clusters of SIP server. The several load balancing algorithms for distributing Session Initiation Protocol (SIP) request to a cluster of SIP servers. This algorithm also supports the following three techniques such as CJSQ, TJSQ and TLWL. It is combine knowledge of the SIP, recognizing variability in call length, dynamic estimates of <b>back-end</b> server <b>load</b> for different SIP transactions. In this paper load balancer improves both throughput and response time. The SIP is a protocol of growing importance, with uses for VOIP, IPTV, audio conferencing, instant messaging. We present {{a detailed analysis of}} occupancy to show how our algorithms significantly reduce response time...|$|R
40|$|The {{absence of}} {{investor}} {{reaction to the}} poor performance of mutual funds is a widely reported phenomenon. This paper investigates the role of load costs as {{an explanation for the}} phenomenon and concludes that <b>back-end</b> <b>load</b> fees are an obstacle to reaction. We find that investors with a high likelihood of undergoing a liquidity crisis, preferring liquidity in decision making, act contrary to the reaction hypothesis, and investors with broader investment horizons do not react to poor performances {{due to the fact that}} they are “imprisoned” by <b>back-end</b> <b>load</b> fees. Mutual Fund, Performance Reaction, Load Costs, Investor Behaviour...|$|E
40|$|Due to a timing {{mismatch}} between fee receipts and commission payments, {{there is a}} new and growing market for securities backed by fees from <b>back-end</b> <b>load</b> and level load mutual funds. This paper develops a contingent claims methodology for the valuation of these securities. The resulting security value depends primarily on the current value of fund assets and the fee schedule. The valuation formula also provides an analytical expression for the appropriate strategy for hedging fluctuations in asset value. As a case study, we investigate the hedging performance of an institution that holds a portfolio of these securities. ...|$|E
40|$|In {{this paper}} we study the {{performance}} reaction of investors {{in a small}} market context. Instead of the asymmetrical investors’ reaction to winners and losers, as usually documented for the US, an absence of risk-adjusted performance reaction was observed. The absence of reaction {{can be attributed to}} either lower investor sophistication, conflicts of interests {{in the context of the}} Portuguese universal banking industry, or the existence of relevant <b>back-end</b> <b>load</b> cost which prevent investors from reacting. A high persistence of net investment flows was also noted. Our results are consistent with the idea that the financial groups with larger market shares have the capacity “to drive” their customers to funds with larger fees. This practice emerges as a non-transparent means of increasing prices. Mutual Funds, Performance Reaction, Investor Behaviour, Small Markets and Regulation...|$|E
40|$|Abstract—This paper {{introduces}} several novel load-balancing algorithms for distributing Session Initiation Protocol (SIP) re-quests to {{a cluster}} of SIP servers. Our load balancer improves both throughput and response time versus a single node while ex-posing a single interface to external clients. We present the design, implementation, and evaluation of our system using {{a cluster of}} Intel x 86 machines running Linux. We compare our algorithms to several well-known approaches and present scalability results for up to 10 nodes. Our best algorithm, Transaction Least-Work-Left (TLWL), achieves its performance by integrating several features: knowledge of the SIP protocol, dynamic estimates of <b>back-end</b> server <b>load,</b> distinguishing transactions from calls, recognizing variability in call length, and exploiting differences in processing costs for different SIP transactions. By combining these features, our algorithm provides finer-grained load balancing than stan-dard approaches, resulting in throughput improvements of up to 24 % and response-time improvements of up to two orders of magnitude. We present {{a detailed analysis of}} occupancy to show how our algorithms significantly reduce response time. Index Terms—Dispatcher, load balancing, performance, server, Session Initiation Protocol (SIP). I...|$|R
40|$|Abstract — This paper {{introduces}} the several load balancing algorithms for distributing Session Initiation Protocol (SIP) request to {{a cluster of}} SIP servers. Our load balancer algorithm Transaction Least Work Left is used to allocate work to least values of the servers. It is combine knowledge of the SIP. Two types of state exist in SIP. The first, session state, is created by the INVITE transaction and is destroyed by the BYE transaction. The session-oriented nature of SIP {{has important implications for}} load balancing. The SIP is a protocol of growing importance, with uses for VOIP, IPTV, audio conferencing, instant messaging. We Session-aware request assignment (SARA) is the process where a system assigns requests to servers such that sessions are properly recognized by that server, and subsequent requests corresponding to that same session are assigned to the same server. We compare our algorithms to several well-known approaches and present scalability results. Our algorithm, Transaction Least-Work-Left (TLWL), achieves its performance by integrating several features: dynamic estimates of <b>back-end</b> server <b>load,</b> knowledge of the SIP protocol, recognizing variability in call length, distinguishing transactions from calls and exploiting differences in processing costs for different SIP transaction...|$|R
40|$|Graduation date: 2008 The Arc Marine {{data model}} is a {{generalized}} template to guide the implementation of geographic information systems (GIS) projects in the marine environment. Arc Marine developed out of a collaborative process involving research and industry shareholders in coastal and marine research. This template models and attempts to standardize common marine data types to facilitate data sharing and analytical tool development. The {{next step in the}} development of Arc Marine is adaptation to the problems of specific research communities, and specific programs, under the broad umbrella of coastal and marine research by community specific customization of Arc Marine. In this study, Arc Marine was customized from its core model to fit the research goals of the whale satellite telemetry tagging program of the Oregon State University Marine Mammal Institute (MMI). This customization serves as a case study of the ability of Arc Marine to achieve its six primary objectives {{in the context of the}} marine animal tracking community. These objectives are: 1) to create a common model for assembling, managing, and publishing tracking data sets; 2) to produce, share, and exchange these tracking data in a similar format and standard structure; 3) to provide a unified approach for community software developers extending the capabilities of ArcGIS; 4) to extend the power of marine geospatial analysis through a framework for incorporating object-oriented behaviors and for dealing with scale dependencies; 5) to provide a mechanism for the implementation of data content standards; and 6) to aid researchers in a fuller understanding of object-oriented GISs and the power of advanced spatial data structures. The primary question examined in this thesis is: How can the Arc Marine data model be customized to best meet the research objectives of the OSU MMI and the marine mammal tracking community, in order to explore the relationship of the distribution and movement of endangered marine mammal species to underlying physical and biological oceanographic processes? The MMI customization of Arc Marine is focused on the use of Argos satellite telemetry tagging. The customized database schema was described in Universal Markup Language by modification of the core Arc Marine data model in Microsoft Visio 2003 and implemented as an ArcGIS 9. 2 geodatabase (personal, file, and ArcSDE). Tool development and scripting were carried out predominantly in Python 2. 4. The two major schema modifications of the MMI customization were the implementation of the Animal and AnimalEvent object classes. The Animal class is a subclass of Vehicle and models the tagged animal as a tracked instrument platform carrying an array of sensors to measure its environment. The AnimalEvent class represents interactions in time between the Animal and an open-ended range of event types including field observations, tagging, sensor measurements, and satellite geolocating. A programming interface is described for AnimalEvent (AnimalEventUI) and the InstantaneousPoint feature class (InstantaneousPointUI) that represents observed animal locations. Further customization came through the development of a comprehensive development framework for animal tracking in Arc Marine. This framework implements front-end analysis tools through Python scripting, ArcGIS extensions, or standalone applications developed in VB. NET. <b>Back-end</b> database <b>loading</b> is implemented in Python through the ArcGIS geoprocessing object and the DB-API 2. 0 database abstraction layer. Through a description of the multidimensional data cube model of Arc Marine, Arc Marine and the MMI customization are demonstrated to be foundation schemas for a relational database management system (RDBMS), object relational database management system (ORDBMS), or enterprise spatial data warehouse. This modeling method shows that Arc Marine is built upon atomic measures (scalar quantities, vector quantities, points, lines, and polygons) that are described by related dimensional tables (such as time, data parameters, tagged animal, or species) and concept hierarchies of different levels generalization (for example, tag < animal < social group < population < species). This data cube structure further shows that Arc Marine is an appropriate target schema for the application of on-line analytical processing (OLAP) tools, data mining, and spatial data mining to satellite telemetry tracking datasets. In this customization case study, Arc Marine partially meets each of its six major goals. In particular, the development of the MMI application development platform demonstrates full implementation of a unified approach for community software developers. Meanwhile, the data cube model of Arc Marine for OLAP demonstrates a successful extension of marine geospatial analysis to deal more effectively with scale dependencies and a mechanism for the expansion of researchers’ understanding of high power analytical methods...|$|R
40|$|Due to a timing {{mismatch}} between fee receipts and commission payments, {{there is a}} new and growing market for securities backed by fees from <b>back-end</b> <b>load</b> and level load mutual funds. This paper develops a contingent claims methodology for the valuation of these securities. The resulting security value depends primarily on the current value of fund assets and the fee schedule. The valuation formula also provides an analytical expression for the appropriate strategy for hedging uctuations in asset value. As a case study, we investigate The mutual fund industry manages over six trillion dollars of assets. These funds are o ered by avariety of di erent sponsors, many of whom either do not market their product directly or are not the sole marketers of their product to potential investors. Instead, these mutual funds rely on brokerage houses to help market and sell their funds. Approximately 14...|$|E
40|$|Our {{analysis}} of daily index fund flows indicates a strong contemporaneous correlation between fund inflows and S&P market returns. We also document a strong {{negative correlation between}} fund out flows and S&P market returns {{with the exception of}} outflows from a <b>back-end</b> <b>load</b> fund. These effects may be interpreted in two ways. Either investor supply and demand affects S&P market prices, or investors condition their demand and supply on intra-day market fluctuations. To sort out these effects, we examine trailing investor reaction to market moves. Our results suggest the market reacts to daily demand. However, only negative reactions appear due to past returns. We investigate whether index investor demand shocks are permanent or temporary by examining the related behavior of the S&P futures index. Clear evidence supports the hypothesis that they are permanent. This result may help explain the unusual recent relative performance of the S&P 500 index. Using the average market-timing newsletter recommendation over the period, we find that investors appear to react to "expert" advice about the market. Bullish newsletter sentiment is associated with greater inflows, although outflows are not well explained by newsletter advice. Dispersion in advice is associated with lower inflows. We find a high correlation among a number of variables used as a proxy for investor disagreement. ...|$|E
40|$|Switching {{is the key}} {{functionality}} {{for many}} devices like electronic Router and Switch, optical Router, Network on Chips (NoCs) and so on. Basically, switching is responsible for moving data unit from one port/location to another (or multiple) port(s) /location(s). In past years, the high capacity, low delay were the main concerns when designing high-end switching unit. As new demands, requests and technologies emerge, flexibility and low power cost switching design become to weight the same as throughput and delay. On one hand, highly flexible (i. e, programming ability) switching can cope with variable needs stem from new applications (i. e, VoIP) and popular user behavior (i. e, p 2 p downloading); on the other hand, reduce the energy and power dissipation for switching could not only save bills and build echo system but also expand components life time. Many research efforts have been devoted to increase switching flexibility and reduce its power cost. In this thesis work, we consider to exploit virtualization as the main technique to build flexible software router in the first part, then {{in the second part}} we draw our attention on energy saving in NoC (i. e, a switching fabric designed to handle the on chip data transmission) and software router. In {{the first part of the}} thesis, we consider the virtualization inside Software Routers (SRs). SR, i. e, routers running in commodity Personal Computers (PCs), become an appealing solution compared to traditional Proprietary Routing Devices (PRD) for various reasons such as cost (the multi-vendor hardware used by SRs can be cheap, while the equipment needed by PRDs is more expensive and their training cost is higher), openness (SRs can make use of a large number of open source networking applications, while PRDs are more closed) and flexibility. The forwarding performance provided by SRs has been an obstacle to their deployment in real networks. For this reason, we proposed to aggregate multiple routing units that form an powerful SR known as the Multistage Software Router (MSR) to overcome the performance limitation for a single SR. Our results show that the throughput can increase almost linearly as the number of the internal routing devices. But some other features related to flexibility (such as power saving, programmability, router migration or easy management) have been investigated less than performance previously. We noticed that virtualization techniques become reality thanks to the quick development of the PC architectures, which are now able to easily support several logical PCs running in parallel on the same hardware. Virtualization could provide many flexible features like hardware and software decoupling, encapsulation of virtual machine state, failure recovery and security, to name a few. Virtualization permits to build multiple SRs inside one physical host and a multistage architecture exploiting only logical devices. By doing so, physical resources can be used in a more efficient way, energy savings features (switching on and off device when needed) can be introduced and logical resources could be rented on-demand instead of being owned. Since virtualization techniques are still difficult to deploy, several challenges need to be faced when trying to integrate them into routers. The main aim of the first part in this thesis is to find out the feasibility of the virtualization approach, to build and test virtualized SR (VSR), to implement the MSR exploiting logical, i. e. virtualized, resources, to analyze virtualized routing performance and to propose improvement techniques to VSR and virtual MSR (VMSR). More specifically, we considered different virtualization solutions like VMware, XEN, KVM to build VSR and VMSR, being VMware a closed source solution but with higher performance and XEN/KVM open source solutions. Firstly we built and tested each single component of our multistage architecture (i. e, <b>back-end</b> router, <b>load</b> balancer) inside the virtual infrastructure, then and we extended the performance experiments with more complex scenarios like multiple Back-end Router (BR) or Load Balancer (LB) which cooperate to route packets. Our results show that virtualization could introduce 40 % performance penalty compare with the hardware only solution. Keep the performance limitation in mind, we developed the whole VMSR and we obtained low throughput with 64 B packet flow as expected. To increase the VMSR throughput, two directions could be considered, the first one is to improve the single component (i. e, VSR) performance and the other is to work from the topology (i. e, best allocation of the VMs into the hardware) point of view. For the first method, we considered to tune the VSR inside the KVM and we studied closely such as Linux driver, scheduler, interconnect methodology which could impact the performance significantly with proper configuration; then we proposed two ways for the VMs allocation into physical servers to enhance the VMSR performance. Our results show that with good tuning and allocation of VMs, we could minimize the virtualization penalty and get reasonable throughput for running SRs inside virtual infrastructure and add flexibility functionalities into SRs easily. In the second part of the thesis, we consider the energy efficient switching design problem and we focus on two main architecture, the NoC and MSR. As many research works suggest, the energy cost in the Communication Technologies (ICT) is constantly increasing. Among the main ICT sectors, a large portion of the energy consumption is contributed by the telecommunication infrastructure and their devices, i. e, router, switch, cell phone, ip TV settle box, storage home gateway etc. More in detail, the linecards, links, System on Chip (SoC) including the transmitter/receiver on these variate devices are the main power consuming units. We firstly present the work on the power reduction of the data transmission in SoC, which is carried out by the NoC. NoC is an approach to design the communication subsystem between different Processing Units (PEs) in a SoC. PEs could be different elements such as CPU, memory, digital signal/analog signal processor etc. Different PEs performs specific tasks depending on the applications running on the chip. Different tasks need to exchange data information among each other, thus flits (chopped packet with limited header information) are generated by PEs. The flits are injected into the NoC by the proper interface and routed until reach the destination PEs. For the whole procedure, the NoC behaves as a packet switch network. Studies show that in general the information processing in the PEs only consume 60 % energy while the remaining 40 % are consumed by the NoC. More importantly, as the current network designing principle, the NoC capacity is devised to handle the peak load. This is a clear sign for energy saving when the network load is low. In our work, we considered to exploit Dynamic Voltage and Frequency Scaling (DVFS) technique, which can jointly decrease or increase the system voltage and frequency when necessary, i. e, decrease the voltage and frequency at low load scenario to save energy and reduce power dissipation. More precisely, we studied two different NoC architectures for energy saving, namely single plane chip and multi-plane chip architecture. In both cases we have a very strict constraint to be that all the links and transmitter/receivers on the same plane work at the same frequency/voltage to avoid synchronization problem. This is the main difference with many existing works in the literature which usually assume different links can work at different frequency, that is hard to be implemented in reality. For the single plane NoC, we exploited different routing schemas combined with DVFS to reduce the power for the whole chip. Our results haven been compared with the optimal value obtained by modeling the power saving formally as a quadratic programming problem. Results suggest that just by using simple load balancing routing algorithm, we can save considerable energy for the single chip NoC architecture. Furthermore, we noticed that in the single plane NoC architecture, the bottleneck link could limit the DVFS effectiveness. Then we discovered that multiplane NoC architecture is fairly easy to be implemented and it could help with the energy saving. Thus we focus on the multiplane architecture and we found out that DVFS could be more efficient when we concentrate more traffic into one plane and send the remaining flows to other planes. We compared load concentration and load balancing with different power modeling and all simulation results show that load concentration is better compared with load balancing for multiplan NoC architecture. Finally, we also present one of the the energy efficient MSR design technique, which permits the MSR to follow the day-night traffic pattern more efficiently with our on-line energy saving algorithm...|$|R

