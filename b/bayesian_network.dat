5720|5694|Public
25|$|A <b>Bayesian</b> <b>network,</b> Bayes network, belief network, Bayes(ian) {{model or}} {{probabilistic}} directed acyclic graphical {{model is a}} probabilistic graphical model (a type of statistical model) that represents a set of random variables and their conditional dependencies via a directed acyclic graph (DAG). For example, a <b>Bayesian</b> <b>network</b> could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network {{can be used to}} compute the probabilities of the presence of various diseases.|$|E
25|$|The hidden markov {{model can}} be {{represented}} as the simplest dynamic <b>Bayesian</b> <b>network.</b> The mathematics behind the HMM were developed by L. E. Baum and coworkers.|$|E
25|$|To {{develop a}} <b>Bayesian</b> <b>network,</b> we often first develop a DAG G such {{that we believe}} X {{satisfies}} the local Markov property with respect to G. Sometimes this is done by creating a causal DAG. We then ascertain the conditional probability distributions of each variable given its parents in G. In many cases, in particular in the case where the variables are discrete, if we define the joint distribution of X to be the product of these conditional distributions, then X is a <b>Bayesian</b> <b>network</b> with respect to G.|$|E
40|$|In this paper, {{we propose}} an {{algebraic}} characterization for equivalent classes of <b>Bayesian</b> <b>networks.</b> Unlike the other characterizations, {{which are based}} on the graphical structure of <b>Bayesian</b> <b>networks,</b> our algebraic characterization is derived from the intrinsic algebraic structure of <b>Bayesian</b> <b>networks,</b> i. e., joint probability distribution factorization. The new proposed algebraic characterization not only provides us with a new perspective to look into equivalent <b>Bayesian</b> <b>networks,</b> but also suggests simple and efficient methods for determining equivalence of <b>Bayesian</b> <b>networks</b> and identifying compelled edges in <b>Bayesian</b> <b>networks.</b> ...|$|R
25|$|Efficient {{algorithms}} {{exist that}} perform inference {{and learning in}} <b>Bayesian</b> <b>networks.</b> <b>Bayesian</b> <b>networks</b> that model sequences of variables (e.g. speech signals or protein sequences) are called dynamic <b>Bayesian</b> <b>networks.</b> Generalizations of <b>Bayesian</b> <b>networks</b> that can represent and solve decision problems under uncertainty are called influence diagrams.|$|R
40|$|The {{continuous}} {{growth of}} data {{has created a}} demand for better data fusion algorithms. In this study {{we have used a}} method called <b>Bayesian</b> <b>networks</b> to answer the demand. The reason why <b>Bayesian</b> <b>networks</b> are used in wide range of applications is that modelling with <b>Bayesian</b> <b>networks</b> offers easy and straightforward representation for combining a priori knowledge with the observations. Another reason for growing use of the <b>Bayesian</b> <b>networks</b> is that <b>Bayesian</b> <b>networks</b> can combine attributes having different dimensions. In addition to the quite well-known theory of discrete and continuous <b>Bayesian</b> <b>networks,</b> we introduce a reasoning scheme to the hybrid <b>Bayesian</b> <b>networks.</b> The reasoning method used is based on polytree algorithm. Our aim is to show how to apply the hybrid <b>Bayesian</b> <b>networks</b> to identification. Also one method to achieve dynamic features is discussed. We have simulated dynamic hybrid <b>Bayesian</b> <b>networks</b> in order to identify aircraft in noisy environment...|$|R
25|$|There {{are several}} {{equivalent}} definitions of a <b>Bayesian</b> <b>network.</b> For all the following, let G = (V,E) be a {{directed acyclic graph}} (or DAG), and let X = (X'v)v ∈ V be a set of random variables indexed by V.|$|E
25|$|Because a <b>Bayesian</b> <b>network</b> is a {{complete}} model for the variables and their relationships, {{it can be used}} to answer probabilistic queries about them. For example, the network can be used to find out updated knowledge of the state of a subset of variables when other variables (the evidence variables) are observed. This process of computing the posterior distribution of variables given evidence is called probabilistic inference. The posterior gives a universal sufficient statistic for detection applications, when one wants to choose values for the variable subset which minimize some expected loss function, for instance the probability of decision error. A <b>Bayesian</b> <b>network</b> can thus be considered a mechanism for automatically applying Bayes' theorem to complex problems.|$|E
25|$|In the {{simplest}} case, a <b>Bayesian</b> <b>network</b> is specified by an expert and is {{then used to}} perform inference. In other applications the task of defining the network is too complex for humans. In this case the network structure and {{the parameters of the}} local distributions must be learned from data.|$|E
40|$|Abstract. In this paper, we {{describe}} the Hugin Tool as an efficient tool for knowledge discovery through construction of <b>Bayesian</b> <b>networks</b> by fusion of data and domain expert knowledge. The Hugin Tool supports structural learning, parameter estimation, and adaptation of parameters in <b>Bayesian</b> <b>networks.</b> The performance of the Hugin Tool is illustrated using real-world <b>Bayesian</b> <b>networks,</b> commonly used examples from the literature, and randomly generated <b>Bayesian</b> <b>networks.</b> ...|$|R
40|$|Key words: fault tree; the Bayesian networks; metro construction; safety {{evaluation}} Abstract. The paper introduced the <b>Bayesian</b> <b>networks</b> briefly and discussed the algorithm of transforming fault tree into <b>Bayesian</b> <b>networks</b> at first, then regarded the structures impaired caused by tunnel blasting construction as a example, introduced the built and calculated method of the <b>Bayesian</b> <b>networks</b> by matlab. Then assumed the probabilities of essential events, calculated {{the probability of}} top event and the posterior probability of each essential events by the <b>Bayesian</b> <b>networks.</b> After that the paper contrast the characteristics of fault tree analysis and the <b>Bayesian</b> <b>networks,</b> Identified that the <b>Bayesian</b> <b>networks</b> is better than fault tree analysis in {{safety evaluation}} in some case, and provided a valid way to assess risk in metro construction...|$|R
50|$|Bayesian {{programming}} {{may also}} be seen as an algebraic formalism to specify graphical models such as, for instance, <b>Bayesian</b> <b>networks,</b> dynamic <b>Bayesian</b> <b>networks,</b> Kalman filters or hidden Markov models. Indeed, Bayesian Programming is more general than <b>Bayesian</b> <b>networks</b> and has a power of expression equivalent to probabilistic factor graphs.|$|R
25|$|Suppose {{that there}} are two events which could cause grass to be wet: either the {{sprinkler}} is on or it's raining. Also, suppose that the rain has a direct effect {{on the use of the}} sprinkler (namely that when it rains, the sprinkler is usually not turned on). Then the situation can be modeled with a <b>Bayesian</b> <b>network</b> (shown to the right). All three variables have two possible values, T (for true) and F (for false).|$|E
25|$|The Markov {{blanket of}} a node is {{the set of}} nodes {{consisting}} of its parents, its children, and any other parents of its children. The Markov blanket renders the node independent {{of the rest of}} the network; the joint distribution of the variables in the Markov blanket of a node is sufficient knowledge for calculating the distribution of the node. X is a <b>Bayesian</b> <b>network</b> with respect to G if every node is conditionally independent of all other nodes in the network, given its Markov blanket.|$|E
25|$|A causal {{network is}} a <b>Bayesian</b> <b>network</b> with an {{explicit}} {{requirement that the}} relationships be causal. The additional semantics of the causal networks specify that if a node X is actively caused {{to be in a}} given state x (an action written as do(X=x)), then the probability density function changes to the one of the network obtained by cutting the links from the parents of X to X, and setting X to the caused value x. Using these semantics, one can predict the impact of external interventions from data obtained prior to intervention.|$|E
5000|$|... aGrUM: C++ library (with Python bindings) for {{different}} types of PGMs including <b>Bayesian</b> <b>Networks</b> and Dynamic <b>Bayesian</b> <b>Networks</b> (released under the GPLv3) ...|$|R
40|$|<b>Bayesian</b> <b>networks</b> {{are widely}} used for {{knowledge}} representation and uncertain reasoning. One {{of the most important}} services which <b>Bayesian</b> <b>networks</b> provide is (probabilistic) inference. Effective inference algorithms have been developed for probabilistic inference in <b>Bayesian</b> <b>networks</b> for many years. However, the effectiveness of the inference algorithms depends on the sizes of <b>Bayesian</b> <b>networks.</b> As the sizes of <b>Bayesian</b> <b>networks</b> become larger and larger in real applications, the inference algorithms become less effective and sometimes are even unable to carry out inference. In this thesis, a new inference algorithm specifically designed for large and complex <b>Bayesian</b> <b>networks,</b> called 2 ̆ 7 path propagation 2 ̆ 7, is proposed. Path propagation takes full advantage {{of one of the most}} popular inference algorithms, i. e., global propagation. It improves over global propagation by carrying out inference only in certain paths in a junction tree that are relevant to queries. Compared with global propagation, path propagationtakes less computational resources and can effectively improve the computational efficiency for inference in large and complex <b>Bayesian</b> <b>networks...</b>|$|R
40|$|This {{dissertation}} {{studies the}} algebraic varieties {{arising from the}} conditional independence statements of <b>Bayesian</b> <b>networks.</b> Reduction techniques are described for relating these varieties to the varieties for smaller <b>Bayesian</b> <b>networks.</b> Particular {{attention is paid to}} the issues of primality, dimension, and degree. A classification of 5 -node <b>Bayesian</b> <b>networks</b> is given based on {{whether or not they are}} prime for all state vectors. A proof of the Degree- 2 Conjecture is given for a subclass of <b>Bayesian</b> <b>networks</b> which includes those with binomial global Markov ideal...|$|R
25|$|Likened to a <b>Bayesian</b> <b>network,</b> an HTM {{comprises}} {{a collection}} of nodes that are arranged in a tree-shaped hierarchy. Each node in the hierarchy discovers an array of causes in the input patterns and temporal sequences it receives. A Bayesian belief revision algorithm is used to propagate feed-forward and feedback beliefs from child to parent nodes and vice versa. However, the analogy to Bayesian networks is limited, because HTMs can be self-trained (such that each node has an unambiguous family relationship), cope with time-sensitive data, and grant mechanisms for covert attention.|$|E
25|$|When {{activity}} {{recognition is}} performed indoors and in cities using the widely available Wi-Fi signals and 802.11 access points, {{there is much}} noise and uncertainty. These uncertainties are modeled using a dynamic <b>Bayesian</b> <b>network</b> model by Yin et al. A multiple goal model that can reason about user's interleaving goals is presented by Chai and Yang, where a deterministic state transition model is applied. A better model that models the concurrent and interleaving activities in a probabilistic approach is proposed by Hu and Yang. A user action discovery model is presented by Yin et al., where the Wi-Fi signals are segmented to produce possible actions.|$|E
25|$|In {{practical}} terms, these complexity results {{suggested that}} while Bayesian networks were rich representations for AI and machine learning applications, {{their use in}} large real-world applications {{would need to be}} tempered by either topological structural constraints, such as naïve Bayes networks, or by restrictions on the conditional probabilities. The bounded variance algorithm was the first provable fast approximation algorithm to efficiently approximate probabilistic inference in Bayesian networks with guarantees on the error approximation. This powerful algorithm required the minor restriction on the conditional probabilities of the <b>Bayesian</b> <b>network</b> to be bounded away from zero and one by 1/p(n) where p(n) was any polynomial on the number of nodes in the network n.|$|E
40|$|Includes abstract. Includes bibliographical {{references}} (leaves 181 - 203). In this thesis, {{a methodology}} for integrated catchment water resources assessment using <b>Bayesian</b> <b>Networks</b> was developed. A custom made software application that combines <b>Bayesian</b> <b>Networks</b> with GIS {{was used to}} facilitate data pre-processing and spatial modelling. Dynamic <b>Bayesian</b> <b>Networks</b> were implemented in the software for time-series modelling...|$|R
40|$|<b>Bayesian</b> <b>Networks</b> are an {{extremely}} powerful and useful method for reasoning. However, surprisingly few people {{outside of a}} small community of Artificial Intelligence researchers actually have a working knowledge of <b>Bayesian</b> <b>Networks.</b> We describe in this paper our goal of enabling students to more readily use <b>Bayesian</b> <b>Networks,</b> the software tool we have developed to achieve this goal, and our motivation for the various design aspects of the tool. 1 INTRODUCTION When faced with something new, people commonly ask two questions, who and why. Here, those questions would be: who uses <b>Bayesian</b> <b>Networks</b> and why are they used? <b>Bayesian</b> <b>Networks</b> are typically used by Artificial Intelligence researchers who have an excellent background in and understanding of reasoning and probability theory. Applications for <b>Bayesian</b> <b>Networks</b> include medical diagnosis, traffic scene analysis [7], map learning, and computer vision/perceptual grouping problems [8]. Charniak [2] says that "It is probably fair to [...] ...|$|R
40|$|<b>Bayesian</b> <b>networks</b> {{for large}} and complex domains are dicult to {{construct}} and maintain. For example modifying a small network fragment in a repetitive structure might be very time consuming. Top-down modelling may simplify the construction of large <b>Bayesian</b> <b>networks,</b> but methods (partly) supporting top-down modelling have only recently been introduced and tools do not exist. In this paper, we try to take a topdown approach to constructing <b>Bayesian</b> <b>networks</b> by using existing object oriented methods. We change these where they fail to support top-down modeling. This provides a new framework that allows topdown methodologies {{for the construction of}} <b>Bayesian</b> <b>networks,</b> provides an ecient class hierarchy and a compact way of specifying and representing temporal <b>Bayesian</b> <b>networks.</b> Furthermore, a conceptual simpli- cation is achieved. Introduction Constructing and maintaining <b>Bayesian</b> <b>networks</b> (BNs) can be a time consuming process. Using current methods and tools, a top-down a [...] ...|$|R
500|$|Similarly, topological orderings of DAGs {{can be used}} {{to order}} the {{compilation}} operations in a makefile. The program evaluation and review technique uses DAGs to model the milestones and activities of large human projects, and schedule these projects to use as little total time as possible. Combinational logic blocks in electronic circuit design, and the operations in dataflow programming languages, involve acyclic networks of processing elements. DAGs can also represent collections of events and their influence on each other, either in a probabilistic structure such as a <b>Bayesian</b> <b>network</b> or as a record of historical data such as family trees or the version histories of [...] distributed revision control systems. DAGs can also be used as a compact representation of sequence data, such as the directed acyclic word graph representation of a collection of strings, or the binary decision diagram representation of sequences of binary choices. More abstractly, ...|$|E
500|$|Sometimes {{events are}} not {{associated}} with a specific physical time. [...] Provided that pairs of events have a purely causal relationship, that is edges represent causal relations between the events, {{we will have a}} directed acyclic graph. For instance, a <b>Bayesian</b> <b>network</b> represents a system of probabilistic events as vertices in a directed acyclic graph, in which the likelihood of an event may be calculated from the likelihoods of its predecessors in the DAG. In this context, the moral graph of a DAG is the undirected graph created by adding an (undirected) edge between all parents of the same vertex (sometimes called marrying), and then replacing all directed edges by undirected edges. Another type of graph with a similar causal structure is an influence diagram, the vertices of which represent either decisions to be made or unknown information, and the edges of which represent causal influences from one vertex to another. In epidemiology, for instance, these diagrams are often used to estimate the expected value of different choices for intervention.|$|E
2500|$|The term {{hierarchical}} model is sometimes considered {{a particular type}} of <b>Bayesian</b> <b>network,</b> but has no formal definition. Sometimes the term is reserved for models with three or more levels of random variables; other times, it is reserved for models with latent variables. In general, however, any moderately complex <b>Bayesian</b> <b>network</b> is usually termed [...] "hierarchical".|$|E
40|$|In current constraint-based (Pearl-style) {{systems for}} {{discovering}} <b>Bayesian</b> <b>networks,</b> inputs with deterministic relations are prohibited. This restricts {{the applicability of}} these systems. In this paper, we formalize a sufficient condition under which <b>Bayesian</b> <b>networks</b> can be recovered even with deterministic relations. The sufficient condition leads to an improvement to Pearl’s IC algorithm; other constraint-based algorithms can be similarly improved. The new algorithm, assuming the sufficient condition proposed, is able to recover <b>Bayesian</b> <b>networks</b> with deterministic relations, and moreover suffers no loss of performance when applied to nondeterministic <b>Bayesian</b> <b>networks...</b>|$|R
40|$|This paper {{considers}} the computational power of constant size, dynamic <b>Bayesian</b> <b>networks.</b> Although discrete dynamic <b>Bayesian</b> <b>networks</b> {{are no more}} powerful than hidden Markov models, dynamic <b>Bayesian</b> <b>networks</b> with continuous random variables and discrete children of continuous parents are capable of performing Turing-complete computation. With modified versions of existing algorithms for belief propagation, such a simulation {{can be carried out}} in real time. This result suggests that dynamic <b>Bayesian</b> <b>networks</b> may be more powerful than previously considered. Relationships to causal models and recurrent neural networks are also discussed...|$|R
40|$|Abstract. <b>Bayesian</b> <b>networks</b> for {{the static}} {{as well as}} for the dynamic case have gained an {{enormous}} interest in the research community of machine learning and pattern recognition. Although the parallels between dynamic <b>Bayesian</b> <b>networks</b> and Kalman filters are well-known since many years, <b>Bayesian</b> <b>networks</b> have not been applied to problems in the area of adaptive control of dynamic systems. In our work we exploit the well-known similarities between <b>Bayesian</b> <b>networks</b> and Kalman filters to model and control linear dynamic systems using dynamic <b>Bayesian</b> <b>networks.</b> The analytical models are compared with models being trained with step and impulse response. The experiments show that the analytical model as well as the trained model are suitable for control purposes, which leads to the idea of self adaptive controllers...|$|R
2500|$|X is a <b>Bayesian</b> <b>network</b> {{with respect}} to G if, for any two nodes u, v: ...|$|E
2500|$|Using a <b>Bayesian</b> <b>network</b> {{can save}} {{considerable}} amounts of memory, if the dependencies {{in the joint}} distribution are sparse. For example, a naive way of storing the conditional probabilities of 10 two-valued variables as a table requires storage space for [...] values. If the local distributions of no variable depends on more than three parent variables, the <b>Bayesian</b> <b>network</b> representation only needs to store at most [...] values.|$|E
2500|$|Automatically {{learning}} the graph {{structure of a}} <b>Bayesian</b> <b>network</b> (BN) is a challenge pursued within machine learning. The basic idea goes back to a recovery algorithm ...|$|E
40|$|<b>Bayesian</b> <b>networks</b> are formal {{graphical}} languages for {{representation and}} communication of decision scenarios requiring reasoning under uncertainty. We will analyze <b>Bayesian</b> <b>networks</b> and outline their advantages and disadvantages. Based on these assumptions we discuss transport decision scenarios under uncertainty. A transport planning approach like the postal delivery demonstrates a good framework for building and handling with normative systems like <b>Bayesian</b> <b>networks...</b>|$|R
40|$|<b>Bayesian</b> <b>networks</b> for {{the static}} {{as well as}} for the dynamic case have gained an {{enormous}} interest in the research community of artificial intelligence, machine learning and pattern recognition. Although the parallels between dynamic <b>Bayesian</b> <b>networks</b> and Kalman filters are well known since many years, <b>Bayesian</b> <b>networks</b> have not been applied to problems in the area of adaptive control of dynamic systems...|$|R
40|$|<b>Bayesian</b> <b>Networks</b> {{are being}} used {{extensively}} for reasoning under uncertainty. Inference mechanisms for <b>Bayesian</b> <b>Networks</b> are compromised {{by the fact that}} they can only deal with propositional domains. In this work, we introduce an extension of that formalism, Hierarchical <b>Bayesian</b> <b>Networks,</b> that can represent additional information about the structure of the domains of variables. Hierarchical <b>Bayesian</b> <b>Networks</b> are similar to <b>Bayesian</b> <b>Networks,</b> in that they represent probabilistic dependencies between variables as a directed acyclic graph, where eachnodeofthe graph corresponds to a random variable and is quanti#ed by the conditional probability of that variable given the values of its parents in the graph. What extends the expressivepower of Hierarchical <b>Bayesian</b> <b>Networks</b> is that a node may correspond to an aggregation of simpler types. A component of one node may itself represent a composite structure; this allows the representation of complex hierarchical domains. Furthermore, probabilistic dependencies can be expressed at any level, between nodes that are contained in the same structure...|$|R
