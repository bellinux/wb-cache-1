2|8|Public
40|$|Performance-based {{contracting}} (PBC) for roadway {{maintenance is}} relatively new among various alternative contracting options available at present and is increasingly drawing more attention from state Departments of Transportation (DOTs) and the contracting community. Because performance-based maintenance contracts extend over multiple years (typically 5 - 7 years) and shift performance risk to contractors, {{it is critical that}} contractors be selected based on a form of best-value method rather than on the conventional low-bid method. Currently, highway agencies use various methods for determining the best-value bid based on cost and technical scores. Five best-value <b>bid</b> <b>identification</b> methods that are already in practice by the state transportation agencies in Florida, Virginia, North Carolina, United Kingdom, and New Zealand were used as case studies for this research. These five methods were evaluated in terms of the agency?s willingness to pay for quality and the neutrality of these methods with respect to lowest bid and highest quality. To understand and describe the bid evaluation method, the agency can develop a willingness to pay (WTP) curve. This curve should represent the agency?s needs and budget, reflect their project characteristics, and accommodate associated performance risks. An Excel macro based software tool has been developed that automates these five best-value <b>bid</b> <b>identification</b> methods and also helps customize anyone of these options for any agency...|$|E
40|$|The {{traditional}} design-bid-build {{methods for}} designing, constructing, inspecting, and financing highway projects are rapidly changing. The traditional methods are being consolidated into {{a relatively new}} contracting method called design-bid (D-B) that offers more opportunities for innovation, value engineering, risk-sharing, efficient coordination, as well as economization of time and money. ^ A review of eight D-B projects from Texas, Minnesota, Washington State, and Utah (conducted under this research) revealed that bid evaluation methods are subjective and rely on simplistic averaging of cost and proposal quality (or technical) ratings. These practices {{are more prone to}} face legal challenges since they tend to be ambiguous and subjective. Additionally, these practices evaluate cost and proposal quality independently (i. e., cost is evaluated regardless of the proposed quality and visa versa). This might lead to reduced prices, {{but at the same time}} lower quality. A model for best <b>bid</b> <b>identification</b> was developed based on Game theory. The selection of best bid is modeled as a two-person cooperative game between quality and cost. In other words, the objective is to find the arbitration values of cost and quality. Apart from selecting the best bid, this model helps to identify best value for cost and quality, which are not necessary the values provided by any bidder. These best values for cost and quality might help for finalizing final contract with selected bidder. ...|$|E
40|$|This paper {{proposes a}} semiparametric {{estimation}} procedure of the first-price auction model with risk averse bidders within the independent private values paradigm. We {{show that the}} model is nonidentified in general from observed <b>bids.</b> Thus <b>identification</b> of the model must be achieved through additional restrictions. We then exploit heterogeneity across auctioned objects to establish semiparametric identification under a common but unknown support condition and parameterization of the bidders' utility function. Next we propose a semiparametric method for estimating the corresponding auction model. This method involves several steps and allows to recover {{the parameters of the}} utility function as well as the bidders' private values and their density. In particular, we show that our semiparametric estimator of the utility function parameter(s) converges at the optimal rate, which is slower than the parametric one. An illustration of the method on U. S. Forest Service timber sales is [...] ...|$|R
40|$|Negotiation {{scenarios}} involving nonlinear utility {{functions are}} specially challenging, because traditional negotiation mechanisms cannot be applied. Even mechanisms designed and proven useful for nonlinear utility spaces may fail if the utility space is highly nonlinear. For example, although both contract sampling and constraint sampling {{have been successfully}} used in auction based negotiations with constraint-based utility spaces, they tend to fail in highly nonlinear utility scenarios. In this paper, we will show that the performance of these approaches decrease drastically in highly nonlinear utility scenarios, and propose a mechanism which balances utility and deal probability for the <b>bidding</b> and deal <b>identification</b> processes. The experiments show that the proposed mechanisms yield better results than the previous approaches in highly nonlinear negotiation scenarios. ...|$|R
40|$|The {{building}} <b>identification</b> (<b>BID)</b> {{problem is}} based on a process that uses publicly available information to automatically assign addresses to buildings in satellite imagery. In previous work, we have shown the advantages of casting the BID problem as a Constraint Satisfaction Problem (CSP) using the same generic constraint-model to represent all problem instances. However, a generic model is unable to represent with the necessary precision the addressing variations throughout the world, limiting the applicability of our previous approach. In this paper, we describe the end-to-end process used to solve the BID with a new model-generation technique that uses instance-specific information to automatically infer a representative constraint model of the BID. This inferred model is used by our custom constraint solver to identify buildings in satellite imagery more efficiently and with higher precision than using a single model. We evaluate our approach on El Segundo California, and empirically demonstrate its effectiveness for geographic areas larger than previously tested. We conclude with a discussion of the generality of our approach, and present directions for future work...|$|R
40|$|Consider {{the problem}} of mapping postal {{addresses}} to buildings in satellite imagery using publicly available information, defined as the Building <b>Identification</b> (<b>BID)</b> problem in [1]. This problem takes as input a bounding box that defines the area of a satellite image, buildings identified in the image, vector information that specifies streets in the image, {{and a set of}} phone-book entries for the area. The task is to find the set of possible address assignments for each building. In [1], we showed how the task can be framed as a Constraint Satisfaction Problem (CSP), which we solved with an existing solver in [1] and a custom solver in [2]. The CSP is given by P = (V, D, C) where V is the set of buildings, D the set of their respective potential addresses, and C a set of constraints that describe the physical layout of the buildings on the map and address numbering strategies. In the context of a web application, a typical BID scenario is as follows. A user, presented with a map such as a Google map, either selects a specific building in an area of interest and requests the address of the building, or he/she provides an address and requests the buildings that could have this address...|$|R
40|$|This {{proposal}} {{is aimed at}} {{reducing the risk of}} adverse drug interactions that may occur when over-the-counter (OTC) preparations are taken in conjunction with prescription drugs in an unsupervised regimen. Such polymedicating is practiced widely among the elderly. A pilot program would be implemented over 12 months at three drugstores of a major retail chain. A barcode-based computer system would be used to identify potential adverse drug interactions for elderly customers. All volunteers admitted to the study, controls and subjects, would agree to buy all their medications, prescriptions and OTC, at the participating pharmacies. In return, the volunteers would receive discounts of 25 percent on prescription and OTC drugs and 10 percent on vitamins. Study subjects (N = 375) would carry barcoded <b>identification</b> (<b>BID)</b> cards that would activate the computerized program to assess each purchase for compatibility with their other medications; controls (N = 375) would carry "dummy" BID cards that would prompt the computer to approve all drug purchases. A final comparison of the subjects with the controls, as well as with a sample of elderly residents selected randomly from the community, would determine whether such a computerized, commercially based drug use review system could reduce the potential for adverse interactions between OTC and prescription drugs among the elderly...|$|R
40|$|Competitive bidding {{has tended}} {{to be based on}} the {{principle}} of pricing over other criteria, rather than on a specific business relationship in the past. This implies that the bidder will generally place himself in a position that reinforces his chances of award on a "one off" basis, without looking to the buyer with an open intention of strengthening ties on a long-term co-operative basis. This has reduced the bidders role to that of a supplier of services based on a competitive policy in which price has always been the predominant ploy. The bidder will thus look for any means that will allow him to cut corners, without creating a direct qualitative impact on the bidder/buyer relationships, but which will allow the bidder to increase his profitability and ensures that the bid remains cost effective. Recent trends in the eighties have transformed this approach substantially. Internationalisation of procurement has exerted greater pressure on the firm's capacity to provide cost effective "one off" bids, due to the bidding firm's structures, the time factor in response to <b>bids</b> and the <b>identification</b> of a greater number of bidders that are in a position to respond to the buyers' specification. The direct consequence of this phenomenon is that the bidder wishing to remain competitive must be perceived by the future buyer as the most adequate business partner in future business development. This in turn will encourage the bidder to find other arguments to win the award, which will be specifically oriented away from value/cost analysis of the specific deal in question. ...|$|R
40|$|The {{purpose of}} this study was to {{identify}} the knowledge transfer mechanisms in project bidding for two business clusters in New Zealand, and how ICT played a role in facilitating a "virtual space" for sharing and re-use of these mechanisms. Genre Systems was the theoretical framework adopted to guide this inquiry and to build on further theory. Within the context of this study, genres are the knowledge transfer mechanisms that communicate information and knowledge to members of the community, following specific social rules. The genres and the way they are being employed contribute towards explaining how knowledge is shared and reused by a community. Action research methodology was used to direct data collection and analysis, and validate how the study was carried out. The study comprised of one action research cycle, which has been divided in five stages: Diagnosis, Planning, Development, Evaluation, and Specifying Learning. Mapping the clusters' collaborative interactions during project bidding helped to identify the knowledge transfer mechanisms. This allowed the identification of an ICT solution that could improve project <b>bidding,</b> and <b>identification</b> of how this knowledge could be stored for reuse in future bids. One of the clusters decided to work together with the researcher towards the design of a new portal to address their project bidding needs. The portal took six iterations to complete and went live in November 2005. A database, several "digital genres" (since these genres exist in an electronic medium), and some procedures were created to facilitate knowledge transfer for the cluster's project bidding process. The team had the opportunity to reflect on the whole experience, identify potential features and genres to incorporate in the portal, and start thinking how they could improve the development process in future interventions. The introduction of ICT encouraged the cluster to develop digital genres that were more dynamic and flexible than the ones used before then. The main finding of the study is a five-step process to create digital genres based on the activities carried out by the team: finding reference points for the digital genre; defining the social rules for the digital genre; embedding the social rules in the template; testing the template; and legitimising the digital genre. Further findings discussed the "natural" and "induced" ways for a cluster to increase its knowledge-base. The first instance takes place during the normal practices of cluster members working together towards business opportunities over a period of time, whereas the later instance is triggered by a specific event or initiative. In this study, the decision by the cluster to introduce website and database technology to assist in managing their knowledge-base provided an opportunity to explore the role of ICT in increasing the cluster's knowledge-base. Final findings showed that a project of this nature not only has to overcome the common IT development challenges (budget, project management, user buy-in), but also those derived from working with a team of volunteer people from different organisations, such as in the case of a cluster...|$|R
40|$|UnrestrictedThe initial formulation, or model, of {{a problem}} greatly {{influences}} {{the efficiency of the}} problem-solving process. Hence, modeling is critical in determining the performance of the problem-solving process {{and the quality of the}} produced solution. Unfortunately, modeling remains an art and has resisted automation. Additionally, slight variations in the characteristics of a given problem instance make it difficult to represent one class of problems using a unique model. Consequently, a robust approach to modeling is required.; My thesis presents an automated approach to modeling. I exploit information contained in the input data in order to customize the constraint model of a given problem instance. I apply my approach to the area of Constraint Programming, focusing on a class of problems where a solution is guaranteed to exist for all problem instances. Specifically, I enhance a generic constraint model of a Constraint Satisfaction Problem (CSP) by adding new constraints to this model. These additional constraints are selected from a library of constraints by testing features of the problem instance at hand. The resulting constraint model is customized such that it best represents the problem instance given the data provided as input.; The resulting framework is applicable to problems where instances are seeded with some initial input data. The techniques present in the framework are generally defined so they can be applied across domains. They cope with the uncertainty in the model refinement process by handling noisy data and incorrect inferences, generating additional information as needed. Furthermore, the framework uses Support Vector Machines (SVMs) to determine the scope of the inferred constraints and it automatically instantiates the constraint model in a format supported by a specialized constraint solver.; I evaluate the effectiveness of my approach in two domains, Sudoku puzzles and the building <b>identification</b> (<b>BID)</b> problem. I show how it can infer the most specific constraint model given the available public information, scale to large problem instances, and use a SVM model to efficiently determine constraint scopes. I also evaluate the effectiveness of the framework for the BID problem in areas such as New Orleans and Belgrade where non-homogenous problem structures co-exist and across different Sudoku puzzle variations, demonstrating the resulting improvement when using an inferred model over a generic one. Additionally, I evaluate the framework's ability to augment the initial set of data points with new ones when applying an iterative constraint-propagation algorithm, which leads to more accurate constraint models...|$|R

