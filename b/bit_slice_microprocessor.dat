5|125|Public
40|$|A {{case study}} of an {{emerging}} design methodology for multiple processor computer systems is described, where the technology is based on bit slice microprocessors. The evolving techniques emphasize multilevel simulation models. At the lowest level is a <b>bit</b> <b>slice</b> <b>microprocessor</b> interpreter for detailed investigation of the functions which can be microprogrammed and designed into these components. The next higher level model is a machine language interpreter whose detailed characteristics {{are determined by the}} results gained from the lowest level model. At the highest level are several models to investigate operating system and architectural strategies. The same approach is applicable to many design studies of multiple processor systems implemented as VLSI chips or <b>bit</b> <b>slice</b> <b>microprocessor</b> technology...|$|E
40|$|The {{application}} of a <b>bit</b> <b>slice</b> <b>microprocessor</b> to a satellite-borne packet switch, serving geographically distributed users, is discussed. A system architecture that employs this packet switch is examined, {{and the performance of}} the switch is evaluated by obtaining an upper bound on the system throughput...|$|E
40|$|A {{wide variety}} of uses have been {{proposed}} for the spectrum of currently available microprocessor systems. Included in this set of applications {{is the use of}} microprocessors for implementing large systems; here, the possibility of employing bit slice microprocessors for various parts of a multiple control unit SIMD processor is discussed. A brief summary of <b>bit</b> <b>slice</b> <b>microprocessor</b> architecture is given, followed by an outline of individual applications to various components such as control units and arithmetic/logic units of the SIMD processor...|$|E
40|$|A multistation, {{multichannel}} {{cross correlation}} processor using the 250 k bit to 4 M bit recording format is discussed. The design is modular, using <b>bit</b> <b>sliced</b> <b>microprocessors</b> {{to perform the}} routine calculations for phase and delay on a per station basis, {{as well as for}} fractional bit shift correction and Fourier transformation of the correlation coefficients on a per baseline basis...|$|R
40|$|Within the {{framework}} of SPS experiments the authors have inserted one or more <b>bit</b> <b>slice</b> <b>microprocessors</b> to obtain an improvement of data quality and time efficiency and more flexibility in adapting to experimental conditions. For experiment WA 2 (1976 - 1978), analysis by microprograms of ADC data, MWPC and TDC multiplicities, and TDC data formatting {{has made it possible}} to reject 70 % of events. This in turn allows an efficient online control and savings of approximately= 100 h of CDC CPU time. In experiment NA 10 (1980 - 1981), physics requires an increase in beam intensity by a factor of 10. Four microprocessors working in parallel allows one to concile to readout data flow with the acquisition capacity of the two computers N 10 -N 500 due to a 90 % reduction of the data flow. The use of modular units adapting to the different readout systems and to the experiment permits easy integration. A complete development system facilitates the updating of software. (0 refs) ...|$|R
40|$|The {{advent of}} Very Large Scale Integration (VLSI) {{technology}} has rendered the gate level model impractical for many simulation activities {{critical to the}} design automation process. As an alternative, an approach to the modeling of VLSI devices at the chip level is described, including the specification of modeling language constructs important to the modeling process. A model structure is presented in which models of the LSI devices are constructed as single entities. The modeling structure is two layered. The functional layer in this structure is used to model the input/output response of the LSI chip. A second layer, the fault mapping layer, is added, if fault simulations are required, in order to map the effects of hardware faults onto the functional layer. Modeling examples for each layer are presented. Fault modeling at the chip level is described. Approaches to realistic functional fault selection and defining fault coverage for functional faults are given. Application of the modeling techniques to single chip and <b>bit</b> <b>slice</b> <b>microprocessors</b> is discussed...|$|R
40|$|In {{the past}} {{communications}} concentrators {{have been designed}} using mini-computers. In this work a design for a high speed concentrator (in the megabits range) is developed using the 3000 series <b>bit</b> <b>slice</b> <b>microprocessor.</b> The proposed concentrator realizes the functions of multiplexing of the data arriving on the low speed lines, demultiplexing of the data arriving on the high speed line, including canned responses and code conversion. The basic system hardware configuration and the principles of operation of the multiplexing and the demultiplexing subsystems are presented. The software for these two functions are also presented. Using queueing theory, {{an estimate of the}} required buffer size is provided. Possible areas of further improvement are also indicated...|$|E
40|$|A g cueing {{microcontroller}} {{is described}} {{which consists of}} a tandem pair of microprocessors, dedicated {{to the task of}} simulating pilot sensed cues caused by gravity effects. This task includes execution of a g cueing model which drives actuators that alter the configuration of the pilot's seat. The g cueing microcontroller receives acceleration commands from the aerodynamics model in the main computer and creates the stimuli that produce physical acceleration effects of the aircraft seat on the pilots anatomy. One of the two microprocessors is a fixed instruction processor that performs all control and interface functions. The other, a specially designed bipolar <b>bit</b> <b>slice</b> <b>microprocessor,</b> is a microprogrammable processor dedicated to all arithmetic operations. The two processors communicate with each other by a shared memory. The g cueing microcontroller contains its own dedicated I/O conversion modules for interface with the seat actuators and controls, and a DMA controller for interfacing with the simulation computer. Any application which can be microcoded within the available memory, the available real time and the available I/O channels, could be implemented in the same controller...|$|E
40|$|The {{submission}} {{begins by}} demonstrating {{that the conditions}} required for consideration under the University's research degrees regulations have been met in full. There then follows a commentary which starts by explaining {{the origin of the}} research theme concerned and which continues by discussing the nature and significance of the work. This has been an extensive programme to devise new methods of improving the computational speed and efficiency required for effective implementation of FIR and IIR digital filters and transforms. The problems are analysed and initial experimental work is described which sought to quantify the performance to be derived from peripheral vector processors. For some classes of computation, especially in real time, it was necessary to tum to pure systolic array hardware engines and a large number of innovations are suggested, both in array architecture and {{in the creation of a}} new hybrid opto-electronic adder capable of improving the performance ofprocessing elements for the array. This significant and original research is extended further by including a class of computation involving a <b>bit</b> <b>sliced</b> co-processor. A means of measuring the performance of this system is developed and discussed. The contribution of the work has been evident in: software innovation for horizontal architecture microprocessors; improved multi-dimensional systolic array designs; the development of completely new implementations of processing elements in such arrays; and in the details of co-processing architectures for <b>bit</b> <b>sliced</b> <b>microprocessors.</b> The use of Read Only Memory in creating n-dimensional FIR or IIR filters, and in executing the discrete cosine transform is a further innovative contribution that has enabled researchers to re-examine the case for pre-calculated systems previously using stored squares. The Read Only Memory work has suggested that Read Only Memory chips may be combined in a way architecturally similar to systolic array processing elements. This led to original concepts of pipelining for memory devices. The work is entirely coherent in that it covers the application of these contributions to a set of common processes, producing a set of performance graded and scaleable solutions. In order that effective solutions are proposed it was necessary to demonstrate a solid underlying appreciation of the computational mechanics involved. Whilst the published papers within this submission assume such an understanding, two appendices are provided to demonstrate the essential groundwork necessary to underpin the work resulting in these publications. The improved results obtained from the programme were threefold: execution time; theoretical clocking speeds and circuit areas; and speed up ratios. In the case of the investigations involving vector signal processors the issue was one of quantifying the performance bounds of the architecture in performing specific combinations of signal processing functions. An important aspect of this work was the optimisation achieved in the programming of the device. The use of innovative techniques reduced the execution time for the complex combinational algorithms involved to sub 10 milliseconds. Given the real time constraints for typical applications and the aims for this research the work evolved toward dedicated hardware solutions. Systolic arrays were thus a significant area of investigation. In such systems meritorious criteria are concerned with achieving: a higher regularity in architectural structure; data exchanges only with nearest neighbour processing elements; minimised global distribution functions such as power supplies and clock lines; minimised latency; minimisation in the use of latches; the elimination of output adders; and the design of higher speed processing elements. The programme has made original and significant contributions to the art of effective array design culminating in systems calculated to clock at 100 MHz when using 1 micron CMOS technology, whilst creating reductions in transistor count when compared with contemporary implementations. The improvements vary by specific design but are ofthe order of 30 -l 00...|$|R
50|$|Custom CISCs were {{commonly}} constructed using <b>bit</b> <b>slice</b> {{computer logic}} {{such as the}} AMD 2900 chips, with custom microcode. A <b>bit</b> <b>slice</b> component {{is a piece of}} an arithmetic logic unit (ALU), register file or microsequencer. Most bit-slice integrated circuits were 4-bits wide.|$|R
50|$|MCS251 <b>bit</b> <b>slice</b> {{controller}} for background task.|$|R
40|$|Computer Electronics: Made Simple Computerbooks {{presents}} {{the basics of}} computer electronics and explains how a microprocessor works. Various types of PROMs, static RAMs, dynamic RAMs, floppy disks, and hard disks are considered, along with microprocessor support devices made by Intel, Motorola and Zilog. <b>Bit</b> <b>slice</b> logic and some AMD <b>bit</b> <b>slice</b> products are also described. Comprised of 14 chapters, this book begins with {{an introduction to the}} fundamentals of hardware design, followed by a discussion on the basic building blocks of hardware (NAND, NOR, AND, OR, NOT, XOR); tools and equipment tha...|$|R
5000|$|Underwood-Miller {{published}} Computer: <b>Bit</b> <b>Slices</b> From a Life, by Herbert R.J. Grosch, in 1991 as [...] "A Third Millennium/Underwood-Miller Book". It was {{the only}} book published under this imprint.|$|R
40|$|An {{apparatus}} {{for processing}} multidimensional data with strong spatial characteristics, such as raw image data, {{characterized by a}} large number of parallel data streams in an ordered array is described. It comprises a large number (e. g., 16, 384 in a 128 x 128 array) of parallel processing elements operating simultaneously and independently on single <b>bit</b> <b>slices</b> of a corresponding array of incoming data streams under control of a single set of instructions. Each of the processing elements comprises a bidirectional data bus in communication with a register for storing single <b>bit</b> <b>slices</b> together with a random access memory unit and associated circuitry, including a binary counter/shift register device, for performing logical and arithmetical computations on the <b>bit</b> <b>slices,</b> and an I/O unit for interfacing the bidirectional data bus with the data stream source. The massively parallel processor architecture enables very high speed processing of large amounts of ordered parallel data, including spatial translation by shifting or sliding of bits vertically or horizontally to neighboring processing elements...|$|R
5000|$|Introduced in April 1982, the VAX-11/730, code-named [...] "Nebula", is a still-more-compact, still-lower-performance <b>bit</b> <b>slice</b> {{implementation}} of the VAX architecture. Its CPU has a 270 ns cycle time (3.70 MHz).|$|R
5000|$|Autovision II, 1982, used {{a custom}} {{designed}} Versabus 68000 processor with a custom 8-channel RS-170 Versabus frame grabber employing an AMD Am2900 <b>bit</b> <b>slice</b> micro-controller, packaged in an industrially hardened NEMA-12 enclosure.|$|R
50|$|The {{block cipher}} part {{is harder to}} <b>bit</b> <b>slice,</b> as the S-boxes {{involved}} are too large (8x8) to be efficiently implemented using logical operations, a prerequisite for <b>bit</b> <b>slicing</b> to be more efficient than a regular implementation. However, as all operations are on 8-bit subblocks, the algorithm can be implemented using regular SIMD, or a form of “byteslicing”. As most SIMD instruction sets, with a notable exception of AVX2, do not support parallel look-up tables, the S-box lookups are done as in a non-bytesliced implementation, but their integration {{into the rest of}} the algorithm is not hampered markedly by the byteslicing.|$|R
50|$|EDSAC 2 was {{an early}} computer, the {{successor}} to the Electronic Delay Storage Automatic Calculator (EDSAC). It was the first computer to have a microprogrammed control unit and a <b>bit</b> <b>slice</b> hardware architecture.|$|R
40|$|We develop fast {{polynomial}} time algorithms to optimally fold stacked <b>bit</b> <b>sliced</b> architectures to minimize area subject to height or width constraints. These algorithms {{may also be}} applied to folding problems that arise in standard cell and sea-of-gates designs. KEYWORDS and PHRASES Stacked <b>bit</b> <b>sliced</b> architectures, folding, area + Research supported, in part, by the National Science Foundation under grant MIP 86 - 17374. 2 1. Introduction A stack of <b>bit</b> <b>sliced</b> components ([LARM 90] and [WU 90]) consists of n components of varying height and width with their left ends vertically aligned as in Figure 1 (a). The intra component (i. e., inter slice but local to a component) routing is done on metal layer 1 while the inter component (i. e., intra slice but across components) routing is done on metal layer 2. A component stack may be folded at component i 1 by rotating components i 1 + 1, [...] ., i n by 180 ° so that their aligned ends {{are now on the}} right and the component order is i 1 + 1, [...] ., i [...] ...|$|R
5000|$|<b>Bit</b> <b>slice</b> {{processors}} usually {{include an}} {{arithmetic logic unit}} (ALU) of 1, 2, 4, 8 or 16 bits and control lines (including carry or overflow signals that are internal to the processor in non-bitsliced CPU designs).|$|R
50|$|It {{has been}} called <b>bit</b> <b>slice</b> {{processing}} because m-bit slice is processes at a time. Word parallel signifies selection of all words. It {{can be considered as}} one bit from all words are processed at a time.|$|R
50|$|The {{resulting}} digest is {{the first}} 224, 256, 384 or 512 bits from the 1024-bit final value.It is well suited to a <b>bit</b> <b>slicing</b> implementation using the SSE2 instruction set, giving speeds of 16.8 Cycles per byte.|$|R
5000|$|<b>Bit</b> <b>slicing</b> {{more or less}} {{died out}} due to {{the advent of the}} microprocessor. Recently it's been used in ALUs for quantum computers, and {{has been used as a}} {{software}} technique (e.g. in x86 CPUs, for cryptography.) ...|$|R
50|$|In the 1970s and 1980s, {{a number}} of {{research}} and commercial computers used <b>bit</b> <b>slicing,</b> in which the CPU's arithmetic logic unit (ALU) was built from multiple 4-bit-wide sections, each section including a chip such as an Am2901 or 74181 chip.|$|R
40|$|Restricted AccessOptical and {{electronic}} means of addressing are combined to flash bit-sliced images rapidly in a sequential manner to achieve enormous reduction in circuit {{as well as}} cost of data drivers in display devices. Also, light source i. e. backlight or front light switching scheme is used to reduce power consumption of light source in display devices for both static and dynamic images with high contrast. <b>Bit</b> <b>slice</b> addressing (BSA) preserves colour purity of images at all angles in fast responding liquid crystal displays with simple data drivers. Colour purity of images is also preserved at all angles of view due to a viewing angle characteristic of <b>bit</b> <b>slice</b> addressing that is independent of gray shades...|$|R
50|$|The 74181 is a <b>bit</b> <b>slice</b> {{arithmetic}} {{logic unit}} (ALU), implemented as a 7400 series TTL integrated circuit. The first complete ALU on a single chip, it {{was used as the}} arithmetic/logic core in the CPUs of many historically significant minicomputers and other devices.|$|R
5000|$|<b>Bit</b> <b>slicing,</b> {{although}} not called {{that at the}} time, was also used in computers before large scale integrated circuits (LSI, the predecessor to today's VLSI, or very-large-scale integration circuits). The first bit-sliced machine was EDSAC 2, built at the University of Cambridge Mathematical Laboratory in 1956-1958.|$|R
40|$|This paper {{presents}} a software-based {{study of a}} hardware-based non-sorting median calculation method {{on a set of}} integer numbers. The method divides the binary representation of each integer element in the set into <b>bit</b> <b>slices</b> in order to find the element located in the middle position. The method exhibits a linear complexity order and our analysis shows that the best performance in execution time is obtained when slices of 4 -bit in size are used for 8 -bit and 16 -bit integers, in mostly any data set size. Results suggest that software implementation of <b>bit</b> <b>slice</b> method for median calculation outperforms sorting-based methods with increasing improvement for larger data set size. For data set sizes of N > 5, our simulations show an improvement of at least 40 %...|$|R
40|$|Abstract – Owing to {{its high}} {{complexity}} the hardware {{development of a}} flash ADC of larger wordlength {{has always been a}} challenging issue. Being the fastest ADC available in practice, flash ADCs are the only solution for digitizing fast signals demanded by on-line real time digital processors. As computer designers have launched 64 -bit machines into use, for real time processing applications they need wordlength compatible flash ADCs. This paper reports the development of a programmable word-length flash ADC wherein the word-length in integer multiples of 8 -bits is chosen by the user by opting a combination of 3 -mini switches. The architecture for the large word-length flash ADC is built on a single 8 -bit flash ADC producing progressively <b>bit</b> <b>slice</b> of 8 -bits with the originating analog input and its subsequent residues. The progressive accumulation of <b>bit</b> <b>slices</b> contribute to the total word-length of the ADC. The conversion process terminates with those contribution of <b>bit</b> <b>slices</b> conceding word-length which meets the programmed ones. As the complexity of the proposed large word-length ADC is only slightly greater than that of 8 -bit flash ADC and adaptable to the word-length of the system, it is promising to be useful for high speed real time digital processors. Key words: flash ADC, programmable word-length, conversion time, circuit complexity, advanced architecture...|$|R
50|$|Combining {{components}} to produce <b>bit</b> <b>slice</b> products allowed engineers {{and students to}} create more powerful and complex computers at a more reasonable cost, using off-the-shelf components that could be custom-configured. The complexities of creating a new computer architecture were greatly reduced when {{the details of the}} ALU were already specified (and debugged).|$|R
50|$|The {{stream cipher}} part of CSA {{is prone to}} <b>bit</b> <b>slicing,</b> a {{software}} implementation technique that allows decryption of many blocks, or the same block with many different keys, at the same time. This significantly speeds up a brute force search implemented in software, although the factor is too low to make a real-time attack practical.|$|R
50|$|The main {{advantage}} {{was that}} <b>bit</b> <b>slicing</b> made it economically possible in smaller processors to use bipolar transistors, which switch {{much faster than}} NMOS or CMOS transistors. This allowed for much higher clock rates, where speed was needed; for example DSP functions or matrix transformation, or as in the Xerox Alto, the combination of flexibility and speed, before discrete CPUs were able to deliver that.|$|R
5000|$|<b>Bit</b> <b>slicing</b> is a {{technique}} for constructing a processor from modules of processors of smaller bit width, {{for the purpose of}} increasing the word length; in theory to make an arbitrary n-bit CPU. Each of these component modules processes one bit field or [...] "slice" [...] of an operand. The grouped processing components would then have the capability to process the chosen full word-length of a particular software design.|$|R
50|$|Structured VLSI {{design is}} a modular {{methodology}} originated by Carver Mead and Lynn Conway for saving microchip area by minimizing the interconnect fabrics area. This is obtained by repetitive arrangement of rectangular macro blocks {{which can be}} interconnected using wiring by abutment. An example is partitioning the layout of an adder into a row of equal <b>bit</b> <b>slices</b> cells. In complex designs this structuring may be achieved by hierarchical nesting.|$|R
40|$|Includes bibliographical {{references}} (page 87) There {{are several}} methods {{which can be}} used in the design of a digital computer. Each of these approaches has its advantages and its disadvantages. To learn the trade-offs that apply to the <b>bit</b> <b>slice</b> and microprogram methods, a partial build up of a NOVA CPU was done. In the build up, special attention was focused on the sequencing and central of the CPU. The Project Report presents the outcome of the hardware build up and, in particular, it addresses the issues involved in microcode sequencing and decoding. Two methods of sequencing and decoding are presented in detail. One method relies on firmware to do all the sequencing and mode decoding, such as address modes. The other method relies on firmware and the Mapping PROM to do the sequencing and mode decoding. This project Report investigates the implications of both methods on speed and memory requirements for the CPU. Finally, this Project Report presents technology trends, and investigates the potential use of <b>bit</b> <b>slice</b> technology in future systems...|$|R
40|$|Retinal vessel {{segmentation}} and delineation of morphological {{attributes of}} retinal blood vessels are utilized for diagnosis, screening {{and evaluation of}} various ophthalmologic diseases. In this paper, local entropy-based thresholding and modified Gaussian-based matched filter segmentation techniques have been performed on the <b>bit</b> plane <b>sliced</b> images to assess the information of blood vessels present in different <b>bits.</b> <b>Bit</b> plane <b>slicing</b> has been used prior to thresholding for efficient segmentation and further processing as it highlights the contribution made to the total image appearance by specific bits. This will help in efficient transmission of retinal data and diagnosis of diseases in retinal images. The efficiency of the segmentation method is calculated by evaluating performance measures. This is useful for image compression, robust person identification and efficient transmission. Local entropy-based thresholding is used on the reconstructed image, obtained by combining specific bits in <b>bit</b> plane <b>slicing,</b> for segmentation. This method is tested on the publicly available DRIVE and Aria databases. Performance measures are calculated for the segmentation methods. Supervised segmentation on <b>bit</b> planes <b>sliced</b> images performs better than Gaussian matched filter method...|$|R
