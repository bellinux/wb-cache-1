666|671|Public
50|$|In {{order to}} test {{insensitivity}} to image perturbation {{the data set}} is split into two parts: the first contains images with a uniform background and the second images {{with varying degrees of}} <b>background</b> <b>clutter.</b> If the detector is robust to <b>background</b> <b>clutter</b> then the average correspondence score S should be similar for both subsets of images.|$|E
5000|$|False alarm rate and/or {{probability}} of warning {{is therefore a}} huge problem against surface-to-air missiles due to high IR <b>background</b> <b>clutter</b> originating from the earth.|$|E
5000|$|Can {{potentially}} {{detect the}} kinetic heat of missiles after motor burnout at altitude, {{but probably not}} at low level due to high IR <b>background</b> <b>clutter.</b>|$|E
40|$|In this paper, a novel {{infrared}} target co-detection model {{combining the}} self-correlation features of backgrounds and the commonality features of {{targets in the}} spatio-temporal domain is proposed to detect small targets in a sequence of infrared images with complex backgrounds. Firstly, a dense target extraction model based on nonlinear weights is proposed, which can better suppress background of images and enhance small targets than weights of singular values. Secondly, a sparse target extraction model based on entry-wise weighted robust principal component analysis is proposed. The entry-wise weight adaptively incorporates structural prior in terms of local weighted entropy, thus, it can extract real targets accurately and suppress <b>background</b> <b>clutters</b> efficiently. Finally, the commonality of targets in the spatio-temporal domain are used to construct target refinement model for false alarms suppression and target confirmation. Since real targets could appear in both of the dense and sparse reconstruction maps of a single frame, and form trajectories after tracklet association of consecutive frames, the location correlation of the dense and sparse reconstruction maps for a single frame and tracklet association of the location correlation maps for successive frames have strong ability to discriminate between small targets and <b>background</b> <b>clutters.</b> Experimental results demonstrate that the proposed small target co-detection method can not only suppress <b>background</b> <b>clutters</b> effectively, but also detect targets accurately even if with target-like interference...|$|R
30|$|The object {{tracking}} means {{tracing the}} progress of objects as they move over a sequence of images. Visual object tracking in complex environments is an important topic in the intelligent surveillance field. A good tracking algorithm {{should be able to}} work well in many real circumstances, such as <b>background</b> <b>clutters,</b> occlusions, and different illuminations [1, 2].|$|R
30|$|The {{object in}} the {{football}} sequence (Fig.  5 e) suffers from <b>background</b> <b>clutters.</b> Furthermore, the object also suffers from occlusion by other players, which make the sequence challenging. Overall, our tracker shows favorable performance {{to deal with the}} challenging sequence. The target in faceocc sequence in Fig.  5 f undergoes heavy occlusion. The proposed tracker SACT achieves the best performance in terms of precision score and success score. Our tracker can handle occlusion variations and <b>background</b> <b>clutters</b> well as its adaptive appearance model and the online classifier update strategy. When the object appearance changes rapidly, a larger learning rate is applied. On the contrary, a smaller learning rate is applied. However, whenρ < Θ, which means the current location of the object is not accurate or the occlusion has occurred, the classifier stops updating. In this way, the tracker is prevented from drifting due to avoiding adding inaccurate samples.|$|R
5000|$|Algorithms {{concerned}} with recognition usually function by storing features {{unique to the}} object. However, most images taken have varying degrees of <b>background</b> <b>clutter,</b> which means algorithms may build incorrectly.|$|E
50|$|Weber & Welling here {{introduce}} {{the concept of}} foreground and background. Foreground parts correspond to an instance of a target object class, whereas background parts correspond to <b>background</b> <b>clutter</b> or false detections.|$|E
50|$|The radar was {{developed}} by the Metropolitan Vickers Electrical Company and used moving target indication to eliminate the <b>background</b> <b>clutter</b> generated by the sea. During trials the radar successfully tracked an approaching Canberra jet bomber, 120 miles km.|$|E
40|$|Fashion {{landmarks}} are functional {{key points}} defined on clothes, such as corners of neckline, hemline, and cuff. They have been recently introduced {{as an effective}} visual representation for fashion image understanding. However, detecting fashion landmarks are challenging due to <b>background</b> <b>clutters,</b> human poses, and scales. To remove the above variations, previous works usually assumed bounding boxes of clothes are provided in training and test as additional annotations, which are expensive to obtain and inapplicable in practice. This work addresses unconstrained fashion landmark detection, where clothing bounding boxes are not provided in both training and test. To this end, we present a novel Deep LAndmark Network (DLAN), where bounding boxes and landmarks are jointly estimated and trained iteratively in an end-to-end manner. DLAN contains two dedicated modules, including a Selective Dilated Convolution for handling scale discrepancies, and a Hierarchical Recurrent Spatial Transformer for handling <b>background</b> <b>clutters.</b> To evaluate DLAN, we present a large-scale fashion landmark dataset, namely Unconstrained Landmark Database (ULD), consisting of 30 K images. Statistics show that ULD is more challenging than existing datasets in terms of image scales, <b>background</b> <b>clutters,</b> and human poses. Extensive experiments demonstrate the effectiveness of DLAN over the state-of-the-art methods. DLAN also exhibits excellent generalization across different clothing categories and modalities, making it extremely suitable for real-world fashion analysis. Comment: To appear in ACM Multimedia (ACM MM) 2017 as a full research paper. More details at the project page: [URL]...|$|R
3000|$|..., {{is needed}} to capture the <b>background</b> and <b>clutter</b> characteristics. No prior {{information}} or assumptions are used for this model.|$|R
30|$|The {{objects in}} the {{basketball}} (Fig.  5 g) and soccer (Fig.  5 h) sequences both suffer from multiple challenges, such as fast motion, motion blur, <b>background</b> <b>clutters,</b> occlusion and other challenges, which make these two sequences much challenging. Consequently, all the trackers drift to the background or other objects gradually except our tracker. Overall, SACT achieves the best performance in these two challenging sequences due to its adaptive appearance model and the online classifier update strategy.|$|R
5000|$|Next, {{the prior}} model {{parameters}} are computed from 30 models , 10 {{from each of}} the three learnt categories: spotted cats, faces, and airplanes. This prior encodes the knowledge that [...] "models lacking visual consistency <b>background</b> <b>clutter</b> occupy {{a different part of the}} parameter space from coherent models." ...|$|E
50|$|The {{problem of}} {{defining}} a generative model for object recognition is difficult. The task becomes significantly complicated by {{factors such as}} <b>background</b> <b>clutter,</b> occlusion, and variations in viewpoint, illumination, and scale. Ideally, we would like the particular representation we choose to be robust to {{as many of these}} factors as possible.|$|E
50|$|The Kadir-Brady {{saliency}} detector {{gives the}} highest score across three test classes which are motorbike, car and face.The saliency detector indicates that most detections {{are near the}} object. In contrast, other detectors maps show a much more diffuse pattern over the entire area caused by poor localization and false responses to <b>background</b> <b>clutter.</b>|$|E
40|$|Training object {{detectors}} {{with only}} image-level annotations is very challenging because the target objects are often {{surrounded by a}} large number of <b>background</b> <b>clutters.</b> Many existing approaches tackle this problem through object proposal mining. However, the collected positive regions are either low in precision or lack of diversity, and the strategy of collecting negative regions is not carefully designed, neither. Moreover, training is often slow because region selection and object detector training are processed separately. In this context, the primary contribution of this work is to improve weakly supervised detection with an optimized region selection strategy. The proposed method collects purified positive training regions by progressively removing easy <b>background</b> <b>clutters,</b> and selects discriminative negative regions by mining class-specific hard samples. This region selection procedure is further integrated into a CNN-based weakly supervised detection (WSD) framework, and can be performed in each stochastic gradient descent mini-batch during training. Therefore, the entire model can be trained end-to-end efficiently. Extensive evaluation results on PASCAL VOC 2007, VOC 2010 and VOC 2012 datasets are presented which demonstrate that the proposed method effectively improves WSD. Comment: 11 pages, 7 figure...|$|R
40|$|A polarimetric {{coherent}} Time-Frequency (TF) decompo-sition {{approach for}} ship detection is proposed in this pa-per. At first, the PolSAR data are decomposed in azimuth direction, range direction only or in both directions. Then a novel statistical descriptor called polarimetric TF co-herence indicator, {{is applied to}} detect maritime targets in different environments. By using polarimetric RadarSat- 2 data over various scenes, experimental results demon-strate that, the proposed method can efficiently enhance contrast between targets and <b>background</b> <b>clutters</b> in terms of ship detection...|$|R
40|$|Abstract. Color histograms {{are widely}} used for visual {{tracking}} due to their robustness against object deformations. However, traditional histogram representation often suffers from problems of partial occlusion, <b>background</b> <b>cluttering</b> and other appearance corruptions. In this paper, we propose a probabilistic index histogram to improve the discriminative power of the histogram representation. With this modeling, an input frame is translated into an index map whose entries indicate indexes to a separate bin. Based on the index map, we introduce spatial information and the bin-ratio dissimilarity in histogram comparison. The proposed probabilistic indexing technique, together with the two robust measurements, greatly increases the discriminative power of the histogram representation. Both qualitative and quantitative evaluations show the robustness of the proposed approach against partial occlusion, noisy and <b>clutter</b> <b>background.</b> ...|$|R
5000|$|Two colour {{detectors}} {{are used}} in some systems {{to assist in the}} suppression of <b>background</b> <b>clutter</b> and lower FAR. Even though it solves some problems, it creates others as it complicates the system further due to the optical, sensitivity and extremely high pixel rate requirements which impact negatively on cost and reliability.|$|E
50|$|The algorithm’s {{creation}} {{was inspired}} by the inability of Kalman filtering to perform object tracking well in the presence of significant <b>background</b> <b>clutter.</b> The presence of clutter tends to produce probability distributions for the object state which are multi-modal and therefore poorly modeled by the Kalman filter. The Condensation Algorithm in its most general form requires no assumptions about the probability distributions of the object or measurements.|$|E
5000|$|To formalize these ideas, let [...] be {{the query}} image, which {{contains}} either {{an example of}} the foreground category [...] or only <b>background</b> <b>clutter</b> of a generic background category [...] Also let [...] be the set of training images used as the foreground category. The decision of whether [...] contains an object from the foreground category, or only clutter from the background category is: ...|$|E
5000|$|Very good {{probability}} of warning in high <b>clutter</b> <b>background</b> environments.|$|R
40|$|Abstract — <b>Cluttered</b> <b>background</b> removal in static {{images with}} mild {{occlusion}} remains still a challenging task for object identification or classification problems. In {{most of the}} real-world images, vehicle objects with <b>cluttered</b> <b>background</b> containing trees, road views, buildings, people, etc tent to be a noisy data or leads {{to the problem of}} clarity. The background feature covers the major portion of the image. Classification of objects fails due to <b>cluttered</b> <b>background</b> features and occluded features. This paper presents a novel approach for background removal in static images containing car object with <b>cluttered</b> <b>background</b> and mild occlusion. The morphological operations like region filling technique, background subtraction along with mapping function are used to extract the region of interest being the vehicle object. A critical evaluation of the proposed approach with the University of Illinois, Urbana-Champaign (UIUC) standard database is presented...|$|R
40|$|Existing {{saliency}} detection approaches use {{images as}} in-puts and {{are sensitive to}} foreground/background similari-ties, complex background textures, and occlusions. We ex-plore the problem of using light fields as input for saliency detection. Our technique is enabled by the availability of commercial plenoptic cameras that capture the light field of a scene in a single shot. We show that the unique refocusing capability of light fields provides useful focusness, depths, and objectness cues. We further develop a new saliency de-tection algorithm tailored for light fields. To validate our approach, we acquire a light field database {{of a range of}} indoor and outdoor scenes and generate the ground truth saliency map. Experiments show that our saliency detection scheme can robustly handle challenging scenarios such as similar foreground and <b>background,</b> <b>cluttered</b> <b>background,</b> complex occlusions, etc., and achieve high accuracy and robustness. 1...|$|R
5000|$|Detectors {{are trained}} to search for {{pedestrians}} in the video frame by scanning the whole frame. The detector would “fire” if the image features inside the local search window meet certain criteria. Some methods employ global features such as edge template, others uses local features like histogram of oriented gradients [...] descriptors. The drawback {{of this approach is}} that the performance can be easily affected by <b>background</b> <b>clutter</b> and occlusions.|$|E
50|$|This {{variant of}} the IR Umkhonto was {{recently}} developed {{in collaboration with the}} Finnish Navy. It has a more advanced seeker-head algorithm for differentiating between the target and <b>background</b> <b>clutter</b> often found in and around the Baltic archipelago. Because of the improvement in the seeker head, the newer version has a more efficient flight path, allowing for an increase in range of 3 km; a new maximum range of 15 km. Its current flight ceiling is 8 km.|$|E
5000|$|Bapu {{introduced}} a painting style of simple bright colours. His unique style consisted of economy of strokes, freehand drawing {{and a lack}} of <b>background</b> <b>clutter.</b> [...] His paintings focus on Hindu mythological characters, and he has painted the Hindu epic Ramayana as a pictorial story. His character portrayals, such as Shiva, Bhima, Duryodhana, look distinctly male with wide chests, large jaws and large biceps; while Krishna and Rama are more feminine in build. Bapu has also {{introduced a}} new style of cursive writing in Telugu. The font is his own handwriting and reflects the same simplicity as his art.|$|E
40|$|Abstract. In {{order to}} improve the {{accuracy}} and stability of infrared target detection, a novel moving target detection approach based on temporal-spatial domain fusion is presented. A multi-level spatial-temporal median filter is utilized to extract the background frame, with which the <b>background</b> <b>clutters</b> are suppressed by using the background subtraction technique. Then a local weighted operator is applied to enhance the targets. Lastly, the otsu thresholding algorithm is utilized to detect the targets. Experimental results demonstrate that the proposed approach is capable of detecting infrared moving targets effectively for F 1 measurement up to 92. 8 %...|$|R
30|$|We {{classify}} {{image features}} into four categories: shape, appearance, motion, and depth features. Shape features {{are employed in}} many detection algorithms due to their invariance to viewpoint changes [1]. Shape features are very sparse in detection and modeling processes. Therefore, shape-based detection methods can be efficient. However, it is rather difficult to extract accurate shape features because of <b>background</b> <b>clutters.</b> Appearance features are successfully applied in sliding window-based detection systems [2, 3]. They compute contrast information and describe such information using various descriptors. Histograms of gradient orientations (HOGs) have achieved good performance in pedestrian detection [3]. Unfortunately, it is rather difficult to detect heavily occluded objects using appearance-based methods.|$|R
40|$|The paper {{proposes a}} method to keep the tracker robust to <b>background</b> <b>clutters</b> by online {{selecting}} discriminative features from a large feature space. Furthermore, the feature selection procedure is embedded into the particle filtering process {{with the aid of}} existed “background ” particles. Feature values from background patches and object observations are sampled during tracking and Fisher discriminant is employed to rank the classification capacity of each feature based on sampled values. Top-ranked discriminative features are selected into the appearance model and simultaneously invalid features are removed out to adjust the object representation adaptively. The implemented tracker with online discriminative feature selection module embedded shows promising results on experimental video sequences...|$|R
5000|$|The AGM-124A {{was a small}} weapon with folding {{wings and}} fins to reduce storage space within the launcher. It was {{intended}} to be launched in large numbers - 10 or more missiles launched nearly simultaneously was envisaged for a typical attack; indeed the name Wasp derived from this [...] "swarm" [...] tactic. The missiles would follow a pre-programmed path to the target area before activating a millimeter wave active radar homing to identify and home on a specific target. This high resolution radar was able to distinguish targets even against enemy jamming and high <b>background</b> <b>clutter</b> from the ground.|$|E
50|$|Given {{the task}} of finding a {{particular}} object in a query image, the overall objective of the Bayesian One-Shot Learning algorithm is to compare the probability that that object {{is present in the}} image and the probability that only <b>background</b> <b>clutter</b> is present in the image. If the former probability is higher, the algorithm reports the object's presence in the image, and if the latter probability is higher, the algorithm reports the absence of that object in the image. In order to compute these probabilities, the object class must be modeled from a set of (1 ~ 5) training images containing examples of that object.|$|E
50|$|The antenna was not {{particularly}} effective, with a gain of about 25 db, so to receive a useful signal from such ranges an enormous broadcast signal was needed. The system could develop a peak power of up to 10 MW, which {{can be compared to}} the most powerful commercial radio stations at around 500 kW. Reception of the signal was a complex affair, as very little signal would be returned after a round-trip of several thousand kilometers, requiring a receiver sensitivity of 80 to 90 dB to extract a signal out of the <b>background</b> <b>clutter.</b> The system relied on ultra-linear amplifiers that could amplify the signal across the entire frequency range without introducing distortion.|$|E
40|$|Many {{tracking}} algorithms {{have difficulties}} dealing with occlusions and <b>background</b> <b>clutters,</b> and consequently don't converge to an appropriate solution. Tracking {{based on the}} mean shift algorithm has shown robust performance in many circumstances but still fails e. g. when encountering dramatic intensity or colour changes in a pre-defined neighbourhood. In this paper, we present a robust tracking algorithm that integrates the advantages of mean shift tracking with those of tracking local invariant features. These features are integrated into the mean shift formulation so that tracking is performed based both on mean shift and feature probability distributions, coupled with an expectation maximisation scheme. Experimental results show robust tracking performance {{on a series of}} complicated real image sequences...|$|R
40|$|Detection and {{recognition}} of moving objects using statistical motion detection and Fourier descriptors Object recognition, i. e. classification of objects into one of several known object classes, generally is a difficult task. In this paper we {{address the problem of}} detecting and classifying moving objects in image sequences from traffic scenes recorded with a static camera. In the first step, a statistical, illumination invariant motion detection algorithm is used to produce binary masks of the scene–changes. Next, Fourier descriptors of the shapes from the refined masks are computed and used as feature vectors describing the different objects in the scene. Finally, a feed–forward neural net is used to distinguish between humans, vehicles, and <b>background</b> <b>clutters.</b> ...|$|R
40|$|Sparsity-regularized {{synthetic}} aperture radar (SAR) imaging framework has shown its remarkable performance to generate a feature enhanced high resolution image, in which a sparsity-inducing regularizer is involved by exploiting the sparsity priors of some visual features in the underlying image. However, since the simple prior of low level features are insufficient to describe different semantic contents in the image, this type of regularizer will be incapable of distinguishing between the target of interest and unconcerned <b>background</b> <b>clutters.</b> As a consequence, the features belonging to the target and clutters are simultaneously affected in the generated image without concerning their underlying semantic labels. To address this problem, we propose a novel semantic information guided framework for target oriented SAR image formation, which aims at enhancing the interested target scatters while suppressing the <b>background</b> <b>clutters.</b> Firstly, we develop a new semantics-specific regularizer for image formation by exploiting the statistical properties of different semantic categories in a target scene SAR image. In order to infer the semantic label for each pixel in an unsupervised way, we moreover induce a novel high-level prior-driven regularizer and some semantic causal rules from the prior knowledge. Finally, our regularized framework for image formation is further derived as a simple iteratively reweighted ℓ_ 1 minimization problem which can be conveniently solved by many off-the-shelf solvers. Experimental results demonstrate the effectiveness and superiority of our framework for SAR image formation in terms of target enhancement and clutters suppression, compared {{with the state of}} the arts. Additionally, the proposed framework opens a new direction of devoting some machine learning strategies to image formation, which can benefit the subsequent decision making tasks. Comment: Submitted to IEEE TGR...|$|R
