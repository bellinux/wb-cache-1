4|10000|Public
40|$|ABSTRACT: To {{investigate}} conjoint stimulus {{control over}} place cells, Fenton et al. (J Gen Physiol 116 : 191 – 209, 2000 a) recorded while rats foraged in a cylinder with 45 ° {{black and white}} cue cards on the wall. Card centers were 135 ° apart. In probe trials, the cards were rotated together or apart by 25 °. Firing field centers shifted during these trials, stretching and shrinking the cognitive map. Fenton et al. (2000 b) described this deformation with an ad hoc vector field equation. We consider what sorts of neural network mechanisms might be capable of accounting for their observations. In an abstract, maximum likelihood formulation, the rat’s location is estimated by a conjoint probability density function of landmark positions. In an attractor neural network model, recurrent connections produce a <b>bump</b> <b>of</b> <b>activity</b> over a two-dimensional array of cells; the bump’s position is influenced by landmark features such as distances or bearings. If features are chosen with appropriate care, the attractor network and maximum likelihood models yield similar results, in accord with previous demonstrations that recurrent neural networks can efficiently implement maximum likelihood computations (Pouget et al. Neura...|$|E
30|$|The {{dynamics}} of large-scale neuronal network dynamics {{can also be}} accounted for by spatially-organized neural field models. These models can be amenable to local and weakly nonlinear stability analysis, especially when the network connectivity exhibits symmetries or is near-symmetric [29]. Hedrick and Zhang (2018) analyze a model of the hippocampal network underlying spatial navigation, in which individual cells can possess multiple place fields [9]. Such multiplicities in place fields have been observed in recordings from rat hippocampus, as the animal navigates large environments [30]. To study the emergence of such multiplicities and their effect on model network dynamics, the authors determine the stability of model equilibria as the spatial domain size is increased. In small environments, when two conflicting locations are presented as inputs to the model, the network operates in a winner-take-all (WTA) regime, so a single input location is represented by a single <b>bump</b> <b>of</b> <b>activity.</b> As the scale of the environment is increased, there is a critical size beyond which two conflicting inputs can be represented by two distinct bumps. This phase transition is characterized through numerical simulations and a local stability analysis which reduces the neural field model to a two-unit model tracking the heights of the two possible bumps. Phase plane and bifurcation analysis can then be used to identify the boundaries of the WTA and combinatorial modes, as well as hysteresis. The authors also show how such analyses could be extended to multiple inputs, relevant to perceptual and decision-making models [31].|$|E
40|$|The {{world is}} an ever-changing place. To {{make sense of}} it, the brain {{must be able to}} process a {{constant}} stream of noisy input data in real time and in an (apparently) optimal manner {{in order to be able}} to direct behavior. Formally, to achieve optimality, the brain ought to be performing some sort of Bayesian filtering; yet how such computations can be performed in neural networks is still an open question [1, 2]. In a previous abstract to this conference [3] we extended the work of Deneve et al. [4] to allow optimal decoding of a single moving stimulus with divisive normalization neural networks; and in this work we extend it still further to handle the case of more complex moving stimuli. For concreteness, we use the example of gait recognition and tracking, in particular the case where we wish to track several different joint angles simultaneously. The approach we take is to build a causal model for the generation of joint angle data, where each joint angle configuration is a function of both the type of gait and the current phase through the gait cycle. Such a hierarchical scheme maps readily onto a neural network. In particular we encode each joint angle as a <b>bump</b> <b>of</b> <b>activity</b> in a low level network (one per joint angle), and the phase angle in a high level network, with one high level network for each gait. Feedforward connections from low to high level networks implement an inverse model of the system, connecting effect to possible cause; while feedbac...|$|E
40|$|International audienceIn {{the field}} of {{computational}} neuroscience, we develop distributed models of the cortex to account for perceptual and sensorimotor capabilities. Adopting a mesoscopic level of modeling with dynamic neural fields representing topologically organized populations of cortical columns, we propose various learning rules, competition mechanisms and interconnection schemes. Under the right conditions, these allow the emergence <b>of</b> spatially coherent <b>bumps</b> <b>of</b> <b>activity</b> yielding attentional properties and high robustness to noise. We focus in this poster on the distributed, continuous and unsupervised learning of multi-sensory representations and sensorimotor behaviors. Learning should lead to the emergence <b>of</b> coherent <b>bumps</b> <b>of</b> <b>activity</b> in cortical maps when correlated stimuli are presented, with the possibility to recall potentially missing modalities. This raises {{the issues of the}} necessity and nature of generalization in a multimodal context. Research projects on this topic range from the introduction of constrained self-organization with associative maps, adaptive learning rule parameters for multimodal selectivity, to local contingencies in high dimensional sensorimotor spaces...|$|R
40|$|A {{demonstration}} {{is made of}} a programmable vision chip, containing {{an array}} of photosensors collocated with a processing circuitry and memory, implementing a Dynamic Neural Field (DNF) over a simple saliency map. The system detects and tracks moving objects with strong contrasts. The computation of the DNF's dynamics is performed entirely on the vision chip. The system solely outputs relevant information that has been processed on the array: the <b>activity</b> <b>of</b> the DNF and/or address-events corresponding to the coordinates <b>of</b> its <b>bumps</b> <b>of</b> <b>activity...</b>|$|R
40|$|Abstract. Based on head {{direction}} {{experiments in}} rats, the existence <b>of</b> localized <b>bumps</b> <b>of</b> thalamic <b>activity</b> has been proposed. We computationally demonstrate {{the existence of}} a novel class <b>of</b> localized <b>bump</b> solutions in a two-layer conductance-based thalamic network and analyze the mechanisms behind these stable patterns. In contrast to previous models <b>of</b> <b>bump</b> <b>activity,</b> here inhibition plays a crucial role in initially spreading neuronal firing and in subsequently sustaining it. In our model, we incorporate local strong, fast GABAA inhibition and diffuse weak, slow GABAB inhibition, based on previous biophysical experiments. These forms of inhibition contribute in different, yet complementary, ways to the observed pattern formation...|$|R
40|$|The hippocampal-entorhinal complex {{plays an}} {{essential}} role within the brain in spatial navigation, mapping a spatial path onto a sequence of cells that reaction potentials. During rest or sleep, these sequences are replayed in either reverse or forward temporal order; in some cases, novel sequences occur that may represent paths not yet taken, but connecting contiguous spatial locations. These sequences potentially {{play a role in}} the planning of future paths. In particular, mental exploration is needed to discover short-cuts or plan alternative routes. Hopeld proposed a two-dimensional planar attractor network as a substrate for the mental exploration. He extended the concept of a line attractor used for the ocular-motor apparatus, to a planar attractor that can memorize any spatial path and then recall this path in memory. Such a planar attractor contains an infinite number of fixed points for the dynamics, each fixed point corresponding to a spatial location. For symmetric connections in the network, the dynamics generally admits a Lyapunov energy function L. Movement through different fixed points is possible because of the continuous attractor structure. In this model, a key role is played by the evolution of a localized activation of the network, a "bump", that moves across this neural sheet that topographically represents space. For this to occur, the history of paths already taken is imprinted on the synaptic couplings between the neurons. Yet attractor dynamics would seem to preclude the bump from moving; hence, a mechanism that destabilizes the bump is required. The mechanism to destabilize such an activity bump and move it to other locations of the network involves an adaptation current that provides a form of delayed inhibition. Both a spin-glass and a graded-response approach are applied to investigating the dynamics of mental exploration mathematically. Simplifying the neural network proposed by Hopfield to a spin glass, I study the problem of recalling temporal sequences and explore an alternative proposal, that relies on storing the correlation of network activity across time, adding a sequence transition term to the classical instantaneous correlation term during the learning of the synaptic "adaptation current" is interpreted as a local field that can destabilize the equilibrium causing the bump to move. We can also combine the adaptation and transition term to show how the dynamics of exploration is affected. To obtain goal-directed searching, I introduce a weak external field associated with a rewarded location. We show how the bump trajectory then follows a suitable path to get to the target. For networks of graded-response neurons with weak external stimulation, amplitude equations known from pattern formation studies in bio-chemico- physical systems are developed. This allows me to predict the modes of network activity that can be selected by an external stimulus and how these modes evolve. Using perturbation theory and coarse graining, the dynamical equations for the evolution of the system are reduced from many sets of nonlinear integro-dierential equations for each neuron to a single macroscopic equation. This equation, in particular close to the transition to pattern formation, takes the form of the Landau Ginzburg equation. The parameters for the connections between the neurons are shown to be related to the parameters of the Landau-Ginzburg equation that governs the <b>bump</b> <b>of</b> <b>activity.</b> The role of adaptation within this approximation is studied, which leads to the discovery that the macroscopic dynamical equation for the system has the same structure of the coupled equations used to describe the propagation of the electrical activity within one single neuron as given by the Fitzhugh-Nagumo equations...|$|E
30|$|In many {{models of}} working memory, {{transient}} stimuli are encoded by feature-selective persistent neural activity. Such stimuli are imagined to induce {{the formation of}} a spatially localised <b>bump</b> <b>of</b> persistent <b>activity</b> which coexists with a stable uniform state. As an example, Camperi and Wang [24] have proposed and studied a network model of visuo-spatial working memory in prefontal cortex adapted from the ring model of orientation of Ben-Yishai and colleagues [1]. Many studies have emerged in the past decades to analyse these localised <b>bumps</b> <b>of</b> <b>activity</b> [25 – 29], see the paper by Coombes for a review of the domain [30]. In [25, 26, 28], the authors have examined the existence and stability <b>of</b> <b>bumps</b> and multi-bumps solutions to an integro-differential equation describing neuronal activity along a single spatial domain. In [27, 29] the study is focused on the two-dimensional model and a method is developed to approximate the integro-differential equation by a partial differential equation which makes possible the determination of the stability of circularly symmetric solutions. It is therefore natural to study the emergence <b>of</b> spatially localized <b>bumps</b> for the structure tensor model in a hypercolumn of V 1. We only deal with the reduced case of equation (13) which means that the membrane activity does not depend upon the contrast of the image intensity, keeping the general case for future work.|$|R
40|$|Based on head {{direction}} {{experiments in}} rats, the existence <b>of</b> localized <b>bumps</b> <b>of</b> thalamic <b>activity</b> has been proposed. We computationally demonstrate {{the existence of}} a novel class <b>of</b> localized <b>bump</b> solutions in a two-layer conductancebased thalamic network and analyze the mechanisms behind these stable patterns. In contrast to previous models <b>of</b> <b>bump</b> <b>activity,</b> here inhibition plays a crucial role in initially spreading neuronal ring and in subsequently sustaining it. In our model, we incorporate local strong, fast GABAA inhibition and diuse weak, slow GABAB inhibition, based on previous biophysical experiments. These forms of inhibition contribute in dierent, yet complementary, ways to the observed pattern formation. Keywords: localized activity, head direction cells, thalamus, conductance-based model, synaptic coupling Abbreviations: GABA { -aminobutyric acid; HD { head direction; PoS { postsubiculum; ATN { anterior thalamic nuclei; AD { anterior dorsal thalamic nucleus; TC { t [...] ...|$|R
40|$|Spatiotemporal {{patterns}} such as traveling {{waves are}} frequently observed in recordings <b>of</b> neural <b>activity.</b> The mechanisms underlying {{the generation of}} such patterns are largely unknown. Previous studies have investigated the existence and uniqueness of different types <b>of</b> waves or <b>bumps</b> <b>of</b> <b>activity</b> using neural-field models, phenomenological coarse-grained descriptions of neural-network dynamics. But it remains unclear how these insights can be transferred to more biologically realistic networks of spiking neurons, where individual neurons fire irregularly. Here, we employ mean-field theory to reduce a microscopic model of leaky integrate-and-fire (LIF) neurons with distance-dependent connectivity to an effective neural-field model. In contrast to existing phenomenological descriptions, the dynamics in this neural-field model depends on the mean and {{the variance in the}} synaptic input, both determining the amplitude and the temporal structure of the resulting effective coupling kernel. For the neural-field model we derive conditions for the existence of spatial and temporal oscillations and periodic traveling waves using linear stability analysis. We first prove that periodic traveling waves cannot occur in a single homogeneous population of neurons, irrespective of the form of distance dependence of the connection probability. Compatible with the architecture of cortical neural networks, traveling waves emerge in two-population networks of excitatory and inhibitory neurons as a combination of delay-induced temporal oscillations and spatial oscillations due to distance-dependent connectivity profiles. Finally, we demonstrate quantitative agreement between predictions of the analytically tractable neural-field model and numerical simulations of both networks of nonlinear rate-based units and networks of LIF neurons. Comment: 42 pages, 12 figure...|$|R
40|$|Abstract. Continuous neural field {{models with}} inhomogeneous {{synaptic}} connectivities {{are known to}} support traveling fronts as well as stable <b>bumps</b> <b>of</b> localized <b>activity.</b> We analyze stationary localized structures in a neural field model with periodic modulation of the synaptic connectivity kernel and find that they are arranged in a snakes-and-ladders bifurcation structure. In the case of Heaviside firing rates, we construct analytically symmetric and asymmetric states and hence de-rive closed-form expressions for the corresponding bifurcation diagrams. We show that the ideas proposed by Beck and co-workers to analyze snaking solutions to the Swift–Hohenberg equation re-main valid for the neural field model, even though the corresponding spatial-dynamical formulation is non-autonomous. We investigate how the modulation amplitude affects the bifurcation structure and compare numerical calculations for steep sigmoidal firing rates with analytic predictions valid in the Heaviside limit...|$|R
40|$|Oscillations {{and other}} rhythmic {{patterns}} <b>of</b> neuronal <b>activity</b> arise throughout {{the central nervous}} system. Such oscillations have been implicated in the genera-tion of sleep rhythms, epilepsy, parkinsonian tremor, sensory processing, and learning. Oscillatory behavior also arises in such physiological processes as respi-ration, movement, and secretion. Researchers have made tremendous efforts to understand the cellular mecha-nisms responsible for these activity patterns. Numerous mathematical models have been developed, often based on the Hodgkin–Huxley formalism. Some of these models exhibit a rich mix of dynamic behaviors. (See, for example, the review articles [2, 3].) The behavior of even a single cell can be quite complicated; an individual cell might fire, for example, repetitive action potentials or bursts of action potentials separated by silent phases of nearly quiescent behavior. Populations of cells can produce synchronized or partially synchronized oscilla-tions, or spatially localized <b>bumps</b> <b>of</b> asynchronous <b>activity.</b> More complex popu-lation rhythms are also possible. For example, activity might propagate through...|$|R
40|$|In many {{models of}} working memory, {{transient}} stimuli are encoded by feature-selective persistent neural activity. Such stimuli are imagined to induce {{the formation of}} a spatially localised <b>bump</b> <b>of</b> persistent <b>activity</b> which coexists with a stable uniform state. As an example, Camperi and Wang [3] have proposed and studied a network model of visuo-spatial working memory in pre-fontal cortex adapted from the ring model of orientation of Ben-Yishai and colleagues [1]. It is therefore natural to study the emergence <b>of</b> spatially localised <b>bumps</b> for the structure tensor model. This modelization was introduced by Chossat and Faugeras in [4] to describe the representation and the processing of image edges and textures in the hypercolumns of the cortical area V 1. The key entity, the structure tensor, intrinsically lives in a non-Euclidean, in effect hyperbolic, space. Its spatio-temporal behaviour is governed by nonlinear integro-differential equations defined on the Poincare ́ disc model of the two-dimensional hyperbolic space. In this pa-per, we present an original study, based on non-Euclidean, hyperbolic, analysis, of a spatially localised bump solution...|$|R
40|$|We study coarse pattern {{formation}} in a cellular automaton modelling a spatially-extended stochastic neural network. The model, originally proposed by Gong and Robinson (Phys Rev E 85 (5) : 055, 101 (R), 2012), {{is known to}} support stationary and travelling <b>bumps</b> <b>of</b> localised <b>activity.</b> We pose the model on a ring and study the existence and stability of these patterns in various limits {{using a combination of}} analytical and numerical techniques. In a purely deterministic version of the model, posed on a continuum, we construct bumps and travelling waves analytically using standard interface methods from neural field theory. In a stochastic version with Heaviside firing rate, we construct approximate analytical probability mass functions associated with bumps and travelling waves. In the full stochastic model posed on a discrete lattice, where a coarse analytic description is unavailable, we compute patterns and their linear stability using equation-free methods. The lifting procedure used in the coarse time-stepper is informed by the analysis in the deterministic and stochastic limits. In all settings, we identify the synaptic profile as a mesoscopic variable, and the width <b>of</b> the corresponding <b>activity</b> set as a macroscopic variable. Stationary and travelling bumps have similar meso- and macroscopic profiles, but different microscopic structure, hence we propose lifting operators which use microscopic motifs to disambiguate them. We provide numerical evidence that waves are supported by a combination of high synaptic gain and long refractory times, while meandering bumps are elicited by short refractory times...|$|R
40|$|This is {{the author}} {{accepted}} manuscript. The final version is available from Springer Verlag via the DOI in this record. We study coarse pattern formation in a cellular automaton modelling a spatially-extended stochastic neural network. The model, originally proposed by Gong and Robinson, is known to support stationary and travelling <b>bumps</b> <b>of</b> localised <b>activity.</b> We pose the model on a ring and study the existence and stability of these patterns in various limits {{using a combination of}} analytical and numerical techniques. In a purely deterministic version of the model, posed on a continuum, we construct bumps and travelling waves analytically using standard interface methods from neural field theory. In a stochastic version with Heaviside firing rate, we construct approximate analytical probability mass functions associated with bumps and travelling waves. In the full stochastic model posed on a discrete lattice, where a coarse analytic description is unavailable, we compute patterns and their linear stability using equation-free methods. The lifting procedure used in the coarse time-stepper is informed by the analysis in the deterministic and stochastic limits. In all settings, we identify the synaptic profile as a mesoscopic variable, and the width <b>of</b> the corresponding <b>activity</b> set as a macroscopic variable. Stationary and travelling bumps have similar meso- and macroscopic profiles, but different microscopic structure, hence we propose lifting operators which use microscopic motifs to disambiguate between them. We provide numerical evidence that waves are supported by a combination of high synaptic gain and long refractory times, while meandering bumps are elicited by short refractory times. Kyle Wedgwood was generously supported by the Wellcome Trust Institutional Strategic Support Award (WT 105618 MA...|$|R
50|$|On March 6, 2013, <b>Bump</b> <b>of</b> Chicken {{released}} {{their first}} live video and album <b>Bump</b> <b>of</b> Chicken Gold Glider Tour 2012, recorded {{live at the}} Yoyogi National Gymnasium, Tokyo, Japan on July 3, 2012.|$|R
40|$|International audienceRetinal {{waves are}} bursts <b>of</b> <b>activity</b> {{occurring}} spontaneously {{in the developing}} retina of vertebrate species, contributing to the shaping of the visual system organization and disappear short after birth. Waves during development are a transient process which evolves dynamically exhibiting different features. Based on our previous modelling work [1, 2], we now propose a classification of stage II retinal waves patterns {{as a function of}} acetylcholine coupling strength and a possible mechanism for waves generation. Our model predicts that spatiotemporal patterns evolve upon maturation or pharmacological manipulation and that waves emerge from a complete homogeneous state without the need of the variability of a neural population. Context & Motivation SACs dynamically change their synaptic coupling upon maturation Coupled cholinergic SACs [3] Cholinergic current evolution upon maturation [4]- 70 mV 60 mV 0 0. 8 88 nM 300 nM 0. 2 0. 4 0. 4 0. 2 Bursting sAHP Increase of Calcium load during bursting Calcium controls the sAHP phase. Voltage is low and Calcium starts offloading Bursting starts again when the Calcium load is low enough Intracellular Calcium Concentration Our biophysical model reproduces experimental observations for individual and coupled SACs dynamics [3, 4], where no previous computational model [5] has been able to do so before. Weak Moderate Strong Simulated Calcium Waves Weak Moderate Strong • Simulated Calcium waves of 4096 neurons on a square lattice. Black and white colours correspond to low and high activity respectively. Weak coupling: localised <b>bumps</b> <b>of</b> <b>activity.</b> Strong coupling: complete synchrony standing waves. Moderate coupling: propagating patterns. Following Retinal Waves Evolution Average Population Bursting Rate g (nS) A G 0. 01 0. 02 0. 03 0. 3 0 0. 1 0. 2 0. 4 0. 5 A B C E D • The average population bursting rate exhibits a sharp transition upon increasing the cholinergic coupling • Network simulations show patterns where waves do emerge (red) and where they do not (blue). A heat map of the average bursting period T, in seconds, of the network illustrates this observation. • Domaines are formed where the propagation of waves is restrained, as observed experimentally in [7]. In contrast to what is shown in [7], our model describes these domains without the need to add two neural population species. • Different types of spatiotemporal patterns are observed corresponding to each value of cholinergic coupling strength Evolution of the spatiotemporal patterns Evolution of the spatiotemporal patterns when increasing the cholinergic conduc-tance (from left to right) starting from a completely homogeneous state where all cells are identical. Conclusions and Perspectives • Spatio-temporal patterns emerge out of a complete homogeneous state showing that variability in neurons is not the underlying drive of pattern formation. • The role of variability in neural populations can be addressed from a computational aspect more easily. • Biophysical parameters (e. g. conductances) could vary upon maturation or pharmacological manipulations, affecting the characterstics of emerging waves. • A computational model able to follow the transitions of neural networks properties could help us gain a lot of insight in understanding the underlying mechanisms that drive them...|$|R
5000|$|<b>Bump</b> <b>of</b> Chicken Willpolis 2014 (Live documentary, February 4, 2015) ...|$|R
5000|$|<b>Bump</b> <b>of</b> Chicken Gold Glider Tour 2012 (Live video, March 6, 2013) ...|$|R
5000|$|Notable Highline Record artists: <b>BUMP</b> <b>OF</b> CHICKEN, Good Dog Happy Man, NANANINE ...|$|R
5000|$|<b>Bump</b> <b>of</b> Chicken — [...] "Good Luck" [...] (from Always Sanchōme no Yūhi 64) ...|$|R
5000|$|There are {{currently}} two conditions that trigger a major version <b>bump</b> <b>of</b> the JPEG library: ...|$|R
5000|$|Present from You is a B-side collection, by <b>Bump</b> <b>of</b> Chicken, {{released}} on June 18, 2008.|$|R
60|$|The <b>bumping</b> <b>of</b> a {{boat was}} again heard outside, then a {{trampling}} of feet, and all was still again.|$|R
5000|$|... "Harujion" [...] (ハルジオン) is {{the fourth}} single by <b>Bump</b> <b>of</b> Chicken. The title track is from the album jupiter.|$|R
30|$|The well in {{the thief}} zone has small {{pressure}} change and its <b>bump</b> <b>of</b> the pressure derivative is not obvious.|$|R
5000|$|... "R.I.P./Merry Christmas" [...] ("R.I.P./Merry Christmas") is {{the fifteenth}} single by <b>Bump</b> <b>of</b> Chicken that was {{released}} on November 25, 2009.|$|R
5000|$|... "Tentai Kansoku" [...] (天体観測) is {{the third}} single by <b>Bump</b> <b>of</b> Chicken. The title track is from the album Jupiter.|$|R
50|$|The {{song was}} used as the ending theme song for Tales of the Abyss, an anime {{adaption}} of the Namco role-playing video game of the same title. The single was produced by Motoo Fujiwara, lead vocalist <b>of</b> the band <b>Bump</b> <b>of</b> Chicken, and the band's producer and longtime collaborator with Enomoto, Mor. <b>Bump</b> <b>of</b> Chicken's song Karma {{was used as}} the original game's theme song, as well as the opening theme song for the anime.|$|R
5000|$|... "Snow Smile" [...] (スノースマイル) is {{the fifth}} single by <b>Bump</b> <b>of</b> Chicken. The title track is from the album Yggdrasil (ユグドラシル).|$|R
5000|$|The {{theme song}} for the movie is [...] "Niji wo Matsu Hito", {{performed}} by popular Japanese rock band <b>Bump</b> <b>of</b> Chicken.|$|R
6000|$|... "I should think, doctor," [...] remarked the captain, who was {{somewhat}} sceptical, [...] "that their <b>bumps</b> <b>of</b> combativeness {{must be very}} large." ...|$|R
5000|$|... "Zero" [...] (ゼロ) is Japanese {{rock band}} <b>Bump</b> <b>of</b> Chicken' 21st single. {{featured}} as the ending theme for video game, Final Fantasy Type-0.|$|R
50|$|This EP is {{the first}} time Enomoto has not worked with <b>Bump</b> <b>of</b> Chicken {{producer}} Mor since her debut under For Life Music.|$|R
5000|$|WHITE TEAM: Exile, Gesu no Kiwami Otome, Golden Bomber, Masahiko Kondō, SMAP, Hideaki Tokunaga, <b>Bump</b> <b>of</b> Chicken, Takashi Hosokawa, Akihiro Miwa, Shinichi Mori ...|$|R
5000|$|... "Planetarium" [...] (Puranetariumu) is {{the tenth}} single by <b>Bump</b> <b>of</b> Chicken, {{released}} on July 21, 2005. The title track {{is from the}} album Orbital Period.|$|R
