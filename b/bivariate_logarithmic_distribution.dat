0|326|Public
30|$|Weighted {{distribution}} theory gives {{a unified}} approach {{to dealing with}} model specification and data interpretation problems. Weighted distributions occur frequently in studies related to reliability, survival analysis, analysis of family data, biomedicine, ecology and several other areas, see Stene (1981) and Oluyede and George (2002). Many authors have presented important results on weighted distributions, Rao (1965) introduced a unified concept of weighted distribution and identified various sampling situations that can modeled by weighted distributions. These situations occur when the recorded observations can not be considered as a random sample from the original distributions. This mean that sometimes {{it is not possible to}} work with a truly random sample from population of interest. Zelen (1974) introduced weighted distribution to represent what broadly perceived as a length-biased sampling. Patil and Ord (1976) studied a size biased sampling and related invariant weighted distributions. Statistical applications of weighted distributions related to human population and ecology can be found in Patil and Rao (1978). Gupta and Tripathi (1996) studied the weighted version of the <b>bivariate</b> <b>logarithmic</b> series <b>distribution,</b> which has applications in many fields such as: ecology, social and behavioral sciences.|$|R
5000|$|<b>Logarithmic</b> <b>distribution,</b> a {{discrete}} probability distribution ...|$|R
40|$|International audienceSeveral {{empirical}} {{studies have shown}} that the animal group size distribution of many species can be well fit by power laws with exponential truncation. A striking empirical result due to H-S Niwa is that the exponent in these power laws is one and the truncation is determined by the average group size experienced by an individual. This distribution is known as the <b>logarithmic</b> <b>distribution.</b> In this paper we provide first principles derivations of the <b>logarithmic</b> <b>distribution</b> and other truncated power laws using a site-based merge and split framework. In particular, we investigate two such models. Firstly, we look at a model in which groups merge whenever they meet but split with a constant probability per time step. This generates a distribution similar, but not identical to the <b>logarithmic</b> <b>distribution.</b> Secondly, we propose a model, based on preferential attachment, that produces the <b>logarithmic</b> <b>distribution</b> exactly. Our derivation helps explain why <b>logarithmic</b> <b>distributions</b> are so widely observed in nature. The derivation also allows us to link splitting and joining behavior to the exponent and truncation parameters in power laws...|$|R
5000|$|In {{probability}} and statistics, the <b>logarithmic</b> <b>distribution</b> (also {{known as}} the <b>logarithmic</b> series <b>distribution</b> or the log-series distribution) is a discrete probability distribution derived from the Maclaurin series expansion ...|$|R
50|$|R. A. Fisher {{described}} the <b>logarithmic</b> <b>distribution</b> {{in a paper}} that used it to model relative species abundance.|$|R
50|$|Lagrange also {{suggested}} in 1781 two other distributions for errors - a Raised cosine <b>distribution</b> and a <b>logarithmic</b> <b>distribution.</b>|$|R
25|$|Numbers {{produced}} {{when doing}} any multiplicative calculations with an Oughtred slide rule, since the answers naturally {{fall into the}} right <b>logarithmic</b> <b>distribution.</b>|$|R
2500|$|The {{number of}} asteroids {{decreases}} markedly with size. Although this generally follows a power law, there are 'bumps' at [...] and , where more asteroids than expected from a <b>logarithmic</b> <b>distribution</b> are found.|$|R
2500|$|The {{negative}} {{binomial distribution}} NB(r,p) can be represented as a compound Poisson distribution: Let [...] denote a sequence of independent and identically distributed random variables, each one having the <b>logarithmic</b> <b>distribution</b> Log(p), with probability mass function ...|$|R
40|$|The coprecipitation of {{scandium}} with calcium as oxalate was studied. Precipitation {{of calcium}} {{was carried out}} in homogeneous precipitation system, in which dimethyl oxalate was decomposed to form oxalate ion. Homogeneous and <b>logarithmic</b> <b>distribution</b> coefficients were obtained by measuring radioactivity of Sc- 46 used as a tracer, and by the chelatometric titration of calcium. <b>Logarithmic</b> <b>distribution</b> was followed at pH 2. 0 [...] - 3. 5, whereas near pH 4 homogeneous distribution was obeyed. It was optimum for the enrichment of scandium, that calcium was precipitated at about 80 °C in the pH range between 2. 5 and 3. 0, and pre-cipitate was filtered after 2 or 3 hours...|$|R
40|$|Portfolio credit risk, CreditRisk +, Operational risk, Collective risk model, Extended {{negative}} binomial <b>distribution,</b> Extended <b>logarithmic</b> <b>distribution,</b> Compound distribution, Extended Panjer recursion, Numerical stability, De Pril’s recursion, Poisson mixture distribution, Generalized tempered stable distribution, (Generalized) inverse Gaussian distribution, Reciprocal generalized inverse Gaussian distribution, Inverse gamma distribution, Severities {{with mixed}} support, 91 B 30, 65 Q 05, 62 P 05, C 63, C 16,...|$|R
30|$|A {{large number}} of {{articles}} were reviewed to determine the candidate distributions, including the exponential <b>distribution,</b> <b>logarithmic</b> normal <b>distribution,</b> two-parameter Weibull distribution, and three-parameter Weibull distribution [16].|$|R
5000|$|The {{negative}} {{binomial distribution}} NB(r,p) can be represented as a compound Poisson distribution: Let {Yn, n ∈ ℕ0} denote a sequence of independent and identically distributed random variables, each one having the <b>logarithmic</b> <b>distribution</b> Log(p), with probability mass function ...|$|R
30|$|As already seen, the {{negative}} binomial distribution can be given a an accident proneness and a “spells” interpretation {{in the context of}} accident theory in terms of a gamma mixed Poisson distribution and a Poisson distribution generalized by a <b>logarithmic</b> <b>distribution</b> (Kemp [1967]).|$|R
40|$|The {{electron}} microscope {{has been used}} to determine the characteristic dimensions and the distribution of the dry mass in bull spermatozoa. The most important result is that all characteristic data are occurring in <b>logarithmic</b> <b>distributions.</b> Furthermore, no correlation between such parameters as head weight and tail weight or head length and tail length was found. The occurrence in <b>logarithmic</b> <b>distributions</b> and the non-correlation of parts in the assembly of a spermatozoon are considered to reflect significant biologic principles. Methodologically, a new procedure is added to quantitative electron microscopy permitting the recording of the mass cross-section (total mass per unit length) of an object. This approach makes possible determinations of the distribution and the total mass of very long and narrow structures...|$|R
40|$|A novel {{method is}} {{presented}} to describe population entities. It consists of 2 steps. First {{the structure of a}} population entity is described in terms of sub entities using a <b>logarithmic</b> <b>distribution.</b> This allows the uniform description of the World in continents, continents in countries, countries in provinces, provinces in cities, etc. Secondly the <b>logarithmic</b> <b>distribution</b> is simplified. This reveals the main structural differences and similarities at a certain level (countries in terms of provinces for example) and opens a window to study scale effects (comparing the description a province in cities and {{the world in terms of}} countries for example). The novel method is applied to the description of the European countries in terms of regions. The results are commented, focussing on the differences and similarities between Southern, Middle and Northern Europe. ...|$|R
40|$|An improvised {{algorithm}} is proposed {{based on the work}} of Yoshimoto and Harada. The improvised algorithm results a graph which is called LDGC or <b>Logarithmic</b> <b>Distribution</b> Graph of Curvature. This graph has the capability to identify the beauty of monotonic planar curves with less effort as compared to LDDC by Yoshimoto and Harada...|$|R
40|$|Relationships {{among the}} {{extended}} negative binomial, the extended Poisson and the extended <b>logarithmic</b> series <b>distributions</b> of order ? are discussed. The results are extentions of {{those for the}} usual distributions. discrete distributions of order ? extended negative binomial distribution of order ? extended Poisson distribution of order ? extended <b>logarithmic</b> series <b>distribution</b> of order ? generalized Poisson distribution...|$|R
40|$|Selection effects, {{connected}} with stochastic errors in source flux and threshold value determination are analyzed. Normal and normal <b>logarithmic</b> <b>distributions</b> of stochastic deviations are considered. These two kind of distributions produce different {{effects on the}} source statistics. Applications to Gamma Ray Burst statistics are discussed. A physical test for checking a close neutron star model of GRBs is suggested. ...|$|R
50|$|Woodcoin uses pure Skein. Its unit of {{exchange}} is LOG. It {{is similar to}} other cryptocurrencies, but has key differences, namely in its release schedule. Whereas most cryptocurrencies use an approach that has their block reward halved every so often, Woodcoin uses a <b>logarithmic</b> <b>distribution</b> model which gradually reduces the number of coins produced with each new block.|$|R
5000|$|... and [...] Solving for [...] and [...] and substituting {{into the}} general solution, we obtain [...] (7)The <b>logarithmic</b> <b>distribution</b> of the {{temperature}} is sketched in the inset of the thumbnail figure.Assuming that the temperature distribution, equation 7, is used with Fourier’s law in equation 5, the heat transfer rate can be expressed in the following form ...|$|R
40|$|We {{present a}} {{numerical}} program, CAESAR, {{that allows us}} to resum large logarithmic contributions to jet observables in a fully automated way. As an application we obtain the first next-to-leading <b>logarithmic</b> <b>distributions</b> for event shapes in hadronic dijet production. Comment: 5 pages, 1 figure. Talk presented at the XI International Workshop on Deep Inelastic Scattering, St. Petersburg, 23 - 27 April 200...|$|R
50|$|If X {{is defined}} {{to be the}} random {{variable}} which is the minimum of N independent realisations from an exponential distribution with rate paramerter &beta;, and if N is a realisation from a <b>logarithmic</b> <b>distribution</b> (where the parameter p in the usual parameterisation is replaced by (1 &minus; p)), then X has the exponential-logarithmic distribution in the parameterisation used above.|$|R
40|$|Abstract. Regulated {{emissions}} of a China stage common rail diesel engine without modification fueled with China stage diesel(D 100) and different n-butanol/diesel blends are tested. The blends are 0 %, 10 %, 20 %, 30 % and 50 % by volume of n-butanol. The influences of CO, THC, NOx and PM emissions by the fraction are analyzed. The results show that, under full load conditons, compared with D 100, with the fraction increasing, the emission of NOx increased {{at low speed}} and then differed little at medium and high speed; CO, THC decreased respectively; PM differed little at low speed and then decreased with the speed increasing. At the maximum torque speed 1400 r/min and rated speed 2200 r/min, compared with D 100,the emission of NOx under low load and CO, THC under high load decreased respectively. With the load increasing, the engine {{emissions of}} particle number concentration transfer from the multimodal <b>logarithmic</b> <b>distribution</b> to unimodal <b>logarithmic</b> <b>distribution</b> form. ...|$|R
30|$|Digital image {{tampering}} operations destroy inbuilt fingerprints {{and create}} own new fingerprint in the tampered region. Considering the Internet speed and storage space, {{most of the}} images are circulated in the JPEG format. In a single compressed JPEG image, the first digits of DCT coefficients follow a <b>logarithmic</b> <b>distribution.</b> This distribution is not followed by DCT coefficients of DCT grid aligned double compressed images. In a tampered image, the major portion of the original JPEG image is aligned double JPEG compressed. Hence, untampered region does not follow this <b>logarithmic</b> <b>distribution.</b> Due to the nonalignment of DCT compression grids, tampered region still follows this <b>logarithmic</b> <b>distribution.</b> Many tampering localization techniques have investigated this fingerprint, {{but the majority of}} them uses SVM classifier, specifically trained for the respective primary and secondary compression qualities of the test images. The efficiency of these classifiers is dependent on the knowledge of tampered image compression history. Hence, these approaches are not fully automated. In this paper, we have investigated a method, which does not require prior compression quality knowledge. Our experimental analysis shows that the addition of Gaussian noise can make the probability distribution of an aligned double compressed image similar to a nonaligned double compressed image. We divided the test image and its Gaussian version into sub-images and clustered them using K-means clustering algorithm. The application of K-means clustering algorithm does not require compression quality knowledge. This makes our approach more practical as compared to the other first digit probability distribution-based algorithms. The proposed algorithm gives compatible performance with the other approaches, based on different JPEG fingerprints.|$|R
40|$|J. M. Keynes (1911) {{shows how}} {{distributions}} look like {{for which the}} arithmetic, the geometric and the harmonic mean are most probable values. We propose a general class of distributions for which the quasi-arithmetic means are ML-estimators such that these distributions can be transformed into an normal or a truncated normal distribution. As special cases we get for example the generalized <b>logarithmic</b> <b>distributions</b> introduced by Chen (1995) ...|$|R
50|$|In {{the context}} of actuarial science, the {{distribution}} appeared in its general form in a paper by K. Hess, A. Liewald and K.D. Schmidt when they characterized all distributions for which the extended Panjer recursion works. For the case , the distribution was already discussed by Willmot and put into a parametrized family with the <b>logarithmic</b> <b>distribution</b> and the negative binomial distribution by H.U. Gerber.|$|R
50|$|More general {{distributions}} can {{be defined}} by fixing some initial values of pj and applying the recursion to define subsequent values. This can be of use in fitting distributions to empirical data. However, some further well-known distributions are available if the recursion above need only hold for a restricted range of values of k: for example the <b>logarithmic</b> <b>distribution</b> and the discrete uniform distribution.|$|R
40|$|Three {{generalised}} distributions are {{studied in}} this thesis from different aspects. The Hurwitz-Lerch zeta distribution (HLZD) that generalises the <b>logarithmic</b> <b>distribution</b> and a class of distributions that follows the power law is considered. To investigate the effects of parameters on the stochastic properties of the HLZD, stochastic orders between members in this large family are established. A relationship between the tail behaviours of the HLZD and that of a class of generalised <b>logarithmic</b> <b>distribution</b> is highlighted. The HLZD has shown good flexibilities in empirical modelling. A robust probability generating function based estimation method using Hellinger-type divergence is implemented in data-fitting {{and the results are}} compared with various other generalisations of <b>logarithmic</b> <b>distribution.</b> An augmented probability generating function is constructed to overcome the difficulties of this estimation procedure when some data are grouped. The Poisson-stopped sum of the Hurwitz-Lerch zeta distribution (Poisson-HLZD) is then proposed as a new generalisation of the negative binomial distribution. Several methods have been used in deriving the probability mass function for this new distribution to show the connections among different approaches from mathematics, statistics and actuarial science. Basic statistical measures and probabilistic properties of the Poisson-HLZD are examined and the usefulness of the model is demonstrated through examples of data-fitting on some real life datasets. Finally, the inverse trinomial distribution (ITD) is reviewed. Both Poisson-HLZD and ITD are proved to have mixed Poisson formulation, which extend the applications of the models for various phenomena. The associated mixing distribution for the ITD is obtained as an infinite Laguerre series and the result is compared to some numerical inversions of Laplace transform...|$|R
40|$|Objective-To {{investigate}} a reported fall in sperm counts during 1940 - 90 {{in relation to}} the reduced lower reference value of ''normal'' during the same period by assuming the null hypothesis that no change had occurred in the probability distribution of the sperm concentration. Design-Analysis by using various mathematical models of the probability distribution of sperm concentration together with experimental data which supported a model employing a <b>logarithmic</b> <b>distribution...</b>|$|R
40|$|Abstract: Three {{branches}} of the string theory landscape have plausibly been identified. One of these branches is expected to exhibit a roughly <b>logarithmic</b> <b>distribution</b> of supersymmetry breaking scales. The original KKLT models are in this class. We argue that certain features of the KKLT model are generic to this branch, and that the resulting phenomenology depends on a small set of discrete choices. As in the MSSM, the weak scale i...|$|R
40|$|Abstract. Selection effects, {{connected}} with stochastic errors in source flux and threshold value determination are analyzed. Normal and normal <b>logarithmic</b> <b>distributions</b> of stochastic deviations are considered. These two kind of distributions produce different {{effects on the}} source statistics. Applications to Gamma Ray Burst statistics are discussed. A physical test for checking a close neutron star model of GRBs is suggested. Key words: methods: statistical – gamma-rays: bursts – stars: neutron 1...|$|R
40|$|This paper {{presents}} {{a study on}} duration of silent pauses in spontaneous and read speech for several speaking styles in French. A univariate analysis shows that the observed multimodality is more exactly a mixture of <b>logarithmic</b> <b>distributions.</b> Then, various explanatory factors are considered, such as audible breathing, hesitation, speech rate and position regarding different level of syntactic boundaries, {{in order to build}} a predictive model of pause duration...|$|R
40|$|In 1881, Newcomb conjectured {{that the}} first {{significant}} digits (FSDs) of numbers in statistical tables would follow a <b>logarithmic</b> <b>distribution</b> with the digit “ 1 ” occurring most often. However, because Newcomb’s proposal was not presented with a theoretical basis, it was not given much attention. Fifty-seven years later, Benford argued for the same principle and showed it was relevant to a large range of data sets, and the <b>logarithmic</b> FSD <b>distribution</b> became known as “Benford’s Law. ” In the mid- 1940 s, Stigler claimed Benford’s Law contained a theoretical inconsistency and supplied an alternative derivation for the distribution of FSDs. In this paper, we examine the theoretical basis of the Stigler distribution and extend his reasoning by incorporating FSD first moment information and information-theoretic methods...|$|R
40|$|The {{modified}} {{geometric distribution}} for the population size of a time-inhomogeneous linear birth-and-death model is obtained by a simple graphical argument. A time-inhomogeneous birth-death-immigration process with a particular relationship between birth and immigration rates is shown to lead to Fisher's <b>logarithmic</b> series <b>distribution</b> for the abundance of families of a particular size (and hence to, for example, Ewens' formula for the allelic distribution of a population). inhomogeneous birth-death process inhomogeneous birth-death-immigration process <b>logarithmic</b> series <b>distribution...</b>|$|R
40|$|The cocrystn. of Ni-NH 4 sulfate with Cu-NH 4 sulfate was {{studied at}} low concns. of Ni salt, using radiotracer 63 Ni. The <b>logarithmic</b> <b>distribution</b> law H. A. Doerner and W. M. Hoskins (1925) holds good for this picromerite system. This {{leads to the}} {{conclusion}} that the crystals that sep. during crystn. are in momentary equil. with the mother liquor and, hence, the compn. of the crystals sepg. is not homogeneous. [on SciFinder(R) ...|$|R
